W99-0621	A88-1019	1999	The second instantiation finds the borders of phrases beginning and end and then pairs them in an optimal way into different phrases	0	These problems formulations are similar to those studied in <REF>Ramshaw and Marcus, 1995</REF> and <TREF>Church, 1988</TREF>; <REF>Argamon et al , 1998</REF>, respectively	1	The experimental results presented using the SNoW based approach compare favorably with previously published results, both for NPs and SV phrases	0	A s important, we present a few experiments that shed light on some of the issues involved in using learned predictors that interact to produce the desired inference	0	6	1
W99-0621	A88-1019	1999	Our earlier example would be marked for base NPs as: I wont to California last May	0	This approach has been studied in <TREF>Church, 1988</TREF>; <REF>Argamon et al , 1998</REF>	1	331 Architecture The architecture used for the Open/Close predictors is shown in Figure 2	0	Two SNoW predictors are used, one to predict if the word currently in consideration is the first in the phrase an open bracket, and the other to predict if it is the last a close bracket	0	6	1
W99-0621	A88-1019	1999	A lot of the work on shallow parsing over the past years has concentrated on manual construction of rules	0	The observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local part-of-speech information has motivated the use of learning methods to recognize these patterns <TREF>Church, 1988</TREF>; <REF>Ramshaw and Marcus, 1995</REF>; <REF>Argamon et al , 1998</REF>; <REF>Cardie and Pierce, 1998</REF>	1	 Research supported by NSF grants IIS-9801638 and SBR-9873450	0	t Research supported by NSF grant CCR-9502540	0	6	1
W02-0102	A88-1019	2002	HMMs have long been central in speech recognition <REF>Rabiner, 1989</REF>	0	Their application to partof-speech tagging <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF> kicked off the era of statistical NLP, and they have found additional NLP applications to phrase chunking, text segmentation, word-sense disambiguation, and information extraction	1	The algorithm is also important to teach for pedagogical reasons, as the entry point to a family of EM algorithms for unsupervised parameter estimation	0	Indeed, it is an instructive special case of 1 the inside-outside algorithm for estimation of probabilistic context-free grammars; 2 belief propagation for training singly-connected Bayesian networks and junction trees <REF>Pearl, 1988</REF>; <REF>Lauritzen, 1995</REF>; 3 algorithms for learning alignment models such as weighted edit distance; 4 general finitestate parameter estimation <REF>Eisner, 2002</REF>	0	6	1
H91-1037	A88-1019	1991	Subsequent analysis suggested that half the errors could be removed with only a little additional work, suggesting that over 90 performance is achievable	0	In a related test, we explored the bracketings produced by Churchs PARTS program <TREF>Church, 1988</TREF>	1	We extracted 200 sentences of WSJ text by taking every tenth sentence from a collection of manually corrected parse trees data from the TREEBANK Project at the University of Pennsylvania	0	We evaluated the NP bracketings in these 200 sentences by hand, and tried to classify the errors	0	6	1
P98-2208	A88-1019	1998	Given that each token has on the average more than 2 possible tags, the procedural description above is very inefficient for all but very short sentences	0	However, the observation that our constraints are localized to a window of a small number of tokens say at most 5 tokens in a sequence, suggests a more efficient scheme originally used by <TREF>Church 1988</TREF>	1	Assume our constraint windows are allowed to look at a window of at most size k sequential parses	0	Let us take the first k tokens of a sentence and generate all possible paths of k arcs spanning k  1 nodes, and apply all constraints to these short paths	0	1	2
P98-2208	A88-1019	1998	Part-of-speech tagging is one of the preliminary steps in many natural language processing systems in which the proper part-of-speech tag of the tokens comprising the sentences are disambiguated using either statistical or symbolic local contextual information	0	Tagging systems have used either a statistical approach where a large corpora is employed to train a probabilistic model which then is used to tag unseen text, eg , <TREF>Church 1988</TREF>, Cutting et al	1	1992, <REF>DeRose 1988</REF>, or a constraint-based approach which employs a large number of hand-crafted linguistic constraints that are used to eliminate impossible sequences or morphological parses for a given word in a given context, recently most prominently exemplified by the Constraint Grammar work <REF>Karlsson et al , 1995</REF>; <REF>Voutilainen, 1995b</REF>; <REF>Voutilainen et al , 1992</REF>; <REF>Voutilainen and Tapanainen, 1993</REF>	0	BriU 1992; 1994; 1995 has presented a transformationbased learning approach	0	6	1
J93-2004	A88-1019	1993	 Right close double quote 231 Automated Stage	0	During the early stages of the Penn Treebank project, the initial automatic POS assignment was provided by PARTS <TREF>Church 1988</TREF>, a stochastic algorithm developed at ATT Bell Labs	1	PARTS uses a modified version of the Brown Corpus tagset close to our own and assigns POS tags with an error rate of 3-5	0	The output of PARTS was automatically tokenized 8 and the tags assigned by PARTS were automatically mapped onto the Penn Treebank tagset	0	3	1
W96-0305	A88-1019	1996	Various methods for POS tagging have been proposed in recent years	0	For simplicity, we adapted the method proposed by <REF>Churchl1988</REF> to tag the definition sentence	1	In the second stage, we select the label which is associated with word lists most similar to the definition as the result	0	We sum up the above descriptions and outline the procedure for labeling a dictionary sense	0	3	1
P97-1030	A88-1019	1997	The experimental results show the proposed method significantly outperforms both hand-crafted and conventional statistical methods	0	The last few years have seen the great success of stochastic part-of-speech POS taggers <TREF>Church, 1988</TREF>: <REF>Kupiec, 1992</REF>; Charniak et M , 1993; <REF>Brill, 1992</REF>; <REF>Nagata, 1994</REF>	1	The stochastic approach generally attains 94 to 96 accuracy and replaces the labor-intensive compilation of linguistics rules by using an automated learning algorithm	0	However, 1NTT is an abbreviation of Nippon Telegraph and Telephone Corporation	0	1	2
P96-1008	A88-1019	1996	1	0	A recent trend in natural language processing has been toward a greater emphasis on statistical approaches, beginning with the success of statistical part-of-speech tagging programs <TREF>Church 1988</TREF>, and continuing with other work using statistical part-of-speech tagging programs, such as BBN PLUM <REF>Weischedel et al 1993</REF> and NYU Proteus <REF>Grishman and Sterling 1993</REF>	1	More recently, statistical methods have been applied to domain-specific semantic parsing <REF>Miller et al 1994</REF>, and to the more difficult problem of wide-coverage syntactic parsing <REF>Magerman 1995</REF>	0	Nevertheless, most natural language systems remain primarily rule based, and even systems that do use statistical techniques, such as ATT Chronus <REF>Levin and Pieraccini 1995</REF>, continue to require a significant rule based component	0	1	2
C96-2114	A88-1019	1996	The training is performed on ambiguity classes and not on individual word tokens	0	<REF>Kallgren 1996</REF> gives a more covering description of how XPOST is used on the Swedish material and also sketches the major differences between this algorithm and some others used for tagging, such as PARTS <TREF>Church 1988</TREF> and VOLSUNGA <REF>DeRose 1988</REF>	1	A characteristic tbature of the SUC is its high number of different tags	0	The number of part-ofspeech tags used in the SUC is 21	0	6	1
J02-3002	A88-1019	2002	Disambiguation of capitalized words is usually handled by POS taggers, which treat capitalized words in the same way as other categories, that is, by accounting for the immediate syntactic context and using estimates collected from a training corpus	0	<REF>As Church 1988</REF> rightly pointed out, however, Proper nouns and capitalized words are particularly problematic: some capitalized words are proper nouns and some are not	1	Estimates from the Brown Corpus can be misleading	0	For example, the capitalized word Acts is found twice in the Brown Corpus, both times as a proper noun in a title	0	1	2
C98-1060	A88-1019	1998	The morphological ambiguity will differ depending on the level of tagging used in each case, as shown in table 2	0	There are two kinds of methods for morphological disambiguation: on one hand, statistical methods need little effort and obtain very good results <TREF>Church, 1988</TREF>; Cutting el al, 1992, at least when applied to English, but when we try to apply them to Basque we encounter additional problems; on the other hand, some rule-based systems <REF>Brill, 1992</REF>; <REF>Voutilainen et al, 1992</REF> are at least as good as statistical systems and are better adapted to free-order languages and agglutinative languages	1	So, we 381 have selected one of each group: Constraint Grammar formalism <REF>Karlsson et al, 1995</REF> and the HMM based TATOO tagger <REF>Armstrong et al, 1995</REF>, which has been designed to be applied it to the output of a morphological analyser and the tagset can be switched easily without changing the input text	0	second  third 70 ks I M M MCG MCG Figure 1-Initial ambiguity3	0	1	2
H90-1055	A88-1019	1990	We are tagging this material with a much simpler tagset than used by previous projects, as discussed at the Oct 1989 DARPA Workshop	0	The material is first processed using Ken Churchs tagger <TREF>Church 1988</TREF>, which labels it as if it were Brown Corpus material, and then is mapped to our tagset by a SEDscript	1	Because of fundamental differences in tagging strategy between the Penn Treebank Project and the Brown project, the resulting mapping is about 9 inaccurate, given the tagging guidelines of the Penn Treebank project as given in 40 pages of explicit tagging guidelines	0	This material is then hand-corrected by our annotators; the result is consistent within annotators to about 3 cf	0	3	2
H90-1055	A88-1019	1990	H90-1055:17	0	Deducing Linguistic Structure from the Statistics of Large Corpora Eric Brill David Magerman Mitchell Marcus Beatrice Santorini Department of Computer and Information Science University of Pennsylvania Philadelphia, PA 19104 1 Introduction Within the last two years, approaches using both stochastic and symbolic techniques have proved adequate to deduce lexical ambiguity resolution rules with less than 3-4 error rate, when trained on moderate sized 500K word corpora of English text eg <TREF>Church, 1988</TREF>; <REF>Hindle, 1989</REF>	1	The success of these techniques suggests that much of the grammatical structure of language may be derived automatically through distributional analysis, an approach attempted and abandoned in the 1950s	0	We describe here two experiments to see how far purely distributional techniques can be pushed to automatically provide both a set of part of speech tags for English, and a grammatical analysis of free English text	0	3	2
H90-1055	A88-1019	1990	This line of research was motivated by a series of successful applications of mutual information statistics to other problems in natural language processing	0	In the last decade, research in speech recognition <REF>Jelinek 1985</REF>, noun classification <REF>Hindle 1988</REF>, predicate argument relations <REF>Church  Hanks 1989</REF>, and other areas have shown that mutual information statistics provide a wealth of information for solving these problems	1	22 Mutual Information Statistics The mutual information statistic <REF>Fano 1961</REF> is a measure of the interdependence of two signals in a message	0	It is a function of the probabilities of the two events: Mz, u  log u xzPvy In this paper, the events x and y will be part-of-speech n-grams instead of single parts-of-speech, as in some earlier work	0	4	2
W97-0902	A88-1019	1997	Each of these three steps will be described below	0	3 The preprocessing stage The noun phrase parser identifies simple non-recursive noun phrases such as DetAdjN or NN The method used for this process involves an algorithm of the type described in <TREF>Church 1988</TREF> which was trained on a manually marked part of our corpus	1	The module is thus geared to the particular type of second language text the checker needs to deal with	0	The resulting information is passed on to a preprocessing module consisting of a number of automata groups	0	3	1
P00-1015	A88-1019	2000	Measures/NNS of/IN manufacturing/VBG activity/NN fell/VBD more/RBR than/IN the/DT overall/JJ measures/NNS/	0	Figure 1: An example sentence with baseNP brackets A number of researchers have dealt with the problem of baseNP identification <TREF>Church 1988</TREF>; <REF>Bourigault 1992</REF>; <REF>Voutilainen 1993</REF>; <REF>Justeson  Katz 1995</REF>	1	Recently some researchers have made experiments with the same test corpus extracted from the 20 th section of the Penn Treebank Wall Street Journal Penn Treebank	0	<REF>Ramshaw  Markus 1998</REF> applied transformbased error-driven algorithm <REF>Brill 1995</REF> to learn a set of transformation rules, and using those rules to locally updates the bracket positions	0	6	1
P07-2053	A88-1019	2007	4 Concluding remarks Though there can be little doubt that the ruling system of bakeoffs actively encourages a degree of oneupmanship, our paper and our software are not offered in a competitive spirit	0	As we said at the out211 set, we dont necessarily believe HunPos to be in any way better than TnT, and certainly the main ideas have been pioneered by <REF>DeRose 1988</REF>, <TREF>Church 1988</TREF>, and others long before this generation of HMM work	1	But to improve the results beyond what a basic HMM can achieve one needs to tune the system, and progress can only be made if the experiments are end to end replicable	0	There is no doubt many other systems could be tweaked further and improve on our results what matters is that anybody could now also tweak HunPos without any restriction to improve the state of the art	0	1	2
P99-1009	A88-1019	1999	In this paper we describe experiments we performed to ascertain how well humans, given an annotated training set, can generate rules for base noun phrase chunking	0	Much previous work has been done on this problem and many different methods have been used: Churchs PARTS 1988 program uses a Markov model; <REF>Bourigault 1992</REF> uses heuristics along with a grammar; Voutilainens NP<REF>Tool 1993</REF> uses a lexicon combined with a constraint grammar; <REF>Juteson and Katz 1995</REF> use repeated phrases; <REF>Veenstra 1998</REF>, Argamon, Dagan  <REF>Krymolowski1998</REF> and Daelemaus, van den <REF>Bosch  Zavrel 1999</REF> use memory-based systems; Ramshaw  Marcus In Press and <REF>Cardie  Pierce 1998</REF> use rule-based systems	1	2 Learning Base Noun Phrases by Machine We used the base noun phrase system of Ramshaw and Marcus RM as the machine learning system with which to compare the human learners	0	It is difficult to compare different machine learning approaches to base NP annotation, since different definitions of base NP are used in many of the papers, but the RM system is the best of those that have been tested on the Penn Treebank	0	6	1
P91-1030	A88-1019	1991	The suggestion which we want to explore is that the association revealed by textual distribution whether its source is a complementation relation, a modification relation, or something else gives us information needed to resolve the prepositional attachment	0	Discovering Lexical Association in Text A 13 million word sample of Associated Press new stories from 1989 were automatically parsed by the Fidditch parser <REF>Hindle 1983</REF>, using Churchs part of speech analyzer as a preprocessor <TREF>Church 1988</TREF>	1	From the syntactic analysis provided by the parser for each sentence, we extracted a table containing all the heads of all noun phrases	0	For each noun phrase head, we recorded the following preposition if any occurred ignoring whether or not the parser attached the preposition to the noun phrase, and the preceding verb if the noun phrase was the object of that verb	0	3	1
J93-3003	A88-1019	1993	We also looked at whether the token constituted an entire intermediate or intonational phrase--possibly with other cue phrases--or not, and what each tokens position within its intermediate phrase and larger intonational phrase was--first-inphrase again, including tokens preceded only by other cue phrases as well as tokens that were absolutely first in intermediate phrase, last, or other	0	We also examined each items part of speech, using Churchs 1988 part-of-speech tagger	1	Finally, we investigated orthographic features of the transcript that might be associated with a discourse/sentential distinction, such as immediately preceding and succeeding punctuation and paragraph boundaries	0	In both the syntactic and orthographic analyses we were particularly interested in discovering how successful nonprosodic features that might be obtained automatically from a text would be in differentiating discourse from sentential uses	0	3	1
J93-3003	A88-1019	1993	While the use of orthographic and part-of-speech data represents only a fractional improvement over orthographic information alone, it is possible that, since the latter is not subject to transcriber idiosyncracy, such an approach may prove more reliable than orthography alone in the general case	0	And, for text-to-speech applications, it 7 The parbof-speech tagger employed in this analysis <TREF>Church 1988</TREF> uses a subset of the part-of-speech tags used in Francis and Kuera 1982	1	We have translated these for Table 12	0	Note that intensifier corresponds to QU in Francis and Kuera 1982	0	3	1
W97-0110	A88-1019	1997	Research on corpus-based natural language learning and processing is rapidly accelerating following the introduction of large on-line corpora, faster computers, and cheap storage devices	0	Recent work involves novel ways to employ annotated corpus in part of speech tagging <TREF>Church 1988</TREF> <REF>Derose 1988</REF> and the application of mutual information statistics on the corpora to uncover lexical information <REF>Church 1989</REF>	1	The goal of the research is the construction of robust and portable natural language processing systems	0	The wide range of topics available on the Internet calls for an easily adaptable information extraction system for different domains	0	6	1
C96-1041	A88-1019	1996	Part-of-speech tagging is to assign the correct tag to each word in the context of the sentence	0	here are three main approaches in tagging problem: rule-based approach Klein and Simmons 13; <REF>Brodda 1982</REF>; <REF>Paulussen and Martin 1992</REF>; <REF>Brill et al 1990</REF>, statistical approach Church :1988; <REF>Merialdo 1994</REF>; <REF>Foster 1991</REF>; <REF>Weischedel et al 1993</REF>; <REF>Kupiec 1992</REF> and connectionist approach <REF>Benello et al 1989</REF>; <REF>Nakanmra et al 1989</REF>	1	In these approaches, statistical approach has the following advantages :  a theoretical framework is provided  automatic learning facility is provided  the probabilities provide a straightforward way to disambiguate Many information sources must be combined to solve tagging problem with statistical approach	0	It is a significant assumption that tire correct tag can generally be chosen from Ihe local context	0	6	1
P96-1041	A88-1019	1996	In this study, we measure performance solely through the cross-entropy of test data; it would be interesting to see how these cross-entropy differences correlate with performance in end applications such as speech recognition	0	In addition, it would be interesting to see whether these results extend to fields other than language modeling where smoothing is used, such as prepositional phrase attachment <REF>Collins and Brooks, 1995</REF>, part-of-speech tagging <TREF>Church, 1988</TREF>, and stochastic parsing <REF>Magerman, 1994</REF>	1	317 Acknowledgements The authors would like to thank Stuart Shieber and the anonymous reviewers for their comments on previous versions of this paper	0	We would also like to thank William Gale and Geoffrey Sampson for supplying us with code for Good-Turing frequency estimation without tears	0	6	1
P96-1041	A88-1019	1996	In addition, we introduce two novel smoothing techniques, one a variation of Jelinek-Mercer smoothing and one a very simple linear interpolation technique, both of which outperform existing methods	0	Smoothing is a technique essential in the construction of n-gram language models, a staple in speech recognition <REF>Bahl, Jelinek, and Mercer, 1983</REF> as well as many other domains <TREF>Church, 1988</TREF>; <REF>Brown et al , 1990</REF>; <REF>Kernighan, Church, and Gale, 1990</REF>	1	A language model is a probability distribution over strings Ps that attempts to reflect the frequency with which each string s occurs as a sentence in natural text	0	Language models are used in speech recognition to resolve acoustically ambiguous utterances	0	6	1
P98-2123	A88-1019	1998	In practice, computational limitations do not allow the enumeration of all possible assignments for long sentences, and smoothing is required for infrequent events	1	This is described in more detail in the original publication <TREF>Church, 1988</TREF>	0	Although more sophisticated algorithms for unsupervised learning which can be trained on plain text instead on manually tagged corpora are well established see eg <REF>Merialdo, 1994</REF>, we decided not to use them	0	The main reason is that with large tag sets, the sparse-data-problem can become so severe that unsupervised training easily ends up in local minima, which can lead to poor results without any indication to the user	0	1	3
P98-2123	A88-1019	1998	<REF>Lezius, Rapp  Wettler 1996</REF> give an overview on some German tagging projects	0	Although we considered a number of algorithms, we decided to use the trigram algorithm described by <TREF>Church 1988</TREF> for tagging	1	It is simple, fast, robust, and among the statistical taggers still more or less unsurpassed in terms of accuracy	0	Conceptually, the Church-algorithm works as follows: For each sentence of a text, it generates all possible assignments of part-of-speech tags to words	0	3	1
J99-2004	A88-1019	1999	A more detailed discussion of LTAGs with an example and some of the key properties of elementary trees is presented in Appendix A 4	0	Supertags Part-of-speech disambiguation techniques POS taggers <TREF>Church 1988</TREF>; <REF>Weischedel et al 1993</REF>; <REF>Brill 1993</REF> are often used prior to parsing to eliminate or substantially reduce the part-of-speech ambiguity	1	The POS taggers are all local in the sense that they use information from a limited context in deciding which tags to choose for each word	0	As is well known, these taggers are quite successful	0	6	1
J99-2004	A88-1019	1999	We tested the performance of the unigram model on the previously discussed two sets of data	0	The words are first assigned standard parts of speech using a conventional tagger <TREF>Church 1988</TREF> and then are assigned supertags according to the unigram model	1	A word in a sentence is considered correctly supertagged if it is assigned the same supertag as it is associated with in the correct parse of the sentence	0	The results of these experiments are tabulated in Table 4	0	3	1
W00-0721	A88-1019	2000	Some external mechanism is assumed to consistently or stochastically annotate substrings as phrases 2	0	Our goal is to come up with a mechanism that, given an input string, identifies the phrases in this string, this is a fundamental task with applications in natural language <TREF>Church, 1988</TREF>; <REF>Ramshaw and Marcus, 1995</REF>; <REF>Mufioz et al , 1999</REF>; <REF>Cardie and Pierce, 1998</REF>	1	The identification mechanism works by using classifiers that process the input string and recognize in the input string local signals which  This research is supported by NSF grants IIS-9801638, SBR-9873450 and IIS-9984168	0	1Full version is in <REF>Punyakanok and Roth, 2000</REF>	0	6	1
C00-1046	A88-1019	2000	Much research has been donc Oll knowledge acquisition fiom large-scalc annotated corpora as a rich source of linguistic knowledge	0	Mtior works done to create English POS taggers henceforth, taggers, for example, include <TREF>Church 1988</TREF>, <REF>Kupicc 1992</REF>, <REF>Brill 1992</REF>and <REF>Voutilaincn et al 1992</REF>	0	The problem with this framework, however, is that such reliable corpora are hardly awdlable duc to a huge amount of the labor-intensive work required	1	In case of the acquisition of non-core knowledge, such as specific, lexically or dolnain dependent knowledge, preparation of annotated corpora becomes more serious problem	0	1	3
W96-0209	A88-1019	1996	2	0	PART:OF-SPEECH TAG SEQUENCE GRAMMAR We utilised the ANLT metagrammatical formalism to develop a feature-based, declarative description of part-of-speech PoS label sequences see eg <TREF>Church, 1988</TREF> for English	1	This grammar compiles into a DCG-like grammar of approximately 400 rules	0	It has been designed to enumerate possible valencies for predicates verbs, adjectives and nouns by including separate rules for each pattern of possible complementation in English	0	6	1
N03-1035	A88-1019	2003	But dictionaries of technical terminology have many one-word terms	0	Simplex or complex NPs eg , <TREF>Church 1988</TREF>; <REF>Hindle and Rooth 1991</REF>; <REF>Wacholder 1998</REF> identify simplex or base NPs  NPs which do not have any component NPs -at least in part because this bypasses the need to solve the quite difficult attachment problem, ie, to determine which simpler NPs should be combined to output a more complex NP	0	But if people find complex NPs more useful than simpler ones, it is important to focus on improvement of techniques to reliably identify more complex terms	1	Semantic and syntactic terms variants	0	1	3
J00-4004	A88-1019	2000	As described in Section 3, each indicator has a unique value for each verb, which corresponds to the frequency of the aspectual marker with the verb except verb frequency, which is an absolute measure over the corpus	0	6 Similar baselines for comparison have been used for many classification problems <REF>Duda and Hart 1973</REF>, eg, part-of-speech tagging <TREF>Church 1988</TREF>; <REF>Allen 1995</REF>	1	611 Computational Linguistics Volume 26, Number 4 The second and third columns of Table 9 show the average value for each indicator over stative and event clauses, as measured over the training examples which exclude be and have	0	These values are computed solely over the 739 training cases in order to avoid biasing the classification experiments in the sections below, which are evaluated over the unseen test cases	0	6	1
J97-3003	A88-1019	1997	To assign capitalized unknown words the category proper noun seems a good heuristic, but may not always work	0	As argued in <TREF>Church 1988</TREF>, who proposes a more elaborated heuristic, <REF>Dermatas and Kokkinakis 1995</REF> proposed a simple probabilistic approach to unknown-word guessing: HCRC, Language Technology Group, University of Edinburgh, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, UK	1	Q 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 3 Table 1 The most frequent open-class tags from the Penn tag set	0	Tag Meaning Example Tag Meaning Example NN common noun table NNS noun plural tables NNP proper noun John NNPS plural proper noun Vikings JJ adjective green RB adverb naturally VB verb base form take VBD verb past took VBG gerund taking VBN past participle taken VBZ verb present, 3d person takes VBP verb, present, non-3d take the probability that an unknown word has a particular Pos-tag is estimated from the probability distribution of hapax words words that occur only once in the previously seen texts	0	6	1
J97-3003	A88-1019	1997	Although our primary goal was not to compare the taggers themselves but rather their performance with the guessing components, we attribute the difference in their performance to the fact that Brills tagger uses the information about the most likely tag for a word whereas the HMM tagger did not have this information and instead used the priors for a set of POS-tags ambiguity class	0	When we removed from the lexicon all the hapax words and, following the recommendation of <TREF>Church 1988</TREF>, all the capitalized words with frequency less than 20, we obtained some 51,522 unknown word-tokens 25,359 wordtypes out of more than a million word-tokens in the Brown Corpus	1	We tagged the fifteen subcorpora of the Brown Corpus by the four combinations of the taggers and the guessers using the lexicon of 22,260 word-types	0	42 Results of the Experiment Table 4 displays the tagging results on the unknown words obtained by the four different combinations of taggers and guessers	0	3	1
N06-1042	A88-1019	2006	In the 329 rule-based approach a large number of hand crafted rules are used to select the correct morphological parse or POS tag of a given word in a given context <REF>Karlsson et al , 1995</REF>; Oflazer and Tcurrency1ur, 1997	0	In the statistical approach a hand tagged corpus is used to train a probabilistic model which is then used to select the best tags in unseen text <TREF>Church, 1988</TREF>; Hakkani-Tcurrency1ur et al , 2002	1	Examples of statistical and machine learning approaches that have been used for tagging include transformation based learning <REF>Brill, 1995</REF>, memory based learning <REF>Daelemans et al , 1996</REF>, and maximum entropy models <REF>Ratnaparkhi, 1996</REF>	0	It is also possible to train statistical models using unlabeled data with the expectation maximization algorithm <REF>Cutting et al , 1992</REF>	0	6	1
P97-1023	A88-1019	1997	After presenting our results and evaluation, we discuss simulation experiments that show how our method performs under different conditions of sparseness of data	0	3 Data Collection For our experiments, we use the 21 million word 1987 Wall Street Journal corpus 4, automatically annotated with part-of-speech tags using the PARTS tagger <TREF>Church, 1988</TREF>	1	In order to verify our hypothesis about the orientations of conjoined adjectives, and also to train and evaluate our subsequent algorithms, we need a 3Certain words inflected with negative affixes such as inor un- tend to be mostly negative, but this rule applies only to a fraction of the negative words	0	Furthermore, there are words so inflected which have positive orientation, eg, independent and unbiased	0	3	1
C00-1044	A88-1019	2000	For example, ve O, dead can be used tkr emphasis, and relet am relet as in her lhce became redder and redder can be used to indicate a progression of coloring, qb distinguish between truly gradablc adjectives and non-gradable adjectives in these exceptional contexts, we have developed a trainable log-linear statistical model that lakes into account tile number of times an adiective has been observed in a form or context indicating gradability relative to the number of limes it has been seen in non-gradable contexts	0	We use a shallow parser to retrieve from a large corpus tagged for part-of-speech with Churchs PARTS tagger <TREF>Church, 1988</TREF> all adjectives and their modifiers	1	Although the most common use of an adverb modifying an adjective is to function as an intensilier or diminisher <REF>Quirk et al , 1985</REF>, p 445, adverbs can also add to tile semantic content of the adjectival phrase instead of providing a grading effect eg , immediately available, politically vuhmrable, or function as cmphasizers, adding to the force o1 tile base adjective and not lo its degree eg , virtually impossible; compare re O, impossible	0	Therefore, we compiled by hand a list of 73 adverbs and noun phrases such as a little, exceedingly, somewhat, and veo that are fiequently used as grading moditicrs	0	3	1
P96-1010	A88-1019	1996	More precisely, assume that the word wh occurs in a sentence W  wlWkwn, and that w is a word we are considering substituting for it, yielding sentence W I Word w is then preferred over wk iff PW > PW, where PW and PW are the probabilities of sentences W and W f respectively	0	1 We calculate PW using the tag sequence of W as an intermediate quantity, and summing, over all possible tag sequences, the probability of the sentence with that tagging; that is: PW   PW, T T where T is a tag sequence for sentence W The above probabilities are estimated as is traditionally done in trigram-based part-of-speech tagging <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF>: PW,T  PWITPT  1  HPwiti HPt, lt,2t,l2 i i where T  tltn, and Ptitl-2ti-1 is the prob ability of seeing a part-of-speech tag tl given the two preceding part-of-speech tags ti-2 and ti-1	1	Equations 1 and 2 will also be used to tag sentences W and W  with their most likely part-of-speech sequences	0	This will allow us to determine the tag that 1To enable fair comparisons between sequences of different length as when considering maybe and may be, we actually compare the per-word geometric mean of the sentence probabilities	0	6	1
E95-1022	A88-1019	1995	Its recall is very high 997 of all words receive the correct morphological analysis, but this system leaves 3-7 of all words ambiguous, trading precision for recall	0	157 ena or the linguists abstraction capabilities eg knowledge about what is relevant in the context, they tend to reach a 95-97 accuracy in the analysis of several languages, in particular English <REF>Marshall 1983</REF>; Black et aL 1992; <TREF>Church 1988</TREF>; <REF>Cutting et al 1992</REF>; de <REF>Marcken 1990</REF>; <REF>DeRose 1988</REF>; <REF>Hindle 1989</REF>; <REF>Merialdo 1994</REF>; <REF>Weischedel et al 1993</REF>; <REF>Brill 1992</REF>; <REF>Samuelsson 1994</REF>; Eineborg and Gambick 1994, etc	1	Interestingly, no significant improvement beyond the 97 barrier by means of purely data-driven systems has been reported so far	0	In terms of the accuracy of known systems, the data-driven approach seems then to provide the best model of part-of-speech distribution	0	6	1
C98-1034	A88-1019	1998	Figure 1: Base NP Examples base noun phrases with initial determiners and modifiers removed: <REF>Justeson  Katz 1995</REF> look for repeated phrases; <REF>Bourigault 1992</REF> uses a handcrafted noun phrase grammar in conjunction with heuristics for finding maximal length noun phrases; Voutilainens NP<REF>Tool 1993</REF> uses a handcrafted lexicon and constraint grammar to find terminological noun phrases that include phrase-final prepositional phrases	0	Churchs PARTS program 1988, on the other hand, uses a probabilistic model automatically trained on the Brown corpus to locate core noun phrases as well as to assign parts of speech	1	More recently, Ramshaw  Marcus In press apply transformation-based learning <REF>Brill, 1995</REF> to the problem	0	Unfortunately, it is difficult to directly compare approaches	0	6	1
A00-1026	A88-1019	2000	1993 call the core noun phrase, that is a noun phrase with no modification to the right of the head	0	Several approaches provide similar output based on statistics <TREF>Church 1988</TREF>, <REF>Zhai 1997</REF>, for example, a finite-state machine <REF>AitMokhtar and Chanod 1997</REF>, or a hybrid approach combining statistics and linguistic rules <REF>Voutilainen and Padro 1997</REF>	1	The SPECIALIST parser is based on the notion of barrier words <REF>Tersmette et al 1988</REF>, which indicate boundaries between phrases	0	After lexical look-up and resolution of category label ambiguity by the Xerox tagger, complementizers, conjunctions, modals, prepositions, and verbs are marked as boundaries	0	6	1
W00-0737	A88-1019	2000	Finally, memory-based learning is adopted to further improve the performance of the chunk tagger	0	The idea of using statistics for chunking goes back to <TREF>Church1988</TREF>, who used corpus frequencies to determine the boundaries of simple nonrecursive noun phrases	1	Skut and <REF>Brants1998</REF> modified Churchs approach in a way permitting efficient and reliable recognition of structures of limited depth and encoded the structure in such a way that it can be recognised by a Viterbi tagger	0	Our approach follows Skut and Brants way by employing HMM-based tagging method to model the chunking process	0	6	1
W00-1320	A88-1019	2000	Thus, Examples 3-5 illustrate how the syntactic context of a word can help determine its meaning	0	22 Motivation from previous work 221 Parsing In recent years, the success of statistical parsing techniques can be attributed to several factors, such as the increasing size of computing machinery to accommodate larger models, the availability of resources such as the Penn Treebank <REF>Marcus et al , 1993</REF> and the success of machine learning techniques for lowerlevel NLP problems, such as part-of-speech tagging <TREF>Church, 1988</TREF>; <REF>Brill, 1995</REF>, and PPattachment <REF>Brill and Resnik, 1994</REF>; <REF>Collins and Brooks, 1995</REF>	1	However, perhaps even more significant has been the lexicalization of the grammar formalisms being probabilistically modeled: crucially, all the recent, successful statistical parsers have in some way made use of bilexical dependencies	0	This includes both the parsers that attach probabilities to parser moves <REF>Magerman, 1995</REF>; <REF>Ratnaparkhi, 1997</REF>, but also those of the lexicalized PCFG variety <REF>Collins, 1997</REF>; <REF>Charniak, 1997</REF>	0	1	2
W01-0706	A88-1019	2001	to  NP only  18 billion  PP in  NP September  While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information  by examining the pattern itself, its nearby context and the local part-of-speech information	0	Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <REF>Collins, 1997</REF>; <REF>Charniak, 1997a</REF>; <REF>Charniak, 1997b</REF>; <REF>Ratnaparkhi, 1997</REF>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns  syntactic phrases or words that participate in a syntactic relationship <TREF>Church, 1988</TREF>; <REF>Ramshaw and Marcus, 1995</REF>; <REF>Argamon et al , 1998</REF>; <REF>Cardie and Pierce, 1998</REF>; <REF>Munoz et al , 1999</REF>; <REF>Punyakanok and Roth, 2001</REF>; <REF>Buchholz et al , 1999</REF>; Tjong <REF>Kim Sang and Buchholz, 2000</REF>	1	Research on shallow parsing was inspired by psycholinguistics arguments <REF>Gee and Grosjean, 1983</REF> that suggest that in many scenarios eg , conversational full parsing is not a realistic strategy for sentence processing and analysis, and was further motivated by several arguments from a natural language engineering viewpoint	0	First, it has been noted that in many natural language applications it is sufficient to use shallow parsing information; information such as noun phrases NPs and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization <REF>Grishman, 1995</REF>; <REF>Appelt et al , 1993</REF>	0	6	1
J00-3003	A88-1019	2000	33 Dialogue Act Decoding The HMM representation allows us to use efficient dynamic programming algorithms to compute relevant aspects of the model, such as  the most probable DA sequence the Viterbi algorithm  the posterior probability of various DAs for a given utterance, after considering all the evidence the forward-backward algorithm The Viterbi algorithm for HMMs <REF>Viterbi 1967</REF> finds the globally most probable state sequence	0	When applied to a discourse model with locally decomposable likelihoods and Markovian discourse grammar, it will therefore find precisely the DA 348 Stolcke et al Dialogue Act Modeling sequence with the highest posterior probability: U  argmaxPUIE  4 u The combination of likelihood and prior modeling, HMMs, and Viterbi decoding is fundamentally the same as the standard probabilistic approaches to speech recognition <REF>Bahl, Jelinek, and Mercer 1983</REF> and tagging <TREF>Church 1988</TREF>	1	It maximizes the probability of getting the entire DA sequence correct, but it does not necessarily find the DA sequence that has the most DA labels correct <REF>Dermatas and Kokkinakis 1995</REF>	0	To minimize the total number of utterance labeling errors, we need to maximize the probability of getting each DA label correct individually, ie, we need to maximize PUilE for each i  1  n We can compute the per-utterance posterior DA probabilities by summing: PuE  E PUIE 5 U: Uiu where the summation is over all sequences U whose ith element matches the label in question	0	6	1
J98-1003	A88-1019	1998	Various methods for POS tagging have been proposed in recent years	0	For simplicity, we adopted the method proposed by <TREF>Church 1988</TREF> to tag definition sentences	1	Experiments indicated an average error rate for tagging of less than 10	0	Tagging errors have limited negative impact, because words in the LLOCE are organized primarily according to topic, not part of speech	0	3	1
P94-1041	A88-1019	1994	I think we I need l to uh I I I need l r I m I et I r m I Algorithm Our algorithm for labeling potential repair patterns encodes the assumption that speech repairs can be processed one at a time	0	The algorithm runs in lockstep with a part-of-speech tagger <TREF>Church, 1988</TREF>, which is used for deciding possible word replacements	1	Words are fed in one at a time	0	The detection clues are checked first	0	3	1
P94-1041	A88-1019	1994	7About half of the difference between the detection recall rate and the correction recall rate is due to abridged repairs being misclassified as modification repairs	0	299 Part-of-speech tagging is the process of assigning to a word the category that is most probable given the sentential context <TREF>Church, 1988</TREF>	1	The sentential context is typically approximated by only a set number of previous categories, usually one or two	0	Good part-of-speech results can be obtained using only the preceding category <REF>Weischedel et al , 1993</REF>, which is what we will be using	0	6	1
A92-1020	A88-1019	1992	Recent research advances may lead to the development of viable book indexing methods for Chinese books	0	These include the availability of efficient and high precision word segmentation methods for Chinese text <REF>Chang et al , 1991</REF>; <REF>Sproat and Shih, 1990</REF>; <REF>Wang et al , 1990</REF>, the availability of statistical analysis of a Chinese corpus <REF>Liu et al , 1975</REF> and large-scale electronic Chinese dictionaries with partof-speech information <REF>Chang et al , 1988</REF>; BDC, 1992, the corpus-based statistical part-of-speech tagger <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF>; <REF>Beale, 1988</REF>, as well as phrasal and clausal analyzers <TREF>Church 1988</TREF>; <REF>Ejerhed 1990</REF> 2	1	Problem description As being pointed out in <REF>Salton, 1988</REF>, back-of-book indexes may consist of more than one word that are derived from a noun phrase	0	Given the text of a book, an indexing system, must perform some kind of phrasal and statistical analysis in order to produce a list of candidate indexes and their occurrence statistics in order to generate indexes as shown in Figure 1 which is an excerpt from the reconstruction of indexes of a book on transformational grammar for Mandarin Chinese <REF>Tang, 1977</REF>	0	1	2
W95-0107	A88-1019	1995	NPtool parse Apparent correct parse less time less time the other hand the other hand many advantages many advantages bnary addressing binary addressing and and instruction formats instruction formats a purely binary computer a purely binary computer Table 1: Apparent errors made by Voutilainens N<REF>Ptool Kupiec 1993</REF> also briefly mentions the use of finite state NP recognizers for both English and French to prepare the input for a program that identified the correspondences between NPs in bilingual corpora, but he does not directly discuss their performance	0	Using statistical methods, Churchs Parts program 1988, in addition to identifying parts of speech, also inserted brackets identifying core NPs	1	These brackets were placed using a statistical model trained on Brown corpus material in which NP brackets had been inserted semi-automatically	0	In the small test sample shown, this system achieved 98 recall for correct brackets	0	3	1
W95-0107	A88-1019	1995	In the small test sample shown, this system achieved 98 recall for correct brackets	0	At about the same time, <REF>Ejerhed 1988</REF>, working with Church, performed comparisons between finite state methods and Churchs stochastic models for identifying both non-recursive clauses and non-recursive NPs in English text	1	In those comparisons, the stochastic methods outperformed the hand built finite-state models, with claimed accuracies of 935 clauses and 986 NPs for the statistical models compared to to 87 clauses and 978 NPs for the finite-state methods	0	Running Churchs program on test material, however, reveals that the definition of NP embodied in Churchs program is quite simplified in that it does not include, for example, structures or words conjoined within NP by either explicit conjunctions like and and or, or implicitly by commas	0	6	1
J94-1002	A88-1019	1994	They consider a range of input variables, including textderived information such as detailed POS labels and syntactic constituent structure, and in some experiments, acoustic information	0	POS labels were given by Churchs tagger <TREF>Church 1988</TREF> and syntactic constituents by Hindles parser <REF>Hindle 1987</REF>	1	The acoustic information previous boundary location, pitch accent location, and phrase duration, which was based on hand-labeled prosodic markers, did not improve performance but resulted in a much smaller tree for prediction	0	All of these approaches have influenced the model proposed here	0	3	1
J96-1001	A88-1019	1996	These tools can then be used by other systems to address more complex tasks	0	For example, previous work has addressed low-level tasks such as tagging a free-style corpus with part-of-speech information <TREF>Church 1988</TREF>, aligning a bilingual corpus <REF>Gale and Church 1991b</REF>; <REF>Brown, Lai, and Mercer 1991</REF>, and producing a list of collocations <REF>Smadja 1993</REF>	1	While each of these tools is based on simple statistics and tackles elementary tasks, we have demonstrated with our work on Champollion that by combining them, one can reach new levels of complexity in the automatic treatment of natural languages	0	Acknowledgments This work was supported jointly by the Advanced Research Projects Agency and the Office of Naval Research under grant N00014-89-J-1782, by the Office of Naval Research under grant N00014-95-1-0745, by the National Science Foundation under grant GER-90-24069, and by the New York State Science and Technology Foundation under grants NYSSTF-CAT91-053 and NYSSTF-CAT94-013	0	6	1
W94-0107	A88-1019	1994	The parser will eventually disambiguate all the descriptions and pick one per object, for a given reading of the sentence	0	This is what the parser is expected to do for disambiguating the standard POS, unless a separate POS disambiguation module is used <TREF>Church, 1988</TREF>	1	Many parsers, including XTAG, use such a module alhd a POS tagger	0	LTAGs present a novel opportunity to reduce the amount of disambiguation done by the parser	0	6	1
W97-0201	A88-1019	1997	Much recent research in the field of natural language processing NLP has focused on an empirical, corpus-based approach <REF>Church and Mercer, 1993</REF>	0	The high accuracy achieved by a corpus-based approach to part-of-speech tagging and noun phrase parsing, as demonstrated by <TREF>Church, 1988</TREF>, has inspired similar approaches to other problems in natural language processing, including syntactic parsing and word sense disambiguation WSD	1	The availability of large quantities of part-ofspeech tagged and syntactically parsed sentences like the Penn Treebank corpus <REF>Marcus, Santorini, and Marcinkiewicz, 1993</REF> has contributed greatly to the development of robust, broad coverage partof-speech taggers and syntactic parsers	0	The Penn Treebank corpus contains a sufficient number of partof-speech tagged and syntactically parsed sentences to serve as adequate training material for building broad coverage part-of-speech taggers and parsers	0	1	2
H90-1069	A88-1019	1990	One method of handling large vocabularies is simply increasing the size of the lexicon	0	Research efforts at IBM Chodorow, et al 1988; Neff, et al 1989, Bell Labs Church, et al 1989, New Mexico State University <REF>Wilks 1987</REF>, and elsewhere have used mechanical processing of on-line dictionaries to infer at least minimal syntactic and semantic information from dictionary definitions	0	However, even assuming a very large lexicon already exists, it can never be complete	1	Systems aiming for coverage of unrestricted language in broad domains must continually deal with new words and novel word senses	0	1	3
J96-2003	A88-1019	1996	In order to make these improvements, we need access to word-class information Pos information <REF>Johansson et al 1986</REF>; <REF>Black, Garside, and Leech 1993</REF> or semantic information <REF>Beckwith et al 1991</REF>, which is usually obtained in three main ways: Firstly, we can use corpora that have been manually tagged by linguistically informed experts <REF>Derouault and Merialdo 1986</REF>	0	Secondly, we can construct automatic part-ofspeech taggers and process untagged corpora <REF>Kupiec 1992</REF>; <REF>Black, Garside, and Leech 1993</REF>; this method boasts a high degree of accuracy, although often the construction of the automatic tagger involves a bootstrapping process based on a core corpus which has been manually tagged <TREF>Church 1988</TREF>	1	The third option is to derive a fully automatic word-classification system from untagged corpora	0	Some advantages of this last approach include its applicability to any natural language for which some corpus exists, independent of the degree of development of its grammar, and its parsimonious commitment to the machinery of modern linguistics	0	1	3
W06-1701	A88-1019	2006	If an external resource is used in the form of a morphological analyzer MA, this will almost always overgenerate, yielding false ambiguity	0	But even if the MA is tight, a considerable proportion of ambiguous tokens will come from legitimate but rare analyses of frequent types <TREF>Church, 1988</TREF>	1	For example the word nem, can mean both not and gender, so both ADV and NOUN are valid analyses, but the adverbial reading is about five orders of magnitude more frequent than the noun reading, 12596 vs 4 tokens in the 1 m word manually annotated Szeged Korpusz <REF>Csendes et al , 2004</REF>	0	Thus the difficulty of the task is better measured by the average information required for disambiguating a token	0	6	3
N03-1033	A88-1019	2003	Almost all approaches to sequence problems such as partof-speech tagging take a unidirectional approach to conditioning inference along the sequence	0	Regardless of whether one is using HMMs, maximum entropy conditional sequence models, or other techniques like decision trees, most systems work in one direction through the sequence normally left to right, but occasionally right to left, eg, <TREF>Church 1988</TREF>	1	There are a few exceptions, such as Brills transformation-based learning <REF>Brill, 1995</REF>, but most of the best known and most successful approaches of recent years have been unidirectional	0	Most sequence models can be seen as chaining together the scores or decisions from successive local models to form a global model for an entire sequence	0	6	1
E95-1003	A88-1019	1995	Part-of-speech tagging is required to detect new terms formed through conversion	0	This is quite feasible using statistical taggers like those of <REF>Garside 1987</REF>, <TREF>Church 1988</TREF> or <REF>Foster 1991</REF> which achieve performance upwards of 97 on unrestricted text	1	Terms formed through semantic drift are the wolves in sheeps clothing stealing through terminological pastures	0	They are well enough conceMcd to allude at times even the human reader and no automatic term-recognition system has attempted to distinguish such terms, despite the prevalence ofpolysemy in such fields as the social sciences Riggs, 1993 and the importance for purposes of terminological standardization that deviant usage be tracked	0	1	2
H94-1034	A88-1019	1994	4	0	Partof-Speech Tagging Part-of-speech tagging is the process of assigning to a word the category that is most probable given the sentential context <TREF>Church, 1988</TREF>	1	The sentential context is typically approximated by only a set number of previous categories, usually one or two	0	Since the context is limited, we are making the Markov assumption, that the next transition depends only on the input, which is the word that we the following changes: 1 we -parated Weposifiom from subordinating conjunctions; 2 we separated uses of to as a preposition from in me as part of a to-infinilive; 3 rather than classify verbs by tense, we classified them into four groups, conjugations of be, conjugations of have, verbs that are followed by a to-infinitive, and verbs that are followed immediately by another verb	0	6	1
W00-1201	A88-1019	2000	On sentences with <40 words, the former model performs at 69 precision, 75 recall, and the latter at 77 precision and 78 recall	0	Ever since the success of HMMs application to part-of-speech tagging in <TREF>Church, 1988</TREF>, machine learning approaches to natural language processing have steadily become more widespread	1	This increase has of course been due to their proven efficacy in many tasks, but also to their engineering effiCacy	0	Many machine learning approaches let the data speak for itself data ipsa loquuntur, as it were, allowing the modeler to focus on what features of the data are important, rather than on the complicated interaction of such features, as had often been the case with hand-crafted NLP systems	0	1	2
A00-2013	A88-1019	2000	In conclusion, we argue strongly that the use of an independent morphological dictionary is the preferred choice to more annotated data under such circumstances	0	1 Full Morphological Tagging English Part of Speech POS tagging has been widely described in the recent past, starting with the <TREF>Church, 1988</TREF> paper, followed by numerous others using various methods: neural networks <REF>Julian Benello and Anderson, 1989</REF>, HMM tagging <REF>Merialdo, 1992</REF>, decision trees <REF>Schmid, 1994</REF>, transformation-based error-driven learning <REF>Brill, 1995</REF>, and maximum entropy <REF>Ratnaparkhi, 1996</REF>, to select just a few	1	However different the methods were, English dominated in these tests	0	Unfortunately, English is a morphologically impoverished language: there are no complicated agreement relations, word order variation is minireal, and the morphological categories are either extremely simple -s for plural of nouns, for example, or almost nonexistent cases expressed by inflection, for example with not too many exceptions and irregularities	0	6	1
H90-1052	A88-1019	1990	The suggestion which we want to explore is that the association revealed by textual distribution whether its source is a complementation relation, a modification relation, or something else gives us information needed to resolve the prepositional attachment	0	Discovering Lexical Association in Text A 13 million word sample of Associated Press new stories from 1989 were automatically parsed by the Fidditch parser <REF>Hindle 1983</REF>, using Churchs part of speech analyzer as a preprocessor <TREF>Church 1988</TREF>	1	From the syntactic analysis provided by the parser for each sentence, we extracted a table containiffg all the heads of all noun phrases	0	For each noun phrase head, we recorded the following preposition if any occurred ignoring whether or not the parser attached the preposition to the noun phrase, and the preceding verb if the noun phrase was the object of that verb	0	3	1
P97-1059	A88-1019	1997	460 of this data has an impact on the tagging accuracy of both the HMM itself and the derived transducer	0	The training of the HMM can be done on either a tagged or untagged corpus, and is not a topic of this paper since it is exhaustively described in the literature <REF>Bahl and Mercer, 1976</REF>; <TREF>Church, 1988</TREF>	1	An HMM can be identically represented by a weighted FST in a straightforward way	0	We are, however, interested in non-weighted transducers	0	6	1
W00-0726	A88-1019	2000	In the early nineties, <REF>Abney 1991</REF> proposed to approach parsing by starting with finding related chunks of words	0	By then, <TREF>Church 1988</TREF> had already reported on recognition of base noun phrases with statistical methods	1	<REF>Ramshaw and Marcus 1995</REF> approached chunking by using a machine learning method	0	Their work has inspired many others to study the application of learning methods to noun phrase chunking 5	0	6	1
C00-2141	A88-1019	2000	Realizing the difficulties o1 complete parsing, many researches turned to explore the partial parsing techniques	0	<TREF>Church1988</TREF> proposed a silnple stochastic technique for lecognizing the non-recursive base noun phrases in English	1	;outilaimen1993 designed an English noun phrase recognition tool -- NPTbol	0	<REF>Abney1997</REF> applied both rule-based and statistics-based approaches for parsing chunks in English	0	6	1
W96-0102	A88-1019	1996	Several approaches have been proposed to construct automatic taggers	0	Most work on statistical methods has used n-gram models or Hidden Markov Model-based taggers eg <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF>; <REF>Cutting et al 1992</REF>; <REF>Merialdo, 1994</REF>, etc	1	In 14 these approaches, a tag sequence is chosen for a sentence that maximizes the product of lexical and contextual probabilities as estimated from a tagged corpus	0	In rule-based approaches, words are assigned a tag based on a set of rules and a lexicon	0	6	1
H91-1077	A88-1019	1991	Categorical ambiguity, however, is of a different kind and is resolved in a different way	0	For the purposes of the present paper, it will be assumed that only content words are at issue, and that the syntactic category of all content words in the text that is under study can be determined automatically <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF>	1	The problem is simply to decide which sense of a content word--noun, verb, adjective, or adverb---is appropriate in a given linguistic context	0	It will also be assumed that sense resolution for individual words can be accomplished on the basis of information about the irnrnediate linguistic context	0	6	1
W98-1117	A88-1019	1998	The program can be trained even with a relatively small amount of treebank data; then it can be J used for parsing unrestricted pre-tagged text	0	As far as coverage is concerned, our parser can handle recursive structures, which is an advantage compared to simpler techniques such as that described by <TREF>Church 1988</TREF>	1	On the other hand, the Markov assumption underlying our approach means that only strictly local dependencies are recognised	0	For full parsing, one would probably need non-local contextual information, such as the long-range trigrams in Link Grammar Della <REF>Pietra et al , 1994</REF>	0	1	3
W98-1117	A88-1019	1998	Regardless of whether or not abstractions such as phrases occur in the model, most of the relevant information is contained directly in the sequence of words and part-of-speech tags to be processed	0	An archetypal representative of this approach is the method described by <TREF>Church 1988</TREF>, who used corpus frequencies to determine the boundaries of simple non, recursive NPs	1	For each pair of part-of-speech tags ti, tj, the probability of an NP boundary   or  occurring between ti and tj is computed	0	On the basis of these context probabilities, the program inserts the symbols  and  into sequences of part-of-speech tags	0	6	1
J93-2006	A88-1019	1993	However, it does undeniably reduce confusion with respect to the proper noun category	0	Some well-known previous efforts <TREF>Church 1988</TREF>; de <REF>Marcken 1990</REF> have dealt with unknown words using various heuristics	1	For instance, Churchs program PARTS has a prepass prior to applying the tri-tag probability model that predicts proper nouns based on capitalization	0	The new aspects of our work are 1 incorporating the treatment of unknown words uniformly within the probability model, 2 approximating the component probabilities for unknowns directly from the training data, and 3 measuring the contribution of the tri-tag model, of the ending, and of capitalization	0	6	1
J93-2006	A88-1019	1993	Purely rule-based techniques seemed too brittle for dealing with the variety of constructions, the long sentences averaging 29 words per sentence, and the degree of unexpected input	0	Statistical models based on local information eg , <REF>DeRose 1988</REF>; <TREF>Church 1988</TREF> might operate effectively in spite of sentence length and unexpected input	1	To see whether our four hypotheses in italics above effectively addressed the four concerns above, we chose to test the hypotheses on two well-known problems: ambiguity both at the structural level and at the part-of-speech level and inferring syntactic and semantic information about unknown words	0	Guided by the past success of probabilistic models in speech processing, we have integrated probabilistic models into our language processing systems	0	1	2
J93-2006	A88-1019	1993	We report in Section 2 on our experiments on the assignment of part of speech to words in text	0	The effectiveness of such models is well known <REF>DeRose 1988</REF>; <TREF>Church 1988</TREF>; <REF>Kupiec 1989</REF>; <REF>Jelinek 1985</REF>, and they are currently in use in parsers eg de <REF>Marcken 1990</REF>	1	Our work is an incremental improvement on these models in three ways: 1 Much less training data than theoretically required proved adequate; 2 we integrated a probabilistic model of word features to handle unknown words uniformly within the probabilistic model and measured its contribution; and 3 we have applied the forward-backward algorithm to accurately compute the most likely tag set	0	In Section 3, we demonstrate that probability models can improve the performance of knowledge-based syntactic and semantic processing in dealing with structural ambiguity and with unknown words	0	1	2
P98-1080	A88-1019	1998	1 is a typical example of the ambiguities encountered in a running text: little POS ambiguity, but a lot of gender, number and case ambiguity columns 3 to 5	0	485 3 The Model Instead of employing the source-channel paradigm for tagging more or less explicitly present eg in <REF>Merialdo, 1992</REF>, <TREF>Church, 1988</TREF>, Hajji, Hladk, 1997 used in the past notwithstanding some exceptions, such as Maximum Entropy and rule-based taggers, we are using here a direct approach to modeling, for which we have chosen an exponential probabilistic model	1	Such model when predicting an event 5 y E Y in a context x has the general form PAC,e YIX  exp-in----1 Aifi y, x Zx 3 where fi Y, x is the set of size n of binary-valued yes/no features of the event value being predicted and its context, hi is a weigth in the exponential sense of the feature fi, and the normalization factor Zx is defined naturally as zx  exp z x 4 yEY i----1 ,Ve use a separate model for each ambiguity class AC which actually appeared in the training data of each of the 13 morphological categories 6	0	The final PAC Yix distribution is further smoothed using unigram distributions on subtags again, separately for each category	0	2	1
P94-1013	A88-1019	1994	This was expanded upon by <REF>Gale et al , 1992</REF>, and in a class-based variant by <REF>Yarowsky, 1992</REF>	0	Decision trees <REF>Brown, 1991</REF> have been usefully applied to word-sense ambiguities, and HMM part-of-speech taggers <REF>Jelinek 1985</REF>, <TREF>Church 1988</TREF>, <REF>Merialdo 1990</REF> have addressed the syntactic ambiguities presented here	1	<REF>Hearst 1991</REF> presented an effective approach to modeling local contextual evidence, while <REF>Resnik 1993</REF> gave a classic treatment of the use of word classes in selectional constraints	0	An algorithm for combining syntactic and semantic evidence in lexical ambiguity resolution has been realized in <REF>Chang et al , 1992</REF>	0	1	2
H89-2012	A88-1019	1989	Preprocessing the Corpus with a Part of Speech Tagger Phrasal verbs involving the preposition to raise an interesting problem because of the possible confusion with the infinitive marker to	0	We have found that if we first tag every word in the corpus with a part of speech using a method such as <TREF>Church 1988</TREF> or <REF>DeRose 1988</REF>, and then measure associations between tagged words, we can identify interesting contrasts between verbs associated with a following preposition toin and verbs associated with a following infinitive marker toto	1	Part of speech notation is borrowed from <REF>Francis and Kucera 1982</REF>; m  preposition; to  infinitive marker; vb  bare verb; vbg  verb  ing; vbd  verb  ed; vbz  verb  s; vbn  verb  en	0	The score identifies quite a number of verbs associated in an interesting way with to; restricting our attention to pairs with a score of 30 or more, there are 768 verbs associated with the preposition toin and 551 verbs with the infinitive marker toto	0	3	2
P99-1021	A88-1019	1999	In the partof-speech tagging field, the disambiguation of capitalized words is treated similarly to the disambiguation of common words	0	However, as <TREF>Church 1988</TREF> rightly pointed out Proper nouns and capitalized words are particularly problematic: some capitalized words are proper nouns and some are not	1	Estimates from the Brown Corpus can be misleading	0	For example, the capitalized word Acts is found twice in Brown Corpus, both times as a proper noun in a title	0	1	2
P97-1029	A88-1019	1997	Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora	0	There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, eg, <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1992</REF>; <REF>DeRose, 1988</REF>, constraint-based techniques <REF>Karlsson et al , 1995</REF>; <REF>Voutilainen, 1995b</REF>; Voutilainen, Heikkil/i, and <REF>Anttila, 1992</REF>; <REF>Voutilainen and Tapanainen, 1993</REF>; <REF>Oflazer and KuruSz, 1994</REF>; <REF>Oflazer and Till 1996</REF> and transformation-based techniques <REF>Brilt, 1992</REF>; <REF>Brill, 1994</REF>; <REF>Brill, 1995</REF>	1	This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements	0	The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item	0	6	1
C98-2203	A88-1019	1998	Given that each token has on the average more than 2 possible tags, the procedural description above is very inefficient for M1 but very short sentences	0	However, the observation that our constraints are localized to a window of a small number of tokens say at most 5 tokens in a sequence, suggests a more efficient scheme originally used by <TREF>Church 1988</TREF>	1	Assume our constraint windows are allowed to look at a window of at most size k sequential parses	0	Let us take the first k tokens of a sentence and generate all possible paths of k arcs spanning k  1 nodes, and apply all constraints to these short paths	0	1	2
C98-2203	A88-1019	1998	Part-of-speech tagging is one of the preliminary steps in many natural language processing systems in which the proper part-of-speech tag of the tokens comprising the sentences are disambiguated using either statistical or symbolic local contextual information	0	Tagging systems have used either a statistical approach where a large corpora is employed to train a probabilistic model which then is used to tag unseen text, eg, <TREF>Church 1988</TREF>, Cutting et al	1	1992, DeR,ose 1988, or a constraint-based approach which employs a large number of hand-crafted linguistic constraints that are used to eliminate impossible sequences or morphological parses for a given word in a given context, recently most prominently exemplified by the Constraint Grammar work <REF>Karlsson et al, 1995</REF>; <REF>Voutilainen, 1995b</REF>; <REF>Voutilainen et al, 1992</REF>; <REF>Voutilainen and Tapanainen, 1993</REF>	0	Brill 1992; 1994; 1995 has presented a transformationbased learning approach	0	6	1
H93-1046	A88-1019	1993	Models G and C For model G, I induced a simple grammar from the training corpus	0	I used Ken Churchs tagger <TREF>Church 1988</TREF> to 234 assign part-of-speech probabilities to words	1	The grammar contains a rule x ---> T for every Treebank chunk x t in the training corpus	0	x is the syntactic category of the chunk, and y is the part-of-speech sequence assigned to the words of the chunk	0	3	1
P93-1024	A88-1019	1993	The corpus used in our first experiment was derived from newswire text automatically parsed by 183 Hindles parser Fidditch <REF>Hindle, 1993</REF>	0	More recently, we have constructed similar tables with the help of a statistical part-of-speech tagger <TREF>Church, 1988</TREF> and of tools for regular expression pattern matching on tagged corpora <REF>Yarowsky, 1992</REF>	1	We have not yet compared the accuracy and coverage of the two methods, or what systematic biases they might introduce, although we took care to filter out certain systematic errors, for instance the misparsing of the subject of a complement clause as the direct object of a main verb for report verbs like say	0	We will consider here only the problem of classifying nouns according to their distribution as direct objects of verbs; the converse problem is formally similar	0	3	1
W94-0111	A88-1019	1994	1; they closely replicate Brills results 1993b, page 96, allowing for the fact that his tests used more templates, including templates like if one of the three previous tags is A	0	Brills results demonstrate that this approach can outperform the Hidden Markov Model approaches that are frequently used for part-of-speech tagging <REF>Jelinek, 1985</REF>; <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF>; <REF>Cutting et al , 1992</REF>; <REF>Weischedel et al , 1993</REF>, as well as showing promise for other applications	1	The resulting model, encoded as a list of rules, is also typically more compact and for some purposes more easily interpretable than a table of HMM probabilities	0	An Incremental Algorithm It is worthwhile noting first that it is possible in some circumstances to significantly speed up the straightforward algorithm described above	0	1	3
A94-1013	A88-1019	1994	We show the method to be efficient and easily adaptable to different text genres, including single-case texts	0	Labeling of sentence boundaries is a necessary prerequisite for many natural language processing NLP tasks, including part-of-speech tagging <TREF>Church, 1988</TREF>, <REF>Cutting et al , 1991</REF>, and sentence alignment <REF>Gale and Church, 1993</REF>, Kay and R<REF>Sscheisen, 1993</REF>	1	End-of-sentence punctuation marks are ambiguous; for example, a period can denote an abbreviation, the end of a sentence, or both, as shown in the examples below: 1 The group included Dr JM Freeman and T Boone Pickens Jr	0	2 This issue crosses party lines and crosses philosophical lines	0	6	1
A94-1013	A88-1019	1994	21 Assignment of Descriptors The first stage of the process is lexical analysis, which breaks the input text a stream of characters into tokens	0	Our implementation uses a slightlymodified version of the tokenizer from the PARTS part-of-speech tagger <TREF>Church, 1988</TREF> for this task	1	A token can be a sequence of alphabetic characters, a sequence of digits numbers containing periods acting as decimal points are considered a single token, or a single non-alphanumeric character	0	A lookup module then uses a lexicon with part-of-speech tags for each token	0	3	1
A94-1006	A88-1019	1994	The list of candidate terms contains both multi-word noun phrases and single words	0	The multi-word terms match a small set of syntactic patterns defined by regular expressions and are found by searching a version of the document tagged with parts of speech <TREF>Church, 1988</TREF>	1	The set of syntactic patterns is considered as a parameter and can be adopted to a specific domain by the user	0	Currently our patterns match only sequences of nouns, which seem to yield the best hit rate in our environment	0	3	1
A94-1006	A88-1019	1994	This current practice is very laborious and runs the risk of missing many important terms	0	Termight uses a part of speech tagger <TREF>Church, 1988</TREF> to identify a list of candidate terms which is then filtered by a manual pass	1	We have found, however, that the manual pass dominates the cost of the monolingual task, and consequently, we have tried to design an interactive user interface see Figure 1 that minimizes the burden on the expert terminologist	0	The terminologist is presented with a list of candidate terms, and corrects the list with a minimum number of key strokes	0	6	1
J99-4003	A88-1019	1999	We rewrite this term as follows: PrW1,ND1,N N  I-IPrWiDilWl,ilDl,il i1 N  l-I PrWilWl,i-lDl,i PrDilWl,i-lDl,i-1 i1 7 Equation 7 involves two probability distributions that need to be estimated	0	These are the same distributions that are needed by previous POS-based language models Equation 5 and POS taggers <TREF>Church 1988</TREF>; <REF>Charniak et al 1993</REF>	0	However, these approaches simplify the context so that the lexical probability is just conditioned on the POS category of the word, and the POS probability is conditioned on just the preceding POS tags, which leads to the following two approximations	0	PrWiIWl,ilDl,i  PrWilDi 8 PrDiIWulDl,il  PrDiIDul 9 However, to successfully incorporate POS information, we need to account for the full richness of the probability distributions, as will be demonstrated in Section 344	1	1	3
P98-1034	A88-1019	1998	Figure 1: Base NP Examples base noun phrases with initial determiners and modifiers removed: <REF>Justeson  Katz 1995</REF> look for repeated phrases; <REF>Bourigault 1992</REF> uses a handcrafted noun phrase grammar in conjunction with heuristics for finding maximal length noun phrases; Voutilainens NP<REF>Tool 1993</REF> uses a handcrafted lexicon and constraint grammar to find terminological noun phrases that include phrase-final prepositional phrases	0	Churchs PARTS program 1988, on the other hand, uses a probabilistic model automatically trained on the Brown corpus to locate core noun phrases as well as to assign parts of speech	1	More recently, Ramshaw  Marcus In press apply transformation-based learning <REF>Brill, 1995</REF> to the problem	0	Unfortunately, it is difficult to directly compare approaches	0	6	1
C94-1025	A88-1019	1994	The recursive expansion of the tree stops if either the information gained by consulting further fv-pairs or the frequencies upon which the calculus is based are smaller than defined thresholds	0	4 TAGGING ALGORITHM Starting point for the implementation of a feature structure tagger was a second-0rdcr-IIMM tagger trigrams based on a modified version of the Viterbi algorithm <REF>Viterbi, 1967</REF>; <TREF>Church, 1988</TREF> which we had earlier implemented in C Kempe,1994	1	There we replaced the function which estimated the contextual probability of a tag state transition probability hy dividing a trigram frequency by a bigram frequency eq	0	3 with a flmction which accomplished this calculus either using PF1Ls in the above-described way eqs 6, 7 or by consulting a decision tree fig	0	5	1
C94-1027	A88-1019	1994	1992 circumvent this problem by training their taggers on untagged data using tile Itaum-Welch algorithm also know as the forward-backward algorithm	0	They report rates of correctly tagged words which are comparable to that presented by <TREF>Church 1988</TREF> and <REF>Kempe 1993</REF>	1	A third and rather new approach is tagging with artificial neural networks	0	In the area of speech recognition neural networks have been used for a decade r, ow	0	4	2
P97-1008	A88-1019	1997	For example, if we choose to create a pseudo-word out of the words make and take, we would change the test data like this: make plans  make, take plans take action  make, take action The method being tested must choose between the two words that make up the pseudo-word	0	32 Data We used a statistical part-of-speech tagger <TREF>Church, 1988</TREF> and pattern matching and concordancing tools due to David Yarowsky to identify transitive main verbs and head nouns of the corresponding direct objects in 44 million words of 1988 Associated Press newswire	1	We selected the noun-verb pairs for the 1000 most frequent nouns in the corpus	0	These pairs are undoubtedly somewhat noisy given the errors inherent in the part-of-speech tagging and pattern matching	0	3	1
J93-1007	A88-1019	1993	151 Computational Linguistics Volume 19, Number 1 <REF>Garside and Leech 1987</REF> have been shown to reach 95-99 performance on free-style text	0	We preprocessed the corpus with a stochastic part-of-speech tagger developed at Bell Laboratories by Ken Church <TREF>Church 1988</TREF>	1	9 In the rest of this section, we describe the algorithm used for the first stage of Xtract in some detail	0	We assume that the corpus is preprocessed by a part of speech tagger and we note wi a collocate of w if the two words appear in a common sentence within a distance of 5 words	0	3	1
J93-1007	A88-1019	1993	Such techniques have various applications	0	Speech recognition <REF>Bahl, Jelinek, and Mercer 1983</REF> and text compression eg , <REF>Bell, Witten, and Cleary 1989</REF>; <REF>Guazzo 1980</REF> have been of long-standing interest, and some new applications are currently being investigated, such as machine translation <REF>Brown et al 1988</REF>, spelling correction <REF>Mays, Damerau, and Mercer 1990</REF>; <REF>Church and Gale 1990</REF>, parsing <REF>Debili 1982</REF>; <REF>Hindle and Rooth 1990</REF>	1	As pointed out by <REF>Bell, Witten, and Cleary 1989</REF>, these applications fall under two research paradigms: statistical approaches and lexical approaches	0	In the statistical approach, language is modeled as a stochastic process and the corpus is used to estimate probabilities	0	6	1
E99-1018	A88-1019	1999	On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms usually with the aid of corpora <REF>Green and Rubin, 1971</REF>; <REF>Voutilainen 1995</REF>	0	On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1992</REF>, rules <REF>Hindle, 1989</REF>; <REF>Brill, 1995</REF>, decision trees <REF>Cardie, 1994</REF>; <REF>Daelemans et al , 1996</REF> or neural networks <REF>Schmid, 1994</REF>	1	In order to increase their robusmess, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon	0	As a common strategy, POS guessers examine the endings of unknown words <REF>Cutting et al 1992</REF> along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech Weischedel et aL, 1993	0	6	1
C98-2118	A88-1019	1998	In practice, computational limitations do not allow the enumeration of all possible assignments for long sentences, and smoothing is required for infrequent events	1	This is described in more detail in the original publication <TREF>Church, 1988</TREF>	0	Although more sophisticated algorithms for unsupervised learning which can be trained on plain text instead on manually tagged corpora are well established see eg <REF>Merialdo, 1994</REF>, we decided not to use them	0	The main reason is that with large tag sets, the sparse-data-problem can become so severe that unsupervised training easily ends up in local minima, which call lead to poor results without any indication to the user	0	1	3
C98-2118	A88-1019	1998	<REF>Lezius, Rapp  Wettler 1996</REF> give an overview on some German tagging projects	0	Although we considered a number of algorithms, we decided to use the trigram algorithm described by <TREF>Church 1988</TREF> for tagging	1	It is simple, fast, robust, and among the statistical taggers still more or less unsurpassed in terms of accuracy	0	Conceptually, the Church-algorithm works as follows: For each sentence of a text, it generates all possible assignments of part-of-speech tags to words	0	3	1
J99-4005	A88-1019	1999	2	0	Part-of-Speech Tagging The prototype source-channel application in natural language is part-of-speech tagging <TREF>Church 1988</TREF>	1	We review it here for purposes of comparison with machine translation	0	Source strings comprise sequences of part-of-speech tags like noun, verb, etc A simple source model assigns a probability to a tag sequence tl tm based on the probabilities of the tag pairs inside it	0	6	1
P89-1015	A88-1019	1989	Indeed, recent increased interest in the problem of disambiguating lexical category in English has led to significant progress in developing effective programs for assigning lexical category in unrestricted text	0	The most successful and comprehensive of these are based on probabilistic modeling of category sequence and word category <REF>Church 1987</REF>; <REF>Garside, Leech and Sampson 1987</REF>; <REF>DeRose 1988</REF>	1	These stochastic methods show impressive performance: Church reports a success rate of 95 to 99, and shows a sample text with an error rate of less than one percent	0	What may seem particularly surprising is that these methods succeed essentially without reference to syntactic structure; purely surface lexical patterns are involved	0	1	2
J93-1001	A88-1019	1993	Part-of-Speech Tagging Many of the very same methods are being applied to problems in natural language processing by many of the very same researchers	0	As a result, the empirical approach has been adopted by almost all contemporary part-of-speech programs: <REF>Bahl and Mercer 1976</REF>, <REF>Leech, Garside, and Atwell 1983</REF>, <REF>Jelinek 1985</REF>, <REF>Deroualt and Merialdo 1986</REF>, <REF>Garside, Leech, and Sampson 1987</REF>, <TREF>Church 1988</TREF>, <REF>DeRose 1988</REF>, <REF>Hindle 1989</REF>, Kupiec 1989, 1992, Ayuso et al	1	1990, de<REF>Marcken 1990</REF>, <REF>Karlsson 1990</REF>, <REF>Boggess, Agarwal, and Davis 1991</REF>, <REF>Merialdo 1991</REF>, and <REF>Voutilainen, Heikkila, and Anttila 1992</REF>	0	These programs input a sequence of words, eg, The chair will table the motion, and output a sequence of part-of-speech tags, eg, art noun modal verb art noun	0	6	1
P03-1065	A88-1019	2003	English parsing is divided into two tasks: shallow parsing and deep parsing	0	The shallow parser constructs Verb Groups VGs and basic Noun Phrases NPs, also called BaseNPs <TREF>Church 1988</TREF>	1	The deep parser utilizes syntactic subcategorization features and semantic features of a head eg , VG to decode both syntactic and logical dependency relationships such as Verb-Subject, Verb-Object, Head-Modifier, etc Part-of-Speech POS Tagging General Lexicon Lexical lookup Named Entity NE Taggig Shallow Parsing PV Identification Deep parsing General Lexicon PV Expert Lexicon Figure 1	0	System Architecture The general lexicon lookup component involves stemming that transforms regular or irregular inflected verbs into the base forms to facilitate the later phrasal verb matching	0	6	1
W96-0205	A88-1019	1996	We redistribute the probability mass of low count sequences to unseen sequences	0	Generalized Forward Backward Reestimation Generalization of the Forward and Viterbi Algorithm In English part of speech taggers, the maximization of Equation 1 to get the most likely tag sequence, is accomplished by the Viterbi algorithm <TREF>Church, 1988</TREF>, and the maximum likelihood estimates of the parameters of Equation 2 are obtained from untagged corpus by the ForwardBackward algorithm <REF>Cutting et al , 1992</REF>	0	However, it is impossible to apply the Viterbi algorithm and the Forward-Backward algorithm for word segmentation of those languages that have no delimiter between words, such as Japanese and Chinese, because word segmentation hypotheses overlap one another	1	Figure 3 shows an example of overlapping word hypotheses and possible word segmentations for the string Ntig-f all prefectures in the nation	0	1	3
W98-0702	A88-1019	1998	An event greater improvement over the baseline is illustrated by the increase in the number of event clauses correctly classified, ie event rrall	0	As shown in Table 7, an event recall of 677 was achieved by the classification rule, as compared to speech tagging <TREF>Church, 1988</TREF>; <REF>Alien, 1995</REF>	1	13 I I I I I I I I I I I I I I I I I I the 00 event recall achieved by the baseline, while suffering no loss in overall accuracy	0	This difference in recall is more dramatic than the accuracy improvement because of the dominance of stative clauses in the test set	0	2	1
W98-1207	A88-1019	1998	What can be done at the present stage is the recognition of relatively simple structures such as NPs and PPs	0	<TREF>Church, 1988</TREF> used a simple mechanism to mark the boundaries of NPs	1	He used part-of-speech tagging and added two flags to the part-of-speech tags to mark the beginning and the end of an NP	0	Our goal is more ambitious in that we mark not only the phrase boundaries of NPs but also the complete structure of a wider class of phrases, starting with APs, NPs and PPs	0	6	1
P91-1023	A88-1019	1991	For a larger dataset, such as the Canadian Hansards, it was not possible to check the results by hand	0	We used the same procedure which is used in <TREF>Church, 1988</TREF>	1	This procedure was developed by Kathryn Baker private communication	0	ratio	0	3	1
J95-2004	A88-1019	1995	In fact, whereas stochastic taggers have to store word-tag, bigram, and trigram probabilities, the rule-based tagger and therefore the finite-state one only have to encode a small number of rules between 200 and 300	0	We empirically compared our tagger with Eric Brills implementation of his tagger, and with our implementation of a trigram tagger adapted from the work of <TREF>Church 1988</TREF> that we previously implemented for another purpose	1	We ran the three programs on large files and piped their output into a file	0	In the times reported, we included the time spent reading the input and writing the output	0	3	1
J95-2004	A88-1019	1995	Although finite-state machines have been used for part-of-speech tagging <REF>Tapanainen and Voutilainen 1993</REF>; <REF>Silberztein 1993</REF>, none of these approaches has the same flexibility as stochastic techniques	0	Unlike stochastic approaches to part-of-speech tagging <TREF>Church 1988</TREF>; <REF>Kupiec 1992</REF>; <REF>Cutting et al 1992</REF>; <REF>Merialdo 1990</REF>; <REF>DeRose 1988</REF>; <REF>Weischedel et al 1993</REF>, up to now the knowledge found in finite-state taggers has been handcrafted and was not automatically acquired	1	<REF>Recently, Brill 1992</REF> described a rule-based tagger that performs as well as taggers based upon probabilistic models and overcomes the limitations common in rule-based approaches to language processing: it is robust and the rules are automatically ac Mitsubishi Electric Research Laboratories, 201 Broadway, Cambridge, MA 02139	0	E-mail: rocbe/schabesmerlcom	0	6	1
W96-0206	A88-1019	1996	A corpus is manually tagged with the categories and transition probabilities between two or three categories are estimated from their relative frequencies	0	This method is commonly used for part-of-speech tagging <TREF>Church, 1988</TREF>	1	The fourth method is a variation of the third method and is also used for part-of-speech tagging	0	This method does not need a pre-annotated corpus for parameter estimation	0	3	1
P94-1032	A88-1019	1994	2	0	Previous <REF>Works Church 1988</REF> proposes a part of speech tagger and a simple noun phrase extractor	1	His noun phrase extractor brackets the noun phrases of input tagged texts according to two probability matrices: one is starting noun phrase matrix; the other is ending noun phrase matrix	0	The methodology is a simple version of Garside and Leechs probabilistic parser 1985	0	6	1
P94-1032	A88-1019	1994	The testing scale is large enough about 150,000 words	0	In contrast, <TREF>Church 1988</TREF> tests a text and extracts the simple noun phrases only	1	Bourigaults work 1992 is evaluated manually, and dose not report the precision	0	Hence, the real performance is not known	0	6	1
W99-0608	A88-1019	1999	For more details, we refer the reader to <REF>Mgrquez and Rodrfguez, 1997</REF>	0	22 STT: A Statistical Tree-based Tagger The aim of statistical or probabilistic tagging <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1992</REF> is to assign the most likely sequence of tags given the observed sequence of words	1	For doing so, two kinds of information are used: the lexical probabilities, ie, the probability of a particular tag conditional on the particular word, and the contextual probabilities, which describe the probability of a particular tag conditional on the surrounding tags	0	Contextual or transition probabilities are usually reduced to the conditioning of the preceding tag bigrams, or pair of tags trigrams, however, the general formulation allows a broader definition of context	0	6	1
A94-1024	A88-1019	1994	based approach implemented with finite-state machines <REF>Koskenniemi et al , 1992</REF>; <REF>Voutilainen and Tapanainen, 1993</REF>	0	A completely different approach to tagging uses statistical methods, eg , <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1993</REF>	1	These systems essentially train a statistical model using a previously hand-tagged corpus and provide the capability of resolving ambiguity on the basis of most likely interpretation	0	The models that have been widely used assume that the part-ofspeech of a word depends on the categories of the two preceding words	0	6	1
J01-4004	A88-1019	2001	As far as coreference resolution is concerned, the goal of these NLP modules is to determine the boundary of the markables, and to provide the necessary information about each markable for subsequent generation of features in the training examples	0	Our part-of-speech tagger is a standard statistical tagger based on the Hidden Markov Model HMM <TREF>Church 1988</TREF>	1	Similarly, we built a statistical HMM-based noun phrase identification module that determines the noun phrase boundaries solely based on the part-of-speech tags assigned to the words in a sentence	0	We also implemented a module that recognizes MUC-style named entities, that is, organization, person, location, date, time, money, and percent	0	3	1
W95-0101	A88-1019	1995	There has recently been a great deal of work exploring methods for automatically training part of speech taggers, as an alternative to laboriously hand-crafting rules for tagging, as was done in the past <REF>Klein and Simmons, 1963</REF>; <REF>Harris, 1962</REF>	0	Almost all of the work in the area of automatically trained taggers has explored Markov-model based part of speech tagging <REF>Jelinek, 1985</REF>; <TREF>Church, 1988</TREF>; <REF>Derose, 1988</REF>; <REF>DeMarcken, 1990</REF>; <REF>Cutting et al , 1992</REF>; <REF>Kupiec, 1992</REF>; <REF>Charniak et al , 1993</REF>; <REF>Weischedel et al , 1993</REF>; <REF>Schutze and Singer, 1994</REF>; <REF>Lin et al , 1994</REF>; <REF>Elworthy, 1994</REF>; <REF>Merialdo, 1995</REF>	1	2 For a Markov-model based tagger, training consists of learning both lexical probabilities Pwordltag and contextual probabilities Ptagiltagil tagi-n	0	Once trained, a sentence can be tagged by searching for the tag sequence that maximizes the product of lexical and contextual probabilities	0	6	1
C92-1033	A88-1019	1992	In the examples ahove, tagging of presents as vbz in the first sentence cuts off a potentially long and cosily garden path with presents as a plural noun followed by a headless relative clause starting with that a proposal  In the second sentence, tagging resolves ambiguity of used vim vs vbd, and associates vbz vs nns	0	Perhaps more imlxmantly, elimination of word-level lexical ambiguity allows the parser to make projection about the input which is yet to be parsed, using a simple lookabead; in particular, phrase boundaries can be determined with a degree of confidence <TREF>Church, 1988</TREF>	1	This latter property is critical for implementing skip-and-fit recovery technique outlined in the previous section	0	Tagging of input also helps to reduce the number of parse structures that can be assigned to a sentence, decreases the demand for consulting of the dictionary, and simplifies dealing with unknown words	0	6	1
W00-1211	A88-1019	2000	The typical examples are the recognition of BaseNP in English and Chinese	0	In English BNP base noun phrase is defined as simple and non-nesting noun phrases, ie noun phrases that do not contain other noun phrase descendants <TREF>Church, 1988</TREF>	1	After that researches on BNP identification reports promising results for such task in English	0	Observing that the Chinese BNP is different form English, <REF>Zhao  Huang, 1999</REF> puts forward the definition of Chinese BNP in terms of combination of determinative modifier and head noun	0	6	1
A94-1011	A88-1019	1994	More sophisticated linguistic information comes in several forms, all of which may need to be represented if performance in an automatic categorisation experiment is to be improved	0	Typical examples of linguistically sophisticated annotation include tagging words with their syntactic category although this has not been found to be effective for 1R, lemma of the word eg corpus for corpora, phrasal information eg identifying noun groups and phrases <REF>Lewis 1992c</REF>, <TREF>Church 1988</TREF>, and subject-predicate identification eg <REF>Hindle 1990</REF>	1	For the RAPRA corpus, we currently identify noun groups and adjective groups	0	This is achieved in a manner similar to Churchs 1988 PARTS algorithm used by Lewis 1992bc, in the sense that its main properties are robustness and corpus sensitivity	0	6	1
A94-1011	A88-1019	1994	For the RAPRA corpus, we currently identify noun groups and adjective groups	0	This is achieved in a manner similar to Churchs 1988 PARTS algorithm used by Lewis 1992bc, in the sense that its main properties are robustness and corpus sensitivity	1	All that is important for this paper is that the technique identifies various groupings of words for example, noun-groups, adjective groups, and so on with a high level of accuracy	0	Major parts of the technique are described in detail in <REF>Finch, 1993</REF>	0	3	1
W93-0111	A88-1019	1993	problem	0	Excellent methods have been developed for part-of-speech POS tagging using stochastic models trained on partially tagged corpora <TREF>Church, 1988</TREF>; Cutting, <REF>Kupiec, Pedersen  Sibun, 1992</REF>	1	Semantic issues have been addressed, particularly for sense disambiguation, by using large contexts, eg, 50 nearby words <REF>Gale, Church  Yarowsky, 1992</REF> or by reference to on-line dictionaries <REF>Krovetz, 1991</REF>; <REF>Lesk, 1986</REF>; <REF>Liddy  Paik, 1992</REF>; <REF>Zernik, 1991</REF>	0	More recently, methods to work with entirely untagged corpora have been developed which show great promise <REF>Brill  Marcus, 1992</REF>; <REF>Finch  Chater, 1992</REF>; <REF>Myaeng  Li, 1992</REF>; <REF>Schutze, 1992</REF>	0	1	2
J01-2002	A88-1019	2001	Although methods for unsupervised training of HMMs do exist, training is usually done in a supervised way by estimation of the above probabilities from relative frequencies in the training data	0	The HMM approach to tagging is by far the most studied and applied <TREF>Church 1988</TREF>; <REF>DeRose 1988</REF>; <REF>Charniak 1993</REF>	1	In van <REF>Halteren, Zavrel, and Daelemans 1998</REF> we used a straightforward implementation of HMMs, which turned out to have the worst accuracy of the four competing methods	0	In the present work, we have replaced this by the TnT system we will refer to this tagger as HMM below	0	6	1
J98-3005	A88-1019	1998	Two-Word Descriptions Three-Word Descriptions Stage Entities Unique Entities Entities Unique Entities POS tagging only 9,079 1,546 2,617 604 After WordNet checkup 1,509 395 81 26  Extraction of candidates for proper nouns	0	After tagging the corpus using the POS part-of-speech tagger <TREF>Church 1988</TREF>, we used a CREP <REF>Duford 1993</REF> regular grammar to first extract all possible candidates for entities	1	These consist of all sequences of words that were tagged as proper nouns NP by POS	0	Our manual analysis showed that out of a total of 2150 entities recovered in this way, 1139 529 are not names of entities	0	3	1
J93-2002	A88-1019	1993	A trained system would probably be more accurate in classifying new verbs	0	Finally, the lexical ambiguity problem could probably be reduced substantially in the applied context by using a statistical tagging program <REF>Brill 1992</REF>; <TREF>Church 1988</TREF>	1	For addressing basic questions in machine learning of natural language the solutions outlined above are not attractive	0	All of those solutions provide the learner with additional specific knowledge of English, whereas the goal for the machine learning effort should be to replace specific knowledge with general knowledge about the types of regularities to be found in natural language	0	6	1
P92-1032	A88-1019	1992	to appear, <REF>Hearst 1991</REF>, <REF>Lesk 1986</REF>, <REF>Smadja and McKeown 1990</REF>, <REF>Walker 1987</REF>, <REF>Veronis and Ide 1990</REF>, <REF>Yarowsky 1992</REF>, Zemik 1990, 1991	0	Much of this work offers the prospect that a disambiguation system might be able to input unrestricted text and tag each word with the most likely sense with fairly reasonable accuracy and efficiency, just as part of speech taggers eg , <TREF>Church 1988</TREF> can now input unrestricted text and assign each word with the most likely part of speech with fairly reasonable accuracy and efficiency	1	The availability of massive lexicographic databases offers a promising route to overcoming the knowledge acquisition bottleneck	0	More than thirty years ago, BarI-<REF>Iillel 1960</REF> predicted that it would be futile to write expert-system-like rules by-hand as they had been doing at Georgetown at the time because there would be no way to scale up such rules to cope with unrestricted input	0	1	2
J95-3004	A88-1019	1995	<REF>Choueka and Lusignan 1985</REF> presented a system for the morphological tagging of large texts that is based on the short context of the word but also depends heavily on human interaction	0	Methods using the short context of a word in order to resolve ambiguity usually categorical ambiguity are very common in English and other languages <REF>DeRose 1988</REF>; <TREF>Church 1988</TREF>; <REF>Karlsson 1990</REF>	1	A system using this approach was developed by Levinger and Ornan in order to serve as a component in their project of morphological disambiguation in Hebrew <REF>Levinger 1992</REF>	0	The main resource, used by this system for disambiguation, is a set of syntactic constraints that were defined manually by the authors and followed two theoretical works that defined short context rules for Hebrew <REF>Pines 1975</REF>; <REF>Albeck 1992</REF>	0	6	1
J95-3004	A88-1019	1995	Another application which is more difficult in Hebrew than in other languages is text-to-speech systems, which cannot be implemented in Hebrew without first solving the morphological ambiguity, since in many cases different analyses of a word imply different pronunciations	0	A much simpler problem occurs in English, where for some words the correct syntactic tag is necessary for pronunciation <TREF>Church 1988</TREF>	1	The notion that this ambiguity problem in Hebrew is very complicated and that it can be dealt with only by using vast syntactic and semantic knowledge has led researchers to look for solutions involving a considerable amount of human interaction	0	<REF>Ornan 1986</REF> for instance, developed a new writing system for Hebrew, called The Phonemic Script	0	6	1
J96-2001	A88-1019	1996	Estimating the Lexical Priors for Rare Forms For a common form such as lopen walk a reasonable estimate of the lexical prior probabilities is the MLE, computed over all occurrences of this form	0	So, in the UdB corpus, lopen occurs 92 times as an infinitive and 43 times as a finite plural, so the MLE 1 Even models of disambiguation that make use of context, such as statistical n-gram taggers, often presume some estimate of lexical priors, in addition to requiring estimates of the transition probabilities of sequences of lexical tags <TREF>Church 1988</TREF>; <REF>DeRose 1988</REF>; <REF>Kupiec 1992</REF>, and this again brings up the question of what to do about unseen or low-frequency forms	1	In working taggers, a common approach is simply to apply a uniform small probability to the various senses of unseen or low-frequency forms: this was done in the tagger discussed in <TREF>Church 1988</TREF>, for example	0	156 Baayen and Sproat Lexical Priors for Low-Frequency Forms to> 8 Figure 1 I I I I 0 2 4 6 log frequency class Relative frequency of Dutch infinitives versus finite plurals in the Uit den Boogaart corpus, as a function of the natural log of the frequency of the word forms	0	6	1
J96-2001	A88-1019	1996	So, in the UdB corpus, lopen occurs 92 times as an infinitive and 43 times as a finite plural, so the MLE 1 Even models of disambiguation that make use of context, such as statistical n-gram taggers, often presume some estimate of lexical priors, in addition to requiring estimates of the transition probabilities of sequences of lexical tags <TREF>Church 1988</TREF>; <REF>DeRose 1988</REF>; <REF>Kupiec 1992</REF>, and this again brings up the question of what to do about unseen or low-frequency forms	0	In working taggers, a common approach is simply to apply a uniform small probability to the various senses of unseen or low-frequency forms: this was done in the tagger discussed in <TREF>Church 1988</TREF>, for example	1	156 Baayen and Sproat Lexical Priors for Low-Frequency Forms to> 8 Figure 1 I I I I 0 2 4 6 log frequency class Relative frequency of Dutch infinitives versus finite plurals in the Uit den Boogaart corpus, as a function of the natural log of the frequency of the word forms	0	The horizontal solid line represents the overall MLE, the relative frequency of the infinitive as computed over all tokens; the horizontal dashed line represents the relative frequency of the infinitive among the hapax legomena	0	6	1
C90-3010	A88-1019	1990	Statistical anMyses of linguistic data were very popular in the 50s and 60s, mainly, even though not only, for literary types of analyses and for studies on the lexicon <REF>Guiraud 1959</REF>, <REF>Muller 1964</REF>, <REF>Moskovich 1977</REF>	0	Stochastic approaches to linguistic analyses have been strongly reevaluated in the past few years, either for syntactic analysis Gmside et al 1987, <TREF>Church 1988</TREF>, or for NLP applications <REF>Brown et al 1988</REF>, or for semantic analysis <REF>Zemik 1989</REF>, <REF>Smadja 1989</REF>	1	Quantitative not statistical evidence on eg word-sense occurrences in a large corpus have been taken into account for lexicographic descriptions Cobuild 17	0	I llere and in the following we have not translated idiomatic phrases and compounds, because there is no point in giving the literal translation of the single words	0	6	1
P91-1037	A88-1019	1991	Furthermore, we might expect that some words, such as prepositions and determiners, for example, do not constitute the typical end to an intonational phrase	0	We test these possibilities by examining part-of-speech in a window of four words surrounding each potential phrase break, using Churchs part-of-speech tagger 1988	1	Recall that each intermediate phrase is composed of one or more pitch accents plus a phrase accent, and each intonational phrase is composed of one or more intermediate phrases plus a boundary tone	0	Informal observation suggests that phrase boundaries are more likely to occur in some accent contexts than in others	0	3	1
P91-1037	A88-1019	1991	Discussion The application of CART techniques to the problem of predicting and detecting phrasing boundaries not only provides a classification procedure for predicting intonational boundaries from text, but it increases our understanding of the importance of several among the numerous variables which might plausibly be related to boundary location	0	In future, we plan to extend the set of variables for analysis to include counts of stressed syllables, automatic NP-detection <TREF>Church, 1988</TREF>, MUTUAL INFORMATION, GENERALIZED MUTUAL INFORMATION scores can serve as indicators of intonational phrase boundaries <REF>Magerman and Marcus, 1990</REF>	1	We will also examine possible interactions among the statistically important variables which have emerged from our initial study	0	CART techniques have worked extremely well at classifying phrase boundaries and indicating which of a set of potential variables appear most important	0	6	1
C00-2089	A88-1019	2000	The main atvantage of the linguistic approach is that the model is constructed from a linguistic Ioint of view and contains many and complex kinds of knowledge iI1 tim lemning approach, tile most extended tbrmalism is based on n-grains or IIMM	0	In tiffs case, the language inodel can be estimated from a labelled corpus supervised methods <TREF>Church, 1988</TREF>Weisehedel et al , 1993 or from a nonlabelled corpus unsupervised methods Cutting et 21	1	, 1992	0	In the first; case, the model is trained from the relative observed Dequencies	0	6	1
C00-2089	A88-1019	2000	122 LKarning Techniques These allnoachcs automatically :onstruel; a language model from a labellod alld brackKted corpus	0	The lirst probabilistic approach was proposed in <TREF>Church, 1988</TREF>	1	This method learn; a bigram model for detecting simph3 noun phrasKs on the Brown corpus	0	Civn a sequene of parts of st3eeh as inlug, the Church program inserts the most prolable openings and Kndings of NPs, using a Viterbiqiko	0	6	1
C90-3030	A88-1019	1990	It shows the descriptive power of low-level morphology-based constraints	0	The most successful achievements so far in the domain of large-scale morphological disambiguation of running text have been those for English reported by <REF>Garside, Leech, and Sampson 1987</REF>, on tagging the LOB corpus, and <TREF>Church 1988</TREF>, on assigning part-of-speech labels and parsing noun phrases	1	Success rates ranging between 95-99 are reported, depending on how success is defined	0	These approaches are probabilistic and based on transitional probabilities calculated from extensive pretagged corpora	0	1	2
P96-1042	A88-1019	1996	The methods we investi1This gives the Viterbi model <REF>Merialdo, 1994</REF>, which we use here	0	2This version of the method uses Bayes theorem  <TREF>Church, 1988</TREF>	1	Pwdt, o Pt, J gate approach this evaluation implicitly, measuring an examples informativeness as the uncertainty in its classification given the current training data <REF>Seung, Opper, and Sompolinsky, 1992</REF>; <REF>Lewis and Gale, 1994</REF>; <REF>MacKay, 1992</REF>	0	The reasoning is that if an examples classification is uncertain given current training data then the example is likely to contain unknown information useful for classifying similar examples in the future	0	6	1
P96-1042	A88-1019	1996	Our work focuses on sample selection for training probabilistic classifiers	0	In statistical NLP, probabilistic classifiers are often used to select a preferred analysis of the linguistic structure of a text for example, its syntactic structure <REF>Black et al , 1993</REF>, word categories <TREF>Church, 1988</TREF>, or word senses <REF>Gale, Church, and Yarowsky, 1993</REF>	1	As a representative task for probabilistic classification in NLP, we experiment in this paper with sample selection for the popular and well-understood method of stochastic part-of-speech tagging using Hidden Markov Models	0	We first review the basic approach of committeebased sample selection and its application to partof-speech tagging	0	6	1
P95-1039	A88-1019	1995	Additionally, there is a slight but not significant improvement of tagging accuracy	0	Statistical part-of-speech disambiguation can be efficiently done with n-gram models <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1992</REF>	1	These models are equivalent to Hidden Markov Models HMMs <REF>Rabiner, 1989</REF> of order n 1	0	The states represent parts of speech categories, tags, there is exactly one state for each category, and each state outputs words of a particular category	0	1	2
W01-0712	A88-1019	2001	A specialised version of the chunking task is NP CHUNKING or baseNP identification in which the goal is to identify the base noun phrases	0	The first work on this topic was done back in the eighties <TREF>Church, 1988</TREF>	1	The data set that has become standard for evaluation machine learning approaches is the one first used by <REF>Ramshaw and Marcus 1995</REF>	0	It consists of the same training and test data segments of the Penn Treebank as the chunking task respectively sections 15-18 and section 20	0	6	1
H91-1065	A88-1019	1991	We report in this paper on one application of probabilistic models to language processing, the assignment of part of speech to words in open text	0	The effectiveness of such models is well known <TREF>Church 1988</TREF> and they are currently in use in parsers eg de <REF>Marcken 1990</REF>	0	Our work is an incremental improvement on these models in two ways: 1 We have run experiments regarding the amount of training data needed in moving to a new domain; 2 we have added probabilistic models of word features to handle unknown words effectively	1	We describe POST and its algorithms and then we describe our extensions, showing the results of our experiments	0	5	1
H91-1065	A88-1019	1991	Using the Viterbi algorithm, we selected the path whose overall probability was highest, and then took the tag predictions from that path	0	We replicated the result <TREF>Church 1988</TREF> that this process is able to predict the parts of speech with only a 3-4 error rate when the possible parts of speech of each the words in the corpus are known	1	This is in fact about the rate of discrepancies among human taggers on the TREEBANK project <REF>Marcus, Santorini  Magerman 1990</REF>	0	22 Quantity of training data While supervised training is shown here to be very effective, it requires a correctly taed corpus	0	6	1
W97-0314	A88-1019	1997	They mainly differ in the emphasis they give to syntactic and statistical control of the induction process	0	In Church,1988 a well-know purely statistical method for POS tagging is applied to the derivation of simple noun phrases that are relevant in the underlying corpus	1	On the contrary more language oriented methods are those where specialized grammar are used	0	LEXTER Bourigault,1992 extracts maximal length noun phrases mlnp from a corpus, and then applies a special purpose noun phrase parsing to hem in order to focus on significant complex nominals	0	6	1
J95-4004	A88-1019	1995	There are a number of large tagged corpora available, allowing for a variety of experiments to be run	0	Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years eg , <REF>Jelinek 1985</REF>; <TREF>Church 1988</TREF>; <REF>Derose 1988</REF>; <REF>Hindle 1989</REF>; <REF>DeMarcken 1990</REF>; <REF>Merialdo 1994</REF>; <REF>Brill 1992</REF>; <REF>Black et al 1992</REF>; <REF>Cutting et al 1992</REF>; <REF>Kupiec 1992</REF>; <REF>Charniak et al 1993</REF>; <REF>Weischedel et al 1993</REF>; <REF>Schutze and Singer 1994</REF>	1	Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography	0	Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation	0	6	1
J95-4004	A88-1019	1995	It has recently become clear that automatically extracting linguistic information from a sample text corpus can be an extremely powerful method of overcoming the linguistic knowledge acquisition bottleneck inhibiting the creation of robust and accurate natural language processing systems	0	A number of part-of-speech taggers are readily available and widely used, all trained and retrainable on text corpora <TREF>Church 1988</TREF>; <REF>Cutting et al 1992</REF>; <REF>Brill 1992</REF>; <REF>Weischedel et al 1993</REF>	1	Endemic structural ambiguity, which can lead to such difficulties as trying to cope with the many thousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules <REF>Fujisaki et al 1989</REF>; <REF>Sharman, Jelinek, and Mercer 1990</REF>; <REF>Black et al 1993</REF> and by computing statistical measures of lexical association <REF>Hindle and Rooth 1993</REF>	0	Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic and world knowledge, can now in some cases be done with high accuracy when all information is derived automatically from corpora <REF>Brown, Lai, and Mercer 1991</REF>; <REF>Yarowsky 1992</REF>; Gale, Church, and <REF>Yarowsky 1992</REF>; <REF>Bruce and Wiebe 1994</REF>	0	6	1
J95-4004	A88-1019	1995	However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics	0	Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging <REF>Jelinek 1985</REF>; <TREF>Church 1988</TREF>; <REF>Derose 1988</REF>; <REF>DeMarcken 1990</REF>; <REF>Merialdo 1994</REF>; <REF>Cutting et al 1992</REF>; <REF>Kupiec 1992</REF>; <REF>Charniak et al 1993</REF>; <REF>Weischedel et al 1993</REF>; <REF>Schutze and Singer 1994</REF>	1	41 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows	0	9 The initial-state annotator assigns each word its most likely tag as indicated in the training corpus	0	6	1
A97-1033	A88-1019	1997	Extraction of candidates for proper nouns	0	After tagging the corpus using the POS part-of-speech tagger <TREF>Church, 1988</TREF>, we used a CREP <REF>Duford, 1993</REF> regular grammar to first extract all possible candidates for entities	1	These consist of all sequences of words that were tagged as proper nouns NP by POS	0	Our manual analysis showed that out of a total of 2150 entities recovered in this way, 1139 529 are not names of entities	0	3	1
A97-1029	A88-1019	1997	In the past decade, the speech recognition community has had huge successes in applying hidden Markov models, or HMMs to their problems	0	More recently, the natural language processing community has effectively employed these models for part-ofspeech tagging, as in the seminal <TREF>Church, 1988</TREF> and other, more recent efforts <REF>Weischedel et al , 1993</REF>	1	We would now propose that HMMs have successfully been applied to the problem of name-finding	0	We have built a named-entity NE recognition system using a slightly-modified version of an HMM; we call our system Nymble	0	1	2
W97-0318	A88-1019	1997	For example, there is less than a 005 chance that the difference between stative and event means for the first four indicators listed 2This test was suggested by Judith Klavans personal communication	0	3Similar baselines for comparison have been used for many classification problems <REF>Duda and Hart, 1973</REF>, eg, part-of-speech tagging <TREF>Church, 1988</TREF>; <REF>Allen, 1995</REF>	1	159 is due to chance	0	Overall, this shows that the differences in stative and event averages are statistically significant for the first seven indicators listed p < 01	0	6	1
C90-3063	A88-1019	1990	Both types of ambiguity, syntactic and lexical, may cause the system to acquire or use inappropriate patterns	0	This problems is consid ered very important when dealing with a corpus: it was the re,Leon for the substantial human intervention in the procedure of <REF>Grishman et al 1986</REF>, and it is the reason why other techniques use manually tagged corpora eg <TREF>Church 1988</TREF>	1	In practice, however, we have discovered that the problem is not so cruciah semantically vMid patterns have occurred many more times in syntactically unambiguous constructs than in mnbiguous ones	0	Thus, they could be identified without the need of first disambiguating the sentences	0	6	1
J90-1003	A88-1019	1990	6 PREPROCESSING WITH A PART OF SPEECH TAGGER Phrasal verbs involving the preposition to raise an interesting problem because of the possible confusion with the infinitive marker to	0	We have found that if we first tag every word in the corpus with a part of speech using a method such as <TREF>Church 1988</TREF>, and then measure associations between tagged words, we can identify interesting contrasts between verbs associated with a following preposition toin and verbs associated with a following infinitive marker toto	1	Part of speech notation is borrowed from <REF>Francis and Kucera 1982</REF>; in  preposition; to  infinitive marker; vb  bare verb; vbg  verb  ing; vbd  verb  ed; vbz  verb  s; vbn  verb  en	0	The association ratio identifies quite a number of verbs associated in an interesting way with to; restricting our attention to pairs with a score of 30 or more, there are 768 verbs associated with the preposition toin and 551 verbs with the infinitive marker to/to	0	3	1
J90-1003	A88-1019	1990	The computational tools available for studying machinereadable corpora are at present still rather primitive	1	These are concordancing programs see Figure 1, which are basically KWIC key word in context; <REF>Aho et al 1988</REF> indexes with additional features such as the ability to extend the context, sort leftward as well as rightward, and so on	0	There is very little interactive software	0	In a typical situation in the lexicography of the 1980s, a lexicographer is giwen the concordances for a word, marks up the printout with colored pens to identify the salient senses, and then writes syntactic descriptions and definitions	0	1	3
W00-1309	A88-1019	2000	/3 2	0	precision  recall 1 HMM-based Chunk Tagger The idea of using statistics for chunking goes back to <TREF>Church1988</TREF>, who used corpus frequencies to determine the boundaries of simple non-recursive noun phrases	1	Skut and <REF>Brants1998</REF> modified Churchs approach in a way permitting efficient and reliable recognition of structures of limited depth and encoded the structure in such a way that it can be recognised by a Viterbi tagger	0	This makes the process run in time linear to the length of the input string	0	6	1
J97-2002	A88-1019	1997	Input Text Tokenization Part-of-speech Lookup Descriptor array construction Classification by learning algorithm Text withsentence boundaries disambiguated 31 Tokenization The first stage of the process is lexical analysis, which breaks the input text a stream of characters into tokens	0	The Satz tokenizer is implemented using the UNIX tool LEX <REF>Lesk and Schmidt 1975</REF> and is modeled on the tokenizer used by the PARTS part-of-speech tagger <TREF>Church 1988</TREF>	1	The tokens returned by the LEX program can be a sequence of alphabetic characters, a sequence of digits, 8 or a sequence of one or more non-alphanumeric characters such as periods or quotation marks	0	32 Part-of-Speech Lookup The individual tokens are next assigned a series of possible parts of speech, based on a lexicon and simple heuristics described below	0	6	1
J97-2002	A88-1019	1997	The lexicon and thus the frequency counts used to calculate the descriptor arrays were derived from the Brown corpus <REF>Francis and Kucera 1982</REF>	0	In initial experiments we used the extensive lexicon from the PARTS part-of-speech tagger <TREF>Church 1988</TREF>, which contains 30,000 words	1	We later experimented with a much smaller lexicon, and these results are discussed in Section 44	0	In Sections 41-49 we describe the results of our experiments with the Satz system using the neural network as the learning algorithm	0	3	1
W96-0303	A88-1019	1996	We regard our use of probabilities as being consistent with Bauers claim that accounting for semi-productivity is an issue of performance, not competence <REF>Bauer 1983</REF>:71f	0	The frequency with which a given word form is associated with a particular lexical entry ie sense or grammatical realization is often highly skewed; <TREF>Church 1988</TREF> points out that a model of part-of-speech assignment in context will be 90 accurate for English if it simply chooses the lexically most frequent part-of-speech for a given word	1	<REF>Briscoe and Carroll 1995</REF> found in one corpus that there were about 18 times as many instances of believe in the most common subcategorizati0n class as in the 4 least common classes combined	0	In the absence of other factors, it seems very likely that language users utilize frequency information to resolve indeterminacies in both generation and interpretation	0	6	1
I05-2022	A88-1019	2005	12 Survey of Related Work Chunking has been studied for English and other languages, though not very extensively	0	The earliest work on chunking based on machine learning goes to Church K, 1988 for English	1	<REF>Ramshaw and Marcus, 1995</REF> used transformation based learning using a large annotated corpus for English	0	<REF>Skut and Brants, 1998</REF> modi ed Churchs approach, and used standard HMM based tagging methods to model the chunking process	0	6	1
P99-1004	A88-1019	1999	27 3 Empirical Comparison We evaluated the similarity functions introduced in the previous section on a binary decision task, using the same experimental framework as in our previous preliminary comparison <REF>Dagan et al , 1999</REF>	0	That is, the data consisted of the verb-object cooccurrence pairs in the 1988 Associated Press newswire involving the 1000 most frequent nouns, extracted via Churchs 1988 and Yarowskys processing tools	1	587,833 80 of the pairs served as a training set from which to calculate base probabilities	0	From the other 20, we prepared test sets as follows: after discarding pairs occurring in the training data after all, the point of similarity-based estimation is to deal with unseen pairs, we split the remaining pairs into five partitions, and replaced each nounverb pair n, vl with a noun-verb-verb triple n, vl, v2 such that Pv2  Pvl	0	3	1
P03-1003	A88-1019	2003	In this paper, we propose a new space and a new metric for computing this distance	0	Being inspired by the success of noisy-channel-based approaches in applications as diverse as speech recognition <REF>Jelinek, 1997</REF>, part of speech tagging <TREF>Church, 1988</TREF>, machine translation <REF>Brown et al , 1993</REF>, information retrieval <REF>Berger and Lafferty, 1999</REF>, and text summarization <REF>Knight and Marcu, 2002</REF>, we develop a noisy channel model for QA	1	This model explains how a given sentence S A that contains an answer sub-string A to a question Q can be rewritten into Q through a sequence of stochastic operations	0	Given a corpus of questionanswer pairs Q, S A , we can train a probabilistic model for estimating the conditional probability PQ  S A 	0	2	1
C96-2136	A88-1019	1996	7 0 7 3 Word Segmentation Algorithm 31 Statistical Language Model For the language model in Equation 1, we used the part of speech trigram nlodel POS trigranl or 2nd-order HMM	0	It is used,as tagging mode in English <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1992</REF> and morphological analysis nlodel word segmentation and tagging in Japanese <REF>Nagata, 1994</REF>	1	Let the input character sequence be /  ccec  We approxinlate PCby PW, 7, the joint prol>ability of word sequence W  wlw2u, and part of speech sequence   tlte, t,,	0	PW,T is then approximated t>y the product of parts of speech trigram probabilities Ptiti-2, i-l and word output probabilities for given part of speech Pwiltl, 71 pc pw, -- IX pt, lt,-,t,-,p,lt, 5 i1 Ptilti-,e,ti- and /-wlti  are estimated >y computing the relative frequencies of the corresponding events in training corpus a 32 Forward-DP Backward-A Algorithm /sing the language model 5, Japanese morplological analysis can be detined,as finding tile set of word segmentation and parts of speech 1/, 7 that maximizes the joint probability of word sequence and tag sequence PW, 7	0	6	1
C96-1058	A88-1019	1996	In this seelion, we will outline the three lexicalist, linguistically perspicuous, qualitatiwly different models that we have leveloped a, nd tested	0	21 Model A: Bigram lexieal affinities N-gram tatters like <TREF>Church, 1988</TREF>; lelinek 1985; <REF>Kupiec 1992</REF>; <REF>Merialdo 1990</REF> take the following view of row /, tagged sentctrce enters the worhl	1	Iirst, a setuenee of tags is gnexated aecordittg to a Markov lrocess, with th random choice of ech tag conditioned ou the previous two tags	0	Second, a word is choseu conditional on each tag	0	6	1
J95-2001	A88-1019	1995	Nevertheless, if a large POS set is specified, the number of rules increases significantly and rule definition becomes highly costly and cumbersome	0	Stochastic taggers use both contextual and morphological information, and the model parameters are usually defined or updated automatically from tagged texts Cerf-Danon and E1-<REF>Beze 1991</REF>; <TREF>Church 1988</TREF>; <REF>Cutting et al 1992</REF>; <REF>Dermatas and Kokkinakis 1988, 1990, 1993, 1994</REF>; <REF>Garside, Leech, and Sampson 1987</REF>; <REF>Kupiec 1992</REF>; Maltese  Department of Electrical Engineering, Wire Communications Laboratory WCL, University of Patras, 265 00 Patras, Greece	1	E-mail: dermataswcleeupatrasgr	0	 1995 Association for Computational Linguistics Computational Linguistics Volume 21, Number 2 and <REF>Mancini 1991</REF>; <REF>Meteer, Schwartz, and Weischedel 1991</REF>; <REF>Merialdo 1991</REF>; <REF>Pelillo, Moro, and Refice 1992</REF>; <REF>Weischedel et al 1993</REF>; <REF>Wothke et al 1993</REF>	0	6	1
W07-0813	A88-1019	2007	2 Relation to Previous Works Quite a few works have dealt with extending a given POS tagger, mainly by smoothing it using extra-information about untreated words	0	For example, <TREF>Church, 1988</TREF> uses the simple heuristic of predicting proper nouns from capitalization	0	This method is not applicable to Arabic and Hebrew, which lack typographical marking of proper nouns	1	More advanced methods like those described by Weischedel et al	0	1	3
W96-0208	A88-1019	1996	In particular, it would be interesting to see if the accuracy ranking of the seven algorithms is affected by a change in the representation	0	Similar comparisons of a range of algorithms should also be performed on other natural language problems such as part-of-speech tagging <TREF>Church, 1988</TREF>, prepositional phrase attachment <REF>Hindle  Rooth, 1993</REF>, anaphora resolution Anoe  <REF>Bennett, 1995</REF>, etc Since the requirements of individual tasks vary, different algorithms may be suitable for different sub-problems in natural language processing	1	87 o 0 : 0 0  / 350 300 250 200 150 1 O0 50 I I I I I 	0	Naive Bales o J 3 Nearest Neighbor --0-- Perceptron -m- C45 ---x   PFOIL-DNF ---1 PFOIL-CNF ---1 PFOIL-DLIST --- I  G    :::::-;    ii212  x2C:222Z/2: 200 400 600 800 1000 1200 Training Examples Figure 3: Testing Time for Line Corpus Conclusions This paper has presented fairly comprehensive experiments comparing seven quite different empirical methods on learning to disambiguate words in context	0	6	1
W99-0634	A88-1019	1999	As far as coreference resolution is concerned, the goal of these NLP modules is to determine the boundary of the markables, and to provide the necessary information about each markable for subsequent generation of features in the training examples	0	Our part-of-speech tagger is a standard sta285 tistical bigram tagger based on the Hidden Markov Model HMM <TREF>Church, 1988</TREF>	1	Similarly, we built a statistical HMM-based noun phrase identification module where the noun phrase boundaries are determined solely based on the part-of-speech tags assigned to the words in a sentence	0	We also implemented a module that recognizes MUC-style named entities, ie, organization, person, location, date, time, money, and percent	0	3	1
C98-1077	A88-1019	1998	1 is a typical example of the ambiguities encountered in a running text: little POS ambiguity, but a lot of gender, number and case ambiguity columns 3 to 5	0	485 3 The Model Instead of employing the source-channel paradigm for tagging more or less explicitly present eg in <REF>Merialdo, 1992</REF>, <TREF>Church, 1988</TREF>, <REF>HajiS, HladkA, 1997</REF> used in the past notwithstanding some exceptions, such as Maximum Entropy and rule-based taggers, we are using here a direct approach to modeling, for which we have chosen an exponential probabilistic model	1	Such model when predicting an event  y E Y in a context x has the general form PAC,eYl x  expEiI ifiy,x Zx 3 where fiY, x is the set of size n of binary-valued yes/no features of the event value being predicted and its context, Ai is a weigth in the exponential sense of the feature fi, and the normalization factor Zx is defined naturally as n Zx   exp Aifiy,x 4 yEY i:1 We use a separate model for each ambiguity class AC which actually appeared in the training data of each of the 13 morphological categories 6	0	The final PAC YlX distribution is further smoothed using unigram distributions on subtags again, separately for each category	0	2	1
J93-1004	A88-1019	1993	For a larger dataset, such as the Canadian Hansards, it was not possible to check the results by hand	0	We used the same procedure that is used in <TREF>Church 1988</TREF>	1	This procedure was developed by Kathryn Baker unpublished	0	79 Computational Linguistics Volume 19, Number 1 fefQ t e E 0 0 0 0 P, o Ol I 0 	0	3	1
W98-1205	A88-1019	1998	The accuracy of this data has an impact on the tagging accuracy of both the HMM itself and the derived transducer	0	The training of the HMM can be done on either a tagged or untagged corpus, and is not a topic of this paper since it is exhaustively described in the literature <REF>Bahl and Mercer, 1976</REF>; <TREF>Church, 1988</TREF>	1	An HMM can be identically represented by a weighted FST in a straightforward way	0	We are, however, interested in non-weighted transducers	0	6	1
A00-1024	A88-1019	2000	The first feature represents the part of speech of the word	0	Vve use an in-house statistical tagger based on <TREF>Church, 1988</TREF> to tag the text in which the unknown word occurs	1	The tag set used is a simplified version of the tags used in the machinereadable version of the Oxford Advanced Learners Dictionary OALD	0	The tag set contains just one tag to identify nouns	0	3	1
A94-1009	A88-1019	1994	The first major use of HMMs for part of speech tagging was in CLAWS <REF>Garside et al , 1987</REF> in the 1970s	0	With the availability of large corpora and fast computers, there has been a recent resurgence of interest, and a number of variations on and alter53 natives to the FB, Viterbi and BW algorithms have been tried; see the work of, for example, Church <TREF>Church, 1988</TREF>, Brill <REF>Brill and Marcus, 1992</REF>; <REF>Brill, 1992</REF>, DeRose <REF>DeRose, 1988</REF> and gupiec <REF>Kupiec, 1992</REF>	1	One of the most effective taggers based on a pure HMM is that developed at Xerox <REF>Cutting et al , 1992</REF>	0	An important aspect of this tagger is that it will give good accuracy with a minimal amount of manually tagged training data	0	6	1
W03-1706	A88-1019	2003	Specifically speaking, the content chunking contains two subtasks: 1 to recognize the maximum phrase in a sequence of content words; 2 to analyze the hierarchical structure within the phrase down to words	0	Like baseNP chunking<TREF>Church, 1988</TREF>; <REF>Ramshaw  Marcus 1995</REF>, content chunk parsing is also a kind of shallow parsing	1	Content chunk parsing is deeper than baseNP chunking in two aspects: 1 a content chunk may contain verb phrases and other phrases even a full sentence as long as the all the components are content words; 2 it may contain recursive NPs	0	Thus the content chunk can supply more structural information than a baseNP	0	6	1
W05-1510	C88-2121	2005	From the perspective of using a lexicalized grammar developed for parsing and importing parsing techniques, our method is similar to the following approaches	1	The Fergus system <REF>Bangalore and Rambow, 2000</REF> uses LTAG Lexicalized Tree Adjoining Grammar <TREF>Schabes et al , 1988</TREF> for generating a word lattice containing realizations and selects the best one using a trigram model	0	<REF>White and Baldridge 2003</REF> developed a chart generator for CCG Combinatory Categorial Grammar <REF>Steedman, 2000</REF> and proposed several techniques for efficient generation such as best-first search, beam thresholding and chunking the input logical forms <REF>White, 2004</REF>	0	Although some of the techniques look effective, the models to rank candidates are still limited to simple language models	0	6	1
W90-0102	C88-2121	1990	Work on the use of synchronous TAGs to capture quantifier scoping possibilities makes use of so-called multicomponent TAGs	0	Finally, the base TAGs may be lexicalized <TREF>Schabes et al , 1988</TREF> or not	1	Once the base formalism has been decided upon we currently are using lexicalized multi-component TAGs with substitution and adjunction, a simple translation strategy from a source string to a target is to parse the string using an appropriate TAG parser for the base formalism	1	Each derivation of the source string can be mapped according to the synchronizing links in the grammar to a target derivation	0	3	2
C96-1085	C88-2121	1996	Also, the provision of conceptual entities which are incrementally generated by the semantic interpretation process supplies the necessary anchoring points for the continuous resolution of textual anaphora and ellipses <REF>Strube  Hahn, 1995</REF>; <REF>Hahn et al , 1996</REF>	0	The lexical distribution of grammatical knowledge one finds in many lexiealized grammar formalisms eg , LTAGS <TREF>Schabes et al , 1988</TREF> or HPSG <REF>Pollard  Sag, 1994</REF> is still constrained to declarative notions	1	Given that the control flow of text understanding is globally unpredictable and, also, needs to be purposefully adapted to critical states of the analysis eg , cases of severe extragrammaticality, we drive lexicalization to its limits in that we also incorporate procedural control knowledge at the lexical gr,unmar level	0	The specification of lexiealized communication primitives allows heterogeneous and local lorms of interaction among groups of lexical items	0	1	3
C92-1034	C88-2121	1992	This will allow for easy maintenance and facilitate updates to the grammar	0	1 Motivations Lexicalized tree-adjoining grammar LTAG <TREF>Schabes et al , 1988</TREF>; <REF>Schabes, 1990</REF> is a tree-rewriting formalism used for specifying the syntax of natural languages	1	It combines elementary lexical trees with two operations, adjoining and substitution	0	In a LTAG, lexical itenm are associated with complex syntactic structures in the form of trees that define the various phrase structures they can participate in	0	6	1
W03-0401	C88-2121	2003	Formally, a derivation tree is represented as a set of dependencies: D   i,  j,r i , where  i is an elementary tree,   i represents a node in  j where substitution/adjunction has occurred, and r i is a label of the applied rule, ie, adjunction or substitution	0	A probability of derivation tree D   i,  j,r i  is generally defined as follows <TREF>Schabes et al , 1988</TREF>; <REF>Chiang, 2000</REF>	1	pD productdisplay i p i   j,r i  Note that each probability on the right represents the syntactic/semantic preference of a dependency of two lexical items	0	We can readily see that the model is very similar to LPCFG models	0	4	2
W03-0401	C88-2121	2003	That is, the models are still based on decomposition into primitive lexical dependencies	1	Derivation trees, the structural description in LTAG <TREF>Schabes et al , 1988</TREF>, represent the association of lexical items ie, elementary trees	1	In LTAG, all syntactic constraints of words are described in an elementary tree, and the dependencies of elementary trees, ie, a derivation tree, describe the semantic relations of words more directly than lexicalized parse trees	0	For example, Figure 3 has a derivation tree corresponding to the parse tree in Figure 1 2	0	5	2
P98-1091	C88-2121	1998	A more linguistically motivated approach is to expand the domain of productions downward to incorporate more tree structures	0	The Lexicalized Tree-Adjoining Grammar LTAG formalism <TREF>Schabes et al , 1988</TREF>, <REF>Schabes, 1990</REF>, although not context-free, is the most well-known instance in this category	1	PLTIGs belong to this third category and generate only context-free languages	0	LTAGs and LTIGs are tree-rewriting systems, consisting of a set of elementary trees combined by tree operations	0	1	2
H91-1035	C88-2121	1991	Thus CCG assigns the following two groupings to John likes apples: 2 John likes apples 3 John likes apples The work on CCG was presented by Mark Steedman in an earlier DARPA SLS Workshop <REF>Steedman, 1989</REF>	0	In this paper, we show how a CCG-like account for coordination can be constructed in the framework of lexicalized tree-adjoining grammars TAGs <REF>Joshi, 1987</REF>; <TREF>Schabes et al , 1988</TREF>; <REF>Schabes, 1990</REF>	1	2	0	In particular, we show how a fixed constituency can be maintained at the level of the elementary trees of lexicalized TAGs and yet be able to achieve the kind of flexibility needed for dealing with the so-called non-constituents	0	4	2
A94-1022	C88-2121	1994	which cannot be felicitously uttered except in a context where there is something in the discourse that a restriction could apply to	0	Conventional approaches to subcategorization, such as Definite Clause Grammar <REF>Pereira and Warren, 1980</REF>, Categorial Grammar <REF>Ades and Steedman, 1982</REF>, PATR-II <REF>Shieber, 1986</REF>, and lexicalized TAG <TREF>Schabes et al, 1988</TREF> all deal with complementation by including in one form or another a notion of subcategorization frame that specifies a sequence of complement phrases and constraints on them	0	Handling all the possible variations in complement distribution in such formalisms inevitably leads to an explosion in the number of such frames, and a correspondingly more difficult task in porting to a new domain	0	In our approach, on the other hand, it becomes possible to view subcategorization of a lexical item as a set of constraints on the outgoing arcs of its semantic graph node	1	2	3
P93-1017	C88-2121	1993	Recently there has been a gain in interest in the so-called mildly context-sensitive formalisms Vijay-<REF>Shanker, 1987</REF>; <REF>Weir, 1988</REF>; <REF>Joshi, VijayShanker, and Weir, 1991</REF>; Vijay-<REF>Shanker and Weir, 1993a</REF> that generate only a small superset of context-free languages	0	One such formalism is lexicalized tree-adjoining grammar LTAG Schabes, Abeill, and <REF>Joshi, 1988</REF>; <REF>Abeillfi et al , 1990</REF>; <REF>Joshi and Schabes, 1992</REF>, which provides a number of attractive properties at the cost of decreased efficiency, On6-time in the worst case <REF>VijayShanker, 1987</REF>; <REF>Schabes, 1991</REF>; <REF>Lang, 1990</REF>; <REF>VijayShanker and Weir, 1993b</REF>	1	An LTAG lexicon consists of a set of trees each of which contains one or more lexical items	0	These elementary trees can be viewed as the elementary clauses including their transformational variants in which the lexical items participate	0	4	2
P07-1079	C88-2121	2007	Much of the appeal of these approaches is tied to the use of a simple formalism, which allows for the use of efficient parsing algorithms, as well as straightforward ways to train discriminative models to perform disambiguation	0	At the same time, there is growing interest in parsing with more sophisticated lexicalized grammar formalisms, such as Lexical Functional Grammar LFG <REF>Bresnan, 1982</REF>, Lexicalized Tree Adjoining Grammar LTAG <TREF>Schabes et al , 1988</TREF>, Headdriven Phrase Structure Grammar HPSG <REF>Pollard and Sag, 1994</REF> and Combinatory Categorial Grammar CCG <REF>Steedman, 2000</REF>, which represent deep syntactic structures that cannot be expressed in a shallower formalism designed to represent only aspects of surface syntax, such as the dependency formalism used in current mainstream dependency parsing	0	We present a novel framework that combines strengths from surface syntactic parsing and deep syntactic parsing, specifically by combining dependency and HPSG parsing	1	We show that, by using surface dependencies to constrain the application of wide-coverage HPSG rules, we can benefit from a number of parsing techniques designed for high-accuracy dependency parsing, while actually performing deep syntactic analysis	0	5	2
W07-2213	C88-2121	2007	This paper will concentrate on context-free grammars CFG and their associated parsers	0	However, virtually all Tree Adjoining Grammars TAG, see eg, <TREF>Schabes et al , 1988</TREF> used in NLP applications can almost be seen as lexicalized Tree Insertion Grammars TIG, which can be converted into strongly equivalent CFGs <REF>Schabes and Waters, 1995</REF>	1	Hence, the parsing techniques and tools described here can be applied to most TAGs used for NLP, with, in the worst case, a light over-generation which can be easily and efficiently eliminated in a complementary pass	0	This is indeed what we have achieved with a TAG automatically extracted from Villemonte de <REF>La Clergerie, 2005</REF>s large-coverage factorized French TAG, as we will see in Section 4	0	4	2
C90-3001	C88-2121	1990	We can thus define lexical transfer rules that avoid the defects of a mere word-to-word approach but still benefit from the simplicity and elegance of a lexical approach	0	We rely on the French and English LTAG grammars Abeille 1988, Abeille 1990 b, Abeilld et al 1990, Abeill6 and Schabes 1989, 1990 that have been designed over the past two years jointly at University of Pennsylvania and University of Paris 7-Jussieu	1	1 Strategy for Machine Translation with LTAGs The idea of using grammars written with lexicalist formalisms for machine translation is not new This research was partially ftmded by ARO grant DAAG29-84-K-0061, DARPA grant N00014-85-K0018, and NSF grant MCS-82-19196 at the University of Pen nsylvania	0	We are indebted to Stuart Shieber for his valuable comments	0	5	2
E91-1005	C88-2121	1991	3 A TAG Analysis The TAG formalism for a recent introduction, see <REF>Joshi 1987a</REF> is well suited for linguistic description because 1 it provides a larger domain of locality than a CFG or other augmented CFG-based formalisms such as tlPSG or LFG, and 2 it allows factoring of recursion from the domain of dependencies	0	This extended domain of locality, provided by the elementary trees of TAG, allows us to lexicalize a TAG grammar: we can associate each tree in a grammar with a lexical item <TREF>Schabes et al 1988</TREF>, <REF>Schabes 1990</REF> 4	1	The tree will contain the lexical item, and all of its syntac3Some verbs allow scrambling out of their Complements more freely than others	0	It appears that all subject-control verbs and most object-control verbs governing the dative allow scrambling fairly fely, while scrambling with objectcontrol verbs governing the accusative is more restricted cir	0	4	2
P95-1036	C88-2121	1995	In Section 8 we conclude with some directions for future work	0	2 Lexicalized Tree-Adjoining Grammar Lexicalized Tree-Adjoining Grammar LTAG <TREF>Schabes et al , 1988</TREF>; <REF>Schabes, 1990</REF> consists of ELEMENTARY TREES, with each elementary tree having a lexical item anchor on its frontier	1	An elementary tree serves as a complex description of the anchor and provides a domain of locality over which the anchor can specify syntactic and semantic predicate-argument constraints	0	Elementary trees are of two kinds a INITIAL TREES and b AUXILIARY TREES	0	6	1
P98-1026	C88-2121	1998	178 6 Comparison to PSG Approaches One feature of word order domains is that they factor ordering alternatives from the syntactic tree, much like feature annotations do for morphological alternatives	0	Other lexicalized grammars collapse syntactic and ordering information and are forced to represent ordering alternatives by lexical ambiguity, most notable L-TAG <TREF>Schabes et al , 1988</TREF> and some versions of CG <REF>Hepple, 1994</REF>	0	This is not necessary in our approach, which drastically reduces the search space for parsing	1	This property is shared by the proposal of <REF>Reape 1993</REF> to associate HPSG signs with sequences of constituents, also called word order domains	0	2	3
P05-2024	C88-2121	2005	This high coverage allowed us to evaluate the parser in terms of the accuracy of dependency analysis on real-world texts, the evaluation measure that is previously used for more statistically-oriented parsers	0	2 HPSG Head-Driven Phrase Structure Grammar HPSG is classified into lexicalized grammars <TREF>Schabes et al , 1988</TREF>	1	It attempts to model linguistic phenomena by interactions between a small number of grammar rules and a large number of lexical entries	0	Figure 1 shows an example of an HPSG derivation of a Japanese sentence kare ga shinda, which means, He died In HPSG, linguistic entities such as words and phrases are represented by typed feature structures called signs, and the grammaticality of a sentence is verified by applying grammar rules to a sequence of signs	0	6	1
P03-2036	C88-2121	2003	We also investigate the reason for that difference	0	Various parsing techniques have been developed for lexicalized grammars such as Lexicalized Tree Adjoining Grammar LTAG <TREF>Schabes et al , 1988</TREF>, and Head-Driven Phrase Structure Grammar HPSG <REF>Pollard and Sag, 1994</REF>	0	Along with the independent development of parsing techniques for individual grammar formalisms, some of them have been adapted to other formalisms <TREF>Schabes et al , 1988</TREF>; van <REF>Noord, 1994</REF>; <REF>Yoshida et al , 1999</REF>; <REF>Torisawa et al , 2000</REF>	0	However, these realizations sometimes exhibit quite different performance in each grammar formalism <REF>Yoshida et al , 1999</REF>; <REF>Yoshinaga et al , 2001</REF>	1	1	3
P03-2036	C88-2121	2003	Various parsing techniques have been developed for lexicalized grammars such as Lexicalized Tree Adjoining Grammar LTAG <TREF>Schabes et al , 1988</TREF>, and Head-Driven Phrase Structure Grammar HPSG <REF>Pollard and Sag, 1994</REF>	0	Along with the independent development of parsing techniques for individual grammar formalisms, some of them have been adapted to other formalisms <TREF>Schabes et al , 1988</TREF>; van <REF>Noord, 1994</REF>; <REF>Yoshida et al , 1999</REF>; <REF>Torisawa et al , 2000</REF>	0	However, these realizations sometimes exhibit quite different performance in each grammar formalism <REF>Yoshida et al , 1999</REF>; <REF>Yoshinaga et al , 2001</REF>	0	If we could identify an algorithmic difference that causes performance difference, it would reveal advantages and disadvantages of the different realizations	1	5	2
A92-1030	C88-2121	1992	The parser achieves an OGn6-time worst case behavior, OG2n4-time for unambiguous grammars and linear time for a large class of grammars	0	The parser uses the following two-pass parsing strategy originally defined for lexicalized grammars <TREF>Schabes et al , 1988</TREF> which improves its performance in practice <REF>Schabes and Joshi, 1990</REF>:  In the first step the parser will select, the set of structures corresponding to each word in the sentence	1	Each structure can be considered as encoding a set of rules	0	In the second step, the parser tries to see whether these structures can be combined to obtain a wellformed structure	0	3	2
A92-1030	C88-2121	1992	XTAG runs under Common Lisp and X Window CLX	0	Tree-adjoining grammar TAG <REF>Joshi et al , 1975</REF>; <REF>Joshi, 1985</REF>; <REF>Joshi, 1987</REF> and its lexicalized variant <TREF>Schabes et al , 1988</TREF>; <REF>Schabes, 1990</REF>; <REF>Joshi and Schabes, 1991</REF> are tree-rewriting systems in which the syntactic properties of words are encoded as tree structured-objects of extended size	0	TAG trees can be combined with adjoining and substitution to form new derived trees	0	1 Tree-adjoining grammar differs from more traditional tree-generating systems such as context-free grammar in two ways: 1	0	6	1
A92-1030	C88-2121	1992	This information is particularly useful for a top-down component of the parser <REF>Schabes and Joshi, 1990</REF>	0	XTAG provides all the utilities required for designing a lexicalized TAG structured as in Schabes et al 1988	1	All the syntactic concepts of lexicalized TAG such as the grouping of the trees in tree families which represents the possible variants on a basic subcategorization frame are accessible through mouse-sensitive items	0	Also, all the operations required to build a grammar such as load trees, define tree families, load syntactic and morphological lexicon can be predefined with a macro-like language whose instructions can be loaded from a file See Figure 5	0	4	2
A92-1030	C88-2121	1992	See the introduction by Joshi 1987 for an introduction to tree-adjoining grammar	0	We refer the reader to Joshi 1985, Joshi 1987, Kroch and Joshi 1985, Abeill et al 1990a, Abeill 1988 and to Joshi and Schabes 1991 for more information on the linguistic characteristics of TAG such as its lexicalization and factoring recursion out of dependencies	1	2The TAG derivation tree is the basis for semantic interpretation <REF>Shieber and Schabes, 1990b</REF>, generation <REF>Shieber and Schabes, 1991</REF> and machine translation Abeill et al , 1990b since the information given in this data-structure is richer than the one found in the derived tree	0	Furthermore, it is at the level of the derivation tree that ambiguity must be defined	0	5	2
C04-1204	C88-2121	2004	Interestingly, several studies suggested that the identification of PropBank annotations would require linguistically-motivated features that can be obtained by deep linguistic analysis <REF>Gildea and Hockenmaier, 2003</REF>; <REF>Chen and Rambow, 2003</REF>	0	They employed a CCG <REF>Steedman, 2000</REF> or LTAG <TREF>Schabes et al , 1988</TREF> parser to acquire syntactic/semantic structures, which would be passed to statistical classifier as features	0	That is, they used deep analysis as a preprocessor to obtain useful features for training a probabilistic model or statistical classifier of a semantic argument identifier	0	These results imply the superiority of deep linguistic analysis for this task	1	4	2
E91-1006	C88-2121	1991	All errors are of course our own	0	As for Lexicalized TAGs, in <TREF>Schabes et al , 1988</TREF> a two step algorithm has been presented: during the first step the trees corresponding to the input string are selected and in the second step the input string is parsed with respect to this set of trees	0	Another paper by <REF>Schabes and Joshi 1989</REF> shows how parsing strategies can take advantage of lexicalization in order to improve parsers performance	0	Two major advantages have been discussed in the cited work: grammar filtering the parser can use only a subset of the entire grammar and bottom-up information further constraints are imposed on the way trees can be combined	1	1	2
E91-1006	C88-2121	1991	In <REF>Kroch and Joshi, 1985</REF> a detailed discussion of the linguistic relevance of TAGs can be found	0	Lexicalized Tree Adjoining Grammars <TREF>Schabes et al , 1988</TREF> are a refinement of TAGs such that each elementary tree is associated with a lexieal item, called the anchor of the tree	1	Therefore, Lexicalized TAGs conform to a common tendency in modem theories of grammar, namely the attempt to embed grammatical information within lexical items	0	Notably, the association between elementary trees and anchors improves also parsing performance, as will be discussed below	0	4	2
P99-1059	C88-2121	1999	Early mechanisms of this sort included categorial grammar Bar-<REF>Hillel, 1953</REF> and subcategorization frames <REF>Chomsky, 1965</REF>	0	Other lexicalized formalisms include <TREF>Schabes et al , 1988</TREF>; Meluk, 1988; <REF>Pollard and Sag, 1994</REF>	1	Besides the possible arguments of a word, a natural-language grammar does well to specify possible head words for those arguments	0	Convene requires an NP object, but some NPs are more semantically or lexically appropriate here than others, and the appropriateness depends largely on the NPs head eg , meeting	0	6	1
C98-1088	C88-2121	1998	A more linguistically motivated approach is to expand the domain of productions downward to incorporate more tree structures	0	The Lexicalized Tree-Adjoining Grammar LTAG formalism <TREF>Schabes et al, 1988</TREF>, <REF>Schabes, 1990</REF> , although not context-free, is the most well-known instance in this category	1	PLTIGs belong to this third category and generate only context-free languages	0	LTAGs and LTIGs are tree-rewriting systems, consisting of a set of elementary trees combined by tree operations	0	1	2
W98-1125	J86-3001	1998	It is somewhat tempting to take the results as indicating that clues have bad effects on the performance more discussion on this later	0	This, however, appears to run counter to what we expect from results reported in prior work on discourse<REF>Kurohashi and Nagao, 1994</REF>; <REF>Litman and Passonneau, 1995</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Marcu, 1997</REF>, where the notion of clues or cue phrases forms an important part of identifying a structure of discourse7 Table 4 shows how the confidence value CF affects the performance of discourse models	0	The CF 7 One problem with earlier work is that evaluations are done on very small data; 9 sections from a scientific writing approx	0	300 sentences <REF>Kurohashi and Nagao, 1994</REF>: 15 narrathes I113 clauses Lhman and Passonneau	0	0	0
W04-0211	J86-3001	2004	Largely formal methods involving manipulating information in lexical ontologies and the output of sentential syntactic and semantic analysis are sufficient to account for most cases of discourse continuity, and give rise to only limited ambiguity in most other cases	0	2 The assignment of correct temporal, personal and spatial interpretation to utterances, which relies in large part on the relative location of referential expression and their 2 Complex default logic based reasoning as in Structured Discourse Representation Theory <REF>Asher 1993</REF>; <REF>Asher and Lascarides 2003</REF>, speculations about the intentions or beliefs of speakers as in <TREF>Grosz and Sidner 1986</TREF>, or the intricate node labeling exercises familiar from Rhetorical Structure Theory <REF>Mann and Thompson 1988</REF>; <REF>Marcu 1999, 2000</REF> are not necessary	0	referents in the DPT representation of the structure of the discourse, can then often be recovered	0	From a computational point of view, this is good news	0	0	0
P89-1025	J86-3001	1989	standing have recognized the need for such information	0	In their work on discourse analysis, <TREF>Grosz and Sidner 1986</TREF> argue that it is necessary to represent the intentional structure, the attentional structure knowledge about which aspects of a dialogue are in focus at each point, and the linguistic structure of The research described in this paper was supported by the Defense Advanced Research Projects Agency DARPA under a NASA Ames cooperative agreement number NCC 2-520	0	The authors would like to thank William Swartout for comments on earlier versions of this paper	0	203 the discourse	0	0	0
P89-1025	J86-3001	1989	There is thus a need for a text plan to contain a specification of the intended effect of individual parts of the text on the hearer and how the parts relate to one another	0	We have developed a text planner that records the following information about the responses it produces:  the information that <TREF>Grosz and Sidner 1986</TREF> have presented as the basics of a discourse structure: intentional structure: a representation of the effect each part of the text is intended to have on the hearer and how the complete text achieves the overall discourse purpose eg , describe entity, persuade hearer to perform an action	0	attentional structure: information / about which objects, properties and events are salient at each point in the discourse	0	Users followup questions are often ambiguous	0	0	0
W93-0236	J86-3001	1993	INTENTIONALITY IN A TOPICAL APPROACH OF DISCOURSE STRUCTURE 1 Jan van Kuppevelt University of Nijmegen Department of Philosophy e-mail: JVKUPPEV KUNRC1URCKUNNL  Position paper The alternative to be outlined provides a proposal to solve a central problem in research on discourse structure and discourse coherence, namely, as pointed out by many authors, that of the relationship between linguistic and intentional structure, or, in other words, between subject matter and presentational relations <REF>Mann and Thompson 1988</REF> or informational and intentional relations <REF>Moore and Pollack 1992</REF>	0	As is argued for in <REF>Van Kuppevelt 1993</REF>, this alternative not only implies uniformity on the structural levels involved, ie the linguistic and intentional level, but also on the level of attentional states <TREF>Grosz and Sidner 1986</TREF>	0	2 The latter is ruled by the dynamics of topic constitution and topic termination, determining which discourse units are in focus of attention during the development of the discourse	0	3 We will see that both linguistic relations and intentions are defined in a uniform way by topic-forming questions in discourse, thereby automatically satisfying the need for a multi-level analysis as is argued for in <REF>Moore and Paris 1992</REF>, and as is signalled by Dale this volume, avoiding differences in discourse segmentation between RST analyses and intentional approaches	0	0	0
W97-0402	J86-3001	1997	Discourse structures of dialogues are usually represented as hierarchical structures which This research is supported in part by the ministry of information and communication of Korea	0	reflect embedding subdialogues <TREF>Grosz and Sidner 1986</TREF>	0	Many researchers have studied the way how to analyze dialogues	0	One of the representative approaches is the plan-based method <REF>Litman et al 1987</REF>; <REF>Caberry 1989</REF>	0	0	0
W03-2121	J86-3001	2003	 extended monologues	0	There are several overtly	0	 declarative theories of the structure of such texts	0	 many of them stemming from the work of Mann	0	0	0
P02-1012	J86-3001	2002	Furthermore, current pronominalization strategies are ill-equipped to deal with the wide variety of reasons that pronouns are used in naturally occurring texts	0	Almost without exception, they focus on anaphoric pronouns as described in Focus/Centering Theory <REF>Webber, 1979</REF>; <REF>Sidner, 1983</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Walker, 1998</REF>, ignoring the multitude of other possible types	0	However, it is certainly true that authors make use of pronouns which are not motivated by anaphoric reference	0	In addition, because such approaches are oriented towards anaphora resolution during parsing, they ignore structures such as the discourse plan which are present during generation but not parsing	0	0	0
P02-1012	J86-3001	2002	Indeed, most work on pronouns in computational linguistics has come under the heading of anaphora resolution as an element of parsing rather than the heading of pronominalization as an element of generation	0	Since discourse anaphora resolution was first studied theoretically <REF>Grosz, 1977</REF>; <REF>Webber, 1979</REF>; <REF>Sidner, 1983</REF>; <TREF>Grosz and Sidner, 1986</TREF>, it has come to be dominated by Centering Theory <REF>Grosz et al , 1995</REF>; <REF>Di Eugenio, 1998</REF>; <REF>Walker, 1998</REF> which proposes rules for the determination of focus and salience within a given segment of discourse	0	Relatively little work has been done on alternate approaches to pronoun resolution <REF>Hobbs, 1976</REF>; <REF>Baldwin, 1995</REF>	0	While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation <REF>Not, 1996</REF>; <REF>Yeh and Mellish, 1997</REF>; <REF>McCoy and Strube, 1999</REF>; <REF>Henschel et al , 2000</REF>; <REF>Kibble and Power, 2000</REF>, there has yet been no substantial return contribution to the field of anaphora resolution	0	0	0
P97-1013	J86-3001	1997	out because unit I is not an important unit for span 1,2 and, as mentioned at the beginning of this section, a rhetorical relation that holds between two spans of a valid text structure must also hold between their most important units: the important unit of span 1,2 is unit 2, ie, the nucleus of the relation rhetrelCONCESSlON, 1,2	0	3 A corpus analysis of discourse markers 31 Materials We used previous work on cue phrases <REF>Halliday and Hasan, 1976</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Martin, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1995</REF>; <REF>Fraser, 1996</REF> to create an initial set of more than 450 potential discourse markers	0	For each potential discourse marker, we then used an automatic procedure that extracted from the Brown corpus a set of text fragments	0	Each text fragment contained a window of approximately 200 words and an emphasized occurrence of a marker	0	0	0
P97-1013	J86-3001	1997	In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs	0	Such constructs can include tense 96 and aspect <REF>Moens and Steedman, 1988</REF>; <REF>Webber, 1988</REF>; <REF>Lascarides and Asher, 1993</REF>, certain patterns of pronominalization and anaphoric usages <REF>Sidner, 1981</REF>; <TREF>Grosz and Sidner, 1986</TREF></TREF>; <REF>Sumita et al , 1992</REF>; <REF>Grosz, Joshi, and Weinstein, 1995</REF>,/t-clefts <REF>Delin and Oberlander, 1992</REF>, and discourse markers or cue phrases <REF>Ballard, Conrad, and Longacre, 1971</REF>; <REF>Halliday and Hasan, 1976</REF>; <REF>Van Dijk, 1979</REF>; <REF>Longacre, 1983</REF>; <TREF>Grosz and Sidner, 1986</TREF></TREF>; <REF>Schiffrin, 1987</REF>; <REF>Cohen, 1987</REF>; <REF>Redeker, 1990</REF>; <REF>Sanders, Spooren, and Noordman, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1995</REF>; <REF>Fraser, 1996</REF>; <REF>Moser and Moore, 1997</REF>	0	In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts	0	The intuition behind our choice relies on the following facts:  Psycholinguistic and other empirical research <REF>Kintsch, 1977</REF>; <REF>Schiffrin, 1987</REF>; <REF>Segal, Duchan, and Scott, 1991</REF>; <REF>Cahn, 1992</REF>; <REF>Sanders, Spooren, and Noordman, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1995</REF>; <REF>Costermans and Fayol, 1997</REF> has shown that discourse markers are consistently used by human subjects both as cohesive ties between adjacent clauses and as macroconnectors between larger textual units	0	0	0
P97-1013	J86-3001	1997	Despite the formal elegance of these approaches, they are very domain dependent and, therefore, unable to handle more than a few restricted exampies	0	On the other hand, although the theories described by <TREF>Grosz and Sidner 1986</TREF>, <REF>Polanyi 1988</REF>, and <REF>Mann and Thompson 1988</REF> are successfully applied manually, they,are too informal to support an automatic approach to discourse analysis	0	In contrast with this previous work, the rhetorical parser that we present builds discourse trees for unrestricted texts	0	We first discuss the key concepts on which our approach relies section 2 and the corpus analysis section 3 that provides the empirical data for our rhetorical parsing algorithm	0	0	0
P99-1046	J86-3001	1999	The prime motivation for identifying such units is to improve performance on languageprocessing or IR tasks	0	Discourse segmentation, on the other hand, is often finer-grained, and focuses on identifying relations between utterances eg <TREF>Grosz and Sidner, 1986</TREF> or <REF>Hirschberg and Grosz, 1992</REF>	0	Many topic segmentations algorithms have been proposed in the literature	0	There is not enough space to review them all here, so we will focus on describing a representative sample that covers most of the features used to predict the location of boundaries	0	0	0
P04-1019	J86-3001	2004	BRIDGING REFERENCES BR <REF>Clark, 1977</REF> anaphoric expressions that cannot be resolved purely on the basis of string matching and thus require the reader to bridge the gap using commonsense inferencesare arguably the most interesting and, at the same time, the most challenging problem in anaphora resolution	0	Work such as <REF>Poesio et al , 1998</REF>; <REF>Poesio et al , 2002</REF>; <REF>Poesio, 2003</REF> provided an experimental confirmation of the hypothesis first put forward by <REF>Sidner 1979</REF> that BRIDGING DESCRIPTIONS BD1 are more similar to pronouns than to other types of definite descriptions, in that they are sensitive to the local rather than the global focus <TREF>Grosz and Sidner, 1986</TREF>	0	This previuous work also suggested that simply choosing the entity whose description is lexically closest to that of the bridging description among those in the current focus space gives poor results; in fact, better results are obtained by always choosing as ANCHOR of the bridging reference2 the first-mentioned entity of the previous sentence <REF>Poesio, 2003</REF>	0	But neither source of information in isolation resulted in an accuracy over 40	0	0	0
P04-1019	J86-3001	2004	<REF>Poesio 2003</REF> used the Web to choose between the hypotheses concerning the anchors of mereological BDs in the GNOME corpus generated on the basis of Centering information see below	0	22 Salience One of the motivations behind <REF>Grosz and Sidners 1986</REF> distinction between two aspects of the attentional state the LOCAL FOCUS and the GLOBAL FOCUSis the difference between the interpretive preferences of pronouns and definite descriptions	0	According to Grosz and Sidner, the interpretation for pronouns is preferentially found in the local focus, whereas that of definite descriptions is preferentially found in the global focus	0	4A similar approach was pursued in parallel by <REF>Berland and Charniak 1999</REF>	0	0	0
P93-1041	J86-3001	1993	For example, cue phrases play an important role in signaling segment changes	0	<TREF>Grosz and Sidner, 1986</TREF> However, such clues are not directly based on coherence which forms the clauses or sentences into a segment	0	<REF>Youmans 1991</REF> proposed VMP vocabulary management profile as an indicator of segment boundaries	0	VMP is a record of the number of new vocabulary terms introduced in an interval of text	0	0	0
A00-1008	J86-3001	2000	Robust natural language understanding in Atlas-Andes is provided by Ros6s CARMEL system Ros6 2000; it uses the spelling correction algorithm devised by <REF>Elmi and Evens 1998</REF>	0	52 Structure of human tutorial dialogues In an earlier analysis <REF>Kim, Freedman and Evens 1998</REF> we showed that a significant portion of human-human tutorial dialogues can be modeled with the hierarchical structure o f task-oriented dialogues <TREF>Grosz and Sidner 1986</TREF>	0	Furthermore, a main building block o f the discourse hierarchy, corresponding to the transaction level in Conversation Analysis <REF>Sinclair and Coulthard 1975</REF>, matches the tutoring episode defined by VanLehn et al	0	1998	0	0	0
A00-1008	J86-3001	2000	Second, Hierarchical decomposition minimizes search time	0	Third, our dialogues are task-oriented and have a hierarchical structure <TREF>Grosz and Sidner 1986</TREF>	0	In such a case, matching the structure of the domain simplifies operator development because they can often be derived from transcripts of human tutoring sessions	0	The hierarchy information is also useful in determining appropriate referring expressions	0	0	0
J89-2001	J86-3001	1989	For example, Mann, Moore, and Levin <REF>Mann et al 1977</REF> used a knowledge structure called a dialog game to model goal-related use of language in joint interactions such as buying/selling and learning/teaching	0	Grosz and Sidner <REF>Grosz et al 1986</REF> and <REF>Reichman 1984</REF> have investigated discourse structure and have shown that a coherent discourse can be segmented into units that have well-defined relationships to one another	0	Reichman contended further that the existing discourse structure established expectations about appropriate next conversational moves	0	Our analysis of naturally occurring dialog indicates that such expectations about appropriate next steps in the dialog form a third component of factual knowledge that plays a major role in comprehending elliptical fragments	0	0	0
J00-3005	J86-3001	2000	1995, <REF>Salton and Allan 1995</REF>, and <REF>Hearst 1997</REF> have shown that word cooccurrences and more sophisticated forms of lexical cohesion can be used to determine segments of topical and thematic continuity	0	<REF>And Morris and Hirst 1991</REF> have also shown that there is a correlation between cohesion-defined textual segments and hierarchical, intentionally defined segments <TREF>Grosz and Sidner 1986</TREF>	0	For example, if the first three paragraphs of a text talk about the moon and the subsequent two paragraphs talk about the Earth, it is possible that the rhetorical structure of the text is characterized by two spans that subsume these two sets of paragraphs and that a rhetorical relation of JOINT or LIST holds between the two spans	0	Also, studies by Harabagiu, Moldovan, and Maiorano <REF>Harabagiu and Maiorano 1996</REF>; <REF>Harabagiu and Moldovan 1999</REF> show that cohesion can be used to determine rhetorical relations that hold between smaller discourse constituents as well	0	0	0
J00-3005	J86-3001	2000	In Section 4, I explain how the annotated data was used to derive algorithms that identify connective occurrences Section 42, determine elementary units of discourse and determine which connectives have a discourse function Section 43, and hypothesize rhetorical relations that hold between elementary units and spans of texts Section 44	0	405 Computational Linguistics Volume 26, Number 3 31 Materials Many researchers have published lists of potential discourse markers and cue phrases <REF>Halliday and Hasan 1976</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Martin 1992</REF>; <REF>Hirschberg and Litman 1993</REF>; <REF>Knott 1995</REF>; <REF>Fraser 1996</REF>	0	I took the union of their lists and created an initial set of more than 450 potential discourse markers	0	For each potential discourse marker, I then used an automatic procedure that extracted from the Brown corpus a set of text fragments	0	0	0
J00-3005	J86-3001	2000	Despite their formal elegance, implementations of these theories cannot yet handle naturally occurring texts, such as that shown in 1	0	On the other hand, the theories aimed at characterizing the constraints that pertain to the structure of unrestricted texts and the computational mechanisms that would enable the derivation of these structures van <REF>Dijk 1972</REF>; <REF>Zock 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Mann and Thompson 1988</REF>; <REF>Polanyi 1988, 1996</REF>; <REF>Hobbs 1990</REF> are either too informal or incompletely specified to support a fully automatic approach to discourse analysis	0	In this paper, I explore the ground found at the intersection of these two lines of research	0	More precisely, I explore the extent to which rhetorical structures of the kind shown in Figure 1 can be built automatically by relying only on cohesion and connectives, ie, phrases such as for example, and, although, and however that are used to link linguistic units at any level <REF>Crystal 1991</REF>, 74	0	0	0
W06-1408	J86-3001	2006	Referring expressions to be generated are required to be distinguishing descriptions, that is, descriptions of the entities being referred to, but not to any other object in the context set	0	A context set is defined as the set of the entities the addressee is currently assumed to be attending to  this is similar to the concept of focus spaces of the discourse focus stack in <REF>Grosz  Sidners 1986</REF> theory of discourse structure	0	Moreover, the contrast set the set of potential distractors <REF>McDonald 1981</REF> is defined to entail all elements of the context set except the intended referents	0	Generating referring expressions is pursued since the eighties eg , <REF>Appelt 1985</REF>, among several others	0	0	0
J93-4004	J86-3001	1993	In addition, the relationships between these intentions are not represented	0	To make clear what is missing, we have represented in Figure 5 the intentional structure of this text using Grosz and Sidners 1986 notions of dominance and satisfaction-precedence	0	In Grosz and Sidners theory 1986, p 179, if an action that satisfies one intention, h, is intended to provide part of the satisfaction of another intention,/2, then/2 dominates h h satisfaction-precedes 12 whenever h must be satisfied before/2	0	The representation shown in Figure 5 makes it clear that the expert systems E top-level intention I0 is to get the user U to intend to replace SETQ X 1 with SETF X 1, and this intention dominates Es intentions to recommend this act /1 and to persuade U to perform it /2	0	0	0
J93-4004	J86-3001	1993	It is impossible to tell from the sets of effects at each level of the decomposition how effects are related to one another	0	<TREF>Grosz and Sidner 1986</TREF> argue that such relations between intentions are a crucial part of intentional structure	0	Contrast Mayburys plans with those produced by our system	0	Our text plans explicitly represent the intended effects of actions and the relationships between these intentions	0	0	0
J93-4004	J86-3001	1993	This may be a communicative goal, such as The speaker intends to 11 Note that rhetorical structure is not the only source of discourse markers	0	They may be used to mark shifts in attentional structure, discourse segment boundaries, or aspects of the exchange structure in interactive discourse <TREF>Grosz and Sidner 1986</TREF>; <REF>Redeker 1990</REF>; <REF>Schiffrin 1987</REF>	0	670 Johanna D Moore and C6cile L Paris Planning Text for Advisory Dialogs achieve the state in which the hearer believes a proposition or a linguistic goal, such as Establish motivation between an act and a goal or Inform the user of a proposition	0	a constraint list: a list of conditions that should be true in order for the operator to have the intended effect	0	0	0
J93-4004	J86-3001	1993	To make clear what is missing, we have represented in Figure 5 the intentional structure of this text using Grosz and Sidners 1986 notions of dominance and satisfaction-precedence	0	In Grosz and Sidners theory 1986, p 179, if an action that satisfies one intention, h, is intended to provide part of the satisfaction of another intention,/2, then/2 dominates h h satisfaction-precedes 12 whenever h must be satisfied before/2	0	The representation shown in Figure 5 makes it clear that the expert systems E top-level intention I0 is to get the user U to intend to replace SETQ X 1 with SETF X 1, and this intention dominates Es intentions to recommend this act /1 and to persuade U to perform it /2	0	In addition, for this schema, the recommendation h must be satisfied before the persuade /2 is attempted	0	0	0
J93-4004	J86-3001	1993	The systems that have been built within 653 Computational Linguistics Volume 19, Number 4 this framework to date <REF>Cohen 1978</REF>; <REF>Appelt 1985</REF> plan short oneor two-sentence texts to achieve the speakers goals	0	In this approach, the intentional structure describing the speakers purposes and the relationships between them <TREF>Grosz and Sidner 1986</TREF> is explicitly represented	0	However, this approach does not represent or use rhetorical knowledge about how speech acts may be combined into larger bodies of coherent text to achieve a speakers goals	0	It assumes that appropriate axioms could be added to generate longer texts, and that the text produced will be coherent as a byproduct of the planning process	0	0	0
J93-4004	J86-3001	1993	To perform these tasks, our system must understand how the previous responses stored in its discourse history relate to one another	0	That is, we must address issues of how to build a representation of the intentional structure of the dialogue that is emerging across conversational turns <TREF>Grosz and Sidner 1986</TREF> and to track global focus <REF>Grosz 1977</REF>	0	In addition, we will need communicative strategies for managing the dialogue, eg, strategies for introducing a topic, strategies for returning to a topic, etc 9	0	Conclusions We have presented an approach to natural language generation that extends previous theories and implementations in order to enable a computational system to play the role of a dialogue participant in an advisory setting	0	0	0
W06-1611	J86-3001	2006	The resulting corpus had 2334 student turns and a comparable number of system turns	0	21 Discourse structure We base our annotation of discourse structure on the Grosz  Sidner theory of discourse structure <TREF>Grosz and Sidner, 1986</TREF>	0	A critical ingredient of this theory is the intentional structure	0	According to the theory, each discourse has a discourse purpose/intention	0	0	0
P98-1090	J86-3001	1998	In this paper we look the phenomenon of long-distance pronominalisation in some detail, examining data from different domains, and consider 550 its implications for GSs theory	0	2 Theories of focus Space unfortunately prevents a full discussion of Groszs 1977, Sidners 1979, and GSs 1986 theories of focus and the attentional state in this abstract	0	The crucial aspects of these theories, for the purpose of the discussion below, are as follows	0	First of all, GS propose a distinction between two components of the attentional state: the GLOBAL FOCUS, structured as a stack of focus spaces and accessed to interpret definite descriptions; and the LOCAL FOCUS, consisting of the information preferentially used to interpret pronouns In addition, they adopt CENTERING THEORY <REF>Grosz et al , 1995</REF> as a theory of the local focus	0	0	0
P98-1090	J86-3001	1998	All 7 long-distance pronouns in the ILEX dialogues we have studied refer to discourse entities introduced in background text in this way	0	Unlike Sidners theory of focus <REF>Sidner, 1979</REF>, the theory of the attentional state in <TREF>Grosz and Sidner, 1986</TREF> henceforth: GS does not include explicit provision for long-distance pronominalisations, although some of the necessary tools are potentially already there, as we will see	0	The component of the theory that deals with pronominal reference, centering theory <REF>Grosz et al , 1995</REF>, only accounts for cases in which the antecedent of a pronoun is introduced by the previous sentence; cases such as 1 have to be handled by different mechanisms	0	In this paper we look the phenomenon of long-distance pronominalisation in some detail, examining data from different domains, and consider 550 its implications for GSs theory	0	0	0
W06-1320	J86-3001	2006	In this paper, we examine one form of lexical cohesion, namely lexical reiteration	0	Following some of the most prominent discourse theories in literature <TREF>Grosz and Sidner, 1986</TREF>; <REF>Marcu, 2000</REF>, a hierarchical representation of the thematic episodes can be proposed	0	The basis for this is the idea that topics can be recursively divided into subtopics	0	Real texts exhibit a more intricate structure, including semantic returns by which a topic is suspended at one point and resumed later in the discourse	0	0	0
W96-0109	J86-3001	1996	INTRODUCTION Topic identification concerns a problem of predicting terms in text which indicate its subject or theme	0	In the past, the problem has been addressed mostly by computational linguists in relation to issues like coreference <REF>Hobbs, 1978</REF>, anaphora resolution <TREF>Grosz and Sidner, 1986</TREF>; <REF>Lappin and Leass, 1994</REF>, or discourse center <REF>Joshi and Weinstein, 1981</REF>; <REF>Walker et al , 1994</REF>	0	In information retrieval, predicting important terms in document is crucial for an effective retrieval of relevant documents<REF>Salton et al , 1993</REF>, though they do not necessarily correspond to the subject or the theme	0	Predicting important terms involves numerical weighting of terms in document	0	0	0
C00-2112	J86-3001	2000	But, according to Familiarity Theory Helm, 1983, reti;rring expressions need not denote mfiquely by virtue of their meaning as they refer to individuals made familiar by the discourse or other context	0	This observation plays a key role in Centering Theory <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al , 1995</REF> and other computational altroaches in which rethrring expressions are resolved by locating their antecedents in the discourse	0	The reference of pronouns like he, definite descriptions like the woman, and referential tenses like had clearly has more to do with salience ill context thml with uniqueness of meaning	0	Similarly, while names like Mary need not denote individuals prominent in the discourse context,  Ve would like to thank the anonymous reviewers for their detailed and helpful comments	0	0	0
P06-2051	J86-3001	2006	The dialog system classi es this input into different categories as eg, instruction, query or social interaction	0	For this purpose we use discourse segments proposed by Grosz and Sidner <TREF>Grosz and Sidner, 1986</TREF> to describe the kind of utterances during the interaction	0	Then the dialog manager can react appropriately if it knows whether the user asked a question or instructed the robot	0	As gesture and object detection in our scenario is not very reliable and time-consuming, the system needs verbal hints of scene information such as pointing gestures or object descriptions to gather information of the gesture detection and object attention system	0	0	0
P89-1030	J86-3001	1989	Any communicative act, be it spoken, written, gestured, or system-initiated, can give rise to DEs	0	As a discourse progresses, an adequate discourse model must represent the relevant entities, and the relationships between them <TREF>Grosz and Sidner, 1986</TREF>, A speaker may then felicitously refer anaphorically to an object subject to focusing or centering constraints <REF>Grosz et al , 1983</REF>, <REF>Sidner 1981, 1983</REF>, <REF>Brennan et al 1987</REF>  if there is an existing DE representing it, or if a corresponding DE may be directly inferred from an existing DE	0	For example, the utterance Every senior in Milford High School has a car gives rise to at least 3 entities, describable in English as the seniors in Milford High School, Milford High School, and the set of cars each of which is owned by some senior in Milford High School	0	These entities may then be accessed by the following next utterances, respectively: They graduate in June	0	0	0
W97-1301	J86-3001	1997	A blind WordNet search for semantic relations is also very expensive computationally	0	A mechanism for focus tracking <TREF>Grosz and Sidner, 1986</TREF> or a clustering algorithm should be applied first in order to minimise the costs	0	In order to have proper names available for resolution of future references, it is useful to create discourse referents for them which contain their entity types	0	Up to now we have identified an entity type for 69 of the names in our corpus, and we resolved 53 of the DDs referring back to proper names with the help of WordNet	0	0	0
W93-0237	J86-3001	1993	The first characteristic of the IMACENE project was its focus on local rhetorical relations in written instructional text in English	0	There are a number of sub-issues related to this focus of concern, all of which tend to lend themselves to a traditional RST approach: Written rather than interactive discourse D A number of studies in the context of interactive discourse have emphasized the need for separate representation of intentions <REF>Fox, 1988</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Moore and Paris, 1989</REF>	0	This mechanism allows the system to deal with, for example, conversational repair, an issue which is not prevalent in written text	0	Instructional text rather than other genres -Instructional text does not tend to make use of the deep and multi-faceted intentions that are common in argumentative and persuasive text such as was the case in the Come home by 5:00 example cited by Moore and Pollack	0	0	0
W00-1433	J86-3001	2000	We are eliminating the joint relation, as it gives no helpful information from a content-planning perspective and annotators are tempted to over-use it	0	One of the criticisms of RST is that there is an infinite set of relations <TREF>Grosz and Sidner, 1986</TREF>	0	The goal is to arrive at a mutually-exclusive, clearlydefined set of relations with discriminatory power in each domain, so we expect that for each new domain, it may be necessary to start with an initial set of high-level relations selected from different categories, examine a small set of texts or dialogs in that domain, and then revise the set of relations by mak ing relevant high-leve	0	relations morespecificWe used this process to develop our annotation scheme	0	0	0
W00-1433	J86-3001	2000	The relationships between many of these statements are unclear without a model of rhetorical structure	0	<REF>In 1999</REF>, Nakatani and Traum describe a hierarchical annotation of dialog for I-units, based on the  domination and satisfaction-precedence relations of <TREF>Grosz and Sidner, 1986</TREF>	0	Other researchers have shown that Grosz and Sidners model of discourse structure GST and RST are similar in many respects <REF>Moser and Moore, 1996</REF>, <REF>Marcu, 1999</REF>	0	However, RST provides more specific relations than GST, and this is useful for content planning	0	0	0
D08-1035	J86-3001	2008	338 without labeled data	0	We are especially interested in cue phrases, which are explicit markers for discourse structure, such as now or first <TREF>Grosz and Sidner, 1986</TREF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1996</REF>	0	Cue phrases have previously been used in supervised topic segmentation eg, <REF>Galley et al 2003</REF>; we show how they can be used in an unsupervised setting	0	The previous section modeled lexical cohesion by treating the bag of words in each sentence as a series of draws from a multinomial language model indexed by the topic segment	0	0	0
D08-1035	J86-3001	2008	But despite the effectiveness of lexical cohesion for unsupervised topic segmentation, it is clear that there are other important indicators that are ignored by the current generation of unsupervised systems	0	For example, consider cue phrases, which are explicit discourse markers such as now or however <TREF>Grosz and Sidner, 1986</TREF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1996</REF>	0	Cue phrases have been shown to be a useful feature for supervised topic segmentation <REF>Passonneau and Litman, 1993</REF>; <REF>Galley et al, 2003</REF>, but cannot be incorporated by current unsupervised models	0	One reason for this is that existing unsupervised methods use arbitrary, hand-crafted metrics for quantifying lexical cohesion, such as weighted cosine similarity <REF>Hearst, 1994</REF>; <REF>Malioutov and Barzilay, 2006</REF>	0	0	0
C96-2158	J86-3001	1996	There are, however, implementability limitations	0	At discourse level, determining the set of admissible antecedents requires a representation which is ordered according to pragmatic relations <TREF>Grosz and Sidner, 1986</TREF>; <REF>Wehber, 1989</REF>	0	Although various theoretical frmneworks have been suggested, the recognition of these relations in the case of unrestricted discourse is still beyond the state-of the-art	0	Moreover, there arc cases ill which antecedent decisions can only be made on the grounds of domain knowledge and inferencing, and although there have been various attempts to integrate components of these kinds into anaphor resolution approaches, a satisfying solution l;o this problem is not available by now	0	0	0
W00-0402	J86-3001	2000	The function of discourse analysis is to divide a text into discourse segments, and to recognize and re-construct the discourse structure of the text as intended by its author	0	Results of discourse analysis can be used to solve many important NLP problems such as anaphoric reference <REF>Hirst 1981</REF>, tense and aspect analysis <REF>Hwang and Schubert 1992</REF>, intention recognition <TREF>Grosz and Sidner 1986</TREF>; <REF>Litman and Allen 1990</REF>, orcan be directly applied to computational NLP applications such as text abstraction <REF>Ono et al 1994</REF>; Tsou et al 1996 and text generation <REF>McKeown 1985</REF>; <REF>Lin et al 1991</REF>	0	Automatic text abstraction has received considerable attention see <REF>Paice 1990</REF> for a comprehensive review	0	While some statistical approaches have had some success in extracting one or more sentences which can serve as a summary <REF>Brandow et al 1995</REF>; <REF>Kupiec et al 1995</REF>; <REF>Salton et al 1997</REF>, summarization in general has remained an elusive task	0	0	0
W04-0713	J86-3001	2004	An example of a rule identifying IPAs is the following: adjectival constructions in which the prepositional complement only subcategorises for concrete entities such as let for x easy for x, fuld af x full of x	0	4 The DAR-algorithm 41 Search Space and DE lists dar presupposes the discourse structure described by <TREF>Grosz and Sidner 1986</TREF>	0	The minimal discourse unit is the utterance U Paragraphs correspond to discourse segments in texts	0	Discourse segments in dialogues were manually marked	0	0	0
J94-2006	J86-3001	1994	This difference is evident in the examples discussed in this paper involving discourse-initial text, and even in an example discussed in this paper that we believe does not involve a discourse segment boundary	0	Note that because the centering literature claims that centering should operate only within a discourse segment, and because this claim is used to explain some otherwise problematic cases of pronoun use, not being able to adequately handle discourse seg1 Notice that we use the term focusing to cover all local focusing frameworks, Sidners focusing framework <REF>Sidner 1979</REF>, Carters extensions to Sidners framework <REF>Carter 1987</REF>, the centering framework <REF>Grosz, Joshi, and Weinstein 1983</REF> and others, our framework RAFT/RAPR, PUNDIT Dahl 1986 and others, etc We use uppercase Focusing, or Local Focusing, or Sidners Focusing Algorithm/Framework to refer to Sidners work	0	We use RAFT/RAPR to refer to our work	0	302 Linda Z Suri and Kathleen F McCoy RAFT/RAPR and Centering ment initial text is much more of a problem for the centering frameworks than may at first be apparent	0	0	0
J94-2006	J86-3001	1994	Pronoun resolution within the centering framework is largely based on an ordering of preferred focus centering moves	0	Other research on discourse eg , <REF>Grosz 1981</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Reichman 1978</REF> has studied another phenomenon, the global focus of discourse	0	The term global focus generally refers to the entity or set of entities that are relevant to or salient in the overall discourse; the identification of global focus typically interacts with the identification of discourse segments	0	Global focus and discourse segmentation are distinct from the phenomenon of local focusing that is addressed in this paper	0	0	0
P98-1100	J86-3001	1998	Lexical cohesion relations <REF>Halliday and Hasan, 1976</REF> between words were identified in RT and used to construct lexical chains of related words in five texts <REF>Morris and Hirst, 1991</REF>	0	It was reported that the lexical chains closely correlated to the intentional structure <TREF>Grosz and Sidner, 1986</TREF> of the texts, where the start and end of chains coincided with the intention ranges	0	However, RT does not capture all types of lexical cohesion relations	0	In previous work, it was found that collocation a lexical cohesion relation was under-represented in the thesaurus	0	0	0
W93-0240	J86-3001	1993	as literally as possible, from their native theories; Then, without any iredefined fram,wolk, w observe the emergence of an integral discourse model encompassing these structures and iJltelltills via necessary bridging knowledge and inferences	0	Thus, on the one hand, our integrative vi,ws toward discourse structures and intentions are similar to <TREF>Grosz and Sidner, 1986</TREF> and Moore a llI <REF>Pollack, 1992</REF> in the sense that we hold  The separation of attentional and intentional tracks of discourse 	0	The stratification of coherence informational and rhetorical intentional relatiJlls	0	On the other hand, unlike previous work, we formulate knowledge sources which expl:,il, how the, emergence of integrated discourse model is possible, rather than just identifying such integrati	0	0	0
W93-0240	J86-3001	1993	we follow existing theories and by identifying the necessary bridging knowledge and interences, we just observe the integration emerging out of the individual discourse structures and intentions ;is defined in their native theories	0	This integrative view is similar to others, eg, <TREF>Grosz and Sidner, 1986</TREF> and Moore and Pollack	0	1992	0	Due to the lack of space, we did not deal with the full ranges of issues, but many of our positions are identical to others, in particular: 1	0	0	0
E93-1030	J86-3001	1993	Thus the open clauses are those on the 251 right frontier of the discourse structure cf	0	<REF>Polanyi 1985</REF>, <TREF>Grosz and Sidner 1986</TREF>, <REF>Webber 1991</REF>, assuming that it is built in a depth first left to right manner	0	SDRT specifies which parts of the SDRS are available to the representation of the current sentence for attachment via a discourse relation	0	DICE provides the means to infer from the readers knowledge resources which discourse relation should be used to do attachment	0	0	0
P08-1097	J86-3001	2008	Finally, topic segmentation provides only an outline of the discourse structure	0	Richer models of discourseincludehierarchicalstructure<REF>GroszandSidner, 1986</REF> and Rhetorical Structure Theory <REF>Mann and Thompson, 1988</REF>	0	The application of gestural analysis to such models may lead to fruitful areas of future research	0	Acknowledgments We thank Aaron Adler, C Mario Christoudias, Michael Collins, Lisa Guttentag, Igor Malioutov, Brian Milch, Matthew Rasmussen, Candace Sidner, Luke Zettlemoyer, and the anonymous reviewers	0	0	0
J96-2005	J86-3001	1996	The utterances in 22b and 22c realize propositions previously established as mutually believed, so they are IRUs	0	2 The cue word but in utterance 22a indicates a push, a new intention <TREF>Grosz and Sidner 1986</TREF>	0	The phrase as far as the certificates are concerned indicates that this new intention is subordinate to the previous discussion of the certificates	0	Thus, utterance 22a, but as far as the certificates are concerned, has the effect that the focus space related to the discussion of retirement investments, corresponding to utterances 8 to 21, is popped from the stack	0	0	0
J96-2005	J86-3001	1996	A representation of an utterance A is hierarchically recent for a representation of an utterance B if A is adjacent to B in the tree structure of the discourse	0	Of all theories based on hierarchical recency, only Grosz and Sidners theory of discourse structure provides an operationalization of hierarchical recency in terms of their stack model of attentional state <REF>Sidner 1979</REF>; <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	Thus, below, the relationship between limited attention and hierarchical recency will be discussed in terms of their stack model, but the discussion should also apply to claims about the role of hierarchical recency in other work	0	In the remainder of this squib, I will argue that the limited attention constraint must account for three types of evidence: 1 the occurrence of informationally redundant utterances in naturally occurring dialogues <REF>Walker 1993</REF>; 2 the infelicity of discourses that depend on accessing discourse entities that are not linearly recent; and 3 experiments that show that humans have limited attentional capacity <REF>Miller 1956</REF>; <REF>Baddeley 1986</REF>	0	0	0
J96-2005	J86-3001	1996	258 Walker Attention and Discourse tentions and the hearers recognition of intention; 2 expectations about what will be discussed	0	The cache model maintains the distinction between intentional structure and attentional state first proposed by <TREF>Grosz and Sidner 1986</TREF>	0	This distinction is critical	0	Just as a cache can be used for processing the references and operations of a hierarchically structured program, so can a cache be used to model attentional state when discourse intentions are hierarchically structured	0	0	0
C98-1062	J86-3001	1998	Approaches that address this problem can be classified in knowledge-based approaches or word-based approaches	0	Knowledge-based systems as Grosz and Sidners 1986 require an extensive manual knowledge engineering effort to create the knowledge base semantic network and/or frames and this is only possible in very limited and well-known domains	0	To overcome this limitation, and to process a large amount of texts, word-based approaches have been developed	0	<REF>Hearst 1997</REF> and <REF>Masson 1995</REF> make use of the word distribution in a text to find a thematic segmentation	0	0	0
P94-1050	J86-3001	1994	DAAL 0389-C0031 PRI	0	tempted to confirm the theories of discourse structure outlined in <TREF>Grosz and Sidner, 1986</TREF> using information from a thesaurus	0	In addition, <REF>Kozima 1993</REF> speculated that segmenting text along topic boundaries may be useful for anaphora resolution and text summarization	0	This paper is about an automatic method of finding discourse boundaries based on the repetition of lexical items	0	0	0
P94-1050	J86-3001	1994	In all but the shortest texts, the topic will be expounded upon through the discussion of multiple subtopics	0	Whether the organization of the text is hierarchical in nature, as described in <TREF>Grosz and Sidner, 1986</TREF>, or linear, as examined in Skorochodko, 1972, boundaries between subtopics will generally exist	0	In some cases, these boundaries will be explicit and will correspond to paragraphs, or in longer texts, sections or chapters	0	They can also be implicit	0	0	0
W93-0208	J86-3001	1993	Structuring Two-Medium Dialog for Learning Language and Other Things Henry Hamburger George Mason University; Fairfax, VA, USA Dan Tufts Research Institute for Informatics; Bucharest, Romania Raza Hashim Bridgewater College; Bridgewater, VA, USA OVERVIEW: Naturalistic two-medium communication with a computational system, using both language and interactive graphics <REF>Cohen, 1991</REF>; <REF>Maier, 1993</REF>; <REF>McKeown, 1993</REF>, is an important practical complement to studies that involve only language, only graphics and/or only people	0	Integrative two-medium work should build on insights and findings in the one-medium disciplines of graphical manipulative interfaces eg , <REF>Hutchins et al , 1986</REF>; <REF>Sullivan and Tyler, 1991</REF> and natural language discourse eg , <TREF>Grosz and Sidner, 1986</TREF>; <REF>Litman and Allen, 1987</REF>; <REF>Hovy, 1988</REF>; <REF>Lambert and Carberry, 1991</REF>; <REF>Paris, 1991</REF>	0	In addition to its general use with a variety of systems, two-medium communication provides an essential foundation for a pedagogically important form of foreign language learning experience <REF>Hamburger and Hashim, 1992</REF>	0	Specifically, it permits a supportive dialog practice system for naturalistic acquisition of various language aspects, by combining discourse constraints with independently comprehensible situational contexts	0	0	0
P92-1001	J86-3001	1992	She pursues a view that task structure, or more generally, domain structure, is sufficient to account for many discourse phenomena but cf	0	<TREF>Grosz and Sidner 1986</TREF>:182	0	She examines in detail the generation of paragraph-length texts describing the layout of a house	0	Houses have structure, following from a basic relation of spatial proximity, and there are also hierarchical levels to the structure rooms can be listed without describing whats in them, or the objects within each room can be detailed	0	0	0
P92-1001	J86-3001	1992	Discourse Interpretation and Commonsense Entailment DICE Discourse and Commonsense Entailment starts with traditional discourse representation structures cf	0	<REF>Kamp 1981</REF>, but goes on to assume with <TREF>Grosz and Sidner 1986</TREF> that candidate discourses possess hierarchical structure, with units linked by discourse relations modelled after those proposed by IIobbs 1979, 1985 cf	0	also <REF>Thompson and Mann 1987</REF>, <REF>Scha and Polanyi 1988</REF>	0	1 <REF>Lascarides and Asher 1991a</REF> use Narration, Explanation, Background, Result and Elaboration	0	0	0
W99-0108	J86-3001	1999	A pronoun interpretation algorithm based on centering which relied on centering transition preferences was developed in Brennan et aL 1987 Using transition preferences in a pronoun generation rule would cover more cases of pronoun use than is covered by Rule 1, but the application of such transition preferences also proved unhelpful in explaining pronoun patterns in our corpus	0	<REF>Reichman 1985</REF> and <TREF>Grosz  Sidner 1986</TREF> indicate that discourse segmentation has an effect on the linguistic realization of referring expressions	0	While this is intuitively appealing, it is unclear how to apply this to the generation problem in part because it is unclear how to define discourse segments to a generation system	0	<REF>Passonneau 1996</REF> argues for the use of the principles of information adequacy and economy	0	0	0
W99-0108	J86-3001	1999	The threading device used to structure will be different for different kinds ofdisc0urses	0	For instance, in the kinds of discourses studied in <TREF>Grosz  Sidner 1986</TREF> the threading device may be the intentional structures and each of their discourse segments would constitute a thread of the discourse, in the discourses that we studied New York Times acles, threads defined in terms of the time referenced in a clause appeared to be quite prominent	0	In this paper we present our preliminary work in uncovering factors that affect pronoun generation decisions	0	Our work so far has led us to hypothesize several factors including: Sentence Boundaries pronouns appear to be the preferred referring form for subsequent reference to an item within the same sentence	0	0	0
W99-0108	J86-3001	1999	However, we argue that a single definition of disburse segment is not sufficient to explain the patterns of pronoun use found, and seek a more general notion	0	Here, to distingnih o notion from other notions of discmuse segmentation found in the literature eg , <REF>Reidmum 1985</REF> or <TREF>Grosz  Sidner 1986</TREF>, we use the term discomae thread to capture the structuring notion to whidz we refer	0	We propose that a discourse generally contains multiple threads which run through the discourse and can serve to structure the discourse	0	In general, a single thread is evident at a particular point in the discourse, but this thread may be replaced by another thread and then picked up again at another point in the discourse cf	0	0	0
C98-2174	J86-3001	1998	3 Deductive Operators The choice of operators implemented in the ftetorica system has been influenced by a number of factors	0	The rules of inference are clear candidates for operationalisation: moves such as Modus Ponens are clearly vital components of any argument though, as noted in <TREF>Grosz and Sidner 1986</TREF>, p201, it is inappropriate to view the implication step as one of conventional material implication	0	The relationship is rather one of support the hearer must be brought to believe that given the current context and domain of discourse the first proposition warrants, in part, concluding the second	0	Even given this weaker, predicate-based reading of a Modus Ponens argument, it is still unclear that any of the other rules of inference which are, after all, formally redundant should be necessary	0	0	0
C98-2174	J86-3001	1998	Belief goals are used to build the content of an argument as in much other NLG work; saliency goals to express the intention to convey information to the hearer following a notion of saliency similar to that proposed in <REF>Walker, 1996</REF>; and topic manipulation goals to control the focus of attention through the discourse	0	The roles of these goals and their interrelationships are explored in relation to the informationintention-attention model of <TREF>Grosz and Sidner 1986</TREF> in more detail in <REF>Reed and Long 1997a</REF>	0	3 Deductive Operators The choice of operators implemented in the ftetorica system has been influenced by a number of factors	0	The rules of inference are clear candidates for operationalisation: moves such as Modus Ponens are clearly vital components of any argument though, as noted in <TREF>Grosz and Sidner 1986</TREF>, p201, it is inappropriate to view the implication step as one of conventional material implication	0	0	0
P93-1009	J86-3001	1993	One such question is how the postulated representations should be further formalized, and how reasoning with these formalizations is to be performed	0	A second question is how this conception of discourse processing may be integrated with theories of discourse structure <TREF>Grosz and Sidner, 1986</TREF>; <REF>Scha and Polanyi, 1988</REF>; <REF>Webber, 1991</REF>	0	While we have looked primarily at two-clause structures, the ramifications that the claims have on multi-clause discourse structure require further investigation	0	Such studies will form the basis for further characterization of the role of coherence establishment in anaphoric processing	0	0	0
W90-0116	J86-3001	1990	For example, an analysis of the texts using Mann and Thompsons 1987 Rhetorical Structure Theory RST would result primarily in the relations sequence and joint and would contain few of the the relations like evidence or justify that give RST its descriptive power	0	Similarly, it is unclear what work a system like that of <TREF>Grosz and Sidner 1986</TREF> would do in analyzing a description	0	Since the structure of descriptions cannot be analyzed adequately with rhetorical relations, perhaps it can be explained in terms of the domain	0	Houses, chips, and families are strongly structured	0	0	0
E91-1015	J86-3001	1991	NorthHolland	0	Gross, BJ and CL <REF>Sidner 1986</REF> Attention, Intentions, and the structure of discourse s  Computational Linguistics, Vol	0	12, No 3, <REF>JulySeptember, 1986</REF>, pp	0	175-204	0	0	0
E91-1015	J86-3001	1991	The partners in this project are CAP GEMINI INNOVATION, CNET, CSELT, DAIMLER-BENZ, ERLANGEN University, INFOVOXj IRISA, LOGICA, PO- LITECHNICO DI TORINOj SARIN, SIEMENS, SUR-, REY University ented dialogues planning techniques have received a fair amount of attention <REF>Allen et al, 1982</REF>; <REF>Litman  Allen, 1984</REF>	0	In the latter approach there is no means to describe and deal with pure discursive phenomena meta-communication such as oral misunderstanding, initiative keeping, initiative giving etc, Whilst in the first approaches there is no attempt to develop a full dialogue system, except in Groszs and Sidners 1986 model that unfortunately does not cover all oral dialogue phenomena <REF>Bilange et al, 1990b</REF>	0	In oral conversation, meta-communication represents a large proportion of all possible phenomena and is not simple to deal with, especially if we strive to obtain natural dialogues	0	Therefore, we developed a computational model able to have clear views on happenings at the task level and at the level of the communication itself	0	0	0
E91-1015	J86-3001	1991	In the domain of travel planning, transactions could be : book a one-way, a return, etc The transaction level is then tied to the plan/sub-plan paradigm	0	A transaction can be viewed as a discourse segment Grosz  Sidner 1986	0	Ezchange level: transactions are achieved through exchanges which may be considered 84Dialogue excerpt of example in section 4 2 when would you like to leave 7 U2 next thursday Sa next tuesday the 30th of November ; and at what time 7 Us no, thursday december the 2nd towards the end of the afternoon St ok december the 2nd around six  initiativesystem, openrequest, getparanteter depdate reactionuser, answer, depdate : 1 El  initiative sstem, echo, 1 evaluation : E2  reactionuser, correct, I, 2 Tl L evaluationsystem, echo, 2 initiativesystem, openrequest, getparameterdeptime Ea reactionuser, answer, deptime : 3 ealuationsste,,, echo,  El : exchangeOwner: system, Intention: getdepdate, Attention: departure, date E2 exchangeOwner: system, Intention: clarifyvaluedepdate, Attention: departure, date Ea exchangeOwner: system, Intention: getdeptime, Attention: departure, time Tl  transactionIntention:problemdescription, Attention:departure, arrival, city, date, time, flight Figure 2	0	Dialogue history representation as negotiations	0	0	0
C08-1129	J86-3001	2008	Two types of cues have been identified for signaling topic shifts	0	The first type is discourse markers <REF>Moser and Moore, 1995</REF>; <REF>Schiffrin, 1987</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Passonneau and Litman, 1997</REF>; <REF>Bangerter and Clark, 2003</REF>	0	Discourse markers can be used to signal the start of a new discourse segment and its relation to other discourse segments	0	For example, now might signal moving on to the next topic, while well might signal 1026 a negative or unexpected response	0	0	0
W00-1001	J86-3001	2000	In this scheme, dialogue acts, the elements of the exchange structure, are classified into the tags shown in Figure 7	0	6 Dialogue Structure and Constraints on Multiple Exchanges 61 Dialogue Segment In the previous discourse model<TREF>Grosz and Sidner, 1986</TREF>, a discourse segment has a beginning and an ending utterances and may have smaller discourse segments in it	0	It is not an easy task to identify such segments with the nesting structure for spoken dialogues, because the structure of a dialogue is often very complicated due to the interaction of two speakers	0	In a preliminary experiment of coding segments in spoken dialogues, there were a lot of disagreements on the granularity or the relation of the segments and on identifying ending utterances of the segment	0	0	0
C90-2069	J86-3001	1990	First, we are developing psychological experiments to test whether the regularities on which the algorithm is based influence the readers recognition of subjective sentences and identification of subjective characters	0	Second, we are extending the algorithm to make connections with work on focus of attention and discomse structure such as <TREF>Grosz  Sidner 1986</TREF>; in particular, we are investigating how resolving anaphora and tracking the current point of view are related <REF>Stark 1987</REF>, <REF>Hewitt 1988</REF>	0	An important direction for future research is reasoning about the plausibility of a suggested interpretation, that is, whether it is plausible that the con tent of a subjective sentence is a particular characters thought or perception	0	We lmve presented part of an algorithm for identifying subjective characters that is based on regularities in the ways that texts initiate, resume, and continue a characters point of view	0	0	0
C08-1123	J86-3001	2008	We show that our automatically acquired cues are general enough to serve as a cross-domain classification mechanism	0	A number of researchers <REF>Hirschberg and Litman, 1993</REF>; <TREF>Grosz and Sidner, 1986</TREF> speak of cue or key phrases in utterances that can serve as useful indicators of discourse structure	0	We have previously investigated the use of such cue phrases to predict dialogue acts or DAs functional tags which represent the communicative intentions behind each user utterance <REF>Webb et al, 2005a</REF>	0	We developed an approach, in common with the work of Samuel et al	0	0	0
J97-1005	J86-3001	1997	Site before after pause duration cue1 wordl cue2 word2 corer infer globaLpro cue-prosody 224,231  t 055 t and f 231,232 f 0 t and f 232,233 t 0 t and f 233,234  f 0 f NA f Figure 7 Example feature coding of potential boundary sites	0	NA   t NA   f NA NA NA NA t NA   f studies on data from corpora <REF>Passonneau 1993</REF> or published excerpts <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	Unlike the cue and pause features, the NP features were thus not directly based on simplifications of existing results	0	Cue-prosody, which encodes a combination of prosodic and cue word features, was motivated by an analysis of errors on our training data, as described in Section 431	0	0	0
J97-1005	J86-3001	1997	We conclude each review by summarizing the differences between our study and previous work	0	21 Characterizing the Notion of a Segment A number of alternative proposals have been presented, which relate segments to intentions <TREF>Grosz and Sidner 1986</TREF>, Rhetorical Structure Theory RST relations <REF>Mann and Thompson 1988</REF> or other semantic relations <REF>Polanyi 1988</REF>; <REF>Hobbs 1979</REF>	0	The linguistic structure of Grosz and Sidners 1986 discourse model consists of multiutterance segments and structural relations among them, yielding a discourse tree structure	0	The hierarchical relations of their linguistic structure are isomorphic with the two other levels of their model, intentional structure and attentional state	0	0	0
J97-1005	J86-3001	1997	Finally, we quantify our results using a significance 106 Passonneau and Litman Discourse Segmentation test, a reliability measure, and, for purposes of comparison with other work, percent agreement	0	22 Correlation of Segmentation with Utterance Features The segmental structure of discourse has been claimed to constrain and be constrained by disparate phenomena, eg, cue phrases <REF>Hirschberg and Litman 1993</REF>; <TREF><TREF>Grosz and Sidner 1986</TREF></TREF></TREF>; <REF>Reichman 1985</REF>; <REF>Cohen 1984</REF>, plans and intentions <REF>Carberry 1990</REF>; <REF>Litman and Allen 1990</REF>; <TREF><TREF>Grosz and Sidner 1986</TREF></TREF></TREF>, prosody <REF>Hirschberg and Pierrehumbert 1986</REF>; <REF>Butterworth 1980</REF>, nominal reference <REF>Webber 1991</REF>; <TREF><TREF>Grosz and Sidner 1986</TREF></TREF></TREF>; <REF>Linde 1979</REF>, and tense <REF>Webber 1988</REF>; <REF>Hwang and Schubert 1992</REF>; <REF>Song and Cohen 1991</REF>	0	However, just as with the early proposals regarding segmentation, many of these proposals are based on fairly informal studies	0	It is only recently that attempts have been made to quantitatively evaluate how utterance features correlate with independently justified segmentations	0	0	0
J97-1005	J86-3001	1997	However, in <REF>Whittaker and Stenton 1988</REF>, a higher level of discourse structure based on topic shifts was agreed upon by at least 4 of 5 judges for 46 of the 56 control shifts	0	In sum, relatively few quantitative empirical studies have been made of how to annotate discourse corpora with features of discourse structure, and those recent ones that exist use various models such as the Grosz and Sidner model 1986, an informal notion of topic <REF>Hearst 1994</REF>; <REF>Flammia and Zue 1995</REF>, transactions <REF>Isard and Carletta 1995</REF>, Relational Discourse Analysis <REF>Moser and Moore 1995</REF>, or control <REF>Whittaker and Stenton 1988</REF>; <REF>Walker and Whittaker 1990</REF>	0	The modalities of the corpora investigated include dialogic or monologic, written, spontaneous or read, and the genres also vary	0	Quantitative evaluations of subjects annotations using notions of agreement, interrater reliability, and/or significance show that good results can be difficult to achieve	0	0	0
J97-1005	J86-3001	1997	<REF>Polanyi 1988</REF> distinguishes among four types of Discourse Constituent Units DCUs based on different types of structural relations eg , sequence	0	As in Grosz and Sidners 1986 model, <REF>Polanyi 1988</REF> proposes that DCUs analogous to segments are structured as a tree, and in both models, the tree structure of discourse constrains how the discourse evolves, and how referring expressions are processed	0	Recent work <REF>Moore and Paris 1993</REF>; <REF>Moore and Pollack 1992</REF> has argued that to account for explanation dialogues, it is necessary to independently model both RST relations and intentions	0	Researchers have begun to investigate the ability of humans to agree with one another on segmentation, and to propose methodologies for quantifying their findings	0	0	0
J97-1005	J86-3001	1997	What we also discuss here, which has not been presented in previous work, is a preliminary evaluation of the reliability of our method where we give a conservative lower bound suggesting that the method is reliable	0	108 Passonneau and Litman Discourse Segmentation 31 Methodology: Empirically Derived Segmentation The claim has been made that different people investigators or subjects are likely to assign similar segment boundaries or segment relations to a discourse <TREF>Grosz and Sidner 1986</TREF>; <REF>Reichman 1985</REF>; <REF>Mann and Thompson 1988</REF>, but it has also been observed that discourse structure can be ambiguous <REF>Pierrehumbert and Hirschberg 1987</REF>	0	Studies asking subjects to assign topical units to sample discourses have shown that the resulting segments vary widely in both size and location <REF>Rotondo 1984</REF>	0	Yet until recently, there has been little attempt to quantify the degree of variability among subjects in performing such a task	0	0	0
J97-1005	J86-3001	1997	Our corpus consists of transcripts of spontaneous spoken monologues, produced by 20 different speakers	0	We use an informal notion of communicative intention as the segmentation criterion, motivated by <TREF>Grosz and Sidner 1986</TREF> and <REF>Polanyi 1988</REF>, who argue that defining a segment as having a coherent goal is more general than establishing a repertoire of specific types of segment goals	0	We do not, however, ask coders to identify hierarchical relations among segments	0	The hypothesis that discourse has a tree structure has frequently been questioned <REF>Dale 1992</REF>; <REF>Moore and Pollack 1992</REF>; <REF>Hearst 1994</REF>; <REF>Walker 1995</REF>, and the magnitude of our segmentation task precludes asking subjects to specify hierarchical relations	0	0	0
J97-1005	J86-3001	1997	21 Characterizing the Notion of a Segment A number of alternative proposals have been presented, which relate segments to intentions <TREF>Grosz and Sidner 1986</TREF>, Rhetorical Structure Theory RST relations <REF>Mann and Thompson 1988</REF> or other semantic relations <REF>Polanyi 1988</REF>; <REF>Hobbs 1979</REF>	0	The linguistic structure of Grosz and Sidners 1986 discourse model consists of multiutterance segments and structural relations among them, yielding a discourse tree structure	0	The hierarchical relations of their linguistic structure are isomorphic with the two other levels of their model, intentional structure and attentional state	0	Rhetorical relations do not play a role in their model	0	0	0
J97-1005	J86-3001	1997	5	0	Conclusion and Future Directions Our initial hypotheses regarding discourse segmentation were that multiutterance segment units reflect discourse coherence, and that while the semantic dimensions of this coherence may vary, it arises partly from consistency in the speakers communicative goals <TREF>Grosz and Sidner 1986</TREF>; <REF>Polanyi 1988</REF>	0	The results from the first part of our study Section 3 support these hypotheses	0	On a relatively unconstrained linear segmentation task, the number of times different naive subjects identify the same segment boundaries in a given narrative transcript is extremely significant	0	0	0
J97-1005	J86-3001	1997	The types of discourse units being coded and the relations among them vary	0	Several studies have used trained coders to locally and globally structure spontaneous or read speech using the model of <TREF>Grosz and Sidner 1986</TREF>, including <REF>Grosz and Hirschberg 1992</REF>; <REF>Nakatani, Hirschberg, and Grosz 1995</REF>; <REF>Stifleman 1995</REF>; <REF>Hirschberg and Nakatani 1996</REF>	0	<REF>In Grosz and Hirschberg 1992</REF>, percent agreement see Section 32 among 7 coders on 3 texts under two conditions--text plus speech or text alone--is reported at levels ranging from 743 to 951	0	<REF>In Hirschberg and Nakatani 1996</REF>, average reliability measured using the kappa coefficient discussed in Carletta 1996 of segmentinitial labels among 3 coders on 9 monologues produced by the same speaker, labeled using text and speech, is8 or above for both read and spontaneous speech; values of at least 8 are typically viewed as representing high reliability see Section 32	0	0	0
J97-1005	J86-3001	1997	No statistical analysis of the significance of the differences was presented, however	0	By statistically analyzing distributions of discourse anaphora with respect to control-based discourse segments, <REF>Walker and Whittaker 1990</REF> showed that shifts of attentional state <TREF>Grosz and Sidner 1986</TREF> occurred when shifts in control were accepted by all dialogue participants	0	In sum, relatively few studies correlate linguistic devices with empirically justified discourse segmentations	0	Quantitative evaluations of the correlations include the use of statistical measures and information retrieval metrics	0	0	0
E93-1031	J86-3001	1993	SDRT starts with traditional VltSs cf	0	<REF>Kamp 1981</REF>, but goes on to assume with <TREF>Grosz and Sidner 1986</TREF> that candidate discourses possess hierarchical structure, with units linked by discourse relations modelled after those proposed by <REF>Hobbs 1985</REF> cf	0	also <REF>Mann and Thompson 1987</REF>, <REF>Scha and Polanyi 1988</REF>	0	The resultant representations are called segmented DRSs or SDPSs	0	0	0
P98-2155	J86-3001	1998	This paper presents an empirically motivated theory of the discourse focusing function of accent	0	The theory describes for the first time the interacting contributions to accent prediction made by factors related to the local and global attentional status of discourse referents in a discourse model <TREF>Grosz and Sidner, 1986</TREF>	0	The ability of the focusing features to predict accent for a blind test corpus is examined using machine learning	0	Because attentional status is a property of referring expressions, a novel approach to accent prediction is proposed to allow for the integration of word-based and constituent-based linguistic features in the models to be learned	0	0	0
P98-2155	J86-3001	1998	<REF>Terken, 1984</REF>; <REF>Hirschberg, 1993</REF>	0	We propose a new theory of the relationship between accent and attention, based on an enriched taxonomy of given/new information status provided by both the LOCAL centering and GLOBAL focus stack model attentional state models in Grosz and Sidners discourse modeling theory 1986	0	939 Analysis of a 20-minute spontaneous story-telling monologue t identified separate but interacting contributions of grammatical function, form of referring expression and accentuation 2 in conveying the attentional status of a discourse referent	0	These interactions can be formally expressed in the framework of attentional modeling by the following principles of interpretation:  The LEXICAL FORM OF A REFERRING EXPRESSION indicates the level of attentional processing, ie, pronouns involve local focusing while full lexical forms involve global focusing <REF>Grosz et al , 1995</REF>	0	0	0
C02-1035	J86-3001	2002	Furthermore, MIND also identifies how an input relates to the overall conversation discourse through discourse understanding	0	In particular, MIND uses a representation called conversation segment to group together inputs that contribute to a same goal or sub-goal <TREF>Grosz and Sidner, 1986</TREF>	0	The result of discourse understanding is an evolving conversation history that reflects the overall progress of a conversation	0	Figure 2 shows a conversation fragment between a user and MIND	0	0	0
C04-1019	J86-3001	2004	Some research groups confirm the suitability of Java for the development of interactive, agentbased systems  for example COLLAGEN <REF>Rich et al 2001</REF>	0	Indeed, the COLLAGEN architecture, like that of the Queens Communicator, manages discourse using a focus stack, a classical idea in the theory of discourse structure <TREF>Grosz and Sidner, 1986</TREF>	0	For dialogues that are not primarily transactionbased or frame-based, and where the system must establish the users broader objectives before offering advice or presenting options, a discourse management strategy based on problem-solving PS objects objectives, recipes, actions and resources is appropriate <REF>Blaylock et al , 2003</REF>	0	We are currently investigating means of using PS objects to orient a dialogue, before using expertise like that currently encapsulated in our domain agents to complete those frame-filling tasks that are needed to support the users objectives	0	0	0
J98-2001	J86-3001	1998	The architecture of our own classifier see below is also consistent with Frauruds hypothesis that these methods are not just used when no suitable antecedent can be found, but more extensive investigations will be needed before we can conclude that this architecture significantly outperforms other ones	0	The presence of such a large number of discourse-new definite descriptions is also problematic for the idea that definite descriptions are interpreted with respect to the global focus <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	A significant percentage of the larger situation definite descriptions encountered in our corpus cannot be said to be in the globai focus in any significant sense: as we observed above, in many of these cases the writer seems to rely on the readers capability to add a new object such as the Illinois Commerce Commission to her or his model of the world, rather than expecting that object to be already present	0	52 A SemiAutomatic Classifier As already mentioned, we are in the course of implementing a system capable of performing the classification task semiautomatically <REF>Vieira 1998</REF>	0	0	0
P95-1040	J86-3001	1995	Both attentional Cf and propositional mutual beliefs structures are updated throughout	0	However, unlike attentional structures which are ephemeral in various time scales and empty at the end of the discourse <TREF>Grosz and Sidner, 1986</TREF>, mutual beliefs persist throughout the conversation, preserving at the end the semantic and pragmatic outcome of the discourse	0	In addition, while propositions can be excluded from the mutual beliefs because they fail to meet some inclusion criterion, no lexical denotation is excluded from Cf regardless of its propositional value	0	This is because the salience most relevant to the attentional state is the proximity of a discourse entity to the head of Cf -the closer it is, the more it is centered and therefore, attentionally salient	0	0	0
P95-1040	J86-3001	1995	This distinction underlies my proposals about the attentional consequences of pitch accents when applied to pronominals, in particular, that while most pitch accents may weaken or reinforce a cospecifiers status as the center of attention, a contrastively stressed pronominal may force a shift, even when contraindicated by textual features	0	To predict and track the center of attention in discourse, theories of centering <REF>Grosz et al , 1983</REF>; <REF>Brennan et al , 1987</REF>; <REF>Grosz et al , 1989</REF> and immediate focus <REF>Sidner, 1986</REF> rely on syntactic and grammatical features of the text such as pronominalization and surface sentence position	0	This may be sufficient for written discourse	0	For oral discourse, however, we must also consider the way intonation affects the interpretation of a sentence, especially the cases in which it alters the predictions of centering theories	0	0	0
C98-1087	J86-3001	1998	In this paper we look the phenomenon of long-distance pronominalisation in some detail, examining data flom different domains, and consider 550 its implications for GSs theory	0	2 Theories of focus Space unfortunately prevents a full discussion of Groszs 1977, Sidners 1979, and GSs 1986 theories of focus and the attentional state in this abstract	0	The crucial aspects of these theories, for the purpose of the discussion below, are as follows	0	First of all, GS propose a distinction between two components of the attentional state: the GLOBAL FOCUS, structured as a stack of focus spaces and accessed to interpret definite descriptions; and the LOCAL FOCUS, consisting ot the information preferentially used to interpret pronouns	0	0	0
C98-1087	J86-3001	1998	All 7 long-distance pronouns in the ILEX dialogues we have studied refer to discourse entities introduced in background text in this way	0	Unlike Sidners theory of focus Sidnet; 1979, tile theory of the attentional state in <TREF>Grosz and Sidner, 1986</TREF> henceforth: GS does not include explicit provision for long-distance pronominalisations, although some of the necessary tools am potentially already there, as we will see	0	The component of the theory that deals with pronominal reference, centering theory <REF>Grosz et al, 1995</REF>, only accounts for cases in which the antecedent of a pronoun is introduced by the previous sentence; cases such as 1 have to be handled by different mechanisms	0	In this paper we look the phenomenon of long-distance pronominalisation in some detail, examining data flom different domains, and consider 550 its implications for GSs theory	0	0	0
J88-3010	J86-3001	1988	OK--now you can slip in the pliers 6	0	And the whole pole comes off Plan of Speaker: The top level goal is get pole off, which succeeds if the following hierarchy of subgoals succeeds: get po off  loosen screw with wrench - slip in pliers identi/scr/ew  identify wrench know chars, of screw know chars, of wrench Intentional structure of discourse as in <TREF>Grosz and Sidner 1986</TREF>: Primary Intentions: I1: intend H get pole off; I2: intend H loosen screw with wrench I3: intend H identify screw Computational Linguistics, Volume 14, Number 3, <REF>September 1988</REF> 89 Robin Cohen On the Relationship Between User Models and Discourse Models Segmentation Structure:    1 2 ds3 3 4 ds2 5 6 dsl There are three segments: ds3 with 13, ds2 with 12, and dsl with I1, where 12 DOM 13 and I1 DOM 12 ie 13 contributes to the satisfaction of 12, etc	0	There are two main sources of difference between the plan of the speaker and the intentional structure of discourse, illustrated by the above example: i there may be no direct match from the utterances to the units subgoals of the plan; here, there is no utterance corresponding to identify wrench, on top of utterance 4, which serves to let the hearer know characteristics of the wrench; ii the intentions recorded for the intentional structure may be at a higher level of detail	0	The examples provided in <TREF>Grosz and Sidner 1986</TREF>, for instance, only record those attached to segments of more than one utterance	0	0	0
J88-3010	J86-3001	1988	The discourse model must thus contain the following key elements: an indication of the structure of the discourse and an organization of the objects of the real world mentioned in the discourse to help anaphora resolution, for example	0	As soon as this kind of history of objects is included covered in the model of <TREF>Grosz and Sidner 1986</TREF> by tracking attentional state and the objects currently in focus, there are elements that are not specifically attached to the user himself	0	The structure of the discourse is essentially provided in two different ways	0	Which of the actual utterances of the discourse group together into logical segments is covered by the linguistic structure of <TREF>Grosz and Sidner 1986</TREF>	0	0	0
J88-3010	J86-3001	1988	Intentional structure should indicate the intentional relations between, again, actual utterances	0	For instance, it is important to determine the cases where the goal underlying an utterance contributes to the satisfaction of the goal underlying another utterance--eg , getting the hearer to believe some proposition p contributes to the satisfaction of getting the hearer to believe some proposition q determined as dominance relations in <TREF>Grosz and Sidner 1986</TREF>	0	In this sense, my interpretation of the derivation of intentional structure agrees well with Wahlsters appeal for an incremental derivation of the discourse model	0	I believe that the intentional structure is related to, but not identical with, the plan of the speaker underlying discourse	0	0	0
J88-3010	J86-3001	1988	I feel that the definition of discourse model here is too narrow--there is more to a model of discourse than an indication of the underlying entities objects, events	0	Schuster seems to suggest that some of the structuring provided in <TREF>Grosz and Sidner 1986</TREF> is there only to highlight the entities, In my view, the actual utterances themselves are worth examining as participating in some structure	0	I also find Schusters definition for user model--the information a system has about the userAsomewhat problematic	0	I think that the user model must concentrate on dynamic information, that is, which has some potential for change	0	0	0
J88-3010	J86-3001	1988	There are two main sources of difference between the plan of the speaker and the intentional structure of discourse, illustrated by the above example: i there may be no direct match from the utterances to the units subgoals of the plan; here, there is no utterance corresponding to identify wrench, on top of utterance 4, which serves to let the hearer know characteristics of the wrench; ii the intentions recorded for the intentional structure may be at a higher level of detail	0	The examples provided in <TREF>Grosz and Sidner 1986</TREF>, for instance, only record those attached to segments of more than one utterance	0	There are, indeed, many issues regarding the relationship of plans and discourse structure; we will not elaborate further here	0	Our main point is that the two terms should be related, but distinct	0	0	0
J88-3010	J86-3001	1988	In this sense, I focus on the interpretation of a discourse from the point of view of one of the conversants	0	I essentially include in the discourse all the components covered by the model of <TREF>Grosz and Sidner 1986</TREF>	0	For the definition of the user model, I also ground the discussion in the point of view of one conversant	0	The model is thus an analysis of the other conversant subsequently referred to as the speaker	0	0	0
J88-3010	J86-3001	1988	The structure of the discourse is essentially provided in two different ways	0	Which of the actual utterances of the discourse group together into logical segments is covered by the linguistic structure of <TREF>Grosz and Sidner 1986</TREF>	0	Often clue words such as but anyway will indicate how to segment the utterances into logical segments, without concern for how individual utterances within that segment relate	0	In addition, there is an indication of the intentional structure	0	0	0
J88-3010	J86-3001	1988	In addition, there is an indication of the intentional structure	0	Here, I would reinterpret slightly the term as used in <TREF>Grosz and Sidner 1986</TREF> see <REF>Cohen 1986</REF>	0	Intentional structure should indicate the intentional relations between, again, actual utterances	0	For instance, it is important to determine the cases where the goal underlying an utterance contributes to the satisfaction of the goal underlying another utterance--eg , getting the hearer to believe some proposition p contributes to the satisfaction of getting the hearer to believe some proposition q determined as dominance relations in <TREF>Grosz and Sidner 1986</TREF>	0	0	0
W02-1702	J86-3001	2002	It is widely accepted that content selection plays a crucial role in text generation <REF>Reiter and Dale 2000</REF>	0	This process is normally seen as a goal-directed activity in which text segments are fit into the discourse structure of the text so as to convey a coherent communicative goal <TREF>Grosz and Sidner 1986</TREF>	0	Content planning techniques, such as textual schemas <REF>McKeown 1985</REF> or plan operators <REF>Moore and Paris 1993</REF>, have been successfully used as models of text generation	0	There are cases, though, in which these techniques may face some limitations, for example, when the structure of the discourse is difficult to anticipate <REF>Mellish et al 1998</REF>	0	0	0
P95-1018	J86-3001	1995	4 Conclusions We have introduced Relational Discourse Analysis, a coding scheme for the exhaustive analysis of text or single speaker discourse	0	RDA is a synthesis of ideas from two theories of discourse structure <TREF>Grosz and Sidner, 1986</TREF>; <REF>Mann and Thompson, 1988</REF>	0	It provides a system for analyzing discourse and formulating hypotheses about cue selection and placement	0	The corpus study results in rules for cue selection and placement that will then be exercised by our text generator	0	0	0
P95-1018	J86-3001	1995	There are three types of simpler functional elements: 1 units, which are descriptions of domain states and actions, 2 matrix elements, which express a mental attitude, a prescription or an evaluation by embedding another element, and 3 relation clusters, which are otherwise like segments except that they have no core:coatributor structure	0	This approach synthesizes ideas which were previously thought incompatible from two theories of discourse structure, the theory proposed by <TREF>Grosz and Sidner 1986</TREF> and Rhetorical Structure Theory RST proposed by <REF>Mann and Thompson 1988</REF>	0	The idea that the hierarchical segment structure of discourse originates with intentions of the speaker, and thus the defining feature of a segment is that there be a recognizable segment purpose, is due to Grosz and Sidner	0	The idea that discourse is hierarchically structured by palrwise relations in which one relatum the nucleus is more central to the speakers purpose is due to Mann and Thompson	0	0	0
P95-1018	J86-3001	1995	The study of cues must begin with descriptive work using intuition and observation to identify the factors affecting cue usage	0	Previous research <REF>Hobbs, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Schiffrin, 1987</REF>; <REF>Mann and Thompson, 1988</REF>; <REF>Elhadad and McKeown, 1990</REF> suggests that these factors include structural features of the discourse, intentional and informational relations in that structure, givenness of information in the discourse, and syntactic form of discourse constituents	0	In order to devise an algorithm for cue selection and placement, we must determine how cue usage is affected by combinations of these factors	0	The corpus study is intended to enable us to gather this information, and is therefore conducted directly in terms of the factors thought responsible for cue selection and placement	0	0	0
W99-0103	J86-3001	1999	Figure 6: Motivational example 2 In this paper, the ranking of the items in Cf also follows Figure 5	0	If the items have the same priority, the algorithm ranks them by the obliqueness of grammatical relation of the subcategorized functions of the main verb: that is, first the subject, object, and objects2, followed by other subcategorized fenons, and finally, adjuncts <TREF>Grosz and Sidner 1986</TREF>, Brennan et ul	0	1987	0	The centering algorithm is based on constraints and rules as well as Cbs and C	0	0	0
C92-2096	J86-3001	1992	The communicative goals associated with the leaves of the structure are then used to retrieve the content of each proposition fiom an underlying knowledge base	0	By making the intentional structure of a paragraph explicit, this work follows the discourse structure theory advanced in <TREF>Grosz  Sidner, 1986</TREF>	0	Note also that, since in RST with planning, the structure of paragraphs is dynamically derived, it is possible to view schemas as the compilation of RST configurations with some information abswacted out, as pointed out in <REF>Mann, 1987</REF>	0	We found that schemas and RST were not appropriate for planning and generating argumentative paragraphs because argument selection cannot be easily performed	0	0	0
W07-0301	J86-3001	2007	However, past work has been confined to slot-filling tasks and has not tackled the troubleshooting domain	0	Conversely, dialog systems for troubleshooting in the literature have not attempted to model uncertainty directly <TREF>Grosz and Sidner, 1986</TREF>; <REF>Lochbaum, 1998</REF>	0	The contribution of this paper is to show how to model a troubleshooting spoken dialog system as a partially observable Markov decision process POMDP	0	We argue that past work in the general troubleshooting literature represents simplifications or special cases of a POMDP, then we show how a troubleshooting POMDP can be combined with a dialog system POMDP to create a unified framework that admits global optimization	0	0	0
W04-0214	J86-3001	2004	While this method may be the best way to go ultimately, empirical work has shown that it has been difficult to put into practice	0	There are many different schemes to choose from, for example Rhetorical Structure Theory <REF>Mann and Thompson, 1986</REF> or the stack model <TREF>Grosz and Sidner, 1986</TREF> and manually annotating with these schemes has variable reliability	0	Finally, annotating these schemes requires real-world knowledge, reasoning, and knowledge of salience and semantics, all of which make automatic segmentation difficult	0	However, past studies such as <REF>Tetreault and Allen 2003</REF> show that for reference resolution, a highlystructured tree may be too constraining, so a shallower approach may be acceptable for studying the effect of discourse segmentation on resolution	0	0	0
W04-0214	J86-3001	2004	23 Discourse Segmentation Another research area that can benefit from a discourse-annotated corpus is discourse structure	0	There has been plenty of theoretical work such as <TREF>Grosz and Sidner, 1986</TREF>, <REF>Moser and Moore, 1996</REF> which shows that just as sentences can be decomposed into smaller constituents, a discourse can be decomposed into smaller units called discourse segments	0	Though there are many different ways to segment discourse, the common themes are that some sequences are more closely related than others discourse segments and that a discourse can be organized as a tree, with the leaves being the individual utterances and the interior nodes being discourse segments	0	The embeddedness of a segment effects which previous segments, and thus their entities, are accessible	0	0	0
W97-0601	J86-3001	1997	As a convention of this type of tagging, utterances that contribute to the success of the whole dialogue, such as greetings, are tagged with all the attributes	0	Thus the goal of the tagging is to show how the structure of the dialogue reflects the structure of the task <REF>Carbelrry, 1989</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Litman and Allen, 1990</REF>	0	Tagging by AVM attributes is required to calculate costs over subdialogues, since for any subdialogue, task attributes define the subdialogue	0	For example, the subdialogue about the attribute arrival-city SA consists of utterances A6 and U6, its cost Cl SA is 2	0	0	0
P01-1014	J86-3001	2001	This strongly suggests that there are critical differences between thesis statements and summary sentences, at least in first-draft essay writing	0	It is possible that thesis statements reflect an intentional facet <TREF>Grosz and Sidner, 1986</TREF> of language, while summary sentences reflect a semantic one <REF>Martin, 1992</REF>	0	More detailed experiments need to be carried out though before proper conclusions can be derived	0	Table 1a: Agreement between human judges on thesis and summary sentence identification	0	0	0
W04-0712	J86-3001	2004	By a group, we understand a collection of information that is orthogonal to other information	0	By 4The reader may recognize a certain similarity of the considerations in this section with the approach of <TREF>Grosz and Sidner, 1986</TREF>	0	An example: We restrict ourself to some remarks: Grosz  Sidner focus on the segmentation of discourse along the hierarchical structure of a task, while we focus on problems concerning repetition this section and variation of tasks next section	0	Grosz  Sidner are mainly concerned with anaphoric reference while we are concerned with ellipsis and related implicit inheritance of information	0	0	0
W99-0304	J86-3001	1999	One reason for this is that our experiments were done with untrained subjects, which means that there can be more room for improvements on the reliability	0	23 m m m  m m  m m m m m m  m m mm m m h Data Map task group scheduling route direction telephone shopping appointment scheduling Total II  l umber of utterance II P A PE Table 1: Evaluation of utterance unit tagging scheme first version second version agree 3 agree 2 disagree agree 3 60 51 1 41 38 8 0 3 35 86 24 1 26 28 6 30 31 87 29 245 119  ii 218 375 agree 2 disagree 54 18 12 4 6 9 20 4 21 11 i13 46 377 076 068 044 012 057 064 3 Discourse Structure 31 First annotation scheme Grosz and Sidner proposed a model of discourse structure, in which discourse structure is composed of the linguistic structure, the intentional structure, and the attentional state <TREF>Grosz and Sidner, 1986</TREF>	0	We built the first annotation scheme of discourse structure in dialogue based on this model	0	The written instruction of the scheme describes as follows	0	0	0
W97-0621	J86-3001	1997	11 Subdialogue behaviors Traditional analyses of human-human dialogue decompose sequences into segments which are locally coherent and which individually address their own subgoals in the overall dialogue structure	0	<REF>Hobbs, 1979</REF>; <REF>Reichman, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Lochbaurn, 1991</REF>	0	Such a segment is opened for a specific purpose, may involve a series of interactions between participants, and may be closed having successfuUy achieved the target subgoal	0	Such a segment may be interrupted for the purpose of achieving a new, locally discovered, subgoal or for approaching a different goal	0	0	0
H92-1089	J86-3001	1992	Third, not every intonational feature which is varied to convey structural information is perceptually salient	0	We present results of a study of the relationship between intonational features including pitch range, timing, and amplitude and aspects of discourse structure defined in terms of Grosz and Sidners 1986 model of discourse	0	We compare structural labelings of AP news text with prosodic/acoustic features examined from recordings of the same text read by a professional newscaster	0	We find significant correlations between prosodic/acoustic characteristics and both local and global aspects of discourse structure identified by our labelers	0	0	0
J95-1003	J86-3001	1995	In Section 4, we go into the process of interpreting deictic and anaphoric expressions in some detail	0	Subsequently, in Section 5, we present some user interactions with EDWARD and we compare the results of EDWARDs referent resolution model with two other models including that of <TREF>Grosz and Sidner 1986</TREF>	0	2	0	Overview of EDWARD EDWARD is implemented in Allegro Common Lisp and runs on DECstations	0	0	0
J95-1003	J86-3001	1995	71 Computational Linguistics Volume 21, Number 1 5	0	Assessing the Quality of EDWARDs Referent Resolution Model To assess the quality of EDWARDs referent resolution model, we collected a series of referring expressions, which were processed by three different referent resolution models, namely that of EDWARD, as described above, a very simplistic model, and the sophisticated and often applied model proposed by <TREF>Grosz and Sidner 1986</TREF>	0	Since there are no benchmarks available to evaluate referent resolution models, we had subjects interact with EDWARD to compile a set of referring expressions	0	Usually, NL test sentences are made up by evaluators/designers themselves, but we think made-up test sentences may to some extent be unconsciously biased	0	0	0
J95-1003	J86-3001	1995	The application domain is military tactical air control	0	Like XTRA, CUBRICON uses two models to interpret deictic expressions: an attentional discourse focus space representation adapted from <TREF>Grosz and Sidner 1986</TREF> and a display model	0	<REF>Stock 1991</REF> describes ALFresco, a prototype built for the exploration of frescoes, using NL Italian and pictures	0	For referent resolution in ALFresco, topic spaces <REF>Grosz, 1978</REF> are combined with Hajiovs 1987 approach, in which entities are assumed to fade away slowly	0	0	0
J95-1003	J86-3001	1995	The proposed model for reference resolution elaborates on Alshawis 1987 notions of context factors and salience and integrates both linguistic and perceptual context effects	0	The model is contrasted with two alternative referent resolution models, namely, a simplistic one and the more sophisticated model proposed by <TREF>Grosz and Sidner 1986</TREF>	0	Based on empirical and analytical grounds, we conclude that the model we propose is preferable from a computational and engineering point of view	0	1	0	0	0
J95-1003	J86-3001	1995	First, EDWARDs Context Model and the Simplistic Model do not make any predictions about discourse intention	0	Discourse intentions play a primary role in explaining discourse structure, defining discourse coherence, and providing a coherent conceptualization of the term discourse <TREF>Grosz and Sidner 1986</TREF>	0	Discourse intentions can provide clues for the beginning and ending of dialogues and subdialogues	0	Referent resolution can make use of this structure to exclude referents to subdialogues that are ended	0	0	0
J95-1003	J86-3001	1995	To prevent uncontrolled growing of the stack, we had the system discard the object at the bottom of the stack as soon as the stack length exceeded a certain maximum	0	The second alternative referent resolution model is that of <TREF>Grosz and Sidner 1986</TREF>	0	Their model consists of two separate mechanisms, each resolving a specific type of referring expression	0	The first mechanism is called focusing	0	0	0
J95-2003	J86-3001	1995	In this section we describe the larger research context of this work and then briefly discuss the previous work that led to it	0	Centering fits within the theory of discourse structure developed by <TREF>Grosz and Sidner 1986</TREF>	0	Grosz and Sidner distinguish among three components of discourse structure: a linguistic structure, an intentional structure, and an attentional state	0	At the level of linguistic structure, discourses divide into constituent discourse segments; an embedding relationship may hold between two segments	0	0	0
J94-2003	J86-3001	1994	Centering has its computational foundations in the work of Grosz and Sidner <REF>Grosz 1977</REF>; <REF>Sidner 1979</REF>; <TREF>Grosz and Sidner 1986</TREF> and was further developed by Grosz, Joshi, and Weinstein 1983, unpublished and <REF>Joshi and Weinstein 1981</REF>	0	Centering is intended to reflect aspects of ATYENTIONAL STATE in a tripartite view of discourse structure that also includes INTENTIONAL STRUCTURE and LINGUISTIC STRUCTURE <TREF>Grosz and Sidner 1986</TREF>	0	In Grosz and Sidners theory of discourse structure, discourses can be segmented based on intentional structure, and a discourse segment exhibits both local and global coherence	0	Global coherence depends on how each segment relates to the overall purpose of the discourse; local coherence depends on aspects such as the syntactic structure of the utterances in that segment, the choice of referring expressions, and the use of ellipses	0	0	0
J94-2003	J86-3001	1994	Centering Theory Within a theory of discourse, CENTERING is a computational model of the process by which conversants coordinate attention in discourse Grosz, Joshi, and Weinstein unpublished	0	Centering has its computational foundations in the work of Grosz and Sidner <REF>Grosz 1977</REF>; <REF>Sidner 1979</REF>; <TREF>Grosz and Sidner 1986</TREF> and was further developed by Grosz, Joshi, and Weinstein 1983, unpublished and <REF>Joshi and Weinstein 1981</REF>	0	Centering is intended to reflect aspects of ATYENTIONAL STATE in a tripartite view of discourse structure that also includes INTENTIONAL STRUCTURE and LINGUISTIC STRUCTURE <TREF>Grosz and Sidner 1986</TREF>	0	In Grosz and Sidners theory of discourse structure, discourses can be segmented based on intentional structure, and a discourse segment exhibits both local and global coherence	0	0	0
J96-3006	J86-3001	1996	1	0	Within the computational discourse community, there is a long-standing debate between proponents of theories based on domain-independent rhetorical relations most notably Rhetorical Structure <REF>Theory, Mann and Thompson 1988</REF>, henceforth RST; see also <REF>Hobbs 1985</REF> and those who subscribe to theories based on intentionality most notably that of <TREF>Grosz and Sidner 1986</TREF>, henceforth GS	0	While some researchers have tried to integrate the two approaches <REF>Moore and Paris 1993</REF>; <REF>Asher and Lascarides 1994</REF>; <REF>Hobbs 1993</REF>, the two are usually viewed as competing theories	0	Here we argue that GS and RST are essentially similar in what they say about how speakers intentions determine a structure of their discourse	0	0	0
J96-3006	J86-3001	1996	Toward a Synthesis of Two Accounts of Discourse Structure Megan Moser University of Pittsburgh Johanna D Moore t University of Pittsburgh Among researchers interested in computational models of discourse, there has been a long-standing debate between proponents of approaches based on domain-independent rhetorical relations, and those who subscribe to approaches based on intentionality	0	In this paper, we argue that the main theories representing these two approaches, RST <REF>Mann and Thompson 1988</REF> and GS <TREF>Grosz and Sidner 1986</TREF>, make similar claims about how speakers intentions determine a structure of their discourse	0	The similarity occurs because the nucleus-satellite relation among text spans in RST corresponds to the dominance relation among intentions in GS Building on this similarity, we sketch a partial mapping between the two theories to show that the main points of the two theories are equivalent	0	Furthermore, the additional claims found in only RST or only GS are largely consistent	0	0	0
J96-3006	J86-3001	1996	E-mail: jmoorecspittedu  1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 3 Prior research has established that recognition of intentional structure, and therefore appropriate generation of cues to such structure, is crucial for many discourseprocessing tasks	0	<TREF>Grosz and Sidner 1986</TREF> argued that intentional structure is crucial for anaphora resolution and plan recognition	0	Hirschberg et al	0	1987 show that intentional structure plays a role in intonation	0	0	0
J96-3006	J86-3001	1996	Intentions encode what the speaker was trying to accomplish with a given portion of discourse	0	The relations between intentions indicate whether one intention contributes to the satisfaction of another dominance or whether one intention must be satisfied before another satisfaction-precedence <TREF>Grosz and Sidner 1986</TREF>	0	In contrast, informational structure is concerned with domain relations among the things being talked about	0	<REF>Moore and Pollack 1992</REF> argue that both intentional and informational analyses are needed simultaneously	0	0	0
J01-4003	J86-3001	2001	Accuracy increased to 917 with the inclusion of selectional constraints	0	22 Centering Theory and BFPs Algorithm Centering theory is part of a larger theory of discourse structure developed by <TREF>Grosz and Sidner 1986</TREF>	0	These researchers assert that discourse structure has three compo508 Tetreault Centering and Pronoun Resolution nents: 1 a linguistic structure, which is the structure of the sequence of utterances; 2 the intentional structure, which is a structure of discourse-relevant purposes; and 3 the attentional state, which is the state of focus	0	The attentional state models the discourse participants focus of attention determined by the other two structures at any one time	0	0	0
P98-2135	J86-3001	1998	2	0	Broadcast News Analysis Human communication is characterized by distinct discourse structure <TREF>Grosz and Sidner 1986</TREF> which is used for a variety of purposes including managing interaction between participants, mitigating limited attention, and signaling topic shifts	0	In processing genre such as technical or journalistic texts, programs can take advantage of explicit discourse cues eg , the first, the most important to perform tasks such as summarization <REF>Paice 1981</REF>	0	Our initial inability to segment topics in closed caption news text using thesaurus based subject assessments <REF>Liddy and Myaeng 1992</REF> motivated an investigation of explicit turn taking signals eg , anchor to reporter handoff	0	0	0
J88-2006	J86-3001	1988	Getting a listener to resume a DS via the stack mechanism is taken to require less effort on a speakers part than returning to elaborate an argument or subtask description later on	0	The significance of <REF>Sidner 1983</REF> and <TREF>Grosz and Sidner 1986</TREF> for the current enterprise is that: Computational Linguistics, Volume 14, Number 2, <REF>June 1988</REF> 63 Bonnie Lynn Webber Tense as Discourse Anaphor  Sidner essentially shows how DF can move gradually among the discourse entities that make up a focus space, as the listener is processing its associated discourse segment;  Grosz and Sidner show how DF can make a radical jump to a different possibly newly evoked discourse entity as the listener moves to process the next discourse segment	0	o I reinterpret this in the current framework in terms of the anaphoric function aNPb,Ea	0	Within a discourse segment, the entity that is the DF is the most likely E a Over the discourse segment, other discourse entities in the segments focus space may in turn become DF	0	0	0
J88-2006	J86-3001	1988	9 <REF>In Sidner 1983</REF> DFs always are stacked for possible resumption later	0	<REF>In Grosz and Sidner 1986</REF> it is an entire focus space FS <REF>Grosz 1977</REF> that gets stacked ie , the collection of entities L is attending to by virtue of the current discourse segment DS but only when the 9purpose of the current DS is taken to dominate that of the one upcoming	0	Dominance relations are also specified further according to the type of discourse	0	In Grosz and Sidner, they are defined for task-related dialogues and arguments	0	0	0
E06-3001	J86-3001	2006	Overview of the data used	0	5 Preliminary Model Overviews The models evaluated in this paper are based on Centering Theory <REF>Grosz et al , 1995</REF>; <TREF>Grosz  Sidner, 1986</TREF> and the algorithms devised by Brennan and colleagues 1987 and adapted by <REF>Tetreault 2001</REF>	0	We examine a language-only model based on Tetreaults Left-Right Centering LRC model, a visual-only model that uses a measure of visual salience to rank the objects in the visual field as possible referential anchors, and an integrated model that balances the visual information along with the linguistic information to generate a ranked list of possible anchors	0	51 The Language-Only Model We chose the LRC algorithm <REF>Tetreault, 2001</REF> to serve as the basis for our language-only model	0	0	0
E87-1042	J86-3001	1987	E87-1042:140	1	TEMPORAL REASONING IN NATURAL LANGUAGE UNDERSTANDING: THE TEMPORAL STRUCTURE OF THE NARRATIVE Alexander Nakhimovsky Department of Computer Science Colgate University Hamilton, NY 13346 USA CSNet: sashacolgate Abstract This paper proposes a new framework for discourse analysis, in the spirit of <TREF>Grosz and Sidner 1986</TREF>, Webber 1987a,b but differentiated with respect to the type or genre of discourse	0	It is argued that different genres call for different representations and processing strategies; particularly important is the distinction between subjective, pefformative discourse and objective discourse, of which narrative is a primary example	1	This paper concentrates on narratives and introduces the notions of temporal focus proposed also in <REF>Webber 1987b</REF> and narrative move	1	1	3
J95-3001	J86-3001	1995	For example, the expectation that the user is going to report the setting of a switch would be represented as obsphysstatepropswitchl,state, PropValue, TruthStatus	0	Expectation of user responses provides a model of the attentional state described by <TREF>Grosz and Sidner 1986</TREF>	0	It contains the list of semantic structures that have meaning for the current subdialog and for other active subdialogs	0	For example, after the computer produces an utterance that is an attempt to have a specific task step S performed, there are expectations for any of the following types of responses: 1 2 3 4 5 6 A statement about missing or uncertain background knowledge necessary for the accomplishment of S A statement about a subgoal of S A statement about the underlying purpose for S A statement about ancestor task steps of which accomplishment of S is a part	0	0	0
J95-3001	J86-3001	1995	10	0	Theoretical Issues from the <REF>Literature Grosz and Sidner 1986</REF> have given a high-level theory of dialog	0	The theory specifies three components, the linguistic, intentional, and attentional structures, and describes their nature and relationships to each other	0	However, their theory leaves a whole variety of issues undetermined; without a full implementation, the question of its applicability remains unanswered	0	0	0
J95-3001	J86-3001	1995	310 Smith, Hipp, and Biermann An Architecture for Voice Dialog Systems The intentional component specifies the purpose of the dialog	0	<TREF>Grosz and Sidner 1986</TREF> use the notation DP and DSP to stand for discourse purpose and discourse segment purpose	0	These entities correspond to the predicate goals that our system poses and then builds the dialog around	0	Our system, in fact, constructs a set of partial proofs and these are our instantiation of the intentional component	0	0	0
J95-3001	J86-3001	1995	Efficient dialog requires that each participant understand the purpose of the interaction and have the necessary prerequisites to cooperate in its achievement	0	This is the intentional structure of <TREF>Grosz and Sidner 1986</TREF>, the goaloriented mechanism that gives direction to the interaction	0	The primary required facilities are a problem solver that can deduce the necessary action sequences and a set of subsystems capable of carrying out those sequences	0	Subdialogs and effective movement between them	0	0	0
J95-3001	J86-3001	1995	In fact, the current subdialog specifies the focus of the interaction, the set of all objects and actions that are locally appropriate	0	This is the attentional structure described by <TREF>Grosz and Sidner 1986</TREF>, and its most important function in our system is to predict the meaning structures the user is likely to communicate in an input	0	For illustration, the opening of a chassis cover plate will often evoke comments about the objects behind the cover; the measurement of a voltage is likely to include references to a voltmeter, leads, voltage range, and the locations of measurement points	0	Thus the subdialog structure provides a set of expected utterances at each point in the conversation, and these have two important roles: 1 2 The expected utterances provide strong guidance for the speech recognition system so that error correction can be enhanced	0	0	0
J95-3001	J86-3001	1995	Efficient human dialog is usually segmented into utterance sequences, subdialogs, that are individually aimed at achieving relevant subgoals <REF>Grosz 1978</REF>; <REF>Linde and Goguen 1978</REF>; <REF>Polanyi and Scha 1983</REF>; <REF>Reichman 1985</REF>	0	These are called segments by <TREF>Grosz and Sidner 1986</TREF> and constitute the linguistic structure defined in their paper	0	The global goal is approached by a series of attempts at subgoals each of which involves a set of interactions, the subdialogs	0	An aggressive strategy for global success is to choose the subgoals judged most likely to lead to success and carry out their associated subdialogs	0	0	0
W99-0106	J86-3001	1999	In other cases, these modules are integrated by means of statistical <REF>Ge et al , 1998</REF> or uncertainty reasoning techniques <REF>Mitkov, 1997</REF>	0	The fact that current anaphora resolution systems rely exclusively on the linear nature of texts in Order to determine the LPA of an anaphor seems odd, given that several studies have claimed that there is a strong relation between discourse structure and reference <REF>Sidner, 1981</REF>; <REF>Gmsz and Sidner, 1986</REF>; Grosz et aL, 1995; <REF>Fox, 1987</REF>; <REF>Vonk et al , 1992</REF>; <REF>Azzam et al , 1998</REF>; Hitzeman and Poesio, 1998	0	These studies claim, on the one hand, that the use of referents in naturally occurring texts imposes constmints on the interpretation of discourse; and, on the other, that the structure of discourse constrains the HAs to which anaphors can be resolved	0	The oddness of the situation can be explained by the fact that both groups seem primafacie to be righL Empkical experiments studies that employ linear techniques for determining the LPAs of anaphom report recall and precision anaphora resolution results in the range of 80 in and Ieass, 1994; <REF>Ge et al , 1998</REF>	0	0	0
W94-0324	J86-3001	1994	Itowever, no elaborate interaction models are provided in this field except simplistic iterative question-answer models	0	In the area of conversational analysis and discourse theory, on the other hand, we find various discourse and dialogue models which address local dialogue structures eg , <REF>Fawcett et al , 1988</REF>; <REF>Grosz and Sidner, 1986, 1990</REF>; <REF>Reichman, 1985</REF>	0	To be able to design a flexible dialogue system which can engage in cooperative information-seeking dialogues we    4 use the Conversational Poles model COR developed by <REF>Sitter and Stein 1992</REF>	0	It has been used to design the interface of a multimedia information system, called MERIT cf	0	0	0
W94-0324	J86-3001	1994	A system which is capable of performing dialogues with a user on the basis of speech, was proposed by <REF>Smith, Hipp and Biermann 1992</REF>	0	Its domain is the maintenance of electrical appliances, and the emphasis in this approach lies on nested communicative goals, and concepts such as intentional, attentional and linguistic structures <TREF>Grosz and Sidner, 1986</TREF>	0	Another system for the treatment of spoken dialogues is reported in <REF>Bilange 1991</REF>	0	The approach, which has been developed in the framework of the SUNDIAL project, 207 7th International Generation Workshop  Kennebunkport, Maine  June 21-24, 1994 is based on the assumption that dialogues can best be described by means of a multi-level approach	0	0	0
W00-1007	J86-3001	2000	One of the most popular approaches to anaphora resolution is centering <REF>Grosz et al , 1995</REF>, henceforth GJW95, which accounts for the relation between the saliency of entities in discourse and the use of referring expressions, incorporating syntax, semantics and pragmatics	0	Centering fits into Grosz and Sidners model of discourse structure <TREF>Grosz and Sidner, 1986</TREF>	0	In this model a discourse is composed of segments which exhibit global coherence	0	A discourse 1This work has been carried out under Staging, an on-going Danish project funded by the Danish Research Councils	0	0	0
J93-3003	J86-3001	1993	The recognition and appropriate generation of cue phrases is of particular interest to research in discourse structure	0	The structural information conveyed by these phrases is crucial to many tasks, such as anaphora resolution <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF></TREF>; <REF>Reichman 1985</REF>, the inference of speaker intention and the recognition of speaker plans <TREF>Grosz and Sidner 1986</TREF></TREF>; <REF>Sidner 1985</REF>; <REF>Litman and Allen 1987</REF>, and the generation of explanations and other text <REF>Zuckerman and Pearl 1986</REF>	0	Despite the crucial role that cue phrases play in theories of discourse and their implementation, however, many questions about how cue phrases are identified and defined remain to be examined	0	In particular, the question of cue phrase polysemy has yet to receive a satisfactory solution	0	0	0
J93-3003	J86-3001	1993	<REF>Alternatively, Cohen 1984</REF> adopts a taxonomy of connectives based on <REF>Quirk 1972</REF> to assign each class of cue phrase a function in her model of argument understanding	0	<TREF>Grosz and Sidner 1986</TREF>, in their tripartite model of discourse structure, classify cue phrases based on the changes they signal to the attentional and intentional states	0	<REF>Zukerman 1986</REF> presents a taxonomy of cue phrases based on three functions in the generation of tutorial explanations: knowledge organization, knowledge acquisition, and affect maintenance	0	Table 14 in the Appendix compares the characterization of items classed as cue phrases in a number of these classification schemes	0	0	0
J93-3003	J86-3001	1993	Previous Studies of Cue Phrases The critical role that cue phrases play in understanding and generating discourse has often been noted in the computational linguistics literature	0	For example, it has been shown that cue phrases can assist in the resolution of anaphora, by indicating the presence of a structural boundary or a relationship between parts of a discourse <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Reichman 1985</REF>	0	In Example 7 RJB86, interpretation of the anaphor it as co-indexed with the system is facilitated by the presence of the cue phrases say and then, marking potential antecedents in as an expert database for an expert system as structurally unavailable	0	503 Computational Linguistics Volume 19, Number 3 Example 7 If the system attempts to hold rules, say as an expert database for an expert system, then we expect it not only to hold the rules but to in fact apply them for us in appropriate situations	0	0	0
J93-3003	J86-3001	1993	The corpus consisted of a keynote address given from notes by Ronald Brachman at the First International Conference on Expert Database Systems in 1986	0	This talk yielded 953 tokens, based upon a set of possible cue phrases derived from <REF>Cohen 1984</REF>, <TREF>Grosz and Sidner 1986</TREF>, <REF>Litman and Hirschberg 1990</REF>, <REF>Reichman 1985</REF>, <REF>Schiffrin 1987</REF>, <REF>Warner 1985</REF>, and <REF>Zuckerman and Pearl 1986</REF>	0	The frequency distribution of the tokens is shown in Table 5	0	By far the most frequent cue phrase occurring in our corpus is the conjunction and, representing 320 336 tokens	0	0	0
P06-2097	J86-3001	2006	For example,  add salt is assigned to ireru:1 add and A  carve with a knife is assigned to case frame ireru:2 carve	0	312 Cue phrases As Grosz and Sidner <TREF>Grosz and Sidner, 1986</TREF> pointed out, cue phrases such as now and well serve to indicate a topic change	0	We use approximately 20 domain-independent cue phrases, such as pxthen, xnext and fO hthen	0	313 Noun Chaining In text segmentation algorithms such as TextTiling HearstM, 1997, lexical chains are widely utilized for detecting a topic shift	0	0	0
J04-2001	J86-3001	2004	1	0	Centering has been proposed as a model of the local attentional states of speakers and hearers involved in the mutual construction of conversation <REF>Brennan, Friedman, and Pollard 1987</REF>; <REF>Grosz and Sidner 1986, 1998</REF>; <REF>Walker 1998</REF>	0	Centering mechanisms are designed to model the coherence of discourse by characterizing transitions between utterances in terms of their inferential load and hence their naturalness	0	These characterizations are intended to capture intuitions about the flow <REF>Chafe 1979</REF> or the ongoing process of meaning <REF>Halliday 1994</REF> in discourse	0	0	0
C98-2183	J86-3001	1998	Dialogue Act Tagging To address a significant concern in machine learning, called the sparse data problem, we nmst select an appropriate set of features	0	Researchers in discourse, such as <TREF>Grosz and Sidner 1986</TREF>, <REF>Lambert 1993</REF>, <REF>Hirschberg and Litman 1993</REF>, <REF>Chen 1995</REF>, <REF>Andernach 1996</REF>, <REF>Samuel 1996</REF>, and Chu-<REF>Carroll 1998</REF> have suggested several features that might be relevant for the task of computing dialogue acts	0	Our system can consider the following features of an utterance: 1 tile cue phrases a in the utterance; 2 the word n-grams a in the utterance; 3 the dialogue act cues 3 in the utterance; 4 the entire utterance for one-, two-, or three-word utterances; 5 speaker information 4 for the utter2The part-of-speech tag of a word is dependent on the words internal features and on the surrounding words; similarly, the dialogue act of an utterance is dependent on the utterances internal features and on tile surrounding utterances	0	3This feature is defined later in this section	0	0	0
J88-3008	J86-3001	1988	Since a discourse has relatively short duration, the discourse model that supports the interaction contains short term or temporary information	0	It is important to note that the representations of entities, as they appear in the discourse have a structure as proposed by <TREF>Grosz and Sidner 1986</TREF>	0	While Grosz and Sidner do not specifically deal with discourse models, their view on discourse is applicable to discourse models	0	The discourse model reflects the structure of the dialog	0	0	0
J87-1002	J86-3001	1987	It is more an indication of the motivation behind each utterance towards the ultimate goal of convincing the hearer	0	The difficulties in plan inference for discourse are discussed in more detail in <TREF>Grosz and Sidner 1986</TREF>, and are in fact a topic of our current concern see discussion of future work in Section 6	0	There is in fact a whole spectrum of problems the hearer must face in recognizing evidence relationships between propositions	0	The four main tests for the hearer can be described as:  use logic,  relax the logic,  stereotype the speaker,  judge plausibility reason as a hypothetical person	0	0	0
J87-1002	J86-3001	1987	We are interested in specifying a processing model for discourse understanding that operates at the level of individual utterances, in the manner of the argument model, to gain insight into how to derive linguistic and intentional structure simultaneously	0	This research is of significance to the current work of <TREF>Grosz and Sidner 1986</TREF>	0	ACKNOWLEDGMENTS This work was supported in part by the Natural Sciences and Engineering Research Council of Canada	0	I am grateful to the anonymous referees for their valuable comments and to Ray Perrault for his initial supervision of this research	0	0	0
J87-1002	J86-3001	1987	For future work, we are studying how to specify this process more precisely	0	See also <TREF>Grosz and Sidner 1986</TREF>	0	Finally, if the hearer is testing a possible evidence relation between two propositions, does not believe the missing premise, and has no prior knowledge of the speaker, the best option available is to try to judge the plausibility of the unstated information	0	Essentially, the hearer must postulate new facts which he may not be sure he wants to also believe and consider relationships between these facts as plausible or not	0	0	0
J87-1002	J86-3001	1987	Both active and 9Pen spaces are tracked, similar to our tracking candidates eligible to be relatives to the current proposition	0	Because of similarities in the representations and techniques for controlling search for interpretations, it is worth investigating as future work the precise relationship among coherence, reference resolution and focus determination for dialogues some of this is being done <TREF>Grosz and Sidner 1986</TREF>	0	53 PSYCHOLOGICAL RESEARCH Although our model is not designed according to psychological studies of discourse comprehension, there are some interesting parallels with existing psychological research	0	<REF>Labov and Fanshel 1977</REF> investigate therapeutic discourse, dialogue between a psychologist and his patient	0	0	0
J87-1002	J86-3001	1987	This approach to the study of clue words is much more detailed than the initial suggestions of <REF>Hobbs 1976</REF> on how to interpret a few connectives such as and in his framework	0	It is also distinct from the investigations of <REF>Reichman 1981</REF> and recently <TREF>Grosz and Sidner 1986</TREF>	0	Grosz and Sidner acknowledge the existence of clues and discuss various discourse structures that can be formed in the presence of clues	0	Reichman also gives a longer list of clue words and the particular conversational moves they signal	0	0	0
C88-2114	J86-3001	1988	A receiver makes use of these classificatory devices to classify and understand any speeifle CS with which he or she is presented	0	Focus space k Speaker Display OAct Act type Act structure  Figure 1 Structural components of the model 23 Cotmmunicative Situation Structures The Conmtunicative Situation Structure CSS is equivalent in level of analysis to the discourse segment of the <TREF>Grosz and Sidner 1986</TREF> model	0	The three components of the CSS see Figure I are the conmnicative act component CAct, the communicative situation component CS, and certain properties specific to the CSS itself	0	A CSS can consist of a number of CSs, and these in turn can consist of a number of CAets	0	0	0
W93-0225	J86-3001	1993	In its broadest outline, the goaJ is to uulerstaad the precise iH:eraction between features of tbrm, meaning and ffim:tion ill the creatioll of discourse coherem:e What kiuld o1 tbrm, meaning tnti flmction links occur etween utteraJlces and how are these thre, ki,lIs of links recognized	0	In a tirst step towards the synthesis we wouhl like to see, we will discuss the lerspective which the GS <TREF>Grosz and Sidner 1986</TREF> and RST RhetoricaJ Structure Theory, Mann and <REF>Thompson 1988</REF> theories take on links of meaning and function	0	We conclude with a brief description of an empiricaJ study suggested by this theory comparison	0	Note that we consider only monologic discourse at this time, believing generalizztions between this and multi-agent discourse to be premature	0	0	0
W03-2101	J86-3001	2003	 is a discourse-level problem	0	Grosz and Sid-	0	 ner<TREF>Grosz and Sidner, 1986</TREF> claim that a robust	0	 model of discourse understanding must use mul-	0	0	0
W03-2101	J86-3001	2003	 has a structure comprised of discourse segments	0	Each discourse segment has a discourse seg-	0	 ment purpose that contributes to the discourse	0	 purpose or intention underlying the overall dis-	0	0	0
C90-3018	J86-3001	1990	other features of non-cue usage: does a connective loose its normal meaning when used as a cue	0	Some researchers <TREF>Grosz  Sidner, 1986</TREF>, <REF>Hirschberg  Litman, 1987</REF> seem to argue that it does: the cue and non-cue usages are actually two distinct words	0	If that is the case, it would be difficult for a generator to choose among the different cue words that can perform the same structural task	0	On the other hand, we have no evidence at this point that cue words are not interchangeable eg , that but is used for one kind of pop and now another	0	0	0
C90-3018	J86-3001	1990	In this paper, we concentrate on the distinctions between similar connectives rather than on the general properties of the class of connectives	0	Work on the structure of discourse <REF>Cohen, 1984</REF>, <REF>Reichman, 1985</REF>, <TREF>Grosz  Sidner, 1986</TREF> has identified the role of connectives in marking structural shifts	0	This work generally relies on the notion that hearers maintain a discourse model which is often represented using stacks	0	Connectives give instructions to the hearer on how to update the discourse model	0	0	0
W00-1013	J86-3001	2000	And of course we will never reach a system in which every user need can be anticipated but then even human beings are not that type of system	0	4See <TREF>Grosz and Sidner, 1986</TREF> for a discussion of the importance of task plans in more explanatory dialogue	0	5It would also need tools that make it easy to model the relation between the linguistic expressions used in the various renderings of the base document	0	One can see this task as akin to that of multilingual generation or even simple document rendering	0	0	0
P95-1005	J86-3001	1995	Otherwise the entity which the expression refers to would have already been popped from the stack by the time the reference would need to be resolved	0	We develop our theory of discourse structure in the spirit of <TREF>Grosz and Sidner 1986</TREF> which has played an influential role in the analysis of discourse entity saliency and in the development of dialogue processing systems	0	Before we make our argument, we will argue for our approach to discourse segmentation	0	In a recent extension to Grosz and Sidners original theory, described in <REF>Lochbaum 1994</REF>, each discourse segment purpose corresponds to a partial or full shared plan 3 <REF>Grosz and Kraus 1993</REF>	0	0	0
P95-1005	J86-3001	1995	There are two main contributions of the work we will discuss in this paper	0	From a theoretical standpoint, we will demonstrate that theories which postulate a strict tree structure of discourse henceforth, Tree Structure Theory, or TST on either the intentional level or the attentional level <TREF>Grosz and Sidner 1986</TREF> are not totally adequate for covering spontaneous dialogues, particularly negotiation dialogues which are composed of multiple threads	0	These are negotiation dialogues in which multiple propositions are negotiated in parallel	0	We will discuss our proposea extension to TST which handles these structures in a perspicuous manner	0	0	0
P95-1005	J86-3001	1995	Notice that in both of these examples, the speakers negotiate over multiple alternatives in parallel	0	We challenge an assumption underlying the best known theories of discourse structure <TREF>Grosz and Sidner 1986</TREF>; <REF>Scha and <REF>Polanyi 1988</REF></REF>; <REF>Polanyi 1988</REF>; <REF>Mann and Thompson 1986</REF>, namely that discourse has a recursive, tree-like structure	0	<REF>Webber 1991</REF> points out that Attentional State i is modeled equivalently as a stack, as in Grosz and Sidners approach, or by constraining the current discourse segment to attach on the rightmost frontier of the discourse structure, as in Polanyi and Schas approach	0	This is because attaching a leaf node corresponds to pushing a new element on the stack; adjoining a node Di to a node Dj corresponds to popping all the stack elements through the one corresponding to Dj and pushing Di on the stack	0	0	0
J92-4007	J86-3001	1992	However, recent work by <REF>Moore and Paris 1992</REF> noted that RST cannot be used as the sole means of controlling discourse structure in an interactive dialogue system, because RST representations provide insufficient information to support the generation of appropriate responses to follow-up questions	0	The basic problem is that an RST representation of a discourse does not fully specify the intentional structure <TREF>Grosz and Sidner 1986</TREF> of that discourse	0	Intentional structure is crucial for responding effectively to questions that address a previous utterance: without a record of what an utterance was intended to achieve, it is impossible to elaborate or clarify that utterance	0	1 Further consideration has led us to conclude that the difficulty observed by Moore and Paris stems from a more fundamental problem with RST analyses	0	0	0
J92-4007	J86-3001	1992	An interpretation system therefore needs the capability of maintaining both levels of relation	0	4 <REF>In Grosz and Sidner 1986</REF>, dominates and satisfaction-precedence are the intentional relations, while supports and generates are the informational relations	0	5 The hearer also needs to believe that it is plausible the speaker holds the same belief; see <REF>Konolige and Pollack 1989</REF>	0	6 This is thus an example of what Sadock calls modus brevis <REF>Sadock 1977</REF>	0	0	0
J92-4007	J86-3001	1992	RST presumes that, in general, there will be a single, preferred rhetorical relation holding between consecutive discourse elements	0	In fact, as has been noted in other work on discourse structure <TREF>Grosz and Sidner 1986</TREF>, discourse elements are related simultaneously on multiple levels	0	In this paper, we focus on two levels of analysis	0	The first involves the relation between the information conveyed in consecutive elements of a coherent discourse	0	0	0
P98-2179	J86-3001	1998	3 Deductive Operators The choice of operators implemented in the Rhetorica system has been influenced by a number of factors	0	The rules of inference are clear candidates for operationalisation: moves such as Modus Ponens are clearly vital components of any argument though, as noted in <TREF>Grosz and Sidner 1986</TREF>, p201, it is inappropriate to view the implication step as one of conventional material implication	0	The relationship is rather one of support the hearer must be brought to believe that given the current context and domain of discourse the first proposition warrants, in part, concluding the second	0	Even given this weaker, predicate-based reading of a Modus Ponens argument, it is still unclear that any of the other rules of inference which are, after all, formally redundant should be necessary	0	0	0
P98-2179	J86-3001	1998	Belief goals are used to build the content of an argument as in much other NLG work; saliency goals to express the intention to convey information to the hearer following a notion of saliency similar to that proposed in <REF>Walker, 1996</REF>; and topic manipulation goals to control the focus of attention through the discourse	0	The roles of these goals and their interrelationships are explored in relation to the informationintention-attention model of <TREF>Grosz and Sidner 1986</TREF> in more detail in <REF>Reed and Long 1997a</REF>	0	3 Deductive Operators The choice of operators implemented in the Rhetorica system has been influenced by a number of factors	0	The rules of inference are clear candidates for operationalisation: moves such as Modus Ponens are clearly vital components of any argument though, as noted in <TREF>Grosz and Sidner 1986</TREF>, p201, it is inappropriate to view the implication step as one of conventional material implication	0	0	0
P07-1101	J86-3001	2007	However, acoustic features capturing the pitch excursion at the right edge of okay feature prominently in disambiguation, whether other contextual cues are present or not	0	CUE PHRASES also known as DISCOURSE MARKERS are linguistic expressions that can be used to convey explicit information about the structure of a discourse or to convey a semantic contribution <TREF>Grosz and Sidner, 1986</TREF>; <REF>Reichman, 1985</REF>; <REF>Cohen, 1984</REF>	0	For example, the word okay can be used to convey a satisfactory evaluation of some entity in the discourse the movie was okay; as a backchannel in a dialogue to indicate that one interlocutor is still attending to another; to convey acknowledgment or agreement; or, in its cue use, to start or nish a discourse segment <REF>Jefferson, 1972</REF>; <REF>Schegloff and Sacks, 1973</REF>; <REF>Kowtko, 1997</REF>; <REF>Ward and Tsukahara, 2000</REF>	0	A major question is how speakers indicate and listeners interpret such variation in meaning	0	0	0
C94-2187	J86-3001	1994	Thus a discourse should look like Figure 1, where G denotes a discourse segment	0	Fnrthermore, we do not intend the disD Figure 1: Discourse Structure course structure to be anything close to the ones that rhetorical theories of discourse t<REF>Iovy, 1990</REF>; <REF>Mann and Tholnpson, 1987</REF>; <REF>Itobbs, 1979</REF> claim it to be, or inteulional structure <TREF>Grosz and Sidner, 1986</TREF> ; indeed we do not assmne any functional relation, ie causation, elaboration, extension, etc , among the segments that constitute a discourse structure	0	The present theory is not so much about the rhetoric or the function of discourse as about the way anaphora are interpreted	0	It is quite possible that a set of discourse segments are not aggregated into a single discourse but may have diverse discourse groupings <REF>Nomoto and Nitta, 1993</REF>	0	0	0
W99-0101	J86-3001	1999	2 Background: Discourse Structure We assume the general theoretical framework of <REF>Roberts 1996</REF>, where discourse is formally characterized as a game of intentional inquiry	0	As in <TREF>Grosz  Sidner 1986</TREF>, discourse is organized by the interlocutors goals and intentions and the plans, or strategies, which conversational participants develop to achieve them	0	<REF>Following Stalnaker 1979</REF>, the primary goal of the language game is communal inquiry, ie, interlocutors attempting to share information about their world, with the repository of that shared information characterized as the interlocutors common groun CG	0	The set of acceptable moves in the game are defined by the conventional and conversational rules of the game, and are classified on the basis of their relationblp to the goals	0	0	0
W00-1430	J86-3001	2000	Indeed, knowing which kind of activity the user is involved in at each moment ie the ontology instances involved in that activity we hypothesise on which person and keyword the users attention is focused on	0	22 Attention focus and Information Structure Theory   Other researchers have investigated attention focus in larger spans of discourse <REF>McCoy and Cheng, 1991</REF>; <TREF>Grosz and Sidner, 1986</TREF> and in dialogue <REF>Jokinen et al , 1998</REF>	0	Corpus analysis <REF>Rats, 1996</REF> confirms the existence of a mechanism called topic, through which interlocutors strive at discourse coherence to reduce the cognitive effort of the hearer	0	The terminology used in the different frameworks is confusing, even contradictory Bosch and van der <REF>Sandt, 1999</REF>	0	0	0
W97-1411	J86-3001	1997	82 D He, G Ritchie and J Lee price band about the depictive mapping, since the user is querying a directly depicted world property	0	Coherence The coherence of the proceeding dialogue should not be damaged by an object becoming the referent of the expression <TREF>Grosz and Sidner, 1986</TREF>	0	It follows that the disambiguation process should be based on the following information sources: the world model and the display model for the sources of candidates and the examination of various restrictions, the dialogue model for providing coherence information about the dialogue and the user model for the modelling of mutual beliefs	0	In practice, our project is too limited to explore all of these issues, and we intend to leave aside issues of mutual belief that is, our user model will be degenerately simple	0	0	0
W06-1309	J86-3001	2006	Ony if these factors are represented in an effective and efficient formal language, dialogue systems can be implemented	0	Examples of such models and their implementation are the informationstate-update approach an implemented system is described in <REF>Larsson, 2002</REF>, or  more linguisticallyorientedapproachesliketheadjacency-pair models or intentional models such as GROSZ and SIDNERs see <TREF>Grosz and Sidner, 1986</TREF>	0	Even if it has been noted often that discourse structure and task structure are not isomorphic, only a few contributions to dialogue research focus on the question of how both structures interfere see Sect	0	2	0	0	0
C96-1052	J86-3001	1996	cl Avoid conveying redundant information	0	:2 Pronominalize objects in the focus of attention <TREF>Grosz and Sidner 1986</TREF>	0	c3 Be relevant according to the attentionM state	0	he context model records the information that has been conveyed and tracks the attentional state	0	0	0
W04-2318	J86-3001	2004	Keywords Dialogue Systems, Discourse structure, Prosody in understanding 1 Introduction Contemporary theories of discourse, both computational and descriptive, postulate a tree-structured hierarchical model of discourse	0	These structures may be viewed as corresponding tointentional structure of discourse segment purposes in the view of <TREF>Grosz and Sidner, 1986</TREF>, to plan and subplan structure directly in the view of <REF>Allen and Litman, 1990</REF>, to nuclei and satellite rhetorical relations in the Rhetorical Structure Theory of <REF>Mann and Thompson, 1987</REF>, or to information structures as in <REF>Traum and Hinkelman, 1992</REF>	0	Despite this diversity of views on the sources of structural organization, these theories agree on the decomposition of discourse into segments and subsegments in a hierarchical structure	0	Discourse segments help to establish the domain of interpretation for referents or anaphors	0	0	0
J88-3013	J86-3001	1988	The discourse model is then also needed to provide the links between the four, which support calls from one to another	0	A shifting focus of attention like that represented by the point of interaction between participants and discourse in Grosz and Sidners 1986 account is naturally presupposed here	0	But my argument is that we need to separate a participants in this case, the systems view of itself from its views of the world and of the user	0	The way these interact with the text model will then be reflected in a subset of relations and hence entities in the discourse model which constitutes the focus of attention	0	0	0
W07-1408	J86-3001	2007	In: ROMAND 206 1th EACL	0	Geneva, 206 3-10 Grosz B and C <REF>Sidner 1986</REF>	0	Atention, Intentions, and the Structure of Discourse, Computational Linguistics 12 3, 175-204	0	Raina, R , et al: Robust Textual Inference using Diverse Knowledge Sources	0	0	0
W07-1408	J86-3001	2007	Step A is identical and is recursively repeated until all clauses are processed	0	31 Focusing Revisited Our version of the focusing algorithm folows Sidners proposal Sidner C , 1983; Grosz B , Sidner C , 1986, to use a Focus Stack, a certain Focus Algorithm with Focus movements and data structures to allow for processing simple inferential relations between different linguistic descriptions co-specifying or coreferring to a given entity	0	Our Focus Algorithm is organized as folows: for each uterance, we assert three hierarchically ordered centersthat we call Main, Secondary and the first Potential Topic, which represent the best three referring expressions as they have been weighted in the candidate list used for pronominal binding; then we also keep a list of Potential Topics for the remaining best candidates	0	These 51 three best candidates repositories are renovated at each new uterance, and are used both to resolve pronominal and nominal cospecification and coreference: this is done both in case of strict identity of linguistic description and of nonidentity	0	0	0
W00-1420	J86-3001	2000	o <context> This is the context input/output	0	The context contains a stack for objects in focus, handled as described in <TREF>Grosz and Sidner, 1986</TREF>	0	Additionally we put the generated information on a history list <REF>Dale, 1995</REF>	0	The context supports the generation of, eg, pronouns see below	0	0	0
W93-0229	J86-3001	1993	Some people <REF>Searle and Vanderveken 1985</REF>, <REF>Cohen and Levesque 1990</REF> have assumed that the recognition of the speakers intention and other mental states in producing an utterance is extremely important to understand its meaning, but have limited their work on one single speech act	0	Because a conversation is a temporal sequence of connected illocutionary acts 110 <REF>Moulin, Rousseau and Vanderveken 1991</REF> where each speech act plays a precise role in the context of other speech acts, some researchers have studied the structure of a conversation and they all agreed that there are several interrelated components in it and many subconversations of different types <TREF>Grosz and Sidner 1986</TREF>, <REF>Litman and Allen 1987</REF>	0	The planning approach has been used by some scientists to produce speech acts in the context of a dialogue <REF>Allen 1983</REF>, <REF>Appelt 1985</REF>, <REF>Litman and Allen 1987</REF>, <REF>Lambert and Carberry 1992</REF>	0	Starting from the approaches mentioned above, the model of speech act planner we propose takes into consideration the following problems: multiagent planning, reasoning on other agents mental states and on ones own mental states, recognition of intentions behind direct and indirect speech acts, use of plans integrating linguistic and non-linguistic actions, coherence of the conversation between two or more agents, handling of subeonversations and modeling of the conversational context	0	0	0
E06-3002	J86-3001	2006	Coherence relations, such as Elaboration, Explanation and Contrast, are relations between discourse units that bind segments of text into one global structure	0	<TREF>Grosz and Sidner, 1986</TREF> incorporates two more important notions into its model the idea of intention and focus	0	The Rhetorical Structure Theory, introduced in <REF>Mann and Thompson, 1987</REF>, binds text spans with rhetorical relations, which are discourse connectives similar to coherence relations	0	The Discourse Representation Theory DRT <REF>Kamp, 1984</REF> computes inter-sentential anaphora and attempts to maintain text cohesion through sets of predicates, termed Discourse Representation Structures DRSs, that represent discourse 32 No one does He can still walk by himself Explanation Who supports Gorbachev	0	0	0
J97-1006	J86-3001	1997	The axioms may then be used by the theorem prover	0	Finally, integration of theorems, the utterances relevant to these theorems, and the expectations for responses that supply missing axioms yields a constructive method for creating and using a discourse model first proposed by <TREF>Grosz and Sidner 1986</TREF>, but for which they did not offer a method of dynamic construction during the course of a dialogue	0	Furthermore, the model enables the system to engage in variable initiative dialogue as outlined in Section 2	0	The interested reader is referred to <REF>Smith, Hipp, and Biermann 1995</REF> for further details about the overall model	0	0	0
J00-4003	J86-3001	2000	13 Only plural nouns ending in s are handled by the system	0	549 Computational Linguistics Volume 26, Number 4 In general, it is not sufficient to look at the most recent antecedents only: this is because segments are organized hierarchically, and the antecedents introduced in a segment at a lower level are typically not accessible from a segment at a higher level <REF>Fox 1987</REF>; <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Reichman 1985</REF>, whereas the antecedents introduced in a prior segment at the same level may be	0	Later in 8, for example, the housej in sentence 50 becomes inaccessible again, and in sentence 65, the text starts referring again to the house introduced in sentence 2	0	Automatically recognizing the hierarchical structure of texts is an unresolved problem, as it involves reasoning about intentions; 14 better results have been achieved on the simpler task of chunking the text into sequences of segments, generally by means of lexical density measures <REF>Hearst 1997</REF>; <REF>Richmond, Smith, and Amitay 1997</REF>	0	0	0
J00-4003	J86-3001	2000	Our tests with bridging descriptions resulted in a great number of false positives	0	Our analysis of these data, as well as of other corpora <REF>Hitzeman and Poesio 1998</REF>, suggests that a local focusing mechanism as proposed in <REF>Grosz 1977</REF>, <REF>Sidner 1979</REF>, Grosz, Joshi, and Weinstein 1983, 1995, and <TREF>Grosz and Sidner 1986</TREF> would improve the results obtained by our system	0	There are several reasons why our system does not yet include such a mechanism	0	One problem already mentioned is that Sidners algorithms as stated, and even as implemented by Carter, are difficult to implement, since considerably more lexical information is needed than we have available eg , about the thematic roles of verbs, a rich knowledge base is needed both to resolve bridging descriptions and larger situation uses, and commonsense inference is needed to evaluate the plausibility of hypotheses	0	0	0
W96-0410	J86-3001	1996	Analogously, an entity is either new or old to the DISCOURSE, according to whether the discourse contains an earlier reference to it	0	Second, entities differ in SALIENCE <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al , 1995</REF>	0	At any point, salience assigns each entity a position in a partial order that indicates how accessible it is for reference in the current context	0	Third, entities are related by material PARTIALLY-ORDERED SET POSET RELATIONS to other entities in the context <REF>Hirschberg, 1985</REF>	0	0	0
W98-0301	J86-3001	1998	Most of the algorithmic research in discourse segmentation focused on segments of coarse granularity <REF>Grosz and Hirschberg, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Passonneau and Litman, 1997</REF>; <REF>Hearst, 1997</REF>; <REF>Yaari, 1997</REF>	0	These segments were defined intentionally in terms of Grosz and Sidners theory 1986 or in terms of an intuitive notion of topic	0	However, in case of applications such as anaphora resolution, discourse parsing, and text summarization, even sentences might prove to be too large discourse segments	0	For example, if we are to defive the discourse structure of texts using an RSTlike representation <REF>Mann and Thompson, 1988</REF>, we will need to determine the elementary textual units that contribute rhetorically to the understanding of those texts; usually, these units are clause-like units	0	0	0
H05-1090	J86-3001	2005	b If the first noun phrase is a third person personal pronoun, use the classification in the focus variable	0	Pronouns are known to signal that the same focus continues <TREF>Grosz and Sidner, 1986</TREF>	0	c If the sentence has not met any of the above tests but has a minimum number of content words, shift the focus	0	If all tests above fail and there are a minimum number of content words, with a sum of Tshift shift the focus	0	0	0
J91-1002	J86-3001	1991	This was found to be true	0	The lexical chains computed by the algorithm given in Section 323 correspond closely to the intentional structure produced from the structural analysis method of <TREF>Grosz and Sidner 1986</TREF>	0	This is important, since Grosz and Sidner give no method for computing the intentions or linguistic segments that make up the structure that they propose	0	Hence the concept of lexical cohesion, defined originally by <REF>Halliday and Hasan 1976</REF> and expanded in this work, has a definite use in an automated text understanding system	0	0	0
J91-1002	J86-3001	1991	This section will concentrate on analyzing correspondences between lexical chains and structural units of text, including:  the correspondence of chain boundaries to structural unit boundaries;  returns to existing chains and what they indicate about structural units;  lexical chain strength and reliability of predicting correspondences between chains and structural units;  an analysis of problems encountered, and when extra textual information is required to validate the correspondences between lexical chains and structural components	0	The text structure theory chosen for this analysis was that of <TREF>Grosz and Sidner 1986</TREF>	0	it was chosen because it is an attempt at a general domain-independent theory of text structure that has gained a significant acceptance in the field as a good standard approach	0	The methodology we used in our analyses was as follows: 1	0	0	0
J91-1002	J86-3001	1991	It follows that if lexical chains can be determined, they will tend to indicate the structure of the text	0	We will describe the application of lexical cohesion to the determination of the discourse structure that was proposed by <TREF>Grosz and Sidner 1986</TREF>	0	Grosz and Sidner propose a structure common to all discourse, which could be used along with a structurally dependent focus of attention to delineate and constrain referring expressions	0	In this theory there are three interacting components: linguistic structure, intentional structure, and attentional state	0	0	0
C00-1031	J86-3001	2000	In other cases, these modules are integrated by means of statistical <REF>Ge et al , 1998</REF> or uncertainty reasoning teclmiques <REF>Mitkov, 1997</REF>	0	The fact that current anaphora resolution systems rely exclusively on the linear nature of texts in order to determine the LPA of an anaphor seems odd, given flint several studies have claimed that there is a strong relation between discourse structure and reference <REF>Sidner, 1981</REF> ; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al , 1995</REF>; <REF>Fox, 1987</REF>; Vonk ct al , 1992; Azzam el al , 1998; <REF>Hitzcman and Pocsio, 1998</REF>	0	These studies claim, on the one hand, that the use of referents in naturally occurring texts imposes constraints on the interpretation of discourse; and, on the other, that the structure of discourse constrains the LPAs to which anaphors can be resolved	0	The oddness of the situation can be explained by lho fac	0	0	0
C92-2114	J86-3001	1992	For lack of space, however, we leave out the model of state change management needed to describe recipe ingredients being mixed together and transformed <REF>Kosseim 1992</REF>, ald the focus model used	0	41 Input We limit our scope to the linguistic part of generation; therefore, we assume that onr input is the ontput of a text planner, which has already grouped actions into discourse structures as proposed by <TREF>Grosz and Sidner 1986</TREF> and <REF>Dale 1988</REF>, The input is thus a sequence of actions and states in which participants ingredients, instruments and agent are represented by indices	0	42 Dictionary of concepts The dictionary of concepts has been inspired by <REF>Nirenburg and Raskin 1987</REF>; concepts are mainly subdivided into actions or objects	0	We have added a category of properties, needed to describe relations between concepts eg , temporal limit or attributes eg size	0	0	0
W05-1606	J86-3001	2005	The referring expression to be generated is required to be a distinguishing description, that is a description of the enitties being referred to, but not to any other object in the context set	0	A context set is defined as the set of the entities the addressee is currently assumed to be attending to  this is similar to the set of entities in the focus spaces of the discourse focus stack in Grosz and Sidners 1986 theory of discourse structure	0	Moreover, the contrast set or the set of potential distractors <REF>McDonald 1981</REF> is defined to entail all elements of the context set except the intended referents	0	Generating referring expressions is pursued since the eighties <REF>Appelt 1985</REF>, <REF>Kronfeld 1986</REF>, <REF>Appelt and Kronfeld 1987</REF>	0	0	0
W01-1603	J86-3001	2001	1: room for a lecture: return 42 B: D soreja dai-kaigishitsu de onegai shimasu Ok Please book the large meeting room	0	---------------------------------------TBI:topic name:segment relation Figure 5: An example dialogue with the dialogue segment tags 23 Dialogue segment DialoguesegmentofJDTAGindicatesboundaryof discourse segment introduced in <TREF>Grosz and Sidner, 1986</TREF>	0	A dialogue segment is identied based on the exchange structure explained above	0	A dialoguesegment tag is rst inserted before each initiating utterance	0	0	0
P92-1025	J86-3001	1992	However, 2 would probably still recognize 4 as an expression of doubt because the linguistic clue but suggests that 4 may be some sort of non-acceptance action, there is nothing to suggest that S1 does not believe that Dr Smith winning a teaching award implies that she is not teaching Architecture, and no other interpretation seems more coherent	0	Since linguistic knowledge is present, less evidence is needed from world knowledge to recognize the discourse actions being performed <TREF>Grosz and Sidner, 1986</TREF>	0	In our model, if a new utterance contributes to a discourse action already in the DM, then there must be an inference path from the utterance that links the utterance up to the current tree structure on the discourse level	0	This inference path will contain an action that determines the relationship of the utterance to the DM by introducing new parameters for which there are many possible instantiations, but which must be instantiated based on values from the DM in order for the path to terminate with an action already in the DM	0	0	0
P92-1025	J86-3001	1992	So, our model captures many of the ways in which people infer beliefs: 1 from the surface form of utterances; 2 from stereotype models; and 3 from acceptance explicit or implicit or non-acceptance of previous actions	0	5 Combining Knowledge <REF>Sources Grosz and Sidner 1986</REF> contend that modeling discourse requires integrating different kinds of knowledge in a unified framework in order to constrain the possible role that an utterance might be serving	0	We use three kinds of knowledge, 1 contextual information provided by previous utterances; 2 world knowledge; and 3 the linguistic information contained in each utterance	0	Contextual knowledge in our model is captured by the DM and the current focus of attention within it	0	0	0
W06-3001	J86-3001	2006	It seems that as long as this relation exists, even if there are many segments in between8, the first entity remains in focus of attention and can be referred to by an implicit deictic or definite NP without any additional retrieval cue	0	We can speak of thematic nesting of segments, which seems to be analogous to the intentional structure in taskoriented dialogues as in <TREF>Grosz and Sidner, 1986</TREF>, also allowing for reference with implicit devices to entities in the superordinate segments after the subordinated ones have been closed	0	It seems, thus, that thematic structure, like the discourse goals, also imposes structure on the discourse	0	These cases, although not numerous, suggest that a more complex discourse structure is needed for QA interactions than one simply based on the discourse goals	0	0	0
W06-3001	J86-3001	2006	Upon Ahrenberg et al	0	1990 this is given by the discourse goals, rather than the overall goals of the user, as is the case in task-oriented dialogues, <TREF>Grosz and Sidner, 1986</TREF>	0	Following Ahrenberg et al	0	1990, the QA discourse is structured in segments composed by a pair of initiative-response units, like questionanswer, or question-assertion, in the absence of an answer	0	0	0
W99-0208	J86-3001	1999	As antecedents may also be discourse chunks of varying length, these same categories were used to classify such antecedents as predicates of a given topical role thought to be the dominant entity within the discourse chunk	0	The aim of this attribute is to use the often mentioned relationship between topicality and coreference see <TREF>Grosz and Sidner 1986</TREF> for operational purposes	0	This classification does not claim to be the actual key for the modelling of topicality in dialogues from a psycholinguistic point of view	0	It does claim, however, to be a useful tool for the resolution of particularly hard cases of coreference, in which the antecedent is not the nearest syntactically appropriate candidate, as will be shown in section 3	0	0	0
P97-1027	J86-3001	1997	The referring expression to generate is required to be a distinguishing description, that is a description of the entity being referred to, but not to any other object in the current context set	0	A context set is defined as the set of entities the addressee is currently assumed to be attending to this is similar to the set of entities in the focus spaces of the discourse focus stack in Grosz and Sidners theory of discourse structure <REF>Grosz, Sidner, 1986</REF>	0	Moreover, the contrast set or, the set of potential distractors <REF>McDonald, 1981</REF>, is defined to entail all elements of the context set except the intended 206 referent	0	In the scope of some context set, an attribute or a relation applicable to the intended referent can be assigned its discriminatory power, 3 that is a measure similar to the number of potential distractors that can be removed from the contrast set with confidence, because this attribute or relation does not apply to them	0	0	0
P97-1035	J86-3001	1997	:EAC, DR, D :AIA9 SEGcr: S3 SMlCr: S4 G0: I GOALS: AC orrcES: A3u5 0TI/ES: A6U6 Figure 4: Task-defined discourse structure of Agent A dialogue interaction utterances that contribute to the success of the whole dialogue, such as greetings, are tagged with all the attributes	0	Since the structure of a dialogue reflects the structure of the task <REF>Carberry, 1989</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Litman and Allen, 1990</REF>, the tagging of a dialogue by the AVM attributes can be used to generate a hierarchical discourse structure such as that shown in Figure 4 for Dialogue 1 Figure 2	0	For example, segment subdialogue 2 in Figure 4 is about both depart-city DC and arrivalcity AC	0	It contains segments 3 and 4 within it, and consists of utterances U1 U6	0	0	0
P97-1035	J86-3001	1997	Let Agent As repair dialogue strategy for subdialogues repairing depart-city be RA and Agent Bs repair strategy for depart-city be RB	0	Then using the performance equation above, predicted performance for RA is: PerformanceRa  40  71 -78  72  --028 For Agent B, using the appropriate subpart of Table 4 to calculate , assuming that the average number of depart-city repair utterances is 138, and using similar 12This assumption has a sound basis in theories of dialogue structure <REF>Carberry, 1989</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Litman and Allen, 1990</REF>, but should be tested empirically	0	calculations, yields PerformanceRB  40	0	-71 78  -94  045 Thus the results of these experiments predict that when an agent needs to choose between the repair strategy that Agent B uses and the repair strategy that Agent A uses for repairing depart-city, it should use Agent Bs strategy RB, since the performanceRB is predicted to be greater than the performanceRa	0	0	0
C88-1044	J86-3001	1988	Testing computational algorithms against multiple genres of natural discourse is important, especially given the universal scope of current frameworks cf	0	<TREF>Grosz and Sidner 1986</TREF>	0	We have chosen to systematically examine texts from a broad range of genres, which vary in spoken versus written medium, number of participants, degree of pre-planning, and formality of situation	0	These genres include informal conversation, partiallyspontaneous televised discussion, newspaper articles, and planning and technical documents	0	0	0
C88-1044	J86-3001	1988	216 view that deictic expressions signal a change in focus of attention while anaphoric expressions signal focus continuation cf, <REF>Ehlich 1982</REF>; <REF>Bosch 1983</REF>	0	It is this view which most closely reflects the assumptions underlying computationaUy explicit models of focus-constrained discourse processing eg , <REF>Linde 1979</REF>; <REF>Reichman 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	We turn now to a presentation of specific claims about demonstratives which have been made in the literature	0	Focus shift	0	0	0
C88-1044	J86-3001	1988	Similarly, in the current centering paradigm <REF>Grosz, Joshi and Weinstein 1986</REF>, <REF>Brennan, Friedman and Pollard 1987</REF> elements in the set of forward looking centers can also be considered activated	0	At the global level, <REF>Sidner and Grosz 1986</REF> describe a model of discourse structure which indicates currently activated beliefs and intentions at any  given point in a discourse	0	In Focus	0	Elements in focus are those which are most highly activated	0	0	0
C88-1044	J86-3001	1988	These require a sophisticated user model which keeps a record of beliefs and intentions of discourse participants	0	While such a model could be incorporated into existing discourse structure frameworks eg <TREF>Grosz and Sidner 1986</TREF>, no specific proposals to account for shared familiarity have yet been advanced but see <REF>Sparck Jones 1986</REF>	0	Activation	0	An adequate model of activation must isolate that subset of shared entities which is activated at any given point in the discourse	0	0	0
J88-3012	J86-3001	1988	This is not due to principled limits, however, but rather to a shortcoming in the state of the art	0	On the other hand, the users utterances can also be analyzed from another viewpoint, namely incorporating them into a coherent discourse model as described by, eg, <TREF>Grosz and Sidner 1986</TREF>	0	Also, this model can be used during all processing steps from understanding to generating	0	Both user models and discourse models are built up at least partially from the user utterances	0	0	0
J88-3012	J86-3001	1988	Given the above definition of dialog memories, however, there is a difference between the two notions	0	As opposed to Schuster, who defines a discourse model as containing representations of entities, along with their properties and relations they participate in, which corresponds exactly to our dialog memory, I use discourse model according to the framework of <TREF>Grosz and Sidner 1986</TREF>, where a discourse model is the syntactic structure of a dialog	0	One part of it, though, could be identified with the dialog memory, namely the focus space stack	0	The overall discourse model additionally represents the structure of the dialog with the segments and their relations, which is not part of the user model	0	0	0
P98-1065	J86-3001	1998	Approaches that address this problem can be classified in knowledge-based approaches or word-based approaches	0	Knowledge-based systems as Grosz and Sidners 1986 require an extensive manual knowledge engineering effort to create the knowledge base semantic network and/or frames and this is only possible in very limited and well-known domains	0	To overcome this limitation, and to process a large amount of texts, word-based approaches have been developed	0	<REF>Hearst 1997</REF> and <REF>Masson 1995</REF> make use of the word distribution in a text to find a thematic segmentation	0	0	0
P00-1053	J86-3001	2000	When looking back more than four units, the linear model was equally effective	0	Here, we compare VT to stack-based models of discourse structure based on Grosz and Sidners 1986 GS focus spaces eg , <REF>Hahn and Strbe, 1997</REF>; Azzam, et al , 1998	0	In these approaches, discourse segments are pushed on the stack as they are encountered in a linear traversal of the text	0	Before a dominating segment is pushed, subordinate segments that precede it are popped from the stack	0	0	0
P00-1053	J86-3001	2000	In this paper, we outline a theory of referential accessibility called Veins Theory VT	0	We compare VT to stack-based models based on Grosz and Sidners 1986 focus spaces, and show how VT addresses the problem of left satellites, ie, subordinate discourse segments that appear prior to their nuclei dominating segments in the linear text	0	Left-satellites pose a problem for stack-based models, which remove subordinate segments from the stack before pushing a nuclear or dominating segment, thus rendering them inaccessible	0	The percentage of such cases is typically small, which may account for the fact that their treatment has been largely overlooked in the literature, but the phenomenon nonetheless persists in most texts	0	0	0
C98-2150	J86-3001	1998	This paper presents an empirically motivated theory of the discourse focusing function of accent	0	The theory describes for the first time the interacting contributions to accent prediction made by factors related to the local and global attentional status of discourse referents in a discourse model <TREF>Grosz and Sidner, 1986</TREF>	0	The ability of the focusing features to predict accent tor a blind test corpus is examined using machiue learning	0	Because attentional status is a property of referring expressions, a novel approach to accent prediction is proposed to allow for the integration of word-based and constituent-based linguistic features in the models to be learned	0	0	0
C98-2150	J86-3001	1998	<REF>Terken, 1984</REF>; <REF>Hirschberg, 1993</REF>	0	We propose a new theory of the relationship between accent and attention, based on an enriched taxonomy of given/new information status provided by both the LOCAL centering and GLOBAL foCUS stack model attentional state models in Grosz and Sidners discourse modeling theory 1986	0	939 Analysis of a 20-minute spontaneous story-telling monologue t identified separate but interacting contributions of grammatical function, form of referring expression and accentuation 2 in conveying the attentional status of a discourse referent	0	These interactions can be formally expressed in the framework of attentional modeling by the following principles of interpretation:  The LEXICAL FORM OF A REFERRING EXPRESSION indicates the level of attentional processing, ie, pronouns involve local focusing while full lexical forms involve global focusing <REF>Grosz et al, 1995</REF>	0	0	0
W01-0814	J86-3001	2001	Preference 22 If the gap of the relative clause is not associated with the nominative case, the gap filler is preferred to be topicalized	0	54 Anaphora and ellipsis Several works have explored the relation between rhetorical structure and reference in English <REF>Fox, 1987</REF>; <REF>Cristea et al , 2000</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al , 1995</REF>	0	Japanese reference, on the other hand, has been studied from a different perspective, being associated mainly with the linear nature of texts as in the centering theory <REF>Kameyama, 1986</REF>; <REF>Walker et al , 1994</REF>	0	Considering that choice of referring expressions is in itself a quite large issue, we have been exploring it separately from this paraphrase-based exploration <REF>Hashimoto, 2001</REF>	0	0	0
W04-0203	J86-3001	2004	For both aspects of discourse relations, it is the fact that the non-canonical order marks part of the utterances information as salient or discourseold that assists these inferences	0	21 Syntax of discourse relations One substructure of a coherent discourse structure is its attentional structure, which can be modeled as a stack of focus spaces <TREF>Grosz and Sidner, 1986</TREF>	0	Each segment in the discourse tree has a corresponding focus space containing the currently salient discourse entities	0	When a segment begins, its focus space is pushed onto the stack on top of any other incomplete segments spaces	0	0	0
W04-0203	J86-3001	2004	2 Additional meaning of non-canonical syntax: discourse relations The meaning of a multi-utterance text is composed not only of the meaning of each individual utterance but also of the relations holding between the utterances	0	These relations have syntactic aspects, such that single utterances can be grouped together and combined into segments recursively and are often modeled as a hierarchical tree structure <TREF>Grosz and Sidner, 1986</TREF>; <REF>Webber et al , 1999</REF>	0	Discourse relations may also have a semantic or meaning component; this property, when treated in the literature, is often referred to as coherence, subject matter, or rhetorical relations <REF>Kehler, 2002</REF>; <REF>Halliday, 1985</REF>; <REF>Mann and Thompson, 1988</REF>	0	The use of an utterance with non-canonical word order helps hearers make inferences about both the syntactic and semantic properties of discourse relations between the utterance and the rest of the discourse	0	0	0
C00-2130	J86-3001	2000	See <REF>Vieira, 1998</REF> for a discussion of tile other heuristics used by the sy> tonl	0	Segmentalion In l i IE-spans limited MI,NTS t1131 lllay general, discourse entities have to pramatical ly delermined,Slit; be nested see, eg, <REF>Rcichman, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Fox, 1987</REF>	0	Eg, in our corpus we found that about 10 of direct analhoric detinite descriptions have more than one possible antecedent if segmentalion is nol taken into account <REF>Vieira and Poesio, 1999</REF>	0	Recognizing the hierarchical structure of segments in a text is, howevm; still pretty umch an open problem, kS it involves reasoning about intentions; 2 better results have been achieved on the simpler task of chtlnking the text into approximate segments, generally by means of lexical density measures <REF>Hearst, 1997</REF> In fact, the lnethods Io limit the lifespan of discourse entity we considered for our system were even simplel: One type of heuristics we looked at are window-based techniques, ie, considering as potential antecedents only the discourse entities within fixed-size windows of previous sentences, allowing however for some discourse entities to take a longer life span: we call this method LOOSE SEGMENTATION	0	0	0
C04-1075	J86-3001	2004	Approaches to coreference resolution usually rely on a set of factors which include gender and number agreements, c-command constraints, semantic consistency, syntactic parallelism, semantic parallelism, salience, proximity, etc These factors can be either constraints which discard invalid ones from the set of possible candidates such as gender and number agreements, c-command constraints, semantic consistency, or preferences which gives more preference to certain candidates and less to others such as syntactic parallelism, semantic parallelism, salience, proximity	0	While a number of approaches use a similar set of factors, the computational strategies the way antecedents are determined, ie the algorithm and formula for assigning antecedents may differ, ie from simple co-occurrence rules <REF>Dagan and Itai 1990</REF> to decision trees <REF>Soon, Ng and Lim 2001</REF>; <REF>Ng and Cardie 2002</REF></REF> to pattern induced rules <REF>Ng and Cardie 2002</REF></REF> to centering algorithms <TREF>Grosz and Sidner 1986</TREF>; <REF>Brennan, Friedman and Pollard 1987</REF>; <REF>Strube 1998</REF>; <REF>Tetreault 2001</REF>	0	This paper proposes a simple constraint-based multi-agent system to coreference resolution of general noun phrases in unrestricted English text	0	For a given anaphor and all the preceding referring expressions as the antecedent candidates, a common constraint agent is first presented to filter out invalid antecedent candidates using various kinds of general knowledge	0	0	0
J02-3003	J86-3001	2002	2 Issues and Insights in Anaphora Resolution 21 The BFP Algorithm Brennan, Walker-<REF>Friedman, and Pollard 1987</REF> were the first to use the centering model as the basis for an anaphora resolution algorithm	0	The centering model <TREF>Grosz and Sidner 1986</TREF>; <REF>Grosz, Joshi, and Weinstein 1983</REF> makes the following assumptions: 1	0	A discourse segment consists of a sequence of utterances, U 1,, U n 2	0	For each utterance, a ranked list of evoked discourse entities is constructed, designated as the Cf list	0	0	0
J02-3003	J86-3001	2002	The semantic/pragmatic focusing account runs into the type of problem demonstrated in 4, where the preferred interpretation for he is John, that is, the structural subject, independent of semantic/pragmatic factors	0	3 In such discourses it seems that a structural account is at play in the sense of Grosz and Sidner 1986	0	4 a John criticized Bill	0	b Next, he insulted Susan	0	0	0
J02-3003	J86-3001	2002	3	0	The Proposal: Aposynthesis 31 Outline of the Discourse Model We assume that the discourse is organized hierarchically in linear and embedded segments as specified in <TREF>Grosz and Sidner 1986</TREF>	0	We also adopt the centering view of local-discourse coherence to model topic continuity in discourse	0	According to the centering model each segment consists of a sequence of utterances	0	0	0
W04-2504	J86-3001	2004	Discourse transitions also correspond to the intentional, informational, and presentational perspectives of discourse	0	Intentional transitions are closely related to Grosz and Sidners dominance and satisfaction precedence relations, which are more relevant to plan-based discourse <TREF>Grosz and Sidner, 1986</TREF>	0	Here we focus on informational transitions and presentational transitions that are more relevant to QA systems since they are targeted for information exchange	0	Informational transitions are mainly centered around Topics of questions	0	0	0
W04-2504	J86-3001	2004	In a fully interactive question answering environment, instead of asking questions, a user may need to reply to a clarification question prompted by the system or may need to simply ask for a confirmation	0	Therefore, it is important to capture the intention from the user <TREF>Grosz and Sidner 1986</TREF>	0	The informational perspective relates to the information content of a question, in particular, the topic and the focus based on the semantics of the content	0	In addition to the intentional and informational aspects, there is also a presentational aspect of discourse that relates to both the input modality ie , questions and the output modality ie , answers	0	0	0
P97-1011	J86-3001	1997	Discourse cues are words or phrases, such as because, first, and although, that mark structural and semantic relationships between discourse entities	0	They play a crucial role in many discourse processing tasks, including plan recognition <REF>Litman and Allen, 1987</REF>, text comprehension <REF>Cohen, 1984</REF>; <REF>Hobbs, 1985</REF>; <REF>Mann and Thompson, 1986</REF>; Reichman-<REF>Adar, 1984</REF>, and anaphora resolution <TREF>Grosz and Sidner, 1986</TREF>	0	Moreover, research in reading comprehension indicates that felicitous use of cues improves comprehension and recall <REF>Goldman, 1988</REF>, but that their indiscriminate use may have detrimental effects on recall <REF>Millis, Graesser, and Haberlandt, 1993</REF>	0	Our goal is to identify general strategies for cue usage that can be implemented for automatic text generation	0	0	0
P97-1011	J86-3001	1997	1 RDA is a scheme devised for analyzing tutorial explanations in the domain of electronics troubleshooting	0	It synthesizes ideas from <TREF>Grosz and Sidner, 1986</TREF> and from RST <REF>Mann and Thompson, 1988</REF>	0	Coders use RDA to exhaustively analyze each explanation in the corpus, ie, every word in each explanation belongs to exactly one element in the analysis	0	An explanation may consist of multiple segments	0	0	0
P97-1011	J86-3001	1997	Other hypotheses about cue usage derive from work on discourse coherence and structure	0	Previous research <REF>Hobbs, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Schiffrin, 1987</REF>; <REF>Mann and Thompson, 1988</REF>; <REF>Elhadad and McKeown, 1990</REF>, which has been largely descriptive, suggests factors such as structural features of the discourse eg , level of embedding and segment complexity, intentional and informational relations in that structure, ordering of relata, and syntactic form of discourse constituents	0	Moser and Moore 1995; 1997 coded a corpus of naturally occurring tutorial explanations for the range of features identified in prior work	0	Because they were also interested in the contrast between occurrence and non-occurrence of cues, they exhaustively coded for all of the factors thought to contribute to cue usage in all of the text	0	0	0
A00-1005	J86-3001	2000	Although these systems have been quite successful, they use detailed models of the domain and therefore cannot be used for diverse applications such as the ones required for customer service centers	0	Other related work on dialogue include <REF>Carberry, 1990</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Reichman, 1981</REF>	0	2	0	PartslD: A System for Identification of Parts for Medical Systems Initially, we were approached by the medical systems business of our company for help in reducing the number of calls handled by human operators at their call center	0	0	0
N07-1003	J86-3001	2007	Block b24 is an interruption segment in which conversants switched their conversation to the interruption game	0	No claim is made that the game and card blocks are discourse segments according to Grosz and Sidners definition 1986	0	4 Defining Initiative Conflicts An initiative conflict occurs when a conversants attempt to show initiative fails because someone else is showing initiative at the same time	0	<REF>Following Whittaker and Stenton 1988</REF>, we use utterance tags to determine whether an utterance shows initiative: forward functions show initiative while others do not	0	0	0
N07-1003	J86-3001	2007	To determine whether a group of utterances form a discourse segment, we took into account whether there exists a shared goal introduced by one of the conversants cf	0	<TREF>Grosz and Sidner, 1986</TREF>	0	32 The MTD Corpus The MTD corpus contains dialogues in which a pair of participants play two games via conversation: an ongoing 18 game that takes a relatively long time to finish and an interruption game that can be done in a couple turns but has a time constraint	0	Both games are done on computers	0	0	0
H05-1031	J86-3001	2005	Our hypothesis is that features capturing the frequency and syntactic and lexical forms of references are suf cient to infer the desired cognitive model	0	Intuitively, pronominalization indicates that an entity was particularly salient at a speci c point of the discourse, as has been widely discussed in attentional status and centering literature <TREF>Grosz and Sidner, 1986</TREF>; <REF>Gordon et al , 1993</REF>	0	Modi ed noun phrases with apposition, relative clauses or premodi cation can also signal different status	0	In addition to the syntactic form features, we used two months worth of news articles collected over the web and independent of the DUC collection we use in our experiments here to collect unigram and bigram lexical models of rst mentions of people	0	0	0
J98-4001	J86-3001	1998	The use of Contributes here refers to a relation between actions	0	<TREF>Grosz and Sidner 1986</TREF> also describe a contributes relation between DSPs that is the inverse of the dominates relation	0	In addition, we have been using contributes informally to refer to the inverse of a subsidiary relationship between plans	0	546 Lochbaum A Collaborative Planning Model A recipe for c is comprised of a set of immediate constituent acts ill,,,fin and constraints pl,, pro	0	0	0
J98-4001	J86-3001	1998	712 Recognizing Relationships between Discourse Segments	0	Once an OCP recognizes the initiation of a new discourse segment, it must determine the relationship of that segments DSP to the other DSPs underlying the discourse <TREF>Grosz and Sidner 1986</TREF>	0	In our model, relationships between SharedPlans provide the basis for determining the corresponding relationships between DSPs	0	An OCP must determine how the SharedPlan used to model a segments DSP is related to the other SharedPlans underlying the discourse	0	0	0
J98-4001	J86-3001	1998	Because each utterance of a discourse segment contributes some information towards the purpose of that segment, the segments DSP may not be completely determined until the last utterance of the segment	0	However, as <TREF>Grosz and Sidner 1986</TREF> have argued, the OCP must be able to recognize initially at least a generalization of the DSP so that the proper moves of attentional state can be made	0	Although CDRA provides a limited method of recognizing new segments and their purposes, it does conform to this aspect of Grosz and Sidners theory	0	In particular, the initial purpose of a segment, as recognized by CDRA, is quite generally specified; it consists only of the intention that the agents form a SharedPlan	0	0	0
J98-4001	J86-3001	1998	71 Recognizing Intentional Structure 711 Recognizing Discourse Segments and their Purposes	0	In their paper on discourse structure, Grosz and Sidner give several examples of the types of intentions that could serve as DSPs <TREF>Grosz and Sidner 1986</TREF>, 179: 1	0	Intend that some 2	0	Intend that some 3	0	0	0
J98-4001	J86-3001	1998	This intention is held by the agent who initiates the segment	0	<REF>Following Grosz and Sidner 1986</REF>, we will refer to that agent as the ICP for initiating conversational participant; the other participant is the OCP	0	DSPs are thus represented as intentions of the form IntThICP, FSPICP, OCP, fl in our model	0	Relationships between DSPs derive from relationships between the corresponding SharedPlans	0	0	0
J98-4001	J86-3001	1998	DSPs that do not involve SharedPlans would thus seem to present a problem for our model; however, many such DSPs may still be explained in terms of SharedPlans	0	For example, consider DSPs of the form Intend that some agent intend to perform some physical task, as proposed by Grosz and Sidner 1986, 179	0	It is possible to explain this type of DSP in terms of the IntTo requirement of the FSP definition Clause 2a in Figure 5	0	According to that requirement, each of the single-agent acts in the agents recipe must be intended by one of the two collaborating agents	0	0	0
J98-4001	J86-3001	1998	Before presenting these analyses, however, we first introduce some terminology that will be used throughout the paper	0	A discourse is composed of discourse segments much as a sentence is composed of constituent phrases <TREF>Grosz and Sidner 1986</TREF>	0	The segmental structure of the sample dialogues is indicated by the bold rule grouping utterances into segments	0	Whereas the term discourse segment applies to all types of discourse, the term subdialogue is reserved for segments that occur within dialogues	0	0	0
J98-4001	J86-3001	1998	If additionally the OCP is able to ascribe the various mental attitudes missing from the SharedPlan that corresponds to that segment, then the OCP has further evidence for the segment boundary	0	These mental attitudes may be ascribed on the basis of those of the OCPs beliefs that are in accord with the mental attitudes comprising the SharedPlan <REF>Pollack 1986a</REF>; <REF>Grosz and Sidner 1990</REF>	0	712 Recognizing Relationships between Discourse Segments	0	Once an OCP recognizes the initiation of a new discourse segment, it must determine the relationship of that segments DSP to the other DSPs underlying the discourse <TREF>Grosz and Sidner 1986</TREF>	0	0	0
J98-4001	J86-3001	1998	In our model, a segments focus space contains a DSP of the form IntThICP, FSP ICP, OCP, fl	0	The operations on the focus space stack depend upon subsidiary rela561 Computational Linguistics Volume 24, Number 4 tionships between SharedPlans in the same way that <TREF>Grosz and Sidner 1986</TREF> describe the operations as depending upon DSP relationships	0	As each SharedPlan corresponding to a discourse segment is completed, the segments focus space is popped from the stack	0	Only those SharedPlans in some space on the stack are candidates for subsidiary relationships	0	0	0
J98-4001	J86-3001	1998	In each case, an agent must recognize both the purpose of an embedded subdialogue and the relationship of that purpose to the purposes associated with the preceding discourse	0	These purposes and their interrelationships form the intentional structure of the discourse <TREF>Grosz and Sidner 1986</TREF>	0	In this paper, we present a computational model for recognizing intentional structure and utilizing it in discourse processing	0	Our model is based on the collaborative planning framework of SharedPlans <REF>Grosz and Sidner 1990</REF>; <REF>Lochbaum, Grosz, and Sidner 1990</REF>; <REF>Grosz and Kraus 1993, 1996</REF>	0	0	0
J98-4001	J86-3001	1998	4	0	Grosz and Sidners Theory of Discourse Structure According to Grosz and Sidners 1986 theory, discourse structure is comprised of three interrelated components: a linguistic structure, an intentional structure, and an attentional state	0	The linguistic structure is a structure that is imposed on the utterances themselves; it consists of discourse segments and embedding relationships among them	0	The linguistic structure of the sample dialogues in Section 1 is indicated by the bold rule grouping utterances into segments	0	0	0
J98-4001	J86-3001	1998	agent know some property of an object	0	Intentions such as these, as well as segment beginnings and endings, might be recognized on the basis of linguistic markers, utterance-level intentions, or knowledge about actions and objects in the domain of discourse <TREF>Grosz and Sidner 1986</TREF>	0	In our model, DSPs take the form IntThICP, FSPICP, OCP,fl	0	This type of DSP addresses several problems with the above examples--problems that motivated Grosz and Sidners 1990 subsequent work on SharedPlans--namely the case of one agent intending another to do something and the so-called master/slave assumption	0	0	0
J98-4001	J86-3001	1998	In this paper, we have presented a SharedPlan model for recognizing DSPs and their interrelationships	0	We now show that this model satisfies the requirements set out by Grosz and Sidners 1986 theory of discourse structure	0	We first discuss the process by which intentional structure is recognized	0	Next, we discuss the way in which intentional structure interacts with the attentional state component of discourse structure	0	0	0
J98-4001	J86-3001	1998	The agent must determine whether the utterance begins a new segment of the discourse, completes the current segment, or contributes to it	0	The intentional structure of the discourse, comprised of discourse segment purposes and their interrelationships, plays a central role in this process <TREF>Grosz and Sidner 1986</TREF>	0	In this paper, we provide a computational model for recognizing intentional structure and utilizing it in discourse processing	0	The model is based on the collaborative planning framework of SharedPlans <REF>Grosz and Kraus 1996</REF>	0	0	0
J98-4001	J86-3001	1998	The use of the SharedPlan stack S in the augmentation process of Figure 13 reflects the operations of the focus space stack	0	73 The Contextual Role of Intentional Structure An utterance of a discourse can either begin a new segment of the discourse, complete the current segment, or contribute to it <TREF>Grosz and Sidner 1986</TREF>	0	Each of these possibilities is modeled by a separate case within the augmentation process given in Figure 13	0	The initiation and completion of discourse segments was discussed in Section 71	0	0	0
J98-4001	J86-3001	1998	People engage in dialogues for a reason	0	Their intentions guide their behavior and their conversational partners recognition of those intentions aids in the latters understanding of their utterances <REF>Grice 1969</REF>; <REF>Sidner 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	In this paper, we present a computational model for recognizing the intentional structure of a discourse and utilizing it in discourse processing	0	The embedded subdialogues in Figures 1 through 3 illustrate a variety of intentions that a person or computer system must recognize to respond effectively to its conversational partner	0	0	0
J98-4001	J86-3001	1998	Reasoning with Intentional Structure Intentional structure plays a central role in discourse processing	0	For each utterance of a discourse, an agent must determine whether the utterance begins a new segment of the discourse, completes the current segment, or contributes to it <TREF>Grosz and Sidner 1986</TREF>	0	If the utterance begins a new segment of the discourse, the agent must recognize the DSP of that segment, as well as its relationship to the other DSPs underlying the discourse and currently in focus	0	If the utterance completes the current segment, the agent must come to believe that the DSP of that segment has been satisfied	0	0	0
J00-3003	J86-3001	2000	In addition, we should model more of the nonlocal aspects of discourse structure, despite our negative results so far	0	For example, a context-free discourse grammar could potentially account for the nested structures proposed in <TREF>Grosz and Sidner 1986</TREF>	0	1 The standard n-gram models for DA discrimination with lexical cues are probably suboptimal for this task, simply because they are trained in the maximum likelihood framework, without explicitly optimizing discrimination between DA types	0	This may be overcome by using discriminative training procedures <REF>Warnke et al 1999</REF>; <REF>Ohler, Harbeck, and Niemann 1999</REF>	0	0	0
J94-2004	J86-3001	1994	Examples are evidently, seemingly, must have, appear to be, as if, as though, and look, as in He looked like he might cry 63 Hedges, eg, adverbs such as more or less and sort of when used as modifiers of adjectives and adverbs, as in It was more or less green, or as adverbials <REF>Quirk et al 1985</REF></REF>, as in The man more or less held a large stretch of the border 64 Evidentials that address expectations 641 Signal that expectations have been met, such as of course when used as an emphasizer subjunct <REF>Quirk et al 1985</REF></REF> as in John of course sat down 642 Signal that expectations have not been met	0	Examples are adverbs such as just, merely, and only when used as attitude diminishers <REF>Quirk et al 1985</REF></REF>, as in He just sat and drank it was expected that he would do something more than sit and drink 7 Adverbials that are conjuncts, which connect units of discourse <REF>Quirk et al 1985</REF></REF> ie , cue phrases; <REF>Reichman 1985</REF>, <TREF>Grosz and Sidner 1986</TREF>, <REF>Cohen 1987</REF>	0	Examples are first, in addition, for instance, on the other hand, after all, anyway, and yet as in Yet, they were the pride of the family 8 Conditional clauses 9 Comparative like, as in They followed her like acolytes behind a goddess 10 Habitual sentences, such as Gus himself often joked about it 11 The past perfective, but only in the main verb phrase 12 The progressive, but only in the main verb phrase the progressive, can typically serve only to continue a characters POV and only within a paragraph see Ehrlich 1987 for an analysis of why this is so for the progressive; 2 stronger ones can continue a characters POV after a paragraph break, or resume a characters POV within a paragraph; 3 still stronger ones, such as evidentials and sentence fragments, can resume the last subjective characters POV or initiate the last active characters just as long as they are expected subjective characters; and 4 the strongest subjective elements, such as exclamations and questions, are always subjective, even when there is not an expected subjective character to whom to attribute the 259 Computational Linguistics Volume 20, Number 2 sentence	0	The sets of text situations corresponding to 1-4 are: lts 2ts 3ts 4ts continuing-subjective broken-subjective, interrupted-subjective presubjective-active, postsubjective-nonactive, postsubjective-active presubjective-nonactive Expectations for a subjective sentence are strongest in situation lts and weakest in situation 4ts, so the algorithm takes even the weakest potential subjective elements to be subjective in lts, but only the strongest ones to be subjective in 4ts	0	0	0
W00-0301	J86-3001	2000	1 Collaborative Agents The underlying premise of the Collageff M for Collaborative agent project is that software agents, when they interact with people, should be governed by the same principles that govern human-to-human collaboration	0	To determine the principles governing human collaboration, we have relied on research in computational linguistics on collaborative discourse, specifically within the SharedPlan framework of Grosz and Sidner 1986, 1990 <REF>Grosz and Kraus, 1996</REF>, <REF>Lochbaum, 1998</REF>	0	This work has provided us with a computationally-specified theory that has been empirically validated across a range of User Agent communicate l Application Figure 1: Collaborative interface agent paradigm	0	human tasks	0	0	0
W97-1201	J86-3001	1997	The latter work examines the placement of accents, as constrained by the interaction of discourse, surface structure and lexical form	0	Pitch accent placement on pronouns as well as on explicit forms in the subject position motivate theory that describes new and givenness in terms of a hierarchical discourse structure <TREF>Grosz and Sidner 1986</TREF>	0	Again, the implications of this theoretical framework can be extracted as features for generating conditional probabilities of prosodic events, with reference to the theory	0	One such feature could be an annotation of discourse segmentation in the input text	0	0	0
W04-2906	J86-3001	2004	Formal written discourse signals a hierarchical, tree-based discourse structure explicitly by the division of the text into chapters, sections, paragraphs, and sentences	0	This structure, in turn, identi es domains for interpretation; many systems for anaphora resolution rely on some notion of locality <TREF>Grosz and Sidner, 1986</TREF>	0	Similarly, this structure represents topical organization, and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic	0	Unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse	0	0	0
W90-0118	J86-3001	1990	Finally, relations such as Topic and Conclusion appear to be due to conventions governing writing style which direct focus of attention	0	<TREF>Grosz  Sidner 1986</TREF> made similar criticisms from the standpoint of characterizing discourse coherence	0	They suggested that each rhetorical relation combines domain information with certain general relations between propositions, between actions, and between intentions	0	Implicit Features Unaccounted For	0	0	0
W08-1103	J86-3001	2008	We anticipate that the user will ask follow-up questions after receiving the initial summary	0	Therefore, it is appropriate to close the initial summary with propositions from the computational class so that the whole graphic is in the users focus of attention <TREF>Grosz and Sidner, 1986</TREF>	0	Thus we hypothesize that a good ordering of propositions in the initial summary is the message-related class, the specific class, and finally the computational class	0	This produces a partial ordering of the propositions to be included in the summary	0	0	0
W03-2114	J86-3001	2003	 been implemented	0	4 Top-Level Context Management	0	 The approach to dialogue modeling we have imple-	0	 mented is based on the theory of dialogue games	0	0	0
C00-1083	J86-3001	2000	Therefore, these studies are not concerned with dlanging the content of the discourse to match the users view	0	In some studies of dialogue management <REF>Rich and Sidner, 1998</REF>; Stent et M , 1999, the state of the dialogue is represented using Grosz and Sidners framework <TREF>Grosz and Sidner, 1986</TREF>	0	We also adopt this theory in our dialogue management mechanism	0	However, they do not keep track of the users viewpoint information as a part of the dialogue state because they were not concerned with dialogue management in virtual environments	0	0	0
W98-0317	J86-3001	1998	Therefore, for dialogue generation, we must identify the determining factors of organization cue phrases and select the cue phrases appropriately	0	In previous studies that have investigated the relationship between cue phrases and the types of structural change eg pop, push, the taxonomies of cue phrases have been presented <TREF>Grosz and Sidner, 1986</TREF>; <REF>Cohen, 1984</REF>; <REF>Schiffrin, 1987</REF>	0	These taxonomies are, however, not sufficient for generation because the correspondence between cue phrase and structural change is many-to-many quite often	0	For example, now,and, and next are all classified as the category signaling push in attentional state	0	0	0
W98-0317	J86-3001	1998	32 Annotation of discourse structure As the basis for examining the relationship between cue phrase and dialogue structure, discourse segment boundary and the level of embedding of the segments were annotated in each dialogue	0	We define discourse segment or simply segment as chunks of utterances that have a coherent goal <TREF>Grosz and Sidner, 1986</TREF>; <REF>Nakatani et al , 1995</REF>; <REF>Passonneau and Litman, 1997</REF>	0	The annotation of hierarchical relations among segments was based on <REF>Nakatani et al , 1995</REF>	0	Figure 1 shows an example from the annotated dialogue corpus	0	0	0
W98-0317	J86-3001	1998	2Task structure: Information that estimates the complexity of succeeding dialogue	0	3<REF>Clark 1997</REF> presents a term discourse topic as concept equivalent to focus space in <TREF>Grosz and Sidner, 1986</TREF>, and call their transition discourse transition	0	For example, push is defied as the transition to the sub topic, and next is defined as the transition to the same level proceeding topic	0	102 factor Discourse structure Task structure Dialogue structure Table 1: The learning features feature name Embedding Fla:e l,lace2 Hes-cue les-cue2 D-trans T-hmraxchy ubgoal Fre-exchange Fs-cue values integer mteger mteger nil, ord, Oh, con, chord, conord, conch, other nil, ord, C1, Cou, cnord conord, conch, other pop, push, next, m-pop, A integer mteger conf, req, inf, quest, ui-conf, ui-req, tti-inf, ui-quest, NA nil, oral, ch, con, chord, conord, conch, other Task-hierarchy T-hierarchy The number of goal-subgoal relations from the current goal to primitive actions	0	0	0
W98-0317	J86-3001	1998	Cue phrases are words and phrases, such as first, and, now, that connect discourse spans and add structure to the discourse both in text and dialogue	0	They signal topic shifts and changes in attentional state <TREF>Grosz and Sidner, 1986</TREF> as well as expressing the relation between the individual units of discourse <REF>Moore, 1995</REF>; R<REF>Ssner and Stede, 1992</REF>	0	In this study, we focus on the former kind of cue phrases, organization cue phrases that signal the structural organization of discourse	0	In instruction dialogue, the organization cue phrases play a crucial role in controlling dialogue and making the material easy to understand	0	0	0
W98-0317	J86-3001	1998	There are 31 cue phrases that occur more than five times	0	As the result of classifying these 31 cue phrases based on the classification of Japanese connectives <REF>Ichikawa, 1978</REF>; <REF>Moriyama, 1997</REF> and cue phrase classification in Enghsh <TREF>Grosz and Sidner, 1986</TREF>; <REF>Cohen, 1984</REF>; <REF>Knott and Dale, 1994</REF>; <REF>Moser and Moore, 1995b</REF>, 20 cue phrases, which occurred total of 848 times, were classified into three classes: changeover, such as soredeha, deha now, now then in English, conjunctive, such as sorede, de and, and then, and ordinal, such as mazu, tsugini first, next	0	Besides these simple cue phrases, there are composite cue phrases such as soredeha-tsugini now first	0	Note that meaning and the usage of each of these Japanese cue phrases does not completely correspond to those of the English words and phrases in parentheses	0	0	0
W98-0317	J86-3001	1998	The reason that we examine these three factors is as follows	0	First, discourse structure is indispensable for selecting cue phrase as claimed in previous studies <TREF>Grosz and Sidner, 1986</TREF>; <REF>Cohen, 1984</REF>; <REF>Eugenio et al , 1997</REF>	0	We examine some features concerning this factor such as the global structure of discourse and structural shifts in discourse	0	Second, while the discourse structure provides information about the preceding discourse, <REF>Cawsey 1993</REF> claimed that information about the succeeding discourse eg , length and complexity is also necessary in order to select cue phrases dynamically in dialogue systems	0	0	0
C98-2130	J86-3001	1998	2	0	Broadcast News Analysis Human communication is characterized by distinct discourse structure <TREF>Grosz and Sidner 1986</TREF> which is used lbr a variety of purposes including managing interaction between participants, mitigating limited attention, and signaling topic shifts	0	In processing genre such as technical or journalistic texts, programs can take advantage of explicit discourse cues eg, the first, the most important to perform tasks such as summarization <REF>Paice 1981</REF>	0	Our initial inability to segment topics in closed caption news text using thesaurus based subject assessments <REF>Liddy and Myaeng 1992</REF> motivated an investigation of explicit turn taking signals eg, anchor to reporter handoff	0	0	0
J99-1001	J86-3001	1999	Our recognition algorithm captures the kinds of evidence identified in Section 3: 1 evidence provided by world knowledge, contextual knowledge, and the surface form of the utterance indicating that the applicability conditions for an e-action are satisfied, and 2 linguistic evidence from clue words suggesting a generic discourse action	0	<TREF>Grosz and Sidner 1986</TREF> claim that when evidence is available from one source, less evidence should be required from others	0	Thus, if there is evidence indicating that the applicability conditions for a discourse act hold, then less linguistic evidence suggesting the discourse act should be required	0	This is the case for interpreting 9 repeated below as an expression of doubt	0	0	0
J99-1001	J86-3001	1999	For example, although it does not generally arise in the kind of interactive dialogues that we are studying, world knowledge in the form of stereotypical beliefs might be used as evidence that a speaker believes that a hearer has some belief in the doubted proposition Pdoubt 4	0	The Process <REF>Model Grosz and Sidner 1986</REF> claim that a robust model of understanding must use multiple knowledge sources in order to recognize the complex relationships that utterances have to one another	0	We have developed an algorithm that combines linguistic, world, and contextual knowledge, such as that identified in Section 3, in order to recognize complex discourse acts, including one kind of expression of doubt	0	Linguistic knowledge consists of clue words and the surface form of the utterance; world knowledge includes a set of stereotypical beliefs that users generally hold and recipes for performing discourse acts; and contextual knowledge consists of a model of the users beliefs 8 Carberry and Lambert Modeling Negotiation Subdialogues acquired from the preceding dialogue, the current structure of the discourse, the existing focus of attention that aspect of the task on which the participants attention is currently centered, and the relative salience degree of prominence of propositions in the discourse	0	0	0
J99-1001	J86-3001	1999	Thus, as the conversation continues, only one proposition would remain open for rejection: the proposition that Dr Smith is teaching CS360	0	This claim is supported by a combination of 1 the stack paradigm <REF>Polanyi 1986</REF>; <REF>Reichman 1978</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Litman and Allen 1987</REF>, which treats topic structure as following a stack-like discipline; 2 focusing heuristics <REF>McKeown 1983</REF> that suggest that if a speaker has more to say about a topic, then he should do so before moving back to a topic deeper on the stack; and 3 the notion of implicit acceptance discussed in Section 46 that argues that passing up the opportunity to reject an assertion in a collaborative dialogue communicates acceptance of it	0	Second, contextual knowledge orders propositions according to their relative salience in the current dialogue	0	This salience can be used to arbitrate among discourse acts for which there is equivalent evidence	0	0	0
J99-1001	J86-3001	1999	7	0	Other Related Work 71 Grosz and Sidners Theory of Discourse <REF>Processing Grosz and Sidner 1986</REF> postulated a theory of discourse structure that included linguistic, intentional, and attentional components, and they argued that the dominance and satisfaction-precedes relationships between discourse segments must be identified in order to determine discourse structure	0	They also noted three kinds of information that contribute to determining the purposes of discourse segments and their relationship to one another: linguistic markers, utterance-level intentions, and general knowledge about actions and objects	0	<REF>Subsequently Lochbaum 1994</REF> developed an algorithm based on Grosz and Sidners SharedPlan model <REF>Grosz and Sidner 1990</REF> that recognizes discourse segment purposes and discourse structure	0	0	0
J99-1001	J86-3001	1999	31 Linguistic Knowledge 311 Evidence for a Generic Discourse Act	0	A number of researchers <REF>Reichman 1978, 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Polanyi 1986</REF>; <REF>Cohen 1987</REF>; <REF>Hirschberg and Litman 1987</REF>; <REF>Litman and Allen 1987</REF>; <REF>Schiffrin 1987</REF>; <REF>Hinkelman 1989</REF>; <REF>Litman and Hirschberg 1990</REF>; <REF>Knott and Dale 1994</REF>; <REF>Knott and Mellish 1996</REF>; <REF>Marcu 1997</REF> have investigated the use in discourse of special words and phrases such as but, anyway, and by the way	0	They found that these clue words, or discourse markers, have a number of different functions, including indicating the role of an utterance in the dialogue, conveying the relationship between utterances, suggesting shifts in focus of attention, conveying the structure of the discourse, etc Consider again the dialogue shown in Figure 1	0	If EA had followed 7-8 with 9a 9a EA: Isnt Architecture one of our required courses	0	0	0
A92-1010	J86-3001	1992	The satellite is more easily replaced than the nucleus because of the nucleus central role in the thematical progression of the discourse	0	Even though there are some critics questioning the use of rhetorical relations in discourse structure theory <TREF>Grosz and Sidner, 1986</TREF> we use 75 rl /rst-nonvolitional-result :domain el/ existence :domain cl / concept :number mass :process r2/show :saying cl :speechact denial :tense present :range a/ascription :domain c2 / capacity :owned-by p/pres-form :range ex / exceeded :tense present Figure 5 : SPL-Plan for There are concepts that are not shown, because the presentation-forms capacity is exceeded	0	RST relations because they proved to be quite useful when we link portions of information	0	In KOMET/Penman, RST-relations are treated the same way as other relations, eg ascription which we used in the plan shown in Figure 4	0	0	0
J97-1003	J86-3001	1997	7 For example, the words residential and apartment both index the same thesaural category and can thus be considered to be in a coherence relation with one another	0	The chains are used to structure texts according to the attentional/intentional theory of discourse structure <TREF>Grosz and Sidner 1986</TREF> discussed above	0	The extent of the lexical chains is assumed to correspond to the extent of a segment	0	The algorithm also incorporates the notion of chain returns--repetition of terms after a long hiatus--to complete an intention that spans over a digression	0	0	0
J97-1003	J86-3001	1997	32 Relationship to Segmentation in Hierarchical Discourse Models Much of the current work in empirical discourse processing makes use of hierarchical discourse models, and several prominent theories of discourse assume a hierarchical segmentation model	0	Foremost among these are the attentional/intentional structure of <TREF>Grosz and Sidner 1986</TREF> and the Rhetorical Structure Theory of <REF>Mann and Thompson 1987</REF>	0	The building blocks for these theories are phrasal or clausal units, and the targets of the analyses are usually very short texts, typically one to three paragraphs in length	0	5 Many problems in discourse analysis, such as dialogue generation and turntaking <REF>Moore and Pollack 1992</REF>; <REF>Walker and Whittaker 1990</REF>, require fine-grained, hierarchical models that are concerned with utterance-level segmentation	0	0	0
P04-1049	J86-3001	2004	3 Coherence-based summarization revisited This section will discuss in more detail the data structures we used to represent discourse structure, as well as the algorithms used to calculate sentence importance, based on discourse structures	0	31 Representing coherence structures 311 Discourse segments Discourse segments can be defined as nonoverlapping spans of prosodic units <REF>Hirschberg  Nakatani 1996</REF>, intentional units <TREF>Grosz  Sidner 1986</TREF>, phrasal units <REF>Lascarides  Asher 1993</REF>, or sentences <REF>Hobbs 1985</REF>	0	We adopted a sentence unit-based definition of discourse segments for the coherence-based approach that assumes non-tree graphs	0	For the coherence-based approach that assumes trees, we used <REF>Marcu 2000</REF>s more fine-grained definition of discourse segments because we used the discourse trees from Carlson et al	0	0	0
P98-2163	J86-3001	1998	The use of interpersonal relations is predicated mainly on the interests, beliefs, and attitudes of addressee and/or author	0	To deal with this problem, we must incorporate the notion of intentional structure and focus space structure <TREF>Grosz and Sidner, 1986</TREF>	0	Since we have focused on te-linkage in this paper, we need not to consider how clauses are combined	0	However, to detect the discourse structure, we need to extend the method so as to deal with the relations between sentences	0	0	0
P95-1015	J86-3001	1995	Many have argued that discourse has a global structure above the level of individual utterances, and that linguistic phenomena like prosody, cue phrases, and nominal reference are partly conditioned by and reflect this structure cf	0	<REF>Grosz and Hirschberg, 1992</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Hirschberg and Grosz, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Hirschberg and Pierrehumbert, 1986</REF>; <REF>Hobbs, 1979</REF>; <REF>Lascarides and Oberlander, 1992</REF>; <REF>Linde, 1979</REF>; <REF>Mann and Thompson, 1988</REF>; <REF>Polanyi, 1988</REF>; <REF>Reichman, 1985</REF>; <REF>Webber, 1991</REF>	0	However, an obstacle to exploiting the relation between global structure and linguistic devices in natural language systems is that there is too little data about how they constrain one another	0	We have been engaged in a study addressing this gap	0	0	0
P95-1015	J86-3001	1995	Grosz and Hirschbergs work also used the classification and regression tree system CART <REF>Breiman et al , 1984</REF> to automatically construct and evaluate decision trees for classifying aspects of discourse structure from intonational feature values	0	<REF>Morris and Hirst 1991</REF> structured a set of magazine texts using the theory of <TREF>Grosz and Sidner, 1986</TREF>, developed a thesaurus-based lexical cohesion algorithm to segment text, then qualitatively compared their segmentations with the results	0	<REF>Hearst 1994</REF> presented two implemented segmentation algorithms based on term repetition, and compared the boundaries produced to the boundaries marked by at least 3 of 7 subjects, using information retrieval metrics	0	<REF>Kozima 1993</REF> had 16 subjects segment a simplified short story, developed an algorithm based on lexical cohesion, and qualitatively compared the results	0	0	0
P95-1015	J86-3001	1995	2 Discourse Segmentation 21 Related Work Segmentation has played a significant role in much work on discourse	0	The linguistic structure of Grosz and Sidners 1986 tri-partite discourse model consists of multi-utterance segments whose hierarchical relations are isomorphic with intentional structure	0	In other work eg , <REF>Hobbs, 1979</REF>; <REF>Polanyi, 1988</REF>, segmental structure is an artifact of coherence relations among utterances, and few if any specific claims are made regarding segmental structure per se	0	Rhetorical Structure Theory RST <REF>Mann and Thompson, 1988</REF> is another tradition of defining relations among utterances, and informs much work in generation	0	0	0
C96-1001	J86-3001	1996	C96-1001:289	0	Discovering the Sounds of Discourse Structure Extended Abstract Barbara J Grosz Division of Engineering and Applied Sciences Harvard University 33 Oxford Street Cambridge, MA 02138 USA groszeecsharvardedu It is widely accepted that discourses are composed of segments and that the recognition of segment boundaries is essential to a determination of discourse meaning <TREF>Grosz and Sidner, 1986</TREF>	0	Written language has orthographic cues such as section headings, paragraph boundaries, and punctuation which can assist in identifying discourse structure	0	In spoken language, intonational variation provides essential information about disconrse structure	0	0	0
P98-1044	J86-3001	1998	Acknowledgements Our thanks go to Daniel Marcu who pointed some weak parts and provided RST analysis and to the TELR1 program who facilitated the second meeting of the three authors	0	7 We use Grosz and Sidners 1986 terminology here, but note the equivalence of dominance in GS and nucleus/satellite relations in RST pointed out by <REF>Moser and Moore 1996</REF>	0	285 References Brennan, SE, Walker Friedman, M and Pollard, CJ	0	1987	0	0	0
P98-1044	J86-3001	1998	On the other hand, satellites are dependent on their nuclei for their meaning and hence may refer to entities introduced within them	0	The definition of veins formalizes these relationship, s Given the mapping of <REF>Grosz and Sidners 1986</REF> stackbased model of discourse structure to RST structure trees outlined by <REF>Moser and Moore 1996</REF>, the domains of referentiality defined for left-polarized trees using VT are consistent with those defined using the stack-based model eg <REF>Passonneau 1995</REF>, <REF>Hahn and Strtibe 1997</REF>	0	However, in cases where the discourse structure is not left-polarized, VT provides a more natural account of referential accessibility than the stackbased model	0	In non left-polarized trees, at least one satellite precedes its nucleus in the discourse and is therefore its left sibling in the binary discourse tree	0	0	0
P98-1044	J86-3001	1998	As such, our approach differs from Walkers 1996, whose account of referentialit, within the cache memory model does not rely on discourse structure, but rather on cue phrases and matching constraints together 281 with constraints on the size of the cache imposed to reflect the plausible limits of the attentional span	0	Our approach is closer to that of <REF>Passonneau 1995</REF> and <REF>Hahn and Strtibe 1997</REF>, who both use a stack-based model of discourse structure based on Grosz and Sidners 1986 focus spaces	0	Such a model is equivalent to a dynamic processing model of a tree-like structure reflecting the hierarchical nesting of discourse segments, and thus has significant similarities to discourse structure trees produced by RST see <REF>Moser and Moore 1996</REF>	0	However, using the RST notion of nuclearity, we go beyond previous work by revealing a hidden structure in the discourse tree, which we call veins, that enables us to determine the referential accessibility domain for each discourse unit and ultimately to apply CT globally, without extensions to CT or addltional Oata structures	0	0	0
E89-1022	J86-3001	1989	Note that most DRT-based anaphora resolution processes <REF>Kamp 1984</REF>, <REF>Frey  Kamp 1986</REF> by and large follow this line, with a few modifications concerning structural conditions in terms of an accessibility relation	0	But there is also a different perspective whose key notion is the well-established concept of focus see eg in Computational <REF>Linguistics Grosz  Sidner 1986</REF> 3	0	As is shown by psychological experiments an detailed overview is given by <REF>Guindon 1985</REF>, a very limited number of discourse referents are focussed	0	Referents in the focus, which can be described in psychological terms as short term memory see Guindon, are quickly accessed; especially pronouns are normally used to refer to items in the focus and therefore extensive search is mostly unnecessary	0	0	0
W93-0222	J86-3001	1993	lxt has constituent structure both below the level of the clause studied by syntacticians and above the level of the clause studied by those working in discourse	0	One kind of evidence for constituent structure above the clause level is tile pattern of pronominalization eg Grosz  Sidners 1986 attentional structure	0	Others include orthographic markers eg indenting paragraphs and in ton ation	0	Relations, such ms contrast, sequence, causality exist in the text and are directly evidenced by lexical items, such as cue words leichman 1985	0	0	0
P95-1042	J86-3001	1995	This is harder than it might at first seem	0	A closely related though not identical problem is found in recognising boundaries in discourse, and there seems to be little agreement in the literature as to the properties and functions they possess <REF>Morris and Hirst, 1991</REF>, <TREF>Grosz and Sidner, 1986</TREF>	0	Our system is aimed at documents typified by those in the MUC-4 corpus <REF>Sundheim, 1992</REF>	0	These deal with Latin American terrorist incidents, and vary widely in terms of origin, medium and purpose	0	0	0
W00-1014	J86-3001	2000	We will in this paper not consider user task models, only system task models	0	The Dialogue history records the focus of attention <TREF>Grosz and Sidner, 1986</TREF> and contains information about objects, properties, and relations as well as other dialogue information such as speech act information and system task information	0	32 Domain Knowledge Management If a request is fully specified it can be used to retrieve the desired information from a background system	0	This task is seldom discussed in literature on dialogue systems, perhaps because it is considered a rather straight forward task	0	0	0
W06-2302	J86-3001	2006	Fig	0	1 GETARUNS AR algorithm 32 Focussing Revisited Our version of the focussing algorithm follows Sidners proposal Sidner C , 1983; Grosz B , Sidner C , 1986, to use a Focus Stack, a certain Focus Algorithm with Focus movements and data structures to allow for processing simple inferential relations between different linguistic descriptions co-specifying or coreferring to a given entity	0	Our Focus Algorithm is organized as follows: for each utterance, we assert three centers that we call Main, Secondary and the first Potential Topic, which represent the best three referring expressions as they have been weighted in the candidate list used for pronominal binding; then we also keep a list of Potential Topics for the remaining best candidates	0	These three best candidates repositories are renovated at each new utterance, and are used both to resolve pronominal and nominal cospecification and coreference: this is done both in case of strict identity of linguistic description and of non-identity	0	0	0
W93-0230	J86-3001	1993	Coherence relations and intentions In recent years, accounts of discourse structure have been developed in which the notion of discourse Iurpose or intention is pivotal	0	A good example is the work of <TREF>Grosz  Sidner 1986</TREF>, who present their account as antagonistic to the coherence relation approach as advocated in tiffs paper	0	In my view, it is fat more attractive to view such a discourse intention approach as compatille with a coherence relation approach	0	Such a synthesis would account for several major weaknesses of the discourse intention approach: 1 it does not lead to a descriptively adequate analysis, 2 it is psychologically inlplausible and 3 it has hardly any explanatory power	0	0	0
J94-4002	J86-3001	1994	62 Discourse Based Methods Most of the work in this area seeks to formulate general principles of discourse structure and interpretation and to integrate methods of anaphora resolution into a computational model of discourse interpretation and sometimes of generation as well	0	Sidner 1981, 1983, Grosz, Joshi, and Weinstein 1983, 1986, <TREF>Grosz and Sidner 1986</TREF>, 21 The difficulty that RAP encounters with such cases was discussed in Section 41	0	We are experimenting with refinements in RAPs scoring mechanism to improve its performance in these and other cases	0	556 Shalom Lappin and Herbert J Leass An Algorithm for Pronominal Anaphora Resolution <REF>Brennan, Friedman, and Pollard 1987</REF>, and <REF>Webber 1988</REF> present different versions of this approach	0	0	0
J94-4002	J86-3001	1994	It relies on measures of salience derived from syntactic structure and a simple dynamic model of attentional state to select the antecedent noun phrase NP of a pronoun from a list of candidates	0	It does not employ semantic conditions beyond those implicit in grammatical number and gender agreement or real-world knowledge in evaluating candidate antecedents; nor does it model intentional or global discourse structure as in <TREF>Grosz and Sidner 1986</TREF>	0	 School of Oriental and African Studies, University of London, London WCIH OXG, UK	0	E-mail: slappincluslulccacuk Most of the first authors work on this paper was done while he was a Research Staff Member in the Computer Science Department of the IBM TJ Watson Research Center	0	0	0
N04-4039	J86-3001	2004	For instance, gestures frequently occur at episode boundaries	0	Pushing and popping of a discourse segment <TREF>Grosz  Sidner, 1986</TREF> may also affect gesture occurrence	0	Therefore, by integrating a discourse analyzer into the LTM, more general structural discourse information can be used in the model	0	Another important direction is to evaluate the effectiveness of agent gestures in actual human-agent interaction	0	0	0
W93-0239	J86-3001	1993	Detecting such sntences specilic;dly in third-persoil fictiona narrative text was the focus of previous work; sue Wiele 1990	0	Notice that But in 22 is being used to connect clauses, aM not in addition to mark the beginning of a new discourse segment as the term discourse,:gmcnt is used in Grosz  <REF>Sidner 1986</REF>	0	The question we are asking is what clauses are being connected by But in 2	0	Under the reading described above, the ibllowiug are the clauses participatiug in the relation: Mary had never leen introduced to Sam	0	0	0
W04-1002	J86-3001	2004	This is the case for many graphics appearing in newspapers, such as the graphic shown in Figure 1	0	On the other hand, when an article is comprised of text and graphics, the graphic generally expands on the text and contributes to the discourse purpose <TREF>Grosz and Sidner, 1986</TREF> of the article	0	For example, Figure 2 illustrates a graphic from Newsweek showing that the income of black women has risen dramatically over the last decade and has reached the level of white women	0	Although this information is not conveyed elsewhere in the article, it contributes to the overall communicative intention of this portion of the article  namely, that there has been a monumental shifting of the sands with regard to the achievements of black women	0	0	0
W04-0714	J86-3001	2004	In the last section the conclusions are made	0	2 Centering Model In the centering theory <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al, 1995</REF>; <REF>Walker et al , 1994</REF>; <REF>Strube and Hahn, 1996</REF>, the attentional state was identified as a basic component of discourse structure that consisted of two levels of focusing: global and local	0	For Grosz and Sidner, the centering theory provided a model for monitoring local focus and yielded the centering model which was designed to account for the difference in the perceived coherence of discourses	0	In the centering model, each utterance U in a discourse segment has two structures associated with it, called forwardlooking centers, C f U, and backward-looking center, C b U	0	0	0
J89-3002	J86-3001	1989	This section will illustrate only the contribution of naive semantics and will not delve into the complex problem of the interactions among the several sources of information	0	<TREF>Grosz and Sidner 1986</TREF> argue that coherence relations are not a useful analytical tool because no clear, closed set of them has been discovered	0	However, there is ample psycholinguistic evidence that in constructing the interpretation of a text, and in recalling what it said, coherence relations are inferred and used by readers <REF>Rickheit and Strohner 1985</REF>	0	In terms of computational linguistics, coherence relations are useful for text summarization and relevance reasoning	0	0	0
J89-3002	J86-3001	1989	I dont know Inherent y Figure 3	0	The Query System 5 NAIVE SEMANTICS AND DISCOURSE PHENOMENA 12 Most computational treatments of discourse phenomena acknowledge the role of world knowledge in anaphora resolution, temporal reasoning, and causal reasoning <REF>Reichman 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Wada and Asher 1986</REF>	0	However, in the past the only method for encoding and incorporating world knowledge involved writing a detailed script for every real-life situation, directly encoding the probable sequence of events, participants, and so forth <REF>Schank and Abelson 1977</REF>	0	This section will demonstrate that word level naive semantics offers a principled, transportable alternative to scripts	0	0	0
J89-3002	J86-3001	1989	Along with syntactic, compositional semantic, and discourse cue information, NS can be used to reason heuristically about discourse and drive many of the inferences drawn by people when they read a discourse	0	The role of syntax and compositional semantics will be underplayed in what follows, only because these contributions have been thoroughly treated by others <REF>Reinhart 1982</REF>; <REF>Asher and Wada 1988</REF>; <REF>Kamp 1981</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Reichman 1985</REF>; <REF>Webber 1985</REF>	0	51 ANAPHORA In anaphora resolution, syntactic constraints, accessibility in the sense of <REF>Kamp 1981</REF>, and discourse segmentation work in concert to limit the number of antecedents available to an anaphoric pronoun or definite NP	0	However, it is clear that the resultant saliency stack can end up with more than one member <REF>Asher and Wada 1988</REF>	0	0	0
C96-2101	J86-3001	1996	Also speech act classification is abandoned, in favour of contextual reasoning and rationality considerations	0	Two general approaches can be distinguished in dialogue management: the structural approach, which uses a dialogue grammar to capture regularities of the dialogue in terms of exchanges and moves <REF>Bilange, 1992</REF>; <REF>Cawsey, 1993</REF>; <TREF>Grosz and Sidner, 1986</TREF>, and the intention-based approach, which classifies the speakers beliefs and intentions into speech acts, and uses planning operators to describe them Appel 1985; <REF>Allen and Perrault, 1980</REF>; <REF>Bunt et al , 1984</REF>	0	Both regard natural language as purposeful behaviour, but differ in how this behaviour is to be described	0	The former sees dialogues as products and compiles participants beliefs and intentions into a predefined dialogue structure, whereas the latter focusses on the participants goals, and hides the structure in the relations between acts which contain appropriately chosen sets of beliefs and intentions as their preconditions and effects	0	0	0
W99-0112	J86-3001	1999	As mentioned earlier in this section, the initial account to centering is only concerned with the choice of referring expressions within a discourse segment	0	Since a more general theory to referring expressions is needed, an extension is presented by <TREF>Grosz and Sidner 1986</TREF>	0	They use a stack mechanism for representing the different discourse segments	0	If one segment is closed off	0	0	0
W99-0112	J86-3001	1999	His Segmented DRT SDRT uses a tree-like representation for the discourse sUuctui I Centering Theory CD proposes a//st structure for the entities one preferably refers to in subsequent sentences	0	In order to cover coreference over discourse segments the centering model was extended by a stack mechanism <TREF>Grosz and Sidner, 1986</TREF>	0	Recently, these data structures have been criticized by <REF>Walker 1998</REF>, because they seem to be too restrictive	0	She proposes a cache storage for the referenis in the focus of attention	0	0	0
P94-1002	J86-3001	1994	words residential and apartment both index the same thesaural category and can thus be considered to be in a coherence relation with one another	0	The chains are used to structure texts according to the attentional/intentional theory of discourse structure <TREF>Grosz  Sidner 1986</TREF>, and the extent of the chains correspond to the extent of a segment	0	The algorithm also incorporates the notion of chain returns repetition of terms after a long hiatus to close off an intention that spans over a digression	0	Since the <REF>Morris  Hirst 1991</REF> algorithm attempts to discover attentional/intentional structure, their goals are different than those of TextTiling	0	0	0
P94-1002	J86-3001	1994	rThis might be explained in part by <REF>Stark 1988</REF> who shows that readers disagree measurably about where to place paragraph boundaries when presented with texts with those boundaries removed	0	ogy that occurred in all of them reappears in this one location in the spirit of a Grosz ; <REF>Sidner 1986</REF> pop operation	0	Thus it displays low similarity both to itself and to its neighbors	0	This is an example of a breakdown caused by the assumptions about the subtopic structure	0	0	0
N04-4035	J86-3001	2004	Formal written discourse signals a hierarchical, tree-based discourse structure explicitly by the division of the text into chapters, sections, paragraphs, and sentences	0	This structure, in turn, identifies domains for interpretation; many systems for anaphora resolution rely on some notion of locality <TREF>Grosz and Sidner, 1986</TREF>	0	Similarly, this structure represents topical organization, and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic	0	Unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse	0	0	0
E99-1038	J86-3001	1999	2	0	Defining focus: a eognito-pragmatie category The term focus has been used in various senses, at least six of which can be identified, ie, phonological <REF>Pierrehumbert, 1980</REF>; <REF>Ladd, 1996</REF>, semantic <REF>Jackendoff, 1972</REF>; <REF>Prince, 1985</REF>, syntactic <REF>Rochemont, 1986</REF>, cognitive <REF>Sanford  Garrod, 1981</REF>; <REF>Musseler et al , 1995</REF>, pragmatic <REF>Halliday, 1967</REF>, and AI-focus <TREF>Grosz  Sidner, 1986</TREF> 	0	We argue that, first, these multiple uses of focus, though resulting in conceptual confusion, hint at the central status of the notion in core as well as peripheral linguistics	0	Second, focus as occurs in discourse is best captured by referring to both the interlocutors cognitive computation and constant interaction, in accordance with the dual ie , cognitive and pragmatic nature of discourse per se <REF>Nuyts, 1992</REF>	0	0	0
W04-2322	J86-3001	2004	In Section 6 we present our conclusions and suggest directions for future research	0	2 The Classical Linguistic Discourse Model C-LDM Unlike the Discourse Structures Model DSM of <TREF>Grosz and Sidner 1986</TREF>, a pragmatic and psychological theory that aims to clarify the relationship between speakers intentions and their focus of attention in discourse, or the rhetorical model of Rhetorical Structures Theory <REF>Mann and Thompson, 1988</REF> that is designed to identify the coherence relations between segments of text, the Linguistic Discourse Model LDM <REF>Polanyi and Scha, 1984</REF>; <REF>Polanyi, 1988</REF>; Polanyi and van den <REF>Berg, 1996</REF> is a syntactically informed, semantically driven model developed to provide proper semantic interpretation for every utterance in a discourse despite the apparent discontinuities that are present even in well structured written texts	0	In its focus on understanding discourse meaning, the LDM is close in spirit to Structured Discourse Representation Theory SDRT <REF>Asher, 1993</REF>	0	While S-DRT attempts to account for discourse structure purely semantically, the LDM framework is concerned to maintain a separation between discourse syntactic structure, on the one hand, and discourse interpretation on the other	0	0	0
W04-2322	J86-3001	2004	Antecedents must be available at a node along the right edge of the discourse tree	0	<REF>Polanyi, 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Webber, 1991</REF> The LDM posits three structural relations between discourse units: 1	0	discourse coordination a Units related by bearing a similar relationship to an existing or newly formed common parent in the tree lists, narratives	0	b Available at the C-node is information common to all child nodes	0	0	0
J96-2004	J86-3001	1996	Where no sensible choice of unit is available pretheoretically, measure 1 may still be preferred	0	Secondly, coding discourse and dialogue phenomena, and especially coding segment boundaries, may be inherently more difficult than many previous types of content analysis for instance, 1 There are several variants of the kappa coefficient in the literature, including one, Scotts pi, which actually has been used at least once in our field, to assess agreement on move boundaries in monologues using action assembly theory <TREF>Grosz and Sidner 1986</TREF>	0	Krippendorffs c is more general than Siegel and Castellans K in that Krippendorff extends the argument from category data to interval and ratio scales; this extension might be useful for, for instance, judging the reliability of TOBI break index coding, since some researchers treat these codes as inherently scalar <REF>Silverman et al 1992</REF>	0	Krippendorffs c and Siegel and Castellans K differ slightly when used on category judgments in the assumptions under which expected agreement is calculated	0	0	0
P97-1026	J86-3001	1997	At any point, an entity is either new or old to the HEARER and either new or old to the DISCOURSE	0	Second, entities differ in SALIENCE <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al , 1995</REF>	0	Salience assigns each entity a position in a partial order that indicates how accessible it is for reference in the current context	0	Third, entities are related by salient PARTIALLYORDERED SET POSET RELATIONS to other entities in the context <REF>Hirschberg, 1985</REF>	0	0	0
J99-3001	J86-3001	1999	At the level of discourse pragmatics, a richer notion than mere reference between terms is needed to account for coherence relations such as those aimed at by Rhetorical Structure Theory 340 Strube and Hahn Functional Centering <REF>Mann and Thompson 1988</REF>	0	In addition, an explicit relation to basic notions from speech act theory is also missing, though it should be considered vital for the global coherence of discourse <TREF>Grosz and Sidner 1986</TREF>	0	In general, it might become increasingly necessary to integrate very deep forms of reasoning, perhaps even nonmonotonic Dunin-<REF>Keplicz and Lukaszewicz 1986</REF> or abductive inference mechanisms <REF>Nagao 1989</REF>, into the anaphora resolution process	0	This might become a sheer necessity when incrementality of processing receives a higher level of attention in the centering community	0	0	0
J99-3001	J86-3001	1999	On the other hand, many of these systems work in a real-world environment <REF>Rich and LuperFoy 1988</REF>; <REF>Lappin and Leass 1994</REF>; <REF>Kennedy and Boguraev 1996</REF> in which noisy data and incomplete, sometimes even faulty, analysis results have to be accounted for	0	The centering model differs from these considerations in that it aims at unfolding a unified theory of discourse coherence at the linguistic, attentional, and intentional level <TREF>Grosz and Sidner 1986</TREF>; hence, the search for a more principled, theory-based solution, but also the need for almost perfect linguistic analyses in terms of parsing and semantic interpretation	0	7	0	Conclusion In this paper, we provided a novel account for ordering the forward-looking center list, a major construct of the centering model	0	0	0
J99-3001	J86-3001	1999	The model requires two constructs, a single backward-looking center and a list of forwardlooking centers, as well as a few rules and constraints that govern the interpretation of centers	0	It is assumed that discourses are composed of constituent segments <TREF>Grosz and Sidner 1986</TREF>, each of which consists of a sequence of utterances	0	Each utterance Ui in a given discourse segment DS is assigned a list of forward-looking centers, CfDS, Ui, and a unique backward-looking center, CbDS, Ui	0	The forward-looking centers of Ui depend only on the discourse entities that constitute the ith utterance; previous utterances provide no constraints on CfDS, Ui	0	0	0
J99-3001	J86-3001	1999	Computational linguists have recognized the need to account for referential ambiguities in discourse and have developed various theories centered around the notion of discourse focus <REF>Grosz 1977</REF>; <REF>Sidner 1983</REF>	0	In a seminal paper, <TREF>Grosz and Sidner 1986</TREF> wrapped up the results of their research and formulated a model in which three levels of discourse coherence are distinguished--attention, intention, and discourse segment structure	0	While this paper gives a comprehensive picture of a complex, yet not explicitly spelled-out theory of discourse coherence, the centering model <REF>Grosz, Joshi, and Weinstein, 1983, 1995</REF> marked a major step in clarifying the relationship between attentional states and local discourse segment structure	0	More precisely, the centering model accounts for the interactions between local coherence and preferential choices of referring expressions	0	0	0
W01-1605	J86-3001	2001	Annotation ranges from broad characterization of document-level information, such as topic or relevance judgments <REF>Voorhees and Harman, 1999</REF>; <REF>Wayne, 2000</REF> to discrete analysis of a wide range of linguistic phenomena	0	However, rich theoretical approaches to discourse/text analysis <REF>Van Dijk and Kintsch, 1983</REF>; <REF>Meyer, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Mann and Thompson, 1988</REF> have yet to be applied on a large scale	0	So far, the annotation of discourse structure of documents has been applied primarily to identifying topical segments <REF>Hearst, 1997</REF>, inter-sentential relations <REF>Nomoto and Matsumoto, 1999</REF>; <REF>Tsou et al , 2000</REF>, and hierarchical analyses of small corpora <REF>Moser and Moore, 1995</REF>; <REF>Marcu et al , 1999</REF>	0	In this paper, we recount our experience in developing a large resource with discourse-level annotation for NLP research	0	0	0
W01-1605	J86-3001	2001	Reseachers in the field have proposed a number of competing hypotheses about what constitutes an elementary discourse unit	0	While some take the elementary units to be clauses <REF>Grimes, 1975</REF>; <REF>Givon, 1983</REF>; <REF>Longacre, 1983</REF>, others take them to be prosodic units <REF>Hirschberg and Litman, 1993</REF>, turns of talk <REF>Sacks, 1974</REF>, sentences <REF>Polanyi, 1988</REF>, intentionally defined discourse segments <TREF>Grosz and Sidner, 1986</TREF>, or the contextually indexed representation of information conveyed by a semiotic gesture, asserting a single state of affairs or partial state of affairs in a discourse world, <REF>Polanyi, 1996</REF>, p5	0	Regardless of their theoretical stance, all agree that the elementary discourse units are non-overlapping spans of text	0	Our goal was to find a balance between granularity of tagging and ability to identify units consistently on a large scale	0	0	0
J99-4006	J86-3001	1999	The statement that the cache retrieves entities related to the prior intention from the main memory to the cache, unless retained in the cache, leaves unanswered two critical processing 3 There are, in addition, several well-recognized problems with the model	0	In particular, as used in computer systems, stacks do not differentiate among different kinds of frames, but interruptions seem to operate differently from normal embeddings <TREF>Grosz and Sidner 1986</TREF> and there are open issues in explaining pronominal reference at discourse segment boundaries	0	621 Computational Linguistics Volume 25, Number 4 questions: 1 How is the cache searched for related entities and how is relatedness determined	0	2 How is a prior intention determined ie, what memory is there for intentional structure and how is that coordinated with information in main memory so that the relevant information can be found	0	0	0
J99-4006	J86-3001	1999	We first examine this evidence from the stack model perspective showing how the data might be accounted for within that model; we then raise some questions about Walkers cache model explanations	0	In earlier work <REF>Grosz 1977a</REF>; <TREF>Grosz and Sidner 1986</TREF> we have argued that it is important to distinguish between two levels of discourse structure and processing: global and local	0	A focus-space stack was proposed as a model for the global level	0	The main claims about its use in processing have been for handling definite descriptions <REF>Grosz 1977a</REF>; <REF>Grosz 1981</REF> and reasoning about intentional structure <REF>Lochbaum 1998</REF>	0	0	0
J99-4006	J86-3001	1999	J99-4006:327	0	Conceptions of Limited Attention and Discourse FocusBarbara J Grosz t Harvard University Peter C Gordon University of North <REF>Carolina Walker 1996</REF> presents a cache model of the operation of attention in the processing of discourse as an alternative to the focus space stack that was proposed previously by Grosz and Sidner <REF>Grosz 1977a</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	In this squib, we present a critical analysis of the cache model and of Walkers supporting evidence from anaphora in discourses with interruptions and from informationally redundant utterances	0	We argue that the cache model is underdetermined in several ways that are crucial to a comparison of the two models and conclude that Walker has not established the superiority of the cache model	0	0	0
J99-4006	J86-3001	1999	A recent article by <REF>Walker 1996</REF> argues that the attentional mechanism has limited capacity, that this limited capacity determines the accessibility of information in discourse processing, and that certain linguistic behavior can only be explained in terms of this limited capacity	0	Walker presents as an alternative to the focus space stack previously proposed to model global attentional state <REF>Grosz 1977a</REF>; <TREF>Grosz and Sidner 1986</TREF> a cache model in which linear recency and a highly constrained cache capacity play primary roles	0	As critical evidence, Walker presents an analysis of anaphora in discourses with interruptions and of informationally redundant utterances IRUs	0	In addition, she cites psychological evidence on the limited capacity of human information processing	0	0	0
C88-2099	J86-3001	1988	The foregoing has sewed to motivate the need for reliable segmentation heuristics	0	Most such heuristics found in the iitera ture are syntactical in nature, relying, in almost Eliza-like fashion, on clue words and phrases see references in <TREF>Grosz  Sidner 1986</TREF>: 177	0	We ptpose that heuristics should be based on semantical considerations such as discontinuities in the representation	0	This paper investigates four kinds of discontinuities: discontinuities of topic, discontinuities of space and time, discontinuities of figure and ground, and discontinuities of the narrative perspective	0	0	0
C88-2099	J86-3001	1988	Nhimovsky 1988 for some discussion	0	<TREF>Grosz  Sidner 1986</TREF> is the first unified approach in which the problem of segmentation is fled up with the notion of atten tional state	0	As argued in <REF>Nakhimovsky 1987b</REF>, some features of their model a stack mechanism for attentional state, the prom inenee of pragmatic notions such as the speakers intentions make it more appropriate for conversation rather than nacative <REF>Webber 1988</REF> and <REF>Naidlimovsky 1988</REF> suggest a model in which the distinction between the top and the rest of die stack is replaced by the distinction between a shnttelm memory and the ESS	0	Ottr work has been developing in close contact with the SUNY Buffalo Graduate Group in Cognitive Sciences pojcct on cognitive and computer systems for understanding narrative text	0	0	0
C88-2099	J86-3001	1988	We thus have three kinds of entities organized into three kinds of structures: linearly ordered stretches of text forming the Linear Text Structure LTS; the Event-Situation Structure ESS, ef	0	<REF>Webber 1987b</REF>, representing the narratives unfolding contents; and the Current Focus Space, which is a collection of focusing mechanisms including the deictic center that together represent the attentional state <TREF>Grosz  Sidner 1986</TREF> of the system	0	The components of the LTS are frequently linked by rbetodcal relationg such as elaboration, resumption or flashback see, eg, <REF>Hobbs 1982</REF>	0	We believe that these rhetorical relations are simply macro labels that stand for certain oft-repeated clusters of discontinuities in the ESS	0	0	0
P07-1075	J86-3001	2007	<REF>Second, Miltsakaki 2003</REF> stated that entities in subordinate clauses are less salient	0	Third, the knowledge of textual structure helps to interpret the meaning of entities in a text <TREF>Grosz and Sidner 1986</TREF>	0	As an example, consider the sentences ABC Co appointed a new chairman	0	Additionally, the current CEO was retired	0	0	0
J00-2001	J86-3001	2000	An example of the type of plan the planner must build is shown in Figure 3 Section 41 discusses the use of this plan in more detail	0	This model of text plans meshes well with the model of discourse structure developed by Grosz and Sidner <REF>Grosz and Sidner 1985, 1986</REF>, in which the purpose of each discourse segment is an important part of the structure	0	9 IGEN constructs its plans using a hierarchical planning algorithm <REF>Nilsson 1980</REF>	0	The planner first checks all of its top-level plans to see which have effects that match the goal	0	0	0
J04-3003	J86-3001	2004	Furthermore, she noted that this identification leads to problems with multiclausal sentences: for example, grammatical function ranking becomes difficult to compute, as a sentence may have more than one subject	0	Kameyama proposed that the local focus be updated after every tensed clause, not after every sentence, and classified tensed clauses into 1 utterances that constitute a permanent update of the local focus, such as coordinated clauses and adjuncts, and 2 embedded utterances that result in temporary updates that are then popped, much as the information introduced into discourse by subordinated discourse segments is popped according to <TREF>Grosz and Sidner 1986</TREF>	0	According to Kameyama, only a few types of clauses, such as the complements of certain verbs, are embedded	0	For example, Kameyama proposes to break up 4 into utterances as follows, and to treat each of these utterances, including subordinate clauses such as U2 or U5, as an update: 4 u1 Her entrance in Scene 2 Act 1 brought some disconcerting applause u2 even before she had sung a note	0	0	0
J04-3003	J86-3001	2004	334 Segmentation	0	According to <TREF>Grosz and Sidner 1986</TREF>, centering is meant to capture preferences only within discourse segments	0	A proper evaluation of the claims of the theory would therefore require a corpus in which discourse segments have been identified	0	Unfortunately, discourse segments are difficult to identify reliably <REF>Passonneau and Litman 1993</REF>, and <TREF>Grosz and Sidner 1986</TREF> do not provide a specification of discourse intentions explicit enough that it can be used to identify the intentional structure of textswhich, according to Grosz and Sidner, determines their segmentation	0	0	0
J04-3003	J86-3001	2004	A proper evaluation of the claims of the theory would therefore require a corpus in which discourse segments have been identified	0	Unfortunately, discourse segments are difficult to identify reliably <REF>Passonneau and Litman 1993</REF>, and <TREF>Grosz and Sidner 1986</TREF> do not provide a specification of discourse intentions explicit enough that it can be used to identify the intentional structure of textswhich, according to Grosz and Sidner, determines their segmentation	0	As a result, only preliminary attempts at annotating texts according to Grosz and Sidners theory have been made	0	For this reason, most previous corpus-based studies of centering either ignored segmentation or used heuristics such as those proposed by <REF>Walker 1989</REF>: Consider every paragraph as a separate discourse segment, except when its first sentence contains a pronoun in subject position or a pronoun whose agreement features are not 18 In previous work <REF>Poesio and Vieira 1998</REF> we came to the conclusion that kappa, while appropriate when the number of categories is fixed and relatively small, is problematic for anaphoric reference, when neither condition applies, and may result in inflated values of agreement	0	0	0
J04-3003	J86-3001	2004	E-mail:hitzemitreorg	0	Submission received: 16 <REF>April 2002</REF>; Revised submission received: 3 <REF>September 2003</REF>; Accepted for publication: 11 <REF>December 2003</REF> 310 Computational Linguistics Volume 30, Number 3 of attention and coherence in discourse <REF>Grosz 1977</REF>; <REF>Sidner 1979</REF>; <TREF>Grosz and Sidner 1986</TREF> concerned with local coherence and salience, that is, coherence and salience within a discourse segment	0	A fundamental characteristic of centering is that it is better viewed as a linguistic theory than a computational one	0	By this we mean that its primary aim is to make cross-linguistically valid claims about which discourses are easier to process, abstracting away from specific algorithms for anaphora resolution or anaphora generation although many such algorithms are based on the theory	0	0	0
J04-3003	J86-3001	2004	Centerings first contention as far as local salience is concerned is that the discourse entities realized by an utterance more on realization below are ranked: that is, that in each utterance some discourse entities are more salient than others	0	This claim, as well, is a basic tenet of much work on discourse <REF>Sidner 1979</REF>; <REF>Prince 1981</REF>; <REF>Givon 1983</REF>; <REF>Gundel, Hedberg, and Zacharski 1993</REF> and is supported by much psychological evidence <REF>Hudson, Tanenhaus, and Dell 1986</REF>; <REF>Gernsbacher and Hargreaves 1988</REF>; <REF>Gordon, Grosz, and Gillion 1993</REF>; <REF>Stevenson, Crawley, and Kleinman 1994</REF>	0	1 Entity-based theories of coherence are so-called by contrast with relation-centered theories of coherence, such as those developed in <REF>Hobbs 1979</REF> and <REF>Mann and Thompson 1988</REF> and used in <REF>Fox 1987</REF> and <REF>Lascarides and Asher 1993</REF>	0	The earliest detailed entity-based theory of coherence we are aware of is by Kintsch and van <REF>Dijk 1978</REF>, who also explicitly mention the need to supplement such theories with a theory of relational coherence more on this in Section 5 312 Computational Linguistics Volume 30, Number 3 These claims about coherence and salience are linked by two further hypotheses: that the identity of the CB is crucially determined by the entities ranking and that the CB is most likely to be realized as a pronoun	0	0	0
C04-1020	J86-3001	2004	Annotator agreement did not differ by text length  2  127; p < 075, arc length  2 < 1, or kind of coherence relation  2 < 1	0	3 Data structures for representing coherence relations Most accounts of discourse coherence assume tree structures to represent coherence relations between discourse segments in a text <REF>Carlson et al , 2002</REF>; Corston-<REF>Oliver, 1998</REF>; <REF>Lascarides  Asher, 1993</REF>; <REF>Longacre, 1983</REF>; <TREF>Grosz  Sidner, 1986</TREF>; <REF>Mann  Thompson, 1988</REF>; <REF>Marcu, 2000</REF>; <REF>Polanyi, 1988</REF>; van <REF>Dijk  Kintsch, 1983</REF>; <REF>Walker, 1998</REF>; <REF>Webber et al , 1999</REF>	0	Other accounts assume less constrained graphs <REF>Hobbs, 1985</REF>	0	The proponents of tree structures argue that trees are easier to formalize and derive than less constrained graphs <REF>Marcu, 2000</REF>	0	0	0
C04-1020	J86-3001	2004	2 Collecting a database of texts annotated with coherence relations This section describes 1 how we define discourse segments, 2 which coherence relations we used to connect the discourse segments, and 3 how the annotation procedure worked	0	21 Discourse segments Discourse segments can be defined as nonoverlapping spans of prosodic units <REF>Hirschberg  Nakatani, 1996</REF>, intentional units <TREF>Grosz  Sidner, 1986</TREF>, phrasal units <REF>Lascarides  Asher, 1993</REF>, or sentences <REF>Hobbs, 1985</REF>	0	We adopted a sentence unit-based definition of discourse segments	0	However, we also assume that contentful coordinating and subordinating conjunctions cf	0	0	0
C04-1020	J86-3001	2004	<REF>Hobbs, 1985</REF>; <REF>Marcu, 2000</REF>; <REF>Webber et al , 1999</REF>	0	Accounts of discourse structure vary greatly with respect to how many discourse relations they assume, ranging from two <TREF>Grosz  Sidner, 1986</TREF> to over 400 different coherence relations, reported in <REF>Hovy and Maier 1995</REF>	0	<REF>However, Hovy and Maier 1995</REF> argue that taxonomies with more relations represent subtypes of taxonomies with fewer relations	0	This means that different taxonomies can be compatible with each other	0	0	0
J97-1007	J86-3001	1997	Although the algorithms would be refined due to the introduction of more discourse structure, they would essentially still serve the purpose of distinguishing potential referents	0	The beginnings of discourse segments, in a sense, indicate shifts of intention in a discourse <TREF>Grosz and Sidner 1986</TREF>	0	In this situation, it may be preferred that subsequent references be full descriptions rather than reduced ones or pronouns, to emphasize the beginning of discourse segments, even if the referents have just been mentioned in the immediately previous utterance	0	<REF>See Grosz and Sidner 1986</REF> and <REF>Dale 1992</REF> for some examples that illustrate this idea	0	0	0
J97-1007	J86-3001	1997	<TREF>Grosz and Sidner 1986</TREF> claim that discourse segmentation is an important factor, though obviously not the only one, governing the use of referring expressions	0	If the idea of context set were restricted to local focus space <TREF>Grosz and Sidner 1986</TREF>, then the resulting descriptions would be to some extent sensitive to local aspects of discourse structure	0	Although the algorithms would be refined due to the introduction of more discourse structure, they would essentially still serve the purpose of distinguishing potential referents	0	The beginnings of discourse segments, in a sense, indicate shifts of intention in a discourse <TREF>Grosz and Sidner 1986</TREF>	0	0	0
J97-1007	J86-3001	1997	Minimal distinguishing descriptions pursue efficiency in producing an adequate description that can identity the intended referent unambiguously with a given context set	0	<REF>Dale 1992</REF> used the global focus space <TREF>Grosz and Sidner 1986</TREF>, as the context set in his domain of small discourse	0	Following this idea, the context set grows as the discourse proceeds	0	Consider, for example, two nominal anaphora referring to the same entity occurring at different places in a discourse	0	0	0
J97-1007	J86-3001	1997	We do not handle the generation of long-distance pronouns, which were rare in our texts	0	A possible solution would be to employ the concept of stacked focus space in Grosz and Sidners discourse structure theory <TREF>Grosz and Sidner 1986</TREF>; <REF>Dale 1992</REF>	0	In the final rule, the implementation of the test of the beginning of a discourse segment is not quite as straightforward as the other constraints	0	In our current implementation, we rely on the hierarchical structure of the message content to be generated as the basis for dividing the message into segments, which is effective in improving the texts generated by our Chinese natural language generation system	0	0	0
J97-1007	J86-3001	1997	In this situation, it may be preferred that subsequent references be full descriptions rather than reduced ones or pronouns, to emphasize the beginning of discourse segments, even if the referents have just been mentioned in the immediately previous utterance	0	<REF>See Grosz and Sidner 1986</REF> and <REF>Dale 1992</REF> for some examples that illustrate this idea	0	Figure 8 indicates that a similar situation may happen in Chinese discourse	0	Among the groups of initial and subsequent references, we focus on the one indexed j, lafengzheng de xian the string pulling the kite	0	0	0
J97-1007	J86-3001	1997	Thus, we employed the notion of discourse structure as the basis for enhancing the rule	0	23 Rule 3: Adding Discourse <REF>Structure Grosz and Sidner 1986</REF> suggest that three structures can be identified within a discourse: linguistic structure, intentional structure, and attentional state	0	The first structure is the sequence of utterances that comprise the discourse	0	Underlying this is the intentional structure, which shows the relationship between the respective purposes of discourse segments	0	0	0
J97-1007	J86-3001	1997	The entity, the big cat, is not a distractor to the black dog because it is of different category, cat	0	<TREF>Grosz and Sidner 1986</TREF> claim that discourse segmentation is an important factor, though obviously not the only one, governing the use of referring expressions	0	If the idea of context set were restricted to local focus space <TREF>Grosz and Sidner 1986</TREF>, then the resulting descriptions would be to some extent sensitive to local aspects of discourse structure	0	Although the algorithms would be refined due to the introduction of more discourse structure, they would essentially still serve the purpose of distinguishing potential referents	0	0	0
W97-0320	J86-3001	1997	This prevents a number of the above errors and suggests that changes in tense, aspect, and modality are promising clues to explore for recognizing subdialogs in this kind of data cf	0	, eg, <TREF>Grosz  Sidner 1986</TREF>; <REF>Nakhimovsky 1988</REF>	0	The CMU data has very little variation in tense and aspect, the reason a mechanism for interpreting them was not incorporated into the Mgorithm	0	Ros et al	0	0	0
W97-0320	J86-3001	1997	In developing the algorithm, our approach was to start with a straightforward, recencybased approach and add complexity as needed to address problems encountered in the data	0	The algorithm does not include a mechanism for handling global focus <TREF>Grosz  Sidner 1986</TREF>, for centering within a discourse segment <REF>Sidner 1979</REF>; <REF>Grosz et al 1995</REF>, or for performing tense and aspect interpretation	0	Instead, the algorithm processes anaphoric references with respect to an Attentional State <TREF>Grosz  Sidner 1986</TREF> structured as a linear list of all times mentioned so far in the current dialog	0	The list is ordered by recency, no entries are ever deleted from the list, and there is no restriction on access	0	0	0
W97-0320	J86-3001	1997	As will be shown in the next section, very few errors can be attributed to the wrong entities being in focus due to not handling subdialogs or multiple threads Ros6 et al 1995	0	6 Global Focus The algorithm is conspicuously lacking in any mechanism for recognizing the global structure of the discourse, such as in Grosz  <REF>Sidner 1986</REF>, <REF>Mann  Thompson 1988</REF>, <REF>Allen  Perranlt 1980</REF>, and their descendants	0	Recently in the literature, <REF>Walker 1996</REF> has argued for a more linear-recency based model of Attentional State though not that discourse structure need not be recognized, while Rosd et al	0	1995 argue for a more complex model of Attentional State than is represented in most current computational theories of discourse	0	0	0
W97-0320	J86-3001	1997	The algorithm does not include a mechanism for handling global focus <TREF>Grosz  Sidner 1986</TREF>, for centering within a discourse segment <REF>Sidner 1979</REF>; <REF>Grosz et al 1995</REF>, or for performing tense and aspect interpretation	0	Instead, the algorithm processes anaphoric references with respect to an Attentional State <TREF>Grosz  Sidner 1986</TREF> structured as a linear list of all times mentioned so far in the current dialog	0	The list is ordered by recency, no entries are ever deleted from the list, and there is no restriction on access	0	The algorithm decides among candidate antecedents based on a combined score reflecting recency, a priori preferences for the type Of anaphoric relations established, and plausibility of the resulting temporal reference	0	0	0
P99-1024	J86-3001	1999	In this case, the background may still contain the open proposition	0	Unlike in dialogue analyses carried out on completed dialogues <TREF>Grosz and Sidner, 1986</TREF>, the dialogue manager needs to maintain a stack of all open discourse segments at each point in an on-going dialogue	0	When a system allows corrections, it can be difficult to determine when a user has completed a discourse segment	0	Ex	0	0	0
P99-1024	J86-3001	1999	This paper describes extensions to CommandTalk to support spoken dialogue	0	While we make no theoretical claims about the nature and structure of dialogue, we are influenced by the theoretical work of <TREF>Grosz and Sidner, 1986</TREF> and will use terminology from that tradition when appropriate	0	We also follow Chu-<REF>Carroll and Brown, 1997</REF> in distinguishing task initiative and dialogue initiative	0	Section 2 demonstrates the dialogue capabilities of CommandTalk by way of an extended example	0	0	0
P99-1077	J86-3001	1999	Much of the relevant linguistic literature is indebted to <REF>Halliday and Hasan 1976</REF>, where cohesion is defined as a network of relationships between locations in the text, arising from i grammatical factors co-reference, use of pro-forms, ellipsis and sentential connectives, and ii lexical factors reiteration and collocation	0	Subsequent work has further developed this taxonomy <REF>Hoey, 1991</REF> and explored its implications in such areas as paragraphing <REF>Longacre, 1979</REF>; <REF>Bond and Hayes, 1984</REF>; <REF>Stark, 1988</REF>, relevance <REF>Sperber and Wilson, 1995</REF> and discourse structure <TREF>Grosz and Sidner, 1986</TREF>	0	The lexical variety of cohesion is semantically defined, invoking a measure of word similarity	0	But this is hard to measure objectively, especially in the case of collocational relationships, which hold between words primarily because they regularly cooccur	0	0	0
A94-1020	J86-3001	1994	Some views concentrate on deriving coherence relations between discourse segments, with the help of world models <REF>Hobbs, 1979</REF>; <REF>Reichman, 1984</REF>	0	Work on Discourse Structure Theory <REF>Grosz, 1977</REF>; <TREF>Grosz and Sidner, 1986</TREF> searches for automatic ways of segmenting discourse based on intentions and purposes embedded in discourse segments	0	Most of the results available are not readily adaptable to the current type of application	0	No world model can be introduced without severe consequences for portability	0	0	0
A94-1020	J86-3001	1994	This number can vary from application to application, and the current limit is set to three	0	<REF>Following Grosz and Sidner 1986</REF>, segments occur in sequence, or are embedded, to allow users to elaborate on a change of focus before returning to the previous topic	0	In case the current segment intersects with the second most recent one on the context list if any, this can be seen as a return to the previous topic segments 1 and 3 in Fig 2	0	The current segment will continue to grow independently, but the candidates in the second most recent segment will become available for reference	0	0	0
P96-1038	J86-3001	1996	The portion of the corpus we report on consists of 494 and 552 intermediate phrases for read and spontaneous speech, respectively	0	33 Discourse Segmentation In our research, the <TREF>Grosz and Sidner 1986</TREF> theory of discourse structure, hereafter GS, provides a foundation for segmenting discourses into constituent parts	0	According to this model, at least three components of discourse structure must be distinguished	0	The utterances composing the discourse divide into segments that may be embedded relative to one another	0	0	0
P96-1038	J86-3001	1996	CDA-94-01024 at Harvard University and by ATT Bell Laboratories	0	that discourse structural information can be inferred from orthographic cues in text, such as paragraphing and punctuation; from linguistic cues in text or speech, such as cue PHIASES 1 <REF>Cohen, 1984</REF>; <REF>Reichman, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF></TREF>; <REF>Passonneau and Litman, 1993</REF></REF>; Passonneau and Litman, to appear and other lexical cues <REF>Hinkelman and Allen, 1989</REF>; from variation in referring expressions <REF>Linde, 1979</REF>; <REF>Levy, 1984</REF>; <TREF>Grosz and Sidner, 1986</TREF></TREF>; <REF>Webber, 1988</REF>; <REF>Song and Cohen, 1991</REF></REF>; <REF>Passonneau and Litman, 1993</REF></REF>, tense, and aspect <REF>Schubert and Hwang, 1990</REF>; <REF>Song and Cohen, 1991</REF></REF>; from knowledge of the domain, especially for taskoriented discourses <REF>Grosz, 1978</REF>; and from speaker intentions <REF>Carberry, 1990</REF>; <REF>Litman and Hirschberg, 1990</REF>; <REF>Lochbaum, 1994</REF>	0	Recent methods for automatic recognition of discourse structure from text have incorporated thesaurus-based and other information retrieval techniques to identify changes in topic <REF>Morris and Hirst, 1991</REF>; <REF>Yarowsky, 1991</REF>; <REF>Iwafiska et al , 1991</REF>; <REF>Hearst, 1994</REF>; <REF>Reynar, 1994</REF>	0	Parallel investigations on prosodic/acoustic cues to discourse structure have investigated the contributions of features such as pitch range, pausal duration, amplitude, speaking rate, and intonational contour to signaling topic change	0	0	0
P96-1038	J86-3001	1996	An intention-based theory of discourse was used in <REF>Hirschberg and Grosz, 1992</REF>; <REF>Grosz and Hirschberg, 1992</REF> to identify intonational correlates of discourse structure in news stories read by a professional speaker	0	Discourse structural elements were determined by experts in the <TREF>Grosz and Sidner 1986</TREF> theory of discourse structure, based on either text alone or text and speech	0	This study revealed strong correlations of aspects of pitch range, amplitude, and timing with features of global and local structure for both segmentation methods	0	Passonneau and Litman to appear analyzed correlations of pause, as well as cue phrases and referential relations, with discourse structure; their segmenters were asked to identify speakers communicative actions	0	0	0
P98-1103	J86-3001	1998	We thus reckon that appropriate context management should provide descriptions of what is said, and that the recognition of the utterance topic is an important task of spoken dialogue systems	0	3 The Topic Model In AI-based dialogue modelling, topics are associated with a particular discourse entity, focus, which is currently in the centre of attention and which the participants want to focus their actions on, eg <TREF>Grosz and Sidner 1986</TREF>	0	The topic focus is a means to describe thematically coherent discourse structure, and its use has been mainly supported by arguments regarding anaphora resolution and processing effort search space limits	0	Our goal is to use topic information in predicting likely content of the next utterance, and thus we are more interested in the topic types that describe the information conveyed by utterances than the actual topic entity	0	0	0
W08-0101	J86-3001	2008	This difficulty in formalizing higher levels of conversation might explain the relatively low interest that conversational analysts have had in semantics and discourse	0	Yet, as conversational analysts focused on micro-levels of dialogue such as turntaking, computational linguists uncovered and formalized macro-level dialogue structure and devised well-defined representations of semantics for at least some forms of dialogues <REF>Allen and Perrault, 1980</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Clark, 1996</REF>, which have in turn been implemented in spoken dialogue systems <REF>Rich and Sidner, 1998</REF>; <REF>Allen et al, 2005</REF>	0	1 12 Current Approaches to Turn-Taking in Spoken Dialogue Systems Unfortunately, while socioand psycho-linguists revealed the complexity of conversational turn-taking behavior, designers of practical spoken dialogue systems have stuck to a simplistic approach to end-ofturn detection hereafter endpointing	0	Typically, silences in user speech are detected using a low-level Voice Activity Detector VAD and a turn is considered finished once a silence lasts longer than a fixed threshold	0	0	0
W02-0226	J86-3001	2002	From the view of GDM, the strategies a dialogue agent may choose can also be classified into three levels, ie, Micro-level strategies how to realize information structure, anaphora, ellipsis, and others, in utterances, Meso-level strategies what to say regarding current group status, so as to complete ongoing group more friendly, Macro-level strategies how to choose discourse topic regarding current task status, so as to complete the underlying task more efficiently	0	6 <TREF>Grosz and Sidner 1986</TREF> proposed a tripartite discourse model consisting of attentional state, intentional structure, and linguistic structure	0	It is influential and covers both dialogue and text	0	But their intentional structure fails to capture the distinction between global level and local level structure	0	0	0
J88-2004	J86-3001	1988	In terms of text structure, the current sentence either continues the same, or starts a new, discourse segment DS; cf	0	<TREF>Grosz and Sidner 1986</TREF>	0	The nature of the processing at the DS juncture is thus quite different from the routine tasks to be performed as long as the text remains in the same DS: the start of new DS prompts, and is prompted by, a shift of attention	0	The circularity here is deliberate	0	0	0
P98-2188	J86-3001	1998	Dialogue Act Tagging To address a significant concern in machine learning, called the sparse data problem, we must select an appropriate set of features	0	Researchers in discourse, such as <TREF>Grosz and Sidner 1986</TREF>, <REF>Lambert 1993</REF>, <REF>Hirschberg and Litman 1993</REF>, <REF>Chen 1995</REF>, <REF>Andernach 1996</REF>, <REF>Samuel 1996</REF>, and Chu-<REF>Carroll 1998</REF> have suggested several features that might be relevant for the task of computing dialogue acts	0	Our system can consider the following features of an utterance: 1 the cue phrases 3 in the utterance; 2 the word n-grams 3 in the utterance; 3 the dialogue act cues 3 in the utterance; 4 the entire utterance for one-, two-, or three-word utterances; 5 speaker information 4 for the utter2The part-of-speech tag of a word is dependent on the words internal features and on the surrounding words; similarly, the dialogue act of an utterance is dependent on the utterances internal features and on the surrounding utterances	0	This feature is defined later in this section	0	0	0
J88-3009	J86-3001	1988	USER MODELS AND DISCOURSE MODELS David N Chin Department of Information and Computer Services University of Hawaii at Manoa 2565 The Mall Honolulu, HI 96822 A user model UM contains information about users, such as users goals, beliefs, knowledge, preferences, and capabilities	0	A discourse model DM contains information about the conversation, such as the linguistic structure, the attentional state, and the intentional structure <TREF>Grosz and Sidner 1986</TREF>	0	Given these definitions, I will argue that the UM intersects the DM	0	That is, the UM contains items that are missing from the UM; the DM contains items that are missing from the DM; and the two share some items	0	0	0
J88-3009	J86-3001	1988	Although both DMs and UMs are built up from propositions expressed in the conversation, the DM expires at the end of the discourse, while parts of the UM are kept for future use	0	<TREF>Grosz and Sidner 1986</TREF> discuss how DMs are built up, and <REF>Chin 1986</REF>, <REF>Litman and Allen 1984</REF>, <REF>Carberry 1983</REF>, and <REF>Allen and Perrault 1980</REF>, among others, discuss this process for different aspects of UMs	0	In summary, the DM and UM are not separate, but rather share common parts	0	Shared parts include the intentional structure of the discourse and the attentional structure of the discourse	0	0	0
W04-1115	J86-3001	2004	Formal written discourse signals a hierarchical, tree-based discourse structure explicitly by the division of the text into chapters, sections, paragraphs, and sentences	0	This structure, in turn, identifies domains for interpretation; many systems for anaphora resolution rely on some notion of locality <TREF>Grosz and Sidner, 1986</TREF>	0	Similarly, this structure represents topical organization, and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic	0	Unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse	0	0	0
D08-1100	J86-3001	2008	Many such models focus on other aspects of a dialog such as coordinated activities, ie turn-taking and grounding, <REF>Traum and Hinkelman, 1992</REF> and regular patterns in the dialog <REF>Carletta et al, 1997</REF> rather than the domain-specific information communicated by participants	0	More complicated dialog representations <TREF>Grosz and Sidner, 1986</TREF>; <REF>Litman and Allen, 1987</REF> model several aspects of a dialog including domain-specific information	0	However, additional components in these models, such as beliefs and intentions, are difficult to observe directly from a conversation and, as for the current technology, may not be learnable through an unsupervised learning approach	0	Since the task-specific information that we would like to model will be used for configuring a dialog system, we can view this information from a dialog system perspective	0	0	0
P93-1020	J86-3001	1993	As in much of the literature on discourse processing, we assume that certain spans of utterances, referred to here as discourse segments, form coherent units	0	The segmental structure of discourse has been claimed to constrain and be constrained by disparate phenomena: cue phrases <REF>Hirschberg and Litman, 1993</REF>; <REF><REF>Gross and Sidner, 1986</REF></REF></REF>; <REF>Reichman, 1985</REF>; <REF>Cohen, 1984</REF>; lexical cohesion <REF>Morris and Hirst, 1991</REF>; plans and intentions <REF>Carberry, 1990</REF>; <REF>Litman and Allen, 1990</REF>; <REF><REF>Gross and Sidner, 1986</REF></REF></REF>; prosody <REF>Grosz and Hirschberg, 1992</REF>; <REF>Hirschberg and Gross, 1992</REF>; <REF>Hirschberg and Pierrehumbert, 1986</REF>; reference <REF>Webber, 1991</REF>; <REF><REF>Gross and Sidner, 1986</REF></REF></REF>; <REF>Linde, 1979</REF>; and tense <REF>Webber, 1988</REF>; <REF>Hwang and Schubert, 1992</REF>; <REF>Song and Cohen, 1991</REF>	0	However, there is weak consensus on the nature of segments and the criteria for recognizing or generating them in a natural language processing system	0	Until recently, little empirical work has been directed at establishing objeively verifiable segment boundaries, even though this is a precondition for 1We use the term utterance to mean a use of a sentence or other linguistic unit, whether in text or spoken language	0	0	0
P93-1020	J86-3001	1993	They then used statistical measures to characterize these discourse structures in terms of acousticprosodic features	0	<REF>Morris and Hirst 1991</REF> structured a set of magazine texts using the theory of <TREF>Grosz and Sidner 1986</TREF>	0	They developed a lexical cohesion algorithm that used the information in a thesaurus to segment text, then qualitatively compared their segmentations with the resuits	0	<REF>Hearst 1993</REF> derived a discourse structure for each text in her study, by incorporating the boundaries agreed upon by the majority of her subjects	0	0	0
P93-1020	J86-3001	1993	RELIABILITY The correspondence between discourse segments and more abstract units of meaning is poorly understood see <REF>Moore and Pollack, 1992</REF>	0	A number of alternative proposals have been presented which directly or indirectly relate segments to intentions <TREF>Grosz and Sidner, 1986</TREF>, RST relations <REF>Mann et al , 1992</REF> or other semantic relations <REF>Polanyi, 1988</REF>	0	We present initial results of an investigation of whether naive subjects can reliably segment discourse using speaker intention as a criterion	0	Our corpus consists of 20 narrative monologues about the same movie, taken from <REF>Chafe 1980</REF> N14,000 words	0	0	0
P93-1020	J86-3001	1993	Several researchers have begun to investigate the ability of humans to agree with one another on segmentation	0	Grosz and Hirschberg <REF>Grosz and Hirschberg, 1992</REF>; <REF>Hirschberg and Grosz, 1992</REF> asked subjects to structure three AP news stories averaging 450 words in length according to the model of <TREF>Grosz and Sidner 1986</TREF>	0	Subjects identified hierarchical structures of discourse segments, as well as local structural features, using text alone as well as text and professionally recorded speech	0	Agreement ranged from 74-95, depending upon discourse feature	0	0	0
W99-0313	J86-3001	1999	IU trees are created by identifying certain kinds of discourse relations	0	Following <TREF>Grosz and Sidner, 1986</TREF>, macro-level analysis captures two fundamental intentional relations between I-units, those of domination or parent-child and satisfactionprecedence or sibling relations	0	The corresponding informational relations are generates and enables <REF>Pollack, 1986</REF>; <REF>Goldman, 1970</REF>	0	More concretely, the domination relation can be elaborated in a planning-based framework as holding between a subsidiary plan and its parent, in which the completion of one plan contributes to the completion of its parent plan; the satisfaction-precedence relation can be elaborated as the temporal dependency between two plans <REF>Lochbaum, 1994</REF>	0	0	0
W99-0313	J86-3001	1999	One scheme which has as content Grounding <REF>Clark and Schaefer, 1989</REF>; <REF>Traum, 1994</REF>, operated at a meso level of granularity, and used non-hierarchical and possibly discontinuous  utterance sets as its structuring principle	0	The second scheme concerned intentional/informational structure <TREF>Grosz and Sidner, 1986</TREF>; <REF>Nakatani et al , 1995</REF> as content, operated at a macro level of granularity, and was structured as hierarchical trees with annotations for capturing discontinuities	0	In addition, these two schemes were linked by using the resulting structures from meso-level analysis as basic input for macro-level analysis	0	There were several factors motivating the decision to use these particular facets of discourse structure for initial analysis	0	0	0
P96-1009	J86-3001	1996	Robust Speech Act Processing The dialogue manager is responsible for interpreting the speech acts in context, formulating responses, and maintaining the systems idea of the state of the discourse	0	It maintains a discourse state that consists of a goal stack with similarities to the plan stack of <REF>Litman  Allen 1987</REF> and the attentional state of <TREF>Grosz  Sidner 1986</TREF>	0	Each element of the stack captures 1	0	the domain or discourse goal motivating the segment 2	0	0	0
E95-1033	J86-3001	1995	We shall illustrate the linguistic aspects of word actor-based parsing by introducing the basic data structures for text-level anaphora as acquaintances of specific word actors, and then turn to the general message-passing protocol that accounts for intraas well as inter-sentential anaphora	0	Our exposition builds on the well-known focusing mechanism <REF>Sidner, 1983</REF>; <TREF>Grosz and Sidner, 1986</TREF>	0	Accordingly, we distinguish each sentences unique focus, a complementary list of alternate potential loci, and a history list composed of discourse elements not in the list of potential loci, but occurring in previous sentences of the current discourse segment	0	These data structures are realized as acquaintances of sentence delimiters to restrict the search space beyond the sentence to the relevant word actors	0	0	0
W00-0310	J86-3001	2000	Further, it embodies and extends theoretical work on intonational meaning in a more general, robust and rigorous way than earlier CTS systems, in an architecture that reflects compositional aspects of dialogue and intonation interpretation	0	2 Theoretical Foundations In this work, we implement and extend the compositional theory of intonational meaning proposed by Pierrehumbert and Hirschberg 1986; 1990, who sought to identify correspondences between the Bell Laboratories, Lucent Technologies 600 Mountain Avenue Murray Hill, NJ 07974 USA chn I j enccresearch, bell-labs, com <TREF>Grosz and Sidner 1986</TREF> computational model of discourse interpretation and Pierrehumberts prosodic grammar for <REF>American English 1980</REF>	0	In the present work, certain aspects of the original theories are modified and adapted to the architecture of the dialogue system in which the CTS component is embedded	0	Below, we present the important fundamental definitions and principles of intonation underlying our CTS system	0	0	0
A92-1040	J86-3001	1992	Co-operative dialogue managemeut, therefore, requires the construction and maintenance of an interactional model: ie a model which specifies the layers of structure which can be distinguished in dialogues	0	<REF>Following Grosz and Sidner 1986</REF> we distinguish linguistic structure, attentional, or belief structure, and intelltionM structure	0	Intentional structure is further differentiated into dialogue structure and task structure <REF>Bunt, 1989</REF>	0	tiowever, rather than using a unitary model where these layers are given as a single structured representation, we have adopted a distributed model where these layers are distributed across a number of modules	0	0	0
P91-1025	J86-3001	1991	1987 for discussions of this parameter	0	llThis parameter may be tied to the intentional aspect of discourse as proposed by <TREF>Grosz and Sidner 1986</TREF>	0	See, eg, <REF>Scha and Polanyi 1988</REF> and <REF>Hobbs 1990</REF> for discourse structure models	0	guage since languages differ in the concepts and real-world entities for which they have words and grammatical constructs	0	0	0
P91-1025	J86-3001	1991	It captures the linguistically significant parameters in the current state of the on-going discourse, s and is especially useful for finding functionally equivalent referring expressions between the source and target languages	0	reference time  the time pivot of the linguistic SOur characterization of the context of utterance draws on a number of existing approaches to discourse representation and discourse processing, most notably those of <TREF>Grosz and Sidner 1986</TREF>, Discourse Representation Theory <REF>Kamp 1981</REF>, <REF>Helm 1982</REF>, Situation Semantics <REF>Barwise and Perry 1983</REF>, <REF>Gawron and Peters 1990</REF>, and Linguistic Discourse Model <REF>Scha and Polanyi 1988</REF>	0	<REF>Lewis 1979</REF> discussed a number of such parameters in a logical framework	0	7Different forms of referring expressions eg pronouns, demonstratives and surface structures ie syntactic and 196 description then s  point of view  the individual from whose viewpoint a situation is described   attentional state -the entities currently in the focus and center of attention   discourse structural context  where the utterance is in the structure of the current discourse I z The specific UTTERANCE SITUATION contains information about those parameters whose values support indexical references and deixes: eg, information about the speaker, hearers, the time and location of the utterance, the perceptually salient context, etc The FTP example text above describes a situation in which a person is typing commands to a computer and it is displaying various things	0	0	0
W97-1408	J86-3001	1997	A context set is defined as the set of entities the addressee is currently assumed to be attending to the contrast set is the same except to the intended referent; an equivalent term is the set of potential distractors <REF>McDonald, 1981</REF>	0	This is similar to the set of entities in the focus spaces of the discourse focus stack in Grosz and Sidners theory of discourse structure <REF>Grosz, Sidner, 1986</REF>	0	The existing algorithms attempt to identify the intended referent by determining a set of descriptors attributed to that referent, that is, a set of attributes	0	Some algorithms also include descriptors in the description that are attributed to other entities related to the original referent, that is, relations from the point of view of the intended referent	0	0	0
W99-0113	J86-3001	1999	In particular: the grammatical hierarchy with subjects ranking higher than objects Grosz, <REF>Joshi, Weinstein 1983</REF>, topic or empathy marking Kameyama 198,5, surface order position 111 <REF>Rainbow, 1993</REF> or grammatical function <REF>Brennan, Friedman and Pollard 1987</REF> of the encoding of discourse entities in the immediately preceding segment	0	<REF>Roberts 1998</REF> argues that C0 is an unordered setof backward-looking centers in terms of classical Discourse Representation Theory notions of familiarity, compatibility and logical accessibility <REF>Kamp 1981</REF>, <REF>Helm 1982</REF>, <REF>Kamp and Reyle 1993</REF>, <REF>Asher 1993</REF>, with an additional constraint that the set of discourse referents are attentionally accessible, a notion taken from <TREF>Grosz and Sidner 1986</TREF>	0	Under Roberts treatment, the set of preferred centers, takes the place of the original C6	0	<REF>Walker 1998</REF> also replaces a unique Ct with a set of possible backward looking centers computed from a set of possible forward looking centers using agreement features, selection constraints of the verb and contra-indexing conditions	0	0	0
J05-2005	J86-3001	2005	the discussion in Marcu 2000	0	Whereas some argue that discourse segments should be prosodic units <REF>Hirschberg and Nakatani 1996</REF>, others argue for intentional units <TREF>Grosz and Sidner 1986</TREF>, phrasal units <REF>Lascarides and Asher 1993</REF>; <REF>Longacre 1983</REF>; <REF>Webber et al 1999</REF>, or sentences <REF>Hobbs 1985</REF>	0	For our database, we mostly adopted a clause-unit-based definition of discourse segments	0	We chose this method of segmenting discourse because it was easy to use	0	0	0
J05-2005	J86-3001	2005	Going beyond the question of how different informational-level accounts can be compatible with each other, <REF>Moser and Moore 1996</REF> discuss the compatibility of rhetorical structure theory RST <REF>Mann and Thompson 1988</REF> with the theory of <TREF>Grosz and Sidner 1986</TREF>	0	However, note that <REF>Moser and Moore 1996</REF> focus on the question of how compatible the claims are that <REF>Mann and Thompson 1988</REF> and <TREF>Grosz and Sidner 1986</TREF> make about intentional-level discourse structure	0	In this article, we aim to develop an easy-to-code representation of informational relations that hold between sentences or other nonoverlapping segments in a discourse monologue	0	We describe an account with a small number of relations in order to achieve more generalizable representations of discourse structures; however, the number is not so small that informational structures that we are interested in are obscured	0	0	0
J05-2005	J86-3001	2005	As a consequence, Knott argues, elaboration relations would be better described in terms of focus structures cf	0	<TREF>Grosz and Sidner 1986</TREF>, which Knott argues are less constrained, than in terms of rhetorical relations cf	0	<REF>Hobbs 1985</REF>; <REF>Mann and Thompson 1988</REF>, which Knott argues are more constrained	0	This hypothesis makes testable empirical claims: Elaboration relations should in some way pattern differently from other coherence relations	0	0	0
J05-2005	J86-3001	2005	contr  contrast ; expv  violated expectation ; ce  causeeffect ; none  no coher e nce re l a t i o n ; gen  generalization ; cond  condition ; examp  example ; ts  temporal s equence ; attr  attribution ; elab  elaboration ; sim  similarity  Annotator 2 Annotator 1 contr e xpv ce none gen c ond e xamp ts attr elab same sim Sum P er centage contr 383 11 0 3 4 0 0 0 2 0 0 0 0 430 447 expv 4 113 0 7 0 0 0 0 0 0 0 0 124 129 ce 0 0 446 14 0 0 0 0 0 5 0 0 465 483 none 66 24 42 0 0 2 2 7 1 6 6 467 1 6 4 715 743 gen 0 0 0 1 21 0 0 0 0 1 0 0 2 3 024 cond 0 0 0 2 0 127 0 1 0 1 0 0 131 136 examp 0 0 1 1 8 0 0 219 0 0 3 0 0 241 251 ts 1 1 2 7 0 0 0 214 0 1 0 0 226 235 attr 0 0 0 5 0 0 0 0 1,387 0 0 0 1,392 1447 elab 0 0 17 260 0 3 0 3 0 3,913 1 0 4,197 4363 same 0 0 2 5 0 0 0 1 0 0 530 1 539 560 sim 7 0 3 4 3 0 0 0 6 0 0 3 1,074 1,136 1181 Sum 461 149 513 396 21 132 246 243 1,393 4,391 535 1,139 Per c entage 479 155 530 412 020 137 256 253 1450 4560 556 1180 261 Computational Linguistics Volume 31, Number 2 3	0	Data Structures for Representing Coherence Relations In order to represent the coherence relations between discourse segments in a text, most accounts of discourse coherence assume tree structures <REF>Britton 1994</REF>; <REF>Carlson, Marcu, and Okurowski 2002</REF>; Corston-<REF>Oliver 1998</REF>; <REF>Longacre 1983</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Mann and Thompson 1988</REF>; <REF>Marcu 2000</REF>; <REF>Polanyi and Scha 1984</REF>; <REF>Polanyi 1996</REF>; <REF>Polanyi et al 2004</REF>; van <REF>Dijk and Kintsch 1983</REF>; <REF>Walker 1998</REF>; some accounts do not allow crossed dependencies but appear to allow nodes with multiple parents <REF>Lascarides and Asher 1991</REF>	0	3 Other accounts assume less constrained graphs that allow crossed dependencies as well as nodes with multiple parents eg , <REF>Bergler 1991</REF>; <REF>Birnbaum 1982</REF>; <REF>Danlos 2004</REF>; <REF>Hobbs 1985</REF>; <REF>McKeown 1985</REF>; <REF>Reichman 1985</REF>; <REF>Zukerman and McConachy 1995</REF>; for dialogue structure, Penstein <REF>Rose et al 1995</REF>	0	Some proponents of tree structures assume that trees are easier to formalize and to derive than less constrained graphs <REF>Marcu 2000</REF>; <REF>Webber et al 2003</REF>	0	0	0
J05-2005	J86-3001	2005	These approaches differ with respect to what kinds of discourse structure they are intended to represent	0	Some accounts aim to represent the intentional-level structure of a discourse; in these accounts, coherence relations reflect how the role played by one discourse segment with respect to the interlocutors intentions relates to the role played by another segment eg , <TREF>Grosz and Sidner 1986</TREF>	0	Other accounts aim to represent the informational structure of a discourse; in these accounts, coherence relations reflect how the meaning conveyed by one discourse segment relates to the meaning conveyed by another discourse segment eg , <REF>Hobbs 1985</REF>; <REF>Marcu 2000</REF>; <REF>Webber et al 1999</REF>	0	Furthermore, accounts of discourse structure vary greatly with respect to how many discourse relations they assume, ranging from 2 <TREF>Grosz and Sidner 1986</TREF> to over 400 different coherence relations reported in Hovy and  Computer Laboratory and Genetics Department, Cambridge, CB3 0FD, UK E-mail: FlorianWolfclcamacuk  Department of Brain and Cognitive Sciences, Cambridge, MA 02139	0	0	0
J05-2005	J86-3001	2005	This means that different informational-level-based taxonomies can be compatible with each other; they differ with respect to how detailed or fine-grained a manner they represent informational structures of texts	0	Going beyond the question of how different informational-level accounts can be compatible with each other, <REF>Moser and Moore 1996</REF> discuss the compatibility of rhetorical structure theory RST <REF>Mann and Thompson 1988</REF> with the theory of <TREF>Grosz and Sidner 1986</TREF>	0	However, note that <REF>Moser and Moore 1996</REF> focus on the question of how compatible the claims are that <REF>Mann and Thompson 1988</REF> and <TREF>Grosz and Sidner 1986</TREF> make about intentional-level discourse structure	0	In this article, we aim to develop an easy-to-code representation of informational relations that hold between sentences or other nonoverlapping segments in a discourse monologue	0	0	0
J05-2005	J86-3001	2005	Other accounts aim to represent the informational structure of a discourse; in these accounts, coherence relations reflect how the meaning conveyed by one discourse segment relates to the meaning conveyed by another discourse segment eg , <REF>Hobbs 1985</REF>; <REF>Marcu 2000</REF>; <REF>Webber et al 1999</REF>	0	Furthermore, accounts of discourse structure vary greatly with respect to how many discourse relations they assume, ranging from 2 <TREF>Grosz and Sidner 1986</TREF> to over 400 different coherence relations reported in Hovy and  Computer Laboratory and Genetics Department, Cambridge, CB3 0FD, UK E-mail: FlorianWolfclcamacuk  Department of Brain and Cognitive Sciences, Cambridge, MA 02139	0	E-mail: egibsonmitedu	0	Submission received: 15th <REF>June 2004</REF>; Revised submission received: 5th <REF>September 2004</REF>; Accepted for publication: 23rd <REF>October 2004</REF>  2005 Association for Computational Linguistics Computational Linguistics Volume 31, Number 2 Maier 1995	0	0	0
J97-1002	J86-3001	1997	A typical transaction is a subdialogue that gets the route follower to draw one route segment on the map	0	Transactions are made up of conversational games, which are often also called dialogue games <REF>Carlson 1983</REF>; <REF>Power 1979</REF>, interactions <REF>Houghton 1986</REF>, or exchanges <REF>Sinclair and Coulthard 1975</REF>, and show the same structure as Grosz and Sidners discourse segments 1986 when applied to task-oriented dialogue	0	All forms of conversational games embody the observation that, by and large, questions are followed by answers, statements by acceptance or denial, and so on	0	Game analysis makes use of this regularity to differentiate between initiations, which set up a discourse expectation about what will follow, and responses, which fulfill those expectations	0	0	0
P98-2145	J86-3001	1998	The global discourse structure of a text can be constructed by relating the discourse segments with each other	0	Therefore, identifying segment boundaries in a text is considered as a first step to construct the discourse structure<TREF>Grosz and Sidner, 1986</TREF>	0	The use of surface linguistic cues in a text for identification of segment boundaries has been extensively researched, since it is impractical to assume the use of world knowledge for discourse analysis of real texts	0	Among a variety of surface cues, lexical cohesion<REF>Halliday and Hasan, 1976</REF>, the surface relationship among words that are semantically similar, has recently received much attention and has been widely used for text segmentation<REF>Morris and Hirst, 1991</REF>; <REF>Kozima, 1993</REF>; <REF>Hearst, 1994</REF>; <REF>Okumura and Honda, 1994</REF>	0	0	0
W06-2708	J86-3001	2006	Each tasks structure includes one or more of the following: giving definitions, formulating a question, obtaining the student answer and remediation by the tutor	0	Generally speaking, the structure of tutorial dialogue is governed by the task structure just as in task-oriented dialogue <TREF>Grosz and Sidner, 1986</TREF>	0	However, the specific annotation structure differs depending on the tutoring method	0	In our basic electricity and electronics domain, a tutorial session consists of a set of teach segments, and within each segment a number of task segments	0	0	0
W02-0105	J86-3001	2002	The discussion of context-free grammars naturally led us to pushdown automata which provided a nice contrast to the Turing machines we studied earlier in the course	0	And, having thus introduced stacks, we then investigated the <TREF>Grosz and Sidner 1986</TREF> stack-based theory of discourse structure, showing that language structures exist at granularities beyond the sentence level	0	Statistical language processing 6 lectures We began this unit by considering word frequency distributions, and in particular, Zipfs law  note that our having studied power-law distributions in the Web unit greatly facilitated this discussion	0	In fact, because we had previously investigated generative models for the Web, it was natural to consider <REF>Millers 1957</REF> monkeys model which demonstrates that very simple generative models can account for Zipfs law	0	0	0
P03-1071	J86-3001	2003	We tried to restrict ourselves to features whose inclusion is motivated by previous work pauses, speech rate and added features that are specific to multi-speaker speech overlap, changes in speaker activity	0	52 Features Cue phrases: previous work on segmentation has found that discourse particles like now, well provide valuable information about the structure of texts <TREF>Grosz and Sidner, 1986</TREF>; <REF>Hirschberg and Litman, 1994</REF>; <REF>Passonneau and Litman, 1997</REF>	0	We analyzed the correlation between words in the meeting corpus and labeled topic boundaries, and automatically extracted utterance-initial cue phrases9 that are statistically correlated with boundaries	0	For every word in the meeting corpus, we counted the number of its occurrences near any topic boundary, and its number of appearances overall	0	0	0
P03-1071	J86-3001	2003	We opted for a linear representation of discourse, since finer-grained discourse structures eg	0	<TREF>Grosz and Sidner, 1986</TREF> are generally considered to be difficult to mark reliably	0	Subjects were asked to mark each speaker change potential boundary as either boundary or non-boundary	0	In the resulting annotation, the agreed segmentation based on majority 1While it would be desirable to have a broader variety of meetings, we hope that experiments on this corpus will still carry some generality	0	0	0
C04-1034	J86-3001	2004	x will one one will	0	3 The DAR Algorithm 31 Search Space and DE lists dar presupposes the discourse structure described by <TREF>Grosz and Sidner 1986</TREF>	0	The minimal discourse unit is the utterance U Paragraphs correspond to discourse segments in texts	0	In dialogues discourse segments were manually marked se section 4	0	0	0
W00-1425	J86-3001	2000	1 Discourse coherence and aggregation hi NLG, theories based on domain-independent rhetorical relations, in particular, Rhetorical Structure Theory <REF>Mann and Thompson, 1987</REF>, are often used in text planning, whose task is to select the relevant information to be expressed and organise it into a hierarchical structure which captures certain discourse preferences such as preferences for the use of rhetorical relations	0	In the theory of discourse structure developed by <TREF>Grosz and Sidner 1986</TREF>, each discourse segment exhibits two types of coherence: local coherence among utterances inside the segment, and global coherence between this segment and other discourse segments	0	Discourse segments are connected by either a dominaTzce relation or a satisfaction-precedence relation	0	There has been an effort to synthesise tile two accounts of discourse structure	0	0	0
P97-1025	J86-3001	1997	7; t1  1u 22	0	IgroupF,  A subgroupU, F,  A unitF, 1,  A unitU, lt,  : 1  It Reason Hyp Def-subgroup 7 Def-unit 7 ::1 9 Hyp Def-unit 7 11 Def-subset 8 11 Def-subset 8 9 Def-group 7 Def-sohition 12 13 14 15 Def-unit 7 13 Def-unit 7 Def-soluti0n 13 17 18 15 Th-solution 17 16 19 Choice 10 20 Ded 7:21 Figure 3: Abstracted Proof about Unit Element of Subgroups of a discourse into an attentional hierarchy, since following the theory of Grosz and Sidner <TREF>Grosz and Sidner, 1986</TREF>, there is a one-to-one correspondence between the intentional hierarchy and the attentional hierarchy	0	In this section, we illustrate the attentional hierarchy with the help of an example, which will be used to discuss reference choices later	0	The input proof in Figure 3 is an ND style proof for the following theorem2: Theorem: Let F be a group and U a subgroup of F If i and lv are unit elements of F and U respectively, then 11u	0	0	0
P97-1025	J86-3001	1997	An explicit reference to a premise or an inference method is not restricted to a nominal phrase, as opposed to many of the treatments of subsequent references found in the literature	0	Despite this difference, the choices to be made here have much in common with the choices of subsequent references discussed in more general frameworks <REF>Reichman, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Dale, 1992</REF>: they depend on the availability of the object to be referred to in the context and are sensitive to the segmentation of a context into an attentional hierarchy	0	Therefore, we have first to devise an architecture for natural language generation that facilitates a natural and effective segmentation of discourse	0	The 190 basic idea is to distinguish between language production activities that effect the global shift of attention, and language production activities that involve only local attentional movement	0	0	0
P97-1025	J86-3001	1997	Concretely, PROVERB uses an architecture that models text generation as a combination of hierarchical planning and focus-guided navigation	0	Following <TREF>Grosz and Sidner, 1986</TREF> we further assume that every posting of a new task by the hierarchical planning mechanism creates new attentional spaces	0	Based on this segmentation, PROVERB makes reference choices according to a discourse theory adapted from Reichman <REF>Reichman, 1985</REF>; <REF>Huang, 1990</REF>	0	2 The System PROVERB PROVERB is a text planner that verbalizes natural deduction ND style proofs <REF>Gentzen, 1935</REF>	0	0	0
P94-1006	J86-3001	1994	In SDRT, on the other hand, not all discourse relations induce subordination, and so there is more scope for different discourse relations holding simultaneously in a consistent KB	0	Grosz and Sidners 1986 model of discourse interpretation is one where the same discourse elements are related simultaneously on the informational and intentional levels	0	But using their framework to model 1 is not straightforward	0	<REF>As Grosz and Sidner 1990</REF> point out: any model or theory of the communication situation must distinguish among beliefs and intentions of different agents, but theirs does not	0	0	0
P89-1016	J86-3001	1989	Although text processing systems are explicitly designed to analyze noninteractive discourse, they fail to provide the needed solutions for analyzing noninteractive speech	0	These systems currently have no means for identifying basic discourse elaborations and, to date, they have not incorporated discourse structural cues which could be helpful in signaling the relationship of discourse segments <TREF>Grosz  Sidner, 1986</TREF>; <REF>Litman  Allen, 1989</REF>; <REF>Oviatt  Cohen, 1989</REF>; <REF>Reichman, 1978</REF>	0	In addition, they are restricted to declarative sentences	0	One recent text analysis system called Tacitus Hobbs, <REF>Stickel, Martin  Edwards, 1988</REF> appears uniquely capable of handling some of the elaborative phenomena found in our corpus	0	0	0
P07-1128	J86-3001	2007	The problem is important for two reasons: First, empirical analysis has shown that annotating transcripts with semantic information eg , topics enables users to browse and find information from multimedia archives more efficiently <REF>Banerjee et al , 2005</REF>	0	Second, because the automatically generated segments make up for the lack of explicit orthographic cues eg , story and paragraph breaks in conversational speech, dialogue segmentation is useful in many spoken language understanding tasks, including anaphora resolution <TREF>Grosz and Sidner, 1986</TREF>, information retrieval eg , as input for the TREC Spoken Document Retrieval SDR task, and summarization <REF>Zechner and Waibel, 2000</REF>	0	This study therefore aims to explore whether a Maximum Entropy MaxEnt classifier can integrate multiple knowledge sources for segmenting recorded speech	0	In this paper, we first evaluate the effectiveness of features that have been proposed in previous work, with a focus on features that can be extracted automatically	0	0	0
P97-1014	J86-3001	1997	The data in both studies reveal that only a weak correlation between the SHIFT transitions and segment boundaries can be observed	0	This finding precludes a reliable prediction of segment boundaries based on the occurrence of 1 Our notion of referential discourse segment should not be confounded with the intentional one originating from <TREF>Grosz  Sidner 1986</TREF>, for reasons discussed in Section 2	0	104 SHIFTS and vice versa	0	In order to accommodate to these empirical results divergent solutions are proposed	0	0	0
P97-1014	J86-3001	1997	 RETAIN R ROUGH-SHIFT RS cu	0	Table h Transition Types As a working hypothesis, for the purposes of anaphora resolution we subscribe to Walkers model, in particular to that part which casts doubt on the hypothesized dependency of the attentional from the intentional structure of discourse <TREF>Grosz  Sidner, 1986</TREF>, p 180	0	We diverge from <REF>Walker 1996a</REF>, however, in that we propose an alternative to the caching mechanism, which we consider to be methodologically more parsimonious and, at least, to be equally effective for an elaboration of this claim, cf	0	Section 6	0	0	0
J95-1002	J86-3001	1995	RST was attractive for the IMAGENE project because of its ability to represent the hierarchical structure of text with rhetorical structures that matched the level of analysis required for the study of expressions of procedural relations	0	There is considerable debate in the field of discourse analysis concerning the relative importance of intentional structure and rhetorical relations eg , <TREF>Grosz and Sidner 1986</TREF>; <REF>Moore and Pollack 1992</REF>, most systems focusing on one or the other	0	The current study has conflated them, as the instructional texts have not tended to display the complex intentional structure common to persuasive texts and interactive discourses <REF>Vander Linden 1993b</REF>	0	Finally, RST has been used by many researchers for the purpose of text generation eg , <REF>Moore and Paris 1988</REF>; <REF>Hovy and McCoy 1989</REF>; <REF>Scott and Souza 1990</REF>; R6sner 33 Computational Linguistics Volume 21, Number 1 Precondition  1 Instruct  1 2 Remove uence 3 Grasp 4 Pull Purpose 151 Return 6 Place Figure 1 The RST representation of the Remove-Phone text	0	0	0
W04-2323	J86-3001	2004	The BDC corpus contains transcribed monologues by speakers who were instructed to perform a series of direction-giving tasks	0	The monologues were subsequently annotated by a group of subjects according to the <TREF>Grosz and Sidner 1986</TREF> theory of discourse structure	0	This theory provides a foundation for hierarchical segmentation of discourses into constituent parts	0	Some of the subjects were experts in discourse theory and others were naive annotators	0	0	0
W04-2323	J86-3001	2004	When high recall is preferred, methods requiring a majority are preferable to those that demand full consensus among annotators	0	The linguistic structure of a discourse is composed of utterances that exhibit meaningful hierarchical relationships <TREF>Grosz and Sidner, 1986</TREF>	0	Automatic segmentation of discourse forms the basis for many applications, from information retrieval and text summarization to anaphora resolution <REF>Hearst, 1997</REF>	0	These automatic methods, usually based on supervised machine learning techniques, require a manually annotated corpus of data for training	0	0	0
H89-2012	J88-1003	1989	Preprocessing the Corpus with a Part of Speech Tagger Phrasal verbs involving the preposition to raise an interesting problem because of the possible confusion with the infinitive marker to	0	We have found that if we first tag every word in the corpus with a part of speech using a method such as <REF>Church 1988</REF> or <TREF>DeRose 1988</TREF>, and then measure associations between tagged words, we can identify interesting contrasts between verbs associated with a following preposition toin and verbs associated with a following infinitive marker toto	1	Part of speech notation is borrowed from <REF>Francis and Kucera 1982</REF>; m  preposition; to  infinitive marker; vb  bare verb; vbg  verb  ing; vbd  verb  ed; vbz  verb  s; vbn  verb  en	0	The score identifies quite a number of verbs associated in an interesting way with to; restricting our attention to pairs with a score of 30 or more, there are 768 verbs associated with the preposition toin and 551 verbs with the infinitive marker toto	0	6	1
P97-1029	J88-1003	1997	Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora	0	There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, eg, <REF>Church, 1988</REF>; <REF>Cutting et al , 1992</REF>; <TREF>DeRose, 1988</TREF>, constraint-based techniques <REF>Karlsson et al , 1995</REF>; <REF>Voutilainen, 1995b</REF>; Voutilainen, Heikkil/i, and <REF>Anttila, 1992</REF>; <REF>Voutilainen and Tapanainen, 1993</REF>; <REF>Oflazer and KuruSz, 1994</REF>; <REF>Oflazer and Till 1996</REF> and transformation-based techniques <REF>Brilt, 1992</REF>; <REF>Brill, 1994</REF>; <REF>Brill, 1995</REF>	1	This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements	0	The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item	0	6	1
W02-0102	J88-1003	2002	HMMs have long been central in speech recognition <REF>Rabiner, 1989</REF>	0	Their application to partof-speech tagging <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF> kicked off the era of statistical NLP, and they have found additional NLP applications to phrase chunking, text segmentation, word-sense disambiguation, and information extraction	1	The algorithm is also important to teach for pedagogical reasons, as the entry point to a family of EM algorithms for unsupervised parameter estimation	0	Indeed, it is an instructive special case of 1 the inside-outside algorithm for estimation of probabilistic context-free grammars; 2 belief propagation for training singly-connected Bayesian networks and junction trees <REF>Pearl, 1988</REF>; <REF>Lauritzen, 1995</REF>; 3 algorithms for learning alignment models such as weighted edit distance; 4 general finitestate parameter estimation <REF>Eisner, 2002</REF>	0	6	1
W94-0111	J88-1003	1994	1; they closely replicate Brills results 1993b, page 96, allowing for the fact that his tests used more templates, including templates like if one of the three previous tags is A	0	Brills results demonstrate that this approach can outperform the Hidden Markov Model approaches that are frequently used for part-of-speech tagging <REF>Jelinek, 1985</REF>; <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF>; <REF>Cutting et al , 1992</REF>; <REF>Weischedel et al , 1993</REF>, as well as showing promise for other applications	1	The resulting model, encoded as a list of rules, is also typically more compact and for some purposes more easily interpretable than a table of HMM probabilities	0	An Incremental Algorithm It is worthwhile noting first that it is possible in some circumstances to significantly speed up the straightforward algorithm described above	0	1	3
W96-0101	J88-1003	1996	We describe a part-of-speech tagger built on these principles and we suggest a methodology for developing an adequate training corpus	0	In the part-of-speech hterature, whether taggers are based on a rule-based approach <REF>Klein and Simmons, 1963</REF>, <REF>Brill, 1992</REF>, <REF>Voutilainen, 1993</REF>, or on a statistical one <REF>Bahl and Mercer, 1976</REF>, <REF>Leech et al , 1983</REF>, <REF>Merialdo, 1994</REF>, <TREF>DeRose, 1988</TREF>, <REF>Church, 1989</REF>, <REF>Cutting et al , 1992</REF>, there is a debate as to whether more attention should be paid to lexical probabilities rather than contextual ones	1	<REF>Church, 1992</REF> claims that part-of-speech taggers depend almost exclusively on lexical probabilities, whereas other researchers, such as Voutilainen <REF>Karlsson et al , 1995</REF> argue that word ambiguities vary widely in function of the specific text and genre	0	Indeed, part of Churchs argument is relevant if a system is based on a large corpus such as the Brown corpus Francis and Kuera, 1982 which represents one million surface forms of morpho-syntacticaJly disambiguated words from a range of balanced texts	0	6	1
W97-0127	J88-1003	1997	The work is based on some similarity metrics	0	 Bahl, <REF>Brown, DeSouza and Mercer, 1989</REF>; Brown, Pietra, deSouza and Mercer,1992; <REF>Chang, 1995</REF>; DeRose,1988; <REF>Garside, 1987</REF>; <REF>Hughes, 1994</REF>; Jardino,1993; <REF>Jelinek, Mercer, and Roukos, 1990b</REF>; Wu, <REF>Wang, Yu and Wang, 1995</REF>; <REF>Magerman, 1994</REF>; <REF>McMahon, 1994</REF>; <REF>McMahon, 1995</REF>; <REF>Pereira, 1992</REF>; <REF>Resnik, 1992</REF>; <REF>Zhao, 1995</REF>; <REF>Brill 1993</REF> and <REF>Pop 1996</REF> present a transformation-based tagging	1	Before a part-of-speech tagger can be built, the word classifications are performed to help us choose a set of part-of-speech	0	They use the sum of two relative entropies obtained from neighboring words as the similarity metric to compare two words	0	6	1
C96-2114	J88-1003	1996	The training is performed on ambiguity classes and not on individual word tokens	0	<REF>Kallgren 1996</REF> gives a more covering description of how XPOST is used on the Swedish material and also sketches the major differences between this algorithm and some others used for tagging, such as PARTS <REF>Church 1988</REF> and VOLSUNGA <TREF>DeRose 1988</TREF>	1	A characteristic tbature of the SUC is its high number of different tags	0	The number of part-ofspeech tags used in the SUC is 21	0	2	1
H89-2014	J88-1003	1989	Several workers have addressed the problem of tagging text	0	Methods have ranged from locally-operating rules <REF>Greene and Rubin, 1971</REF>, to statistical methods <REF>Church, 1989</REF>; <TREF>DeRose, 1988</TREF>; <REF>Garside, Leech and Sampson, 1987</REF>; <REF>Jelinek, 1985</REF> and back-propagation <REF>Benello, Mackie and Anderson, 1989</REF>; <REF>Nakamura and Shikano, 1989</REF>	1	The statistical methods can be described in terms of Markov models	0	States in a model represent categories clc n is the number of different categories used	0	6	1
P89-1015	J88-1003	1989	Indeed, recent increased interest in the problem of disambiguating lexical category in English has led to significant progress in developing effective programs for assigning lexical category in unrestricted text	0	The most successful and comprehensive of these are based on probabilistic modeling of category sequence and word category <REF>Church 1987</REF>; <REF>Garside, Leech and Sampson 1987</REF>; <TREF>DeRose 1988</TREF>	1	These stochastic methods show impressive performance: Church reports a success rate of 95 to 99, and shows a sample text with an error rate of less than one percent	1	What may seem particularly surprising is that these methods succeed essentially without reference to syntactic structure; purely surface lexical patterns are involved	1	4	2
J93-1001	J88-1003	1993	Part-of-Speech Tagging Many of the very same methods are being applied to problems in natural language processing by many of the very same researchers	0	As a result, the empirical approach has been adopted by almost all contemporary part-of-speech programs: <REF>Bahl and Mercer 1976</REF>, <REF>Leech, Garside, and Atwell 1983</REF>, <REF>Jelinek 1985</REF>, <REF>Deroualt and Merialdo 1986</REF>, <REF>Garside, Leech, and Sampson 1987</REF>, <REF>Church 1988</REF>, <TREF>DeRose 1988</TREF>, <REF>Hindle 1989</REF>, Kupiec 1989, 1992, Ayuso et al	1	1990, de<REF>Marcken 1990</REF>, <REF>Karlsson 1990</REF>, <REF>Boggess, Agarwal, and Davis 1991</REF>, <REF>Merialdo 1991</REF>, and <REF>Voutilainen, Heikkila, and Anttila 1992</REF>	0	These programs input a sequence of words, eg, The chair will table the motion, and output a sequence of part-of-speech tags, eg, art noun modal verb art noun	0	6	1
P07-2053	J88-1003	2007	4 Concluding remarks Though there can be little doubt that the ruling system of bakeoffs actively encourages a degree of oneupmanship, our paper and our software are not offered in a competitive spirit	0	As we said at the out211 set, we dont necessarily believe HunPos to be in any way better than TnT, and certainly the main ideas have been pioneered by <TREF>DeRose 1988</TREF>, <REF>Church 1988</REF>, and others long before this generation of HMM work	1	But to improve the results beyond what a basic HMM can achieve one needs to tune the system, and progress can only be made if the experiments are end to end replicable	0	There is no doubt many other systems could be tweaked further and improve on our results what matters is that anybody could now also tweak HunPos without any restriction to improve the state of the art	0	5	2
E91-1025	J88-1003	1991	54 29 3 43 40 4 97 69 7 These results are remarkably good, in spite of the fact that many other systems are reported to reach an accuracy of 9697	0	<REF>Garside 1987</REF>, <REF>Marshall 1987</REF>, <TREF>DeRose 1988</TREF>, <REF>Church 1988</REF>, <REF>Ejerhed 1987</REF>, O<REF>Shaughnessy 1989</REF>	0	Those systems, however, all use heavier artillery than MorP, that has been deliberately restricted in accordance with the hypotheses presented above	1	This restrictiveness concerns both the size of the lexicon and the ways of carrying out disambiguation	1	1	3
J95-2004	J88-1003	1995	Although finite-state machines have been used for part-of-speech tagging <REF>Tapanainen and Voutilainen 1993</REF>; <REF>Silberztein 1993</REF>, none of these approaches has the same flexibility as stochastic techniques	1	Unlike stochastic approaches to part-of-speech tagging <REF>Church 1988</REF>; <REF>Kupiec 1992</REF>; <REF>Cutting et al 1992</REF>; <REF>Merialdo 1990</REF>; <TREF>DeRose 1988</TREF>; <REF>Weischedel et al 1993</REF>, up to now the knowledge found in finite-state taggers has been handcrafted and was not automatically acquired	1	<REF>Recently, Brill 1992</REF> described a rule-based tagger that performs as well as taggers based upon probabilistic models and overcomes the limitations common in rule-based approaches to language processing: it is robust and the rules are automatically ac Mitsubishi Electric Research Laboratories, 201 Broadway, Cambridge, MA 02139	0	E-mail: rocbe/schabesmerlcom	0	2	2
W97-0110	J88-1003	1997	Research on corpus-based natural language learning and processing is rapidly accelerating following the introduction of large on-line corpora, faster computers, and cheap storage devices	0	Recent work involves novel ways to employ annotated corpus in part of speech tagging <REF>Church 1988</REF> <REF>Derose 1988</REF> and the application of mutual information statistics on the corpora to uncover lexical information <REF>Church 1989</REF>	1	The goal of the research is the construction of robust and portable natural language processing systems	0	The wide range of topics available on the Internet calls for an easily adaptable information extraction system for different domains	0	6	1
W95-0101	J88-1003	1995	There has recently been a great deal of work exploring methods for automatically training part of speech taggers, as an alternative to laboriously hand-crafting rules for tagging, as was done in the past <REF>Klein and Simmons, 1963</REF>; <REF>Harris, 1962</REF>	0	Almost all of the work in the area of automatically trained taggers has explored Markov-model based part of speech tagging <REF>Jelinek, 1985</REF>; <REF>Church, 1988</REF>; <REF>Derose, 1988</REF>; <REF>DeMarcken, 1990</REF>; <REF>Cutting et al , 1992</REF>; <REF>Kupiec, 1992</REF>; <REF>Charniak et al , 1993</REF>; <REF>Weischedel et al , 1993</REF>; <REF>Schutze and Singer, 1994</REF>; <REF>Lin et al , 1994</REF>; <REF>Elworthy, 1994</REF>; <REF>Merialdo, 1995</REF>	1	2 For a Markov-model based tagger, training consists of learning both lexical probabilities Pwordltag and contextual probabilities Ptagiltagil tagi-n	0	Once trained, a sentence can be tagged by searching for the tag sequence that maximizes the product of lexical and contextual probabilities	0	6	1
J97-3003	J88-1003	1997	Unknown Words Unknown Common Words Unknown Proper Nouns Tagger Guesser Metrics Error Error Coverage Error Coverage HMM Xerox mean 17851643 30022169 37567270 10785563 63797113 s-error 0484710 0469922 1687396 0613745 1714969 HMM Cascade mean 12378716 21266264 36507909 7776456 64795969 s-error 0917656 0403957 2336381 0853958 2206457 Brill Brill mean 14688501 27411736 38998687 6439525 62160917 s-error 0908172 0539634 2627234 0501082 4010992 Brill Cascade mean 11327863 20986240 37933048 5548990 63816586 s-error 0761576 0480798 2353510 0561009 3775991 the Brown Corpus, we obtained the error rate mean 0 4003093 with the standard error deB0155599	0	This agrees with the results on the closed dictionary ie , without unknown words obtained by other researchers for this class of the model on the same corpus <REF>Kupiec 1992</REF>; <TREF>DeRose 1988</TREF>	1	The Brill tagger showed some better results: error rate mean 0 3327366 with the standard error deBO 123903	0	Although our primary goal was not to compare the taggers themselves but rather their performance with the guessing components, we attribute the difference in their performance to the fact that Brills tagger uses the information about the most likely tag for a word whereas the HMM tagger did not have this information and instead used the priors for a set of POS-tags ambiguity class	0	4	2
J94-2001	J88-1003	1994	A lot of effort has been devoted in the past to the problem of tagging text, ie assigning to each word the correct tag part of speech in the context of the sentence	0	Two main approaches have generally been considered: rule-based <REF>Klein and Simmons 1963</REF>; <REF>Brodda 1982</REF>; <REF>Paulussen and Martin 1992</REF>; <REF>Brill et al 1990</REF> probabilistic <REF>Bahl and Mercer 1976</REF>; <REF>Debili 1977</REF>; <REF>Stolz, Tannenbaum, and Carstensen 1965</REF>; <REF>Marshall 1983</REF>; <REF>Leech, Garside, and Atwell 1983</REF>; <REF>Derouault and Merialdo 1986</REF>; <TREF>DeRose 1988</TREF>; <REF>Church 1989</REF>; <REF>Beale 1988</REF>; <REF>Marcken 1990</REF>; <REF>Merialdo 1991</REF>; <REF>Cutting et al 1992</REF>	1	More recently, some work has been proposed using neural networks <REF>Benello, Mackie, and Anderson 1989</REF>; <REF>Nakamura and Shikano 1989</REF>	0	Multimedia Communications Department, Institut EURECOM, 2229 Route des Cretes, BP 193, 06904 Valbonne Cedex France; merialdoeurecomfr	0	6	1
J94-2001	J88-1003	1994	for evaluation at word level, choose the most probable tag for each word in the sentence argmax argmax Wi  t pti  t/W  t  pW, T T:tit where Wi is the tag assigned to word wi by the tagging procedure b in the context of the sentence W, We call this procedure Maximum Likelihood ML tagging	0	It is interesting to note that the most commonly used method is Viterbi tagging see <TREF>DeRose 1988</TREF>; <REF>Church 1989</REF> although it is not the optimal method for evaluation at word level	1	The reasons for this preference are presumably that:  Viterbi tagging is simpler to implement than ML tagging and requires less computation although they both have the same asymptotic complexity  Viterbi tagging provides the best interpretation for the sentence, which is linguistically appealing  ML tagging may produce sequences of tags that are linguistically impossible because the choice of a tag depends on all contexts taken together	1	However, in our experiments, we will show that Viterbi and ML tagging result in very similar performance	0	2	2
J01-2002	J88-1003	2001	Although methods for unsupervised training of HMMs do exist, training is usually done in a supervised way by estimation of the above probabilities from relative frequencies in the training data	0	The HMM approach to tagging is by far the most studied and applied <REF>Church 1988</REF>; <TREF>DeRose 1988</TREF>; <REF>Charniak 1993</REF>	1	In van <REF>Halteren, Zavrel, and Daelemans 1998</REF> we used a straightforward implementation of HMMs, which turned out to have the worst accuracy of the four competing methods	0	In the present work, we have replaced this by the TnT system we will refer to this tagger as HMM below	0	6	2
J95-3004	J88-1003	1995	<REF>Choueka and Lusignan 1985</REF> presented a system for the morphological tagging of large texts that is based on the short context of the word but also depends heavily on human interaction	0	Methods using the short context of a word in order to resolve ambiguity usually categorical ambiguity are very common in English and other languages <TREF>DeRose 1988</TREF>; <REF>Church 1988</REF>; <REF>Karlsson 1990</REF>	1	A system using this approach was developed by Levinger and Ornan in order to serve as a component in their project of morphological disambiguation in Hebrew <REF>Levinger 1992</REF>	0	The main resource, used by this system for disambiguation, is a set of syntactic constraints that were defined manually by the authors and followed two theoretical works that defined short context rules for Hebrew <REF>Pines 1975</REF>; <REF>Albeck 1992</REF>	0	6	1
J95-3004	J88-1003	1995	Most successful methods have followed speech recognition systems <REF>Jelinek, Mercer, and Roukos 1992</REF> and used large corpora to deduce the probability of each part of speech in the current context usually the two previous words--trigrams	0	These methods have reported performance in the range of 95-99 correct by word <TREF>DeRose 1988</TREF>; <REF>Cutting et al 1992</REF>; <REF>Jelinek, Mercer, and Roukos 1992</REF>; <REF>Kupiec 1992</REF>	1	The difference in performance is due to different evaluation methods, different tag sets, and different corpora	0	<REF>See Church 1992</REF> for a survey	0	2	1
P96-1010	J88-1003	1996	More precisely, assume that the word wh occurs in a sentence W  wlWkwn, and that w is a word we are considering substituting for it, yielding sentence W I Word w is then preferred over wk iff PW > PW, where PW and PW are the probabilities of sentences W and W f respectively	0	1 We calculate PW using the tag sequence of W as an intermediate quantity, and summing, over all possible tag sequences, the probability of the sentence with that tagging; that is: PW   PW, T T where T is a tag sequence for sentence W The above probabilities are estimated as is traditionally done in trigram-based part-of-speech tagging <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF>: PW,T  PWITPT  1  HPwiti HPt, lt,2t,l2 i i where T  tltn, and Ptitl-2ti-1 is the prob ability of seeing a part-of-speech tag tl given the two preceding part-of-speech tags ti-2 and ti-1	1	Equations 1 and 2 will also be used to tag sentences W and W  with their most likely part-of-speech sequences	0	This will allow us to determine the tag that 1To enable fair comparisons between sequences of different length as when considering maybe and may be, we actually compare the per-word geometric mean of the sentence probabilities	0	6	1
A92-1018	J88-1003	1992	More recently, Koskenniemi also used a rule-based approach implemented with finite-state machines <REF>Koskenniemi, 1990</REF>	0	Statistical methods have also been used eg , <TREF>DeRose, 1988</TREF>, <REF>Garside et al , 1987</REF>	1	These provide the capability of resolving ambiguity on the basis of most likely interpretation	1	A form of Markov model has been widely used that assumes that a word depends probabilistically on just its part-of-speech category, which in turn depends solely on the categories of the preceding two words	0	6	1
J96-2001	J88-1003	1996	Estimating the Lexical Priors for Rare Forms For a common form such as lopen walk a reasonable estimate of the lexical prior probabilities is the MLE, computed over all occurrences of this form	0	So, in the UdB corpus, lopen occurs 92 times as an infinitive and 43 times as a finite plural, so the MLE 1 Even models of disambiguation that make use of context, such as statistical n-gram taggers, often presume some estimate of lexical priors, in addition to requiring estimates of the transition probabilities of sequences of lexical tags <REF>Church 1988</REF>; <TREF>DeRose 1988</TREF>; <REF>Kupiec 1992</REF>, and this again brings up the question of what to do about unseen or low-frequency forms	1	In working taggers, a common approach is simply to apply a uniform small probability to the various senses of unseen or low-frequency forms: this was done in the tagger discussed in <REF>Church 1988</REF>, for example	0	156 Baayen and Sproat Lexical Priors for Low-Frequency Forms to> 8 Figure 1 I I I I 0 2 4 6 log frequency class Relative frequency of Dutch infinitives versus finite plurals in the Uit den Boogaart corpus, as a function of the natural log of the frequency of the word forms	0	6	1
E95-1022	J88-1003	1995	Its recall is very high 997 of all words receive the correct morphological analysis, but this system leaves 3-7 of all words ambiguous, trading precision for recall	0	157 ena or the linguists abstraction capabilities eg knowledge about what is relevant in the context, they tend to reach a 95-97 accuracy in the analysis of several languages, in particular English <REF>Marshall 1983</REF>; Black et aL 1992; <REF>Church 1988</REF>; <REF>Cutting et al 1992</REF>; de <REF>Marcken 1990</REF>; <TREF>DeRose 1988</TREF>; <REF>Hindle 1989</REF>; <REF>Merialdo 1994</REF>; <REF>Weischedel et al 1993</REF>; <REF>Brill 1992</REF>; <REF>Samuelsson 1994</REF>; Eineborg and Gambick 1994, etc	1	Interestingly, no significant improvement beyond the 97 barrier by means of purely data-driven systems has been reported so far	0	In terms of the accuracy of known systems, the data-driven approach seems then to provide the best model of part-of-speech distribution	0	6	1
C90-3086	J88-1003	1990	This will partly be based on another important step in the process, namely the construction of constituents, in particular noun phrases and prepositional phrases <REF>Church 1988</REF>, <REF>Kfillgren 1984c</REF>, and partly on a more general algorithm that for pairs or longer sequences of tags calculates the relative probability of alternative tag assignments	1	The principles behind such algorithms are known, but they have never been tried on Swedish material <TREF>DeRose 1988</TREF>, <REF>Marshall 1987</REF>, <REF>EegOlofsson 1985</REF>	1	An indispensable step in the disambiguation process is the assignment of clause boundaries, which presupposes established constituents at the same time as it forms an important basis for disambiguating chains of tags	0	Methods for this are being tested out on Swedish material <REF>Ejerhed 1989</REF>	0	6	1
J95-4004	J88-1003	1995	There are a number of large tagged corpora available, allowing for a variety of experiments to be run	0	Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years eg , <REF>Jelinek 1985</REF>; <REF>Church 1988</REF>; <REF>Derose 1988</REF>; <REF>Hindle 1989</REF>; <REF>DeMarcken 1990</REF>; <REF>Merialdo 1994</REF>; <REF>Brill 1992</REF>; <REF>Black et al 1992</REF>; <REF>Cutting et al 1992</REF>; <REF>Kupiec 1992</REF>; <REF>Charniak et al 1993</REF>; <REF>Weischedel et al 1993</REF>; <REF>Schutze and Singer 1994</REF>	1	Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography	0	Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation	0	6	1
J95-4004	J88-1003	1995	However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics	0	Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging <REF>Jelinek 1985</REF>; <REF>Church 1988</REF>; <REF>Derose 1988</REF>; <REF>DeMarcken 1990</REF>; <REF>Merialdo 1994</REF>; <REF>Cutting et al 1992</REF>; <REF>Kupiec 1992</REF>; <REF>Charniak et al 1993</REF>; <REF>Weischedel et al 1993</REF>; <REF>Schutze and Singer 1994</REF>	1	41 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows	0	9 The initial-state annotator assigns each word its most likely tag as indicated in the training corpus	0	6	1
C96-2151	J88-1003	1996	Statistical taggers usually work as follows: First, each word in the input word string 1471,   , W, is assigned all possible tags according to the lexicon, thereby creating a lattice	0	A dynamic programming technique is then used to find tag the sequence 5/,, , that maximizes PT1,,Tn I Wl,   , Wn  tt  IIPTk T1,,Tk-1;Wl,,Wn kl 1:1 PTk Tk-NI,,Tk-1; VIZk  7 PT wk PTk k-Nl,, k-l  kl fl PTk PT, Tk-N,, - PWk I Tk : PWk Since the maximum does not depend on the factors PWk, these can be omitted, yielding the standard statistical PoS tagging task: max - PTk IU-V,,Tk-JPWk JT TI,,T, tl This is well-described in for example <TREF>DeRose 1988</TREF>	1	We thus have to estimate the two following sets of probabilities:  Lexical probabilities: The probability of each tag T i conditional on the word W that is to be tagged, pr I I wr	0	i Often the converse probabilities PW are given instead, but we will for reasons soou to become apparent use the former formulation	0	6	1
A92-1020	J88-1003	1992	Recent research advances may lead to the development of viable book indexing methods for Chinese books	0	These include the availability of efficient and high precision word segmentation methods for Chinese text <REF>Chang et al , 1991</REF>; <REF>Sproat and Shih, 1990</REF>; <REF>Wang et al , 1990</REF>, the availability of statistical analysis of a Chinese corpus <REF>Liu et al , 1975</REF> and large-scale electronic Chinese dictionaries with partof-speech information <REF>Chang et al , 1988</REF>; BDC, 1992, the corpus-based statistical part-of-speech tagger <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF>; <REF>Beale, 1988</REF>, as well as phrasal and clausal analyzers <REF>Church 1988</REF>; <REF>Ejerhed 1990</REF> 2	1	Problem description As being pointed out in <REF>Salton, 1988</REF>, back-of-book indexes may consist of more than one word that are derived from a noun phrase	0	Given the text of a book, an indexing system, must perform some kind of phrasal and statistical analysis in order to produce a list of candidate indexes and their occurrence statistics in order to generate indexes as shown in Figure 1 which is an excerpt from the reconstruction of indexes of a book on transformational grammar for Mandarin Chinese <REF>Tang, 1977</REF>	0	6	1
C96-2192	J88-1003	1996	In this paper, we report on experimental work dealing with the part-of-speech tagging of a corpus of transcribed spoken Swedish	0	The tagger used implements a standard probabilistic biclass model see, e g, <TREF>DeRose 1988</TREF> trained on a tagged subset of the Stockhohn-Ume Corpus of written Swedish <REF>Ejerhed et al 1992</REF>	1	Given that the transcriptions contain many modifications of standard orthography in order to capture spoken language variants, reductions, etc	0	a special lexicon had to be developed to map spoken langnage variants onto their canonical written language forms	0	3	2
W96-0102	J88-1003	1996	Several approaches have been proposed to construct automatic taggers	0	Most work on statistical methods has used n-gram models or Hidden Markov Model-based taggers eg <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF>; <REF>Cutting et al 1992</REF>; <REF>Merialdo, 1994</REF>, etc	1	In 14 these approaches, a tag sequence is chosen for a sentence that maximizes the product of lexical and contextual probabilities as estimated from a tagged corpus	0	In rule-based approaches, words are assigned a tag based on a set of rules and a lexicon	0	6	1
H91-1077	J88-1003	1991	Categorical ambiguity, however, is of a different kind and is resolved in a different way	0	For the purposes of the present paper, it will be assumed that only content words are at issue, and that the syntactic category of all content words in the text that is under study can be determined automatically <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF>	1	The problem is simply to decide which sense of a content word--noun, verb, adjective, or adverb---is appropriate in a given linguistic context	0	It will also be assumed that sense resolution for individual words can be accomplished on the basis of information about the irnrnediate linguistic context	0	6	1
J93-2006	J88-1003	1993	Purely rule-based techniques seemed too brittle for dealing with the variety of constructions, the long sentences averaging 29 words per sentence, and the degree of unexpected input	1	Statistical models based on local information eg , <TREF>DeRose 1988</TREF>; <REF>Church 1988</REF> might operate effectively in spite of sentence length and unexpected input	1	To see whether our four hypotheses in italics above effectively addressed the four concerns above, we chose to test the hypotheses on two well-known problems: ambiguity both at the structural level and at the part-of-speech level and inferring syntactic and semantic information about unknown words	0	Guided by the past success of probabilistic models in speech processing, we have integrated probabilistic models into our language processing systems	0	2	2
J93-2006	J88-1003	1993	We report in Section 2 on our experiments on the assignment of part of speech to words in text	0	The effectiveness of such models is well known <TREF>DeRose 1988</TREF>; <REF>Church 1988</REF>; <REF>Kupiec 1989</REF>; <REF>Jelinek 1985</REF>, and they are currently in use in parsers eg de <REF>Marcken 1990</REF>	1	Our work is an incremental improvement on these models in three ways: 1 Much less training data than theoretically required proved adequate; 2 we integrated a probabilistic model of word features to handle unknown words uniformly within the probabilistic model and measured its contribution; and 3 we have applied the forward-backward algorithm to accurately compute the most likely tag set	1	In Section 3, we demonstrate that probability models can improve the performance of knowledge-based syntactic and semantic processing in dealing with structural ambiguity and with unknown words	0	5	2
A94-1009	J88-1003	1994	Trento, Italy, pages 133-140, Association for Computational Linguistics	0	Steven J <TREF>DeRose 1988</TREF>	0	Grammatical Category Disambiguation by Statistical Optimization	0	Computational Linguistics, 141 :31-39	0	6	1
A94-1009	J88-1003	1994	The first major use of HMMs for part of speech tagging was in CLAWS <REF>Garside et al , 1987</REF> in the 1970s	0	With the availability of large corpora and fast computers, there has been a recent resurgence of interest, and a number of variations on and alter53 natives to the FB, Viterbi and BW algorithms have been tried; see the work of, for example, Church <REF>Church, 1988</REF>, Brill <REF>Brill and Marcus, 1992</REF>; <REF>Brill, 1992</REF>, DeRose <TREF>DeRose, 1988</TREF> and gupiec <REF>Kupiec, 1992</REF>	1	One of the most effective taggers based on a pure HMM is that developed at Xerox <REF>Cutting et al , 1992</REF>	0	An important aspect of this tagger is that it will give good accuracy with a minimal amount of manually tagged training data	0	6	1
P02-1041	J88-2003	2002	Different accessibility relations can be modeled, eg to distinguish a local context for resolving reflexive anaphors like himself  from a global context <REF>Kruijff, 2001</REF>	0	Finally, the rich temporal ontology underlying models of tense and aspect such as <TREF>Moens and Steedman 1988</TREF> can be captured using the sorting strategy	1	Earlier work like <REF>Blackburn and Lascarides 1992</REF> already explored such ideas	0	HLDS employs hybrid logic to integrate Moens and Steedmans notion of the event nucleus directly into meaning representations	0	6	1
P00-1010	J88-2003	2000	However, at least 30 of the dates and times in the MUC test were fixed-format ones occurring in document headers, trailers, and copyright notices	0	 Finally, there is a large body of work, eg, <TREF>Moens and Steedman 1988</TREF>, <REF>Passoneau 1988</REF>, <REF>Webber 1988</REF>, <REF>Hwang 1992</REF>, <REF>Song and Cohen 1991</REF>, that has focused on a computational analysis of tense and aspect	1	While the work on event chronologies is based on some of the notions developed in that body of work, we hope to further exploit insights from previous work	1	Conclusion We have developed a temporal annotation specification, and an algorithm for resolving a class of time expressions found in news	0	4	2
J98-3003	J88-2003	1998	Other aspects of our ontology are designed following proposals by <REF>Jackendoff 1990</REF>, in particular his analysis of movement events	0	2 <TREF>Moens and Steedman 1988</TREF> also use this term, but they restrict it to momentaneous events	1	Unfortunately, the terminology used in the literature for these kinds of categories varies so much that a standardization seems out of reach	1	404 Stede Verb Alternations event1 fill conf---- > not-full -state-1    f > pa>btination  fill-state-2   water-1  value > full Figure 2 SitSpec representing a fill-event	0	1	3
J98-3003	J88-2003	1998	As their central feature we take them to always involve some change of state: the building loses its integrity, the book comes into existence, or gets finished	0	<REF>While Bach 1986</REF> did not investigate the internal structure of events, others suggested that this needs to be done eg , <TREF>Moens and Steedman 1988</TREF>; <REF>Parsons 1990</REF>	1	<REF>Pustejovsky 1991</REF> treated Vendlerian accomplishments and achievements as transitions from a state Qy to NOT-Qy, and suggested that accomplishments in addition have an intrinsic agent performing an activity that brings about the change of state	0	We follow this line, but modify it in some ways	0	1	3
P97-1013	J88-2003	1997	In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs	0	Such constructs can include tense 96 and aspect <TREF>Moens and Steedman, 1988</TREF>; <REF>Webber, 1988</REF>; <REF>Lascarides and Asher, 1993</REF>, certain patterns of pronominalization and anaphoric usages <REF>Sidner, 1981</REF>; <REF>Grosz and Sidner, 1986</REF></REF>; <REF>Sumita et al , 1992</REF>; <REF>Grosz, Joshi, and Weinstein, 1995</REF>,/t-clefts <REF>Delin and Oberlander, 1992</REF>, and discourse markers or cue phrases <REF>Ballard, Conrad, and Longacre, 1971</REF>; <REF>Halliday and Hasan, 1976</REF>; <REF>Van Dijk, 1979</REF>; <REF>Longacre, 1983</REF>; <REF>Grosz and Sidner, 1986</REF></REF>; <REF>Schiffrin, 1987</REF>; <REF>Cohen, 1987</REF>; <REF>Redeker, 1990</REF>; <REF>Sanders, Spooren, and Noordman, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1995</REF>; <REF>Fraser, 1996</REF>; <REF>Moser and Moore, 1997</REF>	1	In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts	0	The intuition behind our choice relies on the following facts:  Psycholinguistic and other empirical research <REF>Kintsch, 1977</REF>; <REF>Schiffrin, 1987</REF>; <REF>Segal, Duchan, and Scott, 1991</REF>; <REF>Cahn, 1992</REF>; <REF>Sanders, Spooren, and Noordman, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1995</REF>; <REF>Costermans and Fayol, 1997</REF> has shown that discourse markers are consistently used by human subjects both as cohesive ties between adjacent clauses and as macroconnectors between larger textual units	0	3	2
W00-0205	J88-2003	2000	The feature specification of this ompositionally derived accomplishment is therefore identical to that of a sentence containing a telic accomplishment verb, such as destroy	1	According to many researchers, knowledge of lexical aspect--how verbs denote situations as developing or holding in time-may be used to interpret event sequences in discourse <REF>Dowty, 1986</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Passoneau, 1988</REF>	1	In particular, Dowty suggests that, absent other cues, a relic event is interpreted as completed before the next event or state, as with ran into lhe room in 4a; in contrast, atelic situations, such as run, was hungry in 4b and 4 are interpreted as contemporaneous with the following situations: fell and made a pizza, respectively	0	4 a Mary ran into the room	0	3	2
E93-1030	J88-2003	1993	In 10, s is the consequent state of the event of John greeting Max, and it holds at the time t which precedes now	0	So our semantics of the perfect is like that in <TREF>Moens and Steedman 1988</TREF>: a perfect transforms an event into a consequent state, and asserts that the consequent state holds	1	The pluperfect of a state, such as 11, therefore, is assumed to first undergo a transformation into an event	0	11 John had loved Mary	0	4	2
W99-0108	J88-2003	1999	Other genres of text might depend on other kinds of structuring devices	0	Changes in time scale or time, as we redefined the category, may require world knowledge reasoning to recoguize but are often indicated by either cue words and phrases eg , n/he years ago ,  a year, for months; several months ago, a change in grammatical time of the verb eg , past tense versus present tense, or changes in aspect eg , atomic versus extended events versus states as defined by <TREF>Moens  Steedman 1988</TREF>	1	In considering how time change might affect anaphoric expression choice, we consider the choice for the first mention of a discourse entity in a sentence where that entity has recently been referred to in the discourse	0	Our hypothesis is that: Changes in time reliably signal changes of the thread in newspaper articles; definite descriptions should appear when the current reference to a discourse entity is in a different thread from the last reference to that entity and pronouns should occur when the previous mention is in the same thread 3	0	6	1
P98-1007	J88-2003	1998	The imperfective point of view brought by IMP imposes a change of point of view on the term of the eventuality	0	As for accomplishments, we can assume that they can be decomposed into several stages, according to <TREF>Moens and Steedman, 1988</TREF>: first a preparatory phase, second a culmination or achievement we are not concerned here with the result state	1	We can then say that IMP refers only to the preparatory phase, so that the term of the eventuality loses all relevance	0	This explains the so-called imperfective paradox: it is possible to use IMP even though the eventuality never reaches its term: 6 a I1 traversait la rue quand la voiture la 6cras6 He was crossing the street when the car hit him b  I1 traversa la rue quand la voiture la 6cras6 He crossed the street when the car hit him As for achievements, we can assume that they are reduced to a culmination	0	3	2
E93-1031	J88-2003	1993	Secondly, it has been argued that A when B permits many possible temporal relationships between the eventualities denoted by A and B cf	0	<TREF>Moens and Steedman 1988</TREF>; its for this reason that 2c can be interpreted as denoting El; 260 but given this permissiveness, why is 2d not as acceptable as 2c	0	3 The basic explanation: temporal presuppositions The basic explanation for the inappropriateness of 2b and 2d is actually quite simple	0	Sentences containing temporal connectives are presuppositional: the temporal clause introduces an eventuality that must be presupposed to have occurred, for the sentence as a whole to have a truth-value cf	0	6	1
W04-0212	J88-2003	2004	Second, with when, the almost equal distribution of preposed and postposed tokens suggests either free variation of the two patterns or different uses of the two patterns, with each use favoring a different pattern	1	The latter would accord with a theoretical distinction that has been made between postposed when expressing a purely temporal relation between the two clauses, and preposed when expressing a contingent relation between them <TREF>Moens and Steedman, 1988</TREF>	0	Integrated evidence from the PTB and PropBank may help distinguish the two possibilities	0	Third, there is a striking contrast between the patterning of although and even though, especially if one assumes that even though like even when, even after, even if, etc	0	6	1
W08-1119	J88-2003	2008	Weneedamuchbettermodelofhowtocommunicate time, and how this communication depends on the semantics and linguistic expression of the events being described	0	An obvious first step, which we are currently working on, is to include a linguisticallymotivatedtemporalontology <REF>MoensandSteedman, 1988</REF>, which will be separate from the existing domain ontology	1	We also need better techniques for communicating the temporal relationships between events in cases where they are not listed in chronological order <REF>Oberlander and Lascarides, 1992</REF>	0	6 Discussion Two discourse analysts from Edinburgh University, Dr Andy McKinlay and Dr Chris McVittie, kindly examined and compared some of the human and BT45 texts	0	3	2
E93-1048	J88-2003	1993	The domain is limited to trajectoryof-motion events specified by the verbs run, jog, sit is worth noting that as an alternative to positing a lexical ambiguity, one could just as easily invoke a coercion operator on an event predicate Pz mapping it to the process predicate he	0	plurPx  e, which would bring the present treatment more in line with <TREF>Moens and Steedman 1988</TREF> and <REF>Jackendoff 1991</REF>	1	plod, and walk; the locative prepositions to, towards, from, away from, along, eastwards, westwards, and to and back; various landmarks; the distance adverbials n miles; the frequency adverbials twice and n times; and finally the temporal adverbials for and in	0	Trajectory-of-motion events are modeled as continuous constant rate changes of location in one dimension of the TRAJECTOR relative to one or more LANDMARKS following <REF>Regier 1992</REF> in his use of Langackers 1987 terminology	0	4	2
E93-1048	J88-2003	1993	2 3 Theory 31 Ontology Various authors including <REF>Link, 1983</REF>, <REF>Bach, 1986</REF>, <REF>Krifka, 1989</REF>, <REF>Eberle, 1990</REF> have proposed modeltheoretic treatments in which a parallel ontological distinction is made between substances and things, processes and events, etc A similarly parallel distinction is employed here, but in a rather different way: unlike the above treatments, the present account models substances, processes, and other such entities as abstract kinds whose realizations vary in amount	0	As such, the approach developed here may be seen as building upon the work of <REF>Carlson 1977</REF> and his successors; it also represents one way to further formalize the intuitions found in <TREF>Moens and Steedman 1988</TREF> and <REF>Jackendoff 1991</REF>	1	<REF>Following Schubert and Pelletier 1987</REF>, the present account distinguishes individuals from kinds, but not from stages or quantities	0	Extending their ontology, the same distinction is assumed to hold not only in the domain of materials but also in the domain of eventualities, and derivatively in the domains of space and time as well	0	5	2
E95-1036	J88-2003	1995	Note that in a terminal DRS ready for an embedding test, all the auxiliary Rpts disappear do not participate in the embedding	0	The perfect is analyzed by using the notion of a nucleus <TREF>Moens and Steedman, 1988</TREF> to account for the inner structure of an eventuality	1	A nucleus is defined as a structure containing a preparatory process, culmination and consequent state	0	The categorization of verb phrases into different aspectual classes can be phrased in terms of which part of the nucleus they refer to	0	3	2
W98-0702	J88-2003	1998	Moreover, the semantic category of these features can also play a role	0	For example, Sue played the piano is nonc,lminated, while Sue played the sonata signifies a c-lminated event this example comes from <TREF>Moens and Steedman 1988</TREF>	1	32 Classes of Ambiguous Verbs Placing aspectually ambiguous verbs into semantic categories will help predict how these verbs combine with their arguments to determine aspectual class	1	This is because many verbs with related meanings combine with their arguments in similar ways	0	6	1
W98-0702	J88-2003	1998	For example, shaw denotes a state in, H/ lumbar puncture showed evidence of white cells, but denotes an event in, He showed me the photographs	0	This ambiguity presents a diculty for automatically classifying a verb because the aspectual class of a clause is a function of several clausal constituents in addition to the main verb <REF>Dowry, 1979</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Pustejovsky, 1991</REF>	1	However, previous work that numerically evaluates aspectual classification has looked at verbs in isolation <REF>Klavans and Chodorow, 1992</REF>; <REF>Siegel, 1997</REF>	0	10 The verb have is particularly problematic	0	6	1
W98-0702	J88-2003	1998	For example, I made a fire is culminated, whereas, I gazed at the sunset is non-culminated	1	Aspectual classification is necessary for interpreting temporal modifiers and assessing temporal entailments <TREF>Moens and Steedman, 1988</TREF>; <REF>Dorr, 1992</REF>; <REF>Klavans, 1994</REF>, and is therefore a necessary component for applications that perform certain language interpretation, summarization, information retrieval, and machine translation tasks	1	Aspectual classification is a diflqcult problem because many verbs, like have, are aspectually ambiguous	0	In this paper, I demonstrate that verbs can be disambiguated according to aspect by the semantic category of the direct object	0	3	2
W98-0702	J88-2003	1998	Finally, Section 8 provides conclusions and describes future work	0	2 Aspect in Natural Language Aspectual classification is a key component of models that assess temporal constraints between clauses <TREF>Moens and Steedman, 1988</TREF>; <REF>Hwang and Schubert, 1991</REF>; <REF>Dorr, 1992</REF>; <REF>Hitzeman et al , 1994</REF>	1	For example, stativity must be identified to detect temporal constraints between clauses connected with when	0	For example, in interpreting I, I She had good strength when objectively tested	0	3	1
W91-0222	J88-2003	1991	In 26i, the event is associated with the features d,t,-a, whereas, in 26ii the event is associated with the features d,t,a	0	According to <REF>Bennett et al , 1990</REF> in the spirit of <TREF>Moens and Steedman, 1988</TREF>, predicates are allowed to undergo an atomicity coercion in which an inherently non-atomic predicate such as dio may become atomic under certain conditions	1	These conditions are language-specific in nature, ie, they depend on the lexical-semantic structure of the predicate in question	0	Given the featural scheme that is imposed on top of the lexical-semantic framework, it is easy to specify coercion functions for each language	0	5	2
W91-0222	J88-2003	1991	In light of these observations, the lexicM-semantic structure adopted for UNITRAN is an augmented form of Jackendoffs representation in which events are distinguished from states as before, but they are further subdivided into activities, achievements, and accomplishments	0	The subdivision is achieved by means of three features proposed by <REF>Bennett et al , 1990</REF> following the framework of <TREF>Moens and Steedman, 1988</TREF> in the spirit of <REF>Dowty, 1979</REF> and <REF>Vendler, 1967</REF>: dynamic ie , events vs states, as in the Jackendoff framework, :t:telic i e, culminative events transitions vs nonculminative events activities, and atomic ie , point events vs extended events	1	This featural system is imposed on top of the lexical-semantic framework proposed by Jackendoff	0	For example, the primitive GO would be annotated with the features d,t,-a for the verb destroy, but d,t,a for the verb obliterate, thus providing the appropriate distinction for cases such as 12	0	3	2
W91-0222	J88-2003	1991	Figure 2 relates the four types of lexical-semantic frameworks outlined above	0	Note that the system of features proposed by <REF>Bennett et al , 1990</REF> and <TREF>Moens and Steedman, 1988</TREF> provide the finest tuning given that five distinct categories of predicates are identified by the feature settings	1	This system is essentially equivalent to the Dowty/Vendler proposal, but features are used to distinguish the categories more precisely	0	In the next section, we will see how the tense and aspect structure described in section 21 and the lexicM-semantic representation described in this section are combined to provide the framework for generating a target-language surface form	0	5	2
P99-1064	J88-2003	1999	2b John finished drawing the circle	0	<REF>Dowty 1986</REF> and <TREF>Moens and Steedman 1988</TREF> decisively questioned the coherence of the class of achievement verbs, arguing that not all of them are non-durative	1	As noted above, Vendler identifies punctual events through the conjunction of the positive at and negative finish tests	0	However, they do not always yield comparable results : 3a 3b 4a 4b Karpov beat Kasparov at 1000 PM The Allies beat Germany at I000 PM  Karpov finished beating Kasparov The Allies finished beating Germany	0	3	2
E99-1032	J88-2003	1999	They trigger a change-of-state COS, henceforth, result states RSs, henceforth being entailments of CoSs	0	<TREF>Moens and Steedman 1988</TREF>, <REF>Smith 1991</REF>, <REF>Pustejovsky 1995</REF>, and others argue that it is a defining property of telic events	1	They should therefore include an undergoer argument, whose CoS determines the telicity of the event ie , it acts as a measuring-out argument	1	<REF>Tenny 1987</REF> thus claims that telic events require such an argument, which she calls an affected argument	0	3	2
P92-1033	J88-2003	1992	The subdivision is achieved by means of three features proposed by Bennett etal	0	1990 following the framework of <TREF>Moens and Steedman 1988</TREF>: -t-dynamic ie , events vs states, as in the Jackendoff framework, telic ie , culminative events transitions vs noneulminative events activities, and -I-atomic ie , point events vs extended events	1	We impose this system of features on top of the current lexical-semantic framework	0	For example, the lexical entry for all three verbs, ransack, obliterate, and destroy, would contain the following lexical-semantic representation: 6 Event CAUSE Thing X, Event GOLoc Thing X, Position TOLoc X John, Property DESTROYED The three verbs would then be distinguished by annotating this representation with the aspectual features d,t,-a for the verb ransack, d,t,-a for the verb destroy, and d,t,a for the verb obliterate, thus providing the appropriate distinction for cases such as 4	0	5	2
P92-1033	J88-2003	1992	SUMMARY This paper has examined a two-level knowledge representation model for machine translation that integrates aspectual information based on theories by <REF>Bach 1986</REF>, <REF>Comrie 1976</REF>, <REF>Dowty 1979</REF>, mourelatos 1981, <REF>Passonneau 1988</REF>, Pustejovsky 1988, 1989, 1991, and <REF>Vendler 1967</REF>, and more recently by Bennett et al	0	1990 and <TREF>Moens and Steedman 1988</TREF>, with lexicalsemantic information based on Jackendoff 1983, 1990	0	We have examined the question of cross-linguistic applicability showing that the integration of aspect with lexical-semantics is especially critical in machine translation when there are a large number of temporal connectives and verbal selection/realization possibilities that may be generated from a lexical semantic representation	0	Furthermore, we have illustrated that the selection/realization processes may be parameterized, by means of selection charts and coercion functions, so that the processes may operate uniformly across more than one language	0	6	1
P92-1033	J88-2003	1992	S: Juan le dio una puflaJada a Marls John gave a knife-wound to Mary S: Juan le dio pufialadas a Marls John gave knife-wounds to Mary b Duratlve Divergence, E: John met/knew Mary 4 S: Juan coaoci6 a Marls John met Mary S: Juan conoci a Mrfa John knew Merit Figure 1: Three Levels of MT Divergences et el	0	1990 have examined aspect and verb semantics within the context of machine translation in the spirit of <TREF>Moens and Steedman 1988</TREF>	1	This paper borrows from, and extends, these ideas by demonstrating how this theoretical framework might be adapted for crosslinguistic applicability	0	The framework has been tested within the context of an interlingual machine translation system and is currently being used as the basis for extraction of aspectual information from corpora	0	3	2
W98-0304	J88-2003	1998	Although there have been quite a few studies on individual aspects of sentence planning, little attention has been paid to the interaction between the various tasks--exceptions are <REF>Rambow and Korelsky 1992</REF> and <REF>Wanner and Hovy 1996</REF>--and in particular to the role of marker choice in the overall sentence planning process	0	There exists a large body of research in NLU on analysing the temporal structure of texts, including the role of temporal markers, though again restricted to English <TREF>Moens and Steedman 1988</TREF>; <REF>Lascarides and Oberlander 1993</REF>; <REF>Hitzeman et al 1995</REF>	1	We turn to these studies when it comes to identifying the information that needs to be assembled for representing temporal markers	0	3 Linguistic perspective: Describing temporal markers Selecting an appropriate German temporal marker given two events in a temporal relationship requires detailed knowledge of the semantic, pragmatic and syntactic properties that characterize temporal markers	0	1	3
P97-1020	J88-2003	1997	edu Abstract Verbal and compositional lexical aspect provide the underlying temporal structure of events	0	Knowledge of lexical aspect, eg, atelicity, is therefore required for interpreting event sequences in discourse <REF>Dowty, 1986</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Passoneau, 1988</REF>, interfacing to temporal databases <REF>Androutsopoulos, 1996</REF>, processing temporal modifiers <REF>Antonisse, 1994</REF>, describing allowable alternations and their semantic effects <REF>Resnik, 1996</REF>; <REF>Tenny, 1994</REF>, and selecting tense and lexical items for natural language generation <REF>Dorr and Olsen, 1996</REF>; <REF>Klavans and Chodorow, 1992</REF>, cf	1	<REF>Slobin and Bocaz, 1988</REF>	0	We show that it is possible to represent lexical aspect--both verbal and compositional--on a large scale, using Lexical Conceptual Structure LCS representations of verbs in the classes cataloged by <REF>Levin 1993</REF>	0	3	2
P97-1020	J88-2003	1997	Finally, we illustrate how knowledge of lexical aspect facilitates the interpretation of events in NLP applications	0	Knowledge of lexical aspect--how verbs denote situations as developing or holding in time--is required for interpreting event sequences in discourse <REF>Dowty, 1986</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Passoneau, 1988</REF>, interfacing to temporal databases <REF>Androutsopoulos, 1996</REF>, processing temporal modifiers <REF>Antonisse, 1994</REF>, describing allowable alternations and their semantic effects <REF>Resnik, 1996</REF>; <REF>Tenny, 1994</REF>, and for selecting tense and lexical items for natural language generation Dorr and Olsen	1	1996: <REF>Klavans and Chodorow, 1992</REF>, cf	0	<REF>Slobin and Bocaz, 1988</REF>	0	3	2
J03-4002	J88-2003	2003	How does 37b get its interpretation	0	As with 36d, the relevant elements of 37b can be represented as   then R   after S  turn right on County Line   e 3 :turn-rightyou, county line and the unresolved interpretation of 37b is thus  xafterx, EVe 3  aftere 3, EV 560 Computational Linguistics Volume 29, Number 4 As for resolving EV, in a well-known article, <TREF>Moens and Steedman 1988</TREF> discuss several ways in which an eventuality of one type eg , a process can be coerced into an eventuality of another type eg , an accomplishment, which Moens and Steedman call a culminated process	1	In this case, the matrix argument of then the eventuality of turning right on County Line can be used to coerce the process eventuality in 37b into a culminated process of going west on Lancaster Avenue until County Line	0	We treat this coercion as a type of associative or bridging inference, as in the examples discussed in section 31	0	5	2
E91-1022	J88-2003	1991	The alternatives arise when more than one event can be used	0	The temporal ontology is based on a recent theory of temporal semantics developed by <TREF>Moens and Steedman 1988</TREF>	1	This allows a modular representation of the semantics of temporal adverbials like until and by, and also aids in the generation of tense and aspect	0	This system looks at the mechanics of how the alternatives can be generated from the initial data, but we will have less to say about choosing between them	0	5	2
P97-1045	J88-2003	1997	21 Aspectual Categories of Verbs A number of aspectually oriented lexical-semantic representations have been proposed	0	Ve adopt and extend the feature-based framework proposed by <REF>Bennett et al , 1990</REF> in the spirit of <TREF>Moens and Steedman, 1988</TREF>	1	They uses three features: dynamic, telic, and atomic	0	We add two more features: process and gradual	0	3	2
J00-4004	J88-2003	2000	In principle, it is possible for this second module to detect aspectual transformations that apply to any input clause, independent of the manner in which the core constituents interact to produce its fundamental aspectual class	0	600 Siegel and McKeown Improving Aspectual Classification 26 Applications of Aspectual Classification Aspectual classification is a required component of applications that perform natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks <TREF>Moens and Steedman 1988</TREF>; <REF>Klavans and Chodorow 1992</REF>; <REF>Klavans 1994</REF>; <REF>Dorr 1992</REF>; <REF>Wiebe et al 1997</REF>	1	These applications require the ability to reason about time, ie, temporal reasoning	0	Assessing temporal relationships is a prerequisite for inferring sequences of medical procedures in medical domains	0	3	2
J00-4004	J88-2003	2000	598 Siegel and McKeown Improving Aspectual Classification Table 3 Several aspectual entailments	0	If a clause occurring: necessarily entails: then it must be: in past progressive tense as argument of stopped in simple present tense past tense reading past tense reading the habitual reading Nonculminated Event Nonculminated Event or State Event 23 Interpreting Temporal Connectives and Modifiers Several researchers have developed models that incorporate aspectual class to assess temporal constraints between connected clauses <REF>Hwang and Schubert 1991</REF>; <REF>Schubert and Hwang 1990</REF>; <REF>Dorr 1992</REF>; <REF>Passonneau 1988</REF>; <TREF>Moens and Steedman 1988</TREF>; <REF>Hitzeman, Moens, and Grover 1994</REF>	1	For example, stativity must be identified to detect temporal constraints between clauses connected with when	0	For example, in interpreting, 7 She had good strength when objectively tested	0	3	2
J00-4004	J88-2003	2000	An understanding system can recognize the aspectual transformations that have affected a clause only after establishing the clauses fundamental aspectual category	0	Linguistic models motivate the division between a module that first detects fundamental aspect and a second that detects aspectual transformations <REF>Hwang and Schubert 1991</REF>; <REF>Schubert and Hwang 1990</REF>; <REF>Dorr 1992</REF>; <REF>Passonneau 1988</REF>; <TREF>Moens and Steedman 1988</TREF>; <REF>Hitzeman, Moens, and Grover 1994</REF>	1	In principle, it is possible for this second module to detect aspectual transformations that apply to any input clause, independent of the manner in which the core constituents interact to produce its fundamental aspectual class	1	600 Siegel and McKeown Improving Aspectual Classification 26 Applications of Aspectual Classification Aspectual classification is a required component of applications that perform natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks <TREF>Moens and Steedman 1988</TREF>; <REF>Klavans and Chodorow 1992</REF>; <REF>Klavans 1994</REF>; <REF>Dorr 1992</REF>; <REF>Wiebe et al 1997</REF>	0	4	2
J00-4004	J88-2003	2000	Some aspectual markers such as the pseudocleft and many manner adverbs test for intentional events in particular not all events in general, and therefore are not compatible with all events, eg, I died diligently	0	Aspectual coercion such as iteration can allow a punctual event to appear in the progressive, eg She was sneezing for a week point  process  culminated process 4 <TREF>Moens and Steedman 1988</TREF>	1	The predictive power of some indicators is uncertain, since several measure phenomena that are not linguistically constrained by any aspectual category, eg, the present tense, durative for-PPs, frequency and notnever indicators	0	Therefore, the predictive power of individual linguistic indicators is incomplete; only the subset of verbs that adhere to the respective constraints or trends can be correctly classified	0	6	1
J00-4004	J88-2003	2000	the second sentence describes a state, which begins before the event described by the first sentence	0	Aspectual classification is also a necessary prerequisite for interpreting certain adverbial adjuncts, as well as identifying temporal constraints between sentences in a discourse <TREF>Moens and Steedman 1988</TREF>; <REF>Dorr 1992</REF>; <REF>Klavans 1994</REF>	1	In addition, it is crucial for lexical choice and tense selection in machine translation <TREF>Moens and Steedman 1988</TREF>; <REF>Klavans and Chodorow 1992</REF>; <REF>Klavans 1994</REF>; <REF>Dorr 1992</REF>	0	Table 1 sunnarizes the three aspectual distinctions, which compose five aspectual categories	0	4	1
J00-4004	J88-2003	2000	Some aspectual auxiliaries also perform an aspectual transformation of the clause they modify, eg, 11 I finished staring at it culminated process	0	Aspectual coercion, a second type of aspectual transformation, can take place when a clause is modified by an aspectual marker that violates an aspectual constraint <TREF>Moens and Steedman 1988</TREF>; <REF>Pustejovsky 1991</REF>	1	In this case, an alternative interpretation of the clause is inferred which satisfies the aspectual constraint	0	For example, the progressive marker is constrained to appear with an extended event	0	4	2
J00-4004	J88-2003	2000	E-mail: evscscolumbiaedu t Computer Science Dept , 1214 Amsterdam Ave , New York, NY 10027	0	E-mail: kathycscolumbiaedu  2001 Association for Computational Linguistics Computational Linguistics Volume 26, Number 4 Aspectual classification is necessary for interpreting temporal modifiers and assessing temporal entailments <TREF>Moens and Steedman 1988</TREF>; <REF>Dorr 1992</REF>; <REF>Klavans 1994</REF> and is therefore a required component for applications that perform certain natural language interpretation, generation, summarization, information retrieval, and machine translation tasks	1	Each of these applications requires the ability to reason about time	0	A verbs aspectual category can be predicted by co-occurrence frequencies between the verb and linguistic phenomena such as the progressive tense and certain temporal modifiers <REF>Klavans and Chodorow 1992</REF>	0	3	2
J00-4004	J88-2003	2000	Aspectual classification is also a necessary prerequisite for interpreting certain adverbial adjuncts, as well as identifying temporal constraints between sentences in a discourse <TREF>Moens and Steedman 1988</TREF>; <REF>Dorr 1992</REF>; <REF>Klavans 1994</REF>	0	In addition, it is crucial for lexical choice and tense selection in machine translation <TREF>Moens and Steedman 1988</TREF>; <REF>Klavans and Chodorow 1992</REF>; <REF>Klavans 1994</REF>; <REF>Dorr 1992</REF>	1	Table 1 sunnarizes the three aspectual distinctions, which compose five aspectual categories	0	In addition to the two distinctions described in the previous section, atomicity distinguishes punctual events eg , She noticed the picture on the wall from extended events, which have a time duration eg , She ran to the store	0	4	2
J00-4004	J88-2003	2000	Therefore, if it appears with an atomic event, eg, 12 He hiccupped point, the event is transformed to an extended event, eg, 13 He was hiccupping process	0	in this case with the iterated reading of the clause <TREF>Moens and Steedman 1988</TREF>	1	25 The First Problem: Fundamental Aspect We define fundamental aspectual class as the aspectual class of a clause before any aspectual transformations or coercions	1	That is, the fundamental aspectual category is the category the clause would have if it were stripped of any and all aspectual markers that induce an aspectual transformation, as well as all components of the clauses pragmatic context that induce a transformation	0	4	2
J00-4004	J88-2003	2000	Aspect in Natural Language Because, in general, the sequential order of clauses is not enough to determine the underlying chronological order, aspectual classification is required for interpreting 596 Siegel and McKeown Improving Aspectual Classification Table 1 Aspectual classes	0	This table is adapted from Moens and Steedman 1988, p 17	1	Culminated Nonculminated EVENTS punctual extended CULMINATION CULMINATED PROCESS recognize build a house POINT PROCESS hiccup run, swim, walk STATES understand even the simplest narratives in natural language	0	For example, consider: 1 Sue mentioned Miami event	0	4	2
P93-1040	J88-2003	1993	THE IMPERFECTIVE PARADOX AND TRAJECTORY-OF-MOTION EVENTS  Michael White Department of Computer and Information Science University of Pennsylvania Philadelphia, PA, USA mwhit el inc c is upenn, edu Abstract In the first part of the paper, I present a new treatment of THE IMPERFICTIVE PARADOX <REF>Dowty 1979</REF> for the restricted case of trajectoryof-motion events	0	This treatment extends and refines those of <TREF>Moens and Steedman 1988</TREF> and <REF>Jackendoff 1991</REF>	1	In the second part, I describe an implemented algorithm based on this treatment which determines whether a specified sequence of such events is or is not possible under certain situationally supplied constraints and restrictive assumptions	0	Bach 1986:12 summarizes THE IMPERFECTIVE PARADOX <REF>Dowty 1979</REF> as follows: how can we characterize the meaning of a progressive sentence like la 17 on the basis of the meaning of a simple sentence like lb 18 when la can be true of a history without lb ever being true	0	3	2
P93-1040	J88-2003	1993	<REF>White 1993</REF>	0	5Much as in <TREF>Moens and Steedman 1988</TREF> and <REF>Jackendoff 1991</REF>, the introduction of gr is necessary to avoid having an ill-sorted formula	1	284 the manner of motion supplied by a verb, it does nevertheless permit one to consider factors such as the normal speed as well as the meanings of the prepositions 10, lowards, etc By making two additional restrictive assumptions, namely that these events be of constant velocity and in one dimension, I have been able to construct and implement an algorithm which determines whether a specified sequence of such events is or is not possible under certain situationally supplied constraints	0	These constraints include the locations of various landmarks assumed to remain stationary and the minimum, maximum, and normal rates associated with various manners of motion eg running, jogging for a given individual	0	5	2
P93-1040	J88-2003	1993	Capitalizing on Bachs insight, I present in the first part of the paper a new treatment of the imperfective paradox which relies on the possibility of having actual events standing in the part-of relation to hypothetical super-events	0	This treatment extends and refines those of <TREF>Moens and Steedman 1988</TREF> and <REF>Jackendoff 1991</REF>, at least for the restricted case of trajectory-of-motion events	1	1 In particular, the present treatment correctly accounts not only for what 2a fails to entail -namely, that John eventually reaches the museum -but also for what 2a does in fact entail -namely, that John follows by jogging at least an initial part of a path that leads to the museum	0	In the second part of the paper, I briefly describe an implemented algorithm based on this theoretical treatment which determines whether a specified sequence of trajectory-of-motion is or is not possible under certain situationally supplied constraints and restrictive assumptions	0	3	2
P07-1113	J88-2003	2007	1 SonyCorp	0	hasheavilypromotedtheVideoWalkman since the products introduction last summer, 2 but Bob Gerson, video editor of This Week in Consumer Electronics, says 3 Sony conceives of 8mm as a family of products, camcorders and VCR decks,  SE classification is a fundamental component in determining the discourse mode of texts <REF>Smith, 2003</REF> and, along with aspectual classification, for temporal interpretation <TREF>Moens and Steedman, 1988</TREF>	1	It may be useful for discourse relation projection and discourse parsing	0	Though situation entities are well-studied in linguistics, they have received very little computational treatment	0	6	1
C98-1007	J88-2003	1998	The imperfective point of view brought by IMP imposes a change of point of view on the term of the eventuality	0	As for accomplishments, we can assume that they can be decomposed into several stages, according to <TREF>Moens and Steedman, 1988</TREF>: first  preparatory phase, second a cuhnination or achievement we are not concerned here with the result state	1	We can then say that IMP refers only to the preparatory phase, so that the term of the eventuality loses all relevance	0	This explains the so-called imperfective paradox: it is possible to use IMP even though the eventnality never reaches its term: 6 a I1 traversait la rue quand la voiture la ras6 He was crossing the street when the car hit him b  I1 traversa la rue quand la voiture la 6cras6 Ile crossed the street when the car hit him As for achievements, we can assume that they are reduced to a culmination	0	3	2
W97-0318	J88-2003	1997	Three machine learning methods are compared for this task: decision tree induction, a genetic algorithm, and log-linear regression	0	The ability to distinguish states, eg, Mark seems happy, from events, eg, Rende ran down the street, is a necessary prerequisite for interpreting certain adverbial adjuncts, as well as identifying temporal constraints between sentences in a discourse <TREF>Moens and Steedman, 1988</TREF>; <REF>Doff, 1992</REF>; <REF>Klavans, 1994</REF>	1	Furthermore, stativity is the first of three fundamental temporal distinctions that compose the aspectual class of a clause	0	Aspectual classification is a necessary component for a system that analyzes temporal constraints, or performs lexical choice and tense selection in machine translation <TREF>Moens and Steedman, 1988</TREF>; <REF>Passonneau, 1988</REF>; <REF>Doff, 1992</REF>; <REF>Klavans, 1994</REF>	0	6	1
W97-0318	J88-2003	1997	Furthermore, stativity is the first of three fundamental temporal distinctions that compose the aspectual class of a clause	0	Aspectual classification is a necessary component for a system that analyzes temporal constraints, or performs lexical choice and tense selection in machine translation <TREF>Moens and Steedman, 1988</TREF>; <REF>Passonneau, 1988</REF>; <REF>Doff, 1992</REF>; <REF>Klavans, 1994</REF>	1	Researchers have used empirical analysis of corpora to develop linguistically-based numerical indicators that aid in aspectual classification <REF>Klavans and Chodorow, 1992</REF>; <REF>Siegel and McKeown, 1996</REF>	0	Specifically, this technique takes advantage of linguistic constraints that pertain to aspect, eg, only clauses that describe an event can appear in the progressive	1	3	2
C08-1037	J88-2003	2008	And that they should be seen as the result of an attempt to take a good metaphor too literally	0	<TREF>Moens and Steedman 1988</TREF> conceived temporal adverbials as functions which coerce their inputs to the appropriate type, by a loose sic	1	analogy with type-coercion in programming languages	0	Under this perspective, aspectual shift is triggered by a conflict between the aspectual type of the situation to be modified and the aspectual constraint set by the temporal preposition heading the modifier1 Coercion operators, then, are thought to adapt the verbal input on the level of model-theoretical interpretation by mapping one sort of situation onto another	0	6	1
C00-2148	J88-2003	2000	By using TAGs we get the additional benefit of an existing parser that yields derivations and derived trees fiom which we can construct the compositional semantics of a given sentence	0	We decompose each event E into a tripartite structure in a manner similar to <TREF>Moens and Steedman 1988</TREF>, introducing a time function for each predicate to specify whether the predicate is true in the preparatory dringE, cuhnination erdE, or consequent resll:E stage of an event	1	hfitial trees capture tile semantics of the basic senses of verbs in each class	0	For example, many IThese restrictions are more like preferences that generate a preferred reading of a sentence	0	4	2
P99-1015	J88-2003	1999	However, this incompleteness is also a consequence of the linguistic characteristics of various indicators	0	For example:  Aspectual coercion such as iteration compromises indicator measurements <TREF>Moens and Steedman, 1988</TREF>	1	For example, a punctual event appears with the progressive in, She was sneezing for a week	0	point --, process --	0	6	1
P99-1015	J88-2003	1999	For example, I made a fire is culminated, since a new state is introduced something is made, whereas, I gazed at the sunset is non-culminated	0	Aspectual classification is necessary for interpreting temporal modifiers and assessing temporal entailments <REF>Vendler, 1967</REF>; <REF>Dowty, 1979</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Dorr, 1992</REF>, and is therefore a necessary component for applications that perform certain natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks	1	Aspect introduces a large-scale, domaindependent lexical classification problem	1	Although an aspectual lexicon of verbs would suffice to classify many clauses by their main verb only, a verbs primary class is often domaindependent <REF>Siegel, 1998b</REF>	0	3	2
P99-1015	J88-2003	1999	112 Table 1: Aspectual classes	0	This table comes from Moens and Steedman <TREF>Moens and Steedman, 1988</TREF>	1	Culm EVENTS STATES punctual extended CULM CULM PROCESS recognize build a house NonPOINT PROCESS Culm hiccup run, swim understand 2 Aspect in Natural Language Table 1 summarizes the three aspectual distinctions, which compose five aspectual categories	1	In addition to the two distinctions described in the previous section, atomicity distinguishes events according to whether they have a time duration punctual versus extended	0	3	2
C92-4177	J88-2003	1992	This can effect not only the semantic interpretation of the text itself, but also translation and the choice of adverb	0	3 3Many of these issues are discussed in the CL Special Issue on Tense and Aspect <REF>June, 1988</REF> in articles by Hinniche, Moens and Steedman, Nakhimovsky, Passoneau, and Webber	1	For example, Passoneau demonstrates how, without an ccurate specification of the pectual tendencies of the verb coupled with the effect of temporal and aspectual adjuncts, messages, which tend to be in the present tense, ttre not correctly understood nor generated in the PUNDIT system	0	For instance, the pressure is low must be interpreted at statlve, whereas the pump operates must be interpreted as a process	0	4	2
W94-0312	J88-2003	1994	It is also clear that events are not undifferentiated masses, but rather have subparts that can be picked out by the choice of phrase type or the addition of adverbial phrases	0	<TREF>Moens  Steedman 1988</TREF> identify three constituents to an event nucleus, a preparatory process, culmination, and consequent state, whereas <REF>Nakhimovsky 1988</REF> identifies five: preparatory, initial, body, final, result, exemplified by the following: 1 15	1	When the children crossed the road, a they waited for the teacher to give a signal b they stepped onto its concrete surface as if it were about to swallow them up	0	c they were nearly hit by a car d they reached the other side stricken with fear	0	5	2
J91-4003	J88-2003	1991	I will call this level the event structure of a word cf	0	<REF>Pustejovsky 1991</REF>; <TREF>Moens and Steedman 1988</TREF>	1	The event structure of a word is one level of the semantic specification 419 Computational Linguistics Volume 17, Number 4 for a lexical item, along with its argument structure, qualia structure, and inheritance structure	0	Because it is recursively defined on the syntax, it is also a property of phrases and sentences	0	6	1
C08-1092	J88-2003	2008	Weather would seem selfcontained, but change, creation and stative are not semantic fields at all	0	Stative belongs to the Aktionsart categorisation of verbs distinguishing it from verbs of activity, achievement and accomplishment, which is orthogonal to the categorisation of verbs into semantic fields <REF>Vendler, 1967</REF>, <TREF>Moens  Steedman 1988</TREF>, <REF>Amaro, 2006</REF>	1	Moreover, a verb can belong to more than one Aktionsart category, as these apply to verbs in contexts	0	33 Suggested Revision of Categories Among verbs, the level of arbitrariness and incorrectness of the WordNet categories seems greater than that of the relations	0	4	2
W06-0906	J88-2003	2006	Differences in annotation could be due to the differences in interpretations of the event; however, we found that the vast majority of radically different judgments can be categorized into a relatively small number of classes	1	Some of these correspond to aspectual features of events, which have been intensively investigated eg , <REF>Vendler, 1967</REF>; <REF>Dowty, 1979</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Passonneau, 1988</REF>	1	We then developed guidelines to cover those cases see the next section	0	22 Event Classes Action vs State: Actions involve change, such as those described by words like speaking, gave, and skyrocketed	0	4	2
W98-0602	J88-2003	1998	Events of type eat differ from those of type run in the way the result d is brought about	0	This can be illustrated by means of the notion of a nucleus-structure Moens/<REF>Steedman 1988</REF>	1	A nucleus-structure consists of three parts: the inception-point IP, the development-portion DP and the culmination-point CP	1	Nucleus-Structure e S S  IP DP CP Figure 1 The result  is evaluated at each part of the nucleus-structure	0	4	2
P90-1016	J88-2003	1990	Further, we do not have a theory of the interaction of temporal interpretation with aspect	0	<REF>See Dowty, 1979</REF>; <REF>Dowty, 1986</REF>; <REF>Moens, 1987</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Nakhimovsky, 1988</REF>; and <REF>Passoneau, 1988</REF>	0	found in these works	0	Section 5 provides a more detailed comparison with <REF>Yip 1986</REF> and <REF>Hornstein 1990</REF>	0	6	1
W04-0912	J88-2003	2004	The decisive units for this selection are phases and boundaries <REF>Bickel, 1996</REF>	0	Presuming a tripartite event structure <TREF>Moens and Steedman, 1988</TREF> consisting of a preparation phase dynamic phase  dyn , a culmination point boundary  and a consequent state static phase  stat , there are three possibilities for aspect to select	1	English and Turkish both have  dyn -selecting aspectual markers, Turkish also a marker for explicit  stat selection; Russian pf aspect explicitly selects 	0	The unmarked members of the aspectual oppositions may assert anything else  Russian ipf aspect may assert anything but the explicit selection of a boundary	0	6	1
P04-1017	P83-1007	2004	The knowledge about the context of anaphor and antecedent is nevertheless ignored	0	However, research in centering theory <REF>Sidner, 1981</REF>; <TREF>Grosz et al , 1983</TREF>; <REF>Grosz et al , 1995</REF>; <REF>Tetreault, 2001</REF> has revealed that the local focusing or centering also has a great efiect on the processing of pronominal expressions	0	The choices of the antecedents of pronouns usually depend on the center of attention throughout the local discourse segment <REF>Mitkov, 1999</REF>	0	To determine the salience of a candidate in the local context, we may need to check the coreferential information of the candidate, such as the existence and properties of its antecedents	0	0	0
P07-2040	P83-1007	2007	We report the results of our experiments in Section 3 and conclude the paper in Section 4	0	2 Relation Detection The proposed method employs contextual features based on centering theory <TREF>Grosz et al , 1983</TREF> as well as conventional syntactic and word-based features	0	These features are organized as a tree structure and are fed into a boosting-based classification algorithm	0	The method consists of three parts: preprocessing POS tagging, NE tagging, and parsing, 1The numbers show correspondences of words between Japanese and English	0	0	0
P98-2204	P83-1007	1998	I propose a model for determining the heaters attentional state in understanding discourse	0	My proposal is inspired by the centering model <TREF>Grosz et al , 1983</TREF>; 1995 and draws on the conclusions of Strube  Hahns 1996 approach for the ranking of the forward-looking center list for German	0	Their approach has been proven as the point of departure for a new model which is valid for English as well	0	The use of the centering transitions in Brennan et als 1987 algorithm prevents it from being applied incrementally cf	0	0	0
P98-2204	P83-1007	1998	2 A Look Back: Centering The centering model describes the relation between the focus of attention, the choices of referring expressions, and the perceived coherence of discourse	0	The model has been motivated with evidence from preferences for the antecedents of pronouns <TREF>Grosz et al , 1983</TREF>; 1995 and has been applied to pronoun resolution Brennan et al	0	1987, inter alia, whose interpretation differs from the original model	0	The centering model itself consists of two constructs, the backward-looking center and the list of forward-looking centers, and a few rules and constraints	0	0	0
E95-1035	P83-1007	1995	2 For the problem with multi-sentence discourses, and the threads that sentences continue, we use an implementation of temporM centering <REF>Kameyama et al , 1993</REF>; <REF>Poesio, 1994</REF>	0	This is a technique similar to the type of centering used for nominal anaphora <REF>Sidner, 1983</REF>; <TREF>Grosz et al , 1983</TREF>	1	Centering assumes that discourse understanding requires some notion of aboutness	0	While nominal centering assumes there is one object that the current discourse is about, temporal centering assumes that there is one thread that the discourse is currently following, and that, in addition to tense and aspect constraints, there is a preference for a new utterance to continue a thread which has a parallel tense or which is semantically related to it and a preference to continue the current thread rather than switching to another thread	0	2	1
P95-1015	P83-1007	1995	Passonneau to appear examined some of the few claims relating discourse anaphoric noun phrases to global discourse structure in the Pear corpus	0	Resuits included an absence of correlation of segmental structure with centering <TREF>Grosz et al , 1983</TREF>; <REF>Kameyama, 1986</REF>, and poor correlation with the contrast between full noun phrases and pronouns	1	As noted in <REF>Passonneau and Litman, 1993</REF>, the NP features largely reflect Passonneaus hypotheses that adjacent utterances are more likely to contain expressions that corefer, or that are inferentially linked, if they occur within the same segment; and that a definite pronoun is more likely than a full NP to refer to an entity that was mentioned in the current segment, if not in the previous utterance	0	33 Evaluation The segmentation algorithms presented in the next two sections were developed by examining only a training set of narratives	0	6	1
C98-2199	P83-1007	1998	I propose a model for determining the hearers attentional state in understanding discourse	0	My proposal is inspired by the centering model <TREF>Grosz et al, 1983</TREF>; 1995 and draws on the conclusions of Strube  Hahns 1996 approach for the ranking of the forward-looking center list for German	0	Their approach has been proven as the point of departure for a new model which is valid for English as well	0	The use of the centering transitions in Brennan et als 1987 algorithm prevents it from being applied incrementally cf	0	0	0
C98-2199	P83-1007	1998	2 A Look Back: Centering The centering model describes the relation between the focus of attention, the choices of referring expressions, and the perceived coherence of discourse	0	The model has been motivated with evidence from preferences for the antecedents of pronouns <TREF>Grosz et al, 1983</TREF>; 1995 and has been applied to pronoun resolution Brennan et al	0	1987, inter alia, whose interpretation differs from the original model	0	The centering model itself consists of two constructs, the backward-looking center and the list of forward-looking centers, and a few rules and constraints	0	0	0
P89-1030	P83-1007	1989	Any communicative act, be it spoken, written, gestured, or system-initiated, can give rise to DEs	0	As a discourse progresses, an adequate discourse model must represent the relevant entities, and the relationships between them <REF>Grosz and Sidner, 1986</REF>, A speaker may then felicitously refer anaphorically to an object subject to focusing or centering constraints <TREF>Grosz et al , 1983</TREF>, <REF>Sidner 1981, 1983</REF>, <REF>Brennan et al 1987</REF>  if there is an existing DE representing it, or if a corresponding DE may be directly inferred from an existing DE	1	For example, the utterance Every senior in Milford High School has a car gives rise to at least 3 entities, describable in English as the seniors in Milford High School, Milford High School, and the set of cars each of which is owned by some senior in Milford High School	0	These entities may then be accessed by the following next utterances, respectively: They graduate in June	0	6	1
P89-1030	P83-1007	1989	This is, to our knowledge, the first implementation of Webbers DE generation ideas	0	We designed the 243 algorithms and structures necessary to generate discourse entities from our logical representation of the meaning of utterances, and from pointing gestures, and currently use them in Januss <REF>Weischedel et al , 1987</REF>, BSN, 1988 pronoun resolution component, which applies centering techniques <TREF>Grosz et al , 1983</TREF>, <REF>Sidner 1981, 1983</REF>, <REF>Brennan et al 1987</REF> to track and constrain references	1	Janus has been demonstrated in the Navy domain for DARPAs Fleet Command Center Battle Management Program FCCBMP, and in the Army domain for the Air Land Battle Management Program ALBM	0	2 Meaninq Representation for DE Generation Webber found that appropriate discourse entities could be generated from the meaning representation of a sentence by applying rules to the representation that are strictly structural in nature, as long as the representation reflects certain crucial aspects of the sentence	0	3	2
P95-1040	P83-1007	1995	This distinction underlies my proposals about the attentional consequences of pitch accents when applied to pronominals, in particular, that while most pitch accents may weaken or reinforce a cospecifiers status as the center of attention, a contrastively stressed pronominal may force a shift, even when contraindicated by textual features	0	To predict and track the center of attention in discourse, theories of centering <TREF>Grosz et al , 1983</TREF>; <REF>Brennan et al , 1987</REF>; <REF>Grosz et al , 1989</REF> and immediate focus <REF>Sidner, 1986</REF> rely on syntactic and grammatical features of the text such as pronominalization and surface sentence position	0	This may be sufficient for written discourse	0	For oral discourse, however, we must also consider the way intonation affects the interpretation of a sentence, especially the cases in which it alters the predictions of centering theories	0	0	0
J99-2001	P83-1007	1999	3	0	Processing Complex Sentences: A Reason for Extending Focusing Algorithms Although complex sentences are prevalent in written English, most other local focusing research focusing: Sidner 1979 and Carter 1987; centering: Grosz, Joshi, and Weinstein 1983, 1995, Brennan, Friedman, and Pollard 1987, Walker 1989, 1993, Kameyama 1986 2, Walker, Iida, and Cote 1994, Brennan 1998, Kameyama, Passonneau, and Poesio 1993, Linson 1993 and Hoffman 1998; and PUNDIT: Dahl 1986, Palmer et al 1986, and Dahl and Ball 1990 did not explicitly and/or adequately address how to process complex sentences	0	Thus, there is a need to extend focusing algorithms	0	An exception to this rule is the work of <REF>Strube 1996</REF> which applies functionalinformation-structure-based criteria on a per-clause basis, <REF>Kameyama 1998</REF>, and <REF>Strube 1998</REF>	0	0	0
P96-1036	P83-1007	1996	This claim is backed up by an empirical evaluation of functional centering	0	The centering model has evolved as a methodology for the description and explanation of the local coherence of discourse <TREF>Grosz et al , 1983</TREF>; 1995, with focus on pronominal and nominal anaphora	0	Though several cross-linguistic studies have been carded out cf	0	the enumeration in Grosz et al	0	0	0
P96-1036	P83-1007	1996	This claim, however, has to be further substantiated by additional cross-linguistic empirical studies	0	5 Comparison with Related Approaches The centering model <TREF>Grosz et al , 1983</TREF>; 1995 is concerned with the interactions between the local coherence of discourse and the choices of referring expressions	0	Crucial for the centering model is the way the forward-looking centers are organized	0	Despite several cross-linguistic studies a kind of standard has emerged based on the study of English cf	0	0	0
C88-2159	P83-1007	1988	Its identification needs peech act cal;egorization of sentences	0	This topic-based approach is in contrast to Kameyamas,Japanese version <REF>Kameyama 1985</REF>, <REF>Kameyama 1986</REF> of tbcus-based spproach to anaphora by <TREF>Grosz et al 1983</TREF>	1	In her framewock, subjecthood and predicate deixis play the principal role, and the fact that topic provides the most important clue to anaphora identification in actual spoken Japanese discourse is not utilized eexplicitly	0	,-L3 Extension of topic introduction One of the pobems with the topicobased approach is that topics reerred to by zero pronouns are not always e:pliitiy marked by the topic postposition wa	0	2	1
P00-1052	P83-1007	2000	In this study,we employ the e-rater essay scoring system to test a hy1 http:2F2Flsacoloradoedu	0	2 http:2F2Fwwwetsorg2Fresearch2Feraterhtml pothesis related to Centering Theory 28<REF>Joshi and Weinstein, 1981</REF>; <TREF>Grosz et al , 1983</TREF>, inter alia29	0	We focus on Centering Theorys Rough-Shift transition which is the least well studied among the four transition types	0	In particular, we examine whether the discourse coherence found in an essay, as de0Cned bya measure of relative proportion of Rough-Shift transitions, might be a signi0Ccant contributor to the accuracy of computer-generated essay scores	0	0	0
P91-1014	P85-1018	1991	The parser can be modified to simulate other types of machines such LRk-like or SLR-like automata	0	It can also be extended to handle unification based grammars using a similar method as that employed by <TREF>Shieber 1985</TREF> for extending Earleys algorithm	1	Furthermore, the algorithm can be tuned to a particular grammar and therefore be made more efficient by carefully determinizing portions of the nondeterministic machine while making sure that the number of states in not increased	0	These variants lead to more efficient parsers than the one based on the basic non-deterministic push-down machine	0	6	1
W91-0108	P85-1018	1991	Finally note that in cases where substantial material has to be supplied, as it were, by the target grammar eg if a transitive verb is supplied but no object, then Definition 3 would allow arbitrary lexicalisations, giving rise to a very large number of permissible outputs	0	If this is felt to be problem, then estricting in the sense of <TREF>Shieber 1985</TREF> the subsumption test in the second half of Definition 3 to ignore the values of certain features, ie pred, would bepstraight-forward	1	This would have the effect of producing a single, exemplary lexicalisation for each significantly different ie different ignoring differences under pred structure which satisfies the minimaximal requirements	0	II4 A Problem with the Mini-maximal Approach One potential problem clearly arises with this approach	0	6	1
P96-1058	P85-1018	1996	So, top-down constraints must be weakened in order for parsing to be guaranteed to terminate	0	In order to solve the nontermination problem, <TREF>Shieber 1985</TREF> proposes restrictor, a statically predefined set of features to consider in propagation, and restriction, a filtering function which removes the features not in restrictor from top-down expectation	1	However, not only does this approach fail to provide a method to automatically generate the restrictor set, it may weaken the predicative power of top-down expectation more than necessary: a globally defined restrictor can only specify the least common features for all propagation paths	1	In this paper, a general method of maximizing top-down constraints is proposed	0	1	3
J01-2005	P85-1018	2001	Manual detection is also problematic: when a grammar is large, particularly if semantic features are included, complete detection is nearly impossible	0	As for the techniques developed so far which partially solve prediction nontermination eg , <TREF>Shieber 1985</TREF>; <REF>Haas 1989</REF>; <REF>Samuelsson 1993</REF>, they do not apply to nonminimal derivations because nonminimal derivations may arise without left recursion or recursion in general s One way is to define p to filter out all features except the context-free backbone of predictions	1	However, this severely restricts the range of possible instantiations of Shiebers algorithm	0	9 A third possibility is to manually fix the grammar so that nonminimal derivations do not occur, as we noted in Section 4	0	1	3
J01-2005	P85-1018	2001	However, simple subsumption may filter out valid parses for some grammars, thus sacrificing completeness	0	7 Another possibility is to filter out problematic features in the Prediction step by using the function p However, automatic detection of such features ie , automatic derivation of p is undecidable for the same reason as the prediction nontermination problem caused by left recursion for unification grammars <TREF>Shieber 1985</TREF>	1	Manual detection is also problematic: when a grammar is large, particularly if semantic features are included, complete detection is nearly impossible	0	As for the techniques developed so far which partially solve prediction nontermination eg , <TREF>Shieber 1985</TREF>; <REF>Haas 1989</REF>; <REF>Samuelsson 1993</REF>, they do not apply to nonminimal derivations because nonminimal derivations may arise without left recursion or recursion in general s One way is to define p to filter out all features except the context-free backbone of predictions	1	1	3
J01-2005	P85-1018	2001	1	0	Unification grammar is a term often used to describe a family of feature-based grammar formalisms, including GPSG <REF>Gazdar et al 1985</REF>, PATR-II <REF>Shieber 1986</REF>, DCG <REF>Pereira and Warren 1980</REF>, and HPSG <REF>Pollard and Sag 1994</REF>	1	In an effort to formalize the common elements of unification-style grammars, <REF>Shieber 1992</REF> developed a logic for describing them, and used this logic to define an abstract parsing algorithm	0	The algorithm uses the same set of operations as Earleys 1970 algorithm for context-free grammars, but modified for unification grammars	0	6	1
P90-1024	P85-1018	1990	It is more so because 1 there is no restriction such as that there should be only one zero morpheme within an S clause, and 2 the stack is useless because zero morphemes are independent morphemes and are not bound to other morphemes comparable to wh-words	0	<TREF>Shieber 1985</TREF> proposes a more efficient approach to gaps in the PATR-II formalism, extending Earleys algorithm by using restriction to do top-down filtering	1	While an approach to zero morphemes similar to Shiebers gap treatment is possible, we can see one advantage of ours	1	That is, our approach does not depend on what kind of parsing algorithm we choose	1	1	3
J93-4001	P85-1018	1993	However, if features are carefully selected so as to increase the amount of pruning done by the chart, the net effect may 583 Computational Linguistics Volume 19, Number 4 be that even though the grammar allows more types of constituents, the chart may end up with fewer instances	0	It is interesting to compare this technique to the restriction proposal in <TREF>Shieber 1985</TREF>	1	Both approaches select functional features to be moved forward in processing order in the hope that some processing will be pruned	1	Shiebers approach changes the processing order of functional constraints so that some of them are processed top-down instead of bottom-up	0	2	1
J97-3004	P85-1018	1997	For the experiments discussed in the final section all goal-weakening operators were chosen by hand, based on small experiments and inspection of the goal table and item table	0	Even if goal weakening is reminiscent of Shiebers 1985 restriction operator, the rules of the game are quite different: in the case of goal weakening, as much information as possible is removed without risking nontermination of the parser, whereas in the case of Shiebers restriction operator, information is removed until the resulting parser terminates	1	For the current version of the grammar of OVIS, weakening the goal category in such a way that all information below a depth of 6 is replaced by fresh variables eliminates the problem caused by the absence of the occur check; moreover, this goal-weakening operator reduces parsing times substantially	1	In the latest version, we use different goal-weakening operators for each different functor	0	2	3
J97-3004	P85-1018	1997	Depending on the properties of a particular grammar, it may, for example, be worthwhile to restrict a given category to its syntactic features before attempting to solve the parse-goal of that category	0	Shiebers 1985 restriction operator can be used here	1	Thus we essentially throw some information away before an attempt is made to solve a memorized goal	0	For example, the category xA, B, f A, B, gA,hB, i C   may be weakened into: xA,B,f ,,g, If we assume that the predicate weaken/2 relates a term t to a weakened version tw, such that tw subsumes t, then 15 is the improved version of the parse predicate: parsewithweakening Cat, P0, P, E0, E  15 weakenCat,WeakenedCat, parseWeakenedCat,P0,P,E0,E, CatWeakenedCat	0	3	2
J97-3004	P85-1018	1997	Therefore, we generally cannot use all information available in the grammar but rather we should compute a weakened version of the linking table	0	This can be accomplished, for example, by replacing all terms beyond a certain depth by anonymous variables, or by other restrictors <TREF>Shieber 1985</TREF>	1	Secondly, the use of a linking table may give rise to spurious ambiguities	0	Consider the case in which the category we are trying to parse can be matched against two different items in the linking table, but in which case the predicted head-category may turn out to be the same	0	6	1
J89-4001	P85-1018	1989	One can obtain similar results for the class of grammars whose context-free backbone is finitely ambiguous--what <REF>Pereira and Warren 1983</REF> called the offline-parsable grammars	0	However, as <TREF>Shieber 1985b</TREF> observed, this class of grammars excludes many linguistically interesting grammars that do not use atomic category symbols	1	230 The present parser as opposed to the table-building algorithm is much like those in the literature	0	Like nearty all parsers using term unification, it is a special case of Earley deduction <REF>Pereira and Warren 1985</REF>	0	6	1
J89-4001	P85-1018	1989	<REF>Sato and Tamaki 1984</REF> proposed to analyze the behavior of Prolog programs, including parsers, by using something much like a weak prediction table	0	To guarantee that the table was finite, they restricted the depth of terms occurring in the table <TREF>Shieber 1985b</TREF> offered a more selective approach--his program predicts only those features chosen by the user as most useful for prediction	1	<REF>Pereira and Shieber 1987</REF> discuss both approaches	0	We will present a variation of Shiebers ideas that depends on using a sorted language	0	2	1
J89-4001	P85-1018	1989	Any general parsing method for definite clause grammar will enter an infinite loop in some cases, and it is the task of the grammar writer to avoid this	0	Generalized phrase structure grammar avoids the problem because it has only the formal power of context-free grammar <REF>Gazdar et al 1985</REF>, but according to <TREF>Shieber 1985a</TREF> this is not adequate for describing human language	1	Lexical functional grammar employs a better solution	0	A lexical functional grammar must include a finitely ambiguous context-free grammar, which we will call the context-free backbone <REF>Barton 1987</REF>	0	6	1
J89-4001	P85-1018	1989	We then define the set of terms in a standard way	0	All unification in this paper is unification of terms, as in <REF>Robinson 1965</REF>--not graphs or other structures, as in much recent work <TREF>Shieber 1985b</TREF>	1	A unification grammar is a five-tuple G  S, ,r T, P, Z where S is a set of sorts, ,r an S-ranked alphabet, T a finite set of terminal symbols, and Z a function letter of arity e in ,r	0	Z is called the start symbol of the grammar the standard notation is S not Z, but by bad luck that conflicts with standard notation for the set of sorts	0	2	1
J89-4001	P85-1018	1989	One could devise more elaborate examples, but this one suffices to make the point: not every natural unification grammar has an obvious context-free backbone	0	Therefore it is useful to have a parser that does not require us to find a context-free backbone, but works directly on a unification grammar <TREF>Shieber 1985b</TREF>	1	We propose to guarantee that the parsing problem is solvable by restricting ourselves to depth-bounded grammars	0	A unification grammar is depth-bounded if for every L > 0 there is a D > 0 such that every parse tree for a sentential form of L symbols has depth less than D In other words, the depth of a tree is bounded by the length of the string it derives	0	6	1
J89-4001	P85-1018	1989	The grammar is depth-bounded because the depth of a tree is a linear function of the length of the string it derives	0	A similar grammar can derive the crossed serial dependencies of Swiss German, which according to <TREF>Shieber 1985a</TREF> no context-free grammar can derive	1	It is clear where the extra formal power comes from: a contextfree grammar has a finite set of nonterminals, but a unification grammar can build arbitrarily large nonterminal symbols	0	It remains to show that there is a parsing algorithm for depth-bounded unification grammars	0	6	1
P94-1016	P85-1018	1994	Some additional penalty may also have been incurred by not using dotted grammar rules to generate reductions, as in standard leftcorner parsing algorithms	0	2 There are important differences between the technique for limited prediction in this parser, and other techniques for limited prediction such as Shiebers notion of restriction <TREF>Shieber, 1985</TREF> which we also use	1	In methods such as Shiebers, predictions are weakened in ways that can result in an overall gain in efficiency, but predictions nevertheless must be dynamically generated for every phrase that is built bottom-up	1	In our log version 314	0	3	2
P94-1016	P85-1018	1994	In addition, the parser maintains a skeletal copy of the chart in which edges are labeled only by the nonterminal symbols contained in their context-free backbone, which gives us more efficient indexing of the full grammar rules	0	Other optimizations include using one-word look-ahead before adding new predictions, and using restrictors <TREF>Shieber, 1985</TREF> to increase the generality of the predictions	1	Comparison with Other Parsers Table 1 compares the average number of edges, average number of predictions, and average parse times 1 in seconds per utterance for the limited 1All parse times given in this paper were produced on a Sun SPARCstation 10/51, running Quintus Pro111 For grammar with start symbol , phrase structure rules P, lexicon L, context-independent categories CI, and context-dependent categories CD; and for word string w  wlwn: Variant Edges Preds Secs Bottom-Up 1191 0 146 Limited Left-Context 203 25 10 Left-Corner 112 78 40 Table h Comparison of Syntax-Only Parsers if  E CD, predictT, 0; addemptycategories 0 ; for i from I to n do foreach C such that C--wi EL do addedgetochartC, i-i, i ; makenewpredictionsC, ii, i ; findnew-reductionsC, il,i end addemptycategories i ; end sub findmew-reductionsB, j, k  foreach A and a such that A- B 6 P do foreach i such that i  match, j do if A 6 CD and predictedA,i or A 6 CI addedgetochartA, i, k; makenewpredictionsA, i, k ; findnewreductionsA, i, k ; end end  sub addemptycategoriesi  foreach A such that A - e E P do if A 6 CD and predictedA,/ or A 6 CI addedgetochartA, i, i ; makenewpredictionsA, i, i ; findnewreductionsA, i, i ; end  sub makenewpredictionsA, i, j  foreach Aft E Predictionsi do predict fl, j end foreach H - ABfl 6 P such that H 6 CI and B E CD and fl 6 CI do predict B, j end foreach H -- AB 6 P such that H E CD and B E CD and fl E CI and predictedH, i or H left-corner-of C and predictedC, i do predict B, j end Figure 1: Limited Left-Context Algorithm left-context parser with those for a variant equivalent to a bottom-up parser when all categories are context independent and for a variant equivalent to a left-corner parser when all categories are context dependent	0	The tests were performed on a set of 194 utterances chosen at random from the ARPA ATIS corpus MADCOW, 1992, using a broad-coverage syntactic grammar of English having 84 coverage of the test set	0	3	2
P98-1101	P85-1018	1998	The situation becomes more complicated when we move to unification-based grammars, since there may be an unbounded number of different categories appearing in the accessible stack states	0	In the system implemented here we used restriction <TREF>Shieber, 1985</TREF> on the stack states to restrict attention to a finite number of distinct stack states for any given stack depth	1	Since the restriction operation maps a stack state to a more general one, it produces a finite-state approximation which accepts a superset of the language generated by the original unification grammar	0	Thus for general constraint-based grammars the language accepted by our finite-state approximation is not guaranteed to be either a superset or a subset of the language generated by the input grammar	0	3	2
E91-1052	P85-1018	1991	Since the size of the state sets possible with finite partitioning is now finite, the algorithm always terminates	0	After establishing a correspondence between attribute and unification grammar UG, we may see that the technique of restriction used by <TREF>Shieber 1985</TREF> in his extended algorithm is related to finite partitioning on attribute domains, in fact a particular case which takes advantage of the more structured attribute domains of UG	1	For attribute grammar, given that the domains involved are more general eg , the integers, finite partitioning is the required device	0	5	0	6	1
E91-1052	P85-1018	1991	1	0	Earleys 1970 algorithm is a general algorithm for context-free languages, widely used in natural language processing <REF>King, 1983</REF>; <TREF>Shieber, 1985</TREF> and syntactic pattern recognition <REF>Fu, 1982</REF>, where the full generative power of context-free grammar is required	1	The original algorithm and its common implementations, however, assume the atomic symbols of context-free grammars, thus limiting its applicability to systems with attributed symbols, or attribute grammars <REF>Knuth, 1968</REF>	0	Attribute grammar is an elegant formalization of the augmented context-free grammars characteristic of most current NLP systems	0	6	1
E91-1052	P85-1018	1991	However, their particular realization of the technique is severely restricted for NLP applications, since it uses a deterministic one-path LR algorithm, applicable only to semantically unambiguous grammars	0	<REF>Pereira and Warren 1983</REF> and <TREF>Shieber 1985</TREF> present v6rsions of Earleys algorithm for unification grammars, in which unification is the sole operation responsible for attribute evaluation	1	However, given the high computational cost of unification, important differences between attribute and unification grammars in their respective attribution domains and functions Correa, forthcoming, and the more general nature of attribute grammars in this regard, it is of interest to investigate the extension of Earleys algorithm directly to the main subclasses of attribute grammar	1	The paper is organized as follows: Section 2 presents pieliminary elements, including a definition of attribute grammar and Earleys algorithm	0	1	3
E91-1052	P85-1018	1991	Attribute grammar is an elegant formalization of the augmented context-free grammars characteristic of most current NLP systems	0	It is more general than members of the family of unification-based grammar formalisms <REF>Kay, 1985</REF>; <REF>Shieber, 1986</REF>, mainly in that it allows and encourages the use of simpler attribution functions than unification for the definition of attribute values, and hence can lead to computationally efficient grammatical definitions, while maintaining the advantages of a well-understood declarative formalism	1	Attribute grammar has been used in the past by the author to define computational models of Chomskys Government-binding theory, from which practical parsing programs were developed <REF>Correa, 1987a</REF>	0	Many systems based on Earleys algorithm have a clear division between the phases of syntactic and semantic analysis	0	2	1
P89-1029	P85-1018	1989	The parsing problem for offline parsable grammars ts solvable	0	Yet these grammars apparently have enough formal power to describe natural language at least, they can describe the crossed-serial dependencies of Dutch and Swiss German, which are presently the most widely accepted example of a construction that goes beyond context-free grammar <TREF>Shieber 1985a</TREF>	1	Suppose that the variable M ranges over integers, and the function letter s denotes the successor function	0	Consider the rule 1 pM --- psM A grammar containing this rule cannot be offline parsable, because erasing the arguments of the top-level terms in the rule gives 2 p --- p which immediately leads to infinite ambiguity	0	1	2
P89-1029	P85-1018	1989	These ideas can be generalized to other forms of unification	0	Consider dag unification as in <TREF>Shieber 1985b</TREF>	1	Given a set S of sorts, assign a sort to each label and to each atomic dag	1	The arity of a label is a set of sorts not a sequence of sorts as in term unification	0	6	1
J90-1004	P85-1018	1990	This does not deny that compilation methods may be able to convert a grammar into a program that generates without termination problems	0	In fact, the partial execution techniques described by two of us <REF>Pereira and Shieber 1985</REF> could form the basis of a compiler built by partial execution of the new algorithm we propose below relative to a grammar	1	However, the compiler will not generate a program that generates top-down, as Strzalkowskis does	1	v c,k,mj V mj I zag V k,m V e,k saw  helpen voeren help feed Figure 2 Schematic of Verb Subeategorization Lists for Dutch Example	0	1	3
J90-1004	P85-1018	1990	But even this ad hoc solution is problematic, as there may be no principled bound on the size of the subcategorization list	0	For instance, in analyses of Dutch cross-serial verb constructions <REF>Evers 1975</REF>; <REF>Huybrechts 1984</REF>, subcategorization lists may be concatenated by syntactic rules Moort32 Computational Linguistics Volume 16, Number 1, <REF>March 1990</REF> Shieber et al Semantic Head-Driven Grammar gat 1984; <REF>Fodor et al 1985</REF>; <REF>Pollard 1988</REF>, resulting in arbitrarily long lists	1	Consider the Dutch sentence dat Jan Marie de oppasser de olifanten zag helpen that John Mary the keeper the elephants saw help voeren feed that John saw Mary help the keeper feed the elephants The string of verbs is analyzed by appending their subcategorization lists as in Figure 2	0	Subcategorization lists under this analysis can have any length, and it is impossible to predict from a semantic structure the size of its corresponding subcategorization list merely by examining the lexicon	1	1	3
J90-1004	P85-1018	1990	The symptom is an ordering paradox in the sorting	0	For example, the complements rule given by <TREF>Shieber 1985a</TREF> in the PATR-II formalism VP 1 -- VP 2 X VPl head  VP2 head VP2 syncat first  X <VP2 syncat rest  VPI syncat can be encoded as the DCG rule: vpHead, Syncat/VP ->,Head, Compl/LFlSyncat/VP, Compl/LF	1	Top-down generation using this rule will be forced to expand the lower VP before its complement, since LF is uninstantiated initially	0	Any of the reordering methods must choose to expand the child VP node first	0	6	1
J90-1004	P85-1018	1990	where the cat i are terms representing the grammatical category of an expression and its subconstituents	0	Terminal symbols are introduced into rules by enclosing them in list brackets, for example sbar/S --> that, s/S Such rules can be translated into Prolog directly using a difference list encoding of string positions; we assume readers are familiar with this technique <REF>Pereira and Shieber, 1985</REF>	1	Because we concentrate on the relationship between expressions in a language and their logical forms, we will assume that the category terms have both a syntactic and a semantic component	0	In particular, the infix function symbol / will be used to form categories of the form Syn/Sem where Syn is the syntactic category of the expression and Sere is an encoding of its semantics as a logical form; the previous rule uses this notation, for example	0	6	1
J90-1004	P85-1018	1990	This is the correlate of the link relation used in left-corner parsers with top-down filtering; we direct the reader to the discussion by Matsumoto et al	1	1983 or <REF>Pereira and Shieber 1985</REF> for further information	1	applicable  non  chain  ruleRoot, Pivot, RHS : semantics ofroot andpivot ere serae node semanticsRoot, Sem, node semanticsPivot, Sere,  choose a nonchain rue non  chain  ruloLHS, RHS,   whose lhs matches the pivot unifyPivot, LHS,  make sttre tile categories can connect chained nodesPivot, Root	0	A chain rule is applicable to connect a pivot to a root if the pivot can serve as the semantic head of the rule and the left-hand side of the rule is appropriate for linking to the root	0	6	1
J90-1004	P85-1018	1990	The reason is simple	0	Consider, for example, a grammar with a gap-threading treatment of wh-movement <REF>Pereira 1981</REF>; <REF>Pereira and Shieber 1985</REF>, which might include the rule npAffr, npAgr/SemJX-X/Sem -->  	1	stating that an NP with agreement Agr and semantics Sere can be empty provided that the list of gaps in the NP can be represented as the difference list npAgr/SemlX-X, that is, the list containing an NP gap with the same agreement features Agr	1	Because the above rule is a nonchain rule, it will be considered when trying to generate any nongap NP, such as the proper noun np3-sing, G-G/john	0	6	1
J90-1004	P85-1018	1990	Tile algorithm described in this paper is an attempt to resolve these problems in a satisfactory manner	0	Although we believe that this algorithm could be seen as an instance of a uniform architecture for parsing and generation--just as tile extended Earley parser <TREF>Shieber, 1985b</TREF> and the bottom-up generator were instances of the generalized Earley deduction architecture--our efforts to date have been aimed foremost toward the development of the algorithm for generation alone	1	We will mention efforts toward this end in Section 5	0	11 APPLICABILITY OF THE ALGORITHM As does the Earley-based generator, the new algorithm assumes that the grammar is a unification-based or logic grammar with a phrase structure backbone and complex nonterminals	0	2	1
C96-2106	P85-1018	1996	441 Identifying Functional Strata Manually Normally, the grammarian knows which information needs to be made explicit	0	Hence, instead of differentiating between the linguistic strata sYN and SEM, we let the linguist identify which constraints filter and which only serve as a means for representation; see also <TREF>Shieber, 1985</TREF>	1	In contrast to the separation along linguistic levels, this approach adopts a functional view, cutting across linguistic strata	0	On this view, the syntactic constraints together with, eg, semantic selection constraints would constitute a subgrammar	0	6	1
C96-2106	P85-1018	1996	Though theoretically very attractive, codescription has its price: i the grammar is difficult to modularize due to the fact that the levels constrain each other mutually and ii there is a computational overhead when parsers use the complete descriptions	0	Problems of these kinds which were already noted by <TREF>Shieber, 1985</TREF> motivated tile research described here	1	The goal was to develop more flexible ways of using codescriptive grammars than having them applied by a parser with full informational power	0	The underlying observation is that constraints in such grammars can play different roles:  Genuine constraints which relate directly to tile grammaticality wellformedness of the input	0	5	2
E95-1011	P85-1018	1995	Furthermore, the need to perform nondestructive unification means that a large proportion of the processing time is spent copying feature structures	0	One approach to this problem is to refine parsing algorithms by developing techniques such as restrictions, structure-sharing, and lazy unification that reduce the amount of structure that is stored and hence the need for copying of features structures <TREF>Shieber, 1985</TREF>; <REF>Pereira, 1985</REF>; <REF>Karttunen and Kay, 1985</REF>; <REF>Wroblewski, 1987</REF>; <REF>Gerdemann, 1989</REF>; <REF>Godden, 1990</REF>; <REF>Kogure, 1990</REF>; <REF>Emele, 1991</REF>; <REF>Tomabechi, 1991</REF>; <REF>Harrison and Ellison, 1992</REF>	1	While these techniques can yield significant improvements in performance, the generality of unification-based grammar formalisms means that there are still cases where expensive processing is unavoidable	1	This approach does not address the fundamental issue of the tradeoff between the descriptive capacity of a formalism and its computational power	0	1	2
C86-1045	P85-1018	1986	Original Earley prediction works on category symbols	0	An answer to these problems was presented by <TREF>Shieber 1985</TREF> who proposed to do Earley prediction on the basis of some finite quotient of all constituent DAGs which can be specified by the grammar writer	1	Another example for the influence of the CUG efforts on the development of PATR is a new template notation introduced by Lauri Karttunen in his Interlisp-D version of PATR	0	Since categorial grammars exhibit an extensive embedding of categories within other categories, it is useful to unify templates not only with the whole lexical DAG but also with its categorial subgraphs	0	4	2
C94-2141	P85-1018	1994	The sohltion to this problem is to define a finite number of equivalence classes into which the infinite uumber of nnnterminals inay be sorted	0	Fhese ,lasses may be established in a number of ways; the one we have adopted in that presented by Harrison and Ellison,  992 which builds on l;he work of <TREF>Shieber, 1985</TREF>: it introduces the nol;ion of a negative restrictor to define equivalence classes	1	In this solution a predefined portion of a category a specific set of paths is discarded when determining whether a category belongs to an equivalence :lass or not	0	For instance, in the above example we could define the negative restrictor to be orth	0	5	2
E91-1031	P85-1018	1991	It turns out to be the case that only in this way the effect of top-down filtering will pay-off against the increased overhead of having to check the left-corner table	0	6 Some Results The performance of the parsing algorithms discussed in the preceding sections a bottom-up parser for UG BU, a top-down parser for UG of <TREF>Shieber, 1985</TREF> TD, a top-down parser operating on an instantiated grammar TD/1, and a bottom-up parser with topdown filtering operating on an instantiated grammar BU/LC were tested on two experimental CUGs, one implementing the morphosyntactic features of German N Ps, and one implementing the syntax of WH-questions in Dutch by means of a gap-threading mechanism	1	Some illustrative results are listed in Tables 1 and 2	0	Sentencel Sentence2 items sees items sees TD: 93 59 160 105 TD/I: 45 20 68 25 BU: 68 20 120 30 Bu/ c: 12 o6 53 o9 Table1: German For German, an ideal restrictor R was < l > II  cat,val, arg, or dir	0	6	1
E91-1031	P85-1018	1991	In terms of parse times the two algorithms are almost equivalent	0	Comparing our results with those of <TREF>Shieber 1985</TREF> and <REF>Haas 1989</REF>, we see that in all cases top-down filtering may reduce the size of the chart significantly	1	<REF>Whereas Haas 1989</REF> found that top-down filtering never helps to actually decrease parse times in a bottom-up parser, we have found at least one example German where top-down filtering is useful	0	183 7 Conclusions There is a trend in modern linguistics to replace grammars that are completely language specific by grammars which combine universal rules and principles with language specific parameter settings, lexicons, etc This trend can be observed in such diverse frameworks as Lexical Functional Grammar, Government-Binding Theory, Head-driven Phrase Structure Grammar and Categorial Grammar	0	2	3
E91-1031	P85-1018	1991	CHART PARSING OF UNIFICATION GRAMMAR UG	0	Parsing methods for context-free grammar can be extended to unification-based grammar formalisms see <TREF>Shieber, 1985</TREF> or <REF>Haas, 1989</REF>, and therefore they can in principle be used to parse CUG	1	A chart-parser scans a sentence from left to right, while entering items, representing partial derivations, in a chart	0	Assume that items are represented as Prolog terms of the form itemBegin, End, LH S, Parsed, ToParse, where LHS is a feature-structure and Parsed and ToParse contain lists of feature-structures	0	6	1
E91-1031	P85-1018	1991	Contrary to bottomup parsing, however, the adaptation of a top-down algorithm for UG requires some special care	0	For UGs which lack a so-called context-free back-bone, such as CUG, the top-down prediction step can only be guaranteed to terminate if we make use of restriction, as defined in <TREF>Shieber 1985</TREF>	1	Top-down prediction with a restrictor R where R is a finite set of paths through a feature-structure amounts to the following: Restriction The restriction of a feature-structure F relative to a restrictor R is the most specific feature-structure F  E F, such that every path in F j has either an atomic value or is an element of R Predictor Step For each item, End, LHS, Parsed, Next I ToParse such that Rjve, is the restriction of Next relative to R, and each rule RNe:t  RHS, add itemi,i, Rge:t, , RHS	0	Restriction can be used to develop a top-down chart parser for CUG in which the top-down prediction step terminates	1	4	2
P89-1002	P85-1018	1989	The algorithm described in this paper is an attempt to resolve these problems in a satisfactory manner	0	Although we believe that this algorithm could be seen as an instance of a uniform architecture for parsing and generation--just as the extended Earley parser <TREF>Shieber, 1985b</TREF> and the bottom-up generator were instances of the generalized Earley deduction architecture our efforts to date have been aimed foremost toward the development of the algorithm for generation alone	1	We will have little to say about its relation to parsing, leaving such questions for later research1 2 Applicability of the Algorithm As does the Earley-based generator, the new algorithm assumes that the grammar is a unificationbased or logic grammar with a phrase-structure backbone and complex nonterminMs	0	Furthermore, and again consistent with previous work, we assume that the nonterminals associate to the phrases they describe logical expressions encoding their possible meanings	0	2	1
P89-1002	P85-1018	1989	This is the correlate of the link relation used in left-corner parsers with topdown filtering; we direct the reader to the discussion by Matsumoto et al	1	1983 or Pereira and Shieber 1985, p 182 for further information	1	applicablenonchainrule Root, Pivot, RHS :7o semantics of root and pivot are same nodesemantics Root, Sem, nodesemanticsPivot, Sem, o choose a nonchain rule nonehainrulerHS, RttS, whose lhs matches the pivot unifyPivot, LHS, make sure the categories can connect chainednodesPivot, Root	0	A chain rule is applicable to connect a pivot to a root if the pivot can serve as the semantic head of the rule and the left-hand-side of the rule is appropriate for linking to the root	0	6	1
P01-1022	P85-1018	2001	In particular, in order to derive a finite CF grammar, we will need to consider only those features that have a finite number of possible values, or at least consider only finitely many of the possible values for infinitely valued features	0	We can use the technique of restriction <TREF>Shieber 1985</TREF> to remove these features from our feature structures	1	Removing these features may give us a more permissive language model, but it will still be a sound approximation	1	The experimental results reported in this paper are based on a grammar under development at RIACS for a spoken dialogue interface to a semi-autonomous robot, the Personal Satellite Assistant PSA	0	1	2
C98-1098	P85-1018	1998	The situation becomes more complicated when we move to unification-based grammars, since there may be an unbounded number of different categories appearing in the accessible stack states	0	In the system implemented here we used restriction <TREF>Shieber, 1985</TREF> on the stack states to restrict attention to a finite number of distinct stack states for any given stack depth	1	Since the restriction operation maps a stack state to a more general one, it produces a finite-state approximation which accepts a superset of the language generated by the original unification grammar	0	Thus for general constraint-based grammars the language accepted by our finite-state aptroximation is not guaranteed to be either a superset or a subset of the language generated by the input grammar	0	3	2
P96-1033	P85-1018	1996	The rule builds up infinitely large subcategorization lists of which eventually only one is to be matched against the subcategorization list of, eg, the lexical entry for buys	0	Though this rule is not cyclic, it becomes cyclic upon off-line abstraction: magicvp VForm, CSem I3, SSem : magicvp VForm, CSem2l, SSem  Through trimming this magic rule, eg, given a bounded term depth <REF>Sato and Tamaki, 1984</REF> or a restrictor <TREF>Shieber, 1985</TREF>, constructing an abstract unfolding tree reveals the fact that a cycle results from the magic rule	1	This information can then be used to discard the culprit	0	312 Indexing Removing the direct or indirect cycles from the magic part of the compiled grammar does eliminate the necessity of subsumption checking in many cases	0	6	1
P96-1033	P85-1018	1996	As a result of the explicit representation of filtering we do not need to postpone abstraction until run-time, but can trim the magic predicates off-line	0	One can consider this as bringing abstraction into the logic as the definite clause representation of filtering is weakened such that only a mild form of connectedness results which does not affect completeness <TREF>Shieber, 1985</TREF>	1	Consider the following magic rule: magicvpVForm, CgemlArgs, SSem :magicvp VForm, Args, SSem  This is the rule that is derived from the headrecursive vp rule when the partially specified subcategorization list is considered as filtering information cf	0	, fn	0	6	1
P96-1033	P85-1018	1996	More specifically, magic generation falls prey to non-termination in the face of head recursion, ie, the generation analog of left recursion in parsing	0	This necessitates a dynamic processing strategy, ie, memoization, extended with an abstraction function like, eg, restriction <TREF>Shieber, 1985</TREF>, to weaken filtering and a subsumption check to discard redundant results	0	It is shown that for a large class of grammars the subsumption check which often influences processing efficiency rather dramatically can be eliminated through fine-tuning of the magic predicates derived for a particular grammar after applying an abstraction function in an off-line fashion	0	Unfolding can be used to eliminate superfluous filtering steps	0	1	2
P95-1014	P85-1018	1995	In the categorial grammar example only x/3 goals are memoized and thus only these goals incur the cost of table management	0	The abstraction step, which is used in most memoizing systems including complex feature grammar chart parsers where it is somewhat confusingly called restriction, as in <TREF>Shieber 1985</TREF>, receives an elegant treatment in a CLP approach; an abstracted goal is merely one in which not all of the equality constraints associated with the variables appearing in the goal are selected with that goal	1	2 For example, because of the backward application rule and the left-to-right evaluation our parser uses, eventually it will search at every left string position for an uninstantiated category the variable Y in the clause, we might as well abstract all memoized goals of the form xC, L, R to x, L, , ie, goals in which the category and right string position are uninstantinted	0	Making the equality constraints explicit, we see that the abstracted goal is obtained by merely selecting the underlined subset of these below: xXl,X2, X3,Xl  C, X2  L, Xa  R While our formal presentation does not discuss abstraction since it can be implemented in terms of constraint selection as just described, because our implementation uses the underlying Prologs unification mechanism to solve equality constraints over terms, it provides an explicit abstraction operation	0	6	1
C96-2111	P85-1018	1996	24 Top-Down Predictive Linking The aim of our proposal is to define equivalence relations that keep the linking relation finite while also preventing it from being too restrictive; this turns the linking relation into a weakpredietion table in the sense of Haas 1989: 227ff	0	Like Shieber 1985, 1992 with the notion of restriction, we confine our attention to a subset of specifications; in particular, we can define a feature structure that subsumes all VP-type feature structures of Shiebers recursive subcategorization rules	1	But unlike Shieber, our restrictors are computed automatically by building the generalization of the occurrences ofleftrecursive categories in a grammar	1	The intuitive idea is that we consider categories to be left recursive if their tokens can be unified rather than being identical, as in the case of atoms; we then use their generalization, or greatest lower bound, as a common denominator defining an equivalence relation	0	2	3
C96-2111	P85-1018	1996	A better solution, which we have adopted from <REF>Kilbury 1990</REF>, is to introduce rule numbers, which are then used to define a purely filtering linking relation	0	This amounts to the simplest case of the restriction technique of <TREF>Shieber 1985</TREF>	1	Only when a link between numerical pointers is first found is the linking relation between feature structures used to instantiate information	0	3 Consequences of Predictive Linking What is the advantage of predictive linking as discussed above in 2	0	6	1
C96-2111	P85-1018	1996	Such formalisms typically include a contextfree CF base, which allows the use of parsing algorithms designed for CF languages despite the fact that complex-feature-based formalisms are essentially more powerful than CF grammars	0	However, such an adaptation of CF algorithms involves their extension to possibly infinite nonterminal domains, which, as <TREF>Shieber 1985</TREF> and <REF>Haas 1989</REF> have shown, is nontrivial	1	Various CF algorithms make use of a binary relation between a goal category and the category of a constituent phrase or word which either has just been parsed or is to be parsed next	0	Different terms have been used to designate this relation; <REF>Kay 1980</REF> speaks of reachability, while Pereira/<REF>Shieber 1987</REF> and others before them use the term linking for the relation	0	6	1
C96-2111	P85-1018	1996	1990 have discussed similar techniques in the context of semantichead-driven generation, we are concerned here with parsing	0	We view the linking relation not simply as a filter to increase efficiency within the domain of syntactic analysis--this aspect is stressed by <TREF>Shieber 1985</TREF> and other investigators such as <REF>Bouma 1991</REF>--but rather as a device for the top-down predictive instantiation of information, as Shieber et al	1	1990 have shown for semantic-head-driven generation	1	In this paper we are concerned especially with morphosyntactic information and illustrate the relevance of predictive linking for morphological analysis and for the analysis of unknown or new lexical items	0	4	2
C96-2111	P85-1018	1996	Whatever term one takes, an important aspect of the relation is that it can be used to reduce the search space of possible syntactic analyses at an earlier point in parsing and thus serves to improve the efficiency of a parser	0	Shieber 1985, 1992 follows established terminology in speaking of top-down filtering in connection with the prediction step of the Earley algorithm	0	His central notion of restriction, whereby a restrictor is a finite subset of the paths specified in a feature structure, is related to the technique we introduce here, since both guarantee the finiteness of an otherwise possibly infinite domain of complex categories, but Shiebers restrictors are specified manually	1	We propose a general algorithmic method of compilation that avoids manual specification	0	1	3
J93-1002	P85-1018	1993	In particular, declaring certain category-valued features so that they cannot take variable values may lead to nontermination in the backbone construction for some grammars	0	However, it should be possible to restrict the set of features that are considered in category-valued features in an analogous way to Shiebers 1985 restrictors for Earleys 1970 algorithm, so that a parse table can still be constructed	1	36 Ted Briscoe and John Carroll Generalized Probabilistic LR Parsing 4	0	Building LR Parse Tables for Large NL Grammars The backbone grammar generated from the ANLT grammar is large: it contains almost 500 distinct categories and more than 1600 productions	0	1	2
J93-1002	P85-1018	1993	This requirement places a greater load on the grammar writer and is inconsistent with most recent unification-based grammar formalisms, which represent grammatical categories entirely as feature bundles eg <REF>Gazdar et al 1985</REF>; <REF>Pollard and Sag 1987</REF>; <REF>Zeevat, Calder, and Klein 1987</REF>	0	In addition, it violates the principle that grammatical formalisms should be declarative and defined independently of parsing procedure, since different definitions of the CF portion of the grammar will, at least, effect the efficiency of the resulting parser and might, in principle, lead to nontermination on certain inputs in a manner similar to that described by <TREF>Shieber 1985</TREF>	1	In what follows, we will assume that the unification-based grammars we are considering are represented in the ANLT object grammar formalism <REF>Briscoe et al 1987</REF>	0	This formalism is a notational variant of Definite Clause Grammar eg <REF>Pereira and Warren 1980</REF>, in which rules consist of a mother category and one or more daughter categories, defining possible phrase structure configurations	0	1	3
W07-1219	P85-1018	2007	In contrast to the symbols in context-free grammars, feature structures in unification-based grammars often include information encoding part of the derivation history, most notably semantics	0	In order to achieve successful packing rates, feature restriction <TREF>Shieber, 1985</TREF> is used to remove this information during creation of the packed parse forest	1	During the unpacking phase, which operates only on successful parse trees, these features are unified back in again	0	For their experiments with efficient subsumptionbased packing, <REF>Oepen and Carroll, 2000</REF> experimented with different settings of the packing restrictor for the English Resource Grammar ERG <REF>Copestake and Flickinger, 2000</REF>: they found that good packing rates, and overall good performance during forest creation and unpacking were achieved, for the ERG, with partial restriction of the semantics, eg keeping index features unrestricted, since they have an impact on external combinatorial potential, but restricting most of the internal MRS representation, including the list of elementary predications and scope constraints	0	3	2
A00-2022	P85-1018	2000	5 Choosing the Grammar Restrictor and Parsing Strategy In order for the subsumption relation to apply meaningfully to HPSG signs, two conditions must be met	0	Firstly, parse tree construction must not be duplicated in the feature structures by means of the HPSG DTRS feature but be left to the parser ie recorded in the chart; this is achieved in a standard way by feature structure restriction <TREF>Shieber, 1985</TREF> applied to all passive edges	1	Secondly, the processing of constraints that do not restrict the search space but build up new often semantic structure should be postponed, since they are likely to interfere with subsumption	0	For example, analyses that differ only with respect to PP attachment would have the same syntax, but differences in semantics may prevent them being packed	0	6	1
P97-1058	P85-1018	1997	Attention is restricted here to approximations of context-free grammars because context-free languages are the smallest class of formal language that can realistically be applied to the analysis of natural language	0	Techniques such as restriction <TREF>Shieber, 1985</TREF> can be used to construct context-free approximations of many unification-based formalisms, so techniques for constructing finite-state approximations of context-free grammars can then be applied to these formalisms too	0	2 Finite-state calculus A finite-state calculus or finite automata toolkit is a set of programs for manipulating finite-state automata and the regular languages and transducers that they describe	0	Standard operations include intersection, union, difference, determinisation and minimisation	0	6	2
C90-2019	P85-1018	1990	The ELU tormalism provides a generalization of the template facility of PATR-II, the relational abstractions, which are statements abstracting over sets of constraint equations	1	These statements 5 Restrictors are also used to restrict the search space in parsing see <TREF>Shieber 1985</TREF>	1	fbe use of linking information in generation was first proposed by van <REF>Noord 1988</REF>	0	may receive multiple and mcursive definitions	0	6	1
C88-2121	P85-1018	1988	Problems in the prediction step of the Earley parser used for unification-based formalisms no longer exist	0	The use of restrictors as proposed by <TREF>Shieber 1985</TREF> is no longer necessary and the difficulties caused by treating subcategorization as a feature is no longer a problem	1	By assuming that the number of structures associated with a lexical item is finite, since each structure has a lexical item attached to it, we implicitly make the assumption that an input string of finite length cannot be syntactically infinitely ambiguous	0	Since the trees are produced by the input string, the parser can use information that might be non-local to guide the search	0	1	3
C02-1075	P85-1018	2002	The resulting structures form equivalence classes, since they abstract from word-specific information, such as FORM or STEM	0	The abstraction is specified by means of a restrictor <TREF>Shieber, 1985</TREF>, the so-called lexicon restrictor	1	After that, the grammar rules are instantiated by unification, using the abstracted lexicon entries and resulting in derivation trees of depth 1	0	The rule restrictor is applied to each resulting feature structure FS, removing all information contained only in the daughters of a rule	0	3	2
C96-2160	P85-1018	1996	head-dtr syn  counter 1   Then, this can generate an infinite sequence of signs, each of which contains a part,  counter <bar, ba, r,,bar l and is not equivalent to any previously generated sign	0	In order to resolve this difficulty, we apply tim restriction <TREF>Shieber, 1985</TREF> to a rule schemata and a lexical entry, and split the feature structure F  fsR of a rule schema R or a lexical entry F  l, into two, namely, coreF and subF such that F  coreF U subF	1	The definition of the restriction here is given as follows	0	Definition 5 paths For arty node n in a feature structure F, pathsn,F is a set of all the paths that reaches n from the root of F Definition 6 Restriction Schema A restriction schema rs is a set of paths	0	3	1
P91-1032	P85-1018	1991	However, these models are inadequate for language interpretation, since they cannot express the relevant syntactic and semantic regularities	0	Augmented phrase structure grammar APSG formalisms, such as unification-based grammars <TREF>Shieber, 1985a</TREF>, can express many of those regularities, but they are computationally less suitable for language modeling, because of the inherent cost of computing state transitions in APSG parsers	1	The above problems might be circumvented by using separate grammars for language modeling and language interpretation	0	Ideally, the recognition grammar should not reject sentences acceptable by the interpretation grammar and it should contain as much as reasonable of the constraints built into the interpretation grammar	0	1	3
E91-1013	P85-1018	1991	procedure CLOSUREI; begin repeat for each item <AwBx> in I, and each production C-y such that C is unifiable with B and <CBy> is not in I do add <CB--,y> to I; until no more items can be added to I; return I end; procedure NEXT-SI,C for each category C that appears to the right ; of the dot in items begin let J be the set of items <A-wBx> such that <AwBx> is in I and B is unifiable with C; return CLOSUREJ end; Figure 6	0	Preliminary CLOSURE/NEXT-S Procedures The preliminary CLOSURE procedure Unifies the lhs of a predicted production, ie -71 Cy, and the category the prediction is made flom, ieB This approach is essentially top-down lrOlagation of instantiated features and well documented by <TREF>Shieber 1985</TREF> in the context of Earleys algorithm	1	A new item added to the state, <CB--,	0	y>, is not the production C--,y, but its partial instantiation, y is also instantiated to be y as a result of the unification CB if C and some members of y share tags	0	6	1
E91-1013	P85-1018	1991	That is, instantiation of productions introduces the nontermination problem of left-recursive productions to the procedure, as well as to the Predictor Step of Earleys algorithm	0	To overcome this problem, <TREF>Shieber 1985</TREF> proposes restrictor, which specifies a maximum depth of feature-based categories	1	When the depth of a category in a predicted item exceeds the limit imposed by a restrictor, further instantiation of the category in new items is prohibited	0	The Predictor Step eventually halts when it starts creating a new item whose feature specification within the depth allowed by the resuictor is identical to, or subsumed by, a previous one	0	1	2
P99-1061	P85-1018	1999	The situation is different for active chart items since daughters can affect their siblings	0	To be independent from a-certain grammatical theory or implementation, we use restrictors similar to <TREF>Shieber, 1985</TREF> as a flexible and easyto-use specification to perform this deletion	1	A positive restrictor is an automaton describing the paths in a feature structure that will remain after restriction the deletion operation, 3There are refinements of the technique which we have implemented and which in practice produce additional benefits; we will report these in a subsequent paper	0	Briefly, they involve an improvement to th e path collection method, and the storage of other information besides types in the vectors	0	3	2
J85-4001	P85-1018	1985	Estimates of the object-grammar size for typical systems vary from hundreds or thousands 3 up to trillions of rules <REF>Shieber 1983</REF>:4	0	With some formalisms, the context-free object-grammar approach is not even possible because the object grammar would be infinite <TREF>Shieber 1985</TREF>:145	1	Grammar size matters beyond questions of elegance and clumsiness, for it typically affects processing complexity	0	<REF>Berwick and Weinberg 1982</REF> argue that the effects of grammar size can actually dominate complexity for a relevant range of input lengths	0	6	1
P04-1017	P87-1022	2004	That is, for the reference determination, the subject roles of the candidates referent within a discourse segment will be checked intheflrstplace	0	Thisflndingsupportswell the suggestion in centering theory that the grammaticalrelationsshouldbeusedasthe key criteria to rank forward-looking centers in the process of focus tracking <TREF>Brennan et al , 1987</TREF>; <REF>Grosz et al , 1995</REF>	1	3	0	candi Pron and candi NoAntecedent are to be examined in the cases when the subject-role checking fails, which conflrms the hypothesis in the S-List model by <REF>Strube 1998</REF> that co-refereing candidates would have higher preference than other candidates in the pronoun resolution	0	4	2
P04-1017	P87-1022	2004	The S-List model <REF>Strube, 1998</REF>, for example, assumes that a co-referring candidate is a hearer-old discourse entity and is preferred to other hearer-new candidates	0	In the algorithms based on the centering theory <TREF>Brennan et al , 1987</TREF>; <REF>Grosz et al , 1995</REF>, if acandidateanditsantecedentarethebackwardlooking centers of two subsequent utterances respectively, the candidate would be the most preferred since the CONTINUE transition is always ranked higher than SHIFT or RETAIN	1	In this paper, we present a supervised learning-based pronoun resolution system which incorporates coreferential information of candidates in a trainable model	0	For each candidate, we take into consideration the properties of its antecedents in terms of features henceforth backward features, and use the supervised learning method to explore their in uences on pronoun resolution	0	6	1
W99-0104	P87-1022	1999	The first class is characterized by adaptations of previously known reference algonthms eg	0	<REF>Lappin and Leass, 1994</REF>, <TREF>Brennan et al , 1987</TREF> the scarce syntactic and semantic knowledge available m an w system eg	1	<REF>Kameyama, 1997</REF>	0	The second class is based on statistical and machine learning techniques that rely on the tagged corpora to extract features of the coreferential relations eg	0	6	1
P00-1051	P87-1022	2000	One of the most unusual features of centering theory is that the notions of utterance, previous utterance, ranking, and realization used in the definitions above are left unspecified, to be appropriately defined on the basis of empirical evidence, and possibly in a different way for each language	0	As a result, centering theory is best viewed as a cluster of theories, each of which specifies the parameters in a different ways: eg, ranking has been claimed to depend on grammatical function <REF>Kameyama, 1985</REF>; <TREF>Brennan et al , 1987</TREF>, on thematic roles <REF>Cote, 1998</REF>, and on the discourse status of the CFs <REF>Strube and Hahn, 1999</REF>; there are at least two definitions of what counts as previous utterance <REF>Kameyama, 1998</REF>; <REF>Suri and McCoy, 1994</REF>; and realization can be interpreted either in a strict sense, ie, by taking a CF to be realized in an utterance only if an NP in that utterance denotes that CF, or in a looser sense, by also counting a CF as realized if it is referred to indirectly by means of a bridging reference <REF>Clark, 1977</REF>, ie, an anaphoric expression that refers to an object which wasnt mentioned before but is somehow related to an object that already has, as in the vase the handle see, eg, the discussion in <REF>Grosz et al , 1995</REF>; <REF>Walker et al , 1998b</REF>	1	3 METHODS The fact that so many basic notions of centering theory do not have a completely specified definition makes empirical verification of the theory rather difficult	1	Because any attempt at directly annotating a corpus for utterances and their CBs is bound to force the annotators to adopt some specification of the basic notions of the theory, previous studies have tended to study a particular variant of the theory <REF>Di Eugenio, 1998</REF>; <REF>Kameyama, 1998</REF>; <REF>Passonneau, 1993</REF>; <REF>Strube and Hahn, 1999</REF>; <REF>Walker, 1989</REF>	0	1	3
C04-1074	P87-1022	2004	Another important factor in pronoun resolution is the grammatical role of the antecedent	0	The role hierarchy used in centering <TREF>Brennan et al , 1987</TREF>; <REF>Grosz et al , 1995</REF> ranks subjects over direct objects over indirect objects over others	1	<REF>Lappin and Leass 1994</REF> provide a more elaborate model which ranks NP complements and NP adjuncts lowest	0	Two other distinctions in their model express a preference of rhematic2 over thematic arguments: Existential subjects, which follow the verb, rank very high, between subjects and direct objects	0	6	1
C04-1074	P87-1022	2004	Similarly, we can assess other strategies of sentence ordering that have been proposed in the literature	0	Hard-core centering approaches only deal with the last sentence <TREF>Brennan et al , 1987</TREF>	1	In Negra, these approaches can consequently have at most a success rate of 442	1	Performance is particularly low with possessive pronouns which often only have antecedents in the current sentence	1	1	3
W96-0211	P87-1022	1996	While it appears that our existing linguistic bias set will be of use, we believe that the CBL system will benefit from additional linguistic biases	0	Centering constraints see <TREF>Brennan et al , 1987</TREF>, for example, can be encoded as linguistic biases and applied to the pronoun resolution task to increase system performance	1	Furthermore, we have focused on applying the linguistic bias approach to feature set selection for case-based learning algorithms only	0	In future work, we plan to investigate the use of the approach for feature selection in conjunction with other standard machine learning algorithms	0	6	1
P98-2241	P87-1022	1998	A number of studies have developed refinements and extensions of the theory eg	0	<TREF>Brennan et al , 1987</TREF>; <REF>Kameyama, 1986</REF>; <REF>Strube and Hahn, 1996</REF>; <REF>Walker et al , 1998</REF>, but few have attempted to extend the model to multi-party discourse cf	1	<REF>Brennan, 1998</REF>; <REF>Walker, 1998</REF>	0	For dialog systems, the benefits of using centering theory include improved reference resolution and generation of more coherent referring expressions	0	6	1
P04-1011	P87-1022	2004	Separately, the SPG also handles referring expression generation by converting proper names to pronouns when they appear in the previous utterance	0	The rules are applied locally, across adjacent sequences of utterances <TREF>Brennan et al , 1987</TREF>	1	Referring expressions are manipulated in the d-trees, either intrasententially during the creation of the sp-tree, or intersententially, if the full sp-tree contains any period operations	0	The third and fourth sentences for Alt 13 in Figure 4 show the conversion of a named restaurant Carmines to a pronoun	0	6	1
C98-2161	P87-1022	1998	Pragmatic level Working together, surface patterns and possessive relationships can deal with many PPAs found in our corpus, but we still have two problems to be solved: semantic ambiguity among two or more acceptable candidates and abstract anaphors/antecedents, which cannot be solved by simply applying possessive relationship rules	0	For these cases, and possibly for some other cases not included in previous rules, we suggest a pragmatic factor, adapted from S Brennans et al 1987 centering algorithm	1	Although sentence center plays a crucial role in many works in anaphor resolution, usually limiting the number of candidates to be considered, we notice that, because PPAs can refer to almost any NP in the sentence rather than, for example, personal pronouns, which are often related to the sentence center, pragmatic knowledge plays only a secondary but still important role in our approach	0	We have adapted basic aspects of center algorithm, considering subject/object preference, and domain concepts preference, 1012 suggested by R <REF>Mitkov 1996</REF>, aiming to estimate the most probable center for intrasentential PPAs	0	5	2
P98-2204	P87-1022	1998	In Section 3, I introduce my model, its only data structure, the S-list, and the accompanying algorithm	0	In Section 4, I compare the results of my algorithm with the results of the centering algorithm <TREF>Brennan et al , 1987</TREF> with and without specifications for complex sentences <REF>Kameyama, 1998</REF>	1	2 A Look Back: Centering The centering model describes the relation between the focus of attention, the choices of referring expressions, and the perceived coherence of discourse	0	The model has been motivated with evidence from preferences for the antecedents of pronouns <REF>Grosz et al , 1983</REF>; 1995 and has been applied to pronoun resolution Brennan et al	0	6	1
P98-2204	P87-1022	1998	Their approach has been proven as the point of departure for a new model which is valid for English as well	0	The use of the centering transitions in Brennan et als 1987 algorithm prevents it from being applied incrementally cf	1	<REF>Kehler 1997</REF>	0	In my approach, I propose to replace the functions of the backward-looking center and the centering transitions by the order among the elements of the list of salient discourse entities S-list	0	1	3
P98-2204	P87-1022	1998	RANK by transition orderings	0	To illustrate this algorithm, we consider example 1 <TREF>Brennan et al , 1987</TREF> which has two different final utterances ld and ld	1	Utterance ld contains one pronoun, utterance ld t two pronouns	0	We look at the interpretation of ld and ldt	0	6	1
C96-1060	P87-1022	1996	Table 1 illustrates the Pour transitions that are detined according to diese constraints	0	<TREF>Brennan et al , 1987</TREF></TREF> proposes a default ordering on transitions which correlates with discourse coherence: CONTINUE is preferred to RETAIN is prelbrred to SMOOTH-SHIFT is pre2The version of centering I presem; here is tiom <TREF>Brennan et al , 1987</TREF></TREF>	1	352 H CbUu  CbWn, Ct,Un 7 CtW,,	0	1 n CbU,  CtU, XNTINUI,; SMOOTII-SItlH CbU,,  CpU, IETAIN IIUIlI-SIIIFT Tatle 1: Ceutering Transitions ferred to IIIII-SIIllT	0	6	1
W97-1302	P87-1022	1997	Although they report that their method estimates over 90 of zero subjects correctly, there are several difficulties including the fact that the test corpus is identical with the corpus from which the pragmatic constraints are extracted, and the fact that there are so many rules46 rules to estimate 175 sentences	0	As for the identifying method available in general discourses, the centering theory<TREF>Brennan et al , 1987</TREF>; <REF>Walker et al , 1990</REF> and the property sharing theory<REF>Kameyama, 1988</REF> are proposed	1	The important feature of these theories is the fact that it is independent of the type of discourse	0	However, according to our experimental result, it seems that these kinds of theory do not estimate zero subjects in high precision for manual sentences 3	1	1	3
C98-2138	P87-1022	1998	This preference can be explained in terms of salience from the point of view of the centering theory	0	The latter proposes the ranking subject, direct object, indirect object <TREF>Brennan et al 1987</TREF> and noun phrases which are parts of prepositional phrases are usually indirect objects	1	Collocation pattern preference This preference is given to candidates which have an identical collocation pattern with a pronoun 2,0	0	The collocation preference here is restricted to the patterns noun phrase pronoun, verb and verb, noun phrase pronoun	0	6	1
J04-3003	P87-1022	2004	Grosz et al list seven such costraints, three of which can be directly evaluated	0	Even though we are not following here the distinction between constraints and rules introduced in <REF>Brennan, Friedman, and Pollard 1987</REF>, we will use for these three claims the names Brennan et al gave them, by which they are now best known: Constraint 1 Strong: All utterances of a segment except for the first have exactly one CB	1	Rule 1 GJW95: If any CF is pronominalized, the CB is Rule 2 GJW95: Sequences of continuations are preferred over sequences of retains, which are preferred over sequences of shifts	0	231 Constraint 1, Topic Uniqueness, and Entity Coherence	0	3	2
W98-1119	P87-1022	1998	162 In effect, we use this probability information to identify the topic of the segment with the belief that the topic is more likely to be referred to by a pronoun	1	The idea is similar to that used in the centering approach <TREF>Brennan et al , 1987</TREF> where a continued topic is the highest-ranked candidate for pronominalization	1	Given the above possible sources of informar tion, we arrive at the following equation, where Fp denotes a function from pronouns to their antecedents: Fp  argmaxP Ap  alp, h, l, t, l, so, d A where Ap is a random variable denoting the referent of the pronoun p and a is a proposed antecedent	0	In the conditioning events, h is the head constituent above p, l r is the list of candidate antecedents to be considered, t is the type of phrase of the proposed antecedent always a noun-phrase in this study, I is the type of the head constituent, sp describes the syntactic structure in which p appears, dspecifies the distance of each antecedent from p and M is the number of times the referent is mentioned	0	5	2
C98-2236	P87-1022	1998	A number of studies have developed refinements and extensions of the theory eg	0	Brennan et at, 1987; <REF>Kameyama, 1986</REF>; <REF>Strube and Hahn, 1996</REF>; <REF>Walker et al, 1998</REF>, but few have attempted to extend the model to mul party discourse cf	1	<REF>Brennan, 1998</REF>; <REF>Walker, 1998</REF>	0	For dialog systems, the benefits of using centering theory include improved reference resolution and generation of more coherent referring expressions	0	6	1
C98-2199	P87-1022	1998	CbU  CpUd cbu  cpud Cb U   CbU   OR no CbUi-l CONTINUE RETAIN CbUi  CbUi-1 SMOOTH-SHIFT ROUGH-SHIFT Table 1: Transition Types Brennan et al	0	1987 modify the second of two rules on center movement and realization which were defined by Grosz et al	0	1983; 1995: Rule 1: If some element of CfUi-1 is realized as a pronoun in Ui, then so is CbUi	0	Rule 2: Transition states are ordered	0	0	0
C98-2199	P87-1022	1998	In Section 3, I introduce my model, its only data structure, the S-list, and the accompanying algorithm	0	In Section 4, I compare the results of my algorithm with the results of the centering algorithm <TREF>Brennan et al, 1987</TREF> with and without specifications for complex sentences <REF>Kamcyama, 1998</REF>	1	2 A Look Back: Centering The centering model describes the relation between the focus of attention, the choices of referring expressions, and the perceived coherence of discourse	0	The model has been motivated with evidence from preferences for the antecedents of pronouns <REF>Grosz et al, 1983</REF>; 1995 and has been applied to pronoun resolution Brennan et al	0	6	1
C98-2199	P87-1022	1998	Their approach has been proven as the point of departure for a new model which is valid for English as well	0	The use of the centering transitions in Brennan et als 1987 algorithm prevents it from being applied incrementally cf	1	<REF>Kehler 1997</REF>	0	In my approach, I propose to replace the functions of the backward-looking center and the centering transitions by the order among the elements of the list of salient discourse entities S-list	0	1	3
C98-2199	P87-1022	1998	RANK by transition orderings	0	To illustrate this algorithm, we consider example 1 <TREF>Brennan et al, 1987</TREF> which has two different final utterances ld and ld	1	Utterance ld contains one pronoun, utterance ld t two pronouns	0	We look at the interpretation of ld and ld	0	6	1
P03-1023	P87-1022	2003	Mitkovs knowledge-poor pronoun resolution method <REF>Mitkov, 1998</REF>, for example, uses the scores from a set of antecedent indicators to rank the candidates	0	And centering algorithms <TREF>Brennan et al , 1987</TREF>; <REF>Strube, 1998</REF>; <REF>Tetreault, 2001</REF>, sort the antecedent candidates based on the ranking of the forward-looking or backwardlooking centers	1	In recent years, supervised machine learning approaches have been widely used in coreference resolution <REF>Aone and Bennett, 1995</REF>; <REF>McCarthy, 1996</REF>; <REF>Soon et al , 2001</REF>; <REF>Ng and Cardie, 2002a</REF>, and have achieved significant success	0	Normally, these approaches adopt a single-candidate model in which the classifier judges whether an antecedent candidate is coreferential to an anaphor with a confidence value	0	6	1
P89-1030	P87-1022	1989	Any communicative act, be it spoken, written, gestured, or system-initiated, can give rise to DEs	0	As a discourse progresses, an adequate discourse model must represent the relevant entities, and the relationships between them <REF>Grosz and Sidner, 1986</REF>, A speaker may then felicitously refer anaphorically to an object subject to focusing or centering constraints <REF>Grosz et al , 1983</REF>, <REF>Sidner 1981, 1983</REF>, <TREF>Brennan et al 1987</TREF>  if there is an existing DE representing it, or if a corresponding DE may be directly inferred from an existing DE	1	For example, the utterance Every senior in Milford High School has a car gives rise to at least 3 entities, describable in English as the seniors in Milford High School, Milford High School, and the set of cars each of which is owned by some senior in Milford High School	0	These entities may then be accessed by the following next utterances, respectively: They graduate in June	0	6	1
P89-1030	P87-1022	1989	This is, to our knowledge, the first implementation of Webbers DE generation ideas	0	We designed the 243 algorithms and structures necessary to generate discourse entities from our logical representation of the meaning of utterances, and from pointing gestures, and currently use them in Januss <REF>Weischedel et al , 1987</REF>, BSN, 1988 pronoun resolution component, which applies centering techniques <REF>Grosz et al , 1983</REF>, <REF>Sidner 1981, 1983</REF>, <TREF>Brennan et al 1987</TREF> to track and constrain references	1	Janus has been demonstrated in the Navy domain for DARPAs Fleet Command Center Battle Management Program FCCBMP, and in the Army domain for the Air Land Battle Management Program ALBM	0	2 Meaninq Representation for DE Generation Webber found that appropriate discourse entities could be generated from the meaning representation of a sentence by applying rules to the representation that are strictly structural in nature, as long as the representation reflects certain crucial aspects of the sentence	0	6	1
P98-2166	P87-1022	1998	Pragmatic level Working together, surface patterns and possessive relationships can deal with many PPAs found in our corpus, but we still have two problems to be solved: semantic ambiguity among two or more acceptable candidates and abstract anaphors/antecedents, which cannot be solved by simply applying possessive relationship rules	0	For these cases, and possibly for some other cases not included in previous rules, we suggest a pragmatic factor, adapted from S Brennans et al 1987 centering algorithm	1	Although sentence center plays a crucial role in many works in anaphor resolution, usually limiting the number of candidates to be considered, we notice that, because PPAs can refer to almost any NP in the sentence rather than, for example, personal pronouns, which are often related to the sentence center, pragmatic knowledge plays only a secondary but still important role in our approach	0	We have adapted basic aspects of center algorithm, considering subject/object preference, and domain concepts preference, 1012 suggested by R <REF>Mitkov 1996</REF>, aiming to estimate the most probable center for intrasentential PPAs	0	5	2
W99-0109	P87-1022	1999	The result is as follows: UI : Cb f a, Cp  a U2:Cba, Cpb U3 : Cb f b, Cp  b U4 : Cb  b, Cp  b In terms of the conventional transitions this works out as U/U2: RETIN U2/U3: SMOOTH SHIFT us/u: COnTINUa This is consistent with Strube and Hahns 1996 observation that a IIrAIN transition ideally predicts a SMOOTH sswr in the following utterance	0	<REF>Brenuan et al 1987</REF> make a very similar claim: A computational system for 9e-emtion would try to plan a retention as a signal of an impending shift, so that after a retention, a shift would be preferred rather than a continuation	1	<REF>Grosz et al 1995</REF> give the following example of the Am SHIFT pattern: 5 a John has had trouble arranging his vacation	0	b He Cb; John cannot find anyone to take over his responsibilities	0	2	1
W99-0109	P87-1022	1999	I suggmtthat these results should be treated with some caution since it is not dear that the authors have the same assumptions about the claims of CT or that what they are testing directly reflects formulations of CT in the more theoretical literature	0	For instance <REF>Passoneau 1998</REF> refers to two variantS of CT: Version A based on <TREF>Brennan et al 1987</TREF> and Version B taken from <REF>Kameyama et al 1993</REF>	1	Passoneau does nt address the issue of direct vs indirect realisation and it appears from the examples given that she only takes account of entities realised by a full NP or possibly null pronoun	0	The analysis according to Version B results in a count of 52 NULL transitions, ie no Cb, which gives the impression that CT is in fact a rather poor measure of coherence, It is probable that a higher measure might have been obtained if Passoneau had allowed entities to be added to the U/s by inference, as discussed in Brennan et al, op cit	0	6	1
W99-0109	P87-1022	1999	Centering theory C is a theory of discourse structure which models the interaction of cohesion and salience in the internal organlsation of a text	0	The main assumptions of the theory as presented by Gross et a11995 GJW, <TREF>Brennan et al 1987</TREF> rare: 1	1	For each utterance in a discourse there is precisely one entity which is the centre of attention or center	0	2	0	6	1
W99-0109	P87-1022	1999	Take the Cb as given and plan the realisation of Ui- to make this entity the highestranked	0	The first strategy is clearly appropriate for interpretation cf <TREF>Brennan et al 1987</TREF> but for generation the issue is less clear-cut	1	Either the generator interprets its own output to designate Cb in terms of the grammatical structure of the previous utterance, in which case there have to be separate principles for deciding on the grammatical structure, or Cb is independently defined in the text plan and this information is used to plan the sentence structure	0	According to the pipelining principle information cannot flow backwards between tasks	0	6	1
W04-0713	P87-1022	2004	The function for resolving IPAs ResolveIpa has similarly been tested on texts, where APAs were excluded	0	We have compared the obtained results with those obtained by testing bfp <TREF>Brennan et al , 1987</TREF> and str98 <REF>Strube, 1998</REF>	1	In all tests the intrasentential anaphors have been manually resolved	0	Expletive and cataphoric uses of pronouns have been marked and excluded from the tests	0	6	1
P95-1017	P87-1022	1995	Thus, even if there exists a perfect theory, it might not work well with noisy input, or it would not cover all the anaphoric phenomena	0	1Walker <REF>Walker, 1989</REF> compares Brennan, Friedman aad Pollards centering approach <TREF>Brennan et al , 1987</TREF> with Hobbs algorithm <REF>Hohbs, 1976</REF> on a theoretical basis	1	These requirements have motivated us to develop robust, extensible, and trainable anaphora resolution systems	0	Previously <REF>Aone and McKee, 1993</REF>, we reported our data-driven multilingual anaphora resolution system, which is robust, exteusible, and manually trainable	0	6	1
W99-0108	P87-1022	1999	But, more generally, we must have a theory that is able to handle all cases of pronoun use	0	A pronoun interpretation algorithm based on centering which relied on centering transition preferences was developed in Brennan et aL 1987 Using transition preferences in a pronoun generation rule would cover more cases of pronoun use than is covered by Rule 1, but the application of such transition preferences also proved unhelpful in explaining pronoun patterns in our corpus	1	<REF>Reichman 1985</REF> and <REF>Grosz  Sidner 1986</REF> indicate that discourse segmentation has an effect on the linguistic realization of referring expressions	0	While this is intuitively appealing, it is unclear how to apply this to the generation problem in part because it is unclear how to define discourse segments to a generation system	0	6	1
P95-1040	P87-1022	1995	This distinction underlies my proposals about the attentional consequences of pitch accents when applied to pronominals, in particular, that while most pitch accents may weaken or reinforce a cospecifiers status as the center of attention, a contrastively stressed pronominal may force a shift, even when contraindicated by textual features	0	To predict and track the center of attention in discourse, theories of centering <REF>Grosz et al , 1983</REF>; <TREF>Brennan et al , 1987</TREF>; <REF>Grosz et al , 1989</REF> and immediate focus <REF>Sidner, 1986</REF> rely on syntactic and grammatical features of the text such as pronominalization and surface sentence position	1	This may be sufficient for written discourse	1	For oral discourse, however, we must also consider the way intonation affects the interpretation of a sentence, especially the cases in which it alters the predictions of centering theories	1	1	3
J99-2001	P87-1022	1999	3	0	Processing Complex Sentences: A Reason for Extending Focusing Algorithms Although complex sentences are prevalent in written English, most other local focusing research focusing: Sidner 1979 and Carter 1987; centering: Grosz, Joshi, and Weinstein 1983, 1995, Brennan, Friedman, and Pollard 1987, Walker 1989, 1993, Kameyama 1986 2, Walker, Iida, and Cote 1994, Brennan 1998, Kameyama, Passonneau, and Poesio 1993, Linson 1993 and Hoffman 1998; and PUNDIT: Dahl 1986, Palmer et al 1986, and Dahl and Ball 1990 did not explicitly and/or adequately address how to process complex sentences	1	Thus, there is a need to extend focusing algorithms	1	An exception to this rule is the work of <REF>Strube 1996</REF> which applies functionalinformation-structure-based criteria on a per-clause basis, <REF>Kameyama 1998</REF>, and <REF>Strube 1998</REF>	0	1	3
E06-3001	P87-1022	2006	Overview of the data used	0	5 Preliminary Model Overviews The models evaluated in this paper are based on Centering Theory <REF>Grosz et al , 1995</REF>; <REF>Grosz  Sidner, 1986</REF> and the algorithms devised by Brennan and colleagues 1987 and adapted by <REF>Tetreault 2001</REF>	1	We examine a language-only model based on Tetreaults Left-Right Centering LRC model, a visual-only model that uses a measure of visual salience to rank the objects in the visual field as possible referential anchors, and an integrated model that balances the visual information along with the linguistic information to generate a ranked list of possible anchors	0	51 The Language-Only Model We chose the LRC algorithm <REF>Tetreault, 2001</REF> to serve as the basis for our language-only model	0	6	1
E06-3001	P87-1022	2006	Together this work suggests that the interlocutors shared visual context has a major impact on their patterns of referring behavior	1	Yet, a number of discourse-based models of reference primarily rely on linguistic information without regard to the surrounding visual environment eg , see <TREF>Brennan et al , 1987</TREF>; <REF>Hobbs, 1978</REF>; <REF>Poesio et al , 2004</REF>; <REF>Strube, 1998</REF>; <REF>Tetreault, 2005</REF>	1	Recently, multi-modal models have emerged that integrate visual information into the resolution process	0	However, many of these models are restricted by their simplifying assumption of communication via a command language	0	1	3
P98-2143	P87-1022	1998	This preference can be explained in terms of salience from the point of view of the centering theory	0	The latter proposes the ranking subject, direct object, indirect object <TREF>Brennan et al 1987</TREF> and noun phrases which are parts of prepositional phrases are usually indirect objects	1	Collocation pattern preference This preference is given to candidates which have an identical collocation pattern with a pronoun 2,0	0	The collocation preference here is restricted to the patterns noun phrase pronoun, verb and verb, noun phrase pronoun	0	6	1
C96-2132	P87-1022	1996	Since the constraints are eflective in the lifferent target from ours, the accuracy of identifying the referents of zero pronouns would be improved much more by using both of his constraints and the constraint we proposed	0	As for the identifying method available in general discourses, the centering theory<TREF>Brennan et al , 1987</TREF>; <REF>Walker et al , 1990</REF> and the property sharing theory<REF>Kameyama, 1988</REF> are proposed	1	Although this kind of theory has a good point that it is independent of the type o17 discourse, the linguistic constraints specitic to expressions like the pragmatic constraints l/roposed by Dohsaka or us are more accurate than theirs when the speeitlc constraints are applicable	1	3 General ontology in manuals and prinmry constraints In this section, we consider the general ontology which can be used in,dl types of manuals	0	1	3
N06-2017	P87-1022	2006	S, O and X Table 1B	0	The members of the CF list are ranked according to their grammatical role <TREF>Brennan et al , 1987</TREF> and their position in the grid3 The derived sequence of CF lists can then be used to compute other important Centering concepts:  The CB, ie the referent that links the current CF list with the previous one such as microsoft in b	1	Transitions <TREF>Brennan et al , 1987</TREF> and NOCBs, that is, cases in which two subsequent CF lists do not have any referent in common	0	Violations of CHEAPNESS <REF>Strube and Hahn, 1999</REF>, COHERENCE and SALIENCE <REF>Kibble and Power, 2000</REF>	0	6	1
N06-2017	P87-1022	2006	The members of the CF list are ranked according to their grammatical role <TREF>Brennan et al , 1987</TREF> and their position in the grid3 The derived sequence of CF lists can then be used to compute other important Centering concepts:  The CB, ie the referent that links the current CF list with the previous one such as microsoft in b	0	Transitions <TREF>Brennan et al , 1987</TREF> and NOCBs, that is, cases in which two subsequent CF lists do not have any referent in common	1	Violations of CHEAPNESS <REF>Strube and Hahn, 1999</REF>, COHERENCE and SALIENCE <REF>Kibble and Power, 2000</REF>	0	22 Metrics of coherence <REF>Karamanis 2003</REF> assumes a system which receives an unordered set of CF lists as its input and uses a metric to output the highest scoring ordering	0	6	1
P04-1050	P87-1022	2004	2 <unit finitefinite-yes idu210> <ne idne410 gfsubj>144</ne> is <ne idne411 gfpredicate> a torc</ne> </unit>	0	The ranking of the CFs other than the CP is defined according to the following preference on their gf <TREF>Brennan et al , 1987</TREF>: obj>iobj>other	1	CFs with the same gf are ranked according to the linear order of the corresponding NPs in the utterance	0	The second column of Table 1 shows how the utterances in example 1 are automatically translated by the scripts developed by Poesio et al	0	6	1
P04-1050	P87-1022	2004	It is often claimed in current work on in natural language generation that the constraints on felicitous text proposed by the theory are useful to guide text structuring, in combination with other factors see <REF>Karamanis, 2003</REF> for an overview	0	However, how successful Centerings constraints are on their own in generating a felicitous text structure is an open question, already raised by the seminal papers of the theory <TREF>Brennan et al , 1987</TREF>; <REF>Grosz et al , 1995</REF>	1	In this work, we explored this question by developing an approach to text structuring purely based on Centering, in which the role of other factors is deliberately ignored	0	In accordance with recent work in the emerging field of text-to-text generation <REF>Barzilay et al , 2002</REF>; <REF>Lapata, 2003</REF>, we assume that the input to text structuring is a set of clauses	0	1	2
P04-1050	P87-1022	2004	However, in this work we are treating CF lists as an abstract representation Following again the terminology in <REF>Kibble and Power 2000</REF>, we call the requirement that CBn be the same as CBn1 the principle of coherence and the requirement that CBn be the same as CPn the principle of salience	0	Each of these principles can be satisfied or violated while their various combinations give rise to the standard transitions of Centering shown in Table 2; Poesio et als scripts compute these violations6 We also make note of the preference between these transitions, known as Centerings Rule 2 <TREF>Brennan et al , 1987</TREF>: continue is preferred to retain, which is preferred to smoothshift, which is preferred to rough-shift	1	Finally, the scripts determine whether CBn is the same as CPn1, known as the principle of cheapness <REF>Strube and Hahn, 1999</REF>	0	The last column of Table 1 shows the violations of cheapness denoted with an asterisk in 17 23 Evaluating the coherence of a text and text structuring The statistics about transitions computed as just discussed can be used to determine the degree to which a text conforms with, or violates, Centerings principles	0	6	1
P99-1079	P87-1022	1999	P99-1079:56	0	Analysis of Syntax-Based Pronoun Resolution Methods Joel R Tetreault University of Rochester Department of Computer Science Rochester, NY, 14627 tetreaulcs, rochester, edu Abstract This paper presents a pronoun resolution algorithm that adheres to the constraints and rules of Centering Theory <REF>Grosz et al , 1995</REF> and is an alternative to Brennan et als 1987 algorithm	1	The advantages of this new model, the Left-Right Centering Algorithm LRC, lie in its incremental processing of utterances and in its low computational overhead	1	The algorithm is compared with three other pronoun resolution methods: Hobbs syntax-based algorithm, Strubes S-list approach, and the BFP Centering algorithm	0	1	3
P99-1079	P87-1022	1999	The noteworthy results were that Hobbs and LRC performed the best	0	The aim of this project is to develop a pronoun resolution algorithm which performs better than the <TREF>Brennan et al 1987</TREF> algorithm 1 as a cognitive model while also performing well empirically	1	A revised algorithm Left-Right Centering was motivated by the fact that the BFP algorithm did not allow for incremental processing of an utterance and hence of its pronouns, and also by the fact that it occasionally imposes a high computational load, detracting from its psycholinguistic plausibility	1	A second motivation for the project is to remedy the dearth of empirical results on pronoun resolution methods	0	1	3
P99-1079	P87-1022	1999	5	0	Identify Transition with the Cb and Cf resolved, use the criteria from <TREF>Brennan et al , 1987</TREF> to assign the transition	1	It should be noted that BFP makes use of Centering Rule 2 <REF>Grosz et al , 1995</REF>, LRC does not use the transition generated or Rule 2 in steps 4 and 5 since Rule 2s role in pronoun resolution is not yet known see <REF>Kehler 1997</REF> for a critique of its use by BFP	0	Computational overhead is avoided since no anchors or auxiliary data structures need to be produced and filtered	0	3	2
W00-1411	P87-1022	2000	The RETAIN is motivated as it enables a cheap SMOOTH SHIFT, and so we need a way of evaluating the whole sequence CONTINUE-RETAIN-SHIFT verSUS CONTINUE-CONTINUE-SHIFT	0	: :24,:Ceaateringin :NLG CT has developed primarily in the context of natural language interpretation, focussing on anaphora resolution see eg, <TREF>Brennan et al 1987</TREF>	0	Curiously, NLG researchers have tended to overlook GJWs proposal that Rule 2 provides a constraint on speakers, and on natural-language generation systems To empirically test the claim made by Rule 2 requires examination of differences in inference load of alternative multi-utterance sequences that differentially realize the same content	0	GJW, p 215	0	6	1
W00-1411	P87-1022	2000	This is also referred to as the backward-looking center or Cb	0	The notion of salience for the purposes of centering theory is most commonly defined according to a hierarchy of grammatical roles: SUBJECT > DIRECT OBJECT > INDIRECT OBJECT > OTHERS see eg, <TREF>Brennan et al 1987</TREF> For alternative approaches see eg, <REF>Strube and Hahn 1999</REF>, <REF>Walker et al 1994</REF>	1	2	0	There is a preference for consecutive utterances within a discourse segment to keep the same entity as the center, and for the center to be realised as Subject or preferred center Cp	0	6	1
W00-1411	P87-1022	2000	Cheapness is satisfied by a transition pair Un-1, Un, Un, Unl if the preferred center of Un is the Cb of Unl For example, this test is satisfied by a RETAIN-SHIFT sequence but not by CONTINUE-SHIFT, so it is predicted that the former pattern will be used to introduce a new center	0	This claim is consistent with the findings of <REF>Brennan 1998</REF>, <TREF>Brennan et al 1987</TREF>	1	If we consider examples la-e below, the sequence cd-e , including a RETAIN-SHIFT sequence, reads more fluently than c-d-e even though the latter scores better according to the canonical ranking	0	a John has had trouble arranging his vacation	0	4	2
W04-0210	P87-1022	2004	We found that it is much easier to annotate the building blocks of a theory of the local focus, and then use scripts to automatically compute the CB	0	There are two advantages to this approach: first of all, agreement on the building blocks is much easier to reach than agreement on the CBin our preliminary experiments we didnt go beyond   6 when trying to directly identify the CB using the definitions from <TREF>Brennan et al , 1987</TREF>	1	And secondly, this approach makes it possible to compute the CB according to different ways of instantiating what we call the parameters of Centering eg , ranking	0	We developed such scripts for the work discussed in <REF>Poesio et al , 2004b</REF>; they can be tested on the web site associated with that paper, http://cswwwessexacuk/staff/poesio/ cbc/	0	6	1
J94-4002	P87-1022	1994	It uses a hierarchy of grammatical roles quite similar to that of RAP, but this role hierarchy does not directly influence antecedent selection	0	Whereas th e hierarchy in RAP contributes to a multi-dimensional measure of the relative salience of all antecedent candidates, in <TREF>Brennan et al 1987</TREF>, it is used only to constrain the choice of the backward-looking center, Cb, of an utterance	1	It does not serve as a general preference measure for antecedence	0	The items in the forward center list, Cf, are ranked according to the hierarchy of grammatical roles	0	6	1
P00-1052	P87-1022	2000	The ranking of the Cf members is determined by the salience status of the entities in the utterance and mayvary crosslinguistically	0	Kameyama 28198529 and Brennan et al 28198729 proposed that the Cf ranking for English is determined by grammatical function as follows: 28229 Rule for ranking of forward-looking centers: SUBJ3EIND	1	OBJ3EOBJ3EOTHERS Later crosslinguistic studies based on empirical work 28<REF>Di Eugenio, 1998</REF>; <REF>Turan, 1995</REF>; <REF>Kameyama, 1985</REF>29 determined the following detailed ranking, with QIS standing for quanti0Ced inde0Cnite subjects 28people, everyone etc29 and PRO-ARB 28we, you29 for arbitrary plural pronominals	0	28329Revised rule for the ranking of forward-looking centers: SUBJ3EIND	0	6	1
J90-3005	P87-1022	1990	For example, as pointed out in Bonnie Webbers Penn presentation, there is a distinction between Tree Adjunction Grammar TAG as a linguistic theory and the several algorithms that have been used to implement TAG parsers: Extended CKY parser, Extended Earley parser, Two-pass extended Earley parser based on lexicalized TAGs, and a DCG parser using lexicalized TAGs	0	There is also a distinction between Centering as a theory for resolving anaphoric pronouns <REF>Joshi and Weinstein 1981</REF>; <REF>Gross et al 1983</REF>, and the attempts to use a centering approach to resolving pronouns in an implementation <TREF>Brennan et al 1987</TREF>	1	In addition, one way of looking inside a system is to look at the performance of one or more modules or components	0	Which components are obtained depends on the nature of the decomposition of the system	0	6	1
W05-1621	P87-1022	2005	PFNOCB, a second baseline, which enhances MNOCB with a global constraint on coherence that <REF>Karamanis, 2003</REF> calls the PageFocus PF	0	PFBFP which is based on PF as well as the original formulation of CT in <TREF>Brennan et al , 1987</TREF>	1	PFKP which makes use of PF as well as the recent reformulation of CT in <REF>Kibble and Power, 2000</REF>	0	<REF>Karamanis et al , 2004</REF> report that PFNOCB outperformed MNOCB but was overtaken by PFBFP and PFKP	1	1	2
C04-1034	P87-1022	2004	The function for resolving IPAsResolveIpa has similarly been tested on texts, where APAswereexcluded	0	We have compared the obtained results with those obtained by testing bfp <TREF>Brennan et al , 1987</TREF> and str98 <REF>Strube, 1998</REF>	1	In all tests the intrasentential anaphors have been manually resolved and expletive and cataphoric uses of pronouns have been marked and excluded from the test	0	Dialogue act units were marked and classified by three annotators following <REF>Eckert and Strube, 2000</REF>	0	6	1
P04-1051	P87-1022	2004	three arguments	0	Finally, the measure MBFP <TREF>Brennan et al , 1987</TREF> uses a lexicographic ordering on 4-tuples which indicate whether the transition is a CONTINUE, RETAIN, SMOOTH-SHIFT, or ROUGHSHIFT	1	cT and all four functions it is computed from take three arguments because the classification depends on COHERENCE	0	As the first transition in the discourse is coherent by default it has no Cb, we can compute cI by distinguishing RETAIN and CONTINUE via SALIENCE	0	6	1
P04-1051	P87-1022	2004	This is in contrast to theories of global coherence, which can consider relations between larger chunks of the discourse and eg structures them into a tree <REF>Mann and Thompson, 1988</REF>; <REF>Marcu, 1997</REF>; <REF>Webber et al , 1999</REF>	0	Measures of local coherence specify which ordering of the sentences makes for the most coherent discourse, and can be based eg on Centering Theory <REF>Walker et al , 1998</REF>; <TREF>Brennan et al , 1987</TREF>; <REF>Kibble and Power, 2000</REF>; <REF>Karamanis and Manurung, 2002</REF> or on statistical models <REF>Lapata, 2003</REF>	1	But while formal models of local coherence have made substantial progress over the past few years, the question of how to efficiently compute an ordering of the sentences in a discourse that maximises local coherence is still largely unsolved	1	The fundamental problem is that any of the factorial number of permutations of the sentences could be the optimal discourse, which makes for a formidable search space for nontrivial discourses	1	1	3
P04-1051	P87-1022	2004	Based on these concepts, CT classifies the transitions between subsequent utterances into different types	0	Table 1 shows the most common classification into the four types CONTINUE, RETAIN, SMOOTH-SHIFT, and ROUGH-SHIFT, which are predicted to be less and less coherent in this order <TREF>Brennan et al , 1987</TREF>	1	<REF>Kibble and Power 2000</REF> define three further classes of transitions: COHERENCE and SALIENCE, which are both defined in Table 1 as well, and NOCB, the class of transitions for which Cbui is undefined	0	Finally, a transition is considered to satisfy the CHEAPNESS constraint <REF>Strube and Hahn, 1999</REF> if Cbui  Cpui1	0	6	1
W06-1665	P89-1010	2006	One more filtering criterion is mutual information MI, which reflects the relatedness of two terms in their combination , kj ww  To keep a relation  kji wwwP, we require , kj ww be a meaningful combination	0	We use the following pointwise MI <TREF>Church and Hanks 1989</TREF>:  ,log, kj kj kj wPwP wwPwwMI  We only keep meaningful combinations such that 0, >kj wwMI  By these filtering criteria, we are able to reduce considerably the number of biterms and triterms	1	For example, on a collection of about 200MB, with a vocabulary size of about 148K, we selected only about 27M useful biterms and about 137M triterms, which remain tractable	0	33 Probability of Biterms In LM used in IR, each query term is attributed the same weight	0	3	2
W02-0606	P89-1010	2002	33 Scoring the semantic similarity of word pairs Measuring the semantic similarity of words on the basis of raw corpus data is obviously a much harder task than measuring the orthographic similarity of words	0	Mutual information first introduced to computational linguistics by <TREF>Church and Hanks 1989</TREF> is one of many measures that seems to be roughly correlated to the degree of semantic relatedness between words	1	The mutual information between two words A and B is given by: IA;B  log PrA;BPrAPrB 1 Intuitively, the larger the deviation between the empirical frequency of co-occurrence of two words and the expected frequency of co-occurrence if they were independent, the more likely it is that the occurrence of one of the two words is not independent from the occurrence of the other	0	Brown et alii 1990 observed that when mutual information is computed in a bi-directional fashion, and by counting co-occurrences of words within a 4Most of the pairs in this block  78  are actually morphologically related	0	6	1
W99-0610	P89-1010	1999	2In the case of an interrupted collocation, words can be separated by an arbitrary number of words, whereas 71 sin:e,:hey assumed that a collocation is a se-,lun:e of adjacent words that frequently apl:,ar tgether	0	<TREF>Church and Hanks, 1989</TREF> delhw:I ;t collocation as a pair of correlated words :mi,,set mutual information to evaluate such ,xi:a,1 :orrelations of word pairs of length two	1	They retrieved interrupted word pairs, as well as,minterrupted word pairs	0	<REF>Haruno et al , 1996</REF>,:onstructed collocations by combining adjacent n-grams with high value of mutual information	0	6	1
J04-2002	P89-1010	2004	Because of their low ambiguity and high specificity, these words are also particularly useful for conceptualizing a knowledge domain or for supporting the creation of a domain ontology	0	Candidate terminological expressions are usually captured with more or less shallow techniques, ranging from stochastic methods <TREF>Church and Hanks 1989</TREF>; <REF>Yamamoto and Church 2001</REF> to more sophisticated syntactic approaches <REF>Jacquemin 1997</REF>	1	155 Navigli and Velardi Learning Domain Ontologies WordNet domain corpus contrastive corpora terminology extraction candidate extraction terminology filtering semantic interpretation semantic disambiguation identification of taxonomic relations identification of conceptual relations Inductive learner Natural Language Processor ontology integration and updating 3 2 1 Lexical Resources Domain Concept Forest Figure 3 The architecture of OntoLearn	0	Obviously, richer syntactic information positively influences the quality of the result to be input to the statistical filtering	0	6	1
J95-1001	P89-1010	1995	Afterward, if a target adjective sense was not resolved, semantic indicator attributes were applied; no individual indicator nouns were used	0	The semantic attributes that were applied were animate, body part, color, concrete, human, and text type; <TREF>Church and Hanks 1989</TREF> had pointed to two of these attributes, person and body part also time, previously mentioned above in a seemingly casual listing of just five attributes potentially useful for describing the lexico-syntactic regularities of noun-verb relations	1	Table 1 shows that these few, general attributes cover almost three-quarters of all instances of the target adjectives	0	Disambiguation by these syntactic and semantic attributes is effectively as reliable as disambiguation using significant indicator nouns: having three apparent errors in disambiguation is not significantly worse than the errorless performance of the significant indicator nouns in the 100-sentence samples	0	4	2
J95-1001	P89-1010	1995	Content words that have a close syntactic relation to one another are useful candidates for examination and are intuitively more likely to bear a close semantic relation than words that are near one another but are not related syntactically	0	One much-studied example is the semantic relation between a verb and its arguments eg , <REF>Boguraev et al 1989</REF>; <TREF>Church and Hanks 1989</TREF>; Braden-<REF>Harder 1991</REF>; <REF>Hindle and Rooth 1991</REF>	0	Discrimination among senses of adjectives based on the nouns they modify or of which they are predicated has been the subject of less intensive and systematic study	0	Determining the potential of this line of evidence is the focus of this paper	1	5	2
P06-1005	P89-1010	2006	Like path coreference, semantic compatibility can be considered a form of world knowledge needed for more challenging pronoun resolution instances	0	We encode the semantic compatibility between a noun and its parse tree parent and grammatical relationship with the parent using mutual information MI <TREF>Church and Hanks, 1989</TREF>	1	Suppose we are determining whether ham is a suitable antecedent for the pronoun it in eat it	0	We calculate the MI as: MIeat:obj, ham  log Preat:obj:hamPreat:objPrham Although semantic compatibility is usually only computed for possessive-noun, subject-verb, and verb-object relationships, we include 121 different kinds of syntactic relationships as parsed in our news corpus3 We collected 488 billion parent:rel:node triples, including over 327 million possessive-noun values, 129 billion subject-verb and 877 million verb-direct object	0	3	2
H90-1055	P89-1010	1990	This line of research was motivated by a series of successful applications of mutual information statistics to other problems in natural language processing	0	In the last decade, research in speech recognition <REF>Jelinek 1985</REF>, noun classification <REF>Hindle 1988</REF>, predicate argument relations <TREF>Church  Hanks 1989</TREF>, and other areas have shown that mutual information statistics provide a wealth of information for solving these problems	1	22 Mutual Information Statistics The mutual information statistic <REF>Fano 1961</REF> is a measure of the interdependence of two signals in a message	0	It is a function of the probabilities of the two events: Mz, u  log u xzPvy In this paper, the events x and y will be part-of-speech n-grams instead of single parts-of-speech, as in some earlier work	0	6	2
C08-1051	P89-1010	2008	The idea behind it is that similar words tend to co-occur in certain patterns	0	Considerable efforts have been devoted to measure word similarity based on cooccurrence frequency of two words in a window <TREF>Church and Hanks, 1989</TREF>; <REF>Turney, 2001</REF>; <REF>Terra and Clarke, 2003</REF>; <REF>Matsuo et al, 2006</REF>	1	In addition to the classical window-based technique, some studies investigated the use of lexico-syntactic patterns eg, X or Y to get more accurate co-occurrence statistics <REF>Chilovski and Pantel, 2004</REF>; <REF>Bollegala et al, 2007</REF>	0	These two approaches are complementary with each other, because they are founded on different hypotheses and utilize different corpus statistics	0	6	1
J91-1001	P89-1010	1991	For example, Wilks et al	0	1989 use this ratio as a criterion for establishing links between words in a semantic network; <TREF>Church and Hanks 1989</TREF> use the logarithm of this ratio as a measure for word association	1	14 Justeson and Katz Co-occurrences of Antonymous Adjectives Under this formulation of the co-occurrence theory, acquiring the lexical relation of antonymy requires a certain amount of training for the association, and as the frequency of adjectives declines, so must the frequency of training for its associations	0	On the whole, then, very infrequent training should result in weaker associations; more generally, adjective frequency should correlate with the strength of lexical associations	0	6	1
P99-1067	P89-1010	1999	In the past, for this purpose a number of measures have been proposed	0	They were based on mutual information <TREF>Church  Hanks, 1989</TREF>, conditional probabilities <REF>Rapp, 1996</REF>, or on some standard statistical tests, such as the chi-square test or the loglikelihood ratio <REF>Dunning, 1993</REF>	0	For the purpose of this paper, we decided to use the loglikelihood ratio, which is theoretically well justified and more appropriate for sparse data than chi-square	1	In preliminary experiments it also led to slightly better results than the conditional probability measure	0	1	3
P01-1025	P89-1010	2001	Finally, methods and strategies for handling low-frequency data are suggested	0	The measures2  Mutual Information a0a2a1  <TREF>Church and Hanks, 1989</TREF>, the log-likelihood ratio test <REF>Dunning, 1993</REF>, two statistical tests: t-test and a3a5a4 -test, and co-occurrence frequency  are applied to two sets of data: adjective-noun AdjN pairs and preposition-noun-verb PNV triples, where the AMs are applied to PN,V pairs	1	See section 3 for a description of the base data	0	For evaluation of the association measures, a6 -best strategies section 41 are supplemented with precision and recall graphs section 42 over the complete data sets	0	3	2
W95-0105	P89-1010	1995	6 Probabifities were estimated using the Penn Treebank version of the Brown corpus	0	The pairs come from an example given by <TREF>Church and Hanks 1989</TREF>, illustrating the words that human subjects most frequently judged as being associated with the word doctor	1	The word sick also appeared on the list, but is excluded here because it is not a noun	0	Word 1 Word 2 doctor nurse doctor lawyer doctor man doctor medicine doctor hospital doctor health doctor sickness Similarity Most Informative Subsumer 94823 health professional 72240 professional person 29683 person, individual 10105 <entity 10105 <entity 00 virtual root 00 virtual root Doctors are minimally similar to medicine and hospitals, since these things are all instances of something having concrete existence, riving or nonliving WordNet class ent ty, but they are much more similar to lawyers, since both are kinds of professional people, and even more similar to nurses, since both are professional people working specifically within the health professions	0	6	1
C08-1086	P89-1010	2008	By no means an exhaustive list, the most commonly cited ranking and scoring algorithms are HITS <REF>Kleinberg 1998</REF> and PageRank <REF>Page et al 1998</REF>, which rank hyperlinked documents using the concepts of hubs and authorities	0	The most well-known keyword scoring methods within the IR community are the tf-idf <REF>Salton and McGill 1983</REF> and pointwise mutual information <TREF>Church and Hanks 1989</TREF> measures, which put more importance on matching keywords that occur frequently in a document relative to the total number of documents that contain the keyword by normalizing term frequencies with inverse document frequencies	1	Various methods including tf-idf have been comparatively evaluated by <REF>Salton and Buckley 1987</REF>	0	Creating nbest lists using the above algorithms produce result sets where each result is considered independently	0	6	1
C08-1086	P89-1010	2008	41 EIIR: Expected Independent Information Ranking Model Baseline Model Recall the task definition from Section 3	0	Finding a property r that most reduces the uncertainty in a query set Q can be modeled by measuring the strength of association between r and Q <REF>Following Pantel and Lin 2002</REF>, we use pointwise mutual information pmi to measure the association strength between two events q and r, where q is a term in Q and r is syntactic dependency, as follows <TREF>Church and Hanks 1989</TREF>:      N fqc N rwc N rqc Ff Ww rqpmi       , , , log,  41 where cq,r is the frequency of r in the feature vector of q as defined in Section 32, W is the set of all words in our corpus, F is the set of all syntactic dependencies in our corpus, and N   WwFf fwc , is the total frequency count of all features of all words	0	We estimate the association strength between a property r and a set of terms Q by taking the expected pmi between r and each term in Q as:       Qq rqpmiqPrQpmi ,,  42 where Pq is the probability of q in the corpus	1	Finally, the EIIR model chooses an n-best list by selecting the n properties from R that have highest pmiQ, r	0	3	2
E06-1050	P89-1010	2006	32 Contexts The context in which a word appears often imposesconstraintsonthesemantictypeoftheword	0	This basic idea has been exploited by many proposals for distributional similarity and clustering, eg, <TREF>Church and Hanks, 1989</TREF>; <REF>Lin, 1998</REF>; <REF>Pereira et al , 1993</REF>	1	Similar to <REF>Lin and Pantel 2001</REF>, we define the contexts of a word to be the undirected paths in dependency trees involving that word at either the beginning or the end	0	The following diagram shows an example dependency tree: Which city hosted the 1988 Winter Olympics	0	6	1
P02-1053	P89-1010	2002	RB, RBR, or RBS VB, VBD, VBN, or VBG anything The second step is to estimate the semantic orientation of the extracted phrases, using the PMI-IR algorithm	0	This algorithm uses mutual information as a measure of the strength of semantic association between two words <TREF>Church  Hanks, 1989</TREF>	1	PMI-IR has been empirically evaluated using 80 synonym test questions from the Test of English as a Foreign Language TOEFL, obtaining a score of 74 <REF>Turney, 2001</REF>	0	For comparison, Latent Semantic Analysis LSA, another statistical measure of word association, attains a score of 64 on the 3 http://wwwcsjhuedu/brill/RBT114tarZ 4 <REF>See Santorini 1995</REF> for a complete description of the tags	0	3	2
P02-1053	P89-1010	2002	same 80 TOEFL questions <REF>Landauer  Dumais, 1997</REF>	0	The Pointwise Mutual Information PMI between two words, word1 and word2, is defined as follows <TREF>Church  Hanks, 1989</TREF>: pword1  word2 PMIword1, word2  log2 pword1 pword2 1 Here, pword1  word2 is the probability that word1 and word2 co-occur	1	If the words are statistically independent, then the probability that they co-occur is given by the product pword1 pword2	0	The ratio between pword1  word2 and pword1 pword2 is thus a measure of the degree of statistical dependence between the words	0	6	1
C00-1084	P89-1010	2000	Thus we introduce d-bigram which is a bigram cooccurrence information concerning the distance<REF>Tsutsumi et al , 1993</REF>	0	Expression 1 calculates the score between two neighboring letters; UKi  E E Mwj,wid;d  x,qd 1 dl j-i--d--1 where wl as an eveN;, d as the distance between two eveN;s, dmax as the maximum distance used in the processing we set drnax - 5, and gd as the weight fimction on distance for this system gd  d-2<REF>Sano et al , 1996</REF>, to decrease tile influence of tile d-bigrams when the distance get longer <TREF>Church and Hanks, 1989</TREF>	1	When calculating the linking score between the letters wi and Wil, tile d-bigram information of the letter pairs around tim target two such as wi-l, wi2; 3 are added	0	Expression 2 calculates the mutual information between two events with d-bigram data; v; d d -2 where x, y as events, d for the distance between two events, and Px as the probability	0	3	2
C96-2099	P89-1010	1996	Linking Score Expression 2 is tbr calculating the linking score between two letters in a sentence 	0	Z 2 d:-:l ji-d-1 dmax : max distance used wl : the i-th letter in the sentence w gd : a certain weight for iV// concerning distance between letters The information between two remote words has less nmaning in a sentence when it comes to the semantic analysis<TREF>Church and Hanks, 1989</TREF>	1	According to the idea we put gd in the expression so that nearer pair can be more effective in calculating the score of the sentence	0	 hi,, I I I--1 B C  F G H Figure 3: Calculation of Linking Score A pair of far-away letters do not have strong relation between each other, neither syntactically nor semantically	0	6	1
P06-2111	P89-1010	2006	Word alignments that are shared by many different words are most probably mismatches	0	For this experiment we used Pointwise Mutual Information I <TREF>Church and Hanks, 1989</TREF>	1	IW, f  log PW, fPWPf,where W is the target word PW is the probability of seeing the word Pf is the probability of seeing the feature PW,f is the probability of seeing the word and the feature together	0	33 Word Alignment The multilingual approach we are proposing relies on automatic word alignment of parallel corpora from Dutch to one or more target languages	0	3	2
D07-1086	P89-1010	2007	For statistical features, previous work Section 2 suggests that the mutual information between the decision tokens xL0 and xR0 may be appropriate	0	The log of the pointwise mutual information <TREF>Church and Hanks, 1989</TREF> between the decision-boundary tokens xL0, xR0 is: MIxL0, xR0  log PrxL0xR0Prx L0PrxR0 This is equivalent to the sum: log CxL0xR0  log K log CxL0 log CxR0	1	For web-based features, the counts C	0	can be taken as a search engines count of the number of pages containing the term	0	6	1
C00-2104	P89-1010	2000	Tile focus of much of this work was to develop the methods themselves	0	<TREF>Church and Hanks 1989</TREF> explored tile use of mutual information statistics in ranking co-occurrences within five-word windows	1	<REF>Smadja 1992</REF> gathered co-occurrences within fiveword windows to find collocations, particularly in specific domains	0	<REF>Hindle 1990</REF> classified nouns on the basis of co-occurring patterns of subjectverb and verb-object pairs	0	6	1
C94-2202	P89-1010	1994	Collocations have been studied by computational linguists in different contexts	0	For instance, there is a substantial body of papers on the extraction of frequently co-occurring words from corpora using statistical methods eg , <REF>Choueka et al , 1983</REF>, <TREF>Church and Hanks, 1989</TREF>, <REF>Smadja, 1993</REF> to list only a few	1	These authors focus on techniques for providing material that can be used in other processing tasks such as x The research rcpmlcd in this paper was undmtaken as the project Collocations and the Lexicalisation of Semantic Operations ET10/75	0	Financial contributions weir by the Commission of the European Community, Association Suissetra Geneva and Oxford University Press	0	6	1
H05-1113	P89-1010	2005	Hence, greater the frequency, the more is the likelihood of the expression to be a MWE	0	612 Point-wise Mutual Information a16  Point-wise Mutual information of a collocation <TREF>Church and Hanks, 1989</TREF> is defined as, a16a18a17a19a11a21a20a23a22a25a24a27a26 a15a28a17a19a11a2a20a23a22a25a24a30a29a31a15a28a17a33a32a34a20a35a32a36a24 a15a28a17a19a11a2a20a35a32a36a24a30a29a37a15a28a17a33a32a34a20a23a22a25a24 where, a11 is the verb and a22 is the object of the collocation	1	The higher the Mutual information of a collocation, the more is the likelihood of the expression to be a MWE	0	613 Least mutual information difference with similar collocations a38  This feature is based on Lins work <REF>Lin, 1999</REF>	0	3	2
H05-1113	P89-1010	2005	Various statistical measures have been suggested for ranking expressions based on their compositionality	0	Some of these are Frequency, Mutual Information <TREF>Church and Hanks, 1989</TREF>, distributed frequency of object <REF>Tapanainen et al , 1998</REF> and LSA model <REF>Baldwin et al , 2003</REF> <REF>Schutze, 1998</REF>	0	In this paper, we define novel measures both collocation based and context based measures to measure the relative compositionality of MWEs of V-N type see section 6 for details	1	Integrating these statistical measures should provide better evidence for ranking the expressions	0	5	2
H05-1113	P89-1010	2005	These ranks are then compared with the human ranking	0	<REF>Breidt, 1995</REF> has evaluated the usefulness of the Point-wise Mutual Information measure as suggested by <TREF>Church and Hanks, 1989</TREF> for the extraction of V-N collocations from German text corpora	1	Several other measures like Log-Likelihood <REF>Dunning, 1993</REF>, Pearsons a2a4a3 <REF>Church et al , 1991</REF></REF>, Z-Score <REF>Church et al , 1991</REF></REF>, Cubic Association Ratio MI3, etc , have been also proposed	0	These measures try to quantify the association of two words but do not talk about quantifying the non-compositionality of MWEs	0	6	1
N07-1028	P89-1010	2007	However, the focus was more on balancing the effect of query expansion techniques such that different concepts in the query were equally benefited	0	Mutual information has been used previously in <TREF>Church and Hanks, 1989</TREF> to identify collocations of terms for identifying semantic relationships in text	1	Experiments were confined to bigrams	0	The use of MaST over a graph of mutual information values to incorporate the most significant dependencies between terms was first noted in <REF>Rijsbergen, 1979</REF>	0	6	1
N07-1028	P89-1010	2007	Mutual Information is attractive because it is not only easy to compute, but also takes into consideration corpus statistics and semantics	0	The mutual information between two terms <TREF>Church and Hanks, 1989</TREF> can be calculated using Equation 2	0	Ix,y  log nx,y N nx N ny N 2 nx,y is the number of times terms x and y occurred within a term window of 100 terms across the corpus, while nx and ny are the frequencies of x and y in the collection of size N terms	0	To tackle the situation where we have an arbitrary number of variables terms we extend the twovariable case to the multivariate case	1	3	2
H89-2012	P89-1010	1989	1	0	Mutual <REF>Information Church and Hanks 1989</REF> discussed the use of the mutual information statistic in order to identify a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type content word/content word to lexico-syntacfic co-occurrence constraints between verbs and prepositions content word/function word	1	Mutual information, lx;y, compares the probability of observing word x and word y together the joint probability with the probabilities of observing x and y independently chance	0	lx;y - log 2 Px,y ex ey If there is a genuine association between x and y, then the joint probability Px,y will he much larger than chance Px Py, and consequently lx;y >> 0, as illustrated in the table below	0	6	1
H89-2012	P89-1010	1989	75 Some Interesting Associations with Doctor in the 1987 AP Corpus N  15 million; w  6 Ix; y fx y fx x fly Y 2	0	Phrasal Verbs 80 24 111 honorary 621 doctor 80 16 1105 doctors 44 dentists 84 60 1105 doctors 241 nurses 71 16 1105 doctors 154 treating 67 12 275 examined 621 doctor 66 12 1105 doctors 317 treat 64 50 621 doctor 1407 bills 64 12 621 doctor 350 visits 63 38 1105 doctors 676 hospitals 61 12 241 nurses 1105 doctors Associations with Doctor Some Less Interesting -13 12 621 doctor 73785 with -14 82 284690 a 1105 doctors 14 24 84716 is 1105 doctors <TREF>Church and Hanks 1989</TREF> also used the mutual information statistic in order to identify phrasal verbs, following up a remark by Sinclair: How common are the phrasal verbs with set	1	Set is particularly rich in making combinations with words like about, in, up, out, on, off, and these words are themselves very common	0	How likely is set off to occur	0	6	1
W93-0309	P89-1010	1993	Extraction of V-N-Collocations from Text Corpora: A Feasibility Study for German Elisabeth Breidt Seminar fiir Sprachwissenschaft University of Tiibingen Kleine Wilhelmstr	0	113, D-72074 Tiibingen breidtarbucklesnsneuphilologieuni-tuebingende Abstract The usefulness of a statistical approach suggested by <TREF>Church and Hanks 1989</TREF> is evaluated for the extraction of verb-noun V-N collocations from German text corpora	1	Some motivations for the extraction of V-N collocations from corpora are given and a couple of differences concerning the German language are mentioned that have implications on the applicability of extraction methods developed for English	0	We present precision and recall results for V-N collocations with support verbs and discuss the consequences for further work on the extraction of collocations from German corpora	0	3	1
W93-0309	P89-1010	1993	Collocations present an area that is important both for lexicography to improve their coverage in modern dictionaries as well as for lexical acquisition in computational linguistics, where the goal is to build either large reusable lexical databases LDBs or specific lexica for specialized NLP-applications	0	We have tested the statistical approach Mutual Information MI, brought up by <TREF>Church and Hanks 1989</TREF> for linguistics, for a semiautomatic extraction of verb-noun V-N collocations from untagged German text corpora	1	We try to answer the question how much can be done with an untagged corpus and what might be gained by lemmatizing, POS-tagging or even superficial parsing	0	<REF>Choueka 1988</REF> describes how to automatically extract word combinations from English corpora as a preselection of collocation candidates to ease a lexicographers search for collocations	0	3	1
W06-1204	P89-1010	2006	AER  MergePos 054 045 049 05101  MergeMI 055 045 050 05045 Table 6: Results using the compositionality based features pressions of various types	1	Some of them are Frequency, Point-wise mutual information <TREF>Church and Hanks, 1989</TREF>, Distributed frequency of object <REF>Tapanainen et al , 1998</REF>, Distributed frequency of object using verb information <REF>Venkatapathy and Joshi, 2005</REF></REF>, Similarity of object in verbobject pair using the LSA model <REF>Baldwin et al , 2003</REF>, <REF>Venkatapathy and Joshi, 2005</REF></REF> and Lexical and Syntactic fixedness <REF>Fazly and Stevenson, 2006</REF>	0	These features have largely been evaluated by the correlation of the compositionality value predicted by these measures with the gold standard value suggested by human judges	0	It has been shown that the correlation of these measures is higher than simple baseline measures suggesting that these measures represent compositionality quite well	0	3	2
W06-1204	P89-1010	2006	In the past, various measures have been suggested for measuring the compositionality of multi-word expressions	0	Some of these are mutual information <TREF>Church and Hanks, 1989</TREF>, distributed frequency <REF>Tapanainen et al , 1998</REF> and Latent Semantic Analysis LSA model <REF>Baldwin et al , 2003</REF>	0	Even though, these measures have been shown to represent compositionality quite well, compositionality itself has not been shown to be useful in any application yet	1	In this paper, we explore this possibility of using the information about compositionality of MWEs verb based for the word alignment task	0	1	2
D07-1053	P89-1010	2007	Our main aim is here to investigate the use of long-distance semantic dependencies to dynamically adapt the prediction to the current semantic context of communication	0	Similar work has been done by <REF>Li and Hirst 2005</REF> and <REF>Matiasek and Baroni 2003</REF>, who exploit Pointwise Mutual Information PMI; <TREF>Church and Hanks, 1989</TREF>	1	Trnka et al	0	2005 dynamically interpolate a high number of topic-oriented models in order to adapt their predictions to the current topic of the text or conversation	0	6	1
P90-1034	P89-1010	1990	More is to be learned from the fact that you can drink wine than from the fact that you can drink it even though there are more clauses in our sample with  as an object of drink than with wine	0	To capture this intuition, we turn, following <TREF>Church and Hanks 1989</TREF>, to mutual information see <REF>Fano 1961</REF>	1	The mutual information of two events lx y is defined as follows: Px y lxy  log2 Px Py where Px y is the joint probability of events x and y, and Px and Py axe the respective independent probabilities	0	When the joint probability Px y is high relative to the product of the independent probabilities, I is positive; when the joint probability is relatively low, I is negative	0	3	2
W05-1207	P89-1010	2005	The aim of this measure is to indicate the relatedness between two elements composing a pair	0	Mutual information has been positively used in many NLP tasks such as collocation analysis <TREF>Church and Hanks, 1989</TREF>, terminology extraction <REF>Damerau, 1993</REF>, and word sense disambiguation <REF>Brown et al , 1991</REF>	1	3 Experimental Evaluation As many other corpus linguistic approaches, our entailment detection model relies partially on some linguistic prior knowledge the expected structure of the searched collocations, ie, the textual entailment patterns and partially on some probability distribution estimation	0	Only a positive combination of both these two ingredients can give good results when applying and evaluating the model	0	1	2
J93-1007	P89-1010	1993	In the first stage, pairwise lexical relations are retrieved using only statistical information	0	This stage is comparable to <TREF>Church and Hanks 1989</TREF> in that it evaluates a certain word association between pairs of words	1	As in <TREF>Church and Hanks 1989</TREF>, the words can appear in any order and they can be separated by an arbitrary number of other words	0	However, the statistics we use provide more information and allow us to have more precision in our output	0	2	2
J93-1007	P89-1010	1993	Example sentences containing the two words in the two possible positions are:  The provision is aimed at making a hostile takeover prohibitively expensive by enabling Borg Warners stockholders to buy the The pill would make a takeover attempt more expensive by allowing the retailers shareholders to buy more company stock Let us note that this filtering method is an original contribution of our work	0	Other works such as <TREF>Church and Hanks 1989</TREF> simply focus on an evaluation of the correlation of appearance of a pair of words, which is roughly equivalent to condition C1	1	See next section	0	However, taking note of their pattern of appearance allows us to filter out more irrelevant collocations with C2 and C3	0	2	1
J93-1007	P89-1010	1993	Finally, at a more general level, although disambiguation was originally considered as a performance task, the collocations retrieved have not been used for any specific computational task	0	<TREF>Church and Hanks 1989</TREF> describe a different set of techniques to retrieve collocations	1	A collocation as defined in their work is a pair of correlated words	0	That is, a collocation is a pair of words that appear together more often than expected	0	6	1
J93-1007	P89-1010	1993	Collocations in the lexicographic meaning are only dealt with in the lexical approach	0	Aside from the work we present in this paper, most of the work carried out within the lexical approach has been done in computer-assisted lexicography by <REF>Choueka, Klein, and Neuwitz 1983</REF> and Church and his colleagues <TREF>Church and Hanks 1989</TREF>	0	Both works attempted to automatically acquire true collocations from corpora	1	Our work builds on Chouekas, and has been developed contemporarily to Churchs	0	2	1
J93-1007	P89-1010	1993	This stage is comparable to <TREF>Church and Hanks 1989</TREF> in that it evaluates a certain word association between pairs of words	1	As in <TREF>Church and Hanks 1989</TREF>, the words can appear in any order and they can be separated by an arbitrary number of other words	0	However, the statistics we use provide more information and allow us to have more precision in our output	0	The output of this first stage is then passed in parallel to the next two stages	0	2	3
J93-1007	P89-1010	1993	This limitation is intrinsic to the technique used since mutual information scores are defined for two items	0	The second limitation is that many collocations identified in <TREF>Church and Hanks 1989</TREF> do not really identify true collocations, but simply pairs of words that frequently appear together such as the pairs doctor-nurse, doctor-bill, doctor-honorary, doctors-dentists, doctors-hospitals, etc These co-occurrences are mostly due to semantic reasons	1	The two words are used in the same context because they are of related meanings; they are not part of a single collocational construct	0	The work we describe in the rest of this paper is along the same lines of research	0	1	3
J93-1007	P89-1010	1993	The two words are often used together because they are associated with the same context rather than for pure structural reasons	0	Many collocations retrieved in <TREF>Church and Hanks 1989</TREF> were of this type, as they retrieved doctors-dentists, doctors-nurses, doctorbills, doctors-hospitals, nurses-doctor, etc , which are not collocations in the sense defined above	1	Such collocations are not of interest for our purpose, although they could be useful for disambiguation or other semantic purposes	0	Condition C2 filters out exactly this type of collocations	0	1	3
J93-1002	P89-1010	1993	In this case, we are interested in collocations between the head of a PP complement, a preposition and the head of the phrase being postmodified	0	In general, these words will not be adjacent in the text, so it will not be possible to use existing approaches unmodified eg <TREF>Church and Hanks 1989</TREF>, because these apply to adjacent words in unanalyzed text	1	<REF>Hindle and Rooth 1991</REF> report good results using a mutual information measure of collocation applied within such a structurally defined context, and their approach should carry over to our framework straightforwardly	0	One way of integrating structural collocational information into the system presented above would be to make use of the semantic component of the ANLT grammar This component pairs logical forms with each distinct syntactic analysis that represent, among other things, the predicate-argument structure of the input	0	1	3
H05-1058	P89-1010	2005	Finally, we write the conditional probability as a function of : Pci  1jsi1,si  11  n1    n where   PH1P H0  Psi1,siPs i1Psi  Psijsi1Ps i The conditional probability, Pci  1jsi1,si is a mapping g from  2 0,1 to p 2 0, 1	0	Beginning with <TREF>Church and Hanks, 1989</TREF>, numerous authors have used the pointwise mutual information between pairs of words to analyze word co-locations and associations	1	This ratio tells us whether si1 and si co-occur more or less often than would be expected by chance alone	0	Consider, for example, the tags DT determiner and NN noun, and the four possible ordered tagpairs	0	6	1
P05-1077	P89-1010	2005	Since we use grammatical context, the feature set is considerably larger than the simple word based proximity feature set for the newspaper corpus	0	43 Calculating Feature Vectors Having collected all nouns and their features, we now proceed to construct feature vectors and values for nouns from both corpora using mutual information <TREF>Church and Hanks, 1989</TREF>	1	We first construct a frequency count vector Ce  ce1,ce2,,cek, where k is the total number of features and cef is the frequency count of feature f occurring in word e Here, cef is the number of times word e occurred in context f We then construct a mutual information vector MIe  mie1,mie2,,miek for each word e, where mief is the pointwise mutual information between word e and feature f, which is defined as: mief  log cef Nsummationtext n i1 cif N  summationtextk j1 cej N 6 where n is the number of words and N  5We perform this operation so that we can compare the performance of our system to that of <REF>Pantel and Lin 2002</REF>	0	summationtextn i1 summationtextm j1 cij is the total frequency count of all features of all words	0	3	2
P04-3025	P89-1010	2004	The SO of a phrase is determined based upon the phrases pointwise mutual information PMI with the words excellent and poor	0	PMI is defined by <TREF>Church and Hanks 1989</TREF> as follows: a0a2a1a4a3a6a5a8a7a10a9a12a11a13a7a15a14a17a16a19a18a21a20a23a22a25a24 a14a27a26a29a28 a5a8a7a10a9a19a30a31a7a15a14a17a16 a28 a5a8a7 a9 a16 a28 a5a8a7 a14 a16a33a32 1 where a28 a5a8a7a10a9a19a30a31a7a15a14a12a16 is the probability that a7a34a9 and a7a35a14 co-occur	0	The SO for a a28a37a36a39a38a41a40a29a42a44a43 is the difference between its PMI with the word excellent and its PMI with the word poor The method used to derive these values takes advantage of the possibility of using the World Wide Web as a corpus, similarly to work such as <REF>Keller and Lapata, 2003</REF>	0	The probabilities are estimated by querying the AltaVista Advanced Search engine1 for counts	1	3	2
W97-1004	P89-1010	1997	To solve the problem, we make use of a kind of cooperative evolution strategy to design an evolutionary algorithm	0	Word compositions have long been a concern in lexicography<REF>Benson et al 1986</REF></REF>; <REF>Miller et al 1995</REF>, and now as a specific kind of lexical knowledge, it has been shown that they have an important role in many areas in natural language processing, eg, parsing, generation, lexicon building, word sense disambiguation, and information retrieving, etceg , <REF>Abney 1989, 1990</REF>; <REF>Benson et al 1986</REF></REF>; <REF>Yarowsky 1995</REF>; <TREF>Church and Hanks 1989</TREF>; Church, <REF>Gale, Hans, and Hindle 1989</REF>	1	But due to the huge number of words, it is impossible to list all compositions between words by hand in dictionaries	0	So an urgent problem occurs: how to automatically acquire word compositions	0	5	2
W97-1004	P89-1010	1997	While bound compositions are not predictable, ie, their reasonableness cannot be derived from the syntactic and semantic properties of the words in them<REF>Smadja 1993</REF>	0	Now with the availability of large-scale corpus, automatic acquisition of word compositions, especially word collocations from them have been extensively studiedeg , <REF>Choueka et al 1988</REF>; <TREF>Church and Hanks 1989</TREF>; <REF>Smadja 1993</REF>	0	The key of their methods is to make use of some statistical means, eg, frequencies or mutual information, to quantify the compositional strength between words	0	These methods are more appropriate for retrieving bound compositions, while less appropriate for retrieving free ones	1	1	3
I05-1049	P89-1010	2005	The classifier can also be used to rank these vectors according to their relative compositionality	0	3 Related <REF>Work Church and Hanks 1989</REF> proposed a measure of association called Mutual Information 9	1	Mutual Information MI is the logarithm of the ratio between the probability of the two words occurring together and the product of the probability of each word occurring individually	0	The higher the MI, the more likely are the words to be associated with each other	0	6	1
P93-1032	P89-1010	1993	Dictionaries produced by hand always substantially lag real language use	0	The last two points do not argue against the use of existing dictionaries, but show that the incomplete information that they provide needs to be supplemented with further knowledge that is best collected automatically The desire to combine hand-coded and automatically learned knowledge 1A point made by <TREF>Church and Hanks 1989</TREF>	1	Arbitrary gaps in listing can be smoothed with a program such as the work presented here	0	For example, among the 27 verbs that most commonly cooccurred with from, Church and Hanks found 7 for which this 235 suggests that we should aim for a high precision learner even at some cost in coverage, and that is the approach adopted here	0	4	2
D07-1115	P89-1010	2007	They are estimated by using Table 2	0	C8B4CRCYD4D3D7B5 BP CUB4CRBND4D3D7B5 CUB4CRBND4D3D7B5B7CUB4BMCRBND4D3D7B5 C8B4CRCYD2CTCVB5 BP CUB4CRBND2CTCVB5 CUB4CRBND2CTCVB5B7CUB4BMCRBND2CTCVB5 PMI based polarity value Using PMI, the strength of association between CR and positive sentences and negative sentences is defined as follows <TREF>Church and Hanks, 1989</TREF>	1	C8C5C1B4CRBND4D3D7B5 BP D0D3CV BE C8B4CRBND4D3D7B5 C8B4CRB5C8B4D4D3D7B5 C8C5C1B4CRBND2CTCVB5 BP D0D3CV BE C8B4CRBND2CTCVB5 C8B4CRB5C8B4D2CTCVB5 PMI based polarity value is defined as their difference	0	This idea is the same as <REF>Turney, 2002</REF>	0	3	2
W05-1202	P89-1010	2005	The reason for choosing this measure is that it can be used to compute the distance between any two co-occurrence vectors independent of any information about other words	0	This is in contrast to many other measures, eg, <REF>Lin 1998</REF>, which use the co-occurrences of features with other words to compute a weighting function such as mutual information MI <TREF>Church and Hanks, 1989</TREF>	1	Since we only have corpus data for the target phrases, it is not possible for us to use such a measure	0	However, the -skew divergence measure has been shown <REF>Weeds, 2003</REF> to perform comparably with measures which use MI, particularly for lower frequency target words	0	6	1
I08-1038	P89-1010	2008	If the absolute value of the relative distance in a sentence for a feature and an opinion word is less than Minimum-Offset, they are considered contextdependent	0	Many methods have been proposed to measure the co-occurrence relation between two words such as  2 Church and Mercer,1993 , mutual information <TREF>Church and Hanks, 1989</TREF></TREF>; <REF>Pantel and Lin, 2002</REF>, t-test <TREF>Church and Hanks, 1989</TREF></TREF>, and loglikelihood Dunning,1993	0	In this paper a revised formula of mutual information is used to measure the association since mutual information of a lowfrequency word pair tends to be very high	1	Table 1 gives the contingency table for two words or phrases w 1  and  w 2 , where A is the number of reviews where w 1  and w 2  co-occur; B indicates the number of reviews where w 1  occurs but does not co-occur with w 2 ; C denotes the number of reviews where w 2  occurs but does not co-occur with w 1 ; D is number of reviews where neither w 1  nor w 2  occurs; N  A  B  C  D With the table, the revised formula of mutual information is designed to calculate the association of w 1 with w 2  as formula 1	0	5	2
W04-0412	P89-1010	2004	Other types of phrases	0	Many efficient techniques exist to extract multiword expressions, collocations, lexical units and idioms <TREF>Church and Hanks, 1989</TREF>; <REF>Smadja, 1993</REF>; <REF>Dias et al , 2000</REF>; <REF>Dias, 2003</REF>	1	Unfortunately, very few have been applied to information retrieval with a deep evaluation of the results	0	Maximal Frequent Sequences	0	1	2
I05-3009	P89-1010	2005	An inter-domain entropy IDE measure will be proposed for this purpose	0	2 Conventional Clustering View for Constructing Lexicon Trees One conventional way to construct the lexicon hierarchy from web corpora is to collect the terms in all web documents and measure the degree of word association between word pairs using some well-known association metrics <TREF>Church and Hanks, 1989</TREF>; <REF>Smadja et al , 1996</REF> as the distance measure	1	Terms of high association are then clustered bottom-up using some clustering techniques to build the hierarchy	0	The clustered hierarchy is then submitted to lexicographers to assign a semantic label to each sub-cluster	0	6	1
P06-1107	P89-1010	2006	The definition can be easily extended to a set of expressions T Given a pair vt and vh we define the following entailment strength indicator Svt,vh	0	Specifically, the measure Snomvt,vh is derived from point-wise mutual information <TREF>Church and Hanks, 1989</TREF>: Snomvt,vh  log pvt,vhnompv tpvhpers 3 where nom is the event of having a nominalized textual entailment pattern and pers is the event of having an agentive nominalization of verbs	1	Probabilities are estimated using maximum-likelihood: pvt,vhnom  fCPnomvt,vhf C uniontextP nomvprimet,vprimeh, 852 pvt  fCFvt/fCuniontextFv, and pvhpers  fCFagentvh/fCuniontextFagentv	0	Counts are considered useful when they are greater or equal to 3	0	3	2
N04-1041	P89-1010	2004	We then construct a mutual information vector MIe  mi e1, mi e2, , mi em  for each word e, where mi ef is the pointwise mutual information between word e and feature f, which is defined as: N c N c N c ef m j ej n i if ef mi       1 1 log 1 where n is the number of words and N    n i m j ij c 11 is the total frequency count of all features of all words	1	Mutual information is commonly used to measure the association strength between two words <TREF>Church and Hanks 1989</TREF>	0	A well-known problem is that mutual information is biased towards infrequent elements/features	0	We therefore multiply mi ef with the following discounting factor: 1,min,min 1 11 11                        m j jf n i ei m j jf n i ei ef ef cc cc c c 2 32 Phase II Following <REF>Pantel and Lin 2002</REF>, we construct a committee for each semantic class	0	3	2
J94-4003	P90-1034	1994	This is the basis for Sadlers Analogical Semantics <REF>Sadler 1989</REF>, which according to his report has not proved effective	0	His results may be improved if more sophisticated methods and larger corpora are used to establish similarity between words such as in <TREF>Hindle 1990</TREF>	1	In particular, an enhancement of our disambiguation method, using similarity-based estimation <REF>Dagan, Marcus, and Markovitch 1993</REF>, was evaluated recently	0	In this evaluation the applicability of the disambiguation method was increased by 15, with only a slight decrease in the precision	0	6	1
J94-4003	P90-1034	1994	 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 4 knowledge can be found in the use of statistical data on the occurrence of lexical relations in large corpora eg , <REF>Grishman, Hirschman, and Nhan 1986</REF>	0	The use of such relations mainly relations between verbs or nouns and their arguments and modifiers for various purposes has received growing attention in recent research <REF>Church and Hanks 1990</REF>; <REF>Zernik and Jacobs 1990</REF>; <TREF>Hindle 1990</TREF>; <REF>Smadja 1993</REF>	1	More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment <REF>Hindle and Rooth 1991</REF> and pronoun references <REF>Dagan and Itai 1990, 1991</REF>	0	Clearly, statistics on lexical relations can also be useful for target word selection	0	6	1
J94-4003	P90-1034	1994	The use of such relations mainly relations between verbs or nouns and their arguments and modifiers for various purposes has received growing attention in recent research <REF>Church and Hanks 1990</REF>; <REF>Zernik and Jacobs 1990</REF>; <TREF>Hindle 1990</TREF>; <REF>Smadja 1993</REF>	0	More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment <REF>Hindle and Rooth 1991</REF> and pronoun references <REF>Dagan and Itai 1990, 1991</REF>	1	Clearly, statistics on lexical relations can also be useful for target word selection	0	Consider, for example, the Hebrew sentence extracted from the foreign news section of the daily Ha-<REF>Aretz, September 1990</REF> transcripted to Latin letters: 1 Nose ze mana mi-shtei ha-mdinot mi-lahtom al hoze shalom	0	6	1
P06-1100	P90-1034	2006	We present an empirical evaluation on the task of attaching partof and causation relations, showing an improvement on F-score over a baseline model	0	NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts <REF>Etzioni et al 2005</REF>, semantic lexicons <REF>Riloff and Shepherd 1997</REF>, concept lists <REF>Lin and Pantel 2002</REF>, and word similarity lists <TREF>Hindle 1990</TREF>	1	Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments <REF>Szpektor et al 2004</REF>, is-a <REF>Ravichandran and Hovy 2002</REF>, part-of <REF>Girju et al 2003</REF>, and other relations	0	The output of most of these systems is flat lists of lexical semantic knowledge such as Italy is-a country and orange similar-to blue	0	6	1
C04-1116	P90-1034	2004	There have been many approachs to automatic detection of similar words from text	0	Our method is similar to <TREF>Hindle, 1990</TREF>, <REF>Lin, 1998</REF>, and <REF>Gasperin, 2001</REF> in the use of dependency relationships as the word features	1	Another approach used the words distribution to cluster the words <REF>Pereira, 1993</REF>, and Inoue <REF>Inoue, 1991</REF> also used the word distributional information in the Japanese-English word pairs to resolve the polysemous word problem	0	Wu <REF>Wu, 2003</REF> shows one approach to collect synonymous collocation by using translation information	0	5	1
C04-1116	P90-1034	2004	3 http:// wwwcisupennedu/ treebank/ rank candidate 1 batt 2 batterie 3 bat 4 BTBTBTBT cover 5 BTY 6 batterry 7 BT BT BT BT BT BT BT BT BT BT adapter 8 bezel 9 BT BT BT BT BT BT BT BT BT BT cheque 10 BTBTBTBT screw Table 3: batterys Synonymous Expression Candidates from the Entire Corpus Author A rank candidate 1 battery 2 controller 3 BT BT BT BT BT BT BT BT Cover 4 APM 5 BTBTBTBT screw 6 mark 7 BT BT BT BT BT BT BT BT BT BT cheque 8 diskette 9 checkmark 10 boot Author B rank candidate 1 batt 2 form 3 protector 4 DISKETTE 5 Mwave 6 BT BT BT BT BT BT BT BT BT BT adapter 7 mouse 8 BT BT BT BT BT BT BT BT BT BT cheque 9 checkmark 10 process Table 4: Noise Candidates from Each Authors Corpus word	0	The words we want to aggregate for text analysis are not rigorous synonyms, but the role is the same, so we have to consider the syntactic relation based on the assumptions that words with the same role tend to modify or be modified by similar words <TREF>Hindle, 1990</TREF>; <REF>Strzalkowski, 1992</REF>	1	On the other hand, window-based techniques are not suitable for our data, because the documents are written by several authors who have a variety of different writing styles eg selecting different prepositions and articles	0	Therefore we consider only syntactic features: dependency pairs, which consist of nouns, verbs, and their relationships	0	6	1
P06-1102	P90-1034	2006	All digits in both patterns and sentences are replaced with a common marker, such 810 that any two numerical values with the same number of digits will overlap during matching	0	Many methods have been proposed to compute distributional similarity between words, eg, <TREF>Hindle, 1990</TREF>, <REF>Pereira et al , 1993</REF>, <REF>Grefenstette, 1994</REF> and <REF>Lin, 1998</REF>	1	Almost all of the methods represent a word by a feature vector, where each feature corresponds to a type of context in which the word appeared	0	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed	0	6	1
C08-1051	P90-1034	2008	et al, 1999; <REF>Torisawa, 2002</REF>	0	Others proposed distributional similarity measures between words <TREF>Hindle, 1990</TREF>; <REF>Lin, 1998</REF>; <REF>Lee, 1999</REF>; <REF>Weeds et al, 2004</REF>	1	Once such similarity is defined, it is trivial to perform clustering	0	On the other hand, some researchers utilized co-occurrence for word clustering	0	6	1
C94-1074	P90-1034	1994	In fact, corpus linguistics became a popular research field because of the claim that shallow techniques could overcome the lexical coverage bottleneck of traditional NLP techniques	0	Among the applications of collocational analysis for lexical acquisition are: the derivation of syntactic disambiguation cues <REF>Basili et al 1991, 1993a</REF>; <REF>Hindle and Rooths 1991</REF>,1993; <REF>Sekine 1992</REF> <REF>Bogges et al 1992</REF>, sense preference <REF>Yarowski 1992</REF>, acquisition of selectional restrictions <REF>Basili et al 1992b, 1993b</REF>; <REF>Utsuro et al 1993</REF>, lexical preference in generation <REF>Smadjia 1991</REF>, word clustering <REF>Pereira 1993</REF>; <TREF>Hindle 1990</TREF>; <REF>Basili et al 1993c</REF>, etc In the majority of these papers, even though the precedent or subsequent statistical processing reduces the number of accidental associations, very large corpora 10,000,000 words are necessary to obtain reliable data on a large enough number of words	1	In addition, most papers produce a performance evaluation of their methods but do not provide a measure of the coverage, ie the percentage of cases for which their method actually provides a right or wrong solution	0	It is quite common that results are discussed only for 10-20 cases	0	1	3
W05-1516	P90-1034	2005	This is known as the Distributional Hypothesis in linguistics <REF>Harris, 1968</REF>	0	For example, the words test and exam are similar because both of them follow verbs such as administer, cancel, cheat on, conduct,  and both of them can be preceded by adjectives such as academic, comprehensive, diagnostic, difficult,  Many methods have been proposed to compute distributional similarity between words <TREF>Hindle, 1990</TREF>; <REF>Pereira et al , 1993</REF>; <REF>Grefenstette, 1994</REF>; <REF>Lin, 1998</REF>	1	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared	0	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed	0	6	1
W06-2904	P90-1034	2006	This is known as the Distributional Hypothesis in linguistics <REF>Harris, 1968</REF>	0	For example, the words test and exam are similar because both of them can follow verbs such as administer, cancel, cheat on, conduct, etc Many methods have been proposed to compute distributional similarity between words, eg, <TREF>Hindle, 1990</TREF>; <REF>Pereira et al , 1993</REF>; <REF>Grefenstette, 1994</REF>; <REF>Lin, 1998</REF>	1	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared	0	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed	0	6	1
P08-2008	P90-1034	2008	<REF>Schutze 1998</REF> used bag-of-words contexts for sense discrimination	0	<TREF>Hindle 1990</TREF> grouped nouns into thesaurus-like lists based on the similarity of their syntactic contexts	0	Our approach is similar with the difference that we do not group noun arguments into finite categories, but instead leave the category boundaries blurry and allow overlaps	1	The DDNs are essentially a form of world knowledge which we extract automatically and apply to VSD	0	5	1
P93-1022	P90-1034	1993	or the cooccurrence of two words within a limited distance in the context	0	Statistical data about these various cooccurrence relations is employed for a variety of applications, such as speech recognition <REF>Jelinek, 1990</REF>, language generation <REF>Smadja and McKeown, 1990</REF>, lexicography <REF>Church and Hanks, 1990</REF>, machine translation Brown et al , ; <REF>Sadler, 1989</REF>, information retrieval <REF>Maarek and Smadja, 1989</REF> and various disambiguation tasks <REF>Dagan et al , 1991</REF>; <REF>Hindle and Rooth, 1991</REF>; <REF>Grishman et al , 1986</REF>; <REF>Dagan and Itai, 1990</REF>	0	A major problem for the above applications is how to estimate the probability of cooccurrences that were not observed in the training corpus	1	Due to data sparseness in unrestricted language, the aggregate probability of such cooccurrences is large and can easily get to 25 or more, even for a very large training corpus <REF>Church and Mercer, 1992</REF>	0	1	3
P93-1022	P90-1034	1993	To account for this problem we developed a simple heuristic that searches for words that are potentially similar to w, using thresholds on mutual information values and frequencies of cooccurrence pairs	0	The search is based on the property that when computing simwl, w2, words that have high mutual information values 5The nominator in our metric resembles the similarity metric in <TREF>Hindle, 1990</TREF>	1	We found, however, that the difference between the two metrics is important, because the denominator serves as a normalization factor	0	with both wl and w2 make the largest contributions to the value of the similarity measure	0	2	1
P98-1082	P90-1034	1998	Semantic variation is rarely studied in specialized domains	0	Works on word similarity and word sense disambiguation are generally based on statistical methods designed for large or even very large corpora <TREF>Hindle, 1990</TREF>; <REF>Agirre and Rigau, 1996</REF>	0	Therefore, they cannot be applied for technical documents which usually are medium size corpora	1	However, dealing with already linguistic filtered data, <REF>Assadi, 1997</REF> aims at statistically build rough clusters supposing that similar candidate terms have similar expansions	0	1	3
W02-1107	P90-1034	2002	We applied both a neural network model and a linguistic method, that is syntactic information, to a large corpora and extracted necessary information	0	To extract semantic information of words such as synonyms and antonyms from corpora, previous research used syntactic structures <TREF>Hindle 1990</TREF>, <REF>Hatzivassiloglou 1993</REF> and <REF>Tokunaga 1995</REF>, response time to associate synonyms and antonyms in psychological experiments <REF>Gross 1989</REF>, or extracting related words automatically from corpora <REF>Grefensette 1994</REF>	1	Most lexical classification is based on parts of speech, as they have very important semantic information	0	For examples, typically, an adjective refers to an attribute, a verb refers to a motion or an event, and a noun refers to an object	0	6	1
P91-1027	P90-1034	1991	3 RELATED WORK Interest in extracting lexical and especially collocational information from text has risen dramatically in the last two years, as sufficiently large corpora and sufficiently cheap computation have become available	0	Three recent papers in this area are <REF>Church and Hanks 1990</REF>, <TREF>Hindle 1990</TREF>, and <REF>Smadja and McKeown 1990</REF>	1	The latter two are concerned exclusively with collocation relations between open-class words and not with grammatical properties	0	Church is also interested primarily in open-class collocations, but he does discuss verbs that tend to be followed by infinitives within his mutual information framework	0	6	1
P07-1057	P90-1034	2007	Following the idea proposed in Harris Distributional Hypothesis <REF>Harris, 1985</REF>, that words occurring in similar contexts are semantically similar, many works have used different definitions of context to identify various types of semantic similarity	0	<TREF>Hindle 1990</TREF> uses a mutual-information based metric derived from the distribution of subject, verb and object in a large corpus to classify nouns	1	Pereira et al	0	1993 cluster nouns according to their distribution as direct objects of verbs, using information-theoretic tools the predecessors of the tools we use in this work	0	6	1
P08-3001	P90-1034	2008	Distributional similarity represents the relatedness of two words by the commonality of contexts the words share, based on the distributional hypothesis <REF>Harris, 1985</REF>, which states that semantically similar words share similar contexts	0	A number of researches which utilized distributional similarity have been conducted, including <TREF>Hindle, 1990</TREF>; <REF>Lin, 1998</REF>; <REF>Geffet and Dagan, 2004</REF> and many others	0	Although they have been successful in acquiring related words, various parameters such as similarity measures and weighting are involved	1	As Weeds et al	0	1	3
P06-1101	P90-1034	2006	In our experiments we set   095	0	32 m,n-cousin Classification The classifier for learning coordinate terms relies on the notion of distributional similarity, ie, the idea that two words with similar meanings will be used in similar contexts <TREF>Hindle, 1990</TREF>	0	We extend this notion to suggest that words with similar meanings should be near each other in a semantic taxonomy, and in particular will likely share a hypernym as a near parent	1	Our classifier for m,n-cousins is derived from the algorithm and corpus given in <REF>Ravichandran et al , 2005</REF>	0	5	1
P97-1066	P90-1034	1997	We agree with the differential definition of semantics : the meaning of the morpho-lexical units is not defined by reference to a concept, but rather by contrast with other units <REF>Rastier et al , 1994</REF>	0	In fact, we are considering word usage rather than word meanin <REF>Zernik, 1990</REF> following in this the distributional point of view, see <REF>Harris, 1968</REF>, <TREF>Hindle, 1990</TREF>	1	Statistical or probabilistic methods are often used to extract semantic clusters from corpora in order to build lexical resources for ANLP tools <TREF>Hindle, 1990</TREF>, <REF>Zernik, 1990</REF>, <REF>Resnik, 1993</REF>, or for automatic thesaurus generation <REF>Grefenstette, 1994</REF>	0	We use similar techniques, enriched by a preliminaxy morpho-syntaztic analysis, in order to perform knowledge acquisition and modeling for a specific task eg : electrical network planning	0	6	1
P97-1066	P90-1034	1997	In fact, we are considering word usage rather than word meanin <REF>Zernik, 1990</REF> following in this the distributional point of view, see <REF>Harris, 1968</REF>, <TREF>Hindle, 1990</TREF>	0	Statistical or probabilistic methods are often used to extract semantic clusters from corpora in order to build lexical resources for ANLP tools <TREF>Hindle, 1990</TREF>, <REF>Zernik, 1990</REF>, <REF>Resnik, 1993</REF>, or for automatic thesaurus generation <REF>Grefenstette, 1994</REF>	1	We use similar techniques, enriched by a preliminaxy morpho-syntaztic analysis, in order to perform knowledge acquisition and modeling for a specific task eg : electrical network planning	0	Moreover, we are dealing with language for specific purpose texts and not with general texts	0	3	1
P08-1002	P90-1034	2008	Our approach avoids hand-crafting a set of spe11 ci c indicator features; we simply use the distribution of the pronouns context	0	Our method is thus related to previous work based on <REF>Harris 1985</REF>s distributional hypothesis2 It has been used to determine both word and syntactic path similarity <TREF>Hindle, 1990</TREF>; <REF>Lin, 1998a</REF>; <REF>Lin and Pantel, 2001</REF>	1	Our work is part of a trend of extracting other important information from statistical distributions	0	<REF>Dagan and Itai 1990</REF> use the distribution of a pronouns context to determine which candidate antecedents can  t the context	0	5	1
P05-1016	P90-1034	2005	The hypothesis states that words that occur in the same contexts tend to have similar meaning	0	Researchers have mostly looked at representing words by their surrounding words <REF>Lund and Burgess 1996</REF> and by their syntactical contexts <TREF>Hindle 1990</TREF>; <REF>Lin 1998</REF>	0	However, these representations do not distinguish between the different senses of words	1	Our framework utilizes these principles and representations to induce disambiguated feature vectors	0	1	3
W05-1504	P90-1034	2005	2a	0	If the bound is too tight to allow the correct parse of some sentence, we would still like to allow an accurate partial parse: a sequence of accurate parse fragments <TREF>Hindle, 1990</TREF>; <REF>Abney, 1991</REF>; <REF>Appelt et al , 1993</REF>; <REF>Chen, 1995</REF>; <REF>Grefenstette, 1996</REF>	1	Furthermore, we would like to use the fact that some fragment sequences are presumably more likely than others	0	Our partial parses will look like the one in Fig	0	6	1
C00-2104	P90-1034	2000	<REF>Smadja 1992</REF> gathered co-occurrences within fiveword windows to find collocations, particularly in specific domains	0	<TREF>Hindle 1990</TREF> classified nouns on the basis of co-occurring patterns of subjectverb and verb-object pairs	1	<REF>Hatzivassiloglou and MeKeown 1993</REF> clustered adjectives into semantic classes, and Pereira et al	0	1993 clustered nouns on their appearance ill verb-object pairs	0	6	1
C04-1111	P90-1034	2004	Also, the patterns are learned with the specific goal of scaling to the terascale see Table 2	0	22 Co-occurrence-based approaches The second class of algorithms uses cooccurrence statistics <TREF>Hindle 1990</TREF>, <REF>Lin 1998</REF>	1	These systems mostly employ clustering algorithms to group words according to their meanings in text	0	Assuming the distributional hypothesis <REF>Harris 1985</REF>, words that occur in similar grammatical contexts are similar in meaning	0	6	1
C96-1083	P90-1034	1996	4 Towards an adequate similarity esfimatation for the building of ontologies The comparison with the similarity score of <TREF>Hindle, 1990</TREF> shows that SYCLADE similarity indicator is specifically relevant for ontology bootstrap and tuning	0	Hindle uses the observed frequencies within a specific syntactic pattern subject/verb, and verb/object to derive a cooccu,> rence score which is an estimate of mutual information <REF>Church and Hanks, 1990</REF>	0	We adapted this score to noun phrase patterns However the similarity measures based on cooccurrence scores and nominal phrase patterns are less relevant for an ontological analysis	1	The subgraph of the chirurgical acts words, which is easy to identify from the SYCLADE graph fig	0	5	1
C96-1083	P90-1034	1996	Automatic exploration of a sublanguage corpus constitutes a first step towards identifying the semantic classes and relationships which are relevant for this sublanguage	0	In the past five years, important research on the automatic acquisition of word classes based on lexical distribution has been published <REF>Church and Hanks, 1990</REF>; <TREF>Hindle, 1990</TREF>; <REF>Smadja, 1993</REF>; Greinstette, 1994; <REF>Grishman and Sterling, 1994</REF>	0	Most of these approaches, however, need large or even very large corpora in order for word classes to be discovered 1 whereas it is often the case that the data to be processed are insufficient to provide reliable lexical intbrmation	1	In other words, it is not always possible to resort to statistical methods	0	1	3
C96-1083	P90-1034	1996	2 Simplifying parse trees to classify words 21 The need for normalized syntactic contexts As Hindles work proves it, among others <REF>Grishman and Sterling, 1994</REF>; <REF>Grefenstette, 1994</REF>:, the mere existence of robust syntactic parsers makes it possible to parse large corpora in order to automate the discovery of syntactic patterns in the spirit of Harriss distributional hypothesis	0	Itowever, Harris methodology implies also to simplify and transform each parse tree 2, so as to obtain so-called elementary sentences exhibiting the main conceptual classes for the domain Sager lIaor instance, Hindle <TREF>Hindle, 1990</TREF> needs a six million word corpus in order to extract noun similarities from predicate-argunlent structures	1	2Changing passive into active sentences, using a verb instead of a nominalization, and so on	0	490 NP NPa AP4 I I Nr As I I stenose serre NPo PP2 Pa NP6 I de D9 NPlo le NPll AP12 t NPla AP14 A15 I I I N Ar gauche I I tronc eorninun Iigure 1: Parse tree for stenose serre de le hone commun gauche et al , 1987	0	6	1
W98-0704	P90-1034	1998	Although Stairmand <REF>Stairmand, 1997</REF> and Richardson <REF>Richardson and Smeaton, 1995</REF> have proposed the use of WordNet in information retrieval, they did not used WordNet in the query expansion framework	0	Our predicate-argument structure-based thesatmis is based on the method proposed by Hindie <TREF>Hindle, 1990</TREF>, although Hindle did not apply it to information retrieval	1	Instead, he used mutual information statistics as a Similarity coefficient, wheras we used the Dice coefficient for normalization purposes	0	Hindle only extracted the subject-verb and the object-verb predicatearguments, while we also extract adjective-noun predicate-arguments	1	2	1
P06-1045	P90-1034	2006	Among many kinds of lexical relations, synonyms are especially useful ones, having broad range of applications such as query expansion technique in information retrieval and automatic thesaurus construction	0	Various methods <TREF>Hindle, 1990</TREF>; <REF>Lin, 1998</REF>; <REF>Hagiwara et al , 2005</REF> have been proposed for synonym acquisition	0	Most of the acquisition methods are based on distributional hypothesis <REF>Harris, 1985</REF>, which states that semantically similar words share similar contexts, and it has been experimentally shown considerably plausible	0	However, whereas many methods which adopt the hypothesis are based on contextual clues concerning words, and there has been much consideration on the language models such as Latent Semantic Indexing <REF>Deerwester et al , 1990</REF> and Probabilistic LSI <REF>Hofmann, 1999</REF> and synonym acquisition method, almost no attention has been paid to what kind of categories of contextual information, or their combinations, are useful for word featuring in terms of synonym acquisition	1	1	3
P06-1045	P90-1034	2006	However, whereas many methods which adopt the hypothesis are based on contextual clues concerning words, and there has been much consideration on the language models such as Latent Semantic Indexing <REF>Deerwester et al , 1990</REF> and Probabilistic LSI <REF>Hofmann, 1999</REF> and synonym acquisition method, almost no attention has been paid to what kind of categories of contextual information, or their combinations, are useful for word featuring in terms of synonym acquisition	0	For example, <TREF>Hindle 1990</TREF> used cooccurrences between verbs and their subjects and objects, and proposed a similarity metric based on mutual information, but no exploration concerning the effectiveness of other kinds of word relationship is provided, although it is extendable to any kinds of contextual information	1	<REF>Lin 1998</REF> also proposed an information theorybased similarity metric, using a broad-coverage parser and extracting wider range of grammatical relationship including modifications, but he didnt further investigate what kind of relationships actually had important contributions to acquisition, either	0	The selection of useful contextual information is considered to have a critical impact on the performance of synonym acquisition	0	6	1
J93-2005	P90-1034	1993	Some of our initial data suggest that the hypothesis of deep semantic selection may in fact be correct, as well as indicating what the nature of the coercion rules may be	0	Using techniques described in <REF>Church and Hindle 1990</REF>, <REF>Church and Hanks 1990</REF>, and <REF>Hindle and Rooth 1991</REF>, Figure 4 shows some examples of the most frequent V-O pairs from the AP corpus	1	Corpus studies confirm similar results for weakly intensional contexts such as the complement of coercive verbs such as veto	0	These are interesting because regardless of the noun type appearing as complement, it is embedded within a semantic interpretation of the proposal to, thereby clothing the complement within an intensional context	0	6	1
J93-2005	P90-1034	1993	Unfortunately, noun compounds are also employed to express numerous other relationships, as in Unix kernel and C debugger	0	We have found, however, that collocational evidence can be employed to suggest which noun compounds reflect taxonomic relationships, using a strategy similar to that employed by <TREF>Hindle 1990</TREF> for detecting synonyms	0	Given a term T, we extract from the phrase database those nouns Ni that appear as the head of any phrase in which T is the immediately preceding term	0	These nouns represent candidate classes of which T may be a member	0	0	0
J93-2005	P90-1034	1993	While full automatic extraction of semantic collocations is not yet feasible, some recent research in related areas is promising	0	<TREF>Hindle 1990</TREF> reports interesting results of this kind based on literal collocations, where he parses the corpus <REF>Hindle 1983</REF> into predicate-argument structures and applies a mutual information measure <REF>Fano 1961</REF>; <REF>Magerman and Marcus 1990</REF> to weigh the association between the predicate and each of its arguments	1	For example, as a list of the most frequent objects for the verb drink in his corpus, Hindle found beer, tea, Pepsi, and champagne	0	Based on the distributional hypothesis that the degree of shared contexts is a similarity measure for words, he develops a similarity metric for nouns based on their substitutability in certain verb contexts	0	6	1
E99-1013	P90-1034	1999	<REF>Although Stairmand 1997</REF> and <REF>Richardson 1995</REF> proposed the use of WordNet in information retrieval, they did not use WordNet in the query expansion framework	0	Our syntactic-relation-based thesaurus is based on the method proposed by <TREF>Hindle 1990</TREF>, although Hindle did not apply it to information retrieval	1	Hindle only extracted subject-verb and object-verb relations, while we also extract adjective-noun and noun-noun relations, in the manner of <REF>Grefenstette 1994</REF>, who applied his 99 Proceedings of EACL 99 Table 3: Average non-interpolated precision for expansion using single or combined thesauri	0	Topic Type Base Title 01175 Description 01428 All 01976 Expanded with WordNet Roget Syntac Cooccur Combined only only only only method 01276 01236 01386 01457 02314 86 52  179 240 969 01509 0,1477 01648 01693 02645 57 34 154 185 852 02010 01999 02131 02191 02724 17 12 78 108 378 syntactically-based thesaurus to information retrieval with mixed results	0	5	1
E99-1013	P90-1034	1999	232 Syntactically-based Thesaurus In contrast to the previous section, this method attempts to gather term relations on the basis of linguistic relations and not document cooccurrence statistics	0	Words appearing in similax grammatical contexts are assumed to be similar, and therefore classified into the same class <REF>Lin, 1998</REF>; <REF>Grefenstette, 1994</REF>; <REF>Grefenstette, 1992</REF>; <REF>Ruge, 1992</REF>; <TREF>Hindle, 1990</TREF>	1	First, all the documents are parsed using the Apple Pie Parser	0	The Apple Pie Parser is a natural language syntactic analyzer developed by Satoshi Sekine at New York University <REF>Sekine and Grishman, 1995</REF>	0	6	1
P93-1024	P90-1034	1993	The problemis that for large enough corpora the number of possible joint events is much larger than the number of event occurrences in the corpus, so many events are seen rarely or never, making their frequency counts unreliable estimates of their probabilities	0	<TREF>Hindle 1990</TREF> proposed dealing with the sparseness problem by estimating the likelihood of unseen events from that of similar events that have been seen	1	For instance, one may estimate the likelihood of a particular direct object for a verb from the likelihoods of that direct object for similar verbs	0	This requires a reasonable definition of verb similarity and a similarity estimation method	0	6	1
P06-1015	P90-1034	2006	With seemingly endless amounts of textual data at our disposal, we have a tremendous opportunity to automatically grow semantic term banks and ontological resources	0	To date, researchers have harvested, with varying success, several resources, including concept lists <REF>Lin and Pantel 2002</REF>, topic signatures <REF>Lin and Hovy 2000</REF>, facts <REF>Etzioni et al 2005</REF>, and word similarity lists <TREF>Hindle 1990</TREF>	1	Many recent efforts have also focused on extracting semantic relations between entities, such as entailments <REF>Szpektor et al 2004</REF>, is-a <REF>Ravichandran and Hovy 2002</REF>, part-of <REF>Girju et al 2006</REF>, and other relations	0	The following desiderata outline the properties of an ideal relation harvesting algorithm:  Performance: it must generate both high precision and high recall relation instances;  Minimal supervision: it must require little or no human annotation;  Breadth: it must be applicable to varying corpus sizes and domains; and  Generality: it must be applicable to a wide variety of relations ie , not just is-a or part-of	0	6	1
J04-3002	P90-1034	2004	We are not aware of other work that uses such collocations as we do	0	Features identified using distributional similarity have previously been used for syntactic and semantic disambiguation <TREF>Hindle 1990</TREF>; <REF>Dagan, Pereira, and Lee 1994</REF> and to develop lexical resources from corpora <REF>Lin 1998</REF>; <REF>Riloff and Jones 1999</REF>	1	We are not aware of other work identifying and using density parameters as described in this article	0	Since our experiments, other related work in NLP has been performed	0	6	1
C04-1036	P90-1034	2004	Typical feature weighting functions include the logarithm of the frequency of word-feature cooccurrence <REF>Ruge, 1992</REF>, and the conditional probability of the feature given the word within probabilistic-based measures <REF>Pereira et al , 1993</REF>, <REF>Lee, 1997</REF>, <REF>Dagan et al , 1999</REF>	0	Probably the most widely used association weight function is point-wise Mutual Information MI <REF>Church et al , 1990</REF>, <TREF>Hindle, 1990</TREF>, <REF>Lin, 1998</REF>, <REF>Dagan, 2000</REF>, defined by:  ,log, 2 fPwP fwPfwMI  A known weakness of MI is its tendency to assign high weights for rare features	1	Yet, similarity measures that utilize MI showed good performance	0	In particular, a common practice is to filter out features by minimal frequency and weight thresholds	0	1	3
C04-1036	P90-1034	2004	Finally, a novel feature weighting and selection function is presented, which yields superior feature vectors and better word similarity performance	0	Distributional Similarity has been an active research area for more than a decade <TREF>Hindle, 1990</TREF>, <REF>Ruge, 1992</REF>, <REF>Grefenstette, 1994</REF>, <REF>Lee, 1997</REF>, <REF>Lin, 1998</REF>, <REF>Dagan et al , 1999</REF>, <REF>Weeds and Weir, 2003</REF>	1	Inspired by Harris distributional hypothesis <REF>Harris, 1968</REF>, similarity measures compare a pair of weighted feature vectors that characterize two words	0	Features typically correspond to other words that co-occur with the characterized word in the same context	0	6	1
P07-1028	P90-1034	2007	Let Seenrp be the set of seen headwords for an argument rp of a predicate p Then we model the selectional preference S of rp for a possible headword w0 as a weighted sum of the similarities between w0 and the seen headwords: Srpw0  summationdisplay wSeenrp simw0,wwtrpw simw0,w is the similarity between the seen and the potential headword, and wtrpw is the weight of seen headword w Similarity simw0,w will be computed on the generalization corpus, again on the basis of extracted tuples p,rp,w	0	We will be using the similarity metrics shown in Table 1: Cosine, the Dice and Jaccard coefficients, and <TREF>Hindles 1990</TREF> and <REF>Lins 1998</REF> mutual information-based metrics	1	We write f for frequency, I for mutual information, and Rw for the set of arguments rp for which w occurs as a headword	0	In this paper we only study corpus-based metrics	0	3	1
W97-0205	P90-1034	1997	Computing MI scores is by now a standard procedure for measuring the co-occurrence between objects relative to their overall occurrence	0	MI is defined in general as follows: y I ix y  log2 Px Py We can use this definition to derive an estimate of the connectedness between words, in terms of collocations <REF>Smadja, 1993</REF>, but also in terms of phrases and grammatical relations <TREF>Hindle, 1990</TREF>	1	For instance the co-occurrence of verbs and the heads of their NP objects iN: size of the corpus, ie the number of stems: N Cobj v n  log2 /v /n N N All nouns are now classified by running a similaxity measure over their MI scores and the MI scores of each CoRELEx class	0	For this we use the Jaccard measure that compares objects relative to the attributes they share <REF>Grefenstette, 1994</REF>	0	6	1
C98-2122	P90-1034	1998	Evaluation of automatically generated lexical resources is a difficult problem	0	In <TREF>Hindle, 1990</TREF>, a small set of sample results are presented	1	In <REF>Smadja, 1993</REF>, automatically extracted collocations are judged by a lexicographer	0	In <REF>Dagan et al, 1993</REF> and <REF>Pereira et al, 1993</REF>, clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time	0	6	1
C98-2122	P90-1034	1998	We also constructed several other thesauri using the same corpus, but with the similarity measures in Figure 1	0	The measure simHindle is the same as the similarity measure proposed in <REF>Hindie, 1990</REF>, except that it does not use dependency triples with negative mutual information	1	The measure simHindle r is the same as simHindle except that all types of dependency relationships are used, instead of just subject and object relationships	0	The measures simcosine, simdice and simJacard are versions of similarity measures commonly used in information retrieval Frakes and Baeza-<REF>Yates, 1992</REF>	0	3	1
C98-2122	P90-1034	1998	and Conclusion There have been many approaches to automatic detection of similar words from text corpora	0	Ours is 772 similar to <REF>Grefenstette, 1994</REF>; <TREF>Hindle, 1990</TREF>; <REF>Ruge, 1992</REF> in the use of dependency relationship as the word features, based on which word similarities are computed	1	Evaluation of automatically generated lexical resources is a difficult problem	0	In <TREF>Hindle, 1990</TREF>, a small set of sample results are presented	0	2	1
C96-2205	P90-1034	1996	The similarity is usually calculated from a thesaurus	0	Since a handmade thesaurus is not slfitahle for machine use, and expensive to compile, automatical construction ofa thesaurus has been attempted using corpora <TREF>Hindle, 1990</TREF>	0	llowever, the thesaurus constructed by such ways does not contain so many nouns, and these nouns are specified by the used corpus	1	In other words, we cannot construct the general thesaurus from only a corpus	0	1	3
C96-2205	P90-1034	1996	In all, we obtained 2,708,135 bits of generalized cooccurrence data, which consisted of 115,330 types	0	23 Measuring the similarity between classes step 3 In step 3, we measure the similarity between two primitive classes by using the method given by Hindle <TREF>Hindle, 1990</TREF>	1	First, we define the nmtual information MI of a verb v and a primitive class C as follows	0	ZmY2 M ,Clogs N eq1 N N In the above equation, N is the total number of cooccurrence data bits, and fv and fC are the frequency of v and C in the whole cooccurrence data set respectively, and fv, C is the frequency of the cooccurrence data C, wo, v	0	3	1
P05-1077	P90-1034	2005	In the next section, we proceed to apply this technique for generating noun similarity lists	0	4 Building Noun Similarity Lists A lot of work has been done in the NLP community on clustering words according to their meaning in text <TREF>Hindle, 1990</TREF>; <REF>Lin, 1998</REF>	1	The basic intuition is that words that are similar to each other tend to occur in similar contexts, thus linking the semantics of words with their lexical usage in text	0	One may ask why is clustering of words necessary in the first place	0	6	1
P92-1028	P90-1034	1992	The UMass/MUC-3 parser would clearly need additional mechanisms to handle the ensuing part of speech and 7Other parsing errors occurred throughout the training set, but only those instances where the antecedent was not recognized as a constituent and the wh-word had an anteceden0 were discarded	0	8Interestingly, in work on the automated classification of nouns, <TREF>Hindle, 1990</TREF> also noted problems with empty words that depend on their complements for meaning	1	221 word sense disambiguation problems	0	However, recent research in these areas indicates that automated approaches for these tasks may be feasible see, for example, Brown, Della Pietra, <REF>Della Pietra,  Mercer, 1991</REF> and l-<REF>Iindle, 1983</REF>	0	6	1
P92-1028	P90-1034	1992	The corpus is relatively small it contains approximately 450,000 words and 18,750 sentences	0	In comparison, most corpus-based algorithms employ substantially larger corpora eg , 1 million words de <REF>Marcken, 1990</REF>, 25 million words <REF>Brent, 1991</REF>, 6 million words <TREF>Hindle, 1990</TREF>, 13 million words <REF>Hindle,  Rooth, 1991</REF>	1	Relative pronoun processing is especially important for the MUC-3 corpus because approximately 25 of the sentences contain at least one relative pronoun	0	3 In fact, the relative pronoun who occurs in approximately 1 out of every 10 sentences	0	6	1
C04-1165	P90-1034	2004	In previous research, word meanings have been statistically modeled based on syntactic information derived from a corpus	0	<TREF>Hindle 1990</TREF> used noun-verb syntactic relations, and <REF>Hatzivassiloglou and McKeown 1993</REF> used coordinated adjective-adjective modifier pairs	0	These methods are useful for the organization of words deep within a hierarchy, but do not seem to provide a solution for the top levels of the hierarchy	1	To find an objective hierarchical word structure, we utilize the complementary similarity measure CSM, which estimates a one-to-many relation, such as superordinatesubordinate relations <REF>Hagita and Sawaki 1995</REF>, <REF>Yamamoto and Umemura 2002</REF>	0	1	3
P94-1032	P90-1034	1994	Do we really need to fully parse the texts in every application	0	Some researchers apply shallow or partial parsers <REF>Smadja, 1991</REF>; <TREF>Hindle, 1990</TREF> to acquiring specific patterns from texts	1	These tell us that it is not necessary to completely parse the texts for some applications	0	This paper will propose a probabilistic partial parser and incorporate linguistic knowledge to extract noun phrases	0	5	1
P98-2127	P90-1034	1998	We also constructed several other thesauri using the same corpus, but with the similarity measures in Figure 1	0	The measure simHinate is the same as the similarity measure proposed in <TREF>Hindle, 1990</TREF>, except that it does not use dependency triples with negative mutual information	1	The measure simHindle,, is the same as simHindle except that all types of dependency relationships are used, instead of just subject and object relationships	0	The measures simcosine, simdice and simdacard are versions of similarity measures commonly used in information retrieval Frakes and Baeza-<REF>Yates, 1992</REF>	0	3	1
P98-2127	P90-1034	1998	and Conclusion There have been many approaches to automatic detection of similar words from text corpora	0	Ours is 772 similar to <REF>Grefenstette, 1994</REF>; <TREF>Hindle, 1990</TREF>; <REF>Ruge, 1992</REF> in the use of dependency relationship as the word features, based on which word similarities are computed	1	Evaluation of automatically generated lexical resources is a difficult problem	0	In <TREF>Hindle, 1990</TREF>, a small set of sample results are presented	0	2	1
P98-2127	P90-1034	1998	Evaluation of automatically generated lexical resources is a difficult problem	0	In <TREF>Hindle, 1990</TREF>, a small set of sample results are presented	1	In <REF>Smadja, 1993</REF>, automatically extracted collocations are judged by a lexicographer	0	In <REF>Dagan et al , 1993</REF> and Pereira et al ,  993, clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time	0	6	1
A92-1013	P90-1034	1992	2 Acquiring syntactic associations Clustered association data are collected by first extracting from the corpus all the syntactically related word pairs	0	Combining statistical and parsing methods has been done by <TREF>Hindle, 1990</TREF>; Hindle and Rooths,1991 and <REF>Smadja and McKewon, 1990</REF>; Smadja,1991	0	The novel aspect of our study is that we collect not only operational pairs, but triples, such as Nprep N, VprepN etc In fact, the preposition convey important information on the nature of the semantic link between syntactically related content words	1	By looking at the preposition, it is possible to restrict the set of semantic relations underlying a syntactic relation eg forpurpose,beneficiary	0	5	1
A92-1013	P90-1034	1992	The results of these studies have important applications in lexicography, to detect lexicosyntactic regularities <REF>Church and Hanks, 1990</REF>1 Calzolari and Bindi,1990, such as, for example support verbs eg make-decision prepositional verbs eg rely-upon idioms, semantic relations eg partof and fixed expressions eg kick the bucket	0	In Hindle,1990; <REF>Zernik, 1989</REF>; Webster el <REF>Marcus, 1989</REF> cooccurrence analyses augmented with syntactic parsing is used for the purpose of word classification	1	All these studies are based on th strong assumption that syntactic similarity in wor patterns implies semantic similarity	0	In Guthrie el al , 1991, sets of consistently contiguous word, neighbourhood are extracted from machinereadable dictionaries, to help semantic disambiguation in information retrieval	0	6	1
A92-1013	P90-1034	1992	In <REF>Smadja, 1989</REF>, <REF>Zernik and Jacobs, 1990</REF>, the associations are filtered by selecting the word pairs x,y whose frequency of occurrence is above fks, where f is the average appearance, s is the standard deviation, and k is an empirically determined factor	0	<TREF>Hindle, 1990</TREF>; Hindle and Rooths,1991 and <REF>Smadja, 1991</REF> use syntactic markers to increase the significance of the data	1	<REF>Guthrie et al , 1991</REF> uses the subject classification given in machine-readable dictionaries eg economics, engineering, etc	0	to reinforce cooccurence links	0	6	1
A94-1011	P90-1034	1994	More sophisticated linguistic information comes in several forms, all of which may need to be represented if performance in an automatic categorisation experiment is to be improved	0	Typical examples of linguistically sophisticated annotation include tagging words with their syntactic category although this has not been found to be effective for 1R, lemma of the word eg corpus for corpora, phrasal information eg identifying noun groups and phrases <REF>Lewis 1992c</REF>, <REF>Church 1988</REF>, and subject-predicate identification eg <TREF>Hindle 1990</TREF>	1	For the RAPRA corpus, we currently identify noun groups and adjective groups	0	This is achieved in a manner similar to Churchs 1988 PARTS algorithm used by Lewis 1992bc, in the sense that its main properties are robustness and corpus sensitivity	0	6	1
W93-0107	P90-1034	1993	In NLP, representing verb semantics with their thematic roles is a consolidated practice, even though theoretical researches <REF>Pustejovski 1991</REF> propose more rich and formal representation frameworks	0	More recent papers <TREF>Hindle 1990</TREF>, <REF>Pereira and Tishby 1992</REF> proposed to cluster nouns on the basis of a metric derived from the distribution of subject, verb and object in the texts	0	Both papers use as a source of information large corpora, but differ in the type of statistical approach used to determine word similarity	0	These studies, though valuable, leave several open problems: 70 1 A metric of conceptual closeness based on mere syntactic similarity is questionable, particularly if applied to verbs	1	1	3
P06-1116	P90-1034	2006	1993 and <REF>Lee 1999</REF>, among others	0	We use the cosine similarity measure for windowbased contexts and the following commonly used similarity measures for the syntactic vector space: <TREF>Hindles 1990</TREF> measure, the weighted Lin measure <REF>Wu and Zhou, 2003</REF>, the -Skew divergence measure <REF>Lee, 1999</REF>, the Jensen-Shannon JS divergence measure <REF>Lin, 1991</REF>, Jaccards coef cient van <REF>Rijsbergen, 1979</REF> and the Confusion probability <REF>Essen and Steinbiss, 1992</REF>	1	The Jensen-Shannon measure JS x1, x2  summationtext yY summationtext xx1,x2 parenleftbigg P yx log parenleftbigg Pyx 1 2 Pyx1Pyx2 parenrightbiggparenrightbigg subsequently performed best for our task	0	We compare the different ranking methodologies and data sets with respect to a manually-de ned gold standard list of 20 goal-type verbs and 20 nouns	0	3	1
J93-2002	P90-1034	1993	First, this approach leverages a little a priori grammatical knowledge using statistical inference	0	Most work on corpora of naturally occurring language 244 Michael R Brent From Grammar to Lexicon either uses no a priori grammatical knowledge <REF>Brill and Marcus 1992</REF>; <REF>Ellison 1991</REF>; <REF>Finch and Chater 1992</REF>; <REF>Pereira and Schabes 1992</REF>, or else it relies on a large and complex grammar <REF>Hindle 1990, 1991</REF>	1	One exception is <REF>Magerman and Marcus 1991</REF>, in which a small grammar is used to aid learning	0	1 A second difference is that the work reported here uses inferential rather than descriptive statistics	0	6	1
J93-2002	P90-1034	1993	In other words, it uses statistical methods to infer facts about the language as it exists in the minds of those who produced the corpus	0	Many other projects have used statistics in a way that summarizes facts about the text but does not draw any explicit conclusions from them <REF>Finch and Chater 1992</REF>; <TREF>Hindle 1990</TREF>	1	On the other hand, <REF>Hindle 1991</REF> does use inferential statistics, and <REF>Brill 1992</REF> recognizes the value of inference, although he does not use inferential statistics per se	0	Finally, many other projects in machine learning of natural language use input that is annotated in some way, either with part-of-speech tags <REF>Brill 1992</REF>; <REF>Brill and Marcus 1992</REF>; <REF>Magerman and Marcus 1990</REF> or with syntactic brackets <REF>Pereira and Schabes 1992</REF>	0	6	1
P91-1017	P90-1034	1991	This is the basis for Sadlers <REF>Analogical Semantics 1989</REF> which has not yet proved effective	0	His results may be improved if more sophisticated techniques and larger corpora are used to establish similarity between words such as in <TREF>Hindle, 1990</TREF>	1	Conflicting data	0	In very few cases two alternatives were supported equally by the statistical data, thus preventing a selection	0	6	1
P91-1017	P90-1034	1991	Consequently, a possible though partial alternative to using manually constructed knowledge can be found in the use of statistical data on the occurrence of lexical relations in large corpora	0	The use of such relations mainly relations between verbs or nouns and their arguments and modifiers for various purposes has received growing attention in recent research <REF>Church and Hanks, 1990</REF>; <REF>Zernik and Jacobs, 1990</REF>; <TREF>Hindle, 1990</TREF>	1	More specifically, two recent works have suggested to use statistical data on lexical relations for resolving ambiguity cases of PP-attachment <REF>Hindle and Rooth, 1990</REF> and pronoun references <REF>Dagan and Itai, 1990a</REF>; <REF>Dagan and Itai, 1990b</REF>	0	Clearly, statistical methods can be useful also for target word selection	0	6	1
P91-1017	P90-1034	1991	The use of such relations mainly relations between verbs or nouns and their arguments and modifiers for various purposes has received growing attention in recent research <REF>Church and Hanks, 1990</REF>; <REF>Zernik and Jacobs, 1990</REF>; <TREF>Hindle, 1990</TREF>	0	More specifically, two recent works have suggested to use statistical data on lexical relations for resolving ambiguity cases of PP-attachment <REF>Hindle and Rooth, 1990</REF> and pronoun references <REF>Dagan and Itai, 1990a</REF>; <REF>Dagan and Itai, 1990b</REF>	1	Clearly, statistical methods can be useful also for target word selection	0	Consider, for example, the Hebrew sentence extracted from the foreign news section of the daily <REF>Haaretz, September 1990</REF> transcripted to Latin letters	0	6	1
I08-1060	P90-1034	2008	Many studies extract synonyms from large monolingual corpora by using context information around targetterms<REF>CroachandYang, 1992</REF>; <REF>ParkandChoi, 1996</REF>; <REF>Waterman, 1996</REF>; <REF>Curran, 2004</REF>	0	Some researchers <TREF>Hindle, 1990</TREF>; <REF>Grefenstette, 1994</REF>; <REF>Lin, 1998</REF> classify terms by similarities based on their distributional syntactic patterns	1	These methods often extract not only synonyms, but also semantically related terms, such as antonyms, hyponyms and coordinate terms such as cat and dog Some studies make use of bilingual corpora or dictionaries to nd synonyms in a target language <REF>Barzilay and McKeown, 2001</REF>; <REF>Shimohata and Sumita, 2002</REF>; <REF>Wu and Zhou, 2003</REF>; <REF>Lin et al, 2003</REF>	0	Lin et al	0	6	1
C92-2082	P90-1034	1992	Semantic Relatedness Information	0	There bas recently been work in the detection of semantically related nouns via, for example, shared argument structures <TREF>Hindle 1990</TREF>, and shared dictionary definition context Wilks e al 1990	0	These approaches attempt to infer relationships among exical terms by looking at very large text samples and determining which ones are related in a statistically significant way	0	The technique introduced in this paper can be seen as having a similar goal but an entirely different approach, since only one sample need be found in order to determine a salient relationship and that sample may be infrequently occurring or nonexistent	1	2	1
W03-1610	P90-1034	2003	However, many studies investigate synonym extraction from only one resource	0	The most frequently used resource for synonym extraction is large monolingual corpora <TREF>Hindle, 1990</TREF>; <REF>Crouch and Yang, 1992</REF>; <REF>Grefenstatte, 1994</REF>; <REF>Park and Choi, 1997</REF>; <REF>Gasperin et al , 2001</REF> and <REF>Lin, 1998</REF>	0	The methods used the contexts around the investigated words to discover synonyms	0	The problem of the methods is that the precision of the extracted synonymous words is low because it extracts many word pairs such as cat and dog, which are similar but not synonymous	1	1	3
N07-1016	P90-1034	2007	It has two sources of evidence: the similarity of the strings themselves ie , edit distance and the similarity of the assertions they appear in	0	This second source of evidence is sometimes referred to as distributional similarity <TREF>Hindle, 1990</TREF>	1	Section 32 presents a simple model for predicting whether a pair of strings co-refer based on string similarity	0	Section 33 then presents a model called the Extracted Shared Property ESP Model for predicting whether a pair of strings co-refer based on their distributional similarity	0	6	1
P99-1004	P90-1034	1999	3 It is worth noting at this point that there are several well-known measures from the NLP literature that we have omitted from our experiments	0	Arguably the most widely used is the mutual information <TREF>Hindle, 1990</TREF>; <REF>Church and Hanks, 1990</REF>; <REF>Dagan et al , 1995</REF>; <REF>Luk, 1995</REF>; D <REF>Lin, 1998a</REF>	1	It does not apply in the present setting because it does not measure the similarity between two arbitrary probability distributions in our case, PVIn  and PVIm, but rather the similarity between a joint distribution PX1,X2 and the corresponding product distribution PX1PX2	0	Hamming-type metrics <REF>Cardie, 1993</REF>; <REF>Zavrel and Daelemans, 1997</REF> are intended for data with symbolic features, since they count feature label mismatches, whereas we are dealing feature Values that are probabilities	0	6	1
W97-0803	P90-1034	1997	Furthermore, this effort is repeated when a system is ported to another domain	0	This criticism leads us to automatic approaches for building thesauri from large corpora <REF>Hirschman et al , 1975</REF>; <TREF>Hindle, 1990</TREF>; <REF>Hatzivassiloglou and McKeown, 1993</REF>; <REF>Pereira et al , 1993</REF>; Tokunaga et aL, 1995; <REF>Ushioda, 1996</REF>	0	Past attempts have basically taken the following steps <REF>Charniak, 1993</REF>	0	1 extract word co-occurrences 2 define similarities distances between words on the basis of co-occurrences 3 cluster words on the basis of similarities The most crucial part of this approach is gathering word co-occurrence data	0	6	1
N03-4011	P90-1034	2003	The Distributional Hypothesis <REF>Harris 1985</REF> states that words that occur in the same contexts tend to be similar	0	There have been many approaches to compute the similarity between words based on their distribution in a corpus <TREF>Hindle 1990</TREF>; <REF>Landauer and Dumais 1997</REF>; <REF>Lin 1998</REF>	1	The output of these programs is a ranked list of similar words to each word	0	For example, Lins approach outputs the following similar words for wine and suit: wine: beer, white wine, red wine, Chardonnay, champagne, fruit, food, coffee, juice, Cabernet, cognac, vinegar, Pinot noir, milk, vodka, suit: lawsuit, jacket, shirt, pant, dress, case, sweater, coat, trouser, claim, business suit, blouse, skirt, litigation,  The similar words of wine represent the meaning of wine	0	6	1
W93-0113	P90-1034	1993	A proper filter must be able to access information in the text using any word of a set of similar words	0	A number of knowledge-rich <REF>Jacobs and Rau, 1990</REF>, <REF>Calzolari and Bindi, 1990</REF>, <REF>Mauldin, 1991</REF> and knowledge-poor <REF>Brown et al , 1992</REF>, <TREF>Hindle, 1990</TREF>, <REF>Ruge, 1991</REF>, <REF>Grefenstette, 1992</REF> methods have been proposed for recognizing when words are similar	1	The knowledge-rich approaches require either a conceptual dependency representation, or semantic tagging of the words, while the knowledge-poor approaches require no previously encoded semantic information, and depend on frequency of co-occurrence of word contexts to determine similarity	0	Evaluations of results produced by the above systems are often been limited to visual verification by a human subject or left to the human reader	0	6	1
W04-1216	P90-1034	2004	3 Distributional Word Similarity Words that tend to appear in the same contexts tend to have similar meanings <REF>Harris 1968</REF>	0	For example, the words corruption and abuse are similar because both of them can be subjects of verbs like arouse, become, betray, cause, continue, cost, exist, force, go on, grow, have, increase, lead to, and persist, etc, and both of them can modify nouns like accusation, act, allegation, appearance, and case, etc Many methods have been proposed to compute distributional similarity between words, eg, <TREF>Hindle, 1990</TREF>, <REF>Pereira et al 1993</REF>, <REF>Grefenstette 1994</REF> and <REF>Lin 1998</REF>	1	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared	0	84 31 Proximity-based Similarity It is natural to use dependency relationship Meluk, 1987 as features, but a parser has to be available	0	6	1
J05-4002	P90-1034	2005	The underlying idea is based largely on the central claim of the distributional hypothesis <REF>Harris 1968</REF>, that is: The meaning of entities, and the meaning of grammatical relations among them, is related to the restriction of combinations of these entities relative to other entities	0	This hypothesized relationship between distributional similarity and semantic similarity has given rise to a large body of work on automatic thesaurus generation <TREF>Hindle 1990</TREF>; <REF>Grefenstette 1994</REF>; <REF>Lin 1998a</REF>; <REF>Curran and Moens 2002</REF>; <REF>Kilgarriff 2003</REF>	0	There are inherent problems in evaluating automatic thesaurus extraction techniques, and much research assumes a gold standard that does not exist see Kilgarriff 2003 and Weeds 2003 for more discussion of this	0	A further problem for distributional similarity methods for automatic thesaurus generation is that they do not offer any obvious way to distinguish between linguistic relations such as synonymy, antonymy, and hyponymy see Caraballo 1999 and Lin et al 2003 for work on this	1	1	3
J05-4002	P90-1034	2005	As can be seen, similarity between neighbor sets is significantly higher at high recall settings low  within the model than at highprecision settings high , which suggests that dist  has high-recall CR characteristics	0	45 Hindles <REF>Measure Hindle 1990</REF> proposed an MI-based measure, which he used to show that nouns could be reliably clustered based on their verb co-occurrences	1	We consider the variant of 458 Weeds and Weir Co-occurrence Retrieval Figure 1 Variation with parameters  and  in development set mean similarity between neighbor sets of the additive t-test based CRM and of dist   Hindles Measure proposed by <REF>Lin 1998a</REF>, which overcomes the problem associated with calculating MI for word-feature combinations that do not occur: sim hind w 1, w 2   summationdisplay Tw 1 Tw 2  minIc, w 1 , Ic, w 2  38 where Tw 1  c : Ic, n > 0	0	This expression is the same as the numerator in the expressions for precision and recall in the difference-weighted MI-based CRM: P dw mi w 1, w 2   summationtext TP Iw 1, c  minIw 1, c,Iw 2, c Iw 1, c summationtext Fw 1  Iw 1, c  summationtext TP minIw 1, c, Iw 2, c summationtext Fw 1  Iw 1, c 39 R dw mi w 1, w 2   summationtext TP Iw 2, c  minIw 2, c,Iw 1, c Iw 2, c summationtext Fw 2  Iw 2, c  summationtext TP minIw 2, c, Iw 1, c summationtext Fw 2  Iw 2, c 40 since TP  Tw 1   Tw 2 	0	6	1
J05-4002	P90-1034	2005	A statistical technique using a language model that assigns a zero probability to these previously unseen events will rule the correct parse or interpretation of the utterance impossible	0	Similarity-based smoothing <TREF>Hindle 1990</TREF>; <REF>Brown et al 1992</REF>; <REF>Dagan, Marcus, and Markovitch 1993</REF>; <REF>Pereira, Tishby, and Lee 1993</REF>; <REF>Dagan, Lee, and Pereira 1999</REF> provides an intuitively appealing approach to language modeling	1	In order to estimate the probability of an unseen co-occurrence of events, estimates based on seen occurrences of similar events can be combined	0	For example, in a speech recognition task, we might predict that cat is a more likely subject of growl than the word cap, even though neither co-occurrence has been seen before, based on the fact that cat is similar to words that do occur as the subject of growl eg , dog and tiger, whereas cap is not	0	6	1
J98-4002	P90-1034	1998	statistical factors, although statistical factors are calculated in terms of the predicate argument structure in which each noun appears	0	Predicate argument structures, which consist of complements case filler nouns and case markers and verbs, have also been used in the task of noun classification <TREF>Hindle 1990</TREF>	1	This can be expressed by Equation 3, where ff is the vector for the noun in question, and items ti represent the statistics for predicate argument structures including n ff  h, t2,, ti  3 In regard to ti, we used the notion of TF	0	IDF <REF>Salton and McGill 1983</REF>	0	6	1
N04-1041	P90-1034	2004	2 Previous Work There have been several approaches to automatically discovering lexico-semantic information from text <REF>Hearst 1992</REF>; <REF>Riloff and Shepherd 1997</REF>; <REF>Riloff and Jones 1999</REF>; <REF>Berland and Charniak 1999</REF>; <REF>Pantel and Lin 2002</REF>; <REF>Fleischman et al 2003</REF>; <REF>Girju et al 2003</REF>	0	One approach constructs automatic thesauri by computing the similarity between words based on their distribution in a corpus <TREF>Hindle 1990</TREF>; <REF>Lin 1998</REF>	1	The output of these programs is a ranked list of similar words to each word	0	For example, Lins approach outputs the following top-20 similar words of orange: D peach, grapefruit, yellow, lemon, pink, avocado, tangerine, banana, purple, Santa Ana, strawberry, tomato, red, pineapple, pear, Apricot, apple, green, citrus, mango A common problem of such lists is that they do not discriminate between the senses of polysemous words	0	6	1
C96-1006	P91-1022	1996	First, most of theln assume that the input corpora me aligned sentence by sentence, which reduces their applicability remarkably	0	Although a number of automatic sentence alignment methods have been proposed <TREF>Brown et al 1991</TREF> ; <REF>Gale  Church 1991</REF> b; <REF>Kay  Roscheisen 1993</REF>; <REF>Chen 1993</REF>, they are not very reliable for real noisy bilingual texts	1	Second, the statistical methods usually require a very large corpus as their input	0	However, it is not easy to obtain a very large corpus	0	1	3
P98-1117	P91-1022	1998	In fact, it could be argued that, ultimately, text alignment is no easier than the more general problem of natural language understanding	0	In addition, most research efforts were directed towards the easiest problem, that of sentence-to-sentence alignment <TREF>Brown et al , 1991</TREF>; <REF>Gale and Church, 1991</REF>; <REF>Debili, 1992</REF>; Kay and lscheisen, 1993; <REF>Simard et al , 1992</REF>; <REF>Simard and Plamondon, 1996</REF>	1	Alignment at the word and term level, which is extremely useful for applications such as lexieal resource extraction, is still a largely unexplored research area<REF>Melamed, 1997</REF>	0	In order to live up to the expectations of the 711 various application fields, alignment technology will therefore have to improve substantially	0	6	1
W96-0201	P91-1022	1996	Several automatic methods have been proposed for this task in recent years	0	However, most of these methods address only the sub-problem of alignment <REF>Catizone et al 1989</REF>, <TREF>Brown et al 1991</TREF>, <REF>Gale  Church 1991</REF>, <REF>Debili  Sammouda 1992</REF>, <REF>Simard et al 1992</REF>, Kay  R<REF>Sscheisen 1993</REF>, <REF>Wu 1994</REF>	1	Alignment algorithms assume the availability of text unit boundary information and their output has less expressive power than a general bitext map	0	The only published solution to the more difficult general bitext mapping problem <REF>Church 1993</REF> can err by several typeset pages	0	1	3
W96-0201	P91-1022	1996	There are several papers in the literature about bitext alignment	0	The algorithms that seem to work best rely on the high correlation between the lengths of corresponding sentences <TREF>Brown et al 1991</TREF>, <REF>Gale  Church 1991</REF>	1	However, these algorithms can fumble in bitext sections that contain many sentences of very similar length, like this vote record: English French Mr McInnis	1	Yes	0	1	3
W96-0201	P91-1022	1996	SIMR borrows several insights from previous work	0	<REF>Like Gale  Church 1991</REF> and Brown et al	1	1991, SIMR relies on the high correlation between the lengths of mutual translations	0	Like charalign <REF>Church 1993</REF>, SIMR infers bitext maps from likely points of correspondence between the two texts, points that are plotted in a two-dimensional space of possibilities	0	6	1
P98-1042	P91-1022	1998	Many software products which aid human translators now contain sentence alignment tools as an aid to speeding up editing and terminology searching	0	Various methods have been developed for sentence alignment which we can categorise as either lexical such as <REF>Chen, 1993</REF>, based on a large-scale bilingual lexicon; statistical such as <TREF>Brown et al , 1991</TREF> <REF>Church, 1993</REF><REF>Gale and Church, 1903</REF>Kay and R<REF>Ssheheisen, 1993</REF>, based on distributional regularities of words or byte-length ratios and possibly inducing a bilingual lexicon as a by-product, or hybrid such as <REF>Utsuro et al , 1994</REF> <REF>Wu, 1994</REF>, based on some combination of the other two	1	Neither of the pure approaches is entirely satisfactory for the following reasons:  Text volume limits the usefulness of statistical approaches	1	We would often like to be able to align small amounts of text, or texts from various domains which do not share the same statistical properties	0	1	3
P99-1043	P91-1022	1999	pruning translation alternatives for query translation	0	Co-occurrence information between neighboring words and words in the same sentence has been used in phrase extraction <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>, phrasal translation <REF>Smadja et al , 1996</REF>; <REF>Kupiec, 1993</REF>; <REF>Wu, 1995</REF>; <REF>Dagan and Church, 1994</REF>, target word selection <REF>Liu and Li, 1997</REF>; <REF>Tanaka and Iwasaki, 1996</REF>, domain word translation <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, sense disambiguation <TREF>Brown et al , 1991</TREF>; <REF>Dagan et al , 1991</REF>; <REF>Dagan and Itai, 1994</REF>; <REF>Gale et al , 1992a</REF>; <REF>Gale et al , 1992b</REF>; <REF>Gale et al , 1992c</REF>; <REF>Shiitze, 1992</REF>; <REF>Gale et al , 1993</REF>; <REF>Yarowsky, 1995</REF>, and even recently for query translation in cross-language IR as well <REF>Ballesteros and Croft, 1998</REF>	1	Co-occurrence statistics is collected from either bilingual parallel and 334 non-parallel corpora <REF>Smadja et al , 1996</REF>; <REF>Kupiec, 1993</REF>; <REF>Wu, 1995</REF>; <REF>Tanaka and Iwasaki, 1996</REF>; <REF>Fung and Lo, 1998</REF>, or monolingual corpora <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>; <REF>Liu and Li, 1997</REF>; <REF>Shiitze, 1992</REF>; <REF>Yarowsky, 1995</REF>	0	As we noted in <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, parallel corpora are rare in most domains	0	6	1
P06-2092	P91-1022	2006	Strategies that use system-external dictionaries, finally, can only be used if a large-enough dictionary exists for a specific language pair	0	22 Word Alignment Aligning below the sentence level is usually done using statistical models for machine translation <TREF>Brown et al , 1991</TREF>; <REF>Brown et al , 1993</REF>; <REF>Hiemstra, 1996</REF>; <REF>Vogel et al , 1999</REF> where any word of the targetlanguageistakentobeapossibletranslation for each source language word	1	The probability of some target language word to be a translation of a source language word then depends on the frequency with which both co-occur at the same or similar positions in the parallel corpus	0	The probabilities are estimated from the using the EM-algorithm1, and a Viterbi search is carried out to compute the most probable sequence of word translation pairs	0	6	1
P06-1062	P91-1022	2006	A number of techniques for aligning sentences in parallel corpora have been proposed	0	<REF>Gale  Church 1991</REF>; <TREF>Brown et al 1991</TREF>; <REF>Wu 1994</REF> used sentence length as the basic feature for alignment	1	<REF>Kay  Roscheisen 1993</REF>; and <REF>Chen 1993</REF> used lexical information for sentence alignment	0	Models combining length and lexicon information were proposed in <REF>Zhao and Vogel, 2002</REF>; <REF>Moore 2002</REF>	0	6	1
P06-1062	P91-1022	2006	To support machine translation, parallel sentences should be extracted from the mined parallel documents	0	However, current sentence alignment models, <TREF>Brown et al 1991</TREF>; <REF>Gale  Church 1991</REF>; <REF>Wu 1994</REF>; Chen 489 1993; <REF>Zhao and Vogel, 2002</REF>; etc	1	are targeted on traditional textual documents	0	Due to the noisy nature of the web documents, parallel web pages may consist of non-translational content and many out-of-vocabulary words, both of which reduce sentence alignment accuracy	1	1	3
J93-2003	P91-1022	1993	Nonetheless, they were able to align phrases in French with the English words that produce them as illustrated in their Figure 3	0	More recently, <REF>Gale and Church 1991a</REF> describe an algorithm similar to the one described in Brown et al	1	1988	0	Like Brown et al , they consider only the simultaneous appearance of words in pairs of sentences that are translations of one another	0	6	1
J93-2003	P91-1022	1993	If we reinterpret the Viterbi alignment to mean the most probable alignment that we can find rather than the most probable alignment that exists, then a similarly reinterpreted Viterbi training algorithm still converges	0	We have already used this algorithm successfully as a part of a system to assign senses to English and French words on the basis of the context in which they appear <REF>Brown et al 1991a, 1991b</REF>	1	We expect to use it in models that we develop beyond Model 5	0	293 Computational Linguistics Volume 19, Number 2 63 Multi-Word Cepts In Models 1-5, we restrict our attention to alignments with cepts containing no more than one word each	0	1	2
P93-1001	P91-1022	1993	P93-1001:25	0	Charalign: A Program for Aligning Parallel Texts at the Character Level Kenneth Ward Church ATT Bell Laboratories 600 Mountain Avenue Murray Hill NJ, 07974-0636 kwc researchattcom Abstract There have been a number of recent papers on aligning parallel texts at the sentence level, eg, <TREF>Brown et al 1991</TREF>, Gale and Church to appear, <REF>Isabelle 1992</REF>, Kay and R/Ssenschein to appear, <REF>Simard et al 1992</REF>, <REF>WarwickArmstrong and Russell 1990</REF>	1	On clean inputs, such as the Canadian Hansards, these methods have been very successful at least 96 correct by sentence	1	Unfortunately, if the input is noisy due to OCR and/or unknown markup conventions, then these methods tend to break down because the noise can make it difficult to find paragraph boundaries, let alone sentences	1	1	3
C98-1113	P91-1022	1998	In fact, it could be argued that, ultimately, text alignment is no easier thal the more general problem of natural laalguage understanding	0	In addition, most research efforts were directed towards the easiest problem, that of sentence-to-sentence alignment <TREF>Brown et al, 1991</TREF>; <REF>Gale and Church, 1991</REF>; <REF>Debili, 1992</REF>; Kay and R<REF>Sscheisen, 1993</REF>; <REF>Simard et al, 1992</REF>; <REF>Simard and Plamondon, 1996</REF>	1	Alignment at the word and term level, which is extremely useful for applications such as lexical resource extraction, is still a largely unexplored research area<REF>Melamed, 1997</REF>	0	In order to live up to the expectations of the 711 various application fields, alignment technology will therefore have to improve substantially	0	6	1
A00-2011	P91-1022	2000	Furthermore, a glossing algorithm can be used for lexical selection in a full-fledged machine translation MT system	0	Many corpus-based MT systems require parallel corpora <REF>Brown et al , 1990</REF>; <TREF>Brown et al , 1991</TREF>; <REF>Gale and Church, 1991</REF>; <REF>Resnik, 1999</REF>	1	<REF>Kikui 1999</REF> used a word sense disambiguation algorithm and a non-paralM bilingual corpus to resolve translation ambiguity	0	In this paper, we present a word-for-word glossing algorithm that requires only a source language corpus	1	2	1
P93-1002	P91-1022	1993	Hence, we use a slightly different framework	0	We view a bilingual corpus as a sequence of sentence beads <TREF>Brown et al , 1991b</TREF>, where a sentence bead corresponds to an irreducible group of sentences that align with each other	1	For example, the correct alignment of the bilingual corpus in Figure 2 consists of the sentence bead El; F1 followed by the sentence bead E2; ;2, F3	0	We can represent an alignment 4 of a corpus as a sequence of sentence beads Epl; Fpl, Ep2; F,, where the E and F can be zero, one, or more sentences long	0	6	1
C94-2175	P91-1022	1994	For the remnant, we allow only 1-1, 1-2, 1-3, 1-4, 2-2 as pMrs of the numbers of sentences: xi,yi e 1,1,1,2,2,1,1,3, 3, 1, 1,4, 4, 1, 2, 2 This optimization problem is solvable as a standard problem in dynamic programming	0	Dynamic programming is applied to bilingual sentence alignment in most of previous works <TREF>Brown et al , 1991</TREF>; <REF>Gate and Church, 1993</REF>; <REF>Chen, 1993</REF>	1	1078 4 Word Correspondence Estimation In this section, first we describe estimation flmctions based-on co-occnrrence frequencies	0	Then, we show how to incorporate word correspondence information available in bilingual dictionaries and to estimate word correspondences not included in bilingual dictionaries	0	6	1
C94-2175	P91-1022	1994	One of the major approaches to analyzing bilingual texts is the statistical approach	0	The statistical approach involves the following: alignment of bilingual texts at the sentence level nsing statistical techniques eg <TREF>Brown, Lai and Mercer 1991</TREF>, <REF>Gale and Church 1993</REF>, <REF>Chen 1993</REF>, and Kay and R<REF>Sscheisen 1993</REF>, statistical machine translation models eg Brown, Cooke, Pietra, Pietra et al	1	1990, finding character-level / word-level / phrase-level correspondences from bilingual texts eg <REF>Gale and Church 1991</REF>, <REF>Church 1993</REF>, and <REF>Kupiec 1993</REF>, and word sense disambiguation for MT eg <REF>Dagan, Itai and Schwall 1991</REF>	0	In general, the statistical approach does not use existing hand-written bilingual dictionaries, and depends solely upon statistics	0	6	1
C94-2175	P91-1022	1994	In general, the statistical approach does not use existing hand-written bilingual dictionaries, and depends solely upon statistics	0	For example, sentence alignment of bilingual texts are performed just by measuring sentence lengths in words or in characters <TREF>Brown et al , 1991</TREF>; <REF>Gale and Church, 1993</REF>, or by statistically estimating word level correspondences <REF>Chen, 1993</REF>; Kay and R<REF>Sscheisen, 1993</REF>	1	The statistical approach analyzes unstructured sentences in bilingual texts, and it is claimed that the results are useful enough in real applications such as machine translation and word sense disambiguation	1	However, structured bilingual sentences are undoubtedly more informative and important for future natural language researches	1	1	3
P98-1069	P91-1022	1998	It remains to be seen how we can also make use of the multilingual texts as NLP resources	0	In the years since the appearance of the first papers on using statistical models for bilingual lexicon compilation and machine translation<REF>Brown et al , 1993</REF>; <TREF>Brown et al , 1991</TREF>; <REF>Gale and <REF>Church, 1993</REF></REF>; <REF>Church, 1993</REF>; <REF>Simard et al , 1992</REF>, large amount of human effort and time has been invested in collecting parallel corpora of translated texts	1	Our goal is to alleviate this effort and enlarge the scope of corpus resources by looking into monolingual, comparable texts	1	This type of texts are known as nonparallel corpora	0	2	1
J96-1001	P91-1022	1996	In this way, we can ignore the context of the collocations and their translations, and base our decisions only on the patterns of co-occurrence of each collocation and its candidate translations across the entire corpus	0	This approach is quite different from those adopted for the translation of single words <REF>Klavans and Tzoukermann 1990</REF>; <REF>Dorr 1992</REF>; <REF>Klavans and Tzoukermann 1996</REF>, since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words <TREF>Brown et al 1991</TREF>; <REF>Dagan, Itai, and Schwall 1991</REF>; <REF>Dagan and Itai 1994</REF>	1	The assumption of a single meaning per collocation was based on our previous experience with English collocations <REF>Smadja 1993</REF>, is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation <REF>Yarowsky 1993</REF>, and was verified during our evaluation of Champollion Section 7	0	We construct a mathematical model of the events we want to correlate, namely, the appearance of any word or group of words in the sentences of our corpus, as follows: To each group of words G, in either the source or the target language, we map a binary random variable Xc that takes the value 1 if G appears in a particular sentence and 0 if not	0	6	1
J96-1001	P91-1022	1996	Smadja, McKeown, and Hatzivassiloglou Translating Collocations for Bilingual Lexicons 2	0	Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment <REF>Gale and Church 1991b</REF>; <TREF>Brown, Lai, and Mercer 1991</TREF>; <REF>Simard, Foster and Isabelle 1992</REF>; <REF>Gale and Church 1993</REF>; <REF>Chen 1993</REF>, word alignment <REF>Gale and Church 1991a</REF>; <REF>Brown et al 1993</REF></REF>; <REF>Dagan, Church, and Gale 1993</REF>; <REF>Fung and McKeown 1994</REF>; <REF>Fung 1995b</REF>, alignment of groups of words <REF>Smadja 1992</REF>; <REF>Kupiec 1993</REF>; van der <REF>Eijk 1993</REF>, and statistical translation <REF>Brown et al 1993</REF></REF>	1	Of these, aligning groups of words is most similar to the work reported here, although, as we shall show, we consider a greater variety of groups than is typical in other research	1	In this section, we describe work on sentence and word alignment and statistical translation, showing how these goals differ from our own, and then describe work on aligning groups of words	0	2	1
J96-1001	P91-1022	1996	Note that there is additional research using statistical approaches to bilingual problems, but it is less related to ours, addressing, for example, word sense disambiguation in the source language by statistically examining context eg , collocations in the source language, thus allowing appropriate word selection in the target language	0	<TREF>Brown et al 1991</TREF>; <REF>Dagan, Itai, and Schwall 1991</REF>; <REF>Dagan and Itai 1994</REF>	0	Our use of bilingual corpora assumes a prealigned corpus	0	Thus, we draw on work done at ATT Bell Laboratories by Gale and Church 1991a, 1991b, 1993 and at IBM by <TREF>Brown, Lai, and Mercer 1991</TREF> on bilingual sentence alignment	1	5	0
W97-0119	P91-1022	1997	Nevertheless, top 20 candidate output give a 509 average increase in accuracy on human translator performance	0	Despite a surge in research using parallel corpora for various machine translation tasks <REF>Brown et al 1993</REF>,<TREF>Brown et al 1991</TREF>; <REF>Gale  <REF>Church 1993</REF></REF>; <REF>Church 1993</REF>; <REF>Dagan  Church 1994</REF>; <REF>Simard et al 1992</REF>; <REF>Chen 1993</REF>; <REF>Melamed 1995</REF>; <REF>Wu  Xia 1994</REF>; <REF>Wu 1994</REF>; Smadja et aI	1	1996, the amount of available bilingual parallel corpora is still relatively small in comparison to the large amount of available monolingual text	1	It ks unlikely that one can find parallel corpora in any given domain in electronic form	0	6	1
P99-1027	P91-1022	1999	Here we regard the context of a word as the preceding and following non-stop words; our approach can easily be extended to other types of contextual features	0	This model is trained on approximately 5 million sentence pairs of Hansard Canadian parliamentary and UN proceedings which have been aligned on a sentence-by-sentence basis by the methods of <TREF>Brown et al , 1991</TREF>, and then further aligned on a word-by-word basis by methods similar to <REF>Brown et al , 1993</REF>	1	The French::English model can be described by simply interchanging English and French notation above	0	It is trained separately on the same training data, using identical procedures	0	6	1
P97-1038	P91-1022	1997	<REF>As Chen 1993</REF> points out, dynamic programming is particularly susceptible to deletions occurring in one of the two languages	0	Thus, dynamic programming based sentence alignment algorithms rely on paragraph anchors <TREF>Brown et al 1991</TREF> or lexical information, such as cognates <REF>Simard 1992</REF>, to maintain a high accuracy rate	1	These methods are not robust with respect to non-literal translations and large deletions <REF>Simard 1996</REF>	1	This paper presents a new approach based on image processing IP techniques, which is immune to such predicaments	0	1	3
W03-0306	P91-1022	2003	11 2042 2007 2024 7976 3532 1065 1637 5982 bnnrule 8488 2504 3868 6132 8655 830 1514 4538 nnrule 6589 6329 6457 3543 3589 3543 3566 5850 Table 1: Trial set results	0	tences <REF>Gale and Church, 1991</REF>; <TREF>Brown et al , 1991</TREF>	1	The observation can be codified as a distance between the word at position i on the LHS and the word at position j on the RHS Dleni,j  1  4  Lli  LrjLl i  Lrj2 1 where Lli is the length of the token at position i on the LHS	0	Note that Dlen is similar to a normalized harmonic mean, ranging from 0 to 10, with the minimum achieved when the lengths are the same	0	6	1
P94-1012	P91-1022	1994	However, since Chinese text consists of an unsegmented character stream without marked word boundaries, it would not be possible to count the number of words in a sentence without first parsing it	0	Although it has been suggested that lengthbased methods are language-independent <REF>Gale  Church 1991</REF>; <TREF>Brown et al 1991</TREF>, they may in fact rely to some extent on length correlations arising from the historical relationships of the languages being aligned	1	If translated sentences share cognates, then the character lengths of those cognates are of course correlated	0	Grammatical similarities between related languages may also produce correlations in sentence lengths	0	1	3
P94-1012	P91-1022	1994	Our report concerns three related topics: 1 progress on the HKUST English-Chinese Parallel Bilingual Corpus; 2 experiments addressing the applicability of Gale  Churchs 1991 lengthbased statistical method to the task of alignment involving a non-Indo-European language; and 3 an improved statistical method that also incorporates domain-specific lexical cues	0	INTRODUCTION Recently, a number of automatic techniques for aligning sentences in parallel bilingual corpora have been proposed Kay  R<REF>Sscheisen 1988</REF>; Catizone e al 1989; <REF>Gale  Church 1991</REF>; <TREF>Brown et al 1991</TREF>; <REF>Chen 1993</REF>, and coarser approaches when sentences are difficult to identify have also been advanced <REF>Church 1993</REF>; Dagan e al 1993	1	Such corpora contain the same material that has been translated by human experts into two languages	0	The goal of alignment is to identify matching sentences between the languages	0	6	1
P94-1012	P91-1022	1994	In other words, the only feature of Lt and L2 that affects their alignment probability is their length	0	Note that there are other length-based alignment methods 81 that measure length in number of words instead of characters <TREF>Brown et al 1991</TREF>	1	However, since Chinese text consists of an unsegmented character stream without marked word boundaries, it would not be possible to count the number of words in a sentence without first parsing it	1	Although it has been suggested that lengthbased methods are language-independent <REF>Gale  Church 1991</REF>; <TREF>Brown et al 1991</TREF>, they may in fact rely to some extent on length correlations arising from the historical relationships of the languages being aligned	1	1	3
A94-1006	P91-1022	1994	Their method thus yields some incorrect noun phrases that will not be proposed by a tagger, but on the other hand does not miss noun phrases that may be missed due to tagging errors	0	3 Bilingual Task: An Application for Word Alignment 31 Sentence and word alignment Bilingual alignment methods <REF>Warwick et al , 1990</REF>; <TREF>Brown et al , 1991a</TREF>; <REF>Brown et al , 1993</REF>; <REF>Gale and Church, 1991b</REF>; <REF>Gale and Church, 1991a</REF>; <REF>Kay and Roscheisen, 1993</REF>; <REF>Simard et al , 1992</REF>; <REF>Church, 1993</REF>; <REF>Kupiec, 1993a</REF>; <REF>Matsumoto et al , 1993</REF>; <REF>Dagan et al , 1993</REF>	1	have been used in statistical machine translation <REF>Brown et al , 1990</REF>, terminology research and translation aids <REF>Isabelle, 1992</REF>; <REF>Ogden and Gonzales, 1993</REF>; van der <REF>Eijk, 1993</REF>, bilingual lexicography <REF>Klavans and Tzoukermann, 1990</REF>; <REF>Smadja, 1992</REF>, word-sense disambiguation <TREF>Brown et al , 1991b</TREF>; <REF>Gale et al , 1992</REF> and information retrieval in a multilingual environment <REF>Landauer and Littman, 1990</REF>	1	Most alignment work was concerned with alignment at the sentence level	0	6	1
A94-1006	P91-1022	1994	3 Bilingual Task: An Application for Word Alignment 31 Sentence and word alignment Bilingual alignment methods <REF>Warwick et al , 1990</REF>; <TREF>Brown et al , 1991a</TREF>; <REF>Brown et al , 1993</REF>; <REF>Gale and Church, 1991b</REF>; <REF>Gale and Church, 1991a</REF>; <REF>Kay and Roscheisen, 1993</REF>; <REF>Simard et al , 1992</REF>; <REF>Church, 1993</REF>; <REF>Kupiec, 1993a</REF>; <REF>Matsumoto et al , 1993</REF>; <REF>Dagan et al , 1993</REF>	0	have been used in statistical machine translation <REF>Brown et al , 1990</REF>, terminology research and translation aids <REF>Isabelle, 1992</REF>; <REF>Ogden and Gonzales, 1993</REF>; van der <REF>Eijk, 1993</REF>, bilingual lexicography <REF>Klavans and Tzoukermann, 1990</REF>; <REF>Smadja, 1992</REF>, word-sense disambiguation <TREF>Brown et al , 1991b</TREF>; <REF>Gale et al , 1992</REF> and information retrieval in a multilingual environment <REF>Landauer and Littman, 1990</REF>	1	Most alignment work was concerned with alignment at the sentence level	0	Algorithms for the more difficult task of word alignment were proposed in <REF>Gale and Church, 1991a</REF>; <REF>Brown et al , 1993</REF></REF>; <REF>Dagan et al , 1993</REF> and were applied for parameter estimation in the IBM statistical machine translation system <REF>Brown et al , 1993</REF></REF>	0	6	1
A94-1006	P91-1022	1994	Part-ofspeech taggers are used in a few applications, such as speech synthesis <REF>Sproat et al , 1992</REF> and question answering <REF>Kupiec, 1993b</REF>	0	Word alignment is newer, found only in a few places <REF>Gale and Church, 1991a</REF>; <REF>Brown et al , 1993</REF>; <REF>Dagan et al , 1993</REF>	0	It is used at IBM for estimating parameters of their statistical machine translation prototype Brown et Authors current address: Dept of Mathematics and Computer Science, Bar Ilan University, Ramat Gan 52900, Israel	0	al, 1993	0	6	1
A94-1006	P91-1022	1994	Most alignment work was concerned with alignment at the sentence level	0	Algorithms for the more difficult task of word alignment were proposed in <REF>Gale and Church, 1991a</REF>; <REF>Brown et al , 1993</REF></REF>; <REF>Dagan et al , 1993</REF> and were applied for parameter estimation in the IBM statistical machine translation system <REF>Brown et al , 1993</REF></REF>	1	Previously translated texts provide a major source of information about technical terms	0	<REF>As Isabelle 1992</REF> argues, Existing translations contain more solutions to more translation problems than any other existing resource	0	6	1
A00-1004	P91-1022	2000	Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages	0	A number of alignment techniques have been proposed, varying from statistical methods <TREF>Brown et al , 1991</TREF>; <REF>Gale and Church, 1991</REF> to lexical methods Kay and R<REF>Sscheisen, 1993</REF>; <REF>Chen, 1993</REF>	1	The method we adopted is t h a t of Simard et al	0	1992	0	6	1
P06-2035	P91-1022	2006	At finer-grained levels, methods are more sophisticated and combine linguistic clues with statistical ones	0	Statistical alignment methods at sentence level have been thoroughly investigated <REF>Gale  Church, 1991a</REF>/ 1991b ; <TREF>Brown et al , 1991</TREF> ; <REF>Kay  Rscheisen, 1993</REF>	1	Others use various linguistic information <REF>Simard et al , 1992</REF> ; <REF>Papageorgiou et al , 1994</REF>	0	Purely statistical alignment methods are proposed at word level <REF>Gale  Church, 1991a</REF> ; <REF>Kitamura  Matsumoto, 1995</REF>	0	6	1
P95-1032	P91-1022	1995	Existing lexicon compilation methods <REF>Kupiec 1993</REF>; <REF>Smadja  McKeown 1994</REF>; <REF>Kumano  Hirakawa 1994</REF>; <REF>Dagan et al 1993</REF>; <REF>Wu  Xia 1994</REF> all attempt to extract pairs of words or compounds that are translations of each other from previously sentencealigned, parallel texts	0	However, sentence alignment <TREF>Brown et al 1991</TREF>; Kay  R<REF>Sscheisen 1993</REF>; <REF>Gale  <REF>Church 1993</REF></REF>; <REF>Church 1993</REF>; <REF>Chen 1993</REF>; <REF>Wu 1994</REF> is not always practical when corpora have unclear sentence boundaries or with noisy text segments present in only one language	1	Our proposed algorithm for bilingual lexicon acquisition bootstraps off of corpus alignment procedures we developed earlier <REF>Fung  Church 1994</REF>; <REF>Fung  McKeown 1994</REF>	0	Those procedures attempted to align texts by finding matching word pairs and have demonstrated their effectiveness for Chinese/English and Japanese/English	0	1	3
W04-1121	P91-1022	2004	It can resolve the alignment problem on real bilingual text	0	There have been a number of papers on aligning parallel texts at the sentence level in the last century, eg, <TREF>Brown et al 1991</TREF>; <REF>Gale and Church, 1993</REF>; <REF>Simard et al 1992</REF>; <REF>Wu DeKai 1994</REF>	1	On clean inputs, such as the Canadian Hansards and the Hong Kang Hansards, these methods have been very successful	1	Church, Kenneth W, 1993; <REF>Chen, Stanley, 1993</REF> proposed some methods to resolve the problem in noisy bilingual texts	0	1	2
P97-1039	P91-1022	1997	Therefore, sentence mapping algorithms need not worry about crossing correspondences	0	<REF>In 1991</REF>, two teams of researchers independently discovered that sentences can be accurately aligned by matching sequences 310 with similar lengths <REF>Gale  Church, 1991a</REF>; <TREF>Brown et al , 1991</TREF>	1	Soon thereafter, <REF>Church 1993</REF> found that bitext mapping at the sentence level is not an option for noisy bitexts found in the real world	1	Sentences are often difficult to detect, especially where punctuation is missing due to OCR errors	1	1	3
P91-1023	P91-1022	1991	bank were surrendered by banc	0	SENT fair Although there has been some previous work on the sentence alignment, eg, <TREF>Brown, Lai, and Mercer, 1991</TREF>, <REF>Kay and Rtscheisen, 1988</REF>, Catizone et al , to appear, the alignment task remains a significant obstacle preventing many potential users from reaping many of the benefits of bilingual corpora, because the proposed solutions are often unavailable, unreliable, and/or computationally prohibitive	1	The align program is based on a very simple statistical model of character lengths	0	The model makes use of the fact that longer sentences in one language tend to be translated into longer sentences in the other language, and that shorter sentences tend to be translated into shorter sentences	0	1	3
C00-2135	P91-1022	2000	The result shows that the use of dependency relation helps to acquire interesting translation patterns	0	Since the advent of statistical methods in Machine qhanslation, the bilingual sentence alignmerit <TREF>Brown et al , 1991</TREF> or word alignment <REF>Dagan et al , 1992</REF> have been explored and achieved numerous success over the last decade	1	In coN;rasl,, fewer resull;s are reported in phraselevel correspondence	0	As word sequences are not translated literally a word for a word, acquiring phraseqevel correspondence still remains an important problem to be exploited	0	1	2
W07-0810	P91-1022	2007	Automatic sentence alignment approaches face two kinds of difficulties: robustness and accuracy	0	A number of automatic sentence alignment techniques have been proposed <REF>Kay and Rscheisen, 1993</REF>; <REF>Gale and Church, 1991</REF>; <TREF>Brown et al , 1991</TREF>; <REF>Debili and Samouda, 1992</REF>; <REF>Papageorgiou et al , 1994</REF>; <REF>Gaussier, 1995</REF>; <REF>Melamed, 1996</REF>; <REF>Fluhr et al , 2000</REF>	1	73 The method proposed in <REF>Kay and Rscheisen, 1993</REF> is based on the assumption that in order for the sentences in a translation to correspond, the words in them must correspond	0	In other words, all necessary information and in particular, lexical mapping is derived from the to-be-aligned texts themselves	0	6	1
W07-0810	P91-1022	2007	In other words, all necessary information and in particular, lexical mapping is derived from the to-be-aligned texts themselves	0	In <REF>Gale and Church, 1991</REF> and <TREF>Brown et al , 1991</TREF>, the authors start from the fact that the length of a source text sentence is highly correlated with the length of its target text translation: short sentences tend to have short translations, and long sentences tend to have long translations	1	The method proposed in <REF>Debili and Sammouda, 1992</REF> is based on the preliminary alignment of words using a conventional bilingual lexicon and the method described in <REF>Papageorgiou et al , 1994</REF> added grammatical labeling based on the assumption that the same parts of speech tend to be employed in the translation	0	In this paper, we present a sentence aligner which is based on a cross-language information retrieval approach and combines different information sources bilingual lexicon, sentence length and sentence position	0	6	1
C94-1026	P91-1022	1994	To do such kinds of researches, the most impmlant task is to align the bilingual texts	0	Many length-based alignment algorithms have been proposed <TREF>Brown et al , 1991</TREF>; <REF>Gale and Church, 1991a</REF>	1	The correct rates are good	1	However, the languages they processed belong to occidental family	1	1	3
C98-1066	P91-1022	1998	It remains to be seen how we can also make use of the multilingual texts as NLP resources	0	In the years since the appearance of the first papers on using statistical models for bilingual lexicon compilation and machine translation<REF>Brown et al, 1993</REF>; <TREF>Brown et al, 1991</TREF>; <REF>Gale and <REF>Church, 1993</REF></REF>; <REF>Church, 1993</REF>; <REF>Simard et al, 1992</REF>, large amount of human effort and time has been invested in collecting parallel corpora of translated texts	1	Our goal is to alleviate this effort and enlarge the scope of corpus resources by looking into monolingual, comparable texts	1	This type of texts are known as nonparallel corpora	0	2	1
W97-0114	P91-1022	1997	The technique for acquiring various kinds of rules such as translation rules, grammar rules, dictionary entries and so on from bilingual corpora needs to include several kinds of sub-techniques; identification of aligned sentence pairs which consist of pairs of one language sentence and translation equivalents of the sentence sentence alignment; identification of equivalent words/phrases pairs from aligned sentence pairs word alignment; and extraction of rules such as translation rules, grammar rules, dictionary entries and so on from identified aligned sentence pairs and equivalent word/phrase pairs	0	Several methods have been proposed with regard to aligning sentences <TREF>Brown et al , 1991</TREF>; <REF>Gale and Church, 1991</REF>; <REF>Haruno and Yamazaki, 1996</REF>; Kay and losche/sen, 1993, alJsnlng words <REF>Church, 1993</REF>; <REF>Kupiec, 1993</REF>; <REF>Matsumoto et al , 1993</REF>; <REF>Wu, 1995</REF>; <REF>Yamada et al , 1996</REF> and acquiring rules from bilingual corpora <REF>Dagan et al , 1991</REF>; <REF>Dagan and Church, 1994</REF>; <REF>Fung and Church, 1994</REF>; Tana, 1994; <REF>Yamada et al , 1995</REF>	1	From the point of view of the extraction of resolution rules of zero pronouns, a technique to identify zero pronouns in a sentence in one language and their antecedents in a translation from aligned sentence pairs is needed	0	But there is currently no method to identify zero pronouns and their antecedents automatically within bilingual corpora	0	6	1
W03-1503	P91-1022	2003	Therefore, we decided to extract NE translation pairs from content-aligned corpora, such as multilingual broadcast news articles including new NEs daily, which are not literally translated	0	Sentential alignment <TREF>Brown et al , 1991</TREF>; <REF>Gale and Church, 1993</REF>; <REF>Kay and Roscheisen, 1993</REF>; <REF>Utsuro et al , 1994</REF>; <REF>Haruno and Yamazaki, 1996</REF> is commonly used as a starting point for finding the translations of words or expressions from bilingual corpora	1	However, it is not always possible to correspond non-parallel corpora in sentences	1	Past statistical methods for non-parallel corpora <REF>Fung and Yee, 1998</REF> are not valid for finding translations of words or expressions with low frequency	0	1	3
C98-1042	P91-1022	1998	Many software products which aid human translators now contain sentence alignment tools as an aid to speeding up editing and terminology searching	0	Various methods have been developed for sentence alignment which we can categorise as either lexical such as <REF>Chen, 1993</REF>, based on a large-scale bilingual lexicon; statistical such as <TREF>Brown et al, 1991</TREF> <REF>Church, 1993</REF>Gale and <REF>Church, 1993</REF><REF>Kay and Rhshcheisen, 1993</REF>, based on distributional regularities of words or byte-lengdl ratios and possibly inducing a bilingual lexicon as a by-product, or hybrid such as <REF>Vtsuro et al, 1994</REF> <REF>Wu, 1994</REF>, based on some combination of the other two	1	Neither of the pure approaches is entirely satisfactory for the following reasons:  Text volume limits the usefulness of statistical approaches	1	We would often like to be able to align small amounts of text, or texts from various domains which do not share the same statistical properties	0	1	3
W02-1211	P91-1022	2002	The performance tends to deteriorate significantly when these approaches are applied to noisy complex corpora with sentence omission or insertion, less literal translation	0	There are basically three kinds of approaches on sentence alignment: the length-based approach <REF>Gale  Church 1991</REF> and <TREF>Brown et al 1991</TREF>, the lexical approach key  <REF>Roscheisen 1993</REF>, and the combination of them <REF>Chen 1993</REF>, <REF>Wu 1994</REF> and <REF>Langlais 1998</REF>, etc	1	The first published algorithms for aligning sentences in parallel texts are length-based approach proposed by <REF>Gale  Church 1991</REF> and <REF>Brow et al 1991</REF>	1	Based on the observation that short sentences tend to be translated as short sentences and long sentences as long sentences, they calculate the most likely sentence correspondences as a function of the relative length of the candidates	0	6	1
W05-0816	P91-1022	2005	For Brn and GC, the search method was based on the one used by Moore, ie, searching within a growing diagonal band	0	Using this search method meant that no prior segmentation of the corpora was needed <REF>Moore, 2002</REF>, either in terms of aligned paragraphs <REF>Gale and Church, 1991</REF>, or some aligned sentences as anchors <TREF>Brown et al , 1991</TREF>	1	We would have liked to study the effect of linguistic distance more systematically, but we couldnt get equivalent manually-checked aligned parallel corpora for other pairs of languages	0	We have to rely on the reported results for other language pairs, but those results, as mentioned before, do not mention the conditions of testing which we are considering for our evaluation and, therefore, cannot be directly compared to our results for English-Hindi	0	6	1
W05-0816	P91-1022	2005	Sentence length methods were based on the intuition that the length of a translated sentence is likely to be similar to that of the source sentence	0	Brown, Lai and Mercer <TREF>Brown et al , 1991</TREF> used word count as the sentence length, whereas Gale and Church <REF>Gale and Church, 1991</REF> used character count	1	Brown, Lai and Mercer assumed prior alignment of paragraphs	0	Gale and Church relied on some previously aligned sentences as anchors	0	5	1
C94-2178	P91-1022	1994	1	0	Motivation There have been quite a number of recent papers on parallel text: Brown et al 1990, 1991, 1993, <REF>Chen 1993</REF>, <REF>Church 1993</REF>, <REF>Church et al 1993</REF>, <REF>Dagan et al 1993</REF>, Gale and Church 1991, 1993, <REF>Isabelle 1992</REF>, <REF>Kay and Rgsenschein 1993</REF>, <REF>Klavans and Tzoukermann 1990</REF>, <REF>Kupiec 1993</REF>, <REF>Matsumoto 1991</REF>, <REF>Ogden and Gonzales 1993</REF>, <REF>Shemtov 1993</REF>, <REF>Simard et al 1992</REF>, <REF>WarwickArmstrong and Russell 1990</REF>, Wu to appear	1	Most of this work has been focused on European language pairs, especially English-French	1	It remains an open question how well these methods might generalize to other language pairs, especially pairs such as English-Japanese and EnglishChinese	1	1	3
W93-0301	P91-1022	1993	This is compared with the previous rate of about 30 terms per hour using charaligns output, and an extremely lower rate before alignment tools were available	0	4 Conclusions Compared with other word alignment algorithms <REF>Brown et al , 1993</REF>; <REF>Gale and Church, 1991a</REF>, wordalign does not require sentence alignment as input, and was shown to produce useful alignments for small and noisy corpora	1	Its robustness was achieved by modifying Brown et als Model 2 to handle an initial rough alignment, reducing the number of parameters and introducing a dependency between alignments of adjacent words	0	Taking the output of charalign as input, wordalign produces significantly better, word7 Offset from correct alignment 0 1 2 3 4 Percentage 605 108 75 52 16 Accumulative percentage 605 713 788 84 856 Table 2: Wordaligns precision on noisy input, scanned by an OCR device	0	1	2
W93-0301	P91-1022	1993	To deal with these robustness issues, <REF>Church 1993</REF> developed a character-based alignment method called charalign	0	The method was intended as a replacement for sentence-based methods eg , <TREF>Brown et al , 1991a</TREF>; <REF>Gale and Church, 1991b</REF>; <REF>Kay and Rosenschein, 1993</REF>, which are very sensitive to noise	1	This paper describes a new program, called wordalign, that starts with an initial rough alignment eg , the output of charalign or a sentence-based alignment method, and produces improved alignments by exploiting constraints at the word-level	0	The alignment algorithm consists of two steps: 1 estimate translation probabilities, and 2 use these probabilities to search for most probable alignment path	0	1	3
W93-0301	P91-1022	1993	More importantly, because wordalign and charalign were designed to work robustly on texts that are smaller and more noisy than the Hansards, it has been possible to successfully deploy the programs at ATT Language Line Services, a commercial translation service, to help them with difficult terminology	0	Aligning parallel texts has recently received considerable attention <REF>Warwick et al , 1990</REF>; <TREF>Brown et al , 1991a</TREF>; <REF>Gale and Church, 1991b</REF>; <REF>Gale and Church, 1991a</REF>; <REF>Kay and Rosenschein, 1993</REF>; <REF>Simard et al , 1992</REF>; <REF>Church, 1993</REF>; <REF>Kupiec, 1993</REF>; <REF>Matsumoto et al , 1993</REF>	1	These methods have been used in machine translation <REF>Brown et al , 1990</REF>; <REF>Sadler, 1989</REF>, terminology research and translation aids <REF>Isabelle, 1992</REF>; <REF>Ogden and Gonzales, 1993</REF>, bilingual lexicography <REF>Klavans and Tzoukermann, 1990</REF>, collocation studies <REF>Smadja, 1992</REF>, word-sense disambiguation <TREF>Brown et al , 1991b</TREF>; <REF>Gale et al , 1992</REF> and information retrieval in a multilingual environment <REF>Landauer and Littman, 1990</REF>	0	The information retrieval application may be of particular relevance to this audience	0	6	1
W93-0301	P91-1022	1993	Aligning parallel texts has recently received considerable attention <REF>Warwick et al , 1990</REF>; <TREF>Brown et al , 1991a</TREF>; <REF>Gale and Church, 1991b</REF>; <REF>Gale and Church, 1991a</REF>; <REF>Kay and Rosenschein, 1993</REF>; <REF>Simard et al , 1992</REF>; <REF>Church, 1993</REF>; <REF>Kupiec, 1993</REF>; <REF>Matsumoto et al , 1993</REF>	0	These methods have been used in machine translation <REF>Brown et al , 1990</REF>; <REF>Sadler, 1989</REF>, terminology research and translation aids <REF>Isabelle, 1992</REF>; <REF>Ogden and Gonzales, 1993</REF>, bilingual lexicography <REF>Klavans and Tzoukermann, 1990</REF>, collocation studies <REF>Smadja, 1992</REF>, word-sense disambiguation <TREF>Brown et al , 1991b</TREF>; <REF>Gale et al , 1992</REF> and information retrieval in a multilingual environment <REF>Landauer and Littman, 1990</REF>	1	The information retrieval application may be of particular relevance to this audience	0	It would be highly desirable for users to be able to express queries in whatever language they chose and retrieve documents that may or may not have been written in the same language as the query	0	6	1
A92-1031	P91-1022	1992	That is, one cannot pick two anchor points, one in each text, and have the program align the corresponding regions above and below the anchor points	0	See <TREF>Brown et al , 1991</TREF> for discussion of an alternative	1	This is not necessarily a problem either, and can be worked around	0	Lastly, it does not give usable results on texts which are not absolutely parallel	0	2	1
W03-0315	P91-1022	2003	One way to remedy this situation is to adapt and retrain the system parameters based on bilingual data from the same source or at least a closely related source	0	A bilingual sentence alignment program <REF>Gale and Church, 1991</REF>, and <TREF>Brown et al , 1991</TREF> is the crucial part in this adaptation procedure, in that it collects bilingual document pairs from the Internet, and identifies sentence pairs, which should have a high likelihood of being correct translations of each other	1	The set of identified bilingual parallel sentence pairs is then added to the training set for parameter reestimation	0	As is well known, text mined from the Internet is very noisy	0	6	1
J94-4003	P91-1030	1994	20 The method of acquiring parameters from ambiguous occurrences in a corpus, relying on the spreading of noise, can be used in many contexts	1	For example, it was used for acquiring statistics for disambiguating prepositional phrase attachments, counting ambiguous occurrences of prepositional phrases as representing both noun-pp and verb-pp constructs <TREF>Hindle and Rooth 1991</TREF>	0	588 Ido Dagan and Alon Itai Word Sense Disambiguation vides a useful source of a sense tagged corpus	0	<REF>Gale, Church, and Yarowsky 1992a</REF> have also exploited this resource for achieving large amounts of testing and training materials	0	1	2
J94-4003	P91-1030	1994	The use of such relations mainly relations between verbs or nouns and their arguments and modifiers for various purposes has received growing attention in recent research <REF>Church and Hanks 1990</REF>; <REF>Zernik and Jacobs 1990</REF>; <REF>Hindle 1990</REF>; <REF>Smadja 1993</REF>	0	More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment <TREF>Hindle and Rooth 1991</TREF> and pronoun references <REF>Dagan and Itai 1990, 1991</REF>	0	Clearly, statistics on lexical relations can also be useful for target word selection	1	Consider, for example, the Hebrew sentence extracted from the foreign news section of the daily Ha-<REF>Aretz, September 1990</REF> transcripted to Latin letters: 1 Nose ze mana mi-shtei ha-mdinot mi-lahtom al hoze shalom	0	1	2
J95-1001	P91-1030	1995	Content words that have a close syntactic relation to one another are useful candidates for examination and are intuitively more likely to bear a close semantic relation than words that are near one another but are not related syntactically	0	One much-studied example is the semantic relation between a verb and its arguments eg , <REF>Boguraev et al 1989</REF>; <REF>Church and Hanks 1989</REF>; Braden-<REF>Harder 1991</REF>; <TREF>Hindle and Rooth 1991</TREF>	1	Discrimination among senses of adjectives based on the nouns they modify or of which they are predicated has been the subject of less intensive and systematic study	0	Determining the potential of this line of evidence is the focus of this paper	0	6	1
P93-1022	P91-1030	1993	or the cooccurrence of two words within a limited distance in the context	0	Statistical data about these various cooccurrence relations is employed for a variety of applications, such as speech recognition <REF>Jelinek, 1990</REF>, language generation <REF>Smadja and McKeown, 1990</REF>, lexicography <REF>Church and Hanks, 1990</REF>, machine translation Brown et al , ; <REF>Sadler, 1989</REF>, information retrieval <REF>Maarek and Smadja, 1989</REF> and various disambiguation tasks <REF>Dagan et al , 1991</REF>; <TREF>Hindle and Rooth, 1991</TREF>; <REF>Grishman et al , 1986</REF>; <REF>Dagan and Itai, 1990</REF>	0	A major problem for the above applications is how to estimate the probability of cooccurrences that were not observed in the training corpus	1	Due to data sparseness in unrestricted language, the aggregate probability of such cooccurrences is large and can easily get to 25 or more, even for a very large training corpus <REF>Church and Mercer, 1992</REF>	0	1	3
J03-4003	P91-1030	2003	Earlier work that is of particular relevance considered the importance of relations between lexical heads for disambiguation in parsing	0	<REF>See Hindle and Rooth 1991</REF> for one of the earliest pieces of research on this topic in the context of prepositional-phrase attachment ambiguity	1	For work that uses lexical relations for parse disambiguation all with very promising resultssee Sekine et al	0	1992, Jones and Eisner 1992a, 1992b, and <REF>Alshawi and Carter 1994</REF>	0	6	1
H92-1047	P91-1030	1992	Some of our initial data suggest that the hypothesis of deep semantic selection may in fact be correct, as well as indicating what the nature of the coercion rules may be	0	Using techniques described in <REF>Church and Hindle 1990</REF>, <REF>Church and Hanks 1990</REF>, and <TREF>Hindle and Rooth 1991</TREF>, below are some examples of the most frequent V-O pairs from the AP corpus	1	Counts for objects of begin/V: 205 begin/V career/O 176 begin/V day/O 159 begin/V work/O 140 begin/V talk/O 120 begin/V campaign/O 113 begin/V investigation/O 106 begin/V process/O 92 begin/V program/O 8S begin/V operation/O 86 begin/V negotiation/O 66 begin/V strike/O 64 begin/V production/O 59 begin/V meeting/O 89 begin/V term/O 50 begin/V visit/O 45 begin/V test/O 39 begin/V construction/O 31 begin/V debate/O 29 begin/V trial/O Corpus studies confirm similar results for weakly intensional contexts <REF>Pustejovsky 1991</REF> such as the complement of coercive verbs such as veto	0	These are interesting because regardless of the noun type appearing as complement, it is embedded within a semantic interpretation of the proposal to, thereby clothing the complement within an intensional context	0	3	2
J93-2005	P91-1030	1993	Some of our initial data suggest that the hypothesis of deep semantic selection may in fact be correct, as well as indicating what the nature of the coercion rules may be	0	Using techniques described in <REF>Church and Hindle 1990</REF>, <REF>Church and Hanks 1990</REF>, and <TREF>Hindle and Rooth 1991</TREF>, Figure 4 shows some examples of the most frequent V-O pairs from the AP corpus	1	Corpus studies confirm similar results for weakly intensional contexts such as the complement of coercive verbs such as veto	0	These are interesting because regardless of the noun type appearing as complement, it is embedded within a semantic interpretation of the proposal to, thereby clothing the complement within an intensional context	0	3	2
W04-1501	P91-1030	2004	In fact, a large amount of ambiguity such as coordination, Noun-Noun compounds and relative clause attachment can be resolved using such a kind of information, and relations can provide a useful interface between syntax and semantics	0	<TREF>Hindle and Rooth, 1991</TREF> had shown the use of dependency in Prepositional Phrase disambiguation, and the experimental results reported in <REF>Hockenmaier, 2003</REF> demonstrate that a language model which encodes a rich notion of predicate argument structure eg including long-range relations arising through coordination can significantly improve the parsing performances	1	Moreover, the notion of predicate argument structure has been advocated as useful in a number of dierent large-scale languageprocessing tasks, and the RS is a convenient intermediate representation in several applications see <REF>Bosco, 2004</REF> for a survey on this topic	0	For instance, in Information Extraction relations allows for recognizing dierent guises in which an event can appear regardless of the several dierent syntactic patterns that can be used to specify it <REF>Palmer et al , 2001</REF> 2 In Question Answering, systems usually use forms of relation-based structured representations of the input texts ie questions and answers and try to match those representations see eg	0	6	1
J99-2007	P91-1030	1999	There has not been a general method proposed to date, however, that learns dependencies between case slots	0	Methods of resolving ambiguities have been based, for example, on the assumption that case slots are mutually independent <TREF>Hindle and Rooth 1991</TREF>, or at most two case slots are dependent <REF>Collins and Brooks 1995</REF>	0	In this article, we propose an efficient and general method of learning dependencies between case frame slots	1	2	0	5	2
J99-2007	P91-1030	1999	Obviously, if we assume that case slots are independent, then we only need to compare PflyXfrom  1 and PietXfrom  1	0	This is nearly equivalent to the disambiguafion method proposed by <TREF>Hindle and Rooth 1991</TREF>	1	Their method, referred to here as the Lexical Association LA method, actually compares the two probabilities by means of hypothesis testing	0	Specifically, it calculates the so-called t-score, which is a statistic about the difference between the two probabilities	0	2	1
W96-0112	P91-1030	1996	We use the definition of lexical likelihood described above to avoid this problem	0	4 32 The data sparseness problem Hindle  Rooth have previously proposed resolving pp-attachment ambiguities with two-word probabilities <TREF>Hindle and Rooth, 1991</TREF>, eg, Pwithlicecream,Pwithleat, but these are not accurate enough to represent lexical preference	1	For example, in the sentences, Britain reopened the embassy in December, Britain reopened the embassy in Teheran, 10 the pp-attachment sites of the two prepositional phrases are different	0	The attachment sites would be determined to be the same, however, if we were to use two-word probabilities c:f<REF>Resnik, 1993</REF>, and thus the ambiguity of only one of the sentences can be resolved	0	1	3
W96-0112	P91-1030	1996	There have been a number of methods proposed to perform structural disambiguation using probability models, many of which have proved to be quite effective <REF>Alshawi and Carter, 1995</REF>; <REF>Black et al , 1992</REF>; Briscoe and Carroll	0	1993; <REF>Chang et al , 1992</REF>; <REF>Collins and Brooks, 1995</REF>; <REF>Fujisaki, 1989</REF>; <TREF>Hindle and Rooth, 1991</TREF>; <REF>Hindle and Rooth, 1993</REF>; <REF>Jelinek et al , 1990</REF>; <REF>Magerman and Marcus, 1991</REF>; <REF>Magerman, 1995</REF>; <REF>Ratnaparkhi et al , 1994</REF>; <REF>Resnik, 1993</REF>; <REF>Su and Chang, 1988</REF>	0	Although each of the disambiguation methods proposed to date has its merits, none resolves the disambiguation problem completely satisfactorily	1	We feel that it is necessary to devise a new method that unifies the above two approaches, ie, to implement psycholinguistic principles of disambiguation on the basis of a probabilistic methodology	0	1	3
W96-0112	P91-1030	1996	Thus our problem involves the following three subproblems: a resolving structural ambiguities based on LPR in terms of probabilistic representations, b resolving structural ambiguities based on RAP and ALPP in terms of probabilistic representations, and c combining the two	0	For subproblem a, we have devised a new method, based on LPR, which has some good properties not shared by the methods proposed so far <REF>Alshawi and Carter, 1995</REF>; <REF>Chang et al , 1992</REF>; <REF>Collins and Brooks, 1995</REF>; <TREF>Hindle and Rooth, 1991</TREF>; <REF>Ratnaparkhi et al , 1994</REF>; <REF>Resnik, 1993</REF>	1	In <REF>Li and Abe, 1995</REF>, we have described this method in detail	0	In the present paper, we mainly describe our solutions to subproblems b and c	0	1	3
W96-0112	P91-1030	1996	If we employ the Maximum Likelihood Estimator, we may find most of the parameters are estimated to be 0: a problem often referred to, in statistical natural language processing, as the data sparseness problem	0	the motivation for using the two-word probabilities in <TREF>Hindle and Rooth, 1991</TREF> appears to be a desire to avoid the data sparseness problem	1	 One may expect this problem to be less severe in the future, when more data are available	0	However, as data size increases, new words may appear, and the number of parameters that need to be estimated may increase as well	0	6	1
A92-1014	P91-1030	1992	We expect that the knowledge to be extracted will not only be useful for disambiguating sentences but also will contribute to discovering ontological classes in given subject domains	0	Though several studies with similar objectives have been reported <REF>Church, 1988</REF>, <REF>Zernik and Jacobs, 1990</REF>, <REF>Calzolari and Bindi, 1990</REF>, <REF>Garside and Leech, 1985</REF>, <TREF>Hindle and Rooth, 1991</TREF>, <REF>Brown et al , 1990</REF>, they require that sample corpora be correctly analyzed or tagged in advance	1	It must be a training corpus, which is tagged or parsed by human or it needs correspondence between two language corpora	0	Because their preparation needs a lot of manual assistance or an unerring tagger or parser, this requirement makes their algorithm, troublesome in actual application environments	0	1	3
J93-1002	P91-1030	1993	In general, these words will not be adjacent in the text, so it will not be possible to use existing approaches unmodified eg <REF>Church and Hanks 1989</REF>, because these apply to adjacent words in unanalyzed text	0	<TREF>Hindle and Rooth 1991</TREF> report good results using a mutual information measure of collocation applied within such a structurally defined context, and their approach should carry over to our framework straightforwardly	1	One way of integrating structural collocational information into the system presented above would be to make use of the semantic component of the ANLT grammar This component pairs logical forms with each distinct syntactic analysis that represent, among other things, the predicate-argument structure of the input	0	In the resolution of PP attachment and similar ambiguities, it is collocation at this level of representation that appears to be most relevant	0	1	2
P92-1028	P91-1030	1992	The corpus is relatively small it contains approximately 450,000 words and 18,750 sentences	0	In comparison, most corpus-based algorithms employ substantially larger corpora eg , 1 million words de <REF>Marcken, 1990</REF>, 25 million words <REF>Brent, 1991</REF>, 6 million words <REF>Hindle, 1990</REF>, 13 million words <REF>Hindle,  Rooth, 1991</REF>	1	Relative pronoun processing is especially important for the MUC-3 corpus because approximately 25 of the sentences contain at least one relative pronoun	0	3 In fact, the relative pronoun who occurs in approximately 1 out of every 10 sentences	0	6	1
A92-1013	P91-1030	1992	For example, we can learr that make decision is a better choice than, say 96 have decision or take decision	0	<REF>Hindle and Rooths, 1991</REF> proposes that a syntactic disambiguation criterion can be gathered by comparing the probability of occurrence of nounpreposition and verb-preposition pairs in V NP PP structures	1	In general word associations are collected by extracting word pairs in a -5 window	0	In <REF>Calzolari and Bindi, 1990</REF>, <REF>Church and Hanks, 1990</REF> the significance of an association x,y is measured by the mutual information Ix,y, ie the probability of observing x and y together, compared with the probability of observing x and y independently	0	6	1
A92-1013	P91-1030	1992	2 Acquiring syntactic associations Clustered association data are collected by first extracting from the corpus all the syntactically related word pairs	0	Combining statistical and parsing methods has been done by <REF>Hindle, 1990</REF>; Hindle and Rooths,1991 and <REF>Smadja and McKewon, 1990</REF>; Smadja,1991	0	The novel aspect of our study is that we collect not only operational pairs, but triples, such as Nprep N, VprepN etc In fact, the preposition convey important information on the nature of the semantic link between syntactically related content words	1	By looking at the preposition, it is possible to restrict the set of semantic relations underlying a syntactic relation eg forpurpose,beneficiary	0	5	2
A92-1013	P91-1030	1992	In <REF>Smadja, 1989</REF>, <REF>Zernik and Jacobs, 1990</REF>, the associations are filtered by selecting the word pairs x,y whose frequency of occurrence is above fks, where f is the average appearance, s is the standard deviation, and k is an empirically determined factor	0	<REF>Hindle, 1990</REF>; Hindle and Rooths,1991 and <REF>Smadja, 1991</REF> use syntactic markers to increase the significance of the data	1	<REF>Guthrie et al , 1991</REF> uses the subject classification given in machine-readable dictionaries eg economics, engineering, etc	0	to reinforce cooccurence links	0	6	1
C92-1033	P91-1030	1992	Much of the overhead and inefficiency comes from the fact that the lexical and structural ambiguity of natmal language input can only be dealt with using limited context information available to the parser	0	Partial parsing techniques have been used with a considerable success in processing large volumes of text, for example ATTs Fidditch <TREF>Hindle and Rooth, 1991</TREF> parsed 13 million words of Associated Press news messages, while MITs parser de <REF>Marcken, 1990</REF> was used to process the 1 million word Lancaster/Oslo/Bergen LOB corpus	1	In both cases, the parsers were designed to do partial processing only, that is, they would never attempt a complete analysis of certain constructions, such as the attachment of pp-adjuncts, subordinate clauses, or coordinations	0	This kind of partial analysis may be sufficient in some applications because of a relatively high precision of identifying correct syntactic dependencies	0	1	2
C92-1033	P91-1030	1992	The experiments were performed within an information retrieval system so that the final recall and precision statistics were used to rnealurc effectiwmess of the panmr	0	a <TREF>Hindle and Rooth 1991</TREF> and <REF>Church and Hanks 1990</REF> used partial parses generated by Fidditch to study word urrtnc patterns m syntactic contexts	1	ACRES DE COLING-92, NANTES, 23-28 AOr 1992 1 9 8 PROC	0	OF COL1NG-92	0	6	1
P93-1032	P91-1030	1993	FUTURE DIRECTIONS This paper presented one method of learning subcategorizations, but there are other approaches one might try	0	For disambiguating whether a PP is subcategorized by a verb in the V NP PP environment, <TREF>Hindle and Rooth 1991</TREF> used a t-score to determine whether the PP has a stronger association with the verb or the preceding NP	0	This method could be usefully incorporated into my parser, but it remains a special-purpose technique for one particular ease	1	Another research direction would be making the parser stochastic as well, rather than it being a categorical finite state device that runs on the output of a stochastic tagger	0	1	2
P06-2029	P91-1030	2006	This successful reuse indicates that lexical preference between prepositions and function words is largely independent of text type	0	<TREF>Hindle and Rooth, 1991</TREF> first proposed solving the prepositional attachment task with the help of statistical information, and also defined the prevalent formulation as a binary decision problem with three words involved	1	<REF>Ratnaparkhi et al , 1994</REF> 228 extended the problem instances to quadruples by also considering the kernel noun of the PP, and used maximum entropy models to estimate the preferences	0	Both supervised and unsupervised training procedures for PP attachment have been investigated and compared in a number of studies, with supervised methods usually being slightly superior <REF>Ratnaparkhi, 1998</REF>; <REF>Pantel and Lin, 2000</REF>, with the notable exception of <REF>Volk, 2002</REF>, who obtained a worse accuracy in the supervised case, obviously caused by the limited size of the available treebank	0	6	1
P06-2029	P91-1030	2006	One reason for this is that many rule-driven syntax analyzers provide no obvious way to integrate uncertain, statistical information into their decisions	0	Another is the traditional emphasis on PP attachment as a binary classification task; since <TREF>Hindle and Rooth, 1991</TREF>, research has concentrated on resolving the ambiguity in the category pattern VNPN, ie predicting the PP attachment to either the verb or the first noun	1	It is often assumed that the correct attachment is always among these 223 two options, so that all problem instances can be solved correctly despite the simplification	0	This task is sufficient to measure the relative quality of different probability models, but it is quite different from what a parser must actually do: It is easier because the set of possible answers is pre-filtered so that only a binary decision remains, and the baseline performance for pure guessing is already 50	0	6	1
P06-2029	P91-1030	2006	This task is sufficient to measure the relative quality of different probability models, but it is quite different from what a parser must actually do: It is easier because the set of possible answers is pre-filtered so that only a binary decision remains, and the baseline performance for pure guessing is already 50	0	But it is harder because it does not provide the predictor with all the information needed to solve many doubtful cases; <TREF>Hindle and Rooth, 1991</TREF> found that human arbiters consistently reach a higher agreement when they are given the entire sentence rather than just the four words concerned	1	Instead of the accuracy of PP attachers in the isolated decision between two words, we investigate the problem of situated PP attachment	0	In this task, all nouns and verbs in a sentence are potential attachment points for a preposition; the computer must find suitable attachments for one or more prepositions in parallel, while building a globally coherent syntax structure at the same time	0	6	1
J98-2002	P91-1030	1998	Verb CPU Time second Average Number of Generalized Levels eat 100 52 buy 066 46 fly 111 60 operate 090 50 Average 092 52 many probabilistic methods proposed in the literature to address the PP-attachment problem using lexical semantic knowledge which, in our view, can be classified into three types	0	The first approach <REF>Hindle and Rooth 1991, 1993</REF> takes doubles of the form verb, prep and nounl, prep, like those in Table 9, as training data to acquire semantic knowledge and judges the attachment sites of the prepositional phrases in quadruples of the form verb, nounl, prep, noun2 eg, see, girl, with, telescope--based on the acquired knowledge	0	<TREF>Hindle and Rooth 1991</TREF> proposed the use of the lexical association measure calculated based on such doubles	1	More specifically, they estimate Pprep I verb and Pprep  noun1, and calculate the so-called t-score, which is a measure of the statistical significance of the difference between Pprep I verb and Pprep  nounl	0	6	1
J98-2002	P91-1030	1998	The first approach <REF>Hindle and Rooth 1991, 1993</REF> takes doubles of the form verb, prep and nounl, prep, like those in Table 9, as training data to acquire semantic knowledge and judges the attachment sites of the prepositional phrases in quadruples of the form verb, nounl, prep, noun2 eg, see, girl, with, telescope--based on the acquired knowledge	0	<TREF>Hindle and Rooth 1991</TREF> proposed the use of the lexical association measure calculated based on such doubles	1	More specifically, they estimate Pprep I verb and Pprep  noun1, and calculate the so-called t-score, which is a measure of the statistical significance of the difference between Pprep I verb and Pprep  nounl	0	If the t-score indicates that the former probability is significantly larger, 233 Computational Linguistics Volume 24, Number 2 Table 9 Example input data as doubles	0	6	1
J98-2002	P91-1030	1998	The generalization step is needed in order to represent the input case frame instances more compactly as well as to judge the degree of acceptability of unseen case frame instances	0	For the extraction problem, there have been various methods proposed to date, which are quite adequate <TREF>Hindle and Rooth 1991</TREF>; <REF>Grishman and Sterling 1992</REF>; <REF>Manning 1992</REF>; <REF>Utsuro, Matsumoto, and Nagao 1992</REF>; <REF>Brent 1993</REF>; <REF>Smadja 1993</REF>; <REF>Grefenstette 1994</REF>; <REF>Briscoe and Carroll 1997</REF>	1	The generalization problem, in contrast, is a more challenging one and has not been solved completely	0	A number of methods for generalizing values of a case frame slot for a verb have been  CC Media Res	0	1	2
J98-2002	P91-1030	1998	236 Li and Abe Generalizing Case Frames Table 13 Results of PP-attachment disambiguation	0	Coverage Accuracy Default 100 562 MDL  Default 100 822 SA  Default 100 767 LA  Default 100 807 LAt  Default 100 781 TEL 100 824 We also implemented the exact method proposed by <TREF>Hindle and Rooth 1991</TREF>, which makes disambiguation judgement using the t-score	1	Figure 10 shows the result as LAt, where the threshold for t-score is set to 128 significance level of 90 percent	0	From Figure 10 we see that with respect to accuracy-coverage curves, MDL outperforms both SA and LA throughout, while SA is better than LA Next, we tested the method of applying a default rule after applying each method	0	3	2
J98-2002	P91-1030	1998	We estimate Pnoun2 I verb, prep and Pnoun2 I nount, prep from training data consisting of triples, and compare them: If the former exceeds the latter by a certain margin we attach it to verb, else if the latter exceeds the former by the same margin we attach it to noun1	0	In our experiments, described below, we compare the performance of our proposed method, which we refer to as MDL, against the methods proposed by <TREF>Hindle and Rooth 1991</TREF>, <REF>Resnik 1993b</REF>, and <REF>Brill and Resnik 1994</REF>, referred to respectively as LA, SA, and TEL	1	Data Set	0	We used the bracketed corpus of the Penn Treebank Wall Street Journal corpus <REF>Marcus, Santorini, and Marcinkiewicz 1993</REF> as our data	0	2	3
D08-1109	P91-1034	2008	Examples of such efforts include work on the induction of synchronous grammars <REF>Wu and Wong, 1998</REF>; <REF>Chiang, 2005</REF> and learning multilingual lexical resources <REF>Genzel, 2005</REF>	0	Another thread of work using cross-lingual links has been in word-sense disambiguation, where senses of words can be defined based on their translations <TREF>Brown et al, 1991</TREF>; <REF>Dagan et al, 1991</REF>; <REF>Resnik and Yarowsky, 1997</REF>; <REF>Ng et al, 2003</REF>	1	When annotations for a task of interest are available in a source language but are missing in the target language, the annotations can be projected across a parallel corpus <REF>Yarowsky et al, 2000</REF>; <REF>Diab and Resnik, 2002</REF>; <REF>Pado and Lapata, 2006</REF>; <REF>Xi and Hwa, 2005</REF>	0	In fact, projection methods have been used to train highly accurate part-of-speech taggers <REF>Yarowsky and Ngai, 2001</REF>; <REF>Feldman et al, 2006</REF>	0	6	1
J94-4003	P91-1034	1994	Finally, in Section 7 we present a comparative analysis of statistical sense disambiguation methods and then conclude in Section 8	0	2 A similar observation underlies the use of parallel bilingual corpora for sense disambiguation <TREF>Brown et al 1991</TREF>; <REF>Gale, Church, and Yarowsky 1992</REF>	1	As we explain in Section 7, these corpora are a form of a manually tagged corpus and are more difficult to obtain than monolingual corpora	0	Erroneously, the preliminary publication of our method <REF>Dagan, Itai, and Schwall 1991</REF> was cited several times as requiring a parallel bilingual corpus, 565 Computational Linguistics Volume 20, Number 4 2	0	6	1
J94-4003	P91-1034	1994	Sense disambiguation thus resembles many other decision tasks, and not surprisingly, several common decision algorithms were employed in different works	0	These include a Bayesian classifier <REF>Gale, Church, and Yarowsky 1993</REF> and a distance 589 Computational Linguistics Volume 20, Number 4 metric between vectors <REF>Schiitze 1993</REF>, both inspired from methods in information retrieval; the use of the flip-flop algorithm for ordering possible informants about the preferred sense, trying to maximize the mutual information between the informant and the ambiguous word <TREF>Brown et al 1991</TREF>; and the use of confidence intervals to establish the degree of confidence in a certain preference, combined with a constraint propagation algorithm the current paper	0	At the present stage of research on sense disambiguation, it is difficult to judge whether a certain decision algorithm is significantly superior to others	0	21 Yet, these decision models can be characterized by several criteria, which clarify the similarities and differences between them	1	4	2
J94-4003	P91-1034	1994	It seems, however, that Brown et al expect that target word selection would be determined mainly by translation probabilities the second factor in the above term, which should be derived from a bilingual corpus <REF>Brown et al 1990</REF>, p 79	0	This view is reflected also in their elaborate method for target word selection <TREF>Brown et al 1991</TREF>, in which better estimates of translation probabilities are achieved as a result of word sense disambiguation	0	Our method, on the other hand, incorporates only 592 Ido Dagan and Alon Itai Word Sense Disambiguation target language probabilities and ignores any notion of translation probabilities	1	It thus demonstrates a possible trade-off between these two types of probabilities: using more informative statistics of the target language may compensate for the lack of translation probabilities	0	2	3
P01-1067	P91-1034	2001	Model parameters are automatically estimated using a corpus of translation pairs	0	TMs have been used for statistical machine translation <REF>Berger et al , 1996</REF>, word alignment of a translation corpus <REF>Melamed, 2000</REF>, multilingual document retrieval <REF>Franz et al , 1999</REF>, automatic dictionary construction <REF>Resnik and Melamed, 1997</REF>, and data preparation for word sense disambiguation programs <TREF>Brown et al , 1991</TREF>	0	Developing a better TM is a fundamental issue for those applications	1	Researchers at IBM first described such a statistical TM in <REF>Brown et al , 1988</REF>	0	1	3
J01-3001	P91-1034	2001	A third difference concerns the granularity of WSD attempted, which one can illustrate in terms of the two levels of semantic distinctions found in many dictionaries: homograph and sense see Section 31	0	Like <REF>Cowie, Guthrie, and Guthrie 1992</REF>, we shall give results at both levels, but it is worth pointing out that the targets of, say, work using translation equivalents eg , <TREF>Brown et al 1991</TREF>; <REF>Gale, Church, and <REF>Yarowsky 1992</REF>c</REF>; and see Section 23 and Roget categories <REF>Yarowsky 1992</REF>; <REF>Masterman 1957</REF> correspond broadly to the wider, homograph, distinctions	1	In this paper we attempt to show that the high level of results more typical of systems trained on many instances of a restricted vocabulary can also be obtained by large vocabulary systems, and that the best results are to be obtained from an optimization of a combination of types of lexical knowledge see Section 2	0	11 Lexical Knowledge and WSD Syntactic, semantic, and pragmatic information are all potentially useful for WSD, as can be demonstrated by considering the following sentences: 1 2 3 4 John did not feel well	0	3	2
P95-1025	P91-1034	1995	Using the definitionbased conceptual co-occurrence data collected from the relatively small Brown corpus, our sense disambiguation system achieves an average accuracy comparable to human performance given the same contextual information	0	Previous corpus-based sense disambiguation methods require substantial amounts of sense-tagged training data <REF>Kelly and Stone, 1975</REF>; <REF>Black, 1988</REF> and <REF>Hearst, 1991</REF> or aligned bilingual corpora <TREF>Brown et al , 1991</TREF>; <REF>Dagan, 1991</REF> and <REF>Gale et al 1992</REF>	1	<REF>Yarowsky 1992</REF> introduces a thesaurus-based approach to statistical sense disambiguation which works on monolingual corpora without the need for sense-tagged training data	0	By collecting statistical data of word occurrences in the context of different thesaurus categories from a relatively large corpus 10 million words, the system can identify salient words for each category	0	1	3
P93-1022	P91-1034	1993	The results of the experiment are summarized in Table 4	0	52 A data recovery task In the second evaluation, the estimation method had to distinguish between members of two sets of 8It should be emphasized that the TWS method uses only a monolingual target corpus, and not a bilingual corpus as in other methods <TREF>Brown et al , 1991</TREF>; <REF>Gale et al , 1992</REF>	1	The alternative cooccurrence patterns in the target language, which correspond to the alternative translations of the ambiguous source words, are constructed using a bilingual lexicon	0	cooccurrence pairs, one of them containing pairs with relatively high probability and the other pairs with low probability	0	6	1
P05-1049	P91-1034	2005	Semi-supervised methods for WSD are characterized in terms of exploiting unlabeled data in learning procedure with the requirement of predefined sense inventory for target words	0	They roughly fall into three categories according to what is used for supervision in learning process: 1 using external resources, eg, thesaurus or lexicons, to disambiguate word senses or automatically generate sense-tagged corpus, <REF>Lesk, 1986</REF>; <REF>Lin, 1997</REF>; <REF>McCarthy et al , 2004</REF>; <REF>Seo et al , 2004</REF>; <REF>Yarowsky, 1992</REF>, 2 exploiting the differences between mapping of words to senses in different languages by the use of bilingual corpora eg parallel corpora or untagged monolingual corpora in two languages <TREF>Brown et al , 1991</TREF>; <REF>Dagan and Itai, 1994</REF>; <REF>Diab and Resnik, 2002</REF>; <REF>Li and Li, 2004</REF>; <REF>Ng et al , 2003</REF>, 3 bootstrapping sensetagged seed examples to overcome the bottleneck of acquisition of large sense-tagged data <REF>Hearst, 1991</REF>; <REF>Karov and Edelman, 1998</REF>; <REF>Mihalcea, 2004</REF>; <REF>Park et al , 2000</REF>; <REF>Yarowsky, 1995</REF>	1	As a commonly used semi-supervised learning method for WSD, bootstrapping algorithm works by iteratively classifying unlabeled examples and adding confidently classified examples into labeled dataset using a model learned from augmented labeled dataset in previous iteration	0	It can be found that the affinity information among unlabeled examples is not fully explored in this bootstrapping process	0	4	2
H93-1052	P91-1034	1993	Later work from the AI community relied heavily upon selectional restrictions for verbs, although primarily in terms of features exhibited by their arguments such as DRINKABLE rather than in terms of individual words or word classes	0	More recent work <TREF>Brown et al 1991</TREF><REF>Hearst 1991</REF> has utilized a set of discrete local questions such as word-to-the-right in the development of statistical decision procedures	0	However, a strong trend in recent years is to treat a reasonably wide context window as an unordered bag of independent evidence points	1	This technique from information retrieval has been used in neural networks, Bayesian discriminators, and dictionary definition matching	0	1	3
P93-1002	P91-1034	1993	Hence, we use a slightly different framework	0	We view a bilingual corpus as a sequence of sentence beads <TREF>Brown et al , 1991b</TREF>, where a sentence bead corresponds to an irreducible group of sentences that align with each other	1	For example, the correct alignment of the bilingual corpus in Figure 2 consists of the sentence bead El; F1 followed by the sentence bead E2; ;2, F3	0	We can represent an alignment 4 of a corpus as a sequence of sentence beads Epl; Fpl, Ep2; F,, where the E and F can be zero, one, or more sentences long	0	4	2
J96-1001	P91-1034	1996	In this way, we can ignore the context of the collocations and their translations, and base our decisions only on the patterns of co-occurrence of each collocation and its candidate translations across the entire corpus	0	This approach is quite different from those adopted for the translation of single words <REF>Klavans and Tzoukermann 1990</REF>; <REF>Dorr 1992</REF>; <REF>Klavans and Tzoukermann 1996</REF>, since for single words polysemy cannot be ignored; indeed, the problem of sense disambiguation has been linked to the problem of translating ambiguous words <TREF>Brown et al 1991</TREF>; <REF>Dagan, Itai, and Schwall 1991</REF>; <REF>Dagan and Itai 1994</REF>	1	The assumption of a single meaning per collocation was based on our previous experience with English collocations <REF>Smadja 1993</REF>, is supported for less opaque collocations by the fact that their constituent words tend to have a single sense when they appear in the collocation <REF>Yarowsky 1993</REF>, and was verified during our evaluation of Champollion Section 7	0	We construct a mathematical model of the events we want to correlate, namely, the appearance of any word or group of words in the sentences of our corpus, as follows: To each group of words G, in either the source or the target language, we map a binary random variable Xc that takes the value 1 if G appears in a particular sentence and 0 if not	0	4	2
J98-1004	P91-1034	1998	If sense labeling is part of the task, an outside source of knowledge is necessary to define the senses	0	Regardless of whether it takes the form of dictionaries <REF>Lesk 1986</REF>; <REF>Guthrie et al 1991</REF>; <REF>Dagan, Itai, and Schwall 1991</REF>; <REF>Karov and Edelman 1996</REF>, thesauri <REF>Yarowsky 1992</REF>; <REF>Walker and Amsler 1986</REF>, bilingual corpora <TREF>Brown et al 1991</TREF>; <REF>Church and Gale 1991</REF>, or hand-labeled training sets <REF>Hearst 1991</REF>; <REF>Leacock, Towell, and Voorhees 1993</REF>; <REF>Niwa and Nitta 1994</REF>; <REF>Bruce and Wiebe 1994</REF>, providing information for sense definitions can be a considerable burden	0	What makes our approach unique is that, since we narrow the problem to sense discrimination, we can dispense of an outside source of knowledge for defining senses	1	 Xerox Palo Alto Research Center, 3333 Coyote Hill Road, Palo Alto, CA 94304 Q 1998 Association for Computational Linguistics Computational Linguistics Volume 24, Number 1 We therefore call our approach automatic word sense discrimination, since we do not require manually constructed sources of knowledge	0	2	3
P95-1026	P91-1034	1995	It thrives on raw, unannotated monolingual corpora the more the merrier	0	Although there is some hope from using aligned bilingual corpora as training data for supervised algorithms <TREF>Brown et al , 1991</TREF>, this approach suffers from both the limited availability of such corpora, and the frequent failure of bilingual translation differences to model monolingual sense differences	1	The use of dictionary definitions as an optional seed for the unsupervised algorithm stems from a long history of dictionary-based approaches, including <REF>Lesk 1986</REF>, Guthrie et al	0	1991, <REF>Veronis and Ide 1990</REF>, and <REF>Slator 1991</REF>	0	1	3
W99-0905	P91-1034	1999	It is also crucial in cross-language text processing including cross-language information retrieval and abstraction	0	Due to the recent availability of large text corpora, various statistical approaches have been tried including using 1 parallel corpora <REF>Brown et al , 1990</REF>, <TREF>Brown et al , 1991</TREF>, <REF>Brown, 1997</REF>, 2 non-parallel bilingual corpora tagged with topic area <REF>Yamabana et al , 1998</REF> and 3 un-tagged mono-language corpora in the target language <REF>Dagan and Itai, 1994</REF>, <REF>Tanaka and Iwasaki, 1996</REF>, <REF>Kikui, 1998</REF>	0	A problem with the first two approaches is that it is not easy to obtain sufficiently large parallel or manually tagged corpora for the pair of languages targeted	1	Although the third approach eases the problem of preparing corpora, it suffers from a lack of useful information in the source language	0	1	3
A94-1006	P91-1034	1994	Their method thus yields some incorrect noun phrases that will not be proposed by a tagger, but on the other hand does not miss noun phrases that may be missed due to tagging errors	0	3 Bilingual Task: An Application for Word Alignment 31 Sentence and word alignment Bilingual alignment methods <REF>Warwick et al , 1990</REF>; <TREF>Brown et al , 1991a</TREF>; <REF>Brown et al , 1993</REF>; <REF>Gale and Church, 1991b</REF>; <REF>Gale and Church, 1991a</REF>; <REF>Kay and Roscheisen, 1993</REF>; <REF>Simard et al , 1992</REF>; <REF>Church, 1993</REF>; <REF>Kupiec, 1993a</REF>; <REF>Matsumoto et al , 1993</REF>; <REF>Dagan et al , 1993</REF>	0	have been used in statistical machine translation <REF>Brown et al , 1990</REF>, terminology research and translation aids <REF>Isabelle, 1992</REF>; <REF>Ogden and Gonzales, 1993</REF>; van der <REF>Eijk, 1993</REF>, bilingual lexicography <REF>Klavans and Tzoukermann, 1990</REF>; <REF>Smadja, 1992</REF>, word-sense disambiguation <TREF>Brown et al , 1991b</TREF>; <REF>Gale et al , 1992</REF> and information retrieval in a multilingual environment <REF>Landauer and Littman, 1990</REF>	1	Most alignment work was concerned with alignment at the sentence level	0	6	1
A94-1006	P91-1034	1994	3 Bilingual Task: An Application for Word Alignment 31 Sentence and word alignment Bilingual alignment methods <REF>Warwick et al , 1990</REF>; <TREF>Brown et al , 1991a</TREF>; <REF>Brown et al , 1993</REF>; <REF>Gale and Church, 1991b</REF>; <REF>Gale and Church, 1991a</REF>; <REF>Kay and Roscheisen, 1993</REF>; <REF>Simard et al , 1992</REF>; <REF>Church, 1993</REF>; <REF>Kupiec, 1993a</REF>; <REF>Matsumoto et al , 1993</REF>; <REF>Dagan et al , 1993</REF>	0	have been used in statistical machine translation <REF>Brown et al , 1990</REF>, terminology research and translation aids <REF>Isabelle, 1992</REF>; <REF>Ogden and Gonzales, 1993</REF>; van der <REF>Eijk, 1993</REF>, bilingual lexicography <REF>Klavans and Tzoukermann, 1990</REF>; <REF>Smadja, 1992</REF>, word-sense disambiguation <TREF>Brown et al , 1991b</TREF>; <REF>Gale et al , 1992</REF> and information retrieval in a multilingual environment <REF>Landauer and Littman, 1990</REF>	1	Most alignment work was concerned with alignment at the sentence level	0	Algorithms for the more difficult task of word alignment were proposed in <REF>Gale and Church, 1991a</REF>; <REF>Brown et al , 1993</REF></REF>; <REF>Dagan et al , 1993</REF> and were applied for parameter estimation in the IBM statistical machine translation system <REF>Brown et al , 1993</REF></REF>	0	6	1
J98-1002	P91-1034	1998	Although this requirement may seem trivial, most corpus-based methods do not, in fact, allow such flexibility	0	For example, defining the senses by the possible translations of the word <REF>Dagan, Itai and Schwall 1991</REF>; <TREF>Brown et al 1991</TREF>; <REF>Gale, Church, and <REF>Yarowsky 1992</REF></REF>, by the Rogets categories <REF>Yarowsky 1992</REF>, or by clustering Schitze 1992, yields a grouping that does not always conform to the desired sense distinctions	0	In comparison to these approaches, our reliance on the MRD for the definition of senses in the initialization of the learning process guarantees the required flexibility in setting the sense distinctions	1	Specifically, the user of our system may choose a certain dictionary definition, a combination of definitions from several dictionaries, or manually listed seed words for every sense that needs to be defined	0	2	3
J98-1002	P91-1034	1998	Traditionally, the problem of sparse data is approached by estimating the probability of unobserved co-occurrences using the actual co-occurrences in the training set	0	This can be done by smoothing the observed frequencies 7 <REF>Church and Mercer 1993</REF> or by class-based methods <TREF>Brown et al 1991</TREF>; <REF>Pereira and Tishby 1992</REF>; <REF>Pereira, Tishby, and Lee 1993</REF>; <REF>Hirschman 1986</REF>; <REF>Resnik 1992</REF>; <REF>Brill et al 1990</REF>; <REF>Dagan, Marcus, and Markovitch 1993</REF>	0	In comparison to these approaches, we use similarity information throughout training, and not merely for estimating co-occurrence statistics	1	This allows the system to learn successfully from very sparse data	0	2	3
W96-0104	P91-1034	1996	Traditionally, the problem of sparse data is approached by estimating the probability of unobserved cooccurrences using the actual cooccurrences in the training set	0	This can be done by smoothing the observed frequencies <REF>Church and Mercer, 1993</REF>, or by class-based methods <TREF>Brown et al , 1991</TREF>; <REF>Pereira and Tishby, 1992</REF>; Pereira et ah, 1993; <REF>Hirschman, 1986</REF>; <REF>Resnik, 1992</REF>; Brill et ah, 1990; <REF>Dagan et al , 1993</REF>	0	In comparison to these approaches, we use similarity information throughout training, and not merely for estimating cooccurrence statistics	1	This allows the system to learn successfully from very sparse data	0	2	3
W05-1207	P91-1034	2005	The aim of this measure is to indicate the relatedness between two elements composing a pair	0	Mutual information has been positively used in many NLP tasks such as collocation analysis <REF>Church and Hanks, 1989</REF>, terminology extraction <REF>Damerau, 1993</REF>, and word sense disambiguation <TREF>Brown et al , 1991</TREF>	0	3 Experimental Evaluation As many other corpus linguistic approaches, our entailment detection model relies partially on some linguistic prior knowledge the expected structure of the searched collocations, ie, the textual entailment patterns and partially on some probability distribution estimation	0	Only a positive combination of both these two ingredients can give good results when applying and evaluating the model	1	1	3
C98-1106	P91-1034	1998	Brown et al presented an algorithm that  This research was done when the author was at Center for the Study of Language and InformationCSLI, Stanford University	0	1In fact, this is partly shown by the fact that many MT systems have substitutable domain-dependent or user  dictionaries  relies on translation probabilities estimated from large bilingual corpora <REF>Brown et al, 1990</REF><TREF>Brown et al, 1991</TREF>	1	<REF>Dagan and Itai 1994</REF> and <REF>Tanaka and Iwasaki 1996</REF> proposed algorithms for selecting target words by using word co-occurrence statistics in the target language corpora	0	The latter algorithms using mono-lingual corpora are particularly important because, at present, we cannot always get a sufficient amount of bilingual or parallel corpora	0	6	1
W98-0712	P91-1034	1998	From an application-oriented perspective, there is the further problem of how it is possible to regiment their role and relevance as a function of context variation	0	As a somewhat radical alternative to taxonomical relationships, other ways of measuring semantic similarity based on distributional evidence have been put forward in the literature see, among others, <TREF>Brown et al 1991</TREF>, <REF>Gale et al 1992</REF>, <REF>Pereira and Tishby 1992</REF>, which emphasise the role played by context in this game	1	These approaches compute the semantic similarity between W z and W, on the basis of the extent to which W,/W,s average contexts of use overlap	0	Here, the context is generally defined as an n-word window centred on Wl/W:	0	6	1
D08-1063	P91-1034	2008	2 Previous Work There are several investigations in literature that explore using parallel corpora to transfer information content from one language most of the time English to another	0	The earliest investigations of the subject have been performed, on word sense disambiguation <REF>Dagan et al, 1991</REF>; PF<TREF>Brown et al, 1991</TREF>; <REF>Gale et al, 1992</REF> perhaps unsurprisingly given its close connection to machine translation  all propose and lightly evaluate methods to use word sense information extracted from the target language to help the sense resolution in the source language and machine translation	1	<REF>Dagan and Itai, 1994</REF> explicitly suggests performing word sense disambiguation in the target language English in the article with the goal of resolving ambiguity in the source language Hebrew, and show moderate 2While applying this method in the case where the source language has absolutely no resources might be an interesting test case, we dont see it as being realistic	0	Resources are build nowadays in a large variety of languages, and not making use of them is rather foolish a certain big bird and sand comes to mind	0	6	1
A97-1056	P91-1034	1997	In order to utilize models with more complicated interactions among feature variables, <REF>Bruce and Wiebe, 1994b</REF> introduce the use of sequential model selection and decomposable models for word-sense disambiguation	0	 Alternative probabilistic approaches have involved using a single contextual feature to perform disambiguation eg , <TREF>Brown et al , 1991</TREF>, <REF>Dagan et al , 1991</REF>, and <REF>Yarowsky, 1993</REF> present techniques for identifying the optimal feature to use in disambiguation	1	Maximum Entropy models have been used to express the interactions among multiple feature variables eg , <REF>Berger et al , 1996</REF>, but within this framework no systematic study of interactions has been proposed	0	Decision tree induction has been applied to word-sense disambiguation eg	0	6	1
W06-1649	P91-1034	2006	Semi-supervised methods for WSD are characterized in terms of exploiting unlabeled data in the learning procedure with the need of predened sense inventories for target words	0	The information for semi-supervised sense disambiguation is usually obtained from bilingual corpora eg parallel corpora or untagged monolingual corpora in two languages <TREF>Brown et al , 1991</TREF>; <REF>Dagan and Itai, 1994</REF>, or sense-tagged seed examples <REF>Yarowsky, 1995</REF>	0	Some observations can be made on the previous supervised and semi-supervised methods	1	They always rely on hand-crafted lexicons eg , WordNet as sense inventories	0	4	2
W03-0412	P91-1034	2003	2 The Design of PhraseNet Context is one important notion in PhraseNet	0	While the context may mean different things in natural language, many previous work in statistically natural language processing defined context as an n-word window around the target word <REF>Gale et al , 1992</REF>; <TREF>Brown et al , 1991</TREF>; <REF>Roth, 1998</REF>	1	In PhraseNet, context has a more precise definition that depends on the grammatical structure of a sentence rather than simply counting surrounding words	0	We define context to be the syntactic structure of the sentence in which the word of interest occurs	0	6	1
P02-1044	P91-1034	2002	By repeating the above processes, it can create an accurate classifier for word translation disambiguation	0	For other related work, see, for example, <TREF>Brown et al 1991</TREF>; <REF>Dagan and Itai 1994</REF>; <REF>Pedersen and Bruce 1997</REF>; <REF>Schutze 1998</REF>; <REF>Kikui 1999</REF>; <REF>Mihalcea and Moldovan 1999</REF>	0	3 Bilingual Bootstrapping 31 Overview Instead of using Monolingual Bootstrapping, we propose a new method for word translation disambiguation using Bilingual Bootstrapping	1	In translation from English to Chinese, for instance, BB makes use of not only unclassified data in English, but also unclassified data in Chinese	0	5	2
W93-0301	P91-1034	1993	To deal with these robustness issues, <REF>Church 1993</REF> developed a character-based alignment method called charalign	0	The method was intended as a replacement for sentence-based methods eg , <TREF>Brown et al , 1991a</TREF>; <REF>Gale and Church, 1991b</REF>; <REF>Kay and Rosenschein, 1993</REF>, which are very sensitive to noise	0	This paper describes a new program, called wordalign, that starts with an initial rough alignment eg , the output of charalign or a sentence-based alignment method, and produces improved alignments by exploiting constraints at the word-level	1	The alignment algorithm consists of two steps: 1 estimate translation probabilities, and 2 use these probabilities to search for most probable alignment path	0	5	2
W93-0301	P91-1034	1993	More importantly, because wordalign and charalign were designed to work robustly on texts that are smaller and more noisy than the Hansards, it has been possible to successfully deploy the programs at ATT Language Line Services, a commercial translation service, to help them with difficult terminology	0	Aligning parallel texts has recently received considerable attention <REF>Warwick et al , 1990</REF>; <TREF>Brown et al , 1991a</TREF>; <REF>Gale and Church, 1991b</REF>; <REF>Gale and Church, 1991a</REF>; <REF>Kay and Rosenschein, 1993</REF>; <REF>Simard et al , 1992</REF>; <REF>Church, 1993</REF>; <REF>Kupiec, 1993</REF>; <REF>Matsumoto et al , 1993</REF>	0	These methods have been used in machine translation <REF>Brown et al , 1990</REF>; <REF>Sadler, 1989</REF>, terminology research and translation aids <REF>Isabelle, 1992</REF>; <REF>Ogden and Gonzales, 1993</REF>, bilingual lexicography <REF>Klavans and Tzoukermann, 1990</REF>, collocation studies <REF>Smadja, 1992</REF>, word-sense disambiguation <TREF>Brown et al , 1991b</TREF>; <REF>Gale et al , 1992</REF> and information retrieval in a multilingual environment <REF>Landauer and Littman, 1990</REF>	1	The information retrieval application may be of particular relevance to this audience	0	3	2
W93-0301	P91-1034	1993	Aligning parallel texts has recently received considerable attention <REF>Warwick et al , 1990</REF>; <TREF>Brown et al , 1991a</TREF>; <REF>Gale and Church, 1991b</REF>; <REF>Gale and Church, 1991a</REF>; <REF>Kay and Rosenschein, 1993</REF>; <REF>Simard et al , 1992</REF>; <REF>Church, 1993</REF>; <REF>Kupiec, 1993</REF>; <REF>Matsumoto et al , 1993</REF>	0	These methods have been used in machine translation <REF>Brown et al , 1990</REF>; <REF>Sadler, 1989</REF>, terminology research and translation aids <REF>Isabelle, 1992</REF>; <REF>Ogden and Gonzales, 1993</REF>, bilingual lexicography <REF>Klavans and Tzoukermann, 1990</REF>, collocation studies <REF>Smadja, 1992</REF>, word-sense disambiguation <TREF>Brown et al , 1991b</TREF>; <REF>Gale et al , 1992</REF> and information retrieval in a multilingual environment <REF>Landauer and Littman, 1990</REF>	1	The information retrieval application may be of particular relevance to this audience	0	It would be highly desirable for users to be able to express queries in whatever language they chose and retrieve documents that may or may not have been written in the same language as the query	0	3	2
J97-1005	P92-1032	1997	Similar results are reported in <REF>Nakatani, Hirschberg, and Grosz 1995</REF> and <REF>Hirschberg and Nakatani 1996</REF> for spontaneous speech as well	1	<REF>Grosz and Hirschberg 1992</REF> also use the classification and regression tree system CART <REF>Brieman et al 1984</REF> to automatically construct and evaluate decision trees for classifying aspects of discourse structure from intonational feature values	1	The studies of <REF>Swerts 1995</REF> and <REF>Swerts and Ostendorf 1995</REF> also investigate the prosodic structuring of discourse	0	<REF>In Swerts 1995</REF>, paragraph boundaries are empirically obtained as described above	0	4	2
J01-3001	P92-1032	2001	SEMCOR contains 91,808 words tagged with WordNet synsets, 6,071 of which are proper names, which we ignored, leaving 85,737 words which could potentially be translated	0	The translation contains only 36,869 words tagged with LDOCE senses; however, this is a reasonable size for an evaluation corpus for the task, and it is several orders of magnitude larger than those used by other researchers working in large vocabulary WSD, for example <REF>Cowie, Guthrie, and Guthrie 1992</REF>, <REF>Harley and Glennon 1997</REF>, and Mahesh et al	1	1997	0	This corpus was also constructed without the excessive cost of additional hand-tagging and does not introduce any of the inconsistencies that can occur with a poorly controlled tagging strategy	0	4	2
J01-3001	P92-1032	2001	A third difference concerns the granularity of WSD attempted, which one can illustrate in terms of the two levels of semantic distinctions found in many dictionaries: homograph and sense see Section 31	1	Like <REF>Cowie, Guthrie, and Guthrie 1992</REF>, we shall give results at both levels, but it is worth pointing out that the targets of, say, work using translation equivalents eg , <REF>Brown et al 1991</REF>; <TREF>Gale, Church, and <REF>Yarowsky 1992</REF>c</TREF>; and see Section 23 and Roget categories <REF>Yarowsky 1992</REF>; <REF>Masterman 1957</REF> correspond broadly to the wider, homograph, distinctions	1	In this paper we attempt to show that the high level of results more typical of systems trained on many instances of a restricted vocabulary can also be obtained by large vocabulary systems, and that the best results are to be obtained from an optimization of a combination of types of lexical knowledge see Section 2	0	11 Lexical Knowledge and WSD Syntactic, semantic, and pragmatic information are all potentially useful for WSD, as can be demonstrated by considering the following sentences: 1 2 3 4 John did not feel well	0	2	1
P99-1043	P92-1032	1999	Co-occurrence information between neighboring words and words in the same sentence has been used in phrase extraction <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>, phrasal translation <REF>Smadja et al , 1996</REF>; <REF>Kupiec, 1993</REF>; <REF>Wu, 1995</REF>; <REF>Dagan and Church, 1994</REF>, target word selection <REF>Liu and Li, 1997</REF>; <REF>Tanaka and Iwasaki, 1996</REF>, domain word translation <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, sense disambiguation <REF>Brown et al , 1991</REF>; <REF>Dagan et al , 1991</REF>; <REF>Dagan and Itai, 1994</REF>; <TREF>Gale et al , 1992a</TREF>; <TREF>Gale et al , 1992b</TREF>; <TREF>Gale et al , 1992c</TREF>; <REF>Shiitze, 1992</REF>; <REF>Gale et al , 1993</REF>; <REF>Yarowsky, 1995</REF>, and even recently for query translation in cross-language IR as well <REF>Ballesteros and Croft, 1998</REF>	1	Co-occurrence statistics is collected from either bilingual parallel and 334 non-parallel corpora <REF>Smadja et al , 1996</REF>; <REF>Kupiec, 1993</REF>; <REF>Wu, 1995</REF>; <REF>Tanaka and Iwasaki, 1996</REF>; <REF>Fung and Lo, 1998</REF>, or monolingual corpora <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>; <REF>Liu and Li, 1997</REF>; <REF>Shiitze, 1992</REF>; <REF>Yarowsky, 1995</REF>	1	As we noted in <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, parallel corpora are rare in most domains	0	We want to devise a method that uses only monolingual data in the primary language to train co-occurrence information	0	4	2
P99-1043	P92-1032	1999	pruning translation alternatives for query translation	0	Co-occurrence information between neighboring words and words in the same sentence has been used in phrase extraction <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>, phrasal translation <REF>Smadja et al , 1996</REF>; <REF>Kupiec, 1993</REF>; <REF>Wu, 1995</REF>; <REF>Dagan and Church, 1994</REF>, target word selection <REF>Liu and Li, 1997</REF>; <REF>Tanaka and Iwasaki, 1996</REF>, domain word translation <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, sense disambiguation <REF>Brown et al , 1991</REF>; <REF>Dagan et al , 1991</REF>; <REF>Dagan and Itai, 1994</REF>; <TREF>Gale et al , 1992a</TREF>; <TREF>Gale et al , 1992b</TREF>; <TREF>Gale et al , 1992c</TREF>; <REF>Shiitze, 1992</REF>; <REF>Gale et al , 1993</REF>; <REF>Yarowsky, 1995</REF>, and even recently for query translation in cross-language IR as well <REF>Ballesteros and Croft, 1998</REF>	1	Co-occurrence statistics is collected from either bilingual parallel and 334 non-parallel corpora <REF>Smadja et al , 1996</REF>; <REF>Kupiec, 1993</REF>; <REF>Wu, 1995</REF>; <REF>Tanaka and Iwasaki, 1996</REF>; <REF>Fung and Lo, 1998</REF>, or monolingual corpora <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>; <REF>Liu and Li, 1997</REF>; <REF>Shiitze, 1992</REF>; <REF>Yarowsky, 1995</REF>	1	As we noted in <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, parallel corpora are rare in most domains	0	4	2
C94-1074	P92-1032	1994	In this paper we use many examples from the RSD	0	21 Morphology The morphologic analyzer <REF>Marziali, 1992</REF> derives from the work on a generative approach to the Italian morphology <REF>Russo, 1987</REF>, first used in DANTE, a NLP system for analysis of short narrative texts in the financial domain <REF>Antonacci et al 1989</REF>	1	Tile analyzer includes over 7000 elementary lemmata stems without affixes, eg flex is the elementary lemma for de448 flex, in-flex, re-fiex anti has been experimented since now on economic, financial, commercial and legal domains	0	Elementary lemmata cover much more than 700 words, since many words have an affix	0	5	2
C94-1074	P92-1032	1994	A second problem with the Fidditch parser is poor performances: tilt recall and precision at detecting word collocations are declared to be as low as 50, I-iowever it is unclear if this value applies only to SVO triples, and how it has been derived	1	The recall is low because tile Fidditch parser, as other partial parsers <REF>Sekine et al, 1992</REF>; Resnik and Hearst, i993, only detect links between adjacent or near-adjacent words	1	Thougll a 50/,, precision and recall might be 447 reasonable for human assisted tasks, like in lexicography, supervised translation, etc , it is not fair enough if collocational analysis must serve a fully automated system	0	In fact, corpus linguistics became a popular research field because of the claim that shallow techniques could overcome the lexical coverage bottleneck of traditional NLP techniques	0	1	3
C94-1074	P92-1032	1994	The parser The SSA syntactic analysis is a rewriting procedure of a single sentence into a set of 1 meme-yy ijgjin esl	0	The SSA is based on a discontinuous grammar, described more formally in <REF>Basili et al 1992a</REF>	1	In tiffs section we provide a qualitative clescription of the rules by which esls are generated	0	Examples of esls generated by the parser are: NV the subject-verb relation, V N the direct objectverb relation, N P N noun preposition noun, V P N verb preposition noun, NAdj adjective noun, N N conqound etc Overall, we identify over 20 different esls	0	3	2
C94-1074	P92-1032	1994	In <REF>Zernik 1990</REF>; <REF>Calzolari and Bindi 1990</REF>; <REF>Smadja 1989</REF>; <REF>Church and Hanks 1990</REF> associations are detected in a 5 window	0	A wider window  tO0 words is used in <TREF>Gale et al 1992</TREF>	1	Windowing techniques are also used in <REF>Jelinek et al, 1990</REF>, where it is proposed a trigram model to automatically derive, and refine, context-free rules of the grammar <REF>Fujisaki et al, 1991</REF>	0	Windowing techniques weekly model tile locality of language as well as other lexical information	0	2	1
C94-1074	P92-1032	1994	In fact, corpus linguistics became a popular research field because of the claim that shallow techniques could overcome the lexical coverage bottleneck of traditional NLP techniques	0	Among the applications of collocational analysis for lexical acquisition are: the derivation of syntactic disambiguation cues <REF>Basili et al 1991, 1993a</REF>; <REF>Hindle and Rooths 1991</REF>,1993; <REF>Sekine 1992</REF> <REF>Bogges et al 1992</REF>, sense preference <REF>Yarowski 1992</REF>, acquisition of selectional restrictions <REF>Basili et al 1992b, 1993b</REF>; <REF>Utsuro et al 1993</REF>, lexical preference in generation <REF>Smadjia 1991</REF>, word clustering <REF>Pereira 1993</REF>; <REF>Hindle 1990</REF>; <REF>Basili et al 1993c</REF>, etc In the majority of these papers, even though the precedent or subsequent statistical processing reduces the number of accidental associations, very large corpora 10,000,000 words are necessary to obtain reliable data on a large enough number of words	1	In addition, most papers produce a performance evaluation of their methods but do not provide a measure of the coverage, ie the percentage of cases for which their method actually provides a right or wrong solution	0	It is quite common that results are discussed only for 10-20 cases	0	1	3
W93-0216	P92-1032	1993	7 SUBJECTS a, b, c, d, e, f, g 161 I0 Hei falls over, Figure 2: Portion of Segntentation from Narrative 6 Subject Annotation of Narratrs httention Digression to describe suml track No verbal communication ie , speaker describes lack thereof Describes that it is a silent movie with only nature sounds Speaker describes sound techniques used in tnovie Explain that there is no speaking ill nlovie Figure 3: Segment spanning 1,12 through 154 3 Discourse Segment Boundaries In <REF>Passonneau and Litman, 1993</REF>, we show that our subjects agree with one another at levels that are statistically significant, thus demonstrating the reliability of intention as a segmentation criterion	0	Percent agreement is defined in <TREF>Gale et al , 1992</TREF> as the ratio of observed agreements with the majority opinion to possible agreements with the majority opinion	1	We use percent agreement to measure the ability of subjects to agree with one anotlter on whether there is  segment boundary between two adjacent prosodic phrases	1	We find that the average agreement across the 20 narratives on the status of all potential boundary locations is 89 with a range from 82-92	0	3	2
W97-0807	P92-1032	1997	The precision is the ratio of the number of correct interpretations, to the number of outputs	0	The column of control denotes the precision of a naive WSD technique, in which the system systematicaily chooses the verb sense appearing most frequently in the database <TREF>Gale et al , 1992</TREF>	1	The precision for each similarity calculation method did not differ greatly, and the use of the length of the path in the Bunruigoihyo thesaurus BGH slightly outperformed other method on the whole	0	However, since the overall precision is biased by frequently appeared verbs such as tsukau and ukeru, our word similarity measurement is not necessarily inferior to other methods	0	6	1
P06-1058	P92-1032	2006	An artificial ambiguous word can be coined with the monosemous words in table 1	0	This process is similar to the use of general pseudowords <TREF>Gale et al , 1992b</TREF>; <REF>Gaustad, 2001</REF>; <REF>Nakov and Hearst, 2003</REF>, but has some essential differences	1	This artificial ambiguous word need to simulate the function of the real ambiguous word, and to acquire semantic knowledge as the real ambiguous word does	0	Thus, we call it an equivalent pseudoword EP for its equivalence with the real ambiguous word	0	2	2
P96-1006	P92-1032	1996	Surrounding words give lower accuracy, perhaps because in our work, only the current sentence forms the surrounding context, which averages about 20 words	0	Previous work on using the unordered set of surrounding words have used a much larger window, such as the 100-word window of <REF>Yarowsky, 1992</REF>, and the 2-sentence context of <REF>Leacock et al , 1993</REF>	1	Verb-object syntactic relation is the weakest knowledge source	0	Our experimental finding, that local collocations are the most predictive, agrees with past observation that humans need a narrow window of only a few words to perform WSD <REF>Choueka and Lusignan, 1985</REF>	1	2	1
P96-1006	P92-1032	1996	In contrast, LEXAS uses supervised learning from tagged sentences, which is also the approach taken by most recent work on WSD, including <REF>Bruce and Wiebe, 1994</REF>; <REF>Miller et al , 1994</REF>; <REF>Leacock et al , 1993</REF>; <REF>Yarowsky, 1994</REF>; <REF>Yarowsky, 1993</REF>; <REF>Yarowsky, 1992</REF>	0	The work of <REF>Miller et al , 1994</REF>; <REF>Leacock et al , 1993</REF>; <REF>Yarowsky, 1992</REF> used only the unordered set of surrounding words to perform WSD, and they used statistical classifiers, neural networks, or IR-based techniques	0	The work of <REF>Bruce and Wiebe, 1994</REF> used parts of speech POS and morphological form, in addition to surrounding words	0	However, the POS used are abbreviated POS, and only in a window of -b2 words	0	6	1
P96-1006	P92-1032	1996	One line of research focuses on the use of the knowledge contained in a machine-readable dictionary to perform WSD, such as <REF>Wilks et al , 1990</REF>; <REF>Luk, 1995</REF>	0	In contrast, LEXAS uses supervised learning from tagged sentences, which is also the approach taken by most recent work on WSD, including <REF>Bruce and Wiebe, 1994</REF>; <REF>Miller et al , 1994</REF>; <REF>Leacock et al , 1993</REF>; <REF>Yarowsky, 1994</REF>; <REF>Yarowsky, 1993</REF>; <REF>Yarowsky, 1992</REF>	1	The work of <REF>Miller et al , 1994</REF>; <REF>Leacock et al , 1993</REF>; <REF>Yarowsky, 1992</REF> used only the unordered set of surrounding words to perform WSD, and they used statistical classifiers, neural networks, or IR-based techniques	0	The work of <REF>Bruce and Wiebe, 1994</REF> used parts of speech POS and morphological form, in addition to surrounding words	0	2	1
P96-1006	P92-1032	1996	We compared the classification accuracy of LEXAS against the default strategy of picking the most frequent sense	1	This default strategy has been advocated as the baseline performance level for comparison with WSD programs <TREF>Gale et al , 1992</TREF>	1	There are two instantiations of this strategy in our current evaluation	0	Since WORDNET orders its senses such that sense 1 is the most frequent sense, one possibility is to always pick sense 1 as the best sense assignment	0	2	1
P96-1006	P92-1032	1996	That is, LEXAS is only concerned with disambiguating senses of a word in a given POS	0	Making such an assumption is reasonable since POS taggers that can achieve accuracy of 96 are readily available to assign POS to unrestricted English sentences <REF>Brill, 1992</REF>; <REF>Cutting et al , 1992</REF>	1	In addition, sense definitions are only available for root words in a dictionary	0	These are words that are not morphologically inflected, such as interest as opposed to the plural form interests, fall as opposed to the other inflected forms like fell, fallen, falling, falls, etc The sense of a morphologically inflected content word is the sense of its uninflected form	0	4	2
P98-1069	P92-1032	1998	9 Related work Using vector space model and similarity measures for ranking is a common approach in IR for query/text and text/text comparisons <REF>Salton and Buckley, 1988</REF>; <REF>Salton and Yang, 1973</REF>; <REF>Croft, 1984</REF>; <REF>Turtle and Croft, 1992</REF>; <REF>Bookstein, 1983</REF>; <REF>Korfhage, 1995</REF>; <REF>Jones, 1979</REF>	1	This approach has also been used by <REF>Dagan and Itai, 1994</REF>; <TREF>Gale et al , 1992</TREF>; <REF>Shiitze, 1992</REF>; <REF>Gale et al , 1993</REF>; <REF>Yarowsky, 1995</REF>; Gale and Church, 1Lunar is not an unknown word in English, Yeltsin finds its translation in the 4-th candidate	1	Table 5: tion out score 0008421 0007895 0007669 0007588 0007283 0006812 0006430 0006218 0005921 0005527 0005335 0005335 0005221 0004731 0004470 0004275 0003878 0003859 0003859 0003784 0003686 0003550 0003519 0003481 0003407 0003407 0003338 0003324 Some Chinese ut English Teng-hui SAR flu Lei poultry SAR hijack poultry Tung Diaoyu PrimeMinister President China Lien poultry China flu PrimeMinister President poultry Kalkanov poultry SAR Zhuhai PrimeMinister President flu apologise unknown word translaChinese  Weng-hui  u Lei j Poultry  Chee-hwa  Teng-hui  SAR  Chee-hwa : Teng-hui  Weng-hui W Weng-hui CLam  Teng-hui - Chee-hwa  Teng-hui Lei  Chee-hwa  Chee-hwa  Leung  Zhuhai I Lei J Yeltsin - Chee-hwa  Lam Lam j Poultry W Teng-hui 0003250 DPP 0003206 Tang 0003202 Tung 0003040 Leung 0003033 China 0002888 Zhuhai 0002886 Tung  Teng-hui Tang Leung Leung  SAR  Lunar Tung 1994 for sense disambiguation between multiple usages of the same word	0	Some of the early statistical terminology translation methods are <REF>Brown et al , 1993</REF>; <REF>Wu and Xia, 1994</REF>; <REF>Dagan and Church, 1994</REF>; <REF>Gale and Church, 1991</REF>; <REF>Kupiec, 1993</REF>; <REF>Smadja et al , 1996</REF>; Kay and R<REF>Sscheisen, 1993</REF>; <REF>Fung and Church, 1994</REF>; <REF>Fung, 1995b</REF>	0	4	2
P98-1069	P92-1032	1998	It remains to be seen how we can also make use of the multilingual texts as NLP resources	1	In the years since the appearance of the first papers on using statistical models for bilingual lexicon compilation and machine translation<REF>Brown et al , 1993</REF>; <REF>Brown et al , 1991</REF>; <REF>Gale and <REF>Church, 1993</REF></REF>; <REF>Church, 1993</REF>; <REF>Simard et al , 1992</REF>, large amount of human effort and time has been invested in collecting parallel corpora of translated texts	1	Our goal is to alleviate this effort and enlarge the scope of corpus resources by looking into monolingual, comparable texts	0	This type of texts are known as nonparallel corpora	0	5	2
C04-1192	P92-1032	2004	The same system used in a validation mode, can be used to check and spot alignment errors in multilingually aligned wordnets as BalkaNet and EuroWordNet	0	Word Sense Disambiguation WSD is wellknown as one of the more difficult problems in the field of natural language processing, as noted in <TREF>Gale et al, 1992</TREF>; <REF>Kilgarriff, 1997</REF>; <REF>Ide and Vronis, 1998</REF>, and others	1	The difficulties stem from several sources, including the lack of means to formalize the properties of context that characterize the use of an ambiguous word in a given sense, lack of a standard and possibly exhaustive sense inventory, and the subjectivity of the human evaluation of such algorithms	1	To address the last problem, <TREF>Gale et al, 1992</TREF> argue for upper and lower bounds of precision when comparing automatically assigned sense labels with those assigned by human judges	0	4	2
C04-1192	P92-1032	2004	The difficulties stem from several sources, including the lack of means to formalize the properties of context that characterize the use of an ambiguous word in a given sense, lack of a standard and possibly exhaustive sense inventory, and the subjectivity of the human evaluation of such algorithms	0	To address the last problem, <TREF>Gale et al, 1992</TREF> argue for upper and lower bounds of precision when comparing automatically assigned sense labels with those assigned by human judges	1	The lower bound should not drop below the baseline usage of the algorithm in which every word that is disambiguated is assigned the most frequent sense whereas the upper bound should not be too restrictive when the word in question is hard to disambiguate even for human judges a measure of this difficulty is the computation of the agreement rates between human annotators	0	Identification and formalization of the determining contextual parameters for a word used in a given sense is the focus of WSD work that treats texts in a monolingual settingthat is, a setting where translations of the texts in other languages either do not exist or are not considered	0	4	2
P95-1015	P92-1032	1995	The summed deviation for perfect performance is thus 0	0	Finally, to interpret our quantitative results, we use the performance of our human subjects as a target goal for the performance of our algorithms <TREF>Gale et al , 1992</TREF>	1	Table 1 shows the average human performance for both the training and test sets of narratives	0	Note that human performance is basically the same for both sets of narratives	0	3	2
P95-1015	P92-1032	1995	By asking subjects to segment discourse using a non-linguistic criterion, the correlation of linguistic devices with independently derived segments can then be investigated in a way that avoids circularity	0	Together, <REF>Grosz and Hirschberg, 1992</REF>; <REF>Hirschberg and Grosz, 1992</REF>; <REF>Nakatani et al , 1995</REF> comprise an ongoing study using three corpora: professionally read AP news stories, spontaneous narrative, and read and spontaneous versions of task-oriented monologues	1	Discourse structures are derived from subjects segmentations, then statistical measures are used to characterize these structures in terms of acoustic-prosodic features	0	Grosz and Hirschbergs work also used the classification and regression tree system CART <REF>Breiman et al , 1984</REF> to automatically construct and evaluate decision trees for classifying aspects of discourse structure from intonational feature values	0	6	1
P95-1015	P92-1032	1995	Researchers have begun to investigate the ability of humans to agree with one another on segmen108 tation, and to propose methodologies for quantifying their findings	0	Several studies have used expert coders to locally and globally structure spoken discourse according to the model of <REF>Grosz and Sidnet 1986</REF>, including <REF>Grosz and Hirschberg, 1992</REF>; <REF>Hirschberg and Grosz, 1992</REF>; <REF>Nakatani et al , 1995</REF>; <REF>Stifleman, 1995</REF>	1	<REF>Hearst 1994</REF> asked subjects to place boundaries between paragraphs of expository texts, to indicate topic changes	0	<REF>Moser and Moore 1995</REF> had an expert coder assign segments and various segment features and relations based on RST	0	3	2
P95-1015	P92-1032	1995	<REF>Moser and Moore 1995</REF> had an expert coder assign segments and various segment features and relations based on RST	1	To quantify their findings, these studies use notions of agreement <TREF>Gale et al , 1992</TREF>; <REF>Moset and Moore, 1995</REF> and/or reliability <REF>Passonneau and Litman, 1993</REF>; Passonneau and Litman, to appear; <REF>Isard and Carletta, 1995</REF>	1	By asking subjects to segment discourse using a non-linguistic criterion, the correlation of linguistic devices with independently derived segments can then be investigated in a way that avoids circularity	0	Together, <REF>Grosz and Hirschberg, 1992</REF>; <REF>Hirschberg and Grosz, 1992</REF>; <REF>Nakatani et al , 1995</REF> comprise an ongoing study using three corpora: professionally read AP news stories, spontaneous narrative, and read and spontaneous versions of task-oriented monologues	0	3	2
W97-0201	P92-1032	1997	By using 10-fold cross validation <REF>Kohavi and John, 1995</REF> to automatically pick the best number of nearest neighbors to use, the performance of LSXAS has improved	0	4 Word Sense Disambiguation in the Large In <TREF>Gale et al , 1992</TREF>, it was argued that any wide coverage WSD program must be able to perform significantly better than the most-frequent-sense classifier to be worthy of serious consideration	1	The performance of LEXAS as indicated in Table 1 is significantly better than the most-frequent-sense classifier for the set of 191 words collected in our corpus	0	Figure 1 and 2 also confirm that all the training examples collected in our corpus are effectively utilized by LEXAS to improve its WSD performance	0	3	2
W97-0321	P92-1032	1997	1	0	Word sense disambiguation has long been one of the major concerns in natural language processing area eg , <REF>Bruce et al , 1994</REF>; <REF>Choueka et al , 1985</REF>; <REF>Gale et al , 1993</REF>; <REF>McRoy, 1992</REF>; <REF>Yarowsky 1992, 1994, 1995</REF>, whose aim is to identify the correct sense of a word in a particular context, among all of its senses defined in a dictionary or a thesaurus	1	Undoubtedly, effective disambiguation techniques are of great use in many natural language processing tasks, eg, machine translation and information retrieving <REF>Allen, 1995</REF>; <REF>Ng and Lee, 1996</REF>; <REF>Resnik, 1995</REF>, etc Previous strategies for word sense disambiguation mainly fall into two categories: statistics-based method and exemplar-based method	1	Statistics-based method often requires large-scale corpora eg , <REF>Hirst, 1987</REF>; <REF>Luk, 1995</REF>, sense-tagging or not, monolingual or aligned bilingual, as training data to specify significant clues for each word sense	0	4	2
W00-1318	P92-1032	2000	H2s,  max Ps, l ew ,n, E EW where EWi  ew I si  synsetew  1 P  si I ewj  - -nj where si  synsetewj, nj  Isyr et w,l In this formula, n is the number of synsets of the translation et	0	23 Heuristic 3: Sense Ordering <TREF>Gale et al , 1992</TREF> reports that word sense disambiguation would be at least 75 correct if a system assigns the most frequently occurring sense	1	<REF>Miller et al , 1994</REF> found that automatic I We use English WordNet version 16 L 143 assignment of polysemous words in Brown Corpus to senses in WordNet was 58 correct with a heuristic of most frequently occurring sense	0	We adopt these previous results to develop sense ordering heuristic	0	4	2
J98-1001	P92-1032	1998	In the area of word sense disambiguation, <REF>Black 1988</REF> developed a model based on decision trees using a corpus of 22 million tokens, after manually sense-tagging approximately 2,000 concordance lines for five test words	1	Since then, supervised learning from sense-tagged corpora has since been used by several researchers: Zernik 1990, 1991, <REF>Hearst 1991</REF>, <REF>Leacock, Towell, and Voorhees 1993</REF>, Gale, Church, and Yarowsky 1992d, 1993, <REF>Bruce and Wiebe 1994</REF>, Miller et al	1	1994, <REF>Niwa and Nitta 1994</REF>, <REF>Lehman 1994</REF>, among others	0	However, despite the availability of increasingly large corpora, two major obstacles impede the acquisition of lexical knowledge from corpora: the difficulties of manually sense-tagging a training corpus, and data sparseness	0	4	2
J98-1001	P92-1032	1998	<REF>Sutcliffe and Slater 1995</REF> replicated this method on full text samples from Orwells Animal Farm and found similar results 72 correct sense assignment, compared with a 33 chance baseline, and 40 using Lesks method	1	Several authors for example, Krovetz and Croft 1989, Guthrie et al 1991, Slator 1992, Cowie, Guthrie, and Guthrie 1992, Janssen 1992, Braden-Harder 1993, Liddy and Paik 1993 have attempted to improve results by using supplementary fields of information in the electronic version of the Longman Dictionary of Contemporary English LDOCE, in particular, the box codes and subject codes provided for each sense	1	Box codes include primitives such as ABSTRACT, ANIMATE, HUMAN, etc , and encode type restrictions on nouns and adjectives and on the arguments of verbs	1	Subject codes use another set of primitives to classify senses of words by subject ECONOMICS, ENGINEERING, etc	0	4	2
J98-1001	P92-1032	1998	<REF>Atkins 1987</REF> and Kilgarriff forthcoming also implicitly adopt the view of <REF>Harris 1954</REF>, according to which each sense distinction is reflected in a distinct context	1	A similar view underlies the class-based methods cited in Section 243 <REF>Brown et al 1992</REF>; <REF>Pereira and Tishby 1992</REF>; <REF>Pereira, Tishby, and Lee 1993</REF>	1	In this volume, Schiitze continues in this vein and proposes a technique that avoids the problem of sense distinction altogether: he creates sense clusters from a corpus rather than relying on a pre-established sense list	0	324 Enumeration or generation	0	4	2
P93-1020	P92-1032	1993	Furthermore, our percent agreement figures are comparable with the results of other segmentation studies discussed above	1	While studies of other tasks have achieved stronger results eg , 968 in a word-sense disambiguation study <TREF>Gale et al , 1992</TREF>, the meaning of percent agreement in isolation is unclear	1	For example, a percent agreement figure of less than 90 could still be very meaningful if the probability of obtaining such a figure is low	0	In the next section we demonstrate the significance of our findings	0	2	2
P93-1020	P92-1032	1993	AGREEMENT AMONG SUBJECTS We measure the ability of subjects to agree with one another, using a figure called percent agreement	1	Percent agreement, defined in <TREF>Gale et al , 1992</TREF>, is the ratio of observed agreements with the majority opinion to possible agreements with the majority opinion	1	Here, agreement among four, five, six, or seven subjects on whether or not there is a segment boundary between two adjacent prosodic phrases constitutes a majority opinion	0	Given a transcript of length n prosodic phrases, there are n-1 possible boundaries	0	3	2
P93-1020	P92-1032	1993	A farmer is thus the most recent noun phrase that is both consistent with, and 148 in the relevant interpretation context of, the pronoun in question	0	One problem in trying to model such discourse structure effects is that segmentation has been observed to be rather subjective <REF>Mann et al , 1992</REF>; <REF>Johnson, 1985</REF>	1	Several researchers have begun to investigate the ability of humans to agree with one another on segmentation	0	Grosz and Hirschberg <REF>Grosz and Hirschberg, 1992</REF>; <REF>Hirschberg and Grosz, 1992</REF> asked subjects to structure three AP news stories averaging 450 words in length according to the model of <REF>Grosz and Sidner 1986</REF>	0	6	1
P93-1020	P92-1032	1993	RELIABILITY The correspondence between discourse segments and more abstract units of meaning is poorly understood see <REF>Moore and Pollack, 1992</REF>	0	A number of alternative proposals have been presented which directly or indirectly relate segments to intentions <REF>Grosz and Sidner, 1986</REF>, RST relations <REF>Mann et al , 1992</REF> or other semantic relations <REF>Polanyi, 1988</REF>	1	We present initial results of an investigation of whether naive subjects can reliably segment discourse using speaker intention as a criterion	0	Our corpus consists of 20 narrative monologues about the same movie, taken from <REF>Chafe 1980</REF> N14,000 words	0	4	2
P98-2145	P92-1032	1998	Answer from five human subjects	0	By this experiment, we try to clarify the upper bound of the performance of the text segmentation task, which can be considered to indicate the degree of the difficulty of the task<REF>Passonneau and Litman, 1993</REF>; <TREF>Gale et al , 1992</TREF>	1	Figure 1,2 and table 1 show the results of the experiments	0	Two figures show the systems mean performance of 14 texts	0	4	2
C98-2140	P92-1032	1998	Answer from five human subjects	0	By this experiment, we try to clarify the upper bound of the performance of the text segmentation task, which can be considered to indicate the degree of the difficulty of the task<REF>Passonneau and Litman, 1993</REF>; <TREF>Gale et al, 1992</TREF>	1	Figure 1,2 and table 1 show the results of the experiments	0	Two figures show the systems mean performance of 14 texts	0	4	2
W97-0323	P92-1032	1997	To avoid one zero count of Pvj Ci nullifying the effect of the other non-zero conditional probabilities in the multiplication, we replace zero counts of P vjCi by PCi/N, where N is the total number of training examples	0	Other more complex smoothing procedures such as those used in <TREF>Gale et al , 1992a</TREF> are also possible, although we have not experimented with these other variations	1	For the experimental results reported in this paper, we used the implementation of Naive-Bayes algorithm in the PEBLS program <REF>Rachlin and Salzberg, 1993</REF>, which has an option for training and testing using the Naive-Bayes algorithm	0	We only changed the handling of zero probability counts to the method just described	0	6	1
W97-0323	P92-1032	1997	587 752 Naive-Bayes 582 745 Table 1: Experimental Results ures are those of <REF>Ng and Lee, 1996</REF>	0	The default strategy of picking the most frequent sense has been advocgted as the baseline performance for evaluating WSD programs <TREF>Gale et al , 1992b</TREF>; <REF>Miller et al , 1994</REF>	1	There are two instantiations of this strategy in our current evaluation	1	Since WORDNET orders its senses such that sense 1 is the most frequent sense, one possibility is to always pick sense 1 as the best sense assignment	0	3	2
W97-0323	P92-1032	1997	This is in spite of the conditional independence assumption made by the Naive-Bayes algorithm, which may be unjustified in the domains tested	1	Gale, Church and Yarowsky <TREF>Gale et al , 1992a</TREF>; <REF>Gale et al , 1995</REF>; <REF>Yarowsky, 1992</REF> have also successfully used the Naive-Bayes algorithm and several extensions and variations for word sense disambiguation	1	On the other hand, our past work on WSD <REF>Ng and Lee, 1996</REF> used an exemplar-based or nearest neighbor learning approach	0	Our WSD program, LEXAS, extracts a set of features, including part of speech and morphological form, surrounding words, local collocations, and verb-object syntactic relation from a sentence containing the word to be disambiguated	0	4	2
W97-0323	P92-1032	1997	Much recent research on word sense disambiguation WSD has adopted a corpus-based, learning approach	1	Many different learning approaches have been used, including neural networks <REF>Leacock et al , 1993</REF></REF>, probabilistic algorithms <REF>Bruce and Wiebe, 1994</REF>; <TREF>Gale et al , 1992a</TREF>; <REF>Gale et al , 1995</REF>; <REF>Leacock et al , 1993</REF></REF>; <REF>Yarowsky, 1992</REF>, decision lists <REF>Yarowsky, 1994</REF>, exemplar-based learning algorithms <REF>Cardie, 1993</REF>; <REF>Ng and Lee, 1996</REF>, etc In particular, <REF>Mooney 1996</REF> evaluated seven state-of-the-art machine learning algorithms on a common data set for disambiguating six senses of the word line	1	The seven algorithms that he evaluated are: a Naive-Bayes classifier <REF>Duda and Hart, 1973</REF>, a perceptron <REF>Rosenblatt, 1958</REF>, a decisiontree learner <REF>Quinlan, 1993</REF>, a k nearest-neighbor classifier exemplar-based learner <REF>Cover and Hart, 1967</REF>, logic-based DNF and CNF learners <REF>Mooney, 1995</REF>, and a decision-list learner <REF>Rivest, 1987</REF>	0	His results indicate that the simple Naive-Bayes algorithm gives the highest accuracy on the line corpus tested	0	3	2
C98-1066	P92-1032	1998	9 Related work Using vector space model and similarity measures for ranking is a common approach in IR for query/text and text/text comparisons <REF>Salton and Buckley, 1988</REF>; <REF>Salton and Yang, 1973</REF>; <REF>Croft, 1984</REF>; <REF>Turtle and Croft, 1992</REF>; <REF>Bookstein, 1983</REF>; <REF>Korflmge, 1995</REF>; <REF>Jones, 1979</REF>	1	This approach has also been used by <REF>Dagan and Itai, 1994</REF>; <TREF>Gale et al, 1992</TREF>; <REF>Shiitze, 1992</REF>; <REF>Gale et al, 1993</REF>; <REF>Yarowsky, 1995</REF>; Gale and Church, 1Lunar is not an unknown word in English, Yeltsin finds its translation in the 4-th candidate	1	Table 5: Some Chinese unknown word translation output score 0008421 0007895 0007669 0007588 0007283 0006812 0006430 0006218 0005921 0005527 0005335 0005335 0005221 0004731 0004470 0004275 0003878 0003859 0003859 0003784 0003686 0003550 0003519 0003481 0003407 0003407 0OO3338 0003324 0003250 0003206 0003202 0003040 0003033 0002888 0002886 English Chinese Teng-hui  Teng-hui SAR , SAR flu N m, Lei  Lei poultry j Poultry SAR  Chee-hwa hijack  Teng-hui poultry  SAR ,ng  Chee-hw Diaoyu  Teng-hui PrimeMinister  Teng-hui President  Teng-hui China  Lava Lien  Teng-hui poultry  Chee-hwa China  Teng-hui flu  Lei PrivaeMinister -I Chee-hwa President 1; Chee-hwa poultry  Leung Kalkanov i Zhuhai poultry I Lei SAR 1 J l Yeltsin Zhuhai -1 l Chee-hwa PrimeMinister  Lain President  Lava flu  Poultry apologise  Teng-hui Dee  Teng-hui Tang J Tang iSlng  Leung Leung : Leung China tN SAR Zhuhai  Lunar Ttulg  Tung 1994 for sense disambiguation between multiple usages of the same word	0	Some of the early statistical terminology translation methods are <REF>Brown et al, 1993</REF>; <REF>Wu and Xia, 1994</REF>; <REF>Dagan and Church, 1994</REF>; <REF>Gale and Church, 1991</REF>; <REF>Kupiec, 1993</REF>; <REF>Smadja et al, 1996</REF>; Kay and R<REF>Sscheisen, 1993</REF>; <REF>Fung and Church, 1994</REF>; <REF>Fhmg, 1995b</REF>	0	4	2
C98-1066	P92-1032	1998	It remains to be seen how we can also make use of the multilingual texts as NLP resources	0	In the years since the appearance of the first papers on using statistical models for bilingual lexicon compilation and machine translation<REF>Brown et al, 1993</REF>; <REF>Brown et al, 1991</REF>; <REF>Gale and <REF>Church, 1993</REF></REF>; <REF>Church, 1993</REF>; <REF>Simard et al, 1992</REF>, large amount of human effort and time has been invested in collecting parallel corpora of translated texts	1	Our goal is to alleviate this effort and enlarge the scope of corpus resources by looking into monolingual, comparable texts	1	This type of texts are known as nonparallel corpora	0	5	2
P97-1035	P92-1032	1997	The PARADISE model posits that performance can be correlated with a meaningful external criterion such as usability, and thus that the overall goal of a spoken dialogue agent is to maximize an objective related to usability	0	User satisfaction ratings <REF>Kamm, 1995</REF>; <REF>Shriberg, Wade, and Price, 1992</REF>; <REF>Polifroni et al , 1992</REF> have been frequently used in the literature as an external indicator of the usability of a dialogue agent	1	The model further posits that two types of factors are potential relevant contributors to user satisfaction namely task success and dialogue costs, and that two types of factors are potential relevant contributors to costs <REF>Walker, 1996</REF>	0	In addition to the use of decision theory to create this objective structure, other novel aspects of PARADISE include the use of the Kappa coefficient <REF>Carletta, 1996</REF>; <REF>Siegel and Castellan, 1988</REF> to operationalize task success, and the use of linear regression to quantify the relative contribution of the success and cost factors to user satisfaction	0	3	2
P97-1035	P92-1032	1997	An agents responses to a query are compared with a predefined key of minimum and maximum reference answers; performance is the proportion of responses that match the key	0	This approach has many widely acknowledged limitations <REF>Hirschman and Pao, 1993</REF>; <REF>Danieli et al , 1992</REF>; <REF>Bates and Ayuso, 1993</REF>, eg, although there may be many potential dialogue strategies for carrying out a task, the key is tied to one particular dialogue strategy	1	In contrast, agents using different dialogue strategies can be compared with measures such as inappropriate utterance ratio, turn correction ratio, concept accuracy, implicit recovery and transaction success Danieli LWe use the term agent to emphasize the fact that we are evaluating a speaking entity that may have a personality	0	Readers who wish to may substitute the word system wherever agent is used	0	4	2
E99-1046	P92-1032	1999	The problems arise because most sense distinctions are not as clear as the distinction between river bank and money bnk, so it is not always straightforward for a person to say what the correct answer is Thus we do not always know what it would mean to say that a computer program got the right answer	0	The issue is discussed in detail by <TREF>Gale et al , 1992</TREF> who identify the problem as one of identifying the upper bound for the performance of a WSD program	1	If people can only agree on the correct answer x of the time, a claim that a program achieves more than x accuracy is hard to interpret, and x is the upper bound for what the program can meaningfully achieve	0	There have been some discussions as to what this upper bound might be	0	4	2
W00-1322	P92-1032	2000	Although this methodology could be valid for certain NLP problems, such as English Part-of-Speech tagging, we think that there exists reasonable evidence to say that, in WSD, accuracy results cannot be simply extrapolated to other domains contrary to the opinion of other authors <REF>Ng, 1997b</REF>: On the aSupervised approaches, also known as data-driven or corpus-dmven, are those that learn from a previously semantically annotated corpus	0	172 one hand, WSD is very dependant to the domain of application <TREF>Gale et al , 1992b</TREF> --see also <REF>Ng and Lee, 1996</REF>; <REF>Ng, 1997a</REF>, in which quite different accuracy figures are obtained when testing an exemplar-based WSD classifier on two different corpora	1	Oi1 the other hand, it does not seem reasonable to think that the training material is large and representative enough to cover all potential types of examples	0	To date, a thorough study of the domain dependence of WSD --in the style of other studies devoted to parsing <REF>Sekine, 1997</REF>-has not been carried out	0	4	2
W00-1322	P92-1032	2000	In order to corroborate the previous hypotheses, this paper explores the portability and tuning of four different ML algorithms previously applied to WSD by training and testing them on different corpora	0	Additionally, supervised methods suffer from the knowledge acquisition bottleneck <TREF>Gale et al , 1992a</TREF>	1	<REF>Ng, 1997b</REF> estimates that the manual annotation effort necessary to build a broad coverage semantically annotated English corpus is about 16 personyears	0	This overhead for supervision could be much greater if a costly tuning procedure is required before applying any existing system to each new domain	0	4	2
W96-0208	P92-1032	1996	A recent special issue of the Machine Learning journal on Bias Evaluation and Selection introduced by Gordon and des<REF>Jardins 1995</REF> presents current research in this general area	0	Learning to Disambiguate Word Senses Several recent research projects have taken a corpus-based approach to lexical disambiguation Brown, Della-Pietra, Della-<REF>Pietra,  Mercer, 1991</REF>; <TREF>Gale, Church,  Yarowsky, 1992b</TREF>; <REF>Leacock et al , 1993b</REF>; <REF>Lehman, 1994</REF>	1	The goal is to learn 2This explanation was originally presented by Shavlik et al	0	1991	0	6	1
J98-4002	P92-1032	1998	Word sense disambiguation is a potentially crucial task in many NLP applications, such as machine translation Brown, Della Pietra, and <REF>Della Pietra 1991</REF>, parsing <REF>Lytinen 1986</REF>; <REF>Nagao 1994</REF> and text retrieval <REF>Krovets and Croft 1992</REF>; <REF>Voorhees 1993</REF>	0	Various corpus-based approaches to word sense disambiguation have been proposed <REF>Bruce and Wiebe 1994</REF>; <REF>Charniak 1993</REF>; <REF>Dagan and Itai 1994</REF>; <REF>Fujii et al 1996</REF>; <REF>Hearst 1991</REF>; <REF>Karov and Edelman 1996</REF>; <REF>Kurohashi and Nagao 1994</REF>; <REF>Li, Szpakowicz, and Matwin 1995</REF>; <REF>Ng and Lee 1996</REF>; <REF>Niwa and Nitta 1994</REF>; Schitze 1992; <REF>Uramoto 1994b</REF>; <REF>Yarowsky 1995</REF>	1	The use of corpus-based approaches has grown with the use of machine-readable text, because unlike conventional rule-based approaches relying on hand-crafted selectional rules some of which are reviewed, for example, by Hirst 1987, corpus-based approaches release us from the task of generalizing observed phenomena through a set of rules	1	Our verb sense disambiguation system is based on such an approach, that is, an example-based approach	0	5	2
W97-0206	P92-1032	1997	Statistically, one would therefore expect the first sense to be the one that is chosen as the most appropriate one in most cases	0	<TREF>Gale et al , 1992</TREF> estimate that automatic sense disambignation would be a, least 75 correct if a system ignored context and assigned the most frequently occurring sense	1	<REF>Miller et al , 1994</REF> found that automatic assignment of polysemous words in the Brown Corpus to senses in WordNet was correct 58 of the time with a guessing heuristic that assumed the most frequently occurring sense to be the correct one	0	The taggers whose work is analyzed here were not aware of the frequency ordering of the senses	0	6	1
C96-1006	P93-1003	1996	With the growing wdume of text available in electronic lorm, a number of methods have been proposed tor extracting word correspondences from bilingual corpora automatically	0	These methods can be divided into those taking a statistical approach <REF>Gale  Church 1991a</REF>; <TREF>Kupiec 1993</TREF>; <REF>Dagan et al 1993</REF>; <REF>Inoue  Nogaito 1993</REF>; <REF>Fung 1995</REF> and those taking a linguistic approach <REF>Yamamoto  Sakamoto 1993</REF>; Kummo  <REF>Hirakawa 1994</REF>; <REF>Ishimoto  Nagao 1994</REF>	1	The statistical approach utilizes the occurrence frequencies and locations of words in a parallel corpus to calculate the pairwise correlations between the words in the two languages	0	The linguistic approach primarily extracts correspondences between compound words by consulting a bilingual dictionary of simple words	0	2	1
W99-0902	P93-1003	1999	5 Other applications of this research Other than the constraints described in Section 2 and frequency determination techniques, the proposed methodology is theoretically scalable to any domain where two streams of chunked information require alignment	0	This suggests applications to the extraction of translation pairs from aligned bilingual corpora <REF>Gale and Church, 1991</REF>; <TREF>Kupiec, 1993</TREF>; <REF>Smadja et al , 1996</REF>, where the system input would be made up of aligned strings generally sentences in the two languages	1	Given that we can devise some way of creating an alignment paradigm between the two input segments, it is possible to apply the scoring and learning methods proposed herein in their existing forms	0	Note, however, that in the case of translation pair extraction, there is a real possibility of the alignment mapping being many-to-many, and crossing over of alignment is expected to occur readily	0	6	1
C08-1067	P93-1003	2008	This paper presents a novel terminology extraction method applied to the French-English part of the database	0	There is a long tradition of research into bilingual terminology extraction <TREF>Kupiec, 1993</TREF>, Gaussier,1998	1	Inmostsystems,candidateterms are first identified in the source language based on predefined PoS patterns  for French, N N, N Prep N, and N Adj are typical patterns	0	In a second step, the translation candidates are extracted from the bilingual corpus based on word alignments	0	6	1
J97-2004	P93-1003	1997	Alignment at other levels of resolution is obviously useful	1	A section, paragraph, sentence, phrase, collocation, or word can be aligned to its translation <TREF>Kupiec 1993</TREF>; <REF>Smadja, McKeown, and Hatzivassiloglou 1996</REF>	1	Other logical approaches involve aligning parse trees of a sentence and its translation <REF>Matsumoto, Ishimoto, and Utsuro 1993</REF>; <REF>Meyers, Yangarber, and Grishman 1996</REF>, or simultaneously generating parse trees and alignment arrangements <REF>Wu 1995</REF>	0	Department of Computer Science, National Tsing Hua University, Hsinchu, 30043, Taiwan, ROC	0	1	2
C98-1071	P93-1003	1998	Prec	0	100 97 200 94 Table 2: Multiword notion results As a comparison, <TREF>Kupiec, 1993</TREF> obtained a precision of 90 for the first hundred associations between English and French noun phrases, using the EM algorithm	1	Our experiments with a similar method showed a precision around 92 for the first hundred associations on a set of aligned sentences comprising the one used for the above experiment	1	Art evaluation on single words, showed a precision of 98 for the first hundred and 97 for the first two hundred	1	1	3
C98-1071	P93-1003	1998	3 Multilingual terminology extraction Several works describe methods to extract terms, or candidate terms, in English and/or French <REF>Justeson and Katz, 1995</REF>; <REF>Daille, 1994</REF>; Nkwenti-<REF>Azeh, 1992</REF>	0	Some more specific works describe methods to align noun phrases within parallel corpora <TREF>Kupiec, 1993</TREF>	1	The underlying assumption beyond these works is that the monolingually extracted units correspond to each other cross-lingually	0	Unfortunately, this is not always the case, and the above methodology suffers flom the weaknesses pointed out by <REF>Wu, 1997</REF> concerning parse-parse-match procedures	1	1	3
P97-1061	P93-1003	1997	In addition, new collocations are produced one after another and most of them are technical jargons	0	There has been a growing interest in corpus-based approaches which retrieve collocations from large corpora <REF>Nagao and Mori, 1994</REF>, <REF>Ikehara et al , 1996</REF> <TREF>Kupiec, 1993</TREF>, <REF>Fung, 1995</REF>, <REF>Kitamura and Matsumoto, 1996</REF>, <REF>Smadja, 1993</REF>, <REF>Smadja et al , 1996</REF>, <REF>Haruno et al , 1996</REF>	1	Although these approaches achieved good results for the task considered, most of them aim to extract fixed collocations, mainly noun phrases, and require the information which is dependent on each language such as dictionaries and parts of speech	1	From a practical point of view, however, a more robust and flexible approach is desirable	0	1	3
W03-0314	P93-1003	2003	This highlights the need for finding multi-word translation correspondences	0	Previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences <TREF>Kupiec, 1993</TREF>, fixed/flexible collocations <REF>Smadja et al , 1996</REF>, n-gram word sequences of arbitrary length <REF>Kitamura and Matsumoto, 1996</REF>, non-compositional compounds <REF>Melamed, 2001</REF>, captoids <REF>Moore, 2001</REF>, and named entities 1	1	In all of these approaches, a common problem seems to be an identification of meaningful multi-word translation units	1	There are a number of factors which make handling of multi-word units more complicated than it appears	1	1	3
W03-0314	P93-1003	2003	Previous approaches effectively narrow down its search space by some heuristics	0	<TREF>Kupiec 1993</TREF> focuses on noun-phrase translations only, Smadja et al	1	1996 limits to find French translation of English collocation identified by his Xtract system, and <REF>Kitamura and Matsumoto 1996</REF> can exhaustively enumerate only rigid word sequences	1	Many of works mentioned in the last paragraph as well as ours extract non-probabilistic translation lexicons	0	2	1
P99-1043	P93-1003	1999	Co-occurrence information between neighboring words and words in the same sentence has been used in phrase extraction <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>, phrasal translation <REF>Smadja et al , 1996</REF>; <TREF>Kupiec, 1993</TREF>; <REF>Wu, 1995</REF>; <REF>Dagan and Church, 1994</REF>, target word selection <REF>Liu and Li, 1997</REF>; <REF>Tanaka and Iwasaki, 1996</REF>, domain word translation <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, sense disambiguation <REF>Brown et al , 1991</REF>; <REF>Dagan et al , 1991</REF>; <REF>Dagan and Itai, 1994</REF>; <REF>Gale et al , 1992a</REF>; <REF>Gale et al , 1992b</REF>; <REF>Gale et al , 1992c</REF>; <REF>Shiitze, 1992</REF>; <REF>Gale et al , 1993</REF>; <REF>Yarowsky, 1995</REF>, and even recently for query translation in cross-language IR as well <REF>Ballesteros and Croft, 1998</REF>	1	Co-occurrence statistics is collected from either bilingual parallel and 334 non-parallel corpora <REF>Smadja et al , 1996</REF>; <TREF>Kupiec, 1993</TREF>; <REF>Wu, 1995</REF>; <REF>Tanaka and Iwasaki, 1996</REF>; <REF>Fung and Lo, 1998</REF>, or monolingual corpora <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>; <REF>Liu and Li, 1997</REF>; <REF>Shiitze, 1992</REF>; <REF>Yarowsky, 1995</REF>	1	As we noted in <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, parallel corpora are rare in most domains	0	We want to devise a method that uses only monolingual data in the primary language to train co-occurrence information	0	6	1
P99-1043	P93-1003	1999	pruning translation alternatives for query translation	0	Co-occurrence information between neighboring words and words in the same sentence has been used in phrase extraction <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>, phrasal translation <REF>Smadja et al , 1996</REF>; <TREF>Kupiec, 1993</TREF>; <REF>Wu, 1995</REF>; <REF>Dagan and Church, 1994</REF>, target word selection <REF>Liu and Li, 1997</REF>; <REF>Tanaka and Iwasaki, 1996</REF>, domain word translation <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, sense disambiguation <REF>Brown et al , 1991</REF>; <REF>Dagan et al , 1991</REF>; <REF>Dagan and Itai, 1994</REF>; <REF>Gale et al , 1992a</REF>; <REF>Gale et al , 1992b</REF>; <REF>Gale et al , 1992c</REF>; <REF>Shiitze, 1992</REF>; <REF>Gale et al , 1993</REF>; <REF>Yarowsky, 1995</REF>, and even recently for query translation in cross-language IR as well <REF>Ballesteros and Croft, 1998</REF>	1	Co-occurrence statistics is collected from either bilingual parallel and 334 non-parallel corpora <REF>Smadja et al , 1996</REF>; <TREF>Kupiec, 1993</TREF>; <REF>Wu, 1995</REF>; <REF>Tanaka and Iwasaki, 1996</REF>; <REF>Fung and Lo, 1998</REF>, or monolingual corpora <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>; <REF>Liu and Li, 1997</REF>; <REF>Shiitze, 1992</REF>; <REF>Yarowsky, 1995</REF>	1	As we noted in <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, parallel corpora are rare in most domains	0	6	1
J97-3002	P93-1003	1997	It can now be assumed that a parallel bilingual corpus may be aligned to the sentence level with reasonable accuracy Kay and Ri3cheisen 1988; <REF>Catizone, Russel, and Warwick 1989</REF>; <REF>Gale and Church 1991</REF>; <REF>Brown, Lai, and Mercer 1991</REF>; <REF>Chen 1993</REF>, even for languages as disparate as Chinese and English <REF>Wu 1994</REF>	0	Algorithms for subsentential alignment have been developed as well as granularities of the character <REF>Church 1993</REF>, word <REF>Dagan, Church, and Gale 1993</REF>; <REF>Fung and Church 1994</REF>; <REF>Fung and McKeown 1994</REF>, collocation <REF>Smadja 1992</REF>, and specially segmented <TREF>Kupiec 1993</TREF> levels	1	However, the identification of subsentential, nested, phrasal translations within the parallel texts remains a nontrivial problem, due to the added complexity of dealing with constituent structure	1	Manual phrasal matching is feasible only for small corpora, either for toy-prototype testing or for narrowly restricted applications	0	1	3
P98-1069	P93-1003	1998	Table 5: tion out score 0008421 0007895 0007669 0007588 0007283 0006812 0006430 0006218 0005921 0005527 0005335 0005335 0005221 0004731 0004470 0004275 0003878 0003859 0003859 0003784 0003686 0003550 0003519 0003481 0003407 0003407 0003338 0003324 Some Chinese ut English Teng-hui SAR flu Lei poultry SAR hijack poultry Tung Diaoyu PrimeMinister President China Lien poultry China flu PrimeMinister President poultry Kalkanov poultry SAR Zhuhai PrimeMinister President flu apologise unknown word translaChinese  Weng-hui  u Lei j Poultry  Chee-hwa  Teng-hui  SAR  Chee-hwa : Teng-hui  Weng-hui W Weng-hui CLam  Teng-hui - Chee-hwa  Teng-hui Lei  Chee-hwa  Chee-hwa  Leung  Zhuhai I Lei J Yeltsin - Chee-hwa  Lam Lam j Poultry W Teng-hui 0003250 DPP 0003206 Tang 0003202 Tung 0003040 Leung 0003033 China 0002888 Zhuhai 0002886 Tung  Teng-hui Tang Leung Leung  SAR  Lunar Tung 1994 for sense disambiguation between multiple usages of the same word	0	Some of the early statistical terminology translation methods are <REF>Brown et al , 1993</REF>; <REF>Wu and Xia, 1994</REF>; <REF>Dagan and Church, 1994</REF>; <REF>Gale and Church, 1991</REF>; <TREF>Kupiec, 1993</TREF>; <REF>Smadja et al , 1996</REF>; Kay and R<REF>Sscheisen, 1993</REF>; <REF>Fung and Church, 1994</REF>; <REF>Fung, 1995b</REF>	1	These algorithms all require parallel, translated texts as input	0	Attempts at exploring nonparallel corpora for terminology translation are very few <REF>Rapp, 1995</REF>; <REF>Fung, 1995a</REF>; <REF>Fung and McKeown, 1997</REF>	0	6	1
J06-3001	P93-1003	2006	Other corpus-based methods determine associations between words <REF>Grefenstette 1992</REF>; <REF>Dunning 1993</REF>; <REF>Lin et al 1998</REF>, which yields a basis for computing thesauri, or dictionaries of terminological expressions and multiword lexemes <REF>Gaizauskas, Demetriou, and Humphreys 2000</REF>; <REF>Grefenstette 2001</REF>	0	From multilingual texts, translation lexica can be generated <REF>Gale and Church 1991</REF>; <TREF>Kupiec 1993</TREF>; <REF>Kumano and Hirakawa 1994</REF>; <REF>Boutsis, Piperidis, and Demiros 1999</REF>; <REF>Grefenstette 1999</REF>	1	The analysis of technical texts is used to automatically build dictionaries of acronyms for a given field <REF>Taghva and Gilbreth 1999</REF>; <REF>Yeates, Bainbridge, and Witten 2000</REF>, and related methods help to compute dictionaries that cover the special vocabulary of a given thematic area <REF>Strohmaier et al 2003a</REF>	0	In computer-assisted language learning CALL, mining techniques for corpora are used to create individualized and user-centric exercises for grammar and text understanding <REF>Schwartz, Aikawa, and Pahud 2004</REF>; <REF>Brown and Eskenazi 2004</REF>; <REF>Fletcher 2004a</REF>	0	6	1
P96-1018	P93-1003	1996	Experimental results show our system outperforms conventional methods for various kinds of Japanese-English texts	0	Corpus-based approaches based on bilingual texts are promising for various applicationsie , lexical knowledge extraction <TREF>Kupiec, 1993</TREF>; <REF>Matsumoto et al , 1993</REF>; <REF>Smadja et al , 1996</REF>; <REF>Dagan and Church, 1994</REF>; <REF>Kumano and Hirakawa, 1994</REF>; <REF>Haruno et al , 1996</REF>, machine translation Brown and others, 1993; <REF>Sato and Nagao, 1990</REF>; <REF>Kaji et al , 1992</REF> and information retrieval <REF>Sato, 1992</REF>	1	Most of these works assume voluminous aligned corpora	0	Many methods have been proposed to align bilingual corpora	0	6	1
C94-1009	P93-1003	1994	4 GENERATING TRANSLATION CANDIDATES 41 Extraction of Japanese Terms Errors in the extraction of terms and phrases from parallel texts eventually lead to a failure in acquiring the correct term/phrase correspondences	0	<REF>In Kupiec 1993</REF> and <REF>Yamamoto 1993</REF>, term and phrase extraction is applied to both of parallel texts	1	In contrast, we extract from units only Japanese terms, thereby reducing the errors caused by term/phrase recognizer	1	Japanese NPs can be recognized more accurately than English NPs because Japanese has considerably less multi-category words	0	1	3
C94-1009	P93-1003	1994	Statistics-based processing has proven to be very powerful for aligning sentences and words in parallel corpora <REF>Brown, 1991</REF>; <REF>Gale, 1993</REF>; <REF>Chen, 1993</REF>	0	Kupiec proposes an Mgorithm for finding loun phrases in bilingual corpora <TREF>Kupiec, 1993</TREF>	1	In this algo o rithm, noui-phrase candidates are extracted from tagged and aligned parallel texts using a noun phrase recognizer and tile correspondences of these nonn phrases are calculated based on the EM algorithm	0	Accuracy of around 90 has been attained for the Imndred highest ranking conespondenccs	0	6	1
A00-1019	P93-1003	2000	It is also interesting to note that the good associations we found are not necessary compositional in nature we must/il Iaut, people of canada/les canadiens, of eourse/6videmment, etc	0	33 Filtering One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints <REF>Ganssier, 1995</REF>; <TREF>Kupiec, 1993</TREF>; hua Chen and Chen, 94; <REF>Fung, 1995</REF>; <REF>Evans and Zhai, 1996</REF>	1	It is also possible to focus on non-compositional compounds, a key point in bilingual applications <REF>Su et al , 1994</REF>; <REF>Melamed, 1997</REF>; Lin, 99	0	Another interesting approach is to restrict sequences to those that do not cross constituent boundary patterns <REF>Wu, 1995</REF>; Furuse and Iida, 96	0	6	1
A94-1006	P93-1003	1994	Unfortunately, these technologies are still not as widely deployed in practical applications as they might be	0	Part-ofspeech taggers are used in a few applications, such as speech synthesis <REF>Sproat et al , 1992</REF> and question answering <TREF>Kupiec, 1993b</TREF>	1	Word alignment is newer, found only in a few places <REF>Gale and Church, 1991a</REF>; <REF>Brown et al , 1993</REF>; <REF>Dagan et al , 1993</REF>	0	It is used at IBM for estimating parameters of their statistical machine translation prototype Brown et Authors current address: Dept of Mathematics and Computer Science, Bar Ilan University, Ramat Gan 52900, Israel	0	6	1
W03-0317	P93-1003	2003	Automatic bilingual lexicon construction based on bilingual corpora has become an important first step for many studies and applications of natural language processing NLP, such as machine translation MT, crosslanguage information retrieval CLIR, and bilingual text alignment	0	As noted in <REF>Tsuji 2002</REF>, many previous methods <REF>Dagan et al , 1993</REF>; <TREF>Kupiec, 1993</TREF>; <REF>Wu and Xia, 1994</REF>; <REF>Melamed, 1996</REF>; <REF>Smadja et al , 1996</REF> deal with this problem based on frequency of words appearing in the corpora, which can not be effectively applied to lowfrequency words, such as transliterated words	1	These transliterated words are often domain-specific and created frequently	0	Many of them are not found in existing bilingual dictionaries	0	1	3
W97-0311	P93-1003	1997	There has been some research into matching compositional phrases across bitexts	0	For example, <TREF>Kupiec 1993</TREF> presented a method for finding translations of whole noun phrases	1	<REF>Wu 1995</REF> showed how to use an existing translation lexicon to populate a database of phrasal correspondences for use in example-based MT These compositional translation patterns enable more sophisticated approaches to MT However, they are only useful if they can be discovered reliably and efficiently	0	Their time may come when we have a better understanding of how to model the human translation process	0	6	1
P06-2035	P93-1003	2006	<REF>Tiedemann, 1993</REF> ; <REF>Boutsis  Piperidis, 1996</REF> ; <REF>Piperidis et al , 1997</REF> combine statistical and linguistic information for the same task	0	Some methods make alignment suggestions at an intermediate level between sentence and word 271 and word <REF>Smadja, 1992</REF> ; <REF>Smadja et al , 1996</REF> ; <TREF>Kupiec, 1993</TREF> ; <REF>Kumano  Hirakawa, 1994</REF> ; <REF>Boutsis  Piperidis, 1998</REF>	1	A common problem is the delimitation and spotting of the units to be matched	1	This is not a real problem for methods aiming at alignments at a high level of granularity paragraphs, sentences where unit delimiters are clear	0	1	3
P95-1032	P93-1003	1995	We have been studying robust lexicon compilation methods which do not rely on sentence alignment	0	Existing lexicon compilation methods <TREF>Kupiec 1993</TREF>; <REF>Smadja  McKeown 1994</REF>; <REF>Kumano  Hirakawa 1994</REF>; <REF>Dagan et al 1993</REF>; <REF>Wu  Xia 1994</REF> all attempt to extract pairs of words or compounds that are translations of each other from previously sentencealigned, parallel texts	1	However, sentence alignment <REF>Brown et al 1991</REF>; Kay  R<REF>Sscheisen 1993</REF>; <REF>Gale  <REF>Church 1993</REF></REF>; <REF>Church 1993</REF>; <REF>Chen 1993</REF>; <REF>Wu 1994</REF> is not always practical when corpora have unclear sentence boundaries or with noisy text segments present in only one language	1	Our proposed algorithm for bilingual lexicon acquisition bootstraps off of corpus alignment procedures we developed earlier <REF>Fung  Church 1994</REF>; <REF>Fung  McKeown 1994</REF>	0	1	3
P04-1068	P93-1003	2004	Compilation of translation lexicons is a crucial process for machine translation MT <REF>Brown et al , 1990</REF> and cross-language information retrieval CLIR systems <REF>Nie et al , 1999</REF>	0	A lot of effort has been spent on constructing translation lexicons from domain-specific corpora in an automatic way <REF>Melamed, 2000</REF>; <REF>Smadja et al , 1996</REF>; <TREF>Kupiec, 1993</TREF>	1	However, such methods encounter two fundamental problems: translation of regional variations and the lack of up-to-date and high-lexical-coverage corpus source, which are worthy of further investigation	1	The first problem is resulted from the fact that the translations of a term may have variations in different dialectal regions	0	1	3
P98-1074	P93-1003	1998	Prec	0	100 97 200 94 Table 2: Multiword notion results As a comparison, <TREF>Kupiec, 1993</TREF> obtained a precision of 90 for the first hundred associations between English and French noun phrases, using the EM algorithm	1	Our experiments with a similar method showed a precision around 92 for the first hundred associations on a set of aligned sentences comprising the one used for the above experiment	1	An evaluation on single words, showed a precision of 9870 for the first hundred and 97 for the first two hundred	0	1	3
P98-1074	P93-1003	1998	3 Multilingual terminology extraction Several works describe methods to extract terms, or candidate terms, in English and/or French <REF>Justeson and Katz, 1995</REF>; <REF>Daille, 1994</REF>; Nkwenti-<REF>Azeh, 1992</REF>	0	Some more specific works describe methods to align noun phrases within parallel corpora <TREF>Kupiec, 1993</TREF>	1	The underlying assumption beyond these works is that the monolingually extracted units correspond to each other cross-lingually	0	Unfortunately, this is not always the case, and the above methodology suffers from the weaknesses pointed out by <REF>Wu, 1997</REF> concerning parse-parse-match procedures	1	1	3
C96-1089	P93-1003	1996	<TREF>Kupiec, 1993</TREF>; Kumano and lirakawa, 1194 extracted noun phrme NP correspondences from aligned parallel corpora	1	n <TREF>Kupiec, 1993</TREF>, Nls in English and French t;exts are first extracted by a NP recoguizer	1	Their correspotldence prol> abilities arc then gradually relined by using an EM-like iteration algorithm	0	t,umano and <REF>Ilirakawa, 1994</REF> lirst extractedJapanese N Ps in the SIII	1	2	1
C96-1089	P93-1003	1996	Although these methods ;re rob/Is HII aSSllllle rio illfOllllttiOll SOltrce their outputs are just word-word correslotMences	0	<TREF>Kupiec, 1993</TREF>; Kumano and lirakawa, 1194 extracted noun phrme NP correspondences from aligned parallel corpora	1	n <TREF>Kupiec, 1993</TREF>, Nls in English and French t;exts are first extracted by a NP recoguizer	1	Their correspotldence prol> abilities arc then gradually relined by using an EM-like iteration algorithm	0	6	1
C00-1058	P93-1003	2000	After that, the two data are merged to make input for the cluster generation module	0	a Statistical weighting Many methods of extracting lexical translation pairs have been proposed <REF>Daille, Gaussier  Langd 1994</REF>; Eijk t993; <REF>Fung 1995</REF>; Gale  <REF>Church 1991</REF>; <REF>Hiemstra 1996</REF>; ltull 1998; <TREF>Kupiec 1993</TREF>; <REF>Melamed 1996</REF>; <REF>Smadja, McKeown  Hatzivmssiloglou 1996</REF>	1	Though it, is ditficult to evaluate the performance of existing methods as they use ditferent corpora for evaluation 5, the performance does not seem to be radically different	0	We adopted log-likelihood ratio <REF>Danning 1993</REF>, which gave the best pertbrmance among crude non-iterative methods in our test experiments 6 	0	6	1
W95-0114	P93-1003	1995	We present an algorithm in finding word correlation statistics for automatic bilingual lexicon compilation from a non-parallel corpus in Chinese and English	0	Most previous automatic lexicon compilation techniques require a sentence-aligned clean parallel bilingual corpus <TREF>Kupiec 1993</TREF>; <REF>Smadja  McKeown 1994</REF>; <REF>Kumano  Hirakawa 1994</REF>; <REF>Dagan et al 1993</REF>; <REF>Wu  Xia 1994</REF>	1	We have previously shown an algorithm which extracts a bilingual lexicon from noisy parallel corpus without sentence alignment <REF>Fung  McKeown 1994</REF>; <REF>Fung 1995</REF>	1	Although bilingual parallel corpora have been available in recent years, they are still relatively few in comparison to the large amount of monolingual text	0	1	3
W95-0114	P93-1003	1995	173 As demonstrated in all the bilingual lexicon compilation algorithms, the foremost task is to identify word features which are similar between a word and its translation, yet different between a word and other words which are not its translations	0	In parallel corpora, this feature could be the positional co-occurrence of a word and its translation in the other language in the same sentences <TREF>Kupiec 1993</TREF>; <REF>Smadja  McKeown 1994</REF>; <REF>Kumano  Hirakawa 1994</REF>; <REF>Dagan et al 1993</REF>; <REF>Wu  Xia 1994</REF> or in the same segments <REF>Fung  Church 1994</REF>; <REF>Fung 1995</REF>	1	In a non-parallel corpus, there is no corresponding sentence or segment pairs, so the co-occurrence feature is not applicable	0	<REF>In Fung  McKeown 1994</REF>; <REF>Fung 1995</REF>, the word feature used was the positional difference vector	0	6	1
C98-1066	P93-1003	1998	Table 5: Some Chinese unknown word translation output score 0008421 0007895 0007669 0007588 0007283 0006812 0006430 0006218 0005921 0005527 0005335 0005335 0005221 0004731 0004470 0004275 0003878 0003859 0003859 0003784 0003686 0003550 0003519 0003481 0003407 0003407 0OO3338 0003324 0003250 0003206 0003202 0003040 0003033 0002888 0002886 English Chinese Teng-hui  Teng-hui SAR , SAR flu N m, Lei  Lei poultry j Poultry SAR  Chee-hwa hijack  Teng-hui poultry  SAR ,ng  Chee-hw Diaoyu  Teng-hui PrimeMinister  Teng-hui President  Teng-hui China  Lava Lien  Teng-hui poultry  Chee-hwa China  Teng-hui flu  Lei PrivaeMinister -I Chee-hwa President 1; Chee-hwa poultry  Leung Kalkanov i Zhuhai poultry I Lei SAR 1 J l Yeltsin Zhuhai -1 l Chee-hwa PrimeMinister  Lain President  Lava flu  Poultry apologise  Teng-hui Dee  Teng-hui Tang J Tang iSlng  Leung Leung : Leung China tN SAR Zhuhai  Lunar Ttulg  Tung 1994 for sense disambiguation between multiple usages of the same word	0	Some of the early statistical terminology translation methods are <REF>Brown et al, 1993</REF>; <REF>Wu and Xia, 1994</REF>; <REF>Dagan and Church, 1994</REF>; <REF>Gale and Church, 1991</REF>; <TREF>Kupiec, 1993</TREF>; <REF>Smadja et al, 1996</REF>; Kay and R<REF>Sscheisen, 1993</REF>; <REF>Fung and Church, 1994</REF>; <REF>Fhmg, 1995b</REF>	1	These algorithms all require parallel, translated texts as input	0	Attempts at exploring nonparallel corpora for terminology translation are very few <REF>Rapp, 1995</REF>; <REF>Fung, 1995</REF>3; <REF>Fung and McKeown, 1997</REF>	0	6	1
W97-0114	P93-1003	1997	The technique for acquiring various kinds of rules such as translation rules, grammar rules, dictionary entries and so on from bilingual corpora needs to include several kinds of sub-techniques; identification of aligned sentence pairs which consist of pairs of one language sentence and translation equivalents of the sentence sentence alignment; identification of equivalent words/phrases pairs from aligned sentence pairs word alignment; and extraction of rules such as translation rules, grammar rules, dictionary entries and so on from identified aligned sentence pairs and equivalent word/phrase pairs	0	Several methods have been proposed with regard to aligning sentences <REF>Brown et al , 1991</REF>; <REF>Gale and Church, 1991</REF>; <REF>Haruno and Yamazaki, 1996</REF>; Kay and losche/sen, 1993, alJsnlng words <REF>Church, 1993</REF>; <TREF>Kupiec, 1993</TREF>; <REF>Matsumoto et al , 1993</REF>; <REF>Wu, 1995</REF>; <REF>Yamada et al , 1996</REF> and acquiring rules from bilingual corpora <REF>Dagan et al , 1991</REF>; <REF>Dagan and Church, 1994</REF>; <REF>Fung and Church, 1994</REF>; Tana, 1994; <REF>Yamada et al , 1995</REF>	1	From the point of view of the extraction of resolution rules of zero pronouns, a technique to identify zero pronouns in a sentence in one language and their antecedents in a translation from aligned sentence pairs is needed	0	But there is currently no method to identify zero pronouns and their antecedents automatically within bilingual corpora	0	6	1
P04-1022	P93-1003	2004	2003 propose a method to extract bilingual collocations using recursive chain-link-type learning	0	In addition to collocation translation, there is also some related work in acquiring phrase or term translations from parallel corpus <TREF>Kupiec, 1993</TREF>; <REF>Yamamoto and Matsumoto 2000</REF>	1	Since large aligned bilingual corpora are hard to obtain, some research has been conducted to exploit translation knowledge from non-parallel corpora	0	Their work is mainly on word level	0	6	1
P04-1022	P93-1003	2004	<REF>Smadja et al , 1996</REF>; <REF>Gao et al , 2002</REF>; <REF>Wu and Zhou, 2003</REF>	0	Some studies have been done for acquiring collocation translations using parallel corpora <REF>Smadja et al, 1996</REF>; <TREF>Kupiec, 1993</TREF>; Echizen-ya et al , 2003	1	These works implicitly assume that a bilingual corpus on a large scale can be obtained easily	1	However, despite efforts in compiling parallel corpora, sufficient amounts of such corpora are still unavailable	1	1	3
C94-2178	P93-1003	1994	1	0	Motivation There have been quite a number of recent papers on parallel text: Brown et al 1990, 1991, 1993, <REF>Chen 1993</REF>, <REF>Church 1993</REF>, <REF>Church et al 1993</REF>, <REF>Dagan et al 1993</REF>, Gale and Church 1991, 1993, <REF>Isabelle 1992</REF>, <REF>Kay and Rgsenschein 1993</REF>, <REF>Klavans and Tzoukermann 1990</REF>, <TREF>Kupiec 1993</TREF>, <REF>Matsumoto 1991</REF>, <REF>Ogden and Gonzales 1993</REF>, <REF>Shemtov 1993</REF>, <REF>Simard et al 1992</REF>, <REF>WarwickArmstrong and Russell 1990</REF>, Wu to appear	1	Most of this work has been focused on European language pairs, especially English-French	0	It remains an open question how well these methods might generalize to other language pairs, especially pairs such as English-Japanese and EnglishChinese	0	6	1
W93-0301	P93-1003	1993	More importantly, because wordalign and charalign were designed to work robustly on texts that are smaller and more noisy than the Hansards, it has been possible to successfully deploy the programs at ATT Language Line Services, a commercial translation service, to help them with difficult terminology	0	Aligning parallel texts has recently received considerable attention <REF>Warwick et al , 1990</REF>; <REF>Brown et al , 1991a</REF>; <REF>Gale and Church, 1991b</REF>; <REF>Gale and Church, 1991a</REF>; <REF>Kay and Rosenschein, 1993</REF>; <REF>Simard et al , 1992</REF>; <REF>Church, 1993</REF>; <TREF>Kupiec, 1993</TREF>; <REF>Matsumoto et al , 1993</REF>	1	These methods have been used in machine translation <REF>Brown et al , 1990</REF>; <REF>Sadler, 1989</REF>, terminology research and translation aids <REF>Isabelle, 1992</REF>; <REF>Ogden and Gonzales, 1993</REF>, bilingual lexicography <REF>Klavans and Tzoukermann, 1990</REF>, collocation studies <REF>Smadja, 1992</REF>, word-sense disambiguation <REF>Brown et al , 1991b</REF>; <REF>Gale et al , 1992</REF> and information retrieval in a multilingual environment <REF>Landauer and Littman, 1990</REF>	0	The information retrieval application may be of particular relevance to this audience	0	6	1
W04-3104	P94-1013	2004	The training of the Nave Bayes classifier consists of estimating the prior probabilities for different categories as well as the probabilities of each category for each feature	0	0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000 19 6 5 19 6 8 1 9 71 19 7 4 19 7 7 1 9 80 19 8 3 1 98 6 1 9 89 19 9 2 1 99 5 1 9 98 2 00 1 Year N u m b e r of C i t a t i ons Yeast Fly Worm Mouse 0 002 004 006 008 01 012 19 65 19 6 8 19 71 19 74 19 77 19 8 0 19 83 19 86 19 8 9 19 92 19 95 19 98 20 01 Year P r op or t i on Yeast Fly Worm Mouse The Decision List method DLL <TREF>Yarowsky, 1994</TREF> is equivalent to simple case statements in most programming languages	1	In a DLL classifier, a sequence of tests is applied to each feature vector	0	If a test succeeds, then the sense associated with that test is returned	0	6	1
P96-1030	P94-1013	1996	The minimum score derived from any of the criteria applied is deemed initially to be the score of the constituent	0	That is, an assumption of full statistical dependence <TREF>Yarowsky, 1994</TREF>, rather than the more common full independence, is made3 When llf events El, E2,, E, are fully independent, then the joint probability PE1 A A En is the product of PEIPEn, but if they are maximally dependent, it is the minimum of these values	1	Of course, neither assumption is any more than an approximation to the truth; but assuming dependence has the advantage that the estimate of the joint probability depends much less strongly on n, and so estimates for alternative joint events can be directly compared, without any possibly tricky normalization, even if they are composed of different numbers of atomic events	0	This property is desirable: different sub-paths through a chart may span different numbers of edges, and one can imagine evaluation criteria which are only defined for some kinds of edge, or which often duplicate information supplied by other criteria	0	3	2
E99-1024	P94-1013	1999	In this paper, we propose a method of detecting Japanese homophone errors in Japanese texts	0	Our method is based on a decision list proposed by Yarowsky <TREF>Yarowsky, 1994</TREF>; <REF>Yarowsky, 1995</REF>	1	We improve the original decision list by using written words in the default evidence	0	The improved decision list can raise the F-measure of error detection	0	5	2
E99-1024	P94-1013	1999	We also use the special evidence default, frqwl, default is defined as the frequency of wl	0	step5 Pick the highest strength estwh,ej among 5As in this paper, the addition of a small value is an easy and effective way to avoid the unsatisfactory case, as shown in <TREF>Yarowsky, 1994</TREF>	1	estwl, , eaw, e,   , e e, and set the word wk as the answer for the evidence ej	0	In this case, the identifying strength is estwk, ej	0	3	2
W06-3604	P94-1013	2006	Instead of viewing all positional features as containers of thousands of atomic word features, it treats the positional features as the basic tests, branching on the word values in the tree	0	More generally, as a precursor to the abovementioned work, confusable disambiguation has been investigated in a string of papers discussing the application of various machine learning algorithms to the task <TREF>Yarowsky, 1994</TREF>; <REF>Golding, 1995</REF>; Mangu 31 and <REF>Brill, 1997</REF>; <REF>Huang and Powers, 2001</REF>	1	6 Discussion In this article we explored the scaling abilities of IGTREE, a simple decision-tree algorithm with favorable asymptotic complexities with respect to multi-label classification tasks	0	IGTREE is applied to word prediction, a task for which virtually unlimited amounts of training examples are available, with very large amounts of predictable class labels; and confusable disambiguation, a specialization of word prediction focusing on small sets of confusable words	0	6	1
P06-1057	P94-1013	2006	Following commonpracticeinfeatureextractioneg	0	<TREF>Yarowsky, 1994</TREF>, and using the mxpost1 part of speech tagger and WordNets lemmatization, the following feature set was used: bag of word lemmas for the context words in the preceding, current and following sentence; unigrams of lemmas and parts of speech in a window of /three words, where each position provides a distinct feature; and bigrams of lemmas in the same window	1	The SVMLight <REF>Joachims, 1999</REF> classifier was used in the supervised settings with its default parameters	0	To obtain a multi-class classifier we used a standard one-vs-all approach of training a binary SVM for each possible sense and then selecting the highest scoring sense for a test example	0	3	2
P98-1003	P94-1013	1998	1991 present the initial success of applying word trigram conditional probabilities to the problem of context based detection and correction of real-word errors	0	<TREF>Yarowsky 1994</TREF> experiments with the use of decision lists for lexical ambiguity resolution, using context features like local syntactic patterns and collocational information, so that multiple types of evidence are considered in the context of an ambiguous word	1	In addition to word-forms, the patterns involve POS tags and lemmas	0	The algorithm is evaluated in missing accent restoration task for Spanish and French text, against a predefined set of a few words giving an accuracy over 99	0	6	1
C04-1101	P94-1013	2004	Therefore, a machine learning approach is proposed, which investigates how these features contribute to the task and how they should be combined	0	4 Combining Linguistic Features with Machine Learning Approach Previous efforts in corpus-based NLP have incorporated machine learning methods to coordinate multiple linguistic features, for example, in accent restoration <TREF>Yarowsky, 1994</TREF> and event classification <REF>Siegel, 1998</REF>	1	Temporal relation determination can be modeled as a relation classification task	0	We formulate the thirteen temporal relations see Figure 1 as the classes to be decided by a classifier	0	6	1
P99-1009	P94-1013	1999	It has been amply demonstrated that a wide assortment of machine learning algorithms are quite effective at extracting linguistic information from manually annotated corpora	1	Among the machine learning algorithms studied, rule based systems have proven effective on many natural language processing tasks, including part-of-speech tagging <REF>Brill, 1995</REF>; <REF>Ramshaw and Marcus, 1994</REF>, spelling correction <REF>Mangu and Brill, 1997</REF>, word-sense disambiguation <REF>Gale et al , 1992</REF>, message understanding <REF>Day et al , 1997</REF>, discourse tagging <REF>Samuel et al , 1998</REF>, accent restoration <TREF>Yarowsky, 1994</TREF>, prepositional-phrase attachment <REF>Brill and Resnik, 1994</REF> and base noun phrase identification Ramshaw and Marcus, In Press; <REF>Cardie and Pierce, 1998</REF>; <REF>Veenstra, 1998</REF>; <REF>Argamon et al , 1998</REF>	0	Many of these rule based systems learn a short list of simple rules typically on the order of 50-300 which are easily understood by humans	0	Since these rule-based systems achieve good performance while learning a small list of simple rules, it raises the question of whether peoand Woman	0	1	2
J98-1006	P94-1013	1998	Performance ranges from 77-84 correct on the test words, where a lower bound for performance based on always selecting the most frequent sense for the same words ie , the sense with the greatest prior probability would yield 53-80 correct	0	<TREF>Yarowsky 1994</TREF>, building on his earlier work, designed a classifier that looks at words within :kk positions from the target; lemma forms are obtained through morphological analysis; and a coarse part-of-speech assignment is performed by dictionary lookup	1	Context is represented by collocations based on words or parts of speech at specific positions within the window or, less specifically, in any position	0	Also coded are some special classes of words, such as WEEKDAY, that might serve to distinguish among word senses	0	6	1
J98-1006	P94-1013	1998	Examples containing the string escorted were collected to train on one sense of the pseudoword and examples containing the string abused were collected to train on the other sense	0	In addition, <REF>Yarowsky 1993</REF> used homophones eg , cellarseller and <TREF>Yarowsky 1994</TREF> created homographs by stripping accents from French and Spanish words	1	Although these latter techniques are useful in their own 156 Leacock, Chodorow, and Miller Corpus Statistics and WordNet Relations right eg , spoken language systems or corrupted transmissions, the resulting materials do not generalize to the acquisition of tagged training for real polysemous or even homographic words	0	The results of disambiguation strategies reported for pseudowords and the like are consistently above 95 overall accuracy, far higher than those reported for disambiguating three or more senses of polysemous words <REF>Wilks et al 1993</REF>; <REF>Leacock, Towell, and Voorhees 1993</REF>	0	6	1
W06-0903	P94-1013	2006	These notions have been used implicitly by researchers and historians when validating the authenticity of documents, but have not been utilised much in automated systems	0	Similar applications have so far been largely confined to authorship identification, such as <REF>Mosteller and Wallace, 1964</REF>; <REF>Fung, 2003</REF> and the identification of association rules <TREF>Yarowsky, 1994</TREF>; <REF>Silverstein et al , 1997</REF>	1	Temporal information is presently underutilised for automated document classification purposes, especially when it comes to guessing at the document creation date automatically	0	This work presents a method of using periodical temporal-frequency information present in documents to create temporal-association rules that can be used for automatic document dating	0	6	1
P97-1009	P94-1013	1997	WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution	0	In several recent proposals <REF>Hearst, 1991</REF>; <REF>Bruce and Wiebe, 1994</REF>; <REF>Leacock, Towwell, and Voorhees, 1996</REF>; <REF>Ng and Lee, 1996</REF>; <REF>Yarowsky, 1992</REF>; <TREF>Yarowsky, 1994</TREF>, statistical and machine learning techniques were used to extract classifiers from hand-tagged corpus	1	Yarowsky <REF>Yarowsky, 1995</REF> proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples	0	Most previous corpus-based WSD algorithms determine the meanings of polysemous words by exploiting their local contexts	0	6	1
P06-2065	P94-1013	2006	Unsupervised learning holds great promise for breakthroughs in natural language processing	0	In cases like <REF>Yarowsky, 1995</REF>, unsupervised methods offer accuracy results than rival supervised methods <TREF>Yarowsky, 1994</TREF> while requiring only a fraction of the data preparation effort	1	Such methods have also been a key driver of progress in statistical machine translation, which depends heavily on unsupervised word alignments <REF>Brown et al , 1993</REF>	0	There are also interesting problems for which supervised learning is not an option	0	1	3
W00-0706	P94-1013	2000	In this setting, a Decision List is a list of features extracted from the training examples and sorted by a log-likelihood measure	0	This measure estimates how strong a particular feature is as an indicator of a specific sense <TREF>Yarowsky, 1994</TREF>	1	When testing, the decision list is checked in order and the feature with the highest weight that matches the test example is used to select the winning word sense	0	Thus, only the single most reliable piece of evidence is used to perform disambiguation	0	6	1
W00-0706	P94-1013	2000	Generally, supervised approaches those that learn from previously semantically annotated corpora have obtained better results than unsupervised methods on small sets of selected ambiguous words, or artificial pseudowords	0	Many standard M L algorithms for supervised learning have been applied, such as: Decision Lists <TREF>Yarowsky, 1994</TREF>; <REF>Agirre and Martinez, 2000</REF>, Neural Networks <REF>Towell and Voorhees, 1998</REF>, Bayesian learning <REF>Bruce and Wiebe, 1999</REF>, Exemplar-based learning <REF>Ng, 1997</REF>, Boosting <REF>Escudero et al , 2000a</REF>, etc Further, in <REF>Mooney, 1996</REF> some of the previous methods are compared jointly with Decision Trees and Rule Induction algorithms, on a very restricted domain	1	Although some published works include the comparison between some alternative algorithms <REF>Mooney, 1996</REF>; <REF>Ng, 1997</REF>; <REF>Escudero et al , 2000a</REF>; <REF>Escudero et al , 2000b</REF>, none of them addresses the issue of the portability of supervised ML algorithms for WSD, ie, testing whether the accuracy of a system trained on a certain corpus can be extrapolated to other corpora or not	0	We think that the study of the domain dependence of WSD --in the style of other studies devoted to parsing <REF>Sekine, 1997</REF>; <REF>Ratnaparkhi, 1999</REF>-is needed to assure the validity of the supervised approach, and to determine to which extent a tuning pre-process is necessary to make real WSD systems portable	0	6	1
P06-1058	P94-1013	2006	Their investigation was based on a 6word test set with 2 senses for each word	0	Yarowsky 1994 and 1995, <REF>Mihalcea and Moldovan 2000</REF>, and <REF>Mihalcea 2002</REF> have made further research to obtain large corpus of higher quality from an initial seed corpus	1	A semi-supervised method proposed by Niu et al	0	2005 clustered untagged instances with tagged ones starting from a small seed corpus, which assumes that similar instances should have similar tags	0	6	1
J00-4004	P94-1013	2000	However, machine learning techniques have not previously been applied to aspectual disambiguation	0	Previous efforts have applied machine induction methods to coordinate corpusbased linguistic indicators in particular, for example, to classify adjectives according to markedness <REF>Hatzivassiloglou and McKeown 1995</REF>, to perform accent restoration <TREF>Yarowsky 1994</TREF>, for sense disambiguation problems <REF>Luk 1995</REF>, and for the automatic identification of semantically related groups of words <REF>Pereira, Tishby, and Lee 1993</REF>; <REF>Hatzivassiloglou and McKeown 1993</REF>; Schiitze 1992	1	8	0	Future Work Parallel bilingual corpora are potential sources of supervised examples for training and testing aspectual classification systems	0	6	1
P96-1006	P94-1013	1996	In contrast, we used exemplar-based learning, where the contributions of all features are summed up and taken into account in coming up with a classification	0	We also include verb-object syntactic relation as a feature, which is not used in <TREF>Yarowsky, 1994</TREF>	0	Although the work of Yarowsky, i994 can be applied to WSD, the results reported in <TREF>Yarowsky, 1994</TREF> only dealt with accent restoration, which is a much simpler problem	1	It is unclear how Yarowskys method will fare on WSD of a common test data set like the one we used, nor has his method been tested on a large data set with highly ambiguous words tagged with the refined senses of WORDNET	0	2	3
P96-1006	P94-1013	1996	In contrast, LEXAS uses supervised learning from tagged sentences, which is also the approach taken by most recent work on WSD, including <REF>Bruce and Wiebe, 1994</REF>; <REF>Miller et al , 1994</REF>; <REF>Leacock et al , 1993</REF>; <TREF>Yarowsky, 1994</TREF>; <REF>Yarowsky, 1993</REF>; <REF>Yarowsky, 1992</REF>	1	The work of <REF>Miller et al , 1994</REF>; <REF>Leacock et al , 1993</REF>; <REF>Yarowsky, 1992</REF> used only the unordered set of surrounding words to perform WSD, and they used statistical classifiers, neural networks, or IR-based techniques	0	The work of <REF>Bruce and Wiebe, 1994</REF> used parts of speech POS and morphological form, in addition to surrounding words	0	However, the POS used are abbreviated POS, and only in a window of -b2 words	0	3	2
P96-1006	P94-1013	1996	One line of research focuses on the use of the knowledge contained in a machine-readable dictionary to perform WSD, such as <REF>Wilks et al , 1990</REF>; <REF>Luk, 1995</REF>	0	In contrast, LEXAS uses supervised learning from tagged sentences, which is also the approach taken by most recent work on WSD, including <REF>Bruce and Wiebe, 1994</REF>; <REF>Miller et al , 1994</REF>; <REF>Leacock et al , 1993</REF>; <TREF>Yarowsky, 1994</TREF>; <REF>Yarowsky, 1993</REF>; <REF>Yarowsky, 1992</REF>	1	The work of <REF>Miller et al , 1994</REF>; <REF>Leacock et al , 1993</REF>; <REF>Yarowsky, 1992</REF> used only the unordered set of surrounding words to perform WSD, and they used statistical classifiers, neural networks, or IR-based techniques	0	The work of <REF>Bruce and Wiebe, 1994</REF> used parts of speech POS and morphological form, in addition to surrounding words	0	3	2
P96-1006	P94-1013	1996	We also include verb-object syntactic relation as a feature, which is not used in <TREF>Yarowsky, 1994</TREF>	0	Although the work of Yarowsky, i994 can be applied to WSD, the results reported in <TREF>Yarowsky, 1994</TREF> only dealt with accent restoration, which is a much simpler problem	1	It is unclear how Yarowskys method will fare on WSD of a common test data set like the one we used, nor has his method been tested on a large data set with highly ambiguous words tagged with the refined senses of WORDNET	0	The work of <REF>Miller et al , 1994</REF> is the only prior work we know of which attempted to evaluate WSD on a large data set and using the refined sense distinction of WORDNET	0	2	3
P96-1006	P94-1013	1996	That local collocation knowledge provides important clues to WSD is pointed out in <REF>Yarowsky, 1993</REF>, although it was demonstrated only on performing binary or very coarse sense disambiguation	0	The work of <TREF>Yarowsky, 1994</TREF> is perhaps the most similar to our present work	1	However, his work used decision list to perform classification, in which only the single best disambiguating evidence that matched a target context is used	0	In contrast, we used exemplar-based learning, where the contributions of all features are summed up and taken into account in coming up with a classification	0	3	2
P02-1046	P94-1013	2002	Suppose the initial classifier correctly labels 100 out of 1000 instances, and makes no mistakes	0	Then the initial precision is 1<REF>Yarowsky, 1995</REF>, citing <TREF>Yarowsky, 1994</TREF>, actually uses a superficially different score that is, however, a monotone transform of precision, hence equivalent to precision, since it is used only for sorting	1	1 and recall is 01	0	Suppose further that we add an atomic rule that correctly labels 19 new instances, and incorrectly labels one new instance	0	6	1
W97-0108	P94-1013	1997	Methods can typically be delineated along two dimensions, corpns-based vs dictionary-based approaches	0	Corpus-based word sense disambignation algorjthm such as <REF>Ng and Lee, 1996</REF>; <REF>Bruce and Wiebe, 1994</REF>; <TREF>Yarowsky, 1994</TREF> relied on supervised learning fzom annotated corpora	1	The main drawback of these approaches is their requirement of a sizable sense-tagged corpus	0	Attempts to alleviate this tagbottleneck ilude tmotstrias Te ot ill,, 1996; <REF>Hearst, 1991</REF> and unsupervised algorith Yarowsky, 199s Dictionary-based approaches rely on linguistic knowledge sources such as mali,e-readable dictionaries <REF>Luk, 1995</REF>; <REF>Veronis and Ide, 1990</REF> and WordNet <REF>Agirre and Rigau, 1996</REF>; <REF>Resnik, 1995</REF> and e0ploit these for word sense disaznbiguation	0	1	3
P96-1010	P94-1013	1996	In this case, a more effective approach is to learn features that characterize the different contexts in which each word tends to occur	0	A number of feature-based methods have been proposed, including Bayesian classifiers <REF>Gale, Church, and Yarowsky, 1993</REF>, decision lists <TREF>Yarowsky, 1994</TREF>, Bayesian hybrids <REF>Golding, 1995</REF>, and, more recently, a method based on the Winnow multiplicative weight-updating algorithm <REF>Golding and Roth, 1996</REF>	1	We adopt the Bayesian hybrid method, which we will call Bayes, having experimented with each of the methods and found Bayes to be among the best-performing for the task at hand	0	This method has been described elsewhere <REF>Golding, 1995</REF> and so will only be briefly reviewed here; however, the version used here uses an improved smoothing technique, which is mentioned briefly below	0	6	1
P96-1010	P94-1013	1996	Moreover, word trigrams are ineffective at capturing longdistance properties such as discourse topic and tense	0	Feature-based approaches, such as Bayesian classifters <REF>Gale, Church, and Yarowsky, 1993</REF>, decision lists <TREF>Yarowsky, 1994</TREF>, and Bayesian hybrids <REF>Golding, 1995</REF>, have had varying degrees of success for the problem of context-sensitive spelling correction	0	However, we report experiments that show that these methods are of limited effectiveness for cases such as their, there, theyre and than, then, where the predominant distinction to be made among the words is syntactic	1	71 Confusion set Train Test Most freq	0	2	3
E06-2018	P94-1013	2006	The essence behind many algorithms for word sense disambiguation is to implicitly or explicitly classify all possible context words into groups relating to one or another sense	0	This can be done in a supervised <TREF>Yarowsky, 1994</TREF>, a semi-supervised <REF>Yarowsky, 1995</REF> or a fully unsupervised way <REF>Pantel  Lin, 2002</REF>	1	However, the classification can only work if the statistical clues are clear enough and if there are not too many exceptions	0	In terms of word co-occurrence statistics, we can say that within the local contexts of an ambiguous word, context words typical of the same sense should have high co-occurrence counts, whereas context words associated with different senses should have cooccurrence counts that are considerably lower	0	6	1
A00-2015	P94-1013	2000	1995, we formalize the problem of deciding dependency preference of subordinate clauses by utilizing the correlation of scope embedding preference and dependency preference of Japanese subordinate clauses	0	Then, as a statistical learning method, we employ the decision list learning method of <TREF>Yarowsky 1994</TREF>, where optimal combination of those features are selected and sorted in the form of decision rules, according to the strength of correlation between those features and the dependency preference of the two subordinate clauses	1	We evaluate the proposed method through the experiment on learning dependency preference of Japanese subordinate clauses from the EDR bracketed corpus section 4	0	We show that the proposed method outperforms other related methods/models	0	3	2
A00-2015	P94-1013	2000	The head vp chunk of Clause1 does not modify that of Clause2, but modifies that of another subordinate clause or the matrix clause which follows Clause2	0	Roughly speaking, the first corresponds to the case where Clause2 inherently has a scope of the same or a broader breadth compared with that of Clause1, while the second corresponds to the case where Clause2 inherently has a narrower scope compared with that of Clause17 32 Decision List Learning A decision list <TREF>Yarowsky, 1994</TREF> is a sorted list of the decision rules each of which decides the value of a decision D given some evidence E Each decision rule in a decision list is sorted TOur modeling is slightly different from those of other standard approaches to statistical dependency analysis <REF>Collins, 1996</REF>; <REF>Fujio and Matsumoto, 1998</REF>; <REF>Haruno et al , 1998</REF> which simply distinguish the two cases: the case where dependency relation holds between the given two vp chunks or clauses, and the case where dependency relation does not hold	1	In contrast to those standard approaches, we ignore the case where the head vp chunk of Clause1 modifies that of another subordinate clause which precedes Clause2	0	This is because we assume that this case is more loosely related to the scope embedding preference of subordinate clauses	0	3	2
A00-2015	P94-1013	2000	We formalize the problem of deciding scope embedding preference as a classification problem, in which various types of linguistic information of each subordinate clause are encoded as features and used for deciding which one of given two subordinate clauses has a broader scope than the other	0	As a statistical learning method, we employ the decision list learning method of <TREF>Yarowsky 1994</TREF>	1	113 Table 2: Features of Japanese Subordinate Clauses Feature Type  of Feat  Each Binary Feature Punctuation 2 with-comma, without-comma Grammatical adverb, adverbial-noun, formal-noun, temporal-noun, some features have distinction 17 quoting-particle, copula, predicate-conjunctive-particle, of chunk-final/middle topic-marking-particle, sentence-final-particle 12 Conjugation form of chunk-final conjugative word Lexical lexicalized forms of Grammatical features, with more than 9 occurrences in EDR corpus 235 stem, base, mizen, renyou, rental, conditional, imperative, ta, tari, re, conjecture, volitional adverb eg , ippou-de, irai, adverbial-noun eg , tame, baai topic-marking-particle eg , ha, mo, quoting-particle to, predicate-conjunctive-particle eg , ga, kara, temporal-noun eg , ima, shunkan, formal-noun eg , koto, copula dearu, sentence-final-particle eg , ka, yo 31 The Task Definition Considering the dependency preference of Japanese subordinate clauses described in section 24, the following gives the definition of our task of deciding the dependency of Japanese subordinate clauses	0	Suppose that a sentence has two subordinate clauses Clause1 and Clause2, where the head vp chunk of Clausel precedes that of Clause2	0	3	2
A00-2015	P94-1013	2000	For each piece of evidence, calculate the likelihood ratio of the conditional probability of a decision D  xl given the presence of that piece of evidence to the conditional probability of the rest of the decisions D -,xl: PDxl I EI lg2 PDxl EI Then, a decision list is constructed with pieces of evidence sorted in descending order with respect to their likelihood ratios, s 2	0	The final line of a decision list is defined as a default, where the likelihood ratio is calculated as the ratio of the largest marginal probability of the decision D  xl to the marginal proba<REF>Syarowsky 1994</REF> discusses several techniques for avoiding the problems which arise when an observed count is 0	1	Among those techniques, we employ the simplest one, ie, adding a small constant c 01 < c < 025 to the numerator and denominator	0	With this modification, more frequent evidence is preferred when there exist several evidences for each of which the conditional probability PDx  EI equals to 1	0	3	2
W03-0417	P94-1013	2003	Example confusion sets include: principle, principal, then, than, and weather, whether	0	Until now, many methods have been proposed for this problem including winnow-based algorithms <REF>Golding and Roth, 1999</REF>, differential grammars <REF>Powers, 1998</REF>, transformation based learning <REF>Mangu and Brill, 1997</REF>, decision lists <TREF>Yarowsky, 1994</TREF>	1	Confusion set disambiguation has very similar characteristics to a word sense disambiguation problem in which the system has to identify the meaning of a polysemous word given the surrounding context	0	The merit of using confusion set disambiguation as a test-bed for a learning algorithm is that since one does not need to annotate the examples to make labeled data, one can conduct experiments using an arbitrary amount of labeled data	0	6	1
W00-1320	P94-1013	2000	<REF>Yarowsky, 1995</REF> also uses wide context, but incorporates the one-senseper-discourse and one-sense-per-collocation constraints, using an unsupervised learning technique	0	The supervised technique in <TREF>Yarowsky, 1994</TREF> has a more specific notion of context, employing not just words that can appear within a window of Ik, but crucially words that abut and fall in the 2 window of the target word	1	More recently, <REF>Lin, 1997</REF> has shown how syntactic context, and dependency structures in particular, can be successfully employed for word sense disambiguation	0	<REF>Stetina and Nagao, 1997</REF> have shown that by employing a fairly simple and somewhat ad-hoc unsupervised method of WSD using a WordNet-based similarity heuristic, they could enhance PP-attachment performance to a significantly higher level than systems that made no use of lexical semantics 881 accuracy	0	6	1
W04-0861	P94-1013	2004	a7 Decision List DL are lists of weighted classification rules involving the evaluation of one single feature	0	At classification time, the algorithm applies the rule with the highest weight that matches the test example <TREF>Yarowsky, 1994</TREF>	1	The provider is IXA and they also applied smoothing to generate more robust decision lists	0	a7 In the Vector Space Model method cosVSM, each example is treated as a binary-valued feature vector	0	3	2
W97-1502	P94-1013	1997	3 Discriminant-Based Training Many of the properties extracted from QLFs can be presented to non-expert users in a form they can easily understand	0	Those properties that hold for some analyses of a particular utterance but not for others I will refer to as discriminants Dagan and ltai, 1994; <TREF>Yarowsky, 1994</TREF>	1	Discriminants that fairly consistently hold for correct but not some incorrect analyses, or vice versa, are likely to be useful in distinguishing correct from incorrect analyses at run time	0	Thus for training on an utterance to be effective, we need to provide enough user-friendly discriminants to allow the user to select the correct analyses, and as many as possible system-friendly discriminants that, over the corpus as a whole, distinguish reliably between correct and incorrect analyses	0	6	1
A97-1025	P94-1013	1997	In this work, we use the words directly	0	<TREF>Yarowsky 1994</TREF> notes that conceptual spelling correction is part of a closely related class of problems which include word sense disambiguation, word choice selection in machine translation, and accent and capitalization restoration	1	This class of problems has been attacked by many others	0	A number of feature-based methods have been tried, including Bayesian classifiers <REF>Gale, Church, and Yarowsky, 1992</REF>; <REF>Golding, 1995</REF>, decision lists <TREF>Yarowsky, 1994</TREF>, and knowledge-based approaches <REF>McRoy, 1992</REF>	0	6	1
A97-1025	P94-1013	1997	This class of problems has been attacked by many others	0	A number of feature-based methods have been tried, including Bayesian classifiers <REF>Gale, Church, and Yarowsky, 1992</REF>; <REF>Golding, 1995</REF>, decision lists <TREF>Yarowsky, 1994</TREF>, and knowledge-based approaches <REF>McRoy, 1992</REF>	1	<REF>Recently, Golding and Schabes 1996</REF> described a system, Tribayes, that combines a trigram model of the words parts of speech with a Bayesian classifier	0	The trigram component of the system is used to make decisions for those confusion sets that 166 terms documents X T O rxr D  O rxd txd txr Figure 1: Singular value decomposition SVD of matrix X produces matrices T, S and D	0	6	1
J04-1001	P94-1013	2004	To construct classifiers using supervised methods, we need classified data such as those in Figure 1	0	22 Decision Lists Let us first consider the use of decision lists, as proposed in <TREF>Yarowsky 1994</TREF>	1	Let f  denote a feature of the context of 	0	A feature can be, for example, a words occurrence immediately to the left of 	0	3	2
J04-1001	P94-1013	2004	Many methods for word sense disambiguation based on supervised learning technique have been proposed	0	They include those using naive Bayes <REF>Gale, Church, and Yarowsky 1992a</REF>, decision lists <TREF>Yarowsky 1994</TREF>, nearest neighbor <REF>Ng and Lee 1996</REF>, transformation-based learning <REF>Mangu and Brill 1997</REF>, neural networks <REF>Towell and Voorhees 1998</REF>, Winnow <REF>Golding and Roth 1999</REF>, boosting <REF>Escudero, Marquez, and Rigau 2000</REF>, and naive Bayesian ensemble <REF>Pedersen 2000</REF>	1	The assumption behind these methods is that it is nearly always possible to determine the sense of an ambiguous word by referring to its context, and thus all of the methods build a classifier ie , a classification program using features representing context information eg , surrounding context words	0	For other related work on translation disambiguation, see Brown et al	0	6	1
C98-1003	P94-1013	1998	1991 present the initial success of applying word trigram conditional probabilities to the problem of context based detection and correction of real-word errors	0	<TREF>Yarowsky 1994</TREF> experiments with the use of decision lists for lexical ambiguity resolution, using context features like local syntactic patterns and collocational information, so that multiple types of evidence are considered in the context of an ambiguous word	1	In addition to word-forms, the patterns involve POS tags and lemmas	0	The algorithm is evaluated in missing accent restoration task for Spanish and French text, against a predefined set of a few words giving an accuracy over 99	0	6	1
W00-1310	P94-1013	2000	While the basic idea of our model is similar to trigger models, they handle co-occurrences of word pairs independently and do not use a representation of the whole context	0	This omission is also done in applications such as word sense dismnbiguation Yarowsky: 1994; FUNG et al , 1999	1	Our model is the most related to Coccaro mad <REF>Jurafsky 1998</REF>, in that a reduced vector space approach was taken and context is represented by the accumulation of word cooccurrence vectors	0	Their model was reported to decrease the test set perplexity by 12, compared to the bigram nmdel	0	5	2
W97-0321	P94-1013	1997	Exemplar-based method makes use of typical contexts exemplars of a word sense, eg, verbnoun collocations or adjective-noun collocations, and identifies the correct sense of a word in a particular context by comparing the context with the exemplars <REF>Ng and Lee, 1996</REF>	0	Recently, some kinds of learning techniques have been applied to cumulatively acquire exemplars form large corpora <REF>Yarowsky, 1994, 1995</REF>	0	But ideal resources from which to learn exemplars are not generally available for any languages	1	Moreover, the effectiveness of this method on disambiguating words in large-scale corpora into fine-grained sense distinctions needs to be further investigated <REF>Ng and Lee, 1996</REF>	0	1	3
W97-0321	P94-1013	1997	1	0	Word sense disambiguation has long been one of the major concerns in natural language processing area eg , <REF>Bruce et al , 1994</REF>; <REF>Choueka et al , 1985</REF>; <REF>Gale et al , 1993</REF>; <REF>McRoy, 1992</REF>; <REF>Yarowsky 1992, 1994, 1995</REF>, whose aim is to identify the correct sense of a word in a particular context, among all of its senses defined in a dictionary or a thesaurus	1	Undoubtedly, effective disambiguation techniques are of great use in many natural language processing tasks, eg, machine translation and information retrieving <REF>Allen, 1995</REF>; <REF>Ng and Lee, 1996</REF>; <REF>Resnik, 1995</REF>, etc Previous strategies for word sense disambiguation mainly fall into two categories: statistics-based method and exemplar-based method	0	Statistics-based method often requires large-scale corpora eg , <REF>Hirst, 1987</REF>; <REF>Luk, 1995</REF>, sense-tagging or not, monolingual or aligned bilingual, as training data to specify significant clues for each word sense	0	6	1
P04-1074	P94-1013	2004	For another example, tense/aspect can be affected by auxiliary words, trend verbs, etc This shows that classification of temporal indicators based on partof-speech POS information alone cannot determine relative temporal relations	0	3 Machine Learning Approaches for Relative Relation Resolution Previous efforts in corpus-based natural language processing have incorporated machine learning methods to coordinate multiple linguistic features for example in accent restoration <TREF>Yarowsky, 1994</TREF> and event classification <REF>Siegel and McKeown, 1998</REF>, etc Relative relation resolution can be modeled as a relation classification task	1	We model the thirteen relative temporal relations see Figure 1 as the classes to be decided by a classifier	0	The resolution process is to assign an event pair ie the two events under concern 2 to one class according to their linguistic features	0	6	1
J98-1001	P94-1013	1998	However, despite these findings, the value of N has continued to vary over the course of WSD work more or less arbitrarily	0	Yarowsky 1993, 1994a, 1994b examines different windows of microcontext, including 1-contexts, k-contexts, and words pairs at offsets -1 and -2, -1 and 1, and 1 and 2, and sorts them using a log-likelihood ratio to find the most reliable evidence for disambiguation	1	Yarowsky makes the observation that the optimal value of k varies with the kind of ambiguity: he suggests that local ambiguities need only a window of k  3 or 4, while semantic or topic-based ambiguities require a larger window of 20-50 words see Section 312	0	No single best measure is reported, suggesting that for different ambiguous words, different distance relations are more efficient	0	6	1
P95-1026	P94-1013	1995	STEP 3a: Train the supervised classification algorithm on the SENSE-A/SENSE-B seed sets	0	The decision-list algorithm used here <TREF>Yarowsky, 1994</TREF> identifies other collocations that reliably partition the seed training data, ranked by the purity of the distribution	1	Below is an abbreviated example of the decision list trained on the plant seed data	0	9 Initial decision list for plant abbreviated LogL 810 758 739 720 627 470 439 430 410 352 348 345 Collocation Sense plant life  A manufacturing plant  B life within 4-2-10 words  A manufacturing in 4-2-10 words  B animal within -I-2-10 words  A equipment within -1-2-10 words , B employee within 4-2-10 words  B assembly plant  B plant closure  B plant species  A automate within 4-2-10 words :: B microscopic plant  A 9Note that a given collocate such as life may appear multiple times in the list in different collocations1 relationships, including left-adjacent, right-adjacent, cooccurrence at other positions in a k-word window and various other syntactic associations	0	3	2
P95-1026	P94-1013	1995	1 9 Comparison with Previous Work This algorithm exhibits a fundamental advantage over supervised learning algorithms including <REF>Black 1988</REF>, <REF>Hearst 1991</REF>, Gale et al	1	1992, Yarowsky 1993, 1994, Leacock et al	0	1993, <REF>Bruce and Wiebe 1994</REF>, and <REF>Lehman 1994</REF>, as it does not require costly hand-tagged training sets	0	It thrives on raw, unannotated monolingual corpora the more the merrier	0	2	1
P95-1026	P94-1013	1995	4 In general, the high reliability of this behavior in excess of 97 for adjacent content words, for example makes it an extremely useful property for sense disambiguation	0	A supervised algorithm based on this property is given in <TREF>Yarowsky, 1994</TREF>	1	Using a decisien list control structure based on <REF>Rivest, 1987</REF>, this algorithm integrates a wide diversity of potential evidence sources lemmas, inflected forms, parts of speech and arbitrary word classes in a wide diversity of positional relationships including local and distant collocations, trigram sequences, and predicate-argument association	0	The training procedure computes the word-sense probability distributions for all such collocations, and orders them by r 0 /PrSenseAlColloeationix 5 the log-likelihood ratio  gt prISenseBlColloeationi, with optional steps for interpolation and pruning	0	6	1
W02-1003	P94-1013	2002	Experimental results show that the new algorithm produces substantially lower error rates and entropy, while simultaneously learning lists that are over an order of magnitude smaller than those produced by the standard algorithm	0	Decision lists <REF>Rivest, 1987</REF> have been used for a variety of natural language tasks, including accent restoration <TREF>Yarowsky, 1994</TREF>, word sense disambiguation <REF>Yarowsky, 2000</REF>, finding the past tense of English verbs <REF>Mooney and Califf, 1995</REF>, and several other problems	1	We show a problem with the standard algorithm for learning probabilistic decision lists, and we introduce an incremental algorithm that consistently works better	0	While the obvious implementation for this algorithm would be very slow, we also show how to efficiently implement it	0	6	1
W02-1003	P94-1013	2002	Many of the problems that probabilistic decision list algorithms have been used for are very similar: in a given text context, determine which of two choices is most appropriate	0	Accent restoration <TREF>Yarowsky, 1994</TREF>, word sense disambiguation <REF>Yarowsky, 2000</REF>, and other problems all fall into this framework, and typically use similar feature types	1	We thus chose one problem of this type, grammar checking, and believe that our results should carry over at least to these other, closely related problems	0	In particular, we chose to use exactly the same training, test, problems, and feature sets used by Banko and Brill 2001a; 2001b	0	6	1
W02-1003	P94-1013	2002	Our probabilistic decision lists can thus be thought of as a competitive way to probabilize TBLs, with the advantage of preserving the list-structure and simplicity of TBL, and the possible disadvantage of losing the dependency on the current state	0	<TREF>Yarowsky 1994</TREF> suggests two improvements to the standard algorithm	1	First, he suggests an optional, more complex smoothing algorithm than the one we applied	0	His technique involves estimating both a probability based on the global probability distribution for a question, and a local probability, given that no questions higher in the list were TRUE, and then interpolating between the two probabilities	0	5	2
W02-1003	P94-1013	2002	If no other rule is used, the last rule always triggers, ensuring that some probability is always returned	0	The standard algorithm for learning decision lists <TREF>Yarowsky, 1994</TREF> is very simple	1	The goal is to minimize the entropy of the decision list, where entropy represents how uncertain we are about a particular decision	0	For each rule, we find the expected entropy using that rule, then sort all rules by their entropy, and output the rules in order, lowest entropy first	0	6	1
C04-1112	P94-1013	2004	In the system presented here, the classifiers built for each ambiguous word are based on its lemma instead	0	Lemmatization allows for more compact and generalizable data by clustering all inflected forms of an ambiguous word together, an effect already commented on by <TREF>Yarowsky 1994</TREF>	1	The more inflection in a language, the more lemmatization will help to compress and generalize the data	0	In the case of our WSD system this means that less classifiers have to be built therefore adding up the training material available to the algorithm for each ambiguous wordform	0	4	2
C04-1112	P94-1013	2004	Alternatively, we chose for a model constructing classifiers based on lemmas therefore reducing the number of classifiers that need to be made	0	As has already been noted by <TREF>Yarowsky 1994</TREF>, using lemmas helps to produce more concise and generic evidence than inflected forms	1	Therefore building classifiers based on lemmas increases the data available to each classifier	0	We make use of the advantage of clustering all instances of eg one verb in a single classifier instead of several classifiers one for each inflected form found in the data	0	4	2
W00-1326	P94-1013	2000	For instance, governing body and governing bodies are different collocations for the sake of this paper	0	4 Adaptation of decision lists to n-way ambiguities Decision lists as defined in <REF>Yarowsky, 1993</REF>; 1994 are simple means to solve ambiguity problems	0	They have been successfully applied to accent restoration, word sense disambiguation 209 and homograph disambiguation <TREF>Yarowsky, 1994</TREF>; 1995; 1996	1	In order to build decision lists the training examples are processed to extract the features each feature corresponds to a kind of collocation, which are weighted with a log-likelihood measure	0	1	2
W00-1326	P94-1013	2000	4 Adaptation of decision lists to n-way ambiguities Decision lists as defined in <REF>Yarowsky, 1993</REF>; 1994 are simple means to solve ambiguity problems	0	They have been successfully applied to accent restoration, word sense disambiguation 209 and homograph disambiguation <TREF>Yarowsky, 1994</TREF>; 1995; 1996	1	In order to build decision lists the training examples are processed to extract the features each feature corresponds to a kind of collocation, which are weighted with a log-likelihood measure	0	The list of all features ordered by log-likelihood values constitutes the decision list	0	1	2
J04-1003	P94-1013	2004	The context within which the ambiguous word occurs is typically represented by a set of linguistically motivated features from which a learning algorithm induces a representative model that performs the disambiguation	0	A variety of classifiers have been employed for this task see Mooney 1996 and Ide and Veronis 1998 for overviews, the most popular being decision lists <REF>Yarowsky 1994, 1995</REF> and naive Bayesian classifiers <REF>Pedersen 2000</REF>; <REF>Ng 1997</REF>; <REF>Pedersen and Bruce 1998</REF>; <REF>Mooney 1996</REF>; <REF>Cucerzan and Yarowsky 2002</REF>	1	We employed a naive Bayesian classifier <REF>Duda and Hart 1973</REF> for our experiments, as it is a very convenient framework for incorporating prior knowledge and studying its influence on the classification task	0	In Section 51 we describe a basic naive Bayesian classifier and show how it can be extended with informative priors	0	1	2
C02-1112	P94-1013	2002	At present we have chosen one algorithm which does not combine features Decision Lists and another which does combine features AdaBoost	0	Despite their simplicity, Decision Lists Dlist for short as defined in <TREF>Yarowsky 1994</TREF> have been shown to be very effective for WSD <REF>Kilgarriff  Palmer, 2000</REF>	1	Features are weighted with a log-likelihood measure, and arranged in an ordered list according to their weight	0	In our case the probabilities have been estimated using the maximum likelihood estimate, smoothed adding a small constant 01 when probabilities are zero	0	1	2
C02-1112	P94-1013	2002	Previous work	0	<TREF>Yarowsky 1994</TREF> defined a basic set of features that has been widely used with some variations by other WSD systems	1	It consisted on words appearing in a window of k positions around the target and bigrams and trigrams constructed with the target word	0	He used words, lemmas, coarse part-of-speech tags and special classes of words, such as Weekday	0	6	1
W01-0502	P94-1013	2001	Machine learning methods have become the most popular technique in a variety of classification problems of these sort, and have shown significant success	1	A partial list consists of Bayesian classifiers <REF>Gale et al , 1993</REF>, decision lists <TREF>Yarowsky, 1994</TREF>, Bayesian hybrids <REF>Golding, 1995</REF>, HMMs <REF>Charniak, 1993</REF>, inductive logic methods <REF>Zelle and Mooney, 1996</REF>, memorya3 This research is supported by NSF grants IIS-9801638, IIS0085836 and SBR-987345	0	based methods <REF>Zavrel et al , 1997</REF>, linear classifiers <REF>Roth, 1998</REF>; <REF>Roth, 1999</REF> and transformationbased learning <REF>Brill, 1995</REF>	0	In many of these classification problems a significant source of difficulty is the fact that the number of candidates is very large  all words in words selection problems, all possible tags in tagging problems etc Since general purpose learning algorithms do not handle these multi-class classification problems well see below, most of the studies do not address the whole problem; rather, a small set of candidates typically two is first selected, and the classifier is trained to choose among these	0	1	2
W06-2608	P94-1013	2006	62 Performance of the Syntagmatic Kernel Table 3 shows the performance of the Syntagmatic Kernel on both data sets	0	As baseline, we report the result of a standard approach consisting on explicit bigrams and trigrams of words and PoS tags around the words to be disambiguated <TREF>Yarowsky, 1994</TREF>	1	The results show that the Syntagmatic Kernel outperforms the baseline in any configuration hard/soft-matching	0	The soft-matching criteria further improve the classification performance	0	3	1
W06-2608	P94-1013	2006	, 2005a and WordSenseDisambiguation WSD <REF>Strapparava et al , 2004</REF>	0	In general, the strategy adopted to model syntagmatic relations is to provide bigrams and trigrams of collocated words as features to describe local contexts <TREF>Yarowsky, 1994</TREF>, and each word is regarded as a different instance to classify	1	For instance, occurrences of a given class of named entities such as names of persons can be discriminated in texts by recognizing word patterns in their local contexts	0	For example the token Rossi, whenever is preceded by the token Prof , often represents the name of a person	0	3	2
W06-1624	P94-1013	2006	Obviously, how to measure the confidence of features is a very important issue for the decision list	0	We use the metric described in <TREF>Yarowsky, 1994</TREF>; <REF>Golding, 1995</REF>	1	Provided that 1  0Ps f > for all i :  max    i i confidence f P s f 1 This value measures the extent to which the context is unambiguously correlated with one particular slot i s  24 Slot-value merging and semantic reclassification The slot-value merger is to combine the slots assigned to the concepts in an input sentence	0	Another simultaneous task of the slot-value merger is to check the consistency among the identified slot-values	0	3	2
A00-2017	P94-1013	2000	Estimating terms of the form Prwlh  is done by assuming some generative probabilistic model, typically using Markov or other independence assumptions, which gives rise to estimating conditional probabilities of n-grams type features in the word or POS space	0	Machine learning based classifiers and maximum entropy models which, in principle, are not restricted to features of these forms have used them nevertheless, perhaps under the influence of probabilistic methods <REF>Brill, 1995</REF>; <TREF>Yarowsky, 1994</TREF>; <REF>Ratnaparkhi et al , 1994</REF>	1	It has been argued that the information available in the local context of each word should be augmented by global sentence information and even information external to the sentence in order to learn 124 better classifiers and language models	0	Efforts in this directions consists of 1 directly adding syntactic information, as in <REF>Chelba and Jelinek, 1998</REF>; <REF>Rosenfeld, 1996</REF>, and 2 indirectly adding syntactic and semantic information, via similarity models; in this case n-gram type features are used whenever possible, and when they cannot be used due to data sparsity, additional information compiled into a similarity measure is used <REF>Dagan et al , 1999</REF>	0	6	1
P01-1005	P94-1013	2001	Numerous methods have been presented for confusable disambiguation	0	The more recent set of techniques includes mult iplicative weightupdate algorithms <REF>Golding and Roth, 1998</REF>, latent semantic analysis <REF>Jones and Martin, 1997</REF>, transformation-based learning <REF>Mangu and Brill, 1997</REF>, differential grammars <REF>Powers, 1997</REF>, decision lists <TREF>Yarowsky, 1994</TREF>, and a variety of Bayesian classifiers <REF>Gale et al , 1993</REF>, <REF>Golding, 1995</REF>, <REF>Golding and Schabes, 1996</REF>	1	In all of these approaches, the problem is formulated as follows: Given a specific confusion set eg to,two,too, all occurrences of confusion set members in the test set are replaced by a marker; everywhere the system sees this marker, it must decide which member of the confusion set to choose	0	Confusion set disambiguation is one of a class of natural language problems involving disambiguation from a relatively small set of alternatives based upon the string context in which the ambiguity site appears	0	6	1
P03-2038	P94-1013	2003	In particular, they may involve performing speech recognition on speech data, parsing on text data, application of hand-coded rules to the results of parsing, or some combination of these	0	Statistics are then compiled to estimate the probability pa j f of each semantic atom a given each separate feature f, using the standard formula pa j f  Naf  1Nf  2 where Nf is the number of occurrences in the training data of utterances with feature f, and N af is the number of occurrences of utterances with both feature f and semantic atom a The decoding process follows <TREF>Yarowsky, 1994</TREF> in assuming complete dependence between the features	1	Note that this is in sharp contrast with the Naive Bayes classifier <REF>Duda et al , 2000</REF>, which assumes complete independence	0	Of course, neither assumption can be true in practice; however, as argued in <REF>Carter, 2000</REF>, there are good reasons for preferring the dependence alternative as the better option in a situation where there are many features extracted in ways that are likely to overlap	0	3	2
P03-2038	P94-1013	2003	There is typically no corpus data available at the start of a project, but considerable amounts at the end: the intention behind ALTERF is to allow us to shift smoothly from an initial version of the system which is entirely rule-based, to a final version which is largely data-driven	0	ALTERF characterises semantic analysis as a task slightly extending the decision-list classification algorithm <TREF>Yarowsky, 1994</TREF>; <REF>Carter, 2000</REF>	1	We start with a set of semantic atoms, each representing a primitive domain concept, and define a semantic representation to be a non-empty set of semantic atoms	0	For example, in the procedure assistant domain we represent the utterances please speak up show me the sample syringe set an alarm for five minutes from now no i said go to the next step respectively as fincrease volumeg fshow, sample syringeg fset alarm, 5, minutesg fcorrection, next stepg where increase volume, show, sample syringe, set alarm, 5, minutes, correction and next step are semantic atoms	0	5	2
C00-2102	P94-1013	2000	1	0	For each piece of evidence, we calculate the Iw of likelihood ratio of the largest; conditional probability of the decision D  :rl given the presence of that piece of evidence to the second largest conditional probability of the decision D x2: I EI lg2 PDx2 I EI Then a decision list is constructed with pieces of evidence sorted in descending order with respect to their log of likelihood ratios, where the decision of the rule at each line is D  xl with the largest conditional probability <TREF>Yarowsky 1994</TREF> discusses several techniques for avoiding the problems which arise when an observed count is 0	1	lq-om among those techniques, we employ tlm simplest ram, ie, adding a small constant c 01 < < 025 to the numerator and denominator	0	With this inodification, more frcquent evidence is preferred when several evidence candidates exist with the same 708 2	0	6	1
C00-2102	P94-1013	2000	Left  Context   ML2MII ll,ight Named Entity  Context  M   Mm<3  1 2 Current Position 4 Supervised Learning for Japanese Named Entity Recognition This section describes how to apply tile decision list learning method to chunking/tagging named entities	1	41 Decision List Learning A decision list <REF>Rivest, 1987</REF>; <TREF>Yarowsky, 1994</TREF> is a sorted list of decision rules, each of which decides the wflue of a decision D given some evidence E Each decision rule in a decision list is sorted in descending order with respect to some preference value, and rules with higher preference values are applied first when applying the decision list to some new test; data	0	First, the random variable D representing a decision w, ries over several possible values, and the random wriable E representing some evidence varies over 1 and 0 where 1 denotes the presence of the corresponding piece of evidence, 0 its absence	0	Then, given some training data in which the correct value of the decision D is annotated to each instance, the conditional probabilities PD  x I E  1 of observing the decision D  x under the condition of the presence of the evidence E E  1 are calculated and the decision list is constructed by the tbllowing procedure	0	3	2
C00-2102	P94-1013	2000	In general, creating training data tbr supervised learning is somewhat easier than creating pattern matching rules by hand	0	Next, we apply Yarowskys method tbr supervised decision list learning I <TREF>Yarowsky, 1994</TREF> to 1VVe choose tile decision list learning method as the 705 Table 1: Statistics of NE Types of IREX NE Type ORGANIZATION PERSON LOCATION ARTIFACT DATE TIME MONEY PERCENT Total frequency  Training 3676 197 3840 206 5463 292 747 40 3567 191 502 27 390 21 492 26 18677 Test 361 239 338 224 413 274 48 32 260 172 54 35 15 10 21 14 1510 Japanese named entity recognition, into which we incorporate several noun phrase chunking techniques sections 3 and 4 and experimentally evaluate their performance on the IREX, workshops training and test data section 5	1	As one of those noun phrase chunking techniques, we propose a method for incorporating richer contextual information as well as patterns of constituent morphemes within a named entity, compared with those considered in tire previous research <REF>Sekine et al , 1998</REF>; <REF>Borthwick, 1999</REF>, and show that the proposed method outperlbrms these approaches	0	2 Japanese Named Entity Recognition 21 Task of the IREX Workshop The task of named entity recognition of the IREX workshop is to recognize eight named entity types in Table 1 IREX <REF>Conmfittee, 1999</REF>	0	3	2
W07-2067	P94-1013	2007	This small number has almost no effect on more frequent words, but boosts the score of less common, yet potentially equally informative, words	0	222 Decision List The decision list classifier uses the log-likelihood of correspondence between each context feature and each sense, using additive smoothing <TREF>Yarowsky, 1994</TREF>	1	The decision list was created by ordering the correspondences from strongest to weakest	0	Instances that did not match any rule in the decision list were assigned the most frequent sense, as calculated from the training data	0	3	2
W97-0323	P94-1013	1997	Much recent research on word sense disambiguation WSD has adopted a corpus-based, learning approach	0	Many different learning approaches have been used, including neural networks <REF>Leacock et al , 1993</REF></REF>, probabilistic algorithms <REF>Bruce and Wiebe, 1994</REF>; <REF>Gale et al , 1992a</REF>; <REF>Gale et al , 1995</REF>; <REF>Leacock et al , 1993</REF></REF>; <REF>Yarowsky, 1992</REF>, decision lists <TREF>Yarowsky, 1994</TREF>, exemplar-based learning algorithms <REF>Cardie, 1993</REF>; <REF>Ng and Lee, 1996</REF>, etc In particular, <REF>Mooney 1996</REF> evaluated seven state-of-the-art machine learning algorithms on a common data set for disambiguating six senses of the word line	1	The seven algorithms that he evaluated are: a Naive-Bayes classifier <REF>Duda and Hart, 1973</REF>, a perceptron <REF>Rosenblatt, 1958</REF>, a decisiontree learner <REF>Quinlan, 1993</REF>, a k nearest-neighbor classifier exemplar-based learner <REF>Cover and Hart, 1967</REF>, logic-based DNF and CNF learners <REF>Mooney, 1995</REF>, and a decision-list learner <REF>Rivest, 1987</REF>	0	His results indicate that the simple Naive-Bayes algorithm gives the highest accuracy on the line corpus tested	0	6	1
W97-0212	P94-1013	1997	It must be noted however that the LDOCE homograph level is far more rough-grained than the CIDE guideword level, let alone the sub-sense level, and that Wilks and Stevensons approach on its own would, by its very nature, not transfer down to more fine-grained distinctions	0	Other research, such as Yarowskys into accent restoration in <REF>Spanish and French 1994</REF>, which reports accuracy levels of 9099, is again at a more rough-grained level, in this case that of distinguished unaccented and accented word forms	1	While the sense tagging results are fairly encouraging, the part of speech tagging results arc at present relatively poor	0	It thus secrns sensible, especially noting Wilks and Stevensons analysis mentioned above, to first run a sentence through a traditional part of speech tagger before trying to disambiguate the senses	0	1	2
P03-1020	P94-1013	2003	From this perspective, either accent identification can be extended to truecasing or truecasing can be extended to incorporate accent restoration	0	<TREF>Yarowsky, 1994</TREF> reports good results with statistical methods for Spanish and French accent restoration	1	Truecasing is also a specialized method for spelling correction by relaxing the notion of casing to spelling variations	0	There is a vast literature on spelling correction <REF>Jones and Martin, 1997</REF>; <REF>Golding and Roth, 1996</REF> using both linguistic and statistical approaches	0	1	2
P03-1020	P94-1013	2003	Finally, we demonstrate the considerable benefits of truecasing through task based evaluations on named entity tagging and automatic content extraction	0	11 Related Work Truecasing can be viewed in a lexical ambiguity resolution framework <TREF>Yarowsky, 1994</TREF> as discriminating among several versions of a word, which happen to have different surface forms casings	1	Wordsense disambiguation is a broad scope problem that has been tackled with fairly good results generally due to the fact that context is a very good predictor when choosing the sense of a word	0	<REF>Gale et al , 1994</REF> mention good results on limited case restoration experiments on toy problems with 100 words	0	6	1
P97-1007	P94-1013	1997	5 Comparison with Previous Work Several approaches have been proposed for attaching the correct sense from a set of prescribed ones of a word in context	0	Some of them have been fully tested in real size texts eg statistical methods <REF>Yarowsky, 1992</REF>, <TREF>Yarowsky, 1994</TREF>, <REF>Miller and Teibel, 1991</REF>, knowledge based methods <REF>Sussna, 1993</REF>, <REF>Agirre and Rigau, 1996</REF>, or mixed methods <REF>Richardson et al , 1994</REF>, <REF>Resnik, 1995</REF>	1	The performance of WSD is reaching a high stance, although usually only small sets of words with clear sense distinctions are selected for disambiguation eg	0	<REF>Yarowsky, 1995</REF> reports a success rate of 96 disambiguating twelve words with two clear sense distinctions each one	0	6	1
J96-2001	P94-1013	1996	Syncretism and related morphological ambiguities present a problem for many NL applications where lexical disambiguation is important; cases where the orthographic form is identical but the pronunciations of the various functions differ are particularly important for speech applications, such as text-to-speech, since appropriate word pronunciations must be computed from orthographic forms that underspecify the necessary information	0	Ideally one would like to build models that use contextual information to perform lexical disambiguation <REF>Yarowsky 1992, 1994</REF>, but such models must be trained on specialized tagged corpora either hand-generated or semi-automatically generated and such training corpora are often not available, at least in the early phases of constructing a particular application	1	Lacking good contextual models, one is forced to fall back on estimates of the lexical prior probabilities for the various functions of a form	0	Following standard terminology, a lexical prior can be defined as follows: Imagine that a given form is n-ways ambiguous; the lexical prior probability of sense i of this form is simply the probability of sense i independent of the context in which the particular instantiation of the form occurs	0	1	3
W97-0318	P94-1013	1997	The Splus statistical package was used for the induction process, with parameters set to their default values	0	Previous efforts in corpus-based natural language processing have incorporated machine learning methods to coordinate multiple linguistic indicators, eg, to classify adjectives according to markedness <REF>Hatzivassiloglou and McKeown, 1995</REF>, to perform accent restoration <TREF>Yarowsky, 1994</TREF></TREF>, for disambiguation problems <TREF>Yarowsky, 1994</TREF></TREF>; <REF>Luk, 1995</REF>, 158 n States Events be 23,409 1000 00 have 7,882 699 301 all other verbs 66,682 162 838 Table 4: Breakdown of verb occurrences	1	and for the automatic identification of semantically related groups of words <REF>Pereira, Tishby, and Lee, 1993</REF>; <REF>Hatzivassiloglou and McKeown, 1993</REF>	0	For more detail on the machine learning experiments described here, see <REF>Siegel 1997</REF>	0	6	1
W02-1036	P94-1013	2002	A feature expression F of the named entity can be any possible subset of the full feature expression mlength, NEtag,POS , or the set indicating that the system outputs no named entity within the segment	0	F         any subset of braceleftBig mlength, NEtag,POS bracerightBig braceleftBig class sys no outputs bracerightBig In the training and testing phases, within each segment SegEv j of event expression, a class is assigned to each system, where each class class i sys for the i-th system is represented as a list of the classes of the named entities output by the system: class i sys  braceleftbigg /,  , / no output i 1,,n 34 Learning Algorithm We apply a simple decision list learning method to the task of learning a classifier for combining outputs of named entity chunkers 4  A decision list <TREF>Yarowsky, 1994</TREF> is a sorted list of decision rules, each of which decides the value of class given some features f of an event	1	Each decision rule in a decision list is sorted in descending order with respect to some preference value, and rules with higher preference values are applied first when applying the decision list to some new test data	0	In this paper, we simply sort the decision list according to the conditional probability Pclass i  f of the class i of the i-th systems output given a feature f 4 Experimental Evaluation We experimentally evaluate the performance of the proposed system combination method using the IREX workshops training and test data	0	3	2
W04-0862	P94-1013	2004	32 Nave Bayes The second system used was a nave Bayes classifier where the similarity between an instance, I, and a sense class, Sj, is defined as: SimI,Sj  PI,Sj  PSjPISj We then choose the sense class, Sj, which maximized the similarity function above, making standard independence assumptions	0	33 Decision List The final system was a decision list classifier that found the log-likelihoods of the correspondence beAssociation for Computational Linguistics for the Semantic Analysis of Text, Barcelona, <REF>Spain, July 2004</REF> SENSEVAL-3: Third International Workshop on the Evaluation of Systems tween features and senses, using plus-one smoothing <TREF>Yarowsky, 1994</TREF>	1	The features were ordered from most to least indicative to form the decision list	0	A separate decision list was constructed for each set of lexical samples in the training data	0	3	2
W96-0208	P94-1013	1996	The ordering of rules employed in a decision list in order to simplify the representation and perform conflict resolution apparently gives it an advantage over other symbolic methods on this task	0	In addition to the results reported by <TREF>Yarowsky 1994</TREF> and <REF>Mooney and Califf 1995</REF>, it provides evidence for the utility of this representation for natural-language problems	1	With respect to training time, the symbolic methods are significantly slower since they are searching for a simple declarative representation of the concept	0	Empirically, the time complexity for most methods are growing somewhat worse than linearly in the number of training examples	0	4	2
W96-0208	P94-1013	1996	Finally, decision lists <REF>Rivest, 1987</REF> are ordered lists of conjunctive rules, where rules are tested in order and the first one that matches an instance is used to classify it	0	A number of effective concept-learning systems have employed decision lists Clark 84 <REF>Niblett, 1989</REF>; <REF>Quinlan, 1993</REF>; <REF>Mooney  Califf, 1995</REF> and they have already been successfully applied to lexical disambiguation <TREF>Yarowsky, 1994</TREF>	1	All of the logic-based methods are variations of the FOIL algorithm for induction of first-order function-free Horn clauses <REF>Quinlan, 1990</REF>, appropriately simplified for the propositional case	0	They are called PFoIL-DNF, PFOlL-CNF, and PFoIL-DLIsT	0	1	2
P02-1044	P94-1013	2002	Many methods for word sense disambiguation using a supervised learning technique have been proposed	0	They include those using Nave Bayes <REF>Gale et al 1992a</REF>, Decision List <TREF>Yarowsky 1994</TREF>, Nearest Neighbor <REF>Ng and Lee 1996</REF>, Transformation Based Learning <REF>Mangu and Brill 1997</REF>, Neural Network Towell and 1 In this paper, we take English-Chinese translation as example; it is a relatively easy process, however, to extend the discussions to translations between other language pairs	1	Computational Linguistics ACL, <REF>Philadelphia, July 2002</REF>, pp	0	343-351	0	6	1
J98-2002	P94-1013	1998	In practice, however, many words have sense ambiguity and a word can belong to several different classes, eg, bird is a member of both BIRD and MEAT	0	Thorough treatment of this problem is beyond the scope of the present paper; we simply note that one can employ an existing word-sense disambiguation technique eg ,<REF>Yarowsky 1992, 1994</REF> in preprocessing, and use the disambiguated word senses as virtual words in the following 220 Li and Abe Generalizing Case Frames ANIMAL BIRD INSECT swallow crow eagle bird bug bee insect Figure 3 An example thesaurus	1	case-pattern acquisition process	0	It is also possible to extend our model so that each word probabilistically belongs to several different classes, which would allow us to resolve both structural and word-sense ambiguities at the time of disambiguation	0	6	1
D07-1026	P94-1013	2007	32 The Syntagmatic Kernel Syntagmatic aspects are probably the most important evidence for recognizing lexical entailment	0	In general, the strategy adopted to model syntagmatic relations in WSD is to provide bigrams and trigrams ofcollocatedwordsasfeaturestodescribelocalcontexts <TREF>Yarowsky, 1994</TREF>	0	The main drawback of this approach is that non contiguous or shifted collocations cannot be identified, decreasing the generalization power of the learning algorithm	1	For example, suppose that the word job has to be disambiguated into the sentence permanent academic job in, and that the occurrence We offer permanent positions is provided for training	0	1	3
C00-1082	P94-1013	2000	In this study we used ill the decision-list method the same 152 types of patterns that were used in/;lie maximuln-entropy method	1	To determine the priority order of the rules, we referred to Yarowskys method <TREF>Yarowsky, 1994</TREF> and Nishiokwamas method <REF>Nishiokaymna et al , 1998</REF> and used the probability and frequency of each rule as measures of this priority order	0	When nnlltiple rifles had the same probability, the rules were arranged in order of their frequency	0	Suppose, for example, that Pattern A Noun: Normal Noun; Particle: Case-Particle: none: wo; Verb: Normal Form: 217; Symhol: Punctuatioif occurs 13 times in a learlfing set and that tell of the occurrences include the inserted partition Inal:k Suppose also thai; Pattern B Noun; Particle; Verb; Symbol occurs 12a times in a learning set and that 90 of the occurrences include the mark	0	3	2
W06-1665	P95-1026	2006	In order to limit the computation complexity, we will only consider adding one additional word into relations	0	The proposed approach follows the same principle as <TREF>Yarowsky, 1995</TREF>, which tried to determine the appropriate word sense according to one relevant context word	0	However, the requirement for query expansion is less than word sense disambiguation: we do not need to know the exact word sense to make expansion	0	We only need to determine the relevant expansion terms	0	0	0
W06-1665	P95-1026	2006	However, our approach does not require determining syntactic dependency	0	The principle of our approach is more similar to <TREF>Yarowsky, 1995</TREF>	0	Compared to this latter, our approach is less demanding: we do not need to identify manually the exact word senses and seed context words	0	The process is fully automatic	0	0	0
W06-2204	P95-1026	2006	A number of researchers have previously developed bootstrapping or semi-supervised approaches to information extraction, named entity recognition, and related tasks <REF>Riloff, 1996</REF>; <REF>Brin, 1998</REF>; <REF>Riloff and Jones, 1999</REF>; <REF>Agichtein et al , 2001</REF>; <REF>Yangarber et al , 2002</REF>; <REF>Stevenson and Greenwood, 2005</REF>; <REF>Etzioni et al , 2005</REF>	0	Several approaches for learning from both labeled and unlabeled data have been proposed <TREF>Yarowsky, 1995</TREF>; <REF>Blum and Mitchell, 1998</REF>; <REF>Collins and Singer, 1999</REF> where the unlabeled data is utilised to boost the performance of the algorithm	0	In <REF>Collins and Singer, 1999</REF> Collins and Singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification	0	However, their approach is reliant on the presence of redundancy in the named entities to be identified	0	0	0
P04-1037	P95-1026	2004	Many recent approaches make use of ideas from statistical machine learning; the availability of shared sense de nitions eg WordNet <REF>Fellbaum, 1998</REF> and recent international competitions <REF>Kilgarrif and Rosenzweig, 2000</REF> have enabled researchers to compare their results	0	Supervised approaches which make use of a small hand-labeled training set <REF>Bruce and Wiebe, 1994</REF>; <REF>Yarowsky, 1993</REF> typically outperform unsupervised approaches <REF>Agirre et al , 2000</REF>; <REF>Litkowski, 2000</REF>; <REF>Lin, 2000</REF>; <REF>Resnik, 1997</REF>; <REF>Yarowsky, 1992</REF>; <TREF>Yarowsky, 1995</TREF>, but tend to be tuned to a speci c corpus and are constrained by scarcity of labeled data	0	In an effort to overcome the dif culty of nding sense-labeled training data, researchers have begun investigating unsupervised approaches to wordsense disambiguation	0	For example, the use of parallel corpora for sense tagging can help with word sense disambiguation <REF>Brown et al , 1991</REF>; <REF>Dagan, 1991</REF>; <REF>Dagan and Itai, 1994</REF>; <REF>Ide, 2000</REF>; <REF>Resnik and Yarowsky, 1999</REF>	0	0	0
E99-1024	P95-1026	1999	In this paper, we propose a method of detecting Japanese homophone errors in Japanese texts	0	Our method is based on a decision list proposed by Yarowsky <REF>Yarowsky, 1994</REF>; <TREF>Yarowsky, 1995</TREF>	0	We improve the original decision list by using written words in the default evidence	0	The improved decision list can raise the F-measure of error detection	0	0	0
J98-1005	P95-1026	1998	Then, a single neural network of the structure described in Section 41 is created and copied 25 times	0	At each training-set size, a new copy of the network is trained under each of the following conditions: 1 using SULU, 2 using SULU but supplying only the labeled training examples to synthesize, 3 standard network training, 4 using a re-implementation of an algorithm proposed by <TREF>Yarowsky 1995</TREF>, and 5 using standard network training but with all training examples labeled to establish an upper bound	0	This procedure is repeated 11 times to average out the effects of example selection and network initialization	0	Yarowskys algorithm expands the region of known, labeled examples out from a small set of hand-labeled seed collocations	0	0	0
J02-3002	P95-1026	2002	<REF>Gale, Church, and Yarowsky 1992</REF> showed that words strongly tend to exhibit only one sense in a document or discourse one sense per discourse	0	Since then this idea has been applied to several tasks, including word sense disambiguation <TREF>Yarowsky 1995</TREF> and named-entity recognition <REF>Cucerzan and Yarowsky 1999</REF>	0	Gale, Church, and Yarowskys observation is also used in our DCA, especially for the identification of abbreviations	0	In capitalized-word disambiguation, however, we use this assumption with caution and first apply strategies that rely not just on single words but on words together with their local contexts n-grams	0	0	0
C98-1037	P95-1026	1998	However, there are still room for improvement in the area of precision	0	Evidence have shown that by exploiting the constraint of so-called one sense per discourse, <REF>Gale, Church and Yarowsky 1992b</REF> and the strategy of bootstrapping <TREF>Yarowsky 1995</TREF>, it is possible to boost coverage, while maintaining about the same level of precision	0	42 Discussions Although it is often difficult to compare studies on different text domain, genre and experimental setup, the approach presented here seems to compare favorably with the experimental results reported in previous WSD research	0	<REF>Luk 1995</REF> experiments with the same words we use except the word bank and reports that there are totally 616 instances of these words in the Brown corpus, slightly less than the 749 instances we have experimented on	0	0	0
C98-1037	P95-1026	1998	1992a report that if one had obtained a set of training materials with errors no more than twenty to thirty percent, one could iterate training materials selection just once or twice and have training sets that had less than ten percent errors	0	The adaptive approach is somehow similar to their idea of incremental learning and to the bootstrap approach proposed by <TREF>Yarowsky 1995</TREF>	0	However, both approaches are still considered static models which are changed only in the training phase	0	242 6 Conclusions We have described a new adaptive approach to word sense disambiguation	0	0	0
W04-2402	P95-1026	2004	It outperformed the best-performing bootstrapping method for this task at the time	0	We also note that there are a number of bootstrapping methods successfully applied to text  eg, word sense disambiguation <TREF>Yarowsky, 1995</TREF>, named entity instance classification <REF>Collins and Singer, 1999</REF>, and the extraction of parts word given the whole word <REF>Berland and Charniak, 1999</REF>	0	In Section 5, we report experiments using syntactic features shown to be useful by the above studies, and compare performance with <REF>Thelen and Riloff 2002</REF>s bootstrapping method	0	43 Techniques for learning from unlabeled data While most of the above bootstrapping methods are targeted to NLP tasks, techniques such as EM and cotraining are generally applicable when equipped with appropriate models or classifiers	0	0	0
E06-1018	P95-1026	2006	That essentially means that whenever a pair of words co-occurs significantly often in a corpus hence a collocation, the concept referenced by that pair is unambiguous, eg growing plant vs power plant	0	However, as also pointed out by <TREF>Yarowsky 1995</TREF>, this observation does not hold uniformly over all possible co-occurrences of two words	0	It is stronger for adjacent co-occurrences or for word pairs in a predicate-argument relationship than for arbitrary associations at equivalent distance, eg a plant is much less clear-cut	0	To alleviate this problem, the first step of the presented algorithm is to build triplets of words target word and two of its cooccurrences instead of pairs target word and one co-occurrence	0	0	0
P06-1031	P95-1026	2006	It is de ned by a16a55a30 a1a56a2 major 3 where a16 and a1a3a2 major denote the target noun and the majority of a1a56a2 in the training data, respectively	0	Equation 3 reads If the target noun appears, then it is distinguished by the majority  The log-likelihood ratio <TREF>Yarowsky, 1995</TREF> decides in which order rules are applied to the target noun in novel context	0	It is de ned by2 a57 a11a46a58 a22a60a59 a1a56a2a62a61 a18 a28a60a63 a22a60a59 a1a56a2a62a61 a18 a28a60a63 4 where a1a56a2 is the exclusive event of a1a3a2 and a22a64a59 a1a3a2a65a61 a18 a28a55a63 is the probability that the target noun is used as a1a56a2 when a18 appears in the context a2  It is important to exercise some care in estimating a22a64a59 a1a56a2a62a61a18a29a28 a63  In principle, we could simply 2For the default rule, the log-likelihood ratio is de ned by replacing a66a50a67 and a68a70a69 with a71 and a68a70a69 major, respectively	0	243 count the number of times that a18 appears in the context a2 of the target noun used as a1a3a2 in the training data	0	0	0
W03-1302	P95-1026	2003	This property of words was first described and quantified by <REF>Yarowsky 1993</REF>, and has become known generally as the One Sense Per Collocation property	0	<TREF>Yarowsky 1995</TREF> used the one sense per collocation property as an essential ingredient for an unsupervised Word-SenseDisambiguationalgorithm	0	For example, the collocations plant life and manufacturing plant are used as seed-examples for the living thing and building senses of plant, and these examples can then be used as high-precision training data to perform more general high-recall disambiguation	0	While Yarowskys algorithm is unsupervised the algorithm does not need a large collection of annotated training examples, it still needs direct human intervention to recognise which ambiguous terms are amenable to this technique, and to choose appropriate seed-collocations for each sense	0	0	0
W03-0427	P95-1026	2003	Alternative to using this data to expand or bootstrap seed lists <REF>Cucerzan and Yarowsky, 1999</REF>; Buchholz and Van den <REF>Bosch, 2000</REF>, we use the unannotated corpus to select useful instances to be added directly to the training set	0	Not unlike <TREF>Yarowsky, 1995</TREF> we use confidence of our classifier on unannotated data to enrich itself; that is, by adding confidently-classified instances to the memory	0	We make the simple assumption that entropy in the class distribution in the nearest neighbour set computed in the classification of a new instance is correlated with the reliability of the classification, when k > 1	0	When k nearest neighbours all vote for the same class, the entropy of that class vote is 00	0	0	0
P98-2228	P95-1026	1998	We trained decision lists <REF>Clark and Niblett, 1989</REF> using a supervised learning approach	0	Decision lists have already been successfully applied to lexical ambiguity resolution by <TREF>Yarowsky, 1995</TREF> where they perfromed well	0	We present the decision list system with a number of training words for which the correct sense is known	0	For each of the words we supply each of its possible senses apart from those removed from consideration by the part-of-speech filter Section 32 within a context consisting of the results from each of the partial taggers, frequency information and 10 simple collocations first noun/verb/preposition to the left/right and first/second word to the left/right	0	0	0
P98-2228	P95-1026	1998	The methodology and evaluation of WSD are somewhat different from those of other NLP modules, and one can distinguish three aspects of this difference, all of which come down to evaluation problems, as does so much in NLP these days	0	First, researchers are divided between a general method that attempts to apply WSD to all the content words of texts, the option taken in this paper and one that is applied only to a small trial selection of texts words for example <REF>Schiitze, 1992</REF> <TREF>Yarowsky, 1995</TREF>	0	These researchers have obtained very high levels of success, in excess of 95, close to the figures for other solved NLP modules, the issue being whether these small word sample methods and techniques will transfer to general WSD over all content words	0	Others, eg	0	0	0
J01-3001	P95-1026	2001	Another source of difference in approach is the proportion of the vocabulary disambiguated	0	Some researchers have concentrated on producing WSD systems that base results on a limited number of words, for example <TREF>Yarowsky 1995</TREF> and <REF>Schtitze 1992</REF> who quoted results for 12 words, and a second group, including <REF>Leacock, Towell, and Voorhees 1993</REF> and <REF>Bruce and Wiebe 1994</REF>, who gave results for just one, namely interest	0	But limiting the vocabulary on which a system is evaluated can have two serious drawbacks	0	First, the words used were not chosen by frequency-based sampling techniques and so we have no way of knowing whether or not they are special cases, a point emphasised by <REF>Kilgarriff 1997</REF>	0	0	0
J01-3001	P95-1026	2001	Test corpora in which each ambiguous token has exactly two senses were used by Brown et al	0	1991, <TREF>Yarowsky 1995</TREF> and others	0	Our system was tested using a technique known as 10-fold cross validation	0	This process is carried out by splitting the available data into ten roughly equal subsets	0	0	0
J01-3001	P95-1026	2001	Yet collocates have limited applicability; although precise, they can only be applied to a limited number of tokens	0	<TREF>Yarowsky 1995</TREF> dealt with this problem largely by producing an unsupervised learning algorithm that generates probabilistic decision list models of word senses from seed collocates	0	This algorithm achieves 97 correct disambiguation	0	In these experiments Yarowsky deals exclusively with binary sense distinctions and evaluates his highly effective algorithms on small samples of word tokens	0	0	0
J01-3001	P95-1026	2001	There has been far less consensus as to the best approach to WSD	0	Currently, machine learning methods <TREF>Yarowsky 1995</TREF>; <REF>Rigau, Atserias, and Agirre 1997</REF> and combinations of classifiers <REF>McRoy 1992</REF> have been popular	0	This paper reports a WSD system employing elements of both approaches	0	Another source of difference in approach is the proportion of the vocabulary disambiguated	0	0	0
P99-1043	P95-1026	1999	Co-occurrence information between neighboring words and words in the same sentence has been used in phrase extraction <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>, phrasal translation <REF>Smadja et al , 1996</REF>; <REF>Kupiec, 1993</REF>; <REF>Wu, 1995</REF>; <REF>Dagan and Church, 1994</REF>, target word selection <REF>Liu and Li, 1997</REF>; <REF>Tanaka and Iwasaki, 1996</REF>, domain word translation <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, sense disambiguation <REF>Brown et al , 1991</REF>; <REF>Dagan et al , 1991</REF>; <REF>Dagan and Itai, 1994</REF>; <REF>Gale et al , 1992a</REF>; <REF>Gale et al , 1992b</REF>; <REF>Gale et al , 1992c</REF>; <REF>Shiitze, 1992</REF>; <REF>Gale et al , 1993</REF>; <TREF>Yarowsky, 1995</TREF>, and even recently for query translation in cross-language IR as well <REF>Ballesteros and Croft, 1998</REF>	0	Co-occurrence statistics is collected from either bilingual parallel and 334 non-parallel corpora <REF>Smadja et al , 1996</REF>; <REF>Kupiec, 1993</REF>; <REF>Wu, 1995</REF>; <REF>Tanaka and Iwasaki, 1996</REF>; <REF>Fung and Lo, 1998</REF>, or monolingual corpora <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>; <REF>Liu and Li, 1997</REF>; <REF>Shiitze, 1992</REF>; <TREF>Yarowsky, 1995</TREF>	0	As we noted in <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, parallel corpora are rare in most domains	0	We want to devise a method that uses only monolingual data in the primary language to train co-occurrence information	0	0	0
P99-1043	P95-1026	1999	The performance of the voting method is better than the baseline because more contextual words are used	0	The results are consistent with the idea in <REF>Gale and Church, 1994</REF>; <REF>Shfitze, 1992</REF>; <TREF>Yarowsky, 1995</TREF>	0	In our experiments, it is found that 1-best contextual word is even better than multiple contextual words	0	This seemingly counterintuitive result leads us to believe that choosing the most discriminative single word is even more powerful than using multiple contextual word equally	0	0	0
P99-1043	P95-1026	1999	Another reason against using single neighboring word comes from <REF>Gale and Church, 1994</REF> where it is argued that as many as 100,000 context words might be needed to have high disambiguation accuracy	0	<REF>Shfitze, 1992</REF>; <TREF>Yarowsky, 1995</TREF> all use multiple context words as discriminating features	0	We have also demonstrated in our domain translation task that multiple context words are useful <REF>Fung and Lo, 1998</REF>; <REF>Fung and McKeown, 1997</REF>	0	Based on the above arguments, we enlarge the disambiguation window to be the entire sentence instead of only one word to the left or right	0	0	0
P99-1043	P95-1026	1999	pruning translation alternatives for query translation	0	Co-occurrence information between neighboring words and words in the same sentence has been used in phrase extraction <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>, phrasal translation <REF>Smadja et al , 1996</REF>; <REF>Kupiec, 1993</REF>; <REF>Wu, 1995</REF>; <REF>Dagan and Church, 1994</REF>, target word selection <REF>Liu and Li, 1997</REF>; <REF>Tanaka and Iwasaki, 1996</REF>, domain word translation <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, sense disambiguation <REF>Brown et al , 1991</REF>; <REF>Dagan et al , 1991</REF>; <REF>Dagan and Itai, 1994</REF>; <REF>Gale et al , 1992a</REF>; <REF>Gale et al , 1992b</REF>; <REF>Gale et al , 1992c</REF>; <REF>Shiitze, 1992</REF>; <REF>Gale et al , 1993</REF>; <TREF>Yarowsky, 1995</TREF>, and even recently for query translation in cross-language IR as well <REF>Ballesteros and Croft, 1998</REF>	0	Co-occurrence statistics is collected from either bilingual parallel and 334 non-parallel corpora <REF>Smadja et al , 1996</REF>; <REF>Kupiec, 1993</REF>; <REF>Wu, 1995</REF>; <REF>Tanaka and Iwasaki, 1996</REF>; <REF>Fung and Lo, 1998</REF>, or monolingual corpora <REF>Smadja, 1993</REF>; <REF>Fung and Wu, 1994</REF>; <REF>Liu and Li, 1997</REF>; <REF>Shiitze, 1992</REF>; <TREF>Yarowsky, 1995</TREF>	0	As we noted in <REF>Fung and Lo, 1998</REF>; <REF>Fung, 1998</REF>, parallel corpora are rare in most domains	0	0	0
P06-2071	P95-1026	2006	Therefore, it makes sense to consider the division between core sense, related sense, and unrelated sense in ISD, and, as an additional complication, their boundaries are often blurred	0	Most importantly, whereas the one-sense-per-discourse assumption <TREF>Yarowsky, 1995</TREF> also applies to discriminating images, there is no guarantee of a local collocational or co-occurrence context around the target image	0	Design or aesthetics may instead determine image placement	0	Thus, considering local text around the image may not be as helpful as local context is for standard WSD	0	0	0
P06-2071	P95-1026	2006	5 Comparison to previous work Space does not allow a complete review of the WSD literature	0	<TREF>Yarowsky, 1995</TREF> demonstrated that semi-supervised WSD could be successful	0	<REF>Schutze, 1998</REF> and <REF>Lin and Pantel, 2002a</REF>, b show that clustering methods are helpful in this area	0	While ISD has received less attention, image categorization has been approached previously by adding text features	0	0	0
P06-2071	P95-1026	2006	We conclude with an outline of plans for future work in section 6	0	2 Data and annotation Yahoos image query API was used to obtain a corpus of pairs of semantically ambiguous images, in thumbnail and true size, and their corresponding web sites for three ambiguous keywords inspired by <TREF>Yarowsky, 1995</TREF>: BASS, CRANE, and SQUASH	0	We apply query augmentation cf	0	Table 1, and exact duplicates were filtered out by identical image URLs, but cases occurred where both thumbnail and true-size image were included	0	0	0
P06-1027	P95-1026	2006	The performance of the semi-supervised CRF is not overly sensitive to the tradeoff parameter a102, except that a102 cannot be set too large	0	51 Comparison to self-training For completeness, we also compared our results to the self-learning algorithm, which has commonly been referred to as bootstrapping in natural language processing and originally popularized by the work of Yarowsky in word sense disambiguation <REF>Abney 2004</REF>; <TREF>Yarowsky 1995</TREF>	0	In fact, similar ideas have been developed in pattern recognition under the name of the decision-directed algorithm <REF>Duda and Hart 1973</REF>, and also traced back to 1970s in the EM literature <REF>Celeux and Govaert 1992</REF>	0	The basic algorithm works as follows: 1	0	0	0
P06-1027	P95-1026	2006	Moreover, in complex structured prediction tasks, such as parsing or sequence modeling part-of-speech tagging, word segmentation, named entity recognition, and so on, it is considerably more difficult to obtain labeled training data than for classification tasks such as document classification, since hand-labeling individual words and word boundaries is much harder than assigning text-level class labels	0	Many approaches have been proposed for semisupervised learning in the past, including: generative models <REF>Castelli and Cover 1996</REF>; <REF>Cohen and Cozman 2006</REF>; <REF>Nigam et al 2000</REF>, self-learning <REF>Celeux and Govaert 1992</REF>; <TREF>Yarowsky 1995</TREF>, cotraining <REF>Blum and Mitchell 1998</REF>, informationtheoretic regularization <REF>Corduneanu and Jaakkola 2006</REF>; <REF>Grandvalet and Bengio 2004</REF>, and graphbased transductive methods <REF>Zhou et al 2004</REF>; <REF>Zhou et al 2005</REF>; <REF>Zhu et al 2003</REF>	0	Unfortunately, these techniques have been developed primarily for single class label classification problems, or class label classification with a structured input <REF>Zhou et al 2004</REF>; <REF>Zhou et al 2005</REF>; <REF>Zhu et al 2003</REF>	0	Although still highly desirable, semi-supervised learning for structured classification problems like sequence segmentation and labeling have not been as widely studied as in the other semi-supervised settings mentioned above, with the sole exception of generative models	0	0	0
P06-1027	P95-1026	2006	Given a biomedical text, the task of identifying gene mentions can be interpreted as a tagging task, where each word in the text can be labeled with a tag that indicates whether it is the beginning of gene mention B, the continuation of a gene mention I, or outside of any gene mention O	0	To compare the performance of different taggers learned by different mechanisms, one can measure the precision, recall and F-measure, given by precision   correct predictions predicted gene mentions recall   correct predictions true gene mentions F-measure  a96a15a14 precision a14 recallprecision a44 recall In our evaluation, we compared the proposed semi-supervised learning approach to the state of the art supervised CRF of <REF>McDonald and Pereira 2005</REF>, and also to self-training <REF>Celeux and Govaert 1992</REF>; <TREF>Yarowsky 1995</TREF>, using the same feature set as <REF>McDonald and Pereira 2005</REF>	0	The CRF training procedures, supervised and semi213 supervised, were run with the same regularization function, a91a47a12 a66 a28a39a8 a94 a66 a94a30a96a34a97a70a98, used in <REF>McDonald and Pereira 2005</REF>	0	First we evaluated the performance of the semisupervised CRF in detail, by varying the ratio between the amount of labeled and unlabeled data, and also varying the tradeoff parameter a102  We choose a labeled training set a0 consisting of 5448 words, and considered alternative unlabeled training sets, a1 5210 words, a80 10,208 words, and a2 25,145 words, consisting of the same, 2 times and 5 times as many sentences as a0 respectively	0	0	0
P06-1056	P95-1026	2006	The monolingual bootstrapping approach was also used by <REF>Hearst 1991</REF>, who used a small set of handlabeled data to bootstrap from a larger corpus for training a noun disambiguation system for English	0	<REF>Unlike Yarowsky 1995</REF>, we use automatic collection of seeds	0	Besides our monolingual bootstrapping technique, we also use bilingual bootstrapping	0	<REF>Diab 2002</REF> has shown that unsupervised WSD systems that use parallel corpora can achieve results that are close to the results of a supervised approach	0	0	0
P06-1056	P95-1026	2006	WSD is a task that has attracted researchers since 1950 and it is still a topic of high interest	0	Determining the sense of an ambiguous word, using bootstrapping and texts from a different language was done by <TREF>Yarowsky 1995</TREF>, <REF>Hearst 1991</REF>, <REF>Diab 2002</REF>, and <REF>Li and Li 2004</REF>	0	<TREF>Yarowsky 1995</TREF> has used a few seeds and untagged sentences in a bootstrapping algorithm based on decision lists	0	He added two constrains  words tend to have one sense per discourse and one sense per collocation	0	0	0
P06-1056	P95-1026	2006	Determining the sense of an ambiguous word, using bootstrapping and texts from a different language was done by <TREF>Yarowsky 1995</TREF>, <REF>Hearst 1991</REF>, <REF>Diab 2002</REF>, and <REF>Li and Li 2004</REF>	0	<TREF>Yarowsky 1995</TREF> has used a few seeds and untagged sentences in a bootstrapping algorithm based on decision lists	0	He added two constrains  words tend to have one sense per discourse and one sense per collocation	0	He reported high accuracy scores for a set of 10 words	0	0	0
J04-3004	P95-1026	2004	For many language-processing tasks, there are an abundance of unlabeled data, but labeled data are lacking and too expensive to create in large quantities, making bootstrapping techniques desirable	0	<REF>The Yarowsky 1995</REF> algorithm was one of the first bootstrapping algorithms to become widely known in computational linguistics	0	In brief, it consists of two loops	0	The inner loop or base learner is a supervised learning algorithm	0	0	0
J98-1006	P95-1026	1998	For example, line is equally polysemous in French and English--and most senses of line translate into French as ligne	0	Several artificial techniques have been used so that classifiers can be developed and tested without having to invest in manually tagging the data: <REF>Yarowsky 1993</REF> and Sch/itze 1995 have acquired training and testing materials by creating pseudowords from existing nonhomographic forms	0	For example, a pseudoword was created by combining abusedescorted	0	Examples containing the string escorted were collected to train on one sense of the pseudoword and examples containing the string abused were collected to train on the other sense	0	0	0
J98-1006	P95-1026	1998	Consequently, it does not provide disambiguated examples that can be used by other systems	0	<TREF>Yarowsky 1995</TREF> has proposed automatically augmenting a small set of experimenter-supplied seed collocations eg , manufacturing plant and plant life for two different senses of the noun plant into a much larger set of training materials	0	He resolved the problem of the sparseness of his collocations by iteratively bootstrapping acquisition of training materials from a few seed collocations for each sense of a homograph	0	He locates examples containing the seeds in the corpus and analyzes these to find new predictive patterns in these sentences and retrieves examples containing these patterns	0	0	0
H05-1107	P95-1026	2005	Another bootstrapping approach reminiscent of EM is self-training	0	<TREF>Yarowsky 1995</TREF> used this method for word sense disambiguation	0	In self-training, annotated examples are used as seeds to train an initial classifier with any supervised learning method	0	This initial classifier is then used to automatically annotate data from a large pool of unlabeled examples	0	0	0
J06-2003	P95-1026	2006	These are split further for each leaf class, as explained in Section 23	0	The algorithm we implemented is inspired by the work of <TREF>Yarowsky 1995</TREF> on word sense disambiguation	0	He classified the senses of a word on the basis of other words that the given word co-occurs with	0	<REF>Collins and Singer 1999</REF> classified proper names 1 We are grateful to HarperCollins Publishers, Inc for permission to use CTRW in this project	0	0	0
W05-1006	P95-1026	2005	Some of the pairs extracted are examples of general semantic patterns, others are examples of genuinely idiomatic phrases	0	Even for semantically predictable phrases, the fact that the words occur in fixed patterns can be very useful for the purposes of disambiguation, as demonstrated by <TREF>Yarowsky, 1995</TREF>	0	However, it 53 would be useful to be able to tell which of the asymmetric patterns extracted by our experiments correspond to semantically regular phrases which happen to have a conventional ordering preference, and which phrases correspond to genuine idioms	0	This final section demonstrates two techniques for performing this filtering task, which show promising results for improving our classification, though should not yet be considered as reliable	0	0	0
P07-1006	P95-1026	2007	Finally, we described our experiments and their results Section 4	0	WSD approaches can be classified as a knowledge-based approaches, which make use of linguistic knowledge, manually coded or extracted from lexical resources <REF>Agirre and Rigau, 1996</REF>; <REF>Lesk 1986</REF>; b corpus-based approaches, which make use of shallow knowledge automatically acquired from corpus and statistical or machine learning algorithms to induce disambiguation models <TREF>Yarowsky, 1995</TREF>; <REF>Schtze 1998</REF>; and c hybrid approaches, which mix characteristics from the two other approaches to automatically acquire disambiguation models from corpus supported by linguistic knowledge <REF>Ng and Lee 1996</REF>; <REF>Stevenson and Wilks, 2001</REF>	0	Hybrid approaches can combine advantages from both strategies, potentially yielding accurate and comprehensive systems, particularly when deep knowledge is explored	0	Linguistic knowledge is available in electronic resources suitable for practical use, such as WordNet <REF>Fellbaum, 1998</REF>, dictionaries and parsers	0	0	0
W99-0903	P95-1026	1999	However, the dictionary definitions alone do not contain enough information to allow reliable disambiguation	0	Recently, many works combined a MRD and a corpus for word sense disambiguation<REF>Karov, 1998</REF>; <REF>Luk, 1995</REF>; <REF>Ng, 1996</REF>; Yarowsky,1995	0	In Yarowsky,1995, the definition words were used as initial sense indicators, automatically tagging the target word examples containing them	0	These tagged examples were then used as seed examples in a bootstrapping process	0	0	0
W99-0903	P95-1026	1999	Recently, many works combined a MRD and a corpus for word sense disambiguation<REF>Karov, 1998</REF>; <REF>Luk, 1995</REF>; <REF>Ng, 1996</REF>; Yarowsky,1995	0	In Yarowsky,1995, the definition words were used as initial sense indicators, automatically tagging the target word examples containing them	0	These tagged examples were then used as seed examples in a bootstrapping process	0	In <REF>Luk, 1995</REF>, using the dictionary definition, co-occurrence data of concepts, rather than words, is collected from a relatively small corpus to tackle the data sparseness problem	0	0	0
W99-0903	P95-1026	1999	Most previous works have reported the results in 70-92 accuracies for particular words	0	However, our system is the unsupervised learning with small POS-tagged corpus,and we do not restrict the words sense set within either binary sensesYarowsky,1995; <REF>Karov, 1998</REF> or dictionarys homograph level<REF>Wilks, 1997</REF>	0	Thus, our system is appropriate for practical WSD system as well as bootstrapping WSD system starting with small corpus	0	Using MRDs for word sense disambiguation was popularized by <REF>Lesk, 1986</REF>	0	0	0
P05-1001	P95-1026	2005	Although useful under some circumstances, when a relatively large amount of labeled data is available, the procedure often degrades performance eg <REF>Merialdo 1994</REF>	0	A number of bootstrapping methods have been proposed for NLP tasks eg <TREF>Yarowsky 1995</TREF>, <REF>Collins and Singer 1999</REF>, <REF>Riloff and Jones 1999</REF>	0	But these typically assume a very small amount of labeled data and have not been shown to improve state-of-the-art performance when a large amount of labeled data is available	0	Our goal has been to develop a general learning framework for reliably using unlabeled data to improve performance irrespective of the amount of labeled data available	0	0	0
C00-2094	P95-1026	2000	The great advantage of statistical methods over symbolic-linguistic methods has been deemed to be their effective exploitation of minimal linguist;it knowledge	0	However, the best performing statistical approaches to lexical ambiguity resolution l;lmmselves rely on complex infornmtion sources such as lemmas, inflected forms, parts of speech and arbitrary word classes If local and distant collocations, trigram sequences, and predicate mgument association <TREF>Yarowsky 1995</TREF>, p 190 or large context-windows up to 1000 neighboring words Sch/itze, 1992	0	Unfortmmtely, in many applications such information is not readily available	0	For instance, in incremental machine translation, it may be desirable to decide for the most probable translation of the arguments of a verb with only the translation of the verb as information source lint no large window of sunounding translations available	0	0	0
C00-2094	P95-1026	2000	The precision results for the ten unsupervised systems taking part in the comtetitive evaluation ranged Kern 20-65 at efficiency values from 3-54	0	The SENSEVAL tanlard is clearly beaten by the earlier results of <TREF>Yarowsky 1995</TREF> 965  precision and <REF>Schiitze 1992</REF> 92  precision	0	However, a comparison to these refrom his random baseline 285  by taking 100/285; reversely, Dagan and Itais 1994 random baseline can be calculated as 100/227  4405	0	Tile ambiguity t;ctor for SENSEVAL is calculated for tile llOUll task in the English SENSEVAL test set	0	0	0
N07-1025	P95-1026	2007	The correct sense of an ambiguous word can be selected based on the context where it occurs, and correspondingly the problem of word sense disambiguation is defined as the task of automatically assigning the most appropriate meaning to a polysemous word within a given context	0	Among the various knowledge-based <REF>Lesk, 1986</REF>; <REF>Galley and McKeown, 2003</REF>; <REF>Navigli and Velardi, 2005</REF> and data-driven <TREF>Yarowsky, 1995</TREF>; <REF>Ng and Lee, 1996</REF>; <REF>Pedersen, 2001</REF> word sense disambiguation methods that have been proposed to date, supervised systems have been constantly observed as leading to the highest performance	0	In these systems, the sense disambiguation problem is formulated as a supervised learning task, where each sense-tagged occurrence of a particular word is transformed into a feature vector which is then used in an automatic learning process	0	Despite their high performance, these supervised systems have an important drawback: their applicability is limited to those few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand	0	0	0
N07-1025	P95-1026	2007	To address the sense-tagged data bottleneck problem, different methods have been proposed in the past, with various degrees of success	0	This includes the automatic generation of sense-tagged data using monosemous relatives <REF>Leacock et al , 1998</REF>; <REF>Mihalcea and Moldovan, 1999</REF>; <REF>Agirre and Martinez, 2004</REF>, automatically bootstrapped disambiguation patterns <TREF>Yarowsky, 1995</TREF>; <REF>Mihalcea, 2002</REF>, parallel texts as a way to point out word senses bearing different translations in a second language <REF>Diab and Resnik, 2002</REF>; <REF>Ng et al , 2003</REF>; <REF>Diab, 2004</REF>, and the use of volunteer contributions over the Web Chklovski and <REF>Mihalcea, 2002</REF>	0	In this paper, we investigate a new approach for building sense tagged corpora using Wikipedia as a source of sense annotations	0	Starting with the hyperlinks available in Wikipedia, we show how we can generate sense annotated corpora that can be used for building accurate and robust sense classifiers	0	0	0
N07-1025	P95-1026	2007	The lack of sense-tagged corpora can also be circumvented using bootstrapping algorithms, which start with a few annotated seeds and iteratively generate a large set of disambiguation patterns	0	This method, initially proposed by <TREF>Yarowsky, 1995</TREF>, was successfully evaluated in the context of the SENSEVAL framework <REF>Mihalcea, 2002</REF>	0	Finally, in an effort related to the Wikipedia collection process, <REF>Chklovski and Mihalcea, 2002</REF> have implemented the Open Mind Word Expert system for collecting sense annotations from volunteer contributors over the Web	0	The data generated using this method was then used by the systems participating in several of the SENSEVAL-3 tasks	0	0	0
P08-1030	P95-1026	2008	Proceedings of ACL-08: HLT, pages 254262, Columbus, Ohio, USA, <REF>June 2008</REF>	0	c2008 Association for Computational Linguistics Refining Event Extraction through Cross-document Inference   Heng Ji Ralph Grishman Computer Science Department New York University New York, NY 10003, USA hengji, grishmancsnyuedu       Abstract We apply the hypothesis of One Sense Per Discourse <TREF>Yarowsky, 1995</TREF> to information extraction IE, and extend the scope of discourse from one single document to a cluster of topically-related documents	0	We employ a similar approach to propagate consistent event arguments across sentences and documents	0	Combining global evidence from related documents with local decisions, we design a simple scheme to conduct cross-document inference for improving the ACE event extraction task 1  Without using any additional labeled data this new approach obtained 76 higher F-Measure in trigger labeling and 6 higher F-Measure in argument labeling over a state-of-the-art IE system which extracts events independently for each sentence	0	0	0
P08-1030	P95-1026	2008	For example its hard to decide whether named represents a PersonnelNominate or PersonnelStart-Position event mention; hacked to death represents a LifeDie or ConflictAttack event mention without following more specific annotation guidelines	0	The trigger labeling task described in this paper is in part a task of word sense disambiguation WSD, so we have used the idea of sense consistency introduced in <TREF>Yarowsky, 1995</TREF>, extending it to operate across related documents	0	Almost all the current event extraction systems focus on processing single documents and, except for coreference resolution, operate a sentence at a time <REF>Grishman et al, 2005</REF>; <REF>Ahn, 2006</REF>; <REF>Hardy et al, 2006</REF>	0	We share the view of using global inference to improve event extraction with some recent research	0	0	0
P97-1009	P95-1026	1997	In several recent proposals <REF>Hearst, 1991</REF>; <REF>Bruce and Wiebe, 1994</REF>; <REF>Leacock, Towwell, and Voorhees, 1996</REF>; <REF>Ng and Lee, 1996</REF>; <REF>Yarowsky, 1992</REF>; <REF>Yarowsky, 1994</REF>, statistical and machine learning techniques were used to extract classifiers from hand-tagged corpus	0	Yarowsky <TREF>Yarowsky, 1995</TREF> proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples	0	Most previous corpus-based WSD algorithms determine the meanings of polysemous words by exploiting their local contexts	0	A basic intuition that underlies those algorithms is the following: i Two occurrences of the same word have identical meanings if they have similar local contexts	0	0	0
P97-1009	P95-1026	1997	Firstly, a word must occur thousands of times before a good classifier can be learned	0	In Yarowskys experiment <TREF>Yarowsky, 1995</TREF>, an average of 3936 examples were used to disambiguate between two senses	0	In Ng and Lees experiment, 192,800 occurrences of 191 words were used as training examples	0	There are thousands of polysemous words, eg, there are 11,562 polysemous nouns in WordNet	0	0	0
C04-1071	P95-1026	2004	Even though we exploited many advantages of deep analysis, we could create a sentiment analysis system at a very low development cost, becausemanyofthetechniquesformachinetranslation can be reused naturally when we regard the extraction of sentiment units as a kind of translation	0	Many techniques which have been studied for the purpose of machine translation, such as word sense disambiguation <REF>Dagan and Itai, 1994</REF>; <TREF>Yarowsky, 1995</TREF>, anaphora resolution <REF>Mitamura et al , 2002</REF>, and automatic pattern extraction from corpora <REF>Watanabe et al , 2003</REF>, can accelerate the further enhancement of sentiment analysis, or other NLP tasks	0	Therefore this work is the first step towards the integration of shallow and wide NLP, with deep NLP	0	---------------------------------------------------	0	0	0
P06-2065	P95-1026	2006	Unsupervised learning holds great promise for breakthroughs in natural language processing	0	In cases like <TREF>Yarowsky, 1995</TREF>, unsupervised methods offer accuracy results than rival supervised methods <REF>Yarowsky, 1994</REF> while requiring only a fraction of the data preparation effort	0	Such methods have also been a key driver of progress in statistical machine translation, which depends heavily on unsupervised word alignments <REF>Brown et al , 1993</REF>	0	There are also interesting problems for which supervised learning is not an option	0	0	0
P06-1058	P95-1026	2006	Their investigation was based on a 6word test set with 2 senses for each word	0	Yarowsky 1994 and 1995, <REF>Mihalcea and Moldovan 2000</REF>, and <REF>Mihalcea 2002</REF> have made further research to obtain large corpus of higher quality from an initial seed corpus	0	A semi-supervised method proposed by Niu et al	0	2005 clustered untagged instances with tagged ones starting from a small seed corpus, which assumes that similar instances should have similar tags	0	0	0
P05-1049	P95-1026	2005	In this paper, we address the problem of word sense disambiguation WSD, which is to assign an appropriate sense to an occurrence of a word in a given context	0	Many methods have been proposed to deal with this problem, including supervised learning algorithms <REF>Leacock et al , 1998</REF>, semi-supervised learning algorithms <TREF>Yarowsky, 1995</TREF>, and unsupervised learning algorithms <REF>Schutze, 1998</REF>	0	Supervised sense disambiguation has been very successful, but it requires a lot of manually sensetagged data and can not utilize raw unannotated data that can be cheaply acquired	0	Fully unsupervised methods do not need the definition of senses and manually sense-tagged data, but their sense clustering results can not be directly used in many NLP tasks since there is no sense tag for each instance in clusters	0	0	0
P05-1049	P95-1026	2005	Semi-supervised methods for WSD are characterized in terms of exploiting unlabeled data in learning procedure with the requirement of predefined sense inventory for target words	0	They roughly fall into three categories according to what is used for supervision in learning process: 1 using external resources, eg, thesaurus or lexicons, to disambiguate word senses or automatically generate sense-tagged corpus, <REF>Lesk, 1986</REF>; <REF>Lin, 1997</REF>; <REF>McCarthy et al , 2004</REF>; <REF>Seo et al , 2004</REF>; <REF>Yarowsky, 1992</REF>, 2 exploiting the differences between mapping of words to senses in different languages by the use of bilingual corpora eg parallel corpora or untagged monolingual corpora in two languages <REF>Brown et al , 1991</REF>; <REF>Dagan and Itai, 1994</REF>; <REF>Diab and Resnik, 2002</REF>; <REF>Li and Li, 2004</REF>; <REF>Ng et al , 2003</REF>, 3 bootstrapping sensetagged seed examples to overcome the bottleneck of acquisition of large sense-tagged data <REF>Hearst, 1991</REF>; <REF>Karov and Edelman, 1998</REF>; <REF>Mihalcea, 2004</REF>; <REF>Park et al , 2000</REF>; <TREF>Yarowsky, 1995</TREF>	0	As a commonly used semi-supervised learning method for WSD, bootstrapping algorithm works by iteratively classifying unlabeled examples and adding confidently classified examples into labeled dataset using a model learned from augmented labeled dataset in previous iteration	0	It can be found that the affinity information among unlabeled examples is not fully explored in this bootstrapping process	0	0	0
P05-1049	P95-1026	2005	Tuu and Tul are acquired by splitting matrix T after the l-th row and the l-th column into 4 sub-matrices	0	32 Comparison between SVM, Bootstrapping and LP For WSD, SVM is one of the state of the art supervised learning algorithms <REF>Mihalcea et al , 2004</REF>, while bootstrapping is one of the state of the art semi-supervised learning algorithms <REF>Li and Li, 2004</REF>; <TREF>Yarowsky, 1995</TREF>	0	For comparing LP with SVM and bootstrapping, let us consider a dataset with two-moon pattern shown in Figure 1a	0	The upper moon consists of 9 points, while the lower moon consists of 13 points	0	0	0
P05-1049	P95-1026	2005	Finally we suggest an entropy based method to automatically identify a distance measure that can boost the performance of LP algorithm on a given dataset	0	It has been shown that one sense per discourse property can improve the performance of bootstrapping algorithm <REF>Li and Li, 2004</REF>; <TREF>Yarowsky, 1995</TREF>	0	This heuristics can be integrated into LP algorithm by setting weight Wi,j  1 if the i-th and j-th instances are in the same discourse	0	In the future we may extend the evaluation of LP algorithm and related cluster assumption based algorithms using more benchmark data for WSD	0	0	0
W06-0505	P95-1026	2006	This classifier extracts entities from text, and assigns a label to these entities chosen from an inventory of possible labels	0	This task is closely related to both named entity recognition NER, which traditionally assigns nouns to a small number of categories and word sense disambiguation Agirre and 1http://classinrialpesfr/ <REF>Rigau, 1996</REF>; <TREF>Yarowsky, 1995</TREF>, where the sense for a word is chosen from a much larger inventory of word senses	0	We will employ a probabilistic model thats been used successfully in NER Conditional Random Fields and use this with an extensive inventory of word senses the WordNet lexical database to perform entity detection	0	In section 2 we describe WordNet and its use for entity categorization	0	0	0
P96-1006	P95-1026	1996	This strategy yields better results, as indicated by a better performance of LEXAS compared with the most frequent heuristic on this set of words	0	Most recently, Yarowsky used an unsupervised learning procedure to perform WSD <TREF>Yarowsky, 1995</TREF>, although this is only tested on disambiguating words into binary, coarse sense distinction	0	The effectiveness of unsupervised learning on disambiguating words into the refined sense distinction of WoRBNET needs to be further investigated	0	The work of <REF>McRoy, 1992</REF> pointed out that a diverse set of knowledge sources are important to achieve WSD, but no quantitative evaluation was given on the relative importance of each knowledge source	0	0	0
P07-1125	P95-1026	2007	Self-training is an alternative single-view algorithm in which a labelled pool is incrementally enlarged with unlabelled samples for which the learner is most confident	0	Early work by <TREF>Yarowsky 1995</TREF> falls within this framework	0	<REF>Banko and Brill 2001</REF> use bagging and agreement to measure confidence on unlabelled samples, and more recently McClosky et al	0	2006 use selftraining for improving parse reranking	0	0	0
P08-1088	P95-1026	2008	As we run EM, we gradually increase the number of edges to retain	0	In our context, bootstrapping has a similar motivation to the annealing approach of <REF>Smith and Eisner 2006</REF>, which also tries to alter the space of hidden outputs in the E-step over time to facilitate learning in the M-step, though of course the use of bootstrapping in general is quite widespread <TREF>Yarowsky, 1995</TREF>	0	4 Experimental Setup In section 5, we present developmental experiments in English-Spanish lexicon induction; experiments 6Empirically, we obtained much better efficiency and even increased accuracy by replacing these marginal likelihood weights with a simple proxy, the distances between the words mean latent concepts: wi,j  Azi zj2, 5 where A is a thresholding constant, zi  Ezi,j  fSsi  P1/2UlatticetopS fSsi, and zj is defined analogously	0	The increased accuracy may not be an accident: whether two words are translations is perhaps better characterized directly by how close their latent concepts are, whereas log-probability is more sensitive to perturbations in the source and target spaces	0	0	0
P02-1046	P95-1026	2002	Suppose the initial classifier correctly labels 100 out of 1000 instances, and makes no mistakes	0	Then the initial precision is 1<TREF>Yarowsky, 1995</TREF>, citing <REF>Yarowsky, 1994</REF>, actually uses a superficially different score that is, however, a monotone transform of precision, hence equivalent to precision, since it is used only for sorting	0	1 and recall is 01	0	Suppose further that we add an atomic rule that correctly labels 19 new instances, and incorrectly labels one new instance	0	0	0
P02-1046	P95-1026	2002	The plenitude of unlabeled natural language data, and the paucity of labeled data, have made bootstrapping a topic of interest in computational linguistics	0	Current work has been spurred by two papers, <TREF>Yarowsky, 1995</TREF> and <REF>Blum and Mitchell, 1998</REF>	0	Blum and Mitchell propose a conditional independence assumption to account for the efficacy of their algorithm, called co-training, and they give a proof based on that conditional independence assumption	0	They also give an intuitive explanation of why co-training works, in terms of maximizing agreement on unlabeled data between classifiers based on different views of the data	0	0	0
W97-0108	P95-1026	1997	,1994 and the DSO corpus of 192,800 sense-tagged occtuTences of 191 words used by <REF>Ng and Lee, 1996</REF> are still insucient in scale for supervised algorithms to perform well on a wide range of texts	0	Unsupervised algoritm such as <TREF>Yarowsky, 1995</TREF> have reported good accuracy that rivals that of supervised algorithms	0	However, the algorithm was only tested on coarse-level senses and not on the refined sense distinctioas of WordNet, which is the required sense granularity of our approach	0	We hence turn to dictionary-based approaches, focusing on WordNet-based algorithms Since they fit in snugly with our WordNet-based semantic class disambiguation task	0	0	0
W97-0108	P95-1026	1997	The main drawback of these approaches is their requirement of a sizable sense-tagged corpus	0	Attempts to alleviate this tagbottleneck ilude tmotstrias Te ot ill,, 1996; <REF>Hearst, 1991</REF> and unsupervised algorith Yarowsky, 199s Dictionary-based approaches rely on linguistic knowledge sources such as mali,e-readable dictionaries <REF>Luk, 1995</REF>; <REF>Veronis and Ide, 1990</REF> and WordNet <REF>Agirre and Rigau, 1996</REF>; <REF>Resnik, 1995</REF> and e0ploit these for word sense disaznbiguation	0	Thus far, two notable sense-tagged corpora, the semantic concordance of WordNet 15 Miller et aal	0	,1994 and the DSO corpus of 192,800 sense-tagged occtuTences of 191 words used by <REF>Ng and Lee, 1996</REF> are still insucient in scale for supervised algorithms to perform well on a wide range of texts	0	0	0
E06-2018	P95-1026	2006	The essence behind many algorithms for word sense disambiguation is to implicitly or explicitly classify all possible context words into groups relating to one or another sense	0	This can be done in a supervised <REF>Yarowsky, 1994</REF>, a semi-supervised <TREF>Yarowsky, 1995</TREF> or a fully unsupervised way <REF>Pantel  Lin, 2002</REF>	0	However, the classification can only work if the statistical clues are clear enough and if there are not too many exceptions	0	In terms of word co-occurrence statistics, we can say that within the local contexts of an ambiguous word, context words typical of the same sense should have high co-occurrence counts, whereas context words associated with different senses should have cooccurrence counts that are considerably lower	0	0	0
E06-2018	P95-1026	2006	In terms of word co-occurrence statistics, we can say that within the local contexts of an ambiguous word, context words typical of the same sense should have high co-occurrence counts, whereas context words associated with different senses should have cooccurrence counts that are considerably lower	0	Although the relative success of previous disambiguation systems eg <TREF>Yarowsky, 1995</TREF> suggests that this should be the case, the effect has usually not been quantified as the emphasis was on a task-based evaluation	0	Also, in most cases the amount of context to be used has not been systematically examined	0	2 Methodology Our starting point is a list of 288 ambiguous words homographs where each comes together with two associated words that are typical of one sense and a third associated word that is typical of another sense	0	0	0
W97-0808	P95-1026	1997	This approach has the advantage of simplicity and training data is only needed for the estimation of one parameter, the sense frequencies	0	The other approach selected was Yarowskys unsupervised algorithm 1995	0	This has the advantage that it does not require any manually tagged data	0	His approach relies on initial seed collocations to discriminate senses that can be observed in a portion of the data	0	0	0
W04-2808	P95-1026	2004	In general, following <REF>Ide and Veronis 1998</REF> the various WSD approaches of the past can be divided into two types, ie, dataand knowledge-based approaches	0	Data-based Methods Data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods <TREF>Yarowsky, 1995</TREF>; <REF>Stevenson, 2003</REF>	0	Supervised methods work with a given and therefore limited set of potential classes in the learning process	0	For example, <REF>Yarowsky 1992</REF> used a thesaurus to generate 1042 statistical models of the most general categories	0	0	0
W04-2808	P95-1026	2004	Historically, after work on WSD had overcome socalled early doubts <REF>Ide and Veronis, 1998</REF> in the 1960s, it was applied to various NLP tasks, such as machine translation, information retrieval, content and grammatical analysis and text processing	0	<TREF>Yarowsky 1995</TREF> used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis	0	However, there is no recorded work on processing speech recognition hypotheses resulting from speech utterances as it is done in our research	0	In general, following <REF>Ide and Veronis 1998</REF> the various WSD approaches of the past can be divided into two types, ie, dataand knowledge-based approaches	0	0	0
W04-2808	P95-1026	2004	In this exploration, we will focus on a subset of these tasks, namely: a2 hypotheses verification HV ie finding the best hypothesis out of a set of possible speech recognition hypotheses SRH; a2 sense disambiguation SD ie determining the best mapping of the lexically ambiguous linguistic forms contained therein to their sense-specific semantic representations; a2 relation tagging RT ie determining adequate semantic relations between the relevant sense-tagged entities	0	Many of these tasks have been addressed in other fields, for example, hypothesis verification in the field of machine translation <REF>Tran et al , 1996</REF>, sense disambiguation in speech synthesis <TREF>Yarowsky, 1995</TREF>, and relation tagging in information retrieval <REF>Marsh and Perzanowski, 1999</REF>	0	These challenges also apply for spoken dialogue systems and arise when they are scaled up towards multidomain and more conversational settings	0	In this paper we will address the utility of using ontologically modeled knowledge to assist in solving these tasks in spoken dialogue systems	0	0	0
W03-0417	P95-1026	2003	The amount of unlabeled data used in their experiments was relatively small from several hundreds to a few thousands	0	<TREF>Yarowsky 1995</TREF> presented an approach that significantly reduces the amount of labeled data needed for word sense disambiguation	0	Yarowsky achieved accuracies of more than 90 for two-sense polysemous words	0	This success was likely due to the use of one sense per discourse characteristic of polysemous words	0	0	0
W97-0208	P95-1026	1997	b Unsupervised training, where information is gathered from raw corpora which has not been semantically disambiguated	0	The best examples of this approach has been the resent work of Yarowsky <REF>Yarowsky, 1992</REF>, <REF>Yarowsky, 1993</REF>, <TREF>Yarowsky, 1995</TREF>	0	These approaches are not mutually exclusive and there are, of course, some hybrid cases, for example Luk <REF>Luk, 1995</REF> uses information in MRD definitions approach 1 and statistical information from untagged corpora approach 2b	0	3 Comparing Different Approaches Approach 2a is the least promising since text tagged with word senses is practically non-existent and is both time consuming and difficnlt to produce manually	0	0	0
P04-1062	P95-1026	2004	Unlabeled data remains a tantalizing potential resource for NLP researchers	0	Some tasks can thrive on a nearly pure diet of unlabeled data <TREF>Yarowsky, 1995</TREF>; <REF>Collins and Singer, 1999</REF>; <REF>Cucerzan and Yarowsky, 2003</REF>	0	But for other tasks, such as machine translation <REF>Brown et al , 1990</REF>, the chief merit of unlabeled data is simply that nothing else is available; unsupervised parameter estimation is notorious for achieving mediocre results	0	The standard starting point is the ExpectationMaximization EM algorithm <REF>Dempster et al , 1977</REF>	0	0	0
W00-1320	P95-1026	2000	Also, as mentioned earlier, we believe there are several features that would allow significant parsing improvement	0	Finally, we would like to investigate the incorporation of unsupervised methods for WSD, such as the heuristically-based methods of <REF>Stetina and Nagao, 1997</REF> and <REF>Stetina et al , 1998</REF>, and the theoretically purer bootstrapping method of <TREF>Yarowsky, 1995</TREF>	0	Bolstered by the success of <REF>Stetina and Nagao, 1997</REF>, <REF>Lin, 1997</REF> and especially <REF>Stetina et al , 1998</REF>, we believe there is great promise the incorporation of word-sense into a probabilistic parsing model	0	9 Acknowledgements I would like to greatly acknowledge the researchers at BBN who allowed me to use and abuse their parser and who fostered the beginning of this research effort: Scott Miller, Lance Ramshaw, Heidi Fox, Sean Boisen and Ralph Weischedeh Thanks to Michelle Engel, who helped enormously with the task of preparing the new data set	0	0	0
W00-1320	P95-1026	2000	<REF>Yarowsky, 1992</REF> uses wide bag-of-words contexts with a naive Bayes classifier	0	<TREF>Yarowsky, 1995</TREF> also uses wide context, but incorporates the one-senseper-discourse and one-sense-per-collocation constraints, using an unsupervised learning technique	0	The supervised technique in <REF>Yarowsky, 1994</REF> has a more specific notion of context, employing not just words that can appear within a window of Ik, but crucially words that abut and fall in the 2 window of the target word	0	More recently, <REF>Lin, 1997</REF> has shown how syntactic context, and dependency structures in particular, can be successfully employed for word sense disambiguation	0	0	0
D08-1108	P95-1026	2008	However, such a list may be quite noisy, ie, many of them are not informal phrases at all	0	An alternative approach to extracting the informal phrases is to use a bootstrapping algorithm eg, <TREF>Yarowsky 1995</TREF>	1	Specifically, we first manually collect a small set of example relations	0	Then, using these relations as a seed set, we extract the text patterns eg, the definition pattern showing how the informal and formal phrases co-occur in the data as discussed in Section 31	0	6	1
C02-1088	P95-1026	2002	One sense per discourse means that the sense of a target word is highly consistent within any given document	0	<TREF>David Yarowsky 1995</TREF> showed it was accurate in the word sense disambiguation	0	We label the examples that are not labeled yet as the category of the labeled word in the discourse as following example and we output named entity tagged corpus	0	Example after the ensemble learning   KIA<typeorganization> reul ji-won-han-da	0	0	0
P07-1109	P95-1026	2007	The transducer approach, however, requires a large set of training examples, which is a limitation not present in the fuzzy matching algorithm	0	Thus, we propose a bootstrapping approach <TREF>Yarowsky, 1995</TREF> to train the stochastic transducer iteratively as it extracts transliterations from a bitext	0	The bootstrapped stochastic transducer is completely language-independent, and we show that it is able to perform at least as well as the Arabic-English specific fuzzy matching algorithm	0	The remainder of this paper is organized as follows	0	0	0
P07-1109	P95-1026	2007	In other words, it would require a relatively large set of known transliterations for training, and this is exactly what we would like the model to acquire	0	In order to overcome this problem, we look to the bootstrapping method outlined in <TREF>Yarowsky, 1995</TREF>	0	Yarowsky trains a rule-based classifier for word sense disambiguation by starting with a small set of seed examples for which the sense is known	0	The trained classifier is then used to label examples for which the sense is unknown, and these newly labeled examples are then used to retrain the classifier	0	0	0
W01-1208	P95-1026	2001	3 <DT> and <DD> are inherently provided to describe terms in HTML	0	Since word senses are often associated with domains <TREF>Yarowsky, 1995</TREF>, word senses can be consequently distinguished by way of determining the domain of each description	0	For example, different senses for pipeline processing method/transportation pipe are associated with computer and construction domains fields, respectively	0	To sum up, the organization module classifies term descriptions based on domains, for which we use domain and description models	0	0	0
P01-1008	P95-1026	2001	Identical words play two roles in this process: first, they are used to learn context rules; second, identical words are used in application of these rules, because the rules contain information about the equality of words in context	0	This method of co-training has been previously applied to a variety of natural language tasks, such as word sense disambiguation <TREF>Yarowsky, 1995</TREF>, lexicon construction for information extraction <REF>Riloff and Jones, 1999</REF>, and named entity classification <REF>Collins and Singer, 1999</REF>	0	In our case, the co-training process creates a binary classifier, which predicts whether a given pair of phrases makes a paraphrase or not	0	Our model is based on the DLCoTrain algorithm proposed by <REF>Collins and Singer, 1999</REF>, which applies a co-training procedure to decision list classifiers for two independent sets of features	0	0	0
J98-1003	P95-1026	1998	Lacking an automatic method, recent WSD works <REF>Bruce and Wiebe 1995</REF>; <REF>Luk 1995</REF>; <TREF>Yarowsky 1995</TREF> still resort to human intervention to identify and group closely related senses in an MRD	0	Using thesaurus categories directly as a coarse sense division may seem to be a viable alternative <TREF>Yarowsky 1995</TREF>	0	However, typical thesauri, such as Rogets <REF>Thesaurus 1987</REF>, suffer sense gaps and, occasionally, are too fine-grained	0	<REF>Yarowsky 1992</REF> reports that there are uses not listed in Rogets for 3 of 12 nouns in his WSD study, while uses which a native speaker might consider as a single sense are often encoded in several Rogets categories	0	0	0
J98-1003	P95-1026	1998	Therefore, the TopSense algorithm is quite general and is expected to produce comparable results for other MRDs and thesauri	0	TopSense is tested on 20 words extensively investigated in recent WSD literature Schitze 1992; <REF>Yarowsky 1992</REF>; <REF>Luk 1995</REF>	0	According to the experimental results, the automatically derived topical clusters can be used to good effect without any human intervention as a coarse sense division for WSD	0	The rest of the paper is organized as follows	0	0	0
J98-1003	P95-1026	1998	E-mail: dr818314csnthuedutw; jschangcsnthuedutw	0	 1998 Association for Computational Linguistics Computational Linguistics Volume 24, Number 1 1995, 3 thesaurus categories <REF>Yarowsky 1992</REF>; <REF>Chen and Chang 1994</REF>, 4 translation in another language Gale, Church, and <REF>Yarowsky 1992</REF>; <REF>Dagan, Itai, and Schwall 1991</REF>; <REF>Dagan and Itai 1994</REF>, 5 automatically induced clusters with sublexical representation <REF>Schiitze 1992</REF>, and 6 hand-crafted lexicons <REF>McRoy 1992</REF>	0	This paper is motivated by the observation that directly using dictionary senses for sense division offers several advantages	0	Sense distinction according to a dictionary is readily available from machine-readable dictionaries MRDs such as the Longman Dictionary of Contemporary English LDOCE <REF>Proctor 1978</REF>	0	0	0
J98-1003	P95-1026	1998	cient for representing the distinction we would want to make for the task of WSD	0	Rogets has been used as the sense division in two recent WSD works <REF>Yarowsky 1992</REF>; <REF>Luk 1995</REF> more or less as is, except for a small number of senses added to fill gaps	0	We contend that a sense division based on the LLOCE topics will offer more or less the same kind of granularity, suitable for WSD	0	For instance, in <REF>Yarowsky 1992</REF>, the senses of star are divided into three Rogets categories, which roughly correspond to five LDOCE star senses labeled with LLOCE topics	0	0	0
J98-1003	P95-1026	1998	Word sense disambiguation WSD has been found useful in many natural language processing NLP applications, including information retrieval <REF>Krovetz and Croft 1992</REF>; <REF>McRoy 1992</REF>, machine translation <REF>Brown et al 1991</REF>; <REF>Dagan, Itai, and Schwall 1991</REF>; <REF>Dagan and Itai 1994</REF>, and speech synthesis <REF>Yarowsky 1992</REF>	0	WSD has received increasing attention in recent literature on computational linguistics <REF>Lesk 1986</REF>; Schiitze 1992; <REF>Gale, Church, and Yarowsky 1992</REF>; <REF>Yarowsky 1992, 1995</REF>; <REF>Bruce and Wiebe 1995</REF>; <REF>Luk 1995</REF>; <REF>Ng and Lee 1996</REF>; <REF>Chang et al 1996</REF>	0	Given a polysemous word in running text, the task of WSD involves examining contextual information to determine the intended sense from a set of predetermined candidates	0	It is a nontrivial task to divide the senses of a word and determine this set, for word sense is an abstract concept frequently based on subjective and subtle distinctions in topic, register, dialect, collocation, part of speech, and valency <REF>McRoy 1992</REF>	0	0	0
J98-1003	P95-1026	1998	Regrettably, the proposed algorithm was only described in a few examples and was not developed further	0	Lacking an automatic method, recent WSD works <REF>Bruce and Wiebe 1995</REF>; <REF>Luk 1995</REF>; <TREF>Yarowsky 1995</TREF> still resort to human intervention to identify and group closely related senses in an MRD	0	Using thesaurus categories directly as a coarse sense division may seem to be a viable alternative <TREF>Yarowsky 1995</TREF>	0	However, typical thesauri, such as Rogets <REF>Thesaurus 1987</REF>, suffer sense gaps and, occasionally, are too fine-grained	0	0	0
P98-1069	P95-1026	1998	9 Related work Using vector space model and similarity measures for ranking is a common approach in IR for query/text and text/text comparisons <REF>Salton and Buckley, 1988</REF>; <REF>Salton and Yang, 1973</REF>; <REF>Croft, 1984</REF>; <REF>Turtle and Croft, 1992</REF>; <REF>Bookstein, 1983</REF>; <REF>Korfhage, 1995</REF>; <REF>Jones, 1979</REF>	0	This approach has also been used by <REF>Dagan and Itai, 1994</REF>; <REF>Gale et al , 1992</REF>; <REF>Shiitze, 1992</REF>; <REF>Gale et al , 1993</REF>; <TREF>Yarowsky, 1995</TREF>; Gale and Church, 1Lunar is not an unknown word in English, Yeltsin finds its translation in the 4-th candidate	0	Table 5: tion out score 0008421 0007895 0007669 0007588 0007283 0006812 0006430 0006218 0005921 0005527 0005335 0005335 0005221 0004731 0004470 0004275 0003878 0003859 0003859 0003784 0003686 0003550 0003519 0003481 0003407 0003407 0003338 0003324 Some Chinese ut English Teng-hui SAR flu Lei poultry SAR hijack poultry Tung Diaoyu PrimeMinister President China Lien poultry China flu PrimeMinister President poultry Kalkanov poultry SAR Zhuhai PrimeMinister President flu apologise unknown word translaChinese  Weng-hui  u Lei j Poultry  Chee-hwa  Teng-hui  SAR  Chee-hwa : Teng-hui  Weng-hui W Weng-hui CLam  Teng-hui - Chee-hwa  Teng-hui Lei  Chee-hwa  Chee-hwa  Leung  Zhuhai I Lei J Yeltsin - Chee-hwa  Lam Lam j Poultry W Teng-hui 0003250 DPP 0003206 Tang 0003202 Tung 0003040 Leung 0003033 China 0002888 Zhuhai 0002886 Tung  Teng-hui Tang Leung Leung  SAR  Lunar Tung 1994 for sense disambiguation between multiple usages of the same word	0	Some of the early statistical terminology translation methods are <REF>Brown et al , 1993</REF>; <REF>Wu and Xia, 1994</REF>; <REF>Dagan and Church, 1994</REF>; <REF>Gale and Church, 1991</REF>; <REF>Kupiec, 1993</REF>; <REF>Smadja et al , 1996</REF>; Kay and R<REF>Sscheisen, 1993</REF>; <REF>Fung and Church, 1994</REF>; <REF>Fung, 1995b</REF>	0	0	0
W02-1304	P95-1026	2002	1998 and <REF>Mihalcea and Moldovan 1999</REF> automatically generate arbitrarily large corpora for unsupervised WSD training, using the synonyms or definitions of word senses provided in WordNet to formulate search engine queries over the Web	0	In another line of research, <TREF>Yarowsky, 1995</TREF> and <REF>Blum and Mitchell, 1998</REF> have shown that it is possible to reduce the need for supervision with the help of large amounts of unannotated data	0	Applying these ideas, <REF>Agirre and Martnez, 2000</REF> has developed knowledge-based prototypes for obtaining accurate examples from the web for specific WordNet synsets, as well as, large quantities of unannotated examples	0	But in order to make significant advances in WSD system accuracy, systems need to be able to use types of lexical knowledge that are not currently available in wide-coverage lexical knowledge bases: for example subcategorisation frequencies for predicates particularly verbs rely on word senses, selectional preferences of predicates for classes of arguments, amongst others <REF>Carroll and McCarthy, 2000</REF>; <REF>McCarthy et al , 2001</REF>; <REF>Agirre and Martnez, 2002</REF>;	0	0	0
W99-0908	P95-1026	1999	Here, their mutual bootstrap algorithm works by iteratively identifying syntactic constructs indicative of known locations, and identifying new locations using these indicative constructs	0	The preliminary labeling by keyword matching used in this paper is similar to the seed collocations used by <TREF>Yarowsky 1995</TREF>	0	There, in a word sense disambiguation task, a bootstrapping algorithm is seeded with some examples of common collocations with the particular sense of some word eg the seed life for the biological sense of plant	0	5 Experimental Results In this section, we provide empirical evidence that bootstrapping a text classifier from unlabeled data can produce a high-accuracy text classifier	0	0	0
A00-3006	P95-1026	2000	<REF>Golding and Roth 1999</REF>, Mays et al	0	1991, <TREF>Yarowsky 1995</TREF>	0	The approach I am pursuing is an application of Bayesian statistics	0	We treat the process by which the electronic text was produced as a noisy channel, and take as our goal the maximization of the probability of each input word, given a string which is the 30 Figure 1: Example text from the Encyclopddie	0	0	0
J04-1001	P95-1026	2004	For each class t, we store the selected top b classified instances in Q t  Lines 1617 show that we create the classified instances by combining the instances with their classification labels	0	After line 17, we can employ the one-sense-per-discourse heuristic to further classify unclassified data, as proposed in <TREF>Yarowsky 1995</TREF>	0	This heuristic is based on the observation that when an ambiguous word appears in the same text several times, its tokens usually refer to the same sense	0	In the bootstrapping process, for each newly classified instance, we automatically assign its class label to those unclassified instances that also contain the same ambiguous word and co-occur with it in the same text	0	0	0
J04-1001	P95-1026	2004	For example, for the sense of money paid for the use of money, we selected the word rate	0	We viewed the seed word as a classified sentence, following a similar proposal in <TREF>Yarowsky 1995</TREF>	0	In this way, for each sense we had a classified instance in English	0	As unclassified data in English, we collected sentences in news articles from a Web site wwwnewscom, and as unclassified data in Chinese, we collected sentences in news articles from another Web site newscntomcom	0	0	0
J04-1001	P95-1026	2004	G40G81G74G79G76G86G75G3G90G82G85G71G86 G38G75G76G81G72G86G72G3G90G82G85G71G86G3 G54G72G81G86G72G86G3 G54G72G72G71G3G90G82G85G71G86G3 G3 G85G72G68G71G76G81G72G86G86G3G87G82G3G74G76G89G72G3G68G87G87G72G81G87G76G82G81G3 G86G75G82G90G3 G3 G80G82G81G72G92G3G83G68G76G71G3G73G82G85G3G87G75G72G3G88G86G72G3G82G73G3G80G82G81G72G92G3 G85G68G87G72G3 G15G3 G3 G68G3G86G75G68G85G72G3G76G81G3G70G82G80G83G68G81G92G3G82G85G3G69G88G86G76G81G72G86G86G3 G75G82G79G71G3 G76G81G87G72G85G72G86G87G3 G3 G68G71G89G68G81G87G68G74G72G15G3G68G71G89G68G81G70G72G80G72G81G87G3G82G85G3G73G68G89G82G85G3 G70G82G81G73G79G76G70G87G3 G15G3 G3 G68G3G87G75G76G81G3G73G79G72G91G76G69G79G72G3G82G69G77G72G70G87G3 G70G88G87G3 G15G3 G3 G90G85G76G87G87G72G81G3G82G85G3G86G83G82G78G72G81G3G87G72G91G87G3 G90G85G76G87G72G3 G3 G87G72G79G72G83G75G82G81G72G3G70G82G81G81G72G70G87G76G82G81G3 G87G72G79G72G83G75G82G81G72G3 G15G3 G3 G73G82G85G80G68G87G76G82G81G3G82G73G3G83G72G82G83G79G72G3G82G85G3G87G75G76G81G74G86G3 G90G68G76G87G3 G15G3 G3 G68G81G3G68G85G87G76G73G76G70G76G68G79G3G71G76G89G76G86G76G82G81G3 G69G72G87G90G72G72G81G3 G79G76G81G72G3 G15G3 G3 G83G85G82G71G88G70G87G3 G83G85G82G71G88G70G87G3 is, it employs a decision list as the classifier	0	This implementation is exactly the one proposed in <TREF>Yarowsky 1995</TREF>	0	We will denote it as MB-D hereafter	0	MB-B and MB-D can be viewed as the state-of-the-art methods for word translation disambiguation using bootstrapping	0	0	0
J04-1001	P95-1026	2004	To perform the task, we could employ a supervised learning method, but since to do so would require human labeling of data, which would be expensive, bootstrapping would be a better choice	0	<TREF>Yarowsky 1995</TREF> has proposed a bootstrapping method for word sense disambiguation	0	When applied to translation from English to Chinese, his method starts learning with a small number of English sentences that contain ambiguous English words and that are labeled with correct Chinese translations of those words	0	It then uses these classified sentences as training data to create a classifier eg , a decision list, which it uses to classify unclassified sentences containing the same ambiguous words	0	0	0
J04-1001	P95-1026	2004	From the results, we see again that BB significantly outperforms MB-D and MB-B	0	Note that the results of MB-D here cannot be directly compared with those in <TREF>Yarowsky 1995</TREF>, because the data used are different	0	Naive Bayesian ensemble did not perform well on the word duty, causing the accuracies of both MB-B and BB to deteriorate	0	7 http://encartamsncom/defaultasp	0	0	0
J04-1001	P95-1026	2004	Although BB is a method nearly equivalent to one based on unsupervised learning, it still performs favorably when compared with the supervised methods note that since the experimental settings are different, the results cannot be directly compared	0	44 Experiment 2: Yarowskys Words We also conducted translation on seven of the twelve English words studied in <TREF>Yarowsky 1995</TREF>	0	Table 5 lists the words we used	0	Table 3 Accuracies of disambiguation in Experiment 1	0	0	0
J04-1001	P95-1026	2004	24 Monolingual Bootstrapping Since data preparation for supervised learning is expensive, it is desirable to develop bootstrapping methods	0	<TREF>Yarowsky 1995</TREF> proposed such a method for word sense disambiguation, which we refer to as monolingual bootstrapping	0	4 Here u  v denotes that u is a sub-sequence of v 5 Li and Li Word Translation Disambiguation Using Bilingual Bootstrapping Let L  denote a set of classified instances labeled data in English, each representing one context of : L   e ,1, t ,1 ,e ,2, t ,2 ,,e ,k, t ,k  t ,i  T  i  1, 2,, k and U  a set of unclassified instances unlabeled data in English, each representing one context of : U   e ,1, e ,2,, e ,l  The instances in Figure 1 can be considered examples of L   Furthermore, we have L E  uniondisplay E L , U E  uniondisplay E U , T  uniondisplay E T , An algorithm for monolingual bootstrapping is presented in Figure 2	0	For a better comparison with bilingual bootstrapping, we have extended the method so that it Input: E, T, L E, U E, Parameter: b, Repeat the following processes until unable to continue 1	0	0	0
C02-1127	P95-1026	2002	Knowledge-based work, such as <REF>Hirst, 1987</REF>; <REF>McRoy, 1992</REF>; <REF>Ng and Lee, 1996</REF> used hand-coded rules or supervised machine learning based on annotated corpus to perform WSD	0	Recent work emphasizes corpus-based unsupervised approach <REF>Dagon and Itai, 1994</REF>; <REF>Yarowsky, 1992</REF>; <TREF>Yarowsky, 1995</TREF> that avoids the need for costly truthed training data	0	Location normalization is different from general WSD in that the selection restriction often used for WSD in many cases is not sufficient to distinguish the correct sense from the other candidates	0	For example, in the sentence The White House is located in Washington, the selection restriction from the collocation located in can only determine that Washington should be a location name, but is not sufficient to decide the actual sense of this location	0	0	0
P99-1020	P95-1026	1999	Other methods that were reported in the lit156 erature disambiguate either one part of speech word ie nouns, or in the case of purely statistical methods focus on very limited number of words	0	Some of the best results were reported in <TREF>Yarowsky, 1995</TREF> who uses a large training corpus	0	For the noun drug Yarowsky obtains 914 correct performance and when considering the restriction one sense per discourse the accuracy increases to 939, result represented in the third column in Table 4	0	6 Extensions 61 Noun-noun and verb-verb pairs The method presented here can be applied in a similar way to determine the conceptual density within noun-noun pairs, or verb-verb pairs in these cases, the NEAR operator should be used for the first step of this algorithm	0	0	0
P99-1020	P95-1026	1999	WSD that use information gathered from training on a corpus that has already been semantically disambiguated supervised training methods <REF>Gale et al , 1992</REF>, <REF>Ng and Lee, 1996</REF>; 3	0	WSD that use information gathered from raw corpora unsupervised training methods <TREF>Yarowsky, 1995</TREF> <REF>Resnik, 1997</REF>	0	There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others <REF>McRoy, 1992</REF> <REF>Bruce and Wiebe, 1994</REF> <REF>Ng and Lee, 1996</REF> <REF>Rigau et al , 1997</REF>	0	Statistical methods produce high accuracy results for small number of preselected words	0	0	0
W97-0201	P95-1026	1997	3 The Effect of Training Corpus Size A number of past research work on WSD, such as <REF>Leacock et al , 1993</REF>; <REF>Bruce and Wiebe, 1994</REF>; <REF>Mooney, 1996</REF>, were tested on a small number of words like line and interest	0	Similarly, <TREF>Yarowsky, 1995</TREF> tested his WSD algorithm on a dozen words	0	The sense-tagged corpus SEMCOI, prepared by <REF>Miller et al , 1994</REF>, contains a substantial subset of the Brown corpus tagged with the refined senses of WORDNET	0	However, as reported in <REF>Miller et al , 1994</REF>, there are not enough training examples per word in SPMCOR to yield a broad coverage, high accuracy WSD program, due to the fact that sense tagging is done on every word in a running text in SEMCOR	0	0	0
W97-0201	P95-1026	1997	However, if one were to resolve word sense to the level of homograph, or coarse sense distinction, then quite high accuracy can be achieved in excess of 90, as reported in <REF>Wilks and Stevenson, 1996</REF>	0	Similarly, if the task is to distinguish between binary, coarse sense distinction, then current WSD techniques can achieve very high accuracy in excess of 96 when tested on a dozen words in <TREF>Yarowsky, 1995</TREF>	0	This is to be expected, since homograph contexts are quite distinct and hence it is a much simpler task to disambiguate among a small number of coarse sense classes	0	This is in contrast to disambiguating word senses to the refined senses of WoRDNET, where for instance, the average number of senses per noun is 78 and the average number of senses per verb is 120 for the set of 191 most ambiguous words investigated in <REF>Ng and Lee, 1996</REF>	0	0	0
D07-1070	P95-1026	2007	the projective case, crossings	0	Our observation is that this situation is ideal for so-called bootstrapping, co-training, or minimally supervised learning methods <TREF>Yarowsky, 1995</TREF>; <REF>Blum and Mitchell, 1998</REF>; <REF>Yarowsky and Wicentowski, 2000</REF>	0	Such methods should thrive when the right answer is overdetermined owing to redundant features and/or global constraints	0	Concretely, suppose we start by training a supervised parser on only 100 examples, using some regularization method to prevent overfitting to this set	0	0	0
D07-1070	P95-1026	2007	Different bootstrapping procedures use different learners, smoothing methods, confidence measures, and procedures for forgetting the labelings from previous iterations	0	In his analysis of <TREF>Yarowsky 1995</TREF>, <REF>Abney 2004</REF> formulates several variants of bootstrapping	0	These are shown to increase either the likelihood of the training data, or a lower bound on that likelihood	0	In particular, Abney defines a function K that is an upper bound on the negative log-likelihood, and shows his bootstrapping algorithms locally minimize K We now present a generalization of Abneys K function and relate it to another semi-supervised learning technique, entropy regularization <REF>Brand, 1999</REF>; <REF>Grandvalet and Bengio, 2005</REF>; <REF>Jiao et al , 2006</REF>	0	0	0
D07-1070	P95-1026	2007	Recall that we did not use the tree annotations to perform feature selection; models trained withonlysupportedfeaturesoughttoperformbetter	0	Although we see statistically significant improvements at the 05 level on a paired permutation test, the quality of the parsers is still quite poor, in contrast to other applications of bootstrapping which rival supervised methods <TREF>Yarowsky, 1995</TREF>	0	Almost certainly, the CoNLL datasets, comprising at most some tens of thousands of sentences per language, are too small to afford qualitative improvements	0	Also, at these relatively small training sizes, ourpreliminaryattemptstoleveragecomparableEnglish corpora did not improve performance	0	0	0
J98-1004	P95-1026	1998	Could one of the other differences be responsible for the difference in performance	0	The fact that the error rate more than doubles when the seeds in Yarowskys 1995 experiments are reduced from a senses best collocations to just one word per sense suggests that the error rate would increase further if no seeds were provided	0	113 Computational Linguistics Volume 24, Number 1 42 Application to Information Retrieval Our principal motivation for concentrating on the discrimination subtask is to apply disambiguation to information retrieval	0	While there is evidence that ambiguity resolution improves the performance of IR systems <REF>Krovetz and Croft 1992</REF>, several researchers have failed to achieve consistent experimental improvements for practically realistic rates of disambiguation accuracy	0	0	0
J98-1004	P95-1026	1998	For example, in many of the methods using hand-labeled training sets eg , Hearst 1991, a relatively small number of training examples is sufficient	0	Yarowsky has proposed an algorithm that requires as little user input as one seed word per sense to start the training process <TREF>Yarowsky 1995</TREF>	0	Such minimal user input will be a negligible burden for users in some situations	0	However, consider the interactive information-access application described above	0	0	0
W03-1015	P95-1026	2003	3 This justifies the use of a decision list as a potential classifier for bootstrapping	0	<REF>See Yarowsky 1995</REF> for details	0	41 The Multi-View Co-Training Algorithm The intuition behind the BM co-training algorithm is to train two classifiers that can help augment each others labeled data by exploiting two separate but redundant views of the data	0	Specifically, each classifier is trained using one view of the labeled data and predicts labels for all instances in the data pool, which consists of a randomly chosen subset of the unlabeled data	0	0	0
W03-1702	P95-1026	2003	The method is applicable not only to nouns but also to adjectives and verbs, since it does not rely on topical context, which is effective only for nouns as pointed out by <REF>Towell and Voorhees 1998</REF>	0	The approach is very general and modular and can work in conjunction with a number of learning strategies for word sense disambiguation <TREF>Yarowsky, 1995</TREF>; <REF>Li and Li, 2002</REF>	0	6	0	Conclusion In this paper, we present the Mutual Assured Resolution of Sense MARS Algorithm for assigning relevant senses to word classes in a given sense inventory ie LDOCE or WordNet	0	0	0
W03-1702	P95-1026	2003	As noted in <REF>Merialdo 1994</REF>, even minimal hand tagging improved on the results of unsupervised methods	0	<TREF>Yarowsky 1995</TREF> showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods	0	<REF>Li and Li 2002</REF> extended the approach by using corpora in two languages to bootstrap the learning process	0	They showed bilingual bootstrapping is even more effective	0	0	0
W97-0321	P95-1026	1997	Exemplar-based method makes use of typical contexts exemplars of a word sense, eg, verbnoun collocations or adjective-noun collocations, and identifies the correct sense of a word in a particular context by comparing the context with the exemplars <REF>Ng and Lee, 1996</REF>	0	Recently, some kinds of learning techniques have been applied to cumulatively acquire exemplars form large corpora <REF>Yarowsky, 1994, 1995</REF>	0	But ideal resources from which to learn exemplars are not generally available for any languages	0	Moreover, the effectiveness of this method on disambiguating words in large-scale corpora into fine-grained sense distinctions needs to be further investigated <REF>Ng and Lee, 1996</REF>	0	0	0
W97-0321	P95-1026	1997	1	0	Word sense disambiguation has long been one of the major concerns in natural language processing area eg , <REF>Bruce et al , 1994</REF>; <REF>Choueka et al , 1985</REF>; <REF>Gale et al , 1993</REF>; <REF>McRoy, 1992</REF>; <REF>Yarowsky 1992, 1994, 1995</REF>, whose aim is to identify the correct sense of a word in a particular context, among all of its senses defined in a dictionary or a thesaurus	0	Undoubtedly, effective disambiguation techniques are of great use in many natural language processing tasks, eg, machine translation and information retrieving <REF>Allen, 1995</REF>; <REF>Ng and Lee, 1996</REF>; <REF>Resnik, 1995</REF>, etc Previous strategies for word sense disambiguation mainly fall into two categories: statistics-based method and exemplar-based method	0	Statistics-based method often requires large-scale corpora eg , <REF>Hirst, 1987</REF>; <REF>Luk, 1995</REF>, sense-tagging or not, monolingual or aligned bilingual, as training data to specify significant clues for each word sense	0	0	0
N03-2025	P95-1026	2003	These heuristics are found to be very helpful in both increasing positive instances ie tag propagation and decreasing the spurious instances ie tag elimination	0	The tag propagation/elimination scheme is adopted from <TREF>Yarowsky 1995</TREF>	0	After this step, a total of 367,441 proper names are classified, including 134,722 PER names, 186,488 LOC names, and 46,231 ORG names	0	The classified proper name instances lead to the construction of an automatically tagged training corpus, consisting of the NE instances and their two left and right neighboring words within the same sentence	0	0	0
W06-2207	P95-1026	2006	Moreover, we focus on robust bootstrapping algorithms that can handle real-world document collections, which contain many domains	0	Although a rich literature covers bootstrapping methods applied to natural language problems <TREF>Yarowsky, 1995</TREF>; <REF>Riloff, 1996</REF>; <REF>Collins and Singer, 1999</REF>; <REF>Yangarber et al , 2000</REF>; <REF>Yangarber, 2003</REF>; <REF>Abney, 2004</REF> several questions remain unanswered when these methods are applied to syntactic or semantic pattern acquisition	0	In this paper we answer two of these questions: 1 Can pattern acquisition be improved with text categorization techniques	0	Bootstrapping-based pattern acquisition algorithms can also be regarded as incremental text categorization TC, since in each iteration documents containing certain patterns are assigned the corresponding category label	0	0	0
W06-2207	P95-1026	2006	The label of each collection document is given bythestrengthofitspatterns	0	Similarlyto<REF>Collins and Singer, 1999</REF>; <TREF>Yarowsky, 1995</TREF>, we define the strength of a pattern p in a category y as the precision of p in the set of documents labeled with category y, estimated using Laplace smoothing: strengthp,y  countp,y  epsilon1countp  kepsilon1 3 where countp,y is the number of documents labeled y containing pattern p, countp is the overall number of labeled documents containing p, and k is the number of domains	0	For all experiments presented here we used epsilon1  1	0	Another point where acquisition algorithms differistheinitializationprocedure: somestartwitha small number of hand-labeled documents <REF>Riloff, 1996</REF>, as illustrated in Figure 2, while others start with a set of seed rules <REF>Yangarber et al , 2000</REF>; <REF>Yangarber, 2003</REF>	0	0	0
W06-2207	P95-1026	2006	Whilemostbootstrapping-basedalgorithmsfollow the same framework, they vary significantly in what they consider the most relevant patterns in each bootstrapping iteration	0	Several approaches have been proposed in the context of word sense disambiguation <TREF>Yarowsky, 1995</TREF>, named entity NE classification <REF>Collins and Singer, 1999</REF>, patternacquisitionforIERiloff,1996; <REF>Yangarber, 2003</REF>, or dimensionality reduction for text categorization TC <REF>Yang and Pedersen, 1997</REF>	0	However, it is not clear which selection approach is the best for the acquisition of syntactico-semantic patterns	0	To answer this question, we have implemented a modular pattern acquisition architecture where several of these ranking strategies are implemented and evaluated	0	0	0
A97-2010	P95-1026	1997	A97-2010:122	0	A Broad-Coverage Word Sense Tagger Dekang Lin Department of Computer Science University of Manitoba Winnipeg, Manitoba, Canada R3T 2N2 lindekcsumanitobaca Previous corpus-based Word Sense Disambiguation WSD algorithms <REF>Hearst, 1991</REF>; <REF>Bruce and Wiebe, 1994</REF>; <REF>Leacock et al , 1996</REF>; <REF>Ng and Lee, 1996</REF>; <REF>Yarowsky, 1992</REF>; <TREF>Yarowsky, 1995</TREF> determine the meanings of polysemous words by exploiting their local contexts	0	A basic intuition that underlies those algorithms is the following: 1 Two occurrences of the same word have identical meanings if they have similar local contexts	0	In other words, previous corpus-based WSD algorithms learn to disambiguate a polysemous word from previous usages of the same word	0	0	0
J98-1001	P95-1026	1998	However, despite the obvious appeal of this approach, it runs up against the same problem of the lack of an established, agreed-upon hierarchy of senses	0	Aware of this problem, Resnik and Yarowsky suggest creating the sense distance matrix based on results in experimental psychology such as <REF>Miller and Charles 1991</REF> or <REF>Resnik 1995b</REF>	0	Even ignoring the cost of creating such a matrix, the psycholinguistic literature has made clear that these results are highly influenced by experimental conditions and the task imposed on the subjects see, for example, Tabossi 1989, 1991, Rayner and Morris 1991; in addition, it is not clear that psycholinguistic data can be of help in WSD aimed toward practical use in NLP systems	0	In general, WSD evaluation confronts difficulties of criteria that are similar to, but orders of magnitude greater than, those facing other tasks such as part-of-speech tagging, due to the elusive nature of semantic distinctions	0	0	0
J98-1001	P95-1026	1998	Brown et al	0	1992, <REF>Pereira and Tishby 1992</REF>, and <REF>Pereira, Tishby, and Lee 1993</REF> propose methods that derive classes from the distributional properties of the corpus itself, while other authors use external information sources to define classes: <REF>Resnik 1992</REF> uses the taxonomy of WordNet; <REF>Yarowsky 1992</REF> uses the categories of Rogets <REF>Thesaurus, Slator 1992</REF> and <REF>Liddy and Paik 1993</REF> use the subject codes in the LDOCE; <REF>Luk 1995</REF> uses conceptual sets built from the LDOCE definitions	0	Class-based methods answer in part the problem of data sparseness and eliminate the need for pretagged 15 For example, in a window of five words to each side of the word ash in the Brown corpus, commonly associated words such asfire, cigar, volcano, etc , do not appear	0	The words cigarette and tobacco co-occur with ash only once, with the same frequency as words such as room, bubble, and house	0	0	0
H05-1050	P95-1026	2005	Even in the fully unsupervised case, it may be possible to prove that if the data were generated from a particular kind of process eg , a Gaussian mixture, then a certain strapping algorithm can recover the hidden variables	0	6 Conclusions In this paper, we showed that it is sometimes possible indeed, preferableto eliminate the initial bit of supervision in bootstrapping algorithms such as the <TREF>Yarowsky 1995</TREF> algorithm for word sense disambiguation	0	Our strapping approach tries many candidate seeds as starting points and evaluates them automatically	0	The evaluation function can be tuned if desired on other task instances, perhaps artificially constructed ones	0	0	0
H05-1050	P95-1026	2005	We discuss such strapping methods in general, and exhibit a particular method for strapping wordsense classifiers for ambiguous words	0	Our experiments on the Canadian Hansards show that our unsupervised technique is significantly more effective than picking seeds by hand <TREF>Yarowsky, 1995</TREF>, which in turn is known to rival supervised methods	0	Some of NLPs most interesting problems have to do with unsupervised learning	0	Human language learners are able to discover word senses, grammatical genders, morphological systems, grammars, discourse registers, and so forth	0	0	0
H05-1050	P95-1026	2005	1992b identified six such words in the Canadian Hansards, a parallel sentence-aligned corpus of parliamentary debate in English and French: drug, duty, land, language, position, sentence	0	We extracted all examples of each word from the 14-million-word English portion of the Hansards8 Note that this is considerably smaller than <TREF>Yarowskys 1995</TREF> corpus of 460 million words, so bootstrapping will not perform as well, and may be more sensitive to the choice of seed	0	Because we are doing unsupervised learning, we both trained and tested these 6 words on the English Hansards	0	We used the French portion of the Hansards only to create a gold standard for evaluating our results9 If an English sentence containing drug is paired with a French sentence that contains exactly one of medicament or drogue, we take that as an infallible indicator of its sense	0	0	0
H05-1050	P95-1026	2005	46 Development Data for tuning hs Before turning to the unsupervised Hansards, we tuned our fertility estimator hs to identify good seeds on development dataie , on other, supervised task instances	0	In the supervised condition, we used just 2 additional task instances, plant and tank, each with 4000 handannotated instances drawn from a large balanced corpus <TREF>Yarowsky, 1995</TREF>	0	In the pseudo-supervised condition, we used no handannotated data, instead constructing 10 artificial supervised task instances section 34 from the English portion of the Hansards	0	To facilitate cross-instance learning, we tried to construct these pseudowords to behave something like our ambiguous test words12 Given a test word t, we randomly selected a seed x,y from its candidate list section 43, excluding any that contained function words13 Our basic idea was to conflate x and y into a pseudoword x-y	0	0	0
H05-1050	P95-1026	2005	Given an instance of the task and a seed s for that instance, one bootstraps a classifier Cs that can classify examples of the task instance	0	21 The Yarowsky algorithm <TREF>Yarowsky 1995</TREF> sparked considerable interest in bootstrapping with his successful method for word sense disambiguation	0	An instance of this task involves a homonymous word such as drug	0	A seed for the instance is a pair of words that are strongly associated, respectively, with the two senses of drug, such as trafficking, therapy	0	0	0
N07-1032	P95-1026	2007	The problem of combining labeled and unlabeled examples in a learning task semi-supervised learning has been studied in the literature under various guises	0	A variety of algorithms eg , bootstrapping <TREF>Yarowsky, 1995</TREF>, co-training <REF>Blum and Mitchell, 1998</REF>, alternating structure optimization <REF>Ando and Zhang, 2005</REF>, etc	0	have been developed in order to improve the performance of supervised algorithms, by automatically extracting knowledge from lots of unlabeled examples	0	Of special interest is the work of <REF>Ando and Zhang 2005</REF>, where the goal is to build many supervised auxiliary tasks from the unsupervised data, by creating artificial labels; this procedure helps learn a transformation of the input space that captures the relatedness of the auxiliary problems to the task at hand	0	0	0
P04-1039	P95-1026	2004	Their investigation was limited in scale to six data items with two senses each and a bounded number of examples per test item	0	Two more recent investigations are by Yarowsky, <TREF>Yarowsky, 1995</TREF>, and later, Mihalcea, <REF>Mihalcea, 2002</REF>	0	Each of the studies, in turn, addresses the issue of data quantity while maintaining good quality training examples	0	Both investigations present algorithms for bootstrapping supervised WSD systems using clean data based on a dictionary or an ontological resource	0	0	0
W99-0905	P95-1026	1999	Although we employed the distributional clustering algorithm for resolving word sense ambiguity, different algorithms are also applicable	0	Among them, the unsupervised algorithm using decisiontrees <TREF>Yarowsky, 1995</TREF> has achieved promising performance	0	An interesting approach is to use the output of our sense-translation linking process as the seeds required by that algorithm	0	7 Concluding Remarks This paper presented an unsupervised method for choosing the correct translation of a source word in context	0	0	0
P06-2077	P95-1026	2006	Recall that the instances tagged with  by the tagging rules are discarded when training data are generated as described in Subsection 41	0	These instances can be retagged with their countability by using the proposed method and some kind of bootstrapping <TREF>Yarowsky, 1995</TREF>	0	This means increase in training data, which might eventually result in further improvement	0	The second is that the proposed method is unsupervised	0	0	0
P06-2077	P95-1026	2006	Indeed, the average accuracy of Proposed is signi cantly superior to that of ME at the 99 con dence level paired t-test	0	This improvement is close to that of one sense per discourse <TREF>Yarowsky, 1995</TREF> improvement ranging from 13 to 17, which seems to be a sensible upper bound of the proposed method	0	By contrast, about half of the plots a29  corresponding to the comparison between ME and MEMCD are below the line	0	From these results, it follows that the one countability per discourse property is a good source of evidence for predicting countability, but it is crucial to devise a way of exploiting the property as we did in this paper	0	0	0
P06-2077	P95-1026	2006	We tested this hypothesis on a set of nouns1 1The conditions of this test are shown in Section 5	0	Note that although the source of the data is the same as in Section 5, as <TREF>Yarowsky 1995</TREF> did	0	We calculated how accurately the majority countability for each discourse predicted countability of the nouns in the discourse when they appeared more than once	0	If the one countability per discourse property is always satis ed, the majority countability for each discourse should predict countability with the accuracy of 100	0	0	0
P06-2077	P95-1026	2006	2005as method as the one to be reinforced by the proposed method	0	In this method, the decision list DL learning algorithm <TREF>Yarowsky, 1995</TREF> is used	0	However, we used the ME algorithm because we found that the method with the ME algorithm instead of the DL learning algorithm performed better when trained on the same training data	0	As the target noun, we selected 23 nouns that were also used in Nagata et al	0	0	0
P06-2077	P95-1026	2006	One sense per discourse claims that when a polysemous word appears more than once in a discourse it is likely that they will all share the same sense	0	<TREF>Yarowsky 1995</TREF> tested the claim on about 37,000 examples and found that when a polysemous word appeared more than once in a discourse, they took on the majority sense for the discourse 998 of the time on average	0	Based on one sense per discourse, we hypothesize that when a noun appears more than once in a discourse, they will all share the same countability in the discourse, that is, one countability per discourse	0	The motivation for this hypothesis is that if one sense per discourse is satis ed, so is one countability per discourse because countability is often determined by word sense	0	0	0
W00-1326	P95-1026	2000	4 Adaptation of decision lists to n-way ambiguities Decision lists as defined in <REF>Yarowsky, 1993</REF>; 1994 are simple means to solve ambiguity problems	0	They have been successfully applied to accent restoration, word sense disambiguation 209 and homograph disambiguation <REF>Yarowsky, 1994</REF>; 1995; 1996	0	In order to build decision lists the training examples are processed to extract the features each feature corresponds to a kind of collocation, which are weighted with a log-likelihood measure	0	The list of all features ordered by log-likelihood values constitutes the decision list	0	0	0
W04-0813	P95-1026	2004	In this section we will describe first the parameters of each method including the smoothing procedure, and then the cross-validation results on the Senseval-3 training data	0	41 Methods and Parameters DL: On Senseval-2 data, we observed that DL improved significantly its performance with a smoothing technique based on <TREF>Yarowsky, 1995a</TREF>	0	For our implementation, the smoothed probabilities were obtained by grouping the observations by raw frequencies and feature types	0	As this method seems sensitive to the feature types and the amount of examples, we tested 3 DL versions: DL smooth using smoothed probabilities, DL fixed replacing 0 counts with 01, and DL discard discarding features appearing with only one sense	0	0	0
W04-0813	P95-1026	2004	2 Learning Algorithms The algorithms presented in this section rely on features extracted from the context of the target word to make their decisions	0	The Decision List DL algorithm is described in <TREF>Yarowsky, 1995b</TREF>	0	In this algorithm the sense with the highest weighted feature is selected, as shown below	0	We can avoid undetermined values by discarding features that have a 0 probability in the divisor	0	0	0
P06-2117	P95-1026	2006	However, labeled data is valuable to improve performance of learners	0	Consequently, semi-supervised learning, which combines both labeled and unlabeled data, has been applied to some NLP tasks such as word sense disambiguation <TREF>Yarowsky, 1995</TREF>; <REF>Pham et al , 2005</REF>, classification <REF>Blum and Mitchell, 1998</REF>; <REF>Thorsten, 1999</REF>, clustering <REF>Basu et al , 2004</REF>, named entity classification <REF>Collins and Singer, 1999</REF>, and parsing <REF>Sarkar, 2001</REF>	0	In this paper, we propose a semi-supervised boosting method to improve statistical word alignment with both limited labeled data and large amounts of unlabeled data	0	The proposed approach modifies the supervised AdaBoost algorithm to a semi-supervised learning algorithm by incorporating the unlabeled data	0	0	0
W04-0846	P95-1026	2004	To avoid the Knowledge Bottleneck, unsupervised or weakly supervised learning approaches have been proposed	0	These include the bootstrapping approach <TREF>Yarowsky 1995</TREF> and the context clustering approach <REF>Schutze 1998</REF>	0	Although the above unsupervised or weakly supervised learning approaches are less subject to the Knowledge Bottleneck, some weakness exists: i for each individual keyword, the sense number has to be provided and in the bootstrapping case, seeds for each sense are also required; ii the modeling usually assumes some form of evidence independency, eg the vector space model used in <REF>Schutze 1998</REF> and <REF>Niu et al 2003</REF>: this limits the performance and its potential enhancement; iii most WSD systems either use selectional restriction in parsing relations, and/or trigger words which co-occur within a window size of the ambiguous word	0	We previously at-tempted combining both types of evidence but only achieved limited improvement due to the lack of a proper modeling of information over-lapping <REF>Niu et al 2003</REF>	0	0	0
J04-1003	P95-1026	2004	The context within which the ambiguous word occurs is typically represented by a set of linguistically motivated features from which a learning algorithm induces a representative model that performs the disambiguation	0	A variety of classifiers have been employed for this task see Mooney 1996 and Ide and Veronis 1998 for overviews, the most popular being decision lists <REF>Yarowsky 1994, 1995</REF> and naive Bayesian classifiers <REF>Pedersen 2000</REF>; <REF>Ng 1997</REF>; <REF>Pedersen and Bruce 1998</REF>; <REF>Mooney 1996</REF>; <REF>Cucerzan and Yarowsky 2002</REF>	0	We employed a naive Bayesian classifier <REF>Duda and Hart 1973</REF> for our experiments, as it is a very convenient framework for incorporating prior knowledge and studying its influence on the classification task	0	In Section 51 we describe a basic naive Bayesian classifier and show how it can be extended with informative priors	0	0	0
W02-0903	P95-1026	2002	<REF>Hastings and Lytinen 1994</REF> investigated attacking the lexical acquisition problem with a system that relies mainly on taxonomic information	0	In the last decade or so research on lexical semantics has focused more on sub-problems like word sense disambiguation <TREF>Yarowsky, 1995</TREF>; <REF>Stevenson and Wilks, 2001</REF>, named entity recognition <REF>Collins and Singer, 1999</REF>, and vocabulary construction for information extraction <REF>Riloff, 1996</REF>	0	All of these can be seen as sub-tasks, because the space of possible classes for each word is restricted	0	In WSD the possible classes for a word are its possible senses; in named entity recognition or IE the number of classes is limited to the fixed usually small number the task focuses on	0	0	0
W02-0903	P95-1026	2002	A class of features that intuitively carry semantic information are collocations, ie, words that co-occur with the nouns of interest in a corpus	0	Collocations have been widely used for tasks such as word sense disambiguation WSD <TREF>Yarowsky, 1995</TREF>, information extraction IE <REF>Riloff, 1996</REF>, and named-entity recognition <REF>Collins and Singer, 1999</REF>	0	The choice of collocations can be conditioned in many ways: according to syntactic relations with the target word, syntactic category, distance from the target, and so on	0	We use a very simple set of collocations: each word a39 that appears within a40a42a41 positions from a noun a43 is a feature	0	0	0
C98-2177	P95-1026	1998	Utilizing existing resources, such as on-line corpora, to aid in this task could improve performance both by decreasing the time to construct the lexicon and by improving its quality	0	Extracting semantic information from word co-occurrence statistics has been effective, particularly for sense disambiguation <REF>Schiitze, 1992</REF>; <REF>Gale et al, 1992</REF>; <TREF>Yarowsky, 1995</TREF>	0	<REF>In Riloff and Shepherd 1997</REF>, noun co-occurrence statistics were used to indicate nominal category membership, for the purpose of aiding in the construction of semantic lexicons	0	Generically, their algorithm can be outlined as follows: 1	0	0	0
P06-1072	P95-1026	2006	The score is the F1 measure on non- attachments	0	Annealing  resembles the popular bootstrapping technique <TREF>Yarowsky, 1995</TREF>, which starts out aiming for high precision, and gradually improves coverage over time	0	With strong bias  greatermuch 0, we seek a model that maintains high dependency precision on non- attachments by attaching most tags to 	0	Over time, as this is iteratively weakened   , we hope to improve coverage dependency recall	0	0	0
H05-1114	P95-1026	2005	This paper deals with word sense disambiguation WSD problem, which is to assign an appropriate sense to an occurrence of a word in a given context	0	Many corpus based statistical methods have been proposed to solve this problem, including supervised learning algorithms <REF>Leacock et al , 1998</REF>; <REF>Towel and Voorheest, 1998</REF>, weakly supervised learning algorithms <REF>Dagan and Itai, 1994</REF>; <REF>Li and Li, 2004</REF>; <REF>Mihalcea, 2004</REF>; <REF>Niu et al , 2005</REF>; <REF>Park et al , 2000</REF>; <TREF>Yarowsky, 1995</TREF>, unsupervised learning algorithms or word sense discrimination <REF>Pedersen and Bruce, 1997</REF>; <REF>Schutze, 1998</REF>, and knowledge based algorithms <REF>Lesk, 1986</REF>; <REF>McCarthy et al , 2004</REF>	0	In general, the most common approaches start by evaluating the co-occurrence matrix of features versus contexts of instances of ambiguous word, given sense-tagged training data for this target word	0	As a result, contexts are usually represented in a highdimensional sparse feature space, which is far from optimal for many classification algorithms	0	0	0
P04-3026	P95-1026	2004	3 Algorithm As in previous work <REF>Rapp, 2002</REF>, our computations are based on a partially lemmatized version of the British National Corpus BNC which has the function words removed	0	Starting from the list of 12 ambiguous words provided by <TREF>Yarowsky 1995</TREF> which is shown in table 2, we created a concordance for each word, with the lines in the concordances each relating to a context window of 20 words	0	From the concordances we computed 12 term/context-matrices analogous to table 1 whose binary entries indicate if a word occurs in a particular context or not	0	Assuming that the amount of information that a context word provides depends on its association strength to the ambiguous word, in each matrix we removed all words that are not among the top 30 first order associations to the ambiguous word	0	0	0
P04-3026	P95-1026	2004	However, this is exactly what we want in sense induction	0	In an attempt to provide a quantitative evaluation of our results, for each of the 12 ambiguous words shown in table 1 we manually assigned the top 30 first-order associations to one of the two senses provided by <TREF>Yarowsky 1995</TREF>	0	We then looked at the first split in our hierarchical trees and assigned each of the two clusters to one of the given senses	0	In no case was there any doubt on which way round to assign the two clusters to the two given senses	0	0	0
W97-0322	P95-1026	1997	The window size, the number of values for the POS features, and the number of words considered in the collocation features are kept deliberately small in order to control the dimensionality of the problem	0	In future work, we will expand all of the above types of features and employ techniques to reduce dimensionality along the lines suggested in <REF>Duda and Hart, 1973</REF> and <REF>Gale, Church, and Yarowsky, 1995</REF>	0	6 Experimental Results Figure 5 shows the average accuracy and standard deviation of disambiguation over 25 random trials for each combination of word, feature set and learning algorithm	0	Those cases where the average accuracy of one algorithm for a particular feature set is significantly higher than another algorithm, as judged by the t-test p01, are shown in bold face	0	0	0
W97-0322	P95-1026	1997	The features used in this work are complex and difficult to interpret and it isnt clear that this complexity is required	0	<TREF>Yarowsky, 1995</TREF> compares his method to <REF>Schiitze, 1992</REF> and shows that for four words the former performs significantly better in distinguishing between two senses	0	Other clustering approaches to word-sense disambiguation have been based on measures of semantic distance defined with respect to a semantic network such as WordNet	0	Measures of semantic distance are based on the path length between concepts in a network and are used to group semantically similar concepts eg	0	0	0
W97-0322	P95-1026	1997	Experiments with 11 other words using collocation seeds result in an average accuracy of 96 percent	0	While <TREF>Yarowsky, 1995</TREF> does not discuss distinguishing more than 2 senses of a word, there is no immediate reason to doubt that the one sense per collocation rule <REF>Yarowsky, 1993</REF> would still hold for a larger number of senses	0	In future work we will evaluate using the one sense per collocation rule to seed our various methods	0	This may help in dealing with very skewed distributions of senses since we currently select collocations based simply on frequency	0	0	0
W97-0322	P95-1026	1997	Those examples in the test set that are most confidently disambiguated are added to the training sample	0	A more recent bootstrapping approach is described in <TREF>Yarowsky, 1995</TREF>	0	This algorithm requires a small number of training examples to serve as a seed	0	There are a variety of options discussed for 204 automatically selecting seeds; one is to identify collocations that uniquely distinguish between senses	0	0	0
W97-0322	P95-1026	1997	Subjectspecific neighborhoods are composed of words having at least one sense marked with that subject code	0	73 EM algorithm The only other application of the EM algorithm to word-sense disambiguation is described in <REF>Gale, Church, and Yarowsky, 1995</REF>	0	There the EM algorithm is used as part of a supervised learning algorithm to distinguish city names from peoples names	0	A narrow window of context, one or two words to either side, was found to perform better than wider windows	0	0	0
J98-1002	P95-1026	1998	48 Karov and Edelman Similarity-based Word Sense Disambiguation Table 2 A summary of the algorithms performance on the four test words	0	Word Senses Sample Size Feedback Size  Correct  Correct per Sense Total drug narcotic 65 100 923 905 medicine 83 65 891 sentence judgment 23 327 1000 925 grammar 4 42 500 suit court 212 1,461 986 948 garment 21 81 550 player performer 48 230 875 923 participant 44 1,552 977 the feedback sets consisted of a few dozen examples, in comparison to thousands of examples needed in other corpus-based methods Schitze 1992; <TREF>Yarowsky 1995</TREF>	0	The average success rate of our algorithm on the 500 appearances of the four test words was 92	0	32 The Drug Experiment We now present in detail several of the results obtained with the word drug	0	0	0
J98-1002	P95-1026	1998	However, as noted above, the MRD definitions alone do not contain enough information to allow reliable disambiguation	0	<REF>Recently, Yarowsky 1995</REF> combined an MRD and a corpus in a bootstrapping process	0	In that work, the definition words were used as initial sense indicators, automatically tagging the target word examples containing them	0	These tagged examples were then used as seed examples in the bootstrapping process	0	0	0
W98-0703	P95-1026	1998	WSD that use information gathered from training on a corpus that has already been semantically disambiguated supervised training methods Gale, <REF>Church et al , 1992</REF>, <REF>Ng and Lee, 1996</REF>; 3	0	WSD that use information gathered from raw corpora unsupervised training methods <TREF>Yarowsky 1995</TREF> <REF>Resnik 1997</REF>	0	There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others <REF>McRoy, 1992</REF> <REF>Bruce and Wiebe, 1994</REF> <REF>Ng and Lee, 1996</REF> Rigau, <REF>Asterias et al , 1997</REF>	0	Statistical methods produce high accuracy results for small number of preselected words	0	0	0
C08-1135	P95-1026	2008	The sentiment of a document is calculated as the average semantic orientation of all such phrases	0	<TREF>Yarowsky 1995</TREF> describes a semi-unsupervised approach to the problem of sense disambiguation of words, also using a set of initial seeds, in this case a few high quality sense annotations	1	These annotations are used to start an iterative process of learning information about the contexts in which senses of words appear, in each iteration labeling senses of previously unlabeled word tokens using information from the previous iteration	0	23 Chinese Language Processing A major issue in processing Chinese text is the fact that words are not delimited in the written language	0	6	1
W97-0812	P95-1026	1997	1991, Gale et al	0	1992, <TREF>Yarowsky 1995</TREF>, and <REF>Karol  Edelman 1996</REF> where strong reliance on statistical techniques for the calculation of word and context similarity commands large source corpora	0	Such advantage can be particularly appreciated with reference to the acquisition of cooccurrence restrictions for those sublanguage domains where large corpora are not available	0	Ironically, the major advantage of the approach proposed --namely, a reliance on structured semantic word nets as the main knowledge source for assessing semantic similarity --is also its major drawback	0	0	0
W03-0601	P95-1026	2003	Word sense disambiguation has long been studied as an important problem in natural language processing <REF>Agirre and Rigau, 1995</REF>; <REF>Gale et al , 1992</REF>; <REF>Manning and Schtze, 1999</REF>; Mihalcea and Moldovan	0	, 1998; <REF>Traupman and Wilensky, 2003</REF>; <TREF>Yarowsky, 1995</TREF>	0	It is illustrated in Figure 1 with the arguably overused bank example	0	A priori, the word bank has a number of meanings including financial institution and a step or edge as in snow bank or river bank	0	0	0
C96-2157	P95-1026	1996	For insl;ance, a:;eltan;e thresholds of evide, nce weights, initially set, higll, can be gradually decreased to allow more recall while keeping lrecision at a reasonable level	0	In additioil, <TREF>Yarowsky, 1995</TREF>, Gale, Church ; <REF>Yarowsky, 1992</REF> point ou; that there is a st, rent tenden:y for words 1;O occur in Ile sense within any given dis:ourse one sense pe, r dis:ourse	0	Th; same seems to atply to :oncelt sele:l;ion, thai, is, Inultille o::mren:es of a :anlidate 1hrase within t discurse should all 1e eithe a:eeltel or reje,:t;;t y the SlOl,te	0	This in turn allows fr tootstratting prcess to gather more contextual evideal:c more quickly, and thus to :onwuge faster trodu:ing, better results	0	0	0
C96-2157	P95-1026	1996	At this time, we make no claim as to whether 1 is an optimal fornmla for cah:ulating evidence weights	0	An alternative method we considered was to estimate certain conditional probabilities, similarly to the formula used in <TREF>Yarowsky, 1995</TREF>: SWt log Pp C A/t ft, AfA   log 2 Pp C R/t ft, Rfl Here fA is an estimate of the probability that any given candidate phrase will be accepted by the spotter, and fR is the probability that this phrase is rejected, ie, fR  l-f A	0	Thus fin our experinmnts show that 1 produces better results than 2	0	We continue investigating other weighting schemes as well	0	0	0
P06-1089	P95-1026	2006	The mean field approximation was used for inference in their method	0	<TREF>Yarowsky 1995</TREF> studied a method for word sense disambiguation using unlabeled data	0	Although no probabilistic models were considered explicitly in the method, they used the property of label consistency named one sense per discourse for unsupervised learning together with local information named one sense per collocation	0	There exist other approaches using global information which do not necessarily aim to use label consistency	0	0	0
W96-0104	P95-1026	1996	On the word drug, our algorithm achieved performance of 905, after being trained on 148 examples contexts	0	In comparison, <TREF>Yarowsky, 1995</TREF> achieved 48 Table 1: A summary of the experimental results on four polysemous words	0	Word Senses Sample Feedback 7o correct  correct Size Size per sense total drug narcotic 65 100 923 905 medicine 83 65 891 sentence judgement 23 327 100 925 grammar 4 42 50 suit court 212 1461 9859 948 garment 21 81 55 player performer 48 230 875 923 participant 44 1552 977 914 correct performance, using 1380 contexts and the dictionary definitions in training	0	4 On the word suit, our method achieved performance of 948, using 233 training contexts; in comparison, <REF>Schutze, 1992</REF> achieved 957o correct performance, using 8206 contexts	0	0	0
W96-0104	P95-1026	1996	However, as noted above, the MRD definitions alone do not contain enough information to allow reliable disambiguation	0	<REF>Recently, Yarowsky 1995</REF> combined a MIlD and a corpus in a bootstrapping process	0	In that work, the definition words were used as initial sense indicators, tagging automatically the target word examples containing them	0	These tagged examples were then used as seed examples in the bootstrapping process	0	0	0
W96-0104	P95-1026	1996	The average success rate of our algorithm was 92	0	The original training set before the addition of the feedback sets consisted of a few dozen examples, in comparison to thousands of examples needed in other corpus-based methods <REF>Schutze, 1992</REF>; <TREF>Yarowsky, 1995</TREF>	0	Results on two of the words on which we tested our algorithm drug and suit have been also reported in the works of Schutze and Yarowsky	0	It is interesting to compare the performance of the different methods on these words	0	0	0
P01-1005	P95-1026	2001	Numerous methods have been presented for confusable disambiguation	0	The more recent set of techniques includes mult iplicative weightupdate algorithms <REF>Golding and Roth, 1998</REF>, latent semantic analysis <REF>Jones and Martin, 1997</REF>, transformation-based learning <REF>Mangu and Brill, 1997</REF>, differential grammars <REF>Powers, 1997</REF>, decision lists <REF>Yarowsky, 1994</REF>, and a variety of Bayesian classifiers <REF>Gale et al , 1993</REF>, <REF>Golding, 1995</REF>, <REF>Golding and Schabes, 1996</REF>	0	In all of these approaches, the problem is formulated as follows: Given a specific confusion set eg to,two,too, all occurrences of confusion set members in the test set are replaced by a marker; everywhere the system sees this marker, it must decide which member of the confusion set to choose	0	Confusion set disambiguation is one of a class of natural language problems involving disambiguation from a relatively small set of alternatives based upon the string context in which the ambiguity site appears	0	0	0
P01-1005	P95-1026	2001	In this section we turn to unsupervised learning in an attempt to achieve this goal	0	Numerous approaches have been explored for exploiting situations where some amount of annotated data is available and a much larger amount of data exists unannotated, eg Marialdos HMM part-of-speech tagger training 1994, Charniaks parser retraining experiment 1996, Yarowskys seeds for word sense disambiguation 1995 and Nigam et als 1998 topic classifier learned in part from unlabelled documents	0	A nice discussion of this general problem can be found in <REF>Mitchell 1999</REF>	0	The question we want to answer is whether there is something to be gained by combining unsupervised and supervised learning when we scale up both the seed corpus and the unlabeled corpus significantly	0	0	0
W03-1315	P95-1026	2003	This approach has also been adopted for the biomedical domain as illustrated in the work of <REF>Hatzivassiloglou et al , 2001</REF>; <REF>Narayanaswamy et al , 2003</REF>; <REF>Castano et al , 2002</REF> 2	0	In the WSD work involving the use of context, we can find two approaches: one that uses few strong contextual evidences for disambiguation purposes, as exemplified by <TREF>Yarowsky, 1995</TREF>; and the other that uses weaker evidences but considers a combination of a number of them, as exemplified by <REF>Gale et al , 1992</REF>	0	We explore both the methods	0	In Section 44, we discuss our formulation and present a simple way of extracting contextual clues	0	0	0
W03-1315	P95-1026	2003	The classification task is an integral part of named entity extraction	0	For this reason, name classification has been studied in solving the named entity extraction task in the NLP and information extraction communities see, for example, <REF>Collins and Singer, 1999</REF>; <REF>Cucerzan and Yarowsky, 1999</REF> and various approaches reported in the MUC conferences MUC-6, 1995	0	However, many of these approaches do not distinguish the detection of the names ie , identifying a sequence of characters and words in text as a name from that of its classification as separate phases	0	Yet, we believe that we will gain from examining the two as separate tasks as the classification task, the focus of this work, is sufficiently distinct from the name identification task	0	0	0
W03-1315	P95-1026	2003	3 44 Classifying Based on Context To identify the best sources of contextual information for classifying names, we considered two possibilities  the use of a single strong piece of evidence and the use of a combination of weak evidences	0	For the former we made use Decision Lists similar to Yarowskys method for Word Sense Disambiguation WSD <TREF>Yarowsky, 1995</TREF>	0	However, we found that this method had a poor recall	0	4 3 As always, the reason for using a threshold is that it allows us to find the appropriate level of compromise between precision and recall	0	0	0
W03-0406	P95-1026	2003	Therefore, the EM method is more practical than Co-training	0	Yarowsky proposed the unsupervised learning method for WSD<TREF>Yarowsky, 1995</TREF>	0	His method is reported to be a special case of Co-training<REF>Blum and Mitchell, 1998</REF>	0	As two independent feature sets, one is the context surrounding the target word and the other is the heuristic of one sense per discourse	0	0	0
W03-0406	P95-1026	2003	This strategy has been very successful, but it has a serious problem in that an inductive learning method requires labeled data, which is expensive because it must be made manually	0	To overcome this problem, unsupervised learning methods using huge unlabeled data to boost the performance of rules learned by small labeled data have been proposed recently<REF>Blum and Mitchell, 1998</REF><TREF>Yarowsky, 1995</TREF><REF>Park et al , 2000</REF><REF>Li and Li, 2002</REF>	0	Among these methods, the method using the EM algorithm proposed by the paper<REF>Nigam et al , 2000</REF>, which is referred to as the EM method in this paper, is the state of the art	0	However, the target of the EM method is text classification	0	0	0
P03-1044	P95-1026	2003	At the same time, certain unsupervised learning algorithms in other domains exhibit inherently natural stopping criteria	0	One example is the algorithm for word sense disambiguation in <TREF>Yarowsky, 1995</TREF>	0	Of particular relevance to our method are the algorithms for semantic classification of names or NPs described in <REF>Thelen and Riloff, 2002</REF>; <REF>Yangarber et al , 2002</REF>	0	Inspired in part by these algorithms, we introduce the counter-training technique for unsupervised pattern acquisition	0	0	0
P02-1064	P95-1026	2002	The problem is that corpus annotation is labour intensive and very expensive	0	In order to overcome this, some unsupervised learning methods and minimally-supervised methods, eg, <TREF>Yarowsky, 1995</TREF>; <REF>Yarowsky and Wicentowski, 2000</REF>, have been proposed	0	However, such methods usually depend on tasks or domains and their performance often does not match one with a supervised learning method	0	Another promising approach is active learning,in which a classifier selects examples to be labeled, and then requests a teacher to label them	0	0	0
P02-1064	P95-1026	2002	It is expected that active learning will reduce considerably manual annotation cost while keeping performance	0	However, few papers in the field of computational linguistics have focused on this approach <REF>Dagan and Engelson, 1995</REF>; <REF>Thompson et al , 1999</REF>; <REF>Ngai and Yarowsky, 2000</REF>; <REF>Hwa, 2000</REF>; <REF>Banko and Brill, 2001</REF>	0	Although there are many active learning methods with various classifiers such as a probabilistic classifier <REF>McCallum and Nigam, 1998</REF>, we focus on active learning with Support Vector Machines SVMs because of their performance	0	The Support Vector Machine, which is introduced by <REF>Vapnik 1995</REF>, is a powerful new statistical learning method	0	0	0
C02-1058	P95-1026	2002	A number of bootstrapping methods have been proposed to reduce the sensetagging cost <REF>Hearst 1991</REF>; <REF>Basili 1997</REF>	0	A variety of unsupervised WSD methods, which use a machinereadable dictionary or thesaurus in addition to a corpus, have also been proposed <REF>Yarowsky 1992</REF>; <TREF>Yarowsky 1995</TREF>; <REF>Karov and Edelman 1998</REF>	0	Bilingual parallel corpora, in which the senses of words in the text of one language are indicated by their counterparts in the text of another language, have also been used in order to avoid manually sense-tagging training data Brown, et al 1991	0	Unlike the previous methods using bilingual corpora, our method does not require parallel corpora	0	0	0
P05-1044	P95-1026	2005	2003	0	Unlike well-known bootstrapping approaches <TREF>Yarowsky, 1995</TREF>, EM and CE have the possible advantage of maintaining posteriors over hidden labels or structure throughout learning; bootstrapping either chooses, for each example, a single label, or remains completely agnostic	0	One can envision a mixed objective function that tries to fit the labeled examples while discriminating unlabeled examples from their neighborhoods8 Regardless of how much if any data are labeled, the question of good smoothing techniques requires more attention	0	Here we used a single zero-mean, constant-variance Gaussian prior for all parameters	0	0	0
P06-2022	P95-1026	2006	Our vector representation of the behavior of a word type across all its instances in a corpus is based on <REF>Lin 1998</REF>s DESCRIPTION OF A WORD	0	<TREF>Yarowsky 1995</TREF> uses a conceptually similar technique for WSD that learns from a small set of seed examples and then increases recall by bootstrapping, evaluated on 12 idiosyncratically polysemous words	0	In that task, often a single disambiguating feature can be found in the context of a polysemous word instance, motivating his use of the decision list algorithm	0	In contrast, the goal here is to learn how event-like or non-event-like a set of contextual features together are	0	0	0
E99-1028	P95-1026	1999	The resuits of experiment demonstrate the effectiveness of the method	0	One of the major approaches to disambiguate word senses is supervised learning <REF>Gale et al , 1992</REF>, <REF>Yarowsky, 1992</REF>, <REF>Bruce and Janyce, 1994</REF>, <REF>Miller et al , 1994</REF>, <REF>Niwa and Nitta, 1994</REF>, <REF>Luk, 1995</REF>, <REF>Ng and Lee, 1996</REF>, <REF>Wilks and Stevenson, 1998</REF>	0	However, a major obstacle impedes the acquisition of lexical knowledge from corpora, ie the difficulties of manually sensetagging a training corpus, since this limits the applicability of many approaches to domains where this hard to acquire knowledge is already available	0	This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning	0	0	0
E99-1028	P95-1026	1999	The weakness of Schiitze and Zerniks method, however, is that it solely relies on human intuition for identifying different senses of a word, ie the human editor has to determine, by her/his intuition, how many senses a word has, and then identify the sets of co-occurring words that correspond to the different senses	0	213 Proceedings of EACL 99 Table 2: The result of disambiguation experimenttwo senses 6  122 -cause eect  require a- -Telose, open,  rrect -fall, decline, win  278 -feel, think, sense T T 280 hit, attack, strike I 250 leave, remain, go  183 gcty t Ol accomplish, operate-216 --occur, happen,  --order, request, arrange- 240 -ass, adopt,  274 -roduce, create, gro--2 --ush, attack, pull -sve, 223 -ship, put, send stop, end, move add, append, total keep, maintain, protect Total 215773 181724 160874 349923 - Correct 83770 113862 I 169875 J Yarowsky used an unsupervised learning procedure to perform noun WSD <TREF>Yarowsky, 1995</TREF>	0	This algorithm requires a small number of training examples to serve as a seed	0	The result shows that the average percentage attained was 961 for 12 nouns when the training data was a 460 million word corpus, although Yarowsky uses only nouns and does not discuss distinguishing more than two senses of a word	0	0	0
W03-1027	P95-1026	2003	The problem is that corpus annotation is labor intensive and very expensive	0	In order to overcome this, several methods are proposed, including minimally-supervised learning methods eg , <TREF>Yarowsky, 1995</TREF>; <REF>Blum and Mitchell, 1998</REF>, and active learning methods eg , <REF>Thompson et al , 1999</REF>; <REF>Sassano, 2002</REF>	0	The spirit behind these methods is to utilize precious labeled examples maximally	0	Another method following the same spirit is one using virtual examples artificially created examples generated from labeled examples	0	0	0
N01-1023	P95-1026	2001	We discuss previous work in combining labeled and unlabeled data in more detail in Section 7	0	Co-training <REF>Blum and Mitchell, 1998</REF>; <TREF>Yarowsky, 1995</TREF> can be informally described in the following manner: 0F Pick two or more views of a classification problem	0	0F Build separate models for each of these views and train each model on a small set of labeled data	0	0F Sample an unlabeled data set and to find examples that each model independently labels with high confidence	0	0	0
N01-1023	P95-1026	2001	Our approach is closely related to previous CoTraining methods <TREF>Yarowsky, 1995</TREF>; <REF>Blum and Mitchell, 1998</REF>; <REF>Goldman and Zhou, 2000</REF>; <REF>Collins and Singer, 1999</REF>	0	<TREF>Yarowsky, 1995</TREF> first introduced an iterative method for increasing a small set of seed data used to disambiguate dual word senses by exploiting the constraint that in a segment of discourse only one sense of a word is used	0	This use of unlabeled data improved performance of the disambiguator above that of purely supervised methods	0	<REF>Blum and Mitchell, 1998</REF> further embellish this approach and gave it the name of CoTraining	0	0	0
N01-1023	P95-1026	2001	This work was partially supported by NSF Grant SBR8920230, ARO Grant DAAH0404-94-G-0426, and DARPA Grant N66001-00-1-8915	0	1998; <REF>Goldman and Zhou, 2000</REF> that has been used previously to train classifiers in applications like word-sense disambiguation <TREF>Yarowsky, 1995</TREF>, document classification <REF>Blum and Mitchell, 1998</REF> and named-entity recognition <REF>Collins and Singer, 1999</REF> and apply this method to the more complex domain of statistical parsing	0	2 Unsupervised techniques in language processing While machine learning techniques that exploit annotated data have been very successful in attacking problems in NLP, there are still some aspects which are considered to be open issues: 0F Adapting to new domains: training on one domain, testing using on another	0	0F Higher performance when using limited amounts of annotated data	0	0	0
N01-1023	P95-1026	2001	The goal in their work is not to get the right bracketing or dependencies but to reduce the word error rate in a speech recognizer	0	Our approach is closely related to previous CoTraining methods <TREF>Yarowsky, 1995</TREF>; <REF>Blum and Mitchell, 1998</REF>; <REF>Goldman and Zhou, 2000</REF>; <REF>Collins and Singer, 1999</REF>	0	<TREF>Yarowsky, 1995</TREF> first introduced an iterative method for increasing a small set of seed data used to disambiguate dual word senses by exploiting the constraint that in a segment of discourse only one sense of a word is used	0	This use of unlabeled data improved performance of the disambiguator above that of purely supervised methods	0	0	0
N01-1023	P95-1026	2001	Since both of these steps ultimately have to agree with each other, we can utilize an iterative method called CoTraining that attempts to increase agreement between a pair of statistical models by exploiting mutual constraints between their output	0	Co-Training has been used before in applications like word-sense disambiguation <TREF>Yarowsky, 1995</TREF>, web-page classification <REF>Blum and Mitchell, 1998</REF> and namedentity identification <REF>Collins and Singer, 1999</REF>	0	In all of these cases, using unlabeled data has resulted in performance that rivals training solely from labeled data	0	However, these previous approaches were on tasks that involved identifying the right label from a small set of labels typically 23, and in a relatively small parameter space	0	0	0
C04-1133	P95-1026	2004	12 Word Sense Disambiguation: Current State of the Art Previous computational concerns for economy of grammatical representation have given way to models of language that not only exploit generative grammatical resources but also have access to large lists of contexts of linguistic items words, to which new structures can be compared in new usages	0	However, following the work of <REF>Yarowsky 1992</REF>, <TREF>Yarowsky 1995</TREF>, many supervised WSD systems use minimal information about syntactic structures, for the most part restricting the notion of context to topical and local features	0	Topical features track open-class words that appear within a certain window around a target word, and local features track small N-grams associated with the target word	0	Disambiguation therefore relies on word co-occurrence statistics, rather than on structural similarities	0	0	0
W03-0107	P95-1026	2003	London, England, would thus always be guessed rather than London, Ontario	0	Bootstrapping methods similar to ours have been shown to be competitive in word sense disambiguation <REF>Yarowsky and Florian, 2003</REF>; <TREF>Yarowsky, 1995</TREF>	0	3 Difficulty of the Task Our ability to disambiguate place names should be weighed against the ease or difficulty of the task	0	In a world where most toponyms referred unambiguously to one place, we would not be impressed by near-perfect performance	0	0	0
P03-1043	P95-1026	2003	These tags are regarded as noise, hence are removed by the tag elimination scheme	0	The tag propagation/elimination scheme is adopted from <TREF>Yarowsky 1995</TREF>	0	After this step, a total of 386,614 proper names were recognized, including 134,722 PER names, 186,488 LOC names, 46,231 ORG names and 19,173 PRO names	0	The overall precision was 90	0	0	0
C98-2223	P95-1026	1998	We trained decision lists <REF>Clark and Niblett, 1989</REF> using a supervised learning approach	0	Decision lists have already been successfully applied to lexical ambiguity resolution by <TREF>Yarowsky, 1995</TREF> where they perfiomed well	0	We present the decision list system with a number of training words for which the correct sense is known	0	For each of the words we supply each of its possible senses apart fiom those removed from consideration by the part-of-speech filter Section 32 within a context consisting of the results from each of the partial taggers, frequency information and 10 simple collocations first noun/verb/preposition to the left/right and first/second word to the left/right	0	0	0
C98-2223	P95-1026	1998	The methodology and evaluation of WSD are somewhat different from those of other NLP modules, and one can distinguish three aspects of this difference, all of which come down to evaluation problelns, as does so much in NLP these days	0	First, researchers are divided between a general inethod that attempts to apply WSD to all the content words of texts, the option taken in this paper and one that is applied only to a small trial selection of texts words for example <REF>Schiitze, 1992</REF> <TREF>Yarowsky, 1995</TREF>	0	These researchers have obtained very high levels of success, in excess of 95, close to the figures for other solved NLP modules, the issue being whether these small word sample methods and techniques will transfer to general WSD over all content words	0	Others, eg	0	0	0
N06-2014	P95-1026	2006	In natural language understanding research with data-driven techniques, data labeling is an essential but time-consuming and costly process	0	To alleviate this effort, various semi-supervised learning algorithms such as self-training <TREF>Yarowsky, 1995</TREF>, cotraining <REF>Blum and Mitchell, 1998</REF>; <REF>Goldman and Zhou, 2000</REF>, transductive SVM <REF>Joachims, 1999</REF> and many others have been proposed and successfully applied under different assumptions and settings	0	They all aim to improve classi cation accuracy by exploiting more readily available unlabeled data as well as labeled examples	0	However, these iterative training methods have shortcomings when trained on data with imbalanced class distributions	0	0	0
W97-1004	P95-1026	1997	To solve the problem, we make use of a kind of cooperative evolution strategy to design an evolutionary algorithm	0	Word compositions have long been a concern in lexicography<REF>Benson et al 1986</REF></REF>; <REF>Miller et al 1995</REF>, and now as a specific kind of lexical knowledge, it has been shown that they have an important role in many areas in natural language processing, eg, parsing, generation, lexicon building, word sense disambiguation, and information retrieving, etceg , <REF>Abney 1989, 1990</REF>; <REF>Benson et al 1986</REF></REF>; <TREF>Yarowsky 1995</TREF>; <REF>Church and Hanks 1989</REF>; Church, <REF>Gale, Hans, and Hindle 1989</REF>	0	But due to the huge number of words, it is impossible to list all compositions between words by hand in dictionaries	0	So an urgent problem occurs: how to automatically acquire word compositions	0	0	0
P07-1004	P95-1026	2007	This is performed on a second development corpus, dev2	0	3 The Framework 31 The Algorithm Our transductive learning algorithm, Algorithm 1, is inspired by the Yarowsky algorithm <TREF>Yarowsky, 1995</TREF>; <REF>Abney, 2004</REF>	0	The algorithm works as follows: First, the translation model is estimated based on the sentence pairs in the bilingual training data L Then, a set of source language sentences, U, is translated based on the current model	0	A subset of good translations and their sources, Ti, is selected in each iteration and added to the training data	0	0	0
N03-4012	P95-1026	2003	Filling the thesaurus: A machine learning algorithm is used to find the relevant thesaurus words from the text data	0	This iterative optimiser, derived from a word disambiguation technique <TREF>Yarowsky, 1995</TREF>, finds the nearest local maximum in the lexical cooccurrence network from each concept seed	0	Early results show that this lexical network can be reduced to a Scale-free and Small-world network1	0	4	0	0	0
E06-3004	P95-1026	2006	<REF>Becker et al , 2005</REF> employed bootstrapping in an active learning method for tagging entities in an astronomic domain	0	<TREF>Yarowsky, 1995</TREF> and <REF>Mihalcea and Moldovan, 2001</REF> utilized bootstrapping for word sense disambiguation	0	<REF>Collins and Singer, 1999</REF> classified NEs through co-training, <REF>Kozareva et al , 2005a</REF> used self-training and cotraining to detect and classify named entities in news domain, <REF>Shen et al , 2004</REF> conducted experimentswithmulti-criteria-basedactivelearning for biomedical NER	0	The experimental data we work with is taken from the CoNLL-2002 competition	0	0	0
P97-1007	P95-1026	1997	5 Comparison with Previous Work Several approaches have been proposed for attaching the correct sense from a set of prescribed ones of a word in context	0	Some of them have been fully tested in real size texts eg statistical methods <REF>Yarowsky, 1992</REF>, <REF>Yarowsky, 1994</REF>, <REF>Miller and Teibel, 1991</REF>, knowledge based methods <REF>Sussna, 1993</REF>, <REF>Agirre and Rigau, 1996</REF>, or mixed methods <REF>Richardson et al , 1994</REF>, <REF>Resnik, 1995</REF>	0	The performance of WSD is reaching a high stance, although usually only small sets of words with clear sense distinctions are selected for disambiguation eg	0	<TREF>Yarowsky, 1995</TREF> reports a success rate of 96 disambiguating twelve words with two clear sense distinctions each one	0	0	0
P97-1007	P95-1026	1997	While the average of senses per noun in DGILE is 18 the average of senses per noun genus is 275 130 and 229 respectively for LPPL	0	Furthermore, it is not possible to apply the powerful one sense per discourse property <TREF>Yarowsky, 1995</TREF> because there is no discourse in dictionaries	0	WSD is a very difficult task even for humans 6, but semiautomatic techniques to disambiguate genus have been broadly used <REF>Amsler, 1981</REF> <REF>Vossen and Serail, 1990</REF> Ageno et ah, 1992 <REF>Artola, 1993</REF> and some attempts to do automatic genus disambiguation have been performed using the semantic codes of the dictionary <REF>Bruce et al , 1992</REF> or using cooccurrence data extracted from the dictionary itself <REF>Wilks et al , 1993</REF>	0	Selecting the correct sense for LDOCE genus terms, <REF>Bruce et al , 1992</REF> report a success rate of 80 90 after hand coding of ten genus	0	0	0
P97-1007	P95-1026	1997	The performance of WSD is reaching a high stance, although usually only small sets of words with clear sense distinctions are selected for disambiguation eg	0	<TREF>Yarowsky, 1995</TREF> reports a success rate of 96 disambiguating twelve words with two clear sense distinctions each one	0	This paper has presented a general technique for WSD which is a combination of statistical and knowledge based methods, and which has been applied to disambiguate all the genus terms in two dictionaries	0	Although this latter task could be seen easier than general WSD 4, genus are usually frequent and general words with high ambiguity 	0	0	0
C98-1066	P95-1026	1998	9 Related work Using vector space model and similarity measures for ranking is a common approach in IR for query/text and text/text comparisons <REF>Salton and Buckley, 1988</REF>; <REF>Salton and Yang, 1973</REF>; <REF>Croft, 1984</REF>; <REF>Turtle and Croft, 1992</REF>; <REF>Bookstein, 1983</REF>; <REF>Korflmge, 1995</REF>; <REF>Jones, 1979</REF>	0	This approach has also been used by <REF>Dagan and Itai, 1994</REF>; <REF>Gale et al, 1992</REF>; <REF>Shiitze, 1992</REF>; <REF>Gale et al, 1993</REF>; <TREF>Yarowsky, 1995</TREF>; Gale and Church, 1Lunar is not an unknown word in English, Yeltsin finds its translation in the 4-th candidate	0	Table 5: Some Chinese unknown word translation output score 0008421 0007895 0007669 0007588 0007283 0006812 0006430 0006218 0005921 0005527 0005335 0005335 0005221 0004731 0004470 0004275 0003878 0003859 0003859 0003784 0003686 0003550 0003519 0003481 0003407 0003407 0OO3338 0003324 0003250 0003206 0003202 0003040 0003033 0002888 0002886 English Chinese Teng-hui  Teng-hui SAR , SAR flu N m, Lei  Lei poultry j Poultry SAR  Chee-hwa hijack  Teng-hui poultry  SAR ,ng  Chee-hw Diaoyu  Teng-hui PrimeMinister  Teng-hui President  Teng-hui China  Lava Lien  Teng-hui poultry  Chee-hwa China  Teng-hui flu  Lei PrivaeMinister -I Chee-hwa President 1; Chee-hwa poultry  Leung Kalkanov i Zhuhai poultry I Lei SAR 1 J l Yeltsin Zhuhai -1 l Chee-hwa PrimeMinister  Lain President  Lava flu  Poultry apologise  Teng-hui Dee  Teng-hui Tang J Tang iSlng  Leung Leung : Leung China tN SAR Zhuhai  Lunar Ttulg  Tung 1994 for sense disambiguation between multiple usages of the same word	0	Some of the early statistical terminology translation methods are <REF>Brown et al, 1993</REF>; <REF>Wu and Xia, 1994</REF>; <REF>Dagan and Church, 1994</REF>; <REF>Gale and Church, 1991</REF>; <REF>Kupiec, 1993</REF>; <REF>Smadja et al, 1996</REF>; Kay and R<REF>Sscheisen, 1993</REF>; <REF>Fung and Church, 1994</REF>; <REF>Fhmg, 1995b</REF>	0	0	0
P01-1026	P95-1026	2001	Although a number of methods have been proposed to generate word senses for example, one based on the vector space model <REF>Schutze, 1998</REF>, it is still difficult to accurately identify word senses without explicit dictionaries that define sense candidates	0	In addition, since word senses are often associated with domains <TREF>Yarowsky, 1995</TREF>, word senses can be consequently distinguished by way of determining the domain of each description	0	For example, different senses for pipeline processing method/transportation pipe are associated with the computer and construction domains fields, respectively	0	To sum up, the organization module classifies term descriptions based on domains, for which we use domain and description models	0	0	0
W04-2312	P95-1026	2004	In general, following <REF>Ide and Veronis 1998</REF> the various WSD approaches of the past can be divided into two types, ie, dataand knowledge-based approaches	0	21 Data-based Methods Data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods <TREF>Yarowsky, 1995</TREF>; <REF>Stevenson, 2003</REF>	0	Supervised methods work with a given and therefore limited set of potential classes in the learning process	0	For example, <REF>Yarowsky 1992</REF> used a thesaurus to generate 1042 statistical models of the most general categories	0	0	0
W04-2312	P95-1026	2004	2 State of the Art After work on WSD had overcome so-called early doubts <REF>Ide and Veronis, 1998</REF> in the 1960s, it was applied to various NLP tasks, such as machine translation, information retrieval, content and grammatical analysis and text processing	0	<TREF>Yarowsky 1995</TREF> used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis	0	However, there is no recorded work on processing speech recognition hypotheses resulting from speech utterances as it is done in our research	0	In general, following <REF>Ide and Veronis 1998</REF> the various WSD approaches of the past can be divided into two types, ie, dataand knowledge-based approaches	0	0	0
P98-1037	P95-1026	1998	However, there are still room for improvement in the area of precision	0	Evidence have shown that by exploiting the constraint of so-called one sense per discourse, <REF>Gale, Church and Yarowsky 1992b</REF> and the strategy of bootstrapping <TREF>Yarowsky 1995</TREF>, it is possible to boost coverage, while maintaining about the same level of precision	0	42 Discussions Although it is often difficult to compare studies on different text domain, genre and experimental setup, the approach presented here seems to compare favorably with the experimental results reported in previous WSD research	0	<REF>Luk 1995</REF> experiments with the same words we use except the word bank and reports that there are totally 616 instances of these words in the Brown corpus, slightly less than the 749 instances we have experimented on	0	0	0
P98-1037	P95-1026	1998	1992a report that if one had obtained a set of training materials with errors no more than twenty to thirty percent, one could iterate training materials selection just once or twice and have training sets that had less than ten percent errors	0	The adaptive approach is somehow similar to their idea of incremental learning and to the bootstrap approach proposed by <TREF>Yarowsky 1995</TREF>	0	However, both approaches are still considered static models which are changed only in the training phase	0	242 6 Conclusions We have described a new adaptive approach to word sense disambiguation	0	0	0
W98-0701	P95-1026	1998	To what extent this assumpI I I I i I I I I I I I I I  I i I I Table 3: Number of words with the same and different sense as its previous occurrence in the same discourse shortened Has predecessor with the same sense Distance anywhere NOUNS  15,373 VERBS 6,923 <10 9,474 3,697 <5 6,892 2,426 5,964 4,797 3,039 <3 <2 2,065 1,578 986 ADJs ADVs 5,523 3812 2,733 1672 1,834 1000 1,566 841 1,219 614 733 348 NOUNS VERBS 2,057 5,227 649 2,521 355 1,561 290 1,269 208 929 103 555 ADJs ADVs 933 830 258 214 104 135 104 82 83 55 42 27 tion holds in real life sentences, however, has yet to be investigated	0	6 Discourse Context <TREF>Yarowsky, 1995</TREF> pointed out that the sense of a target word is highly consistent within any given document one sense per discourse	0	Because our algorithm does not consider the context given by the preceding sentences, we have conducted the following experiment to see to what extent the discourse context could improve the performance of the wordsense disambiguation: Using the semantic concordance files <REF>Miller et al , 1993</REF>, we have counted the occurrences of content words which previously appear in the same discourse file	0	The experiment indicated that the one sense per discourse hypothesis works fairly well for nouns, however, the evidence is much weaker for verbs, adverbs and adjectives	0	0	0
W98-0701	P95-1026	1998	They achieve 905, 925, 948 and 923 percent accuracy in distinguishing between two senses of the noun drug, sentence, suit and player, respectively	0	<TREF>Yarowsky, 1995</TREF>, whose training corpus for the noun drug was 9 times bigger than that of Karov and Edelman, reports 914 correct performance improved to impressive 939 when using the one sense per discourse constraint	0	These methods, however, focus on only two senses of a very limited number of nouns and therefore are not comparable with our approach	0	9 Conclusion This paper presents a new general approach to word sense disambiguation	0	0	0
H05-1046	P95-1026	2005	Work related to toponym tagging has included harvesting of gazetteers from the Web <REF>Uryupina 2003</REF>, hand-coded rules to place name disambiguation, eg, <REF>Li et al 2003</REF> <REF>Zong et al 2005</REF>, and machine learning approaches to the problem, eg, <REF>Smith and Mann 2003</REF>	0	There has of course been a large amount of work on the more general problem of word-sense disambiguation, eg, <TREF>Yarowsky 1995</TREF> <REF>Kilgarriff and Edmonds 2002</REF>	0	We discuss the most relevant work here	0	While <REF>Uryupina 2003</REF> uses machine learning to induce gazetteers from the Internet, we merely download and merge information from two popular Web gazetteers	0	0	0
P03-1008	P95-1026	2003	We use a decision list DL classifier	0	All features encountered in the training data are ranked in the DL best evidence first according to the following loglikelihood ratio <TREF>Yarowsky, 1995</TREF>: Log Prreading i jfeature k  P j6i Prreading j jfeature k  We estimated probabilities via maximum likelihood, adopting a simple smoothing method <REF>Martinez and Agirre, 2000</REF>: 01 is added to both the denominator and numerator	0	The target readings to be distinguished are literal,place-for-people,place-forevent, place-for-product,othermet and mixed	0	All our algorithms are tested on our annotated corpus, employing 10-fold cross-validation	0	0	0
W06-1649	P95-1026	2006	with a de nition or meaning	0	Many corpus based methods have been proposed to deal with the sense disambiguation problem when given de nition for each possible sense of a target word or a tagged corpus with the instances of each possible sense, eg, supervised sense disambiguation <REF>Leacock et al , 1998</REF>, and semi-supervised sense disambiguation <TREF>Yarowsky, 1995</TREF>	0	Supervised methods usually rely on the information from previously sense tagged corpora to determine the senses of words in unseen texts	0	Semi-supervised methods for WSD are characterized in terms of exploiting unlabeled data in the learning procedure with the need of predened sense inventories for target words	0	0	0
W06-1649	P95-1026	2006	Semi-supervised methods for WSD are characterized in terms of exploiting unlabeled data in the learning procedure with the need of predened sense inventories for target words	0	The information for semi-supervised sense disambiguation is usually obtained from bilingual corpora eg parallel corpora or untagged monolingual corpora in two languages <REF>Brown et al , 1991</REF>; <REF>Dagan and Itai, 1994</REF>, or sense-tagged seed examples <TREF>Yarowsky, 1995</TREF>	0	Some observations can be made on the previous supervised and semi-supervised methods	0	They always rely on hand-crafted lexicons eg , WordNet as sense inventories	0	0	0
N03-3004	P95-1026	2003	There is a body of work at the intersection of supervised and unsupervised approaches, which involves using a small amount of training data in order to automatically create more training data, in effect bootstrapping from the small sample of sensetagged data	0	The best example of such an approach is <TREF>Yarowsky, 1995</TREF>, who proposes a method that automatically identifies collocations that are indicative of the sense of a word, and uses those to iteratively label more examples	0	While our focus has been on Pedersen and Bruce, and on Schutze, there has been other work in purely unsupervised approaches to word sense discrimination	0	<REF>Fukumoto and Suzuki, 1999</REF> describe a method for discriminating among verb senses based on determining which nouns cooccur with the target verb	0	0	0
W06-0208	P95-1026	2006	These results show that our approach for learning IE patterns from a large, diverse text collection the Web can indeed improve coverage on a domain-specific IE task, with a small decrease in precision	0	Unannotated texts have been used successfully for a variety of NLP tasks, including named entity recognition <REF>Collins and Singer, 1999</REF>, subjectivity classification <REF>Wiebe and Riloff, 2005</REF>, text classification <REF>Nigam et al , 2000</REF>, and word sense disambiguation <TREF>Yarowsky, 1995</TREF>	0	The Web has become a popular choice as a resource for large quantities of unannotated data	0	Many research ideas have exploited the Web in unsupervised or weakly supervised algorithms for natural language processing eg , <REF>Resnik 1999</REF>, <REF>Ravichandran and Hovy 2002</REF>, <REF>Keller and Lapata 2003</REF>	0	0	0
W06-0208	P95-1026	2006	Consequently, the IE patterns learned from manually annotated training sets typically represent only a subset of the IE patterns that could be useful for the task	0	Many recent approaches in natural language processing <TREF>Yarowsky, 1995</TREF>; <REF>Collins and Singer, 1999</REF>; <REF>Riloff and Jones, 1999</REF>; <REF>Nigam et al , 2000</REF>; <REF>Wiebe and Riloff, 2005</REF> have recognized the need to use unannotated data to improve performance	0	While the Web provides a vast repository of unannotated texts, it is non-trivial to identify texts that belong to a particular domain	0	The difficulty is that web pages are not specifically annotated with tags categorizing their content	0	0	0
C02-1097	P95-1026	2002	Contextual words nearby a target word give more relevant information to decide its sense than those far from it	0	Distance from a target word is used for this purpose and it is calculated by the assumption that the target words in the context window have the same sense <TREF>Yarowsky, 1995</TREF>	0	Each word in the training samples can be weighted by formula 1	0	Let W ij t k  represent a weighting function for a term t k, which appears in the j th training sample for the i th sense, tf ijk 5 POS, collocations, semantic word associations, subcategorization information, semantic roles, selectional preferences and frequency of senses are useful for WSD <REF>Agirre et al , 2001</REF>	0	0	0
I05-3009	P95-1026	2005	1 Domain Specific Words and Lexicon Trees as Important NLP Resources Domain specific words DSWs are important anchoring words for natural language processing applications that involve word sense disambiguation WSD	0	It is appreciated that multi-sense words appearing in the same document tend to be tagged with the same word sense if they belong to the same common domain in the semantic hierarchy <TREF>Yarowsky, 1995</TREF>	0	The existence of some DSWs in a document will therefore be a strong evidence of a specific sense for words within the document	0	For instance, the existence of basketball in a document would strongly suggest the sport sense of the word  R Pistons, rather than its mechanics sense	0	0	0
C00-1023	P95-1026	2000	Having all improved knowledge alout the selectional 1references would then provide better parameters for disanfliguation	0	The model can be seen as a bootstrapping learning process tbr disambiguation, where the information gained from one part selectional preference is used to improve tile other disambiguation and vice versa, reminiscent of the work by Riloff and Jones 1999 and <TREF>Yarowsky 1995</TREF>	0	Lastly, the techniques used in this paper could be scaled to disambiguate not only all adjective-noun pairs, but also other word pairs, such as subjectverb, verb-object, adverb-verb, by obtaining most of the paraineters from the Internet and WordNet	0	If the information fioln SemCor is also used, then the system could be automatically trained to pertbrm disambiguation tasks on all content words within a SellteI1Ce	0	0	0
C00-1023	P95-1026	2000	More recent works take advantage of machine readable dictionaries such as WordNet <REF>Miller, 1990</REF> and Rogets Online Thesaurus	0	Statistical techniques, both supervised learning from tagged corpora <REF>Yarowsky, 1992</REF>, Ng and Lee, 1996, and unsupervised learning <TREF>Yarowsky, 1995</TREF>, <REF>Resnik, 1997</REF>, have been investigated	0	There are also hybrid inodcls that incorporate both statistical and symbolic knowledge <REF>Wiebe et al , 1998</REF>, <REF>Agirre and Iigau, 1996</REF>	0	Supervised models have shown promising results, but the lack of sense tagged corpora often requires the need tbr laboriously tagging trailfing sets manually	0	0	0
P03-1042	P95-1026	2003	In their algorithm of co-training, one classifier always asks the other classifier to label the most certain instances for the collaborator	0	The word sense disambiguation method proposed in <TREF>Yarowsky 1995</TREF> can also be viewed as a kind of co-training	0	Since the assumption of view independence cannot always be met in practice, <REF>Collins and Singer 1998</REF> proposed a co-training algorithm based on agreement between the classifiers	0	As for theoretical analysis, Dasgupta et al	0	0	0
W03-0106	P95-1026	2003	Knowledge-based work, such as <REF>Hirst 1987</REF>; <REF>McRoy 1992</REF>; <REF>Ng and Lee 1996</REF> used hand-coded rules or supervised machine learning based on an annotated corpus to perform WSD	0	Recent work emphasizes a corpus-based unsupervised approach <REF>Dagon and Itai 1994</REF>; <REF>Yarowsky 1992</REF>; <TREF>Yarowsky 1995</TREF> that avoids the need for costly truthed training data	0	Location normalization is different from general WSD in that the selection restriction often used for WSD in many cases is not sufficient to distinguish the correct sense from the other candidates	0	For example, in the sentence The White House is located in Washington, the selection restriction from the collocation located in can only determine that Washington should be a location name, but is not sufficient to decide the actual sense of this location	0	0	0
N04-2003	P95-1026	2004	Semantic analysis is an open research field in natural language processing	0	Two major research topics in this field are Named Entity Recognition NER N <REF>Wacholder and Choi, 1997</REF>; <REF>Cucerzan and Yarowsky, 1999</REF> and Word Sense Disambiguation WSD <TREF>Yarowsky, 1995</TREF>; <REF>Wilks and Stevenson, 1999</REF>	0	NER identifies different kinds of names such as person,location or date, while WSD distinguishes the senses of ambiguous words	0	For example, bank can be labeled as financial institution or edge of a river	0	0	0
W05-0605	P95-1026	2005	To overcome the Knowledge Bottleneck, unsupervised or weakly supervised learning approaches have been proposed	0	These include the bootstrapping approach <TREF>Yarowsky 1995</TREF> and the context clustering approach <REF>Schtze 1998</REF>	0	The above unsupervised or weakly supervised learning approaches are less subject to the Knowledge Bottleneck	0	For example, <TREF>Yarowsky 1995</TREF> only requires sense number and a few seeds for each sense of an ambiguous word hereafter called keyword	0	0	0
W05-0605	P95-1026	2005	The above unsupervised or weakly supervised learning approaches are less subject to the Knowledge Bottleneck	0	For example, <TREF>Yarowsky 1995</TREF> only requires sense number and a few seeds for each sense of an ambiguous word hereafter called keyword	0	<REF>Schtze 1998</REF> may only need minimal annotation to map the resulting context clusters onto external thesaurus for benchmarking and application-related purposes	0	Both methods are based on trigger words only	0	0	0
W03-1611	P95-1026	2003	This problem is similar to word sense ambiguities, which have been studied for many years	0	To solve this problem, we adopt an idea one sense per collocation which was introduced in word sense disambiguation research <TREF>Yarowsky, 1995</TREF>	0	Considering a newspaper article in which the retrieved passage and the input noun phrase is included as the context, the context similarity is taken into account for ranking paraphrase candidates	0	More concretely, context similarity is calculated by following procedure	0	0	0
P02-1044	P95-1026	2002	Although BB is a method nearly equivalent to one based on unsupervised learning, it still performs favorably well when compared with the supervised methods note that since the experimental settings are different, the results cannot be directly compared	0	62 Experiment 2: Yarowskys Words We also conducted translation on seven of the twelve English words studied in <TREF>Yarowsky, 1995</TREF>	0	Table 5 shows the list of the words	0	For each of the words, we extracted about 200 sentences containing the word from the Encarta 4 English corpus and labeled those sentences with Chinese translations ourselves	0	0	0
P02-1044	P95-1026	2002	That is, it employs as a classifier a decision list instead of an ensemble of NBCs	0	This implementation is exactly the one proposed in <TREF>Yarowsky 1995</TREF>, and we will denote it as MB-D hereafter	0	MB-B and MB-D can be viewed as the state-of-the-art methods for word translation disambiguation using bootstrapping	0	6 Experimental Results M M M M o o oo oo oo oo o o o o o oo o oo o o o o             Figure 5: Example of BB We conducted two experiments on English-Chinese translation disambiguation	0	0	0
P02-1044	P95-1026	2002	Since preparing supervised learning data is expensive in many cases, manually labeling data is required, it is desirable to develop a bootstrapping method that starts learning with a small number of classified data but is still able to achieve high performance under the help of a large number of unclassified data which is not expensive anyway	0	<TREF>Yarowsky 1995</TREF> proposes a method for word sense disambiguation, which is based on Monolingual Bootstrapping	0	When applied to our current task, his method starts learning with a small number of English sentences which contain an ambiguous English word and which are respectively assigned with the correct Chinese translations of the word	0	It then uses the classified sentences as training data to learn a classifier eg , a decision list and uses the constructed classifier to classify some unclassified sentences containing the ambiguous word as additional training data	0	0	0
P02-1044	P95-1026	2002	Word translation disambiguation is actually a special case of word sense disambiguation in the example above, gongchang corresponds to the sense of factory and zhiwu corresponds to the sense of vegetation	0	1 <TREF>Yarowsky 1995</TREF> proposes a method for word sense translation disambiguation that is based on a bootstrapping technique, which we refer to here as Monolingual Bootstrapping MB	0	In this paper, we propose a new method for word translation disambiguation using a bootstrapping technique we have developed	0	We refer to the technique as Bilingual Bootstrapping BB	0	0	0
P02-1044	P95-1026	2002	We will describe the results in detail in the full version of this paper	0	Note that the results of MB-D here cannot be directly compared with those in <TREF>Yarowsky, 1995</TREF>, mainly because the data used are different	0	63 Discussions We investigated the reason of BBs outperforming MB and found that the explanation on the reason in Section 4 appears to be true according to the following observations	0	1 In a Nave Bayesian Classifier, words having large values of probability ratio   teP teP have strong influence on the classification of t when they occur, particularly, when they frequently occur	0	0	0
P02-1044	P95-1026	2002	2 It employs the heuristics of one sense per discourse cf	0	, <TREF>Yarowsky 1995</TREF> after using an ensemble of NBCs	0	3 It uses only classified data in English at the beginning	0	4 It individually resolves ambiguities on selected English words such as plant, interest	0	0	0
P02-1044	P95-1026	2002	Each of the seed words was then used as a classified sentence	0	This way of creating classified data is similar to that in <TREF>Yarowsky, 1995</TREF>	0	As unclassified data in English, we collected sentences in news articles from a web site wwwnewscom, and as unclassified data in Chinese, we collected sentences in news articles from another web site newscntomcom	0	We observed that the distribution of translations in the unclassified data was balanced	0	0	0
H05-1017	P95-1026	2005	The IL approach reflects on classical rule-based classification methods, where the user is expected to specify exact classification rules that operate in the feature space	0	Within the machine learning paradigm, IL has been incorporated as a technique for bootstrapping an extensional learning algorithm, as in <TREF>Yarowsky, 1995</TREF>; <REF>Collins and Singer, 1999</REF>; <REF>Liu et al , 2004</REF>	0	This way the user does not need to specify exact classification rules and feature weights, but rather perform a somewhat simpler task of specifying few typical seed features for the category	0	Given the list of seed features, the bootstrapping scheme consists of i preliminary unsupervised categorization of the unlabeled data set based on the seed features, and ii training an extensional supervised classifier using the automatic classification labels of step i as the training data the second step is possibly reiterated, such as by an Expectation-Maximization schema	0	0	0
H05-1017	P95-1026	2005	Several names have been proposed for it  such as TC by bootstrapping with keywords, unsupervised TC, TC by labelling words  where the proposed methods fall mostly within the IL settings described here1	0	It is possible to recognize a common structure of these works, based on a typical bootstrap schema <TREF>Yarowsky, 1995</TREF>; <REF>Collins and Singer, 1999</REF>: Step 1: Initial unsupervised categorization	0	This step was approached by applying some similarity criterion between the initial category seed and each unlabeled document	0	Similarity may be determined as a binary criterion, considering each seed keyword as a classification rule <REF>McCallum and Nigam, 1999</REF>, or by applying an IR style vector similarity measure	0	0	0
W03-0407	P95-1026	2003	However, we find that simply re-training on all the newly labelled data can, in some cases, yield comparable results to agreement-based co-training, with only a fraction of the computational cost	0	Co-training <REF>Blum and Mitchell, 1998</REF>, and several variants of co-training, have been applied to a number of NLP problems, including word sense disambiguation <TREF>Yarowsky, 1995</TREF>, named entity recognition <REF>Collins and Singer, 1999</REF>, noun phrase bracketing <REF>Pierce and Cardie, 2001</REF> and statistical parsing <REF>Sarkar, 2001</REF>; <REF>Steedman et al , 2003</REF>	0	In each case, co-training was used successfully to bootstrap a model from only a small amount of labelled data and a much larger pool of unlabelled data	0	Previous co-training approaches have typically used the score assigned by the model as an indicator of the reliability of a newly labelled example	0	0	0
P98-2182	P95-1026	1998	Utilizing existing resources, such as on-line corpora, to aid in this task could improve performance both by decreasing the time to construct the lexicon and by improving its quality	0	Extracting semantic information from word co-occurrence statistics has been effective, particularly for sense disambiguation <REF>Schiitze, 1992</REF>; <REF>Gale et al , 1992</REF>; <TREF>Yarowsky, 1995</TREF>	0	<REF>In Riloff and Shepherd 1997</REF>, noun co-occurrence statistics were used to indicate nominal category membership, for the purpose of aiding in the construction of semantic lexicons	0	Generically, their algorithm can be outlined as follows: 1	0	0	0
W07-2051	P95-1026	2007	We discuss each in turn below	0	31 Collocation Features The collocation features were inspired by the one-sense-per-collocation heuristic proposed by <TREF>Yarowsky 1995</TREF>	0	These features were designed to capture open class words that exhibit strong collocation properties with respect to the different senses of the target preposition	0	Details of the features in this category are listed below	0	0	0
J98-4002	P95-1026	1998	Thereafter, samples are simply incorporated into the database without any computational overhead as would be associated with globally reestimating parameters in statistics-based systems, meaning that the system can be trained on the remaining examples the residue for the next iteration	0	Iterating between these two 1 Note that these problems are associated with corpus-based approaches in general, and have been identified by a number of researchers <REF>Engelson and Dagan 1996</REF>; <REF>Lewis and Gale 1994</REF>; <REF>Uramoto 1994a</REF>; <TREF>Yarowsky 1995</TREF>	0	574 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling sampling WSDsD out ut : Figure 1 Flow of control of the example sampling system	0	phases, the system progressively enhances the database	0	0	0
J98-4002	P95-1026	1998	Word sense disambiguation is a potentially crucial task in many NLP applications, such as machine translation Brown, Della Pietra, and <REF>Della Pietra 1991</REF>, parsing <REF>Lytinen 1986</REF>; <REF>Nagao 1994</REF> and text retrieval <REF>Krovets and Croft 1992</REF>; <REF>Voorhees 1993</REF>	0	Various corpus-based approaches to word sense disambiguation have been proposed <REF>Bruce and Wiebe 1994</REF>; <REF>Charniak 1993</REF>; <REF>Dagan and Itai 1994</REF>; <REF>Fujii et al 1996</REF>; <REF>Hearst 1991</REF>; <REF>Karov and Edelman 1996</REF>; <REF>Kurohashi and Nagao 1994</REF>; <REF>Li, Szpakowicz, and Matwin 1995</REF>; <REF>Ng and Lee 1996</REF>; <REF>Niwa and Nitta 1994</REF>; Schitze 1992; <REF>Uramoto 1994b</REF>; <TREF>Yarowsky 1995</TREF>	0	The use of corpus-based approaches has grown with the use of machine-readable text, because unlike conventional rule-based approaches relying on hand-crafted selectional rules some of which are reviewed, for example, by Hirst 1987, corpus-based approaches release us from the task of generalizing observed phenomena through a set of rules	0	Our verb sense disambiguation system is based on such an approach, that is, an example-based approach	0	0	0
J98-4002	P95-1026	1998	First, since inputs are simple sentences, information for word sense disambiguation is inadequate in some cases	0	External information such as the discourse or domain dependency of each word sense <REF>Guthrie et al 1991</REF>; <REF>Nasukawa 1993</REF>; <TREF>Yarowsky 1995</TREF> is expected to lead to system improvement	0	Second, some idiomatic expressions represent highly restricted collocations, and overgeneralizing them semantically through the use of a thesaurus can cause further errors	0	Possible solutions would include one proposed by Uramoto, in which idiomatic expressions are described separately in the database so that the system can control their overgeneralization <REF>Uramoto 1994b</REF>	0	0	0
J03-3002	P95-1026	2003	We might then iteratively select additional page pairs in which the current classifier has high confidence of translational equivalence, gradually increasing the pool of parallel data and at the same time expanding the bilingual lexicon	0	This approach to minimally supervised classifier construction has been widely studied <TREF>Yarowsky 1995</TREF>, especially in cases in which the features of interest are orthogonal in some sense eg , <REF>Blum and Mitchell 1998</REF>; <REF>Abney 2002</REF>	0	With respect to the generation of candidate pairs, we have described a progression from index-based searches on AltaVista to exhaustive matching of URLs on the Internet Archive	0	The combination of these approaches may be profitable, particularly for languages that are represented only very sparsely on the Web	0	0	0
I08-1040	P95-1026	2008	As we do not use multiple classifiers our approach is quite far from cotraining	0	But it is close to the paradigm described by <TREF>Yarowsky 1995</TREF> and <REF>Turney 2002</REF> as it also employs self-training based on a relatively small seed data set which is incrementally enlarged with unlabelled samples	1	But our approach does not use point-wise mutual information	0	Instead we use relative frequencies of newly found features in a training subcorpus produced by the previous iteration of the classifier	0	2	2
N07-3002	P95-1037	2007	Finally, I present a simpler and more efcient approach to training dependency parsers by applying a boosting-like procedure to standard training methods	1	Over the past decade, there has been tremendous progress on learning parsing models from treebank data <TREF>Magerman, 1995</TREF>; <REF>Collins, 1999</REF>; <REF>Charniak, 1997</REF>; <REF>Ratnaparkhi, 1999</REF>; <REF>Charniak, 2000</REF>; <REF>Wang et al , 2005</REF>; <REF>McDonald et al , 2005</REF>	1	Most of the early work in this area was based on postulating generative probability models of language that included parse structures <TREF>Magerman, 1995</TREF>; <REF>Collins, 1997</REF>; <REF>Charniak, 1997</REF>	0	Learning in this context consisted of estimating the parameters of the model with simple likelihood based techniques, but incorporating various smoothing and back-off estimation tricks to cope with the sparse data problems <REF>Collins, 1997</REF>; <REF>Bikel, 2004</REF>	0	5	2
N07-3002	P95-1037	2007	Over the past decade, there has been tremendous progress on learning parsing models from treebank data <TREF>Magerman, 1995</TREF>; <REF>Collins, 1999</REF>; <REF>Charniak, 1997</REF>; <REF>Ratnaparkhi, 1999</REF>; <REF>Charniak, 2000</REF>; <REF>Wang et al , 2005</REF>; <REF>McDonald et al , 2005</REF>	0	Most of the early work in this area was based on postulating generative probability models of language that included parse structures <TREF>Magerman, 1995</TREF>; <REF>Collins, 1997</REF>; <REF>Charniak, 1997</REF>	1	Learning in this context consisted of estimating the parameters of the model with simple likelihood based techniques, but incorporating various smoothing and back-off estimation tricks to cope with the sparse data problems <REF>Collins, 1997</REF>; <REF>Bikel, 2004</REF>	0	Subsequent research began to focus more on conditional models of parse structure given the input sentence, which allowed discriminative training techniques such as maximum conditional likelihood ie maximum entropy  to be applied <REF>Ratnaparkhi, 1999</REF>; <REF>Charniak, 2000</REF>	0	5	2
N07-3002	P95-1037	2007	The advantage of this approach is that it does not rely on part-ofspeech tags nor grammatical categories	0	Furthermore, I based training on maximizing the conditional probability of a parse tree given a sentence, unlike most previous generative models <TREF>Magerman, 1995</TREF>; <REF>Collins, 1997</REF>; <REF>Charniak, 1997</REF>, which focus on maximizing the joint probability of the parse tree and the sentence	1	An ef cient training algorithm can be achieved by maximizing the conditional probability of each parsing decision, hence minimizing a loss based on each local link decision independently	0	Importantly, inter-dependence between links can still be accommodated by exploiting dynamic features in training features that take into account the labels of some of the surrounding components when predicting the label of a target component	0	2	1
W07-1001	P95-1037	2007	3 she was a cook in a school cafeteria 1 Figure 3: Dependency graph for the example string	0	tributed to <TREF>Magerman 1995</TREF>, to percolate lexical heads up the tree	1	Figure 3 shows the dependency graph that results from this head percolation approach, where each link in the graph represents a dependency relation from the modifier to the head	0	For example, conventional head percolation rules specify the VP as the head of the S, so was	0	6	1
W03-1119	P95-1037	2003	The decision tree approach has been used in parsing sentence	0	D <TREF>Magerman, 1995</TREF>Ulf Hermijakob and J<REF>Mooney, 1997</REF> to define the rhetorical of text documents <REF>Daniel Marcu, 1999</REF>	1	Most of the previous methods only produce a short sentence whose word order is the same as that of the original sentence, and in the same language, eg, English	0	When nonnative speaker reduce a long sentence in foreign language, they usually try to link the meaning of words within the original sentence into meanings in their language	0	6	1
P96-1008	P95-1037	1996	Unlike probabilities in the parsing model, there obviously is not sufficient training data to estimate slot fill probabilities directly	0	Instead, these probabilities are estimated by statistical decision trees similar 58 to those used in the Spatter parser <TREF>Magerman 1995</TREF>	1	Unlike more common decision tree classifiers, which simply classify sets of conditions, statistical decision trees give a probability distribution over all possible outcomes	0	Statistical decision trees are constructed in a two phase process	0	2	1
P96-1008	P95-1037	1996	A recent trend in natural language processing has been toward a greater emphasis on statistical approaches, beginning with the success of statistical part-of-speech tagging programs <REF>Church 1988</REF>, and continuing with other work using statistical part-of-speech tagging programs, such as BBN PLUM <REF>Weischedel et al 1993</REF> and NYU Proteus <REF>Grishman and Sterling 1993</REF>	0	More recently, statistical methods have been applied to domain-specific semantic parsing <REF>Miller et al 1994</REF>, and to the more difficult problem of wide-coverage syntactic parsing <TREF>Magerman 1995</TREF>	1	Nevertheless, most natural language systems remain primarily rule based, and even systems that do use statistical techniques, such as ATT Chronus <REF>Levin and Pieraccini 1995</REF>, continue to require a significant rule based component	0	Development of a complete end-to-end statistical understanding system has been the focus of several ongoing research efforts, including <REF>Miller et al 1995</REF> and <REF>Koppelman et al 1995</REF>	0	4	2
P96-1008	P95-1037	1996	In the second phase, these distributions are smoothed by mixing together distributions of various nodes in the decision tree	1	As in <TREF>Magerman 1995</TREF>, mixture weights are determined by deleted interpolation on a separate block of training data	1	43 Searching the Semantic Interpretation Model Searching the interpretation model proceeds in two phases	0	In the first phase, every parse T received from the parsing model is rescored for every possible frame type, computing PT I FT our current model includes only a half dozen different types, so this computation is tractable	0	4	2
P98-2214	P95-1037	1998	In empirical approaches to parsing, lexical/semantic collocation extracted from corpus has been proved to be quite useful for ranking parses in syntactic analysis	1	For example, <TREF>Magerman 1995</TREF>, <REF>Collins 1996</REF>, and <REF>Charniak 1997</REF> proposed statistical parsing models which incorporated lexical/semantic information	1	In their models, syntactic and lexical/semantic features are dependent on each other and are combined together	0	This paper also proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis	0	4	2
P98-2214	P95-1037	1998	This paper also proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis	0	However, unlike the models of <TREF>Magerman 1995</TREF>, <REF>Collins 1996</REF>, and <REF>Charniak 1997</REF>, we assume that syntactic and lexical/semantic features are independent	1	Then, we focus on extracting lexical/semantic collocational knowledge of verbs which is useful in syntactic analysis	0	More specifically, we propose a novel method for learning a probability model of subcategorization preference of verbs	0	2	1
P06-2041	P95-1037	2006	Deterministic parsing algorithms for building dependency graphs <REF>Kudo and Matsumoto, 2002</REF>; <REF>Yamada and Matsumoto, 2003</REF>; <REF>Nivre, 2003</REF> 2	0	History-based models for predicting the next parser action <REF>Black et al , 1992</REF>; <TREF>Magerman, 1995</TREF>; <REF>Ratnaparkhi, 1997</REF>; <REF>Collins, 1999</REF> 3	1	Discriminative learning to map histories to parser actions <REF>Kudo and Matsumoto, 2002</REF>; <REF>Yamada and Matsumoto, 2003</REF>; <REF>Nivre et al , 2004</REF> In this section we will define dependency graphs, describe the parsing algorithm used in the experiments and finally explain the extraction of features for the history-based models	0	21 Dependency Graphs A dependency graph is a labeled directed graph, the nodes of which are indices corresponding to the tokens of a sentence	0	6	1
P98-1083	P95-1037	1998	We will discuss the maximum accuracy of 8433	0	Compared to recent stochastic English parsers that yield 86 to 87 accuracy <REF>Collins, 1996</REF>; <TREF>Magerman, 1995</TREF>, 8433 seems unsatisfactory at the first glance	1	The main reason behind this lies in the difference between the two corpora used: Penn Treebank <REF>Marcus et al , 1993</REF> and EDR corpus EDR, 1995	0	Penn Treebank<REF>Marcus et al , 1993</REF> was also used to induce part-of-speech POS taggers because the corpus contains very precise and detailed POS markers as well as bracket, annotations	0	1	3
P98-1083	P95-1037	1998	A broader range of information, in particular lexical information, was found to be essential in disambiguating the syntactic structures of real-world sentences	1	SPATTER <TREF>Magerman, 1995</TREF> augmented the pure PCFG by introducing a number of lexical attributes	1	The parser controlled applications of each rule by using the lexical constraints induced by decision tree algorithm <REF>Quinlan, 1993</REF>	0	The SPATTER parser attained 87 accuracy and first made stochastic parsers a practical choice	0	4	2
W97-0105	P95-1037	1997	It is not surprising, then, that the per-sentence parsing acclzracy suffers when parses are predicted from raw text	0	Clearly the present research task is quite considerably harder than the parsing and tagging tasks undertaken in <REF>Jelinek et al , 1994</REF>; <TREF>Magerman, 1995</TREF>; <REF>Black et al , 1993b</REF>, which would seem to be the closest work to ours, and any comparison between this work and ours must be approached with extreme caution	1	Table 3 shows the differences between the treebank utilized in <REF>Jelinek et al , 1994</REF> on the one hand, and in the work reported here, on the other, is Table 4 shows relevant lSFigures for Average Sentence Length lraLuing Corpus and Training Set Size, for the IBM ManuaLs Corpus, are approximate, and cze fzom Black et aL, 1993a	0	24 Length 1-10 11-15 16-23 sentences ltpltp20 447 559 808 436 i47d 66 430 1216 488 cross constits/sent 915 46 8O7 82 565 113 Table 4: Parsing results reported by Jelinek et	0	2	1
W97-0105	P95-1037	1997	Probabilistic decision trees are utilized as a means of prediction, roughly as in <REF>Jelinek et al , 1994</REF>; <REF>Magermau, 1995</REF>, and as in these references, training is supervised, and in particular is treebank-based	0	In all other respects, our work departs from previous research on broad--coverage 16 I t I I I I I i  I i I I I I I I I I I I I i I 1, I I I I I i I 1 I I I I probabilistic parsing, which either attempts to learn to predict grrarntical structure of test data directly from a training treebank <REF>Brill, 1993</REF>; <REF>Collins, 1996</REF>; <REF>Eisner, 1996</REF>; <REF>Jelinek et al , 1994</REF>; <TREF>Magerman, 1995</TREF>; Skine and <REF>Orishman, 1995</REF>; <REF>Sharman et al , 1990</REF>, or employs a grammar and sometimes a dictionary to capture linguistic expertise directly <REF>Black et al , 1993a</REF>; <REF>GrinBerg et al , 1995</REF>; Schabes; 1992, but arguably at a less detailed and informative level than in the research reported here	1	In what follows, Section 2 explains the contribution to the prediction process of the grammar and of the lexical generalizations created by our grammarian	0	Section 3 shows; from a formal standpoint, how prediction is carried out, and more generally how the parser operates	0	2	1
P06-1110	P95-1037	2006	 Convert PRT to ADVP	0	This convention was established by <TREF>Magerman 1995</TREF>	1	3	0	Remove quotation marks ie terminal items tagged  or 	0	6	1
P01-1010	P95-1037	2001	Head-lexicalized stochastic grammars have recently become increasingly popular see <REF>Collins 1997, 1999</REF>; <REF>Charniak 1997, 2000</REF>	1	These grammars are based on Magermans headpercolation scheme to determine the headword of each nonterminal <TREF>Magerman 1995</TREF>	1	Unfortunately this means that head-lexicalized stochastic grammars are not able to capture dependency relations between words that according to Magermans head-percolation scheme are nonheadwords -eg between more and than in the WSJ construction carry more people than cargo where neither more nor than are headwords of the NP constituent more people than cargo	1	A frontier-lexicalized DOP model, on the other hand, captures these dependencies since it includes subtrees in which more and than are the only frontier words	0	1	3
E99-1025	P95-1037	1999	In the first pass, it tags words as either head words or non-head words	0	Training data for this pass is obtained using a head percolation table <TREF>Magerman 1995</TREF> on bracketed Penn Treebank sentences	1	After training, head tagging is performed according to Equation 1, where 15 is the estimated probability and Hi is a characteristic function which is true iff word i is a head word	0	n H  argmaxH HwilHiHilHi-1Hi-2 i1 1 The second pass then takes the words with this head information and supertags them according to Equation 2, where tHio is the supertag of the ePart of speech tagging models have not used heads in this manner to achieve variable length contexts	0	4	2
E99-1025	P95-1037	1999	There have been two main robust parsing paradigms: Finite State Grammar-based approaches such as <REF>Abney 1990</REF>, <REF>Grishman 1995</REF>, and Hobbs et al	1	1997 and Statistical Parsing such as <REF>Charniak 1996</REF>, <TREF>Magerman 1995</TREF>, and <REF>Collins 1996</REF>	1	<REF>Srinivas 1997a</REF> has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of statistical techniques	0	The idea underlying the approach is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions Supertags that impose complex constraints in a local context	0	4	2
W06-1638	P95-1037	2006	<REF>Collins 1996</REF> split the sentence label S into two versions, representing sentences with and without subjects	0	He 1Not to mention earlier non-PCFG lexicalized statistical parsers, notably <TREF>Magerman 1995</TREF> for the Penn Treebank	1	also modified the treebank to contain different labels for standard and for base noun phrases	0	<REF>Klein and Manning 2003</REF> identified nonterminals that could valuably be split into fine-grained ones using hand-written linguistic rules	0	6	1
P98-1091	P95-1037	1998	Second, one might propagate lexical information upward through the productions	1	Examples of formalisms using this approach include the work of <TREF>Magerman 1995</TREF>, <REF>Charniak 1997</REF>, <REF>Collins 1997</REF>, and <REF>Goodman 1997</REF>	1	A more linguistically motivated approach is to expand the domain of productions downward to incorporate more tree structures	0	The Lexicalized Tree-Adjoining Grammar LTAG formalism <REF>Schabes et al , 1988</REF>, <REF>Schabes, 1990</REF>, although not context-free, is the most well-known instance in this category	0	4	2
W96-0211	P95-1037	1996	Standard symbolic machine learning techniques have been successfully applied to a number of tasks in natural language processing NLP	1	Examples include the use of decision trees for syntactic analysis <TREF>Magerman, 1995</TREF>, coreference <REF>Aone and Bennett, 1995</REF>; <REF>McCarthy and Lehnert, 1995</REF>, and cue phrase identification <REF>Litman, 1994</REF>; the use of inductive logic programming for learning semantic grammars and building prolog parsers 113 <REF>Zelle and Mooney, 1994</REF>; <REF>Zelle and Mooney, 1993</REF>; the use of conceptual clustering algorithms for relative pronoun resolution <REF>Cardie, 1992a</REF>; <REF>Cardie 1992b</REF>, and the use of case-based learning techniques for lexical tagging tasks <REF>Cardie, 1993a</REF>; Daelemans et al , submitted	1	In theory, both statistical and machine learning techniques can significantly reduce the knowledge-engineering effort for building large-scale NLP systems: they offer an automatic means for acquiring robust heuristics for a host of lexical and structural disambiguation tasks	0	It is well-known in the machine learning community, however, that the success of a learning algorithm depends critically on the representation used to describe the training and test instances <REF>Almuallim and Dietterich, 1991</REF>, Langley and Sage, in press	0	4	2
J03-4003	P95-1037	2003	1994, and <TREF>Magerman 1995</TREF>	0	A strength of these models is undoubtedly the powerful estimation techniques that they use: maximum-entropy modeling in <REF>Ratnaparkhi 1997</REF> or decision trees in <REF>Jelinek et al 1994</REF> and <TREF>Magerman 1995</TREF>	1	A weakness, we will argue in this section, is the method of associating parameters with transitions taken by bottom-up, shift-reduce-style parsers	0	We give examples in which this method leads to the parameters unnecessarily fragmenting the training data in some cases or ignoring important context in other cases	0	1	2
J03-4003	P95-1037	2003	3 We find lexical heads in Penn Treebank data using the rules described in Appendix A of <REF>Collins 1999</REF>	1	The rules are a modified version of a head table provided by David Magerman and used in the parser described in <TREF>Magerman 1995</TREF>	1	593 Collins Head-Driven Statistical Models for NL Parsing Internal rules Lexical rules TOP  S JJ  Last S  NP NP VP NN  week NP  JJ NN NNP  IBM NP  NNP VBD  bought VP  VBD NP NNP  Lotus NP  NNP Figure 1 A nonlexicalized parse tree and a list of the rules it contains	0	Internal Rules: TOP  Sbought,VBD Sbought,VBD  NPweek,NN NPIBM,NNP VPbought,VBD NPweek,NN  JJLast,JJ NNweek,NN NPIBM,NNP  NNPIBM,NNP VPbought,VBD  VBDbought,VBD NPLotus,NNP NPLotus,NNP  NNPLotus,NNP Lexical Rules: JJLast,JJ  Last NNweek,NN  week NNPIBM,NNP  IBM VBDbought,VBD  bought NNPLotus,NN  Lotus Figure 2 A lexicalized parse tree and a list of the rules it contains	0	4	2
J03-4003	P95-1037	2003	Similar observations have been made in the context of tagging problems using maximum-entropy models <REF>Lafferty, McCallum, and Pereira 2001</REF>; <REF>Klein and Manning 2002</REF>	1	We first analyze the model of <TREF>Magerman 1995</TREF> through three common examples of ambiguity: PP attachment, coordination, and appositives	1	In each case a word sequence S has two competing structures, T 1 and T 2, with associated decision sequences d 1,  , d n  and e 1,  , e m , respectively	0	Thus the probability of the two structures can be written as PT 1 S productdisplay i1n Pd i d 1 d i1, S PT 2 S productdisplay i1m Pe i e 1 e i1, S It will be useful to isolate the decision between the two structures to a single probability term	0	6	1
J03-4003	P95-1037	2003	<REF>Charniak 2000</REF> describes a series of enhancements to the earlier model of <REF>Charniak 1997</REF>	0	The precision and recall of the traces found by Model 3 were 938 and 901, respectively out of 437 cases in section 23 of the treebank, where three criteria must be met for a trace to be correct: 1 It must be an argument to the correct headword; 2 It must be in the correct position in relation to that headword preceding or following; 15 <TREF>Magerman 1995</TREF> collapses ADVP and PRT into the same label; for comparison, we also removed this distinction when calculating scores	1	608 Computational Linguistics Volume 29, Number 4 Table 2 Results on Section 23 of the WSJ Treebank	0	LR/LP  labeled recall/precision	0	2	2
J03-4003	P95-1037	2003	82 A Comparison to the Models of Jelinek et al	0	1994, <TREF>Magerman 1995</TREF>, and <REF>Ratnaparkhi 1997</REF></REF> We now make a detailed comparison of our models to the history-based models of <REF>Ratnaparkhi 1997</REF></REF>, Jelinek et al	1	1994, and <TREF>Magerman 1995</TREF>	0	A strength of these models is undoubtedly the powerful estimation techniques that they use: maximum-entropy modeling in <REF>Ratnaparkhi 1997</REF> or decision trees in <REF>Jelinek et al 1994</REF> and <TREF>Magerman 1995</TREF>	0	2	1
J03-4003	P95-1037	2003	Another important differencethe ability of models 1, 2, and 3 to generalize to produce context-free rules not seen in training datawas described in section 74 Section 82 showed that the parsing models of <REF>Ratnaparkhi 1997</REF>, Jelinek et al	0	1994, and <TREF>Magerman 1995</TREF> can suffer from very similar problems to the label bias or observation bias problem observed in tagging models, as described in <REF>Lafferty, McCallum, and Pereira 2001</REF> and <REF>Klein and Manning 2002</REF>	1	635 Collins Head-Driven Statistical Models for NL Parsing Acknowledgments My PhD thesis is the basis of the work in this article; I would like to thank Mitch Marcus for being an excellent PhD thesis adviser, and for contributing in many ways to this research	0	I would like to thank the members of my thesis committeeAravind Joshi, Mark Liberman, Fernando Pereira, and Mark Steedmanfor the remarkable breadth and depth of their feedback	0	1	3
J03-4003	P95-1037	2003	For discussion of additional related work, chapter 4 of <REF>Collins 1999</REF> attempts to give a comprehensive review of work on statistical parsing up to around 1998	0	Of particular relevance is other work on parsing the Penn WSJ Treebank <REF>Jelinek et al 1994</REF>; <TREF>Magerman 1995</TREF>; <REF>Eisner 1996a, 1996b</REF>; <REF>Collins 1996</REF>; <REF>Charniak 1997</REF>; <REF>Goodman 1997</REF>; <REF>Ratnaparkhi 1997</REF>; <REF>Chelba and Jelinek 1998</REF>; <REF>Roark 2001</REF>	1	Eisner 1996a, 1996b describes several dependency-based models that are also closely related to the models in this article	0	<REF>Collins 1996</REF> also describes a dependency-based model applied to treebank parsing	0	6	1
J03-4003	P95-1037	2003	<REF>Charniaks 1997</REF> models will most likely perform quite differently with binarybranching trees for example, his current models will learn that rules such as VP  VSGPPare very rare, but with binary-branching structures, this context sensitivity will be lost	0	The models of <TREF>Magerman 1995</TREF> and <REF>Ratnaparkhi 1997</REF> use contextual predicates that would most likely need to be modified given a different annotation style	1	<REF>Goodmans 1997</REF> models are the exception, as he already specifies that the treebank should be transformed into his chosen representation, binary-branching trees	0	731 Representation Affects Structural, not Lexical, Preferences	0	1	3
J99-2004	P95-1037	1999	22 Statistical Parsers Pioneered by the IBM natural language group <REF>Fujisaki et al 1989</REF> and later pursued by, for example, <REF>Schabes, Roth, and Osborne 1993</REF>, Jelinek et al	0	1994, <TREF>Magerman 1995</TREF>, <REF>Collins 1996</REF>, and <REF>Charniak 1997</REF>, this approach decouples the issue of wellformedness of an input string from the problem of assigning a structure to it	1	These systems attempt to assign some structure to every input string	0	The rules to assign a structure to an input are extracted automatically from hand-annotated parses of large corpora, which are then subjected to smoothing to obtain reasonable coverage of the language	0	3	2
C96-1095	P95-1037	1996	During the last few years large treebanks have become available to many researchers, which has resulted in researches applying a range of new techniques for parsing systems	1	Most of the methods that are being suggested include some kind of Machine Learning, such as history based grammars and decision tree models <REF>Black et al , 1993</REF>; <TREF>Magerman, 1995</TREF>, training or inducing statistical grammars <REF>Black, Garside and Leech, 1993</REF>; <REF>Pereira and Schabes, 1992</REF>; <REF>Schabes et al , 1993</REF>, or other techniques <REF>Bod, 1993</REF>	1	Consequently, syntactical analysis has become an area with a wide variety of a algorithms and methods for learning and parsing, and b type of information used for learning and parsing sometimes referred to as feature set	0	These methods only could become popular through evaluation methods for parsing systems, such as Bracket Accuracy, Bracket Recall, Sentence Accuracy and Viterbi Score	0	4	2
W04-0307	P95-1037	2004	Factors contributing to the SCDG parsers performance are analyzed	0	Statistical parsing has been an important focus of recent research <TREF>Magerman, 1995</TREF>; <REF>Eisner, 1996</REF>; <REF>Charniak, 1997</REF>; <REF>Collins, 1999</REF>; <REF>Ratnaparkhi, 1999</REF>; <REF>Charniak, 2000</REF>	1	Several of these parsers generate constituents by conditioning probabilities on non-terminal labels, part-of-speech POS tags, and some headword information <REF>Collins, 1999</REF>; <REF>Ratnaparkhi, 1999</REF>; <REF>Charniak, 2000</REF>	0	They utilize non-terminals that go beyond the level of a single word and do not explicitly use lexical features	0	6	1
W96-0209	P95-1037	1996	Although we report promising results, parse selection that is sufficiently accurate for many practical applications will require a more lexicalised system	0	Magermans 1995 parser is an extension of the history-based parsing approach developed at IBM <REF>Black et al , 1993</REF> in which rules are conditioned on lexical and other essentially arbitrary information available in the parse history	1	In future work, we intend to explore a more restricted and semantically-driven version of this approach in which, firstly, probabilities are associated with different subcategorisation possibilities, and secondly, alternative predicateargument structures derived from the grammar are ranked probabilistically	1	However, the massively increased coverage obtained here by relaxing subcategorisation constraints underlines the need to acquire accurate and complete subcategorisation frames in a corpus-driven fashion, before such constraints can be exploited robustly and effectively with free text	0	5	2
W96-0209	P95-1037	1996	Schabes et al	0	1993 and <TREF>Magerman 1995</TREF> report results using the GEIG evaluation scheme which are numerically similar in terms of parse selection to those reported here, but achieve 100 coverage	1	However, their experiments are not strictly comparable because they both utilise more homogeneous and probably simpler corpora	1	The appendix gives an indication of the diversity of the sentences in our corpus	0	2	1
P98-1020	P95-1037	1998	In our experiments, the window starts at the sentence prior to that containing the token and extends back W the window size sentences	0	The choice to use sentences as the unit of distance is motivated by our intention to incorporate triggers of this form into a probabilistie treebank-based parser and tagger, such as <REF>Black et al , 1998</REF>; <REF>Black et al , 1997</REF>; <REF>Brill, 1994</REF>; <REF>Collins, 1996</REF>; <REF>Jelinek et al , 1994</REF>; <TREF>Magerman, 1995</TREF>; <REF>Ratnaparkhi, 1997</REF>	1	All such parsers and taggers of which we are aware use only intrasentential information in predicting parses or tags, and we wish to remove this information, as far as possible, from our results 7 The window was not allowed to cross a document boundary	0	The perplexity of the task before taking the trigger-pair information into account for tags was 2240 and for rules was 570	0	3	2
P03-1054	P95-1037	2003	Yet, only the labels are used to score the combination	0	Length  40 LP LR F1 Exact CB 0 CB <TREF>Magerman 1995</TREF> 849 846 126 566 <REF>Collins 1996</REF> 863 858 114 599 this paper 869 857 863 309 110 603 <REF>Charniak 1997</REF> 874 875 100 621 <REF>Collins 1999</REF> 887 886 090 671 Length  100 LP LR F1 Exact CB 0 CB this paper 863 851 857 288 131 572 Figure 8: Results of the final model on the test set section 23	1	capture this, DOMINATES-V marks all nodes which dominate any verbal node V, MD with a -V	0	This brought the cumulative F1 to 8691	0	6	1
P03-1054	P95-1037	2003	We describe several simple, linguistically motivated annotations which do much to close the gap between a vanilla PCFG and state-of-the-art lexicalized models	0	Specifically, we construct an unlexicalized PCFG which outperforms the lexicalized PCFGs of <TREF>Magerman 1995</TREF> and <REF>Collins 1996</REF> though not more recent models, such as <REF>Charniak 1997</REF> or <REF>Collins 1999</REF>	1	One benefit of this result is a much-strengthened lower bound on the capacity of an unlexicalized PCFG	0	To the extent that no such strong baseline has been provided, the community has tended to greatly overestimate the beneficial effect of lexicalization in probabilistic parsing, rather than looking critically at where lexicalized probabilities are both needed to make the right decision and available in the training data	0	1	3
P03-1054	P95-1037	2003	This approach was congruent with the great success of word n-gram models in speech recognition, and drew strength from a broader interest in lexicalized grammars, as well as demonstrations that lexical dependencies were a key tool for resolving ambiguities such as PP attachments <REF>Ford et al , 1982</REF>; <REF>Hindle and Rooth, 1993</REF>	0	In the following decade, great success in terms of parse disambiguation and even language modeling was achieved by various lexicalized PCFG models <TREF>Magerman, 1995</TREF>; <REF>Charniak, 1997</REF>; <REF>Collins, 1999</REF>; <REF>Charniak, 2000</REF>; <REF>Charniak, 2001</REF>	1	However, several results have brought into question how large a role lexicalization plays in such parsers	0	<REF>Johnson 1998</REF> showed that the performance of an unlexicalized PCFG over the Penn treebank could be improved enormously simply by annotating each node by its parent category	0	6	2
W00-1320	P95-1037	2000	However, perhaps even more significant has been the lexicalization of the grammar formalisms being probabilistically modeled: crucially, all the recent, successful statistical parsers have in some way made use of bilexical dependencies	1	This includes both the parsers that attach probabilities to parser moves <TREF>Magerman, 1995</TREF>; <REF>Ratnaparkhi, 1997</REF>, but also those of the lexicalized PCFG variety <REF>Collins, 1997</REF>; <REF>Charniak, 1997</REF>	1	155 Even more crucially, the bilexical dependencies involve head-modifier relations hereafter referred to simply as head relations	0	The intuition behind the lexicalization of a grammar formalism is to capture lexical items idiosyncratic parsing preferences	0	4	2
A97-1053	P95-1037	1997	In those research, extracted lexical/semantic collocation is especially useful in terms of ranking parses in syntactic analysis as well as automatic construction of lexicon for NLP	1	For example, in the context of syntactic disambiguation, <REF>Black 1993</REF> and <TREF>Magerman 1995</TREF> proposed statistical parsing models based-on decisiontree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees	1	As lexical/semantic information, <REF>Black 1993</REF> used about 50 semantic categories, while <TREF>Magerman 1995</TREF> used lexicai forms of words	0	<REF>Collins 1996</REF> proposed a statistical parser which is based on probabilities of dependencies between head-words in the parse tree	0	4	2
A97-1053	P95-1037	1997	For example, in the context of syntactic disambiguation, <REF>Black 1993</REF> and <TREF>Magerman 1995</TREF> proposed statistical parsing models based-on decisiontree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees	1	As lexical/semantic information, <REF>Black 1993</REF> used about 50 semantic categories, while <TREF>Magerman 1995</TREF> used lexicai forms of words	1	<REF>Collins 1996</REF> proposed a statistical parser which is based on probabilities of dependencies between head-words in the parse tree	0	In those works, lexical/semantic collocation are used for ranking parses in syntactic analysis	0	4	2
W02-2030	P95-1037	2002	Other researchers have proposed automatically selecting the conditioning information for various states of the model, thus potentially increasing greatly the space of possible features and selectively choosing the best predictors for each situation	1	Decision trees have been applied for feature selection for statistical parsing models by <TREF>Magerman 1995</TREF> and Haruno et al	1	1998	0	Another example of automatic feature selection for parsing is in the context of a deterministic parsing model that chooses parse actions based on automatically induced decision structures over a very rich feature set <REF>Hermjakob and Mooney, 1997</REF>	0	4	2
W02-2030	P95-1037	2002	We grew the trees fully and we calculated final expansion probabilities at the leaves by linear interpolation with estimates one level above	0	This is a similar, but more limited, strategy to the one used by <TREF>Magerman 1995</TREF>	1	The features over derivation trees which we made available to the learner are shown in Table 1	0	The node direction features indicate whether a node is a left child, a right child, or a single child	0	1	2
N07-1057	P95-1037	2007	Figure 1a shows a parse tree in the Penn Treebank style for the English translation in Ex 1	0	Given a parse tree, we use a head percolation table <TREF>Magerman, 1995</TREF> to create the corresponding dependency structure	1	Figure 2a shows the dependency structure derived from the parse tree in Figure 1a	0	32 Word alignment Because most of the 700 languages in ODIN are low-density languages with no on-line bilingual dictionariesorlargeparallelcorpora, aligning the source sentence and its English translation directly would not work well	0	3	2
W00-0709	P95-1037	2000	Information regarding constituent heads, POS tags, and lexical information is pertinent, as is information on constituent ordering and other grammatical information present in the data	0	Most or all of these factors are considered in some form or another by current state-of-the-art statistical parsers such as those of <REF>Charniak 1997</REF>, <TREF>Magerman 1995</TREF> and <REF>Collins 1996</REF>	1	In the present approach, each feature in the feature set corresponds to a depth-one tree structure in the data, ie a mother node and all of its daughters	0	Within this general structure various schemata may be used to derive actual features, where the information about each node employed in the feature is determined by which schema is used	0	6	1
W08-1111	P95-1037	2008	Inparticular,weleveragethe increasing availability of off-the-shelf parsers such as <REF>Charniak, 2001</REF>; <REF>Charniak, 2005</REF> to automatically or semi-automatically assign syntactic analyses to a set of suggested output sentences	0	We then draw on lexicalization techniques for statistical language models <TREF>Magerman, 1995</TREF>; <REF>Collins, 1999</REF>; <REF>Chiang, 2000</REF>; <REF>Chiang, 2003</REF> to induce a probabilistic, lexicalized tree-adjoining grammar that supports the derivation of all the suggested output sentences, and many others besides	1	The final step is to use the training examples to learn an effective search policy so that our run-time generation component can find good output sentences in a reasonable time frame	0	In particular, we use variants of existing search optimization <REF>Daum and Marcu, 2005</REF> and ranking algorithms <REF>Collins and Koo, 2005</REF> to train our run-time component to find good outputs within a specified time window; see also <REF>Stent et al, 2004</REF>; <REF>Walker et al, 2001</REF>	0	3	2
W08-1111	P95-1037	2008	In the first stage, a collection of rules is used to automatically decorate the training syntax with a number of features	1	These include deciding the lexical anchors for each non-terminal constituent and assigning complement/adjunct status for nonterminals which are not on their parents lexicalization path; see <TREF>Magerman, 1995</TREF>; <REF>Chiang, 2003</REF>; <REF>Collins, 1999</REF>	1	In addition, we deterministically add features to improve several grammatical aspects, including 1 enforcing verb inflectional agreement in derived trees, 2 enforcing consistency in the finiteness of VP and S complements, and 3 restricting subject/direct object/indirect object complements to play the same grammatical role in derived trees	1	In the second stage, the complements and adjuncts in the decorated trees are incrementally re80 syntax: cat: SA fin:other,  cat: S cat: NP,  apr: VBP, apn: other pos: PRP we fin:yes,  cat: VP apn: other,  pos: VBP do pos: RB nt fin: yes,  cat: VP, gra: obj1 fin: yes,  cat: VP, gra: obj1 pos: VBP have cat: NP,  gra: obj1 operations: initial tree comp semantics: speech-actaction  assert speech-actcontentpolarity  negative speech-actcontentattribute  resourceAttribute syntax: cat: NP,  apr: VBP, gra: obj1,  apn: other pos: JJ medical pos: NNS supplies cat: ADVP,  gra: adj pos: RB here cat: NP,  apr: VBZ, gra: adj,  apn: 3ps pos: NN captain operations: comp left/right adjunction left/right adjunction semantics: speech-actcontentvalue  medical-supplies speech-actcontentobject-id  market addressee  captain-kirk dialogue-actaddressee  captain-kirk speech-actaddressee  captain-kirk Figure 2: The linguistic resources inferred from the training example in Figure 1	0	3	2
P08-1037	P95-1037	2008	There is both empirical evidence and linguistic intuition to indicate that semantic features can enhance parse disambiguation performance, however	0	For example, a number of different parsers have been shown to benet from lexicalisation, that is, the conditioning of structural features on the lexical head of the given constituent <TREF>Magerman, 1995</TREF>; <REF>Collins, 1996</REF>; <REF>Charniak, 1997</REF>; <REF>Charniak, 2000</REF>; <REF>Collins, 2003</REF>	1	As an example of lexicalisation, we may observe in our training data that knife often occurs as the manner adjunct of open in prepositional phrases headed by with cf open with a knife, which would provide strong evidence for with a knife attaching to open and not box in open the box with a knife	0	It would not, however, provide any insight into the correct attachment of with scissors in open the box with scissors, as the disambiguation model would not be able to predict that knife and scissors are semantically similar and thus likely to have the same attachment preferences	0	6	1
C02-1126	P95-1037	2002	Whats more, on top of the large undertaking of designing and implementing a statistical parsing model, the use of heuristics has required a further e ort, forcing the researcher to bring both linguistic intuition and, more often, engineering savvy to bear whenever moving to a new treebank	1	For example, in the rule sets used by the parsers described in <TREF>Magerman, 1995</TREF>; <REF>Ratnaparkhi, 1997</REF>; <REF>Collins, 1999</REF>, the sets of rules for finding the heads of ADJP, ADVP, NAC, PP and WHPP include rules for picking either the rightmost or leftmost FW foreign word	1	The apparently haphazard placement of these rules that pick out FW and the rarity of FW nodes in the data strongly suggest these rules are the result of engineering e ort	0	Furthermore, it is not at all apparent that tree-transforming heuristics that are useful for one parsing model will be useful for another	0	4	2
C02-1126	P95-1037	2002	In fact, nearly identical head-lexicalizations were used in the disScaughtVBD NPboyNN DET The NN boy ADVPalsoRB RB also VPcaughtVBD VBD caught NPballNN DET the NN ball Figure 2: A simple lexicalized parse tree	0	criminative models described in <TREF>Magerman, 1995</TREF>; <REF>Ratnaparkhi, 1997</REF>, the lexicalized PCFG models in <REF>Collins, 1999</REF>, the generative model in <REF>Charniak, 2000</REF>, the lexicalized TAG extractor in <REF>Xia, 1999</REF> and the stochastic lexicalized TAG models in <REF>Chiang, 2000</REF>; <REF>Sarkar, 2001</REF>; <REF>Chen and VijayShanker, 2000</REF>	1	Inducing a lexicalized structure based on heads has a two-pronged e ect: it not only allows statistical parsers to be sensitive to lexical information by including this information in the probability models dependencies, but it also determines which of all possible dependencies both syntactic and lexicalwill be included in the model itself	0	For example, in Figure 2, the nonterminal NPboyNN is dependent on VPcaughtVBD and not the other way around	0	6	1
I08-1069	P95-1037	2008	Once enriched, the data can be used as a bootstrap for tools such as taggers	0	311 Enriching IGT In a previous study <REF>Xia and Lewis, 2007</REF>, we proposed a three-step process to enrich IGT data: 1 parse the English translation with an English parser and convert English phrase structures PS into dependency structures DS with a head percolation table <TREF>Magerman, 1995</TREF>, 2 align the target line and the English translation using the gloss line, and 3 project the syntactic structures both PS and DS from English onto the target line	1	For instance, given the IGT example in Ex 1, the enrichment algorithm will produce the word alignment in Figure 1 and the syntactic structures in Figure 2	0	The  teacher  gave  a  book  to    the    boy   yesterday Rhoddodd  yr   athro     lyfr     ir     bachgen  ddoe  Gloss line:  Translation: Target line: gave-3sg  the  teacher book  to-the  boy   yesterday Figure 1: Aligning the target line and the English translation with the help of the gloss line 533 gave a Projecting DS athro bachgen lyfr yr ddoeir  Rhoddodd S NP1 VP NN teacher VBD   gave NP2 DT a NP4PP NN the IN NP3 yesterday NN DT book NN boy DT to S NP NN VBD NP NPPP NN INDT NN NNDT   rhoddodd   gave yrthe    athro teacher lyfr book     ir to-the bachogen boy ddoe yesterday teacher a boy the book the yesterdayto The b Projecting PS Figure 2: Projecting syntactic structure from English to the target language We evaluated the algorithm on a small set of 538 IGT instances for several languages	0	3	2
C00-2141	P95-1037	2000	I Introduction Research on syntactic parsing has been a focus in natural language processing for a long lime	0	As the developlnent of corpus linguistics, many statistics-based parsers were proposed, such as <TREF>Magerman1995</TREF>s statistical decision tree parser, <REF>Collins1996</REF>s bigram dependency model parser, 1;/atnaparkhi1997s maximum entropy model parser	1	All of lhem fried to get the complete parse trees of the input sentences, based on the statistical data extracted lrom an annotated corpus	0	The besl parsing accuracy of these parsers was about 87	0	6	1
W03-1006	P95-1037	2003	The extraction procedure determines the structure of each elementary tree by localizing dependencies through the use of heuristics	0	Salient heuristics include the use of a head percolation table <TREF>Magerman, 1995</TREF>, and another table that distinguishes between complements and adjunct nodes in the tree	1	For our current work, we use the head percolation table to determine heads of phrases	1	Also, we treat a PropBank argument ARG0 : : : ARG9 as a complement and a PropBank adjunct ARGMs as an adjunct when such annotation is available1 Otherwise, we basically follow the approach of <REF>Chen, 2001</REF>2 Besides introducing one kind of TAG extraction 1The version of the PropBank we are using is not fully annotated with semantic role information, although the most common predicates are	0	4	2
W96-0213	P95-1037	1996	unlike MaxEnt, cannot be used as a probabilistic component in a larger model	0	MaxEnt can provide a probability for each tagging decision, which can be used in the probability calculation of any structure that is predicted over the POS tags, such as noun phrases, or entire parse trees, as in <REF>Jelinek et al , 1994</REF>, <TREF>Magerman, 1995</TREF>	1	Thus MaxEnt has at least one advantage over each of the reviewed POS tagging techniques	1	It is better able to use diverse information than Markov Models, requires less supporting techniques than SDT, and unlike TBL, can be used in a probabilistic framework	0	2	2
W96-0213	P95-1037	1996	Since most realistic natural language applications must process words that were never seen before in training data, all experiments in this paper are conducted on test data that include unknown words	0	Several recent papers<REF>Brill, 1994</REF>, <TREF>Magerman, 1995</TREF> have reported 965 tagging accuracy on the Wall St Journal corpus	1	The experiments in this paper test the hypothesis that better use of context will improve the accuracy	1	A Maximum Entropy model is well-suited for such experiments since it cornbines diverse forms of contextual information in a principled manner, and does not impose any distributional assumptions on the training data	0	4	2
W96-0213	P95-1037	1996	The total accuracy is higher, implying that the singly-annotated training and test sets are more consistent, and the improvement due to the specialized features is higher than before 1 but still modest, implying that either the features need further improvement or that intra-annotator inconsistencies exist in the corpus	0	Comparison With Previous Work Most of the recent corpus-based POS taggers in the literature are either statistically based, and use Markov Model<REF>Weischedel et al , 1993</REF>, <REF>Merialdo, 1994</REF> or Statistical Decision Tree<REF>Jelinek et al , 1994</REF>, <TREF>Magerman, 1995</TREF>SDT techniques, or are primarily rule based, such as Drills Transformation Based Learner<REF>Drill, 1994</REF>TBL	1	The Maximum Entropy MaxEnt tagger presented in this paper combines the advantages of all these methods	0	It uses a rich feature representation, like TBL and SDT, and generates a tag probability distribution for each word, like Decision Tree and Markov Model techniques	0	2	1
W96-0213	P95-1037	1996	140 A POS tagger is one component in the SDT based statisticM parsing system described in <REF>Jelinek et al , 1994</REF>, <TREF>Magerman, 1995</TREF>	0	The total word accuracy on Wall St Journal data, 965<TREF>Magerman, 1995</TREF>, is similar to that presented in this paper	1	However, the aforementioned SDT techniques require word classes<REF>Brown et al , 1992</REF> to help prevent data fragmentation, and a sophisticated smoothing algorithm to mitigate the effects of any fragmentation that occurs	0	Unlike SDT, the MaxEnt training procedure does not recursively split the data, and hence does not suffer from unreliable counts due to data fragmentation	0	2	1
W96-0213	P95-1037	1996	In contrast, the MaxEnt model combines diverse and non-local information sources without making any independence assumptions	0	140 A POS tagger is one component in the SDT based statisticM parsing system described in <REF>Jelinek et al , 1994</REF>, <TREF>Magerman, 1995</TREF>	1	The total word accuracy on Wall St Journal data, 965<TREF>Magerman, 1995</TREF>, is similar to that presented in this paper	0	However, the aforementioned SDT techniques require word classes<REF>Brown et al , 1992</REF> to help prevent data fragmentation, and a sophisticated smoothing algorithm to mitigate the effects of any fragmentation that occurs	0	4	2
W96-0112	P95-1037	1996	There have been a number of methods proposed to perform structural disambiguation using probability models, many of which have proved to be quite effective <REF>Alshawi and Carter, 1995</REF>; <REF>Black et al , 1992</REF>; Briscoe and Carroll	0	1993; <REF>Chang et al , 1992</REF>; <REF>Collins and Brooks, 1995</REF>; <REF>Fujisaki, 1989</REF>; <REF>Hindle and Rooth, 1991</REF>; <REF>Hindle and Rooth, 1993</REF>; <REF>Jelinek et al , 1990</REF>; <REF>Magerman and Marcus, 1991</REF>; <TREF>Magerman, 1995</TREF>; <REF>Ratnaparkhi et al , 1994</REF>; <REF>Resnik, 1993</REF>; <REF>Su and Chang, 1988</REF>	1	Although each of the disambiguation methods proposed to date has its merits, none resolves the disambiguation problem completely satisfactorily	0	We feel that it is necessary to devise a new method that unifies the above two approaches, ie, to implement psycholinguistic principles of disambiguation on the basis of a probabilistic methodology	0	6	1
W98-1115	P95-1037	1998	6 Conclusion It is worth noting that while we have presented the use of edge-based best-first chart parsing in the service of a rather pure form of PCFG parsing, there is no particular reason to assume that the technique is so limited in its domain of applicability	0	One can imagine the same techniques coupled with more informative probability distributions, such as lexicalized PCFGs <REF>Charniak, 1997</REF>, or even grammars not based upon literal rules, but probability distributions that describe how rules are built up from smaller components <TREF>Magerman, 1995</TREF>; <REF>Collins, 1997</REF>	1	Clearly further research is warranted	1	Be this as it may, the take-home lesson from this paper is simple: combining an edge-based agenda with the figure of merit from CC  is easy to do by simply binarizing the grammar  provides a factor of 20 or so reduction in the number of edges required to find a first parse, and  improves parsing precision and recall over exhaustive parsing	0	5	2
J05-3003	P95-1037	2005	Chen and Vijay-<REF>Shanker 2000</REF> explore a number of related approaches to the extraction of a lexicalized TAG from the Penn-II Treebank with the aim of constructing a statistical model for parsing	0	The extraction procedure utilizes a head percolation table as introduced by <TREF>Magerman 1995</TREF> in combination with a variation of <REF>Collinss 1997</REF> approach to the differentiation between complement and adjunct	1	This results in the construction of a set of lexically anchored elementary trees which make up the TAG in question	0	The number of frame types extracted ie , an elementary tree without a specific lexical anchor ranged from 2,366 to 8,996	0	6	1
C96-1020	P95-1037	1996	uk black,eubank,kashiokaatritlcojp GLeechOcentllancsacuk 1 Introduction A treebank is a body of natural language text which has been grammatically annotated by hand, in terms of some previously-established scheme of grammatical analysis	0	Treebanks have been used within the field of natural language processing as a source of training data for statistical part og speech taggers <REF>Black et al , 1992</REF>; <REF>Brill, 1994</REF>; <REF>Merialdo, 1994</REF>; <REF>Weischedel et al , 1993</REF> and for statistical parsers <REF>Black et al , 1993</REF>; <REF>Brill, 1993</REF>; aelinek et al , 1994; <TREF>Magerman, 1995</TREF>; <REF>Magerman and Marcus, 1991</REF>	1	In this article, we present the ATR/Lancaster 7reebauk of American English, a new resource tbr natural-language-, processing research, which has been prepared by Lancaster University UKs Unit for Computer Research on the English Language, according to specifications provided by ATR Japans Statistical Parsing Group	0	First we provide a static description, with a a discussion of the mode of selection and initial processing of text for inclusion in the treebank, and b an explanation of the scheme of grammatical annotation we then apply to the text	0	4	2
W97-1511	P95-1037	1997	In this framework, a rough grammar is first learned from a bracketed corpus and then the grammar is refined by the combination of rulebased and corpus-based methods	0	Unlike stochastic parsing such as <TREF>Magerman, 1995</TREF><REF>Collins, 1996</REF>, our approach can parse sentences which fall out the current grammar and suggest the plausible hypothesis rules and the best parses	1	The grammar is not acquired from scratch like the approaches shown in 82 Sent	0	Length Comparisons Avg	0	2	1
C00-2099	P95-1037	2000	Formulating it using Gorns notation and the L; and 2 variables, though, is concise, elegant; and novel	0	Nothing prevents conditioning the random variables on arbitrary portions of Clio 1artial tree generated this far, using, eg, maximum-entroly or decision-tree models to extract relevant tatnres of it; there is no difference 689 in principle between our model and history-based parsing, see Black el; al , 1993; <TREF>Magerman, 1995</TREF>	1	The proposed treatment of string realization through the use of the,5 and A4 variables is also both truly novel and important	0	While phrase-structure grammars overemphasize word order by making the processes generating the S variables deterministic, Tesni6re treats string realization as a secondary issue	0	2	1
W06-2920	P95-1037	2006	That approach is based on a conversion from constituent structure to dependency structure by recursively defining a head for each constituent	1	The same idea was used by <TREF>Magerman 1995</TREF>, who developed the first head table for the Penn Treebank <REF>Marcus et al , 1994</REF>, and <REF>Collins 1996</REF>, whose constituent parser is internally based on probabilities of bilexical dependencies, ie dependencies between two words	1	<REF>Collins 1997</REF>s parser and its reimplementation and extension by <REF>Bikel 2002</REF> have by now been applied to a variety of languages: English <REF>Collins, 1999</REF>, Czech <REF>Collins et al , 1999</REF>, German <REF>Dubey and Keller, 2003</REF>, Spanish <REF>Cowan and Collins, 2005</REF>, French <REF>Arun and Keller, 2005</REF>, Chinese <REF>Bikel, 2002</REF> and, according to Dan Bikels web page, Arabic	0	<REF>Eisner 1996</REF> introduced a data-driven dependency parser and compared several probability models on English Penn Treebank data	0	4	2
W05-1514	P95-1037	2005	In the first iteration, the chunker identifies two base phrases, NP Estimated volume and QP 24 million, and replaces each phrase with its nonterminal symbol and head	0	The head word is identified by using the head-percolation table <TREF>Magerman, 1995</TREF>	1	In the second iteration, the chunker identifies NP a light million ounces and converts this phrase into NP	0	This chunking procedure is repeated until the whole sentence is chunked at the fourth iteration, and the full parse tree is easily recovered from the chunking history	0	6	1
W96-0111	P95-1037	1996	Moreover, the results of a less-than-optimal version of DOP on the Wall Street Journal corpus suggest that the approach can be succesfully extended to larger domains	1	As future research, we will apply the full DOP model on WSJ word strings in order to compare our results with the best known parsers on this domain <TREF>Magerman, 1995</TREF>; <REF>Collins, 1996</REF>	1	Acknowledgements I am grateful to Remko Scha for many useful comments and additions	0	I also thank three anonymous reviewers for their comments	0	5	2
W96-0111	P95-1037	1996	Stochastic parsing systems either use a closed lexicon, or use a two step approach where first the words are tagged 133 by a stochastic tagger, after which the p-o-s tags with or without the words are parsed by a stochastic parser	1	The latter approach has become increasingly popular eg <REF>Schabes et al , 1993</REF>; <REF>Weischedel et al , 1993</REF>; <REF>Briscoe, 1994</REF>; <TREF>Magerman, 1995</TREF>; <REF>Collins, 1996</REF>	1	Notice, however, that the tagger used in this two step approach often uses Good-Turing or a similar smoothing method to adjust the observed frequencies of n-grams	0	So why not apply Good-Turing directly to the structural units of a stochastic grammar	0	4	2
C02-1132	P95-1037	2002	Incorporating semantic classes and verb alternation behavior could improve such models performance	1	Automatically derived word clusters are used in the statistical parsers of <REF>Charniak 1997</REF> and <TREF>Magerman 1995</TREF>	1	Incorporating alternation behavior into such models might improve parsing results as well	0	This paper focuses on evaluating probabilistic models of verb-argument structure in terms of how well they model unseen test data, as measured by perplexity	0	6	1
W03-1005	P95-1037	2003	We calculate the precision, recall, and Fscore; however for brevitys sake we only report the F-score for most experiments in this section	0	In addition to antecedent recovery, we also report parsing accuracy, using the bracketing F-Score, the combined measure of PARSEVAL-style labeled bracketing precision and recall <TREF>Magerman, 1995</TREF>	1	44 Results The results of the experiments are summarized in Table 3	0	UNLEX and LEX refer to the unlexicalized and lexicalized models, respectively	0	3	2
P08-1066	P95-1037	2008	Given sentence-aligned bi-lingual training data, we first use GIZA <REF>Och and Ney, 2003</REF> to generate word level alignment	0	We use a statistical CFG parser to parse the English side of the training data, and extract dependency trees with Magermans rules 1995	1	Then we use heuristic rules to extract transfer rules recursively based on the GIZA alignment and the target dependency trees	0	The rule extraction procedure is as follows	0	3	2
P06-2048	P95-1037	2006	As for the learning technique, we used maximum entropy models, speci cally the implementation called MegaM provided by Hal Daume Daume III, 2004	0	For P S, we needed features  40  100 CB 0CB CB 0CB <TREF>Magerman 1995</TREF> 126 566 <REF>Collins 1996</REF> 114 599 Klein/<REF>Manning 2003</REF> 110 603 131 572 this paper 109 582 125 552 <REF>Charniak 1997</REF> 100 621 <REF>Collins 1999</REF> 090 671 Figure 8: Cross-bracketing results for Section 23 of the Penn Treebank	1	that would be relevant to deciding whether a given span i,j should be considered a constituent	0	The basic building blocks we used are depicted in Figure 7	0	6	1
P06-2048	P95-1037	2006	Thus one trades assurances of polynomial running time for greater modeling exibility	1	There are two canonical parsers that fall into this category: the decision-tree parser of <TREF>Magerman, 1995</TREF>, and the maximum-entropy parser of <REF>Ratnaparkhi, 1997</REF>	0	Both showed decent results on parsing the Penn Treebank, but in the decade since these papers were published, history-based parsers have been largely ignored by the research community in favor of PCFG-based approaches	0	There are several reasons why this may be	0	6	1
C08-1081	P95-1037	2008	More precisely, the approach is based on four essential components:  A transition-based deterministic algorithm for building labeled projective dependency graphs in linear time <REF>Nivre, 2003</REF>	0	History-based feature models for predicting the next parser action <REF>Black et al, 1992</REF>; <TREF>Magerman, 1995</TREF>; <REF>Ratnaparkhi, 1997</REF>	1	Discriminative classifiers for mapping histories to parser actions <REF>Kudo and Matsumoto, 2002</REF>; <REF>Yamada and Matsumoto, 2003</REF>	0	Pseudo-projectiveparsingforrecoveringnonprojective structures <REF>Nivre and Nilsson, 2005</REF>	0	6	1
W97-0301	P95-1037	1997	The SPATTER decision trees use predicates on word classes created with a statistical clustering technique, whereas the maximum entropy parser uses predicates that contain merely the words themselves, and thus lacks the need for a typically expensive word clustering procedure	0	Furthermore, the top K BFS search heuristic appears to be much simpler than the stack decoder algorithm outlined in <TREF>Magerman, 1995</TREF>	1	77 Conclusion The maximum entropy parser presented here achieves a parsing accuracy which exceeds the best previously published results, and parses a test sentence in linear observed time, with respect to the sentence length	0	It uses simple and concisely speci fled predicates which can added or modified quickly with little human effort under the maximum entropy framework	0	2	1
W97-0301	P95-1037	1997	For this reason, research into reranking schemes appears to be a promising step towards the goal of improving parsing accuracy	0	6 Comparison With Previous Work The two parsers which have previously reported the best accuracies on the Penn Treebank Wall St Journal are the bigram parser described in <REF>Collins, 1996</REF> and the SPATTER parser described in <REF>Jelinek et al , 1994</REF>; <TREF>Magerman, 1995</TREF>	1	The parser presented here outperforms both the bigram parser and the SPATTER parser, and uses different modelling technology and different information to drive its decisions	0	The bigram parser is a statistical CKY-style chart parser, which uses cooccurrence statistics of headmodifier pairs to find the best parse	0	2	1
W97-0301	P95-1037	1997	Figure 9 shows that the perfect scheme would achieve roughly 93 precision and recall, which is a dramatic increase over the top 1 accuracy of 87 precision and 86 recall	0	Figure 10 shows that the Exact Match, which counts the percentage of times 2Results for SPATTER on section 23 are reported in <REF>Collins, 1996</REF></REF> Parser Precision Maximum Entropy  868 Maximum Entropy 875 <REF>Collins, 1996</REF></REF> 857 <TREF>Magerman, 1995</TREF> 843 Recall 856 863 853 840 Table 5: Results on 2416 sentences of section 23 0 to 100 words in length of the WSJ Treebank	1	Evaluations marked with  ignore quotation marks	0	Evaluations marked with  collapse the distinction between ADVP and PRT, and ignore all punctuation	0	4	2
W97-0301	P95-1037	1997	The PARSEVAL Black and others, 1991 measures compare a proposed parse P with the corresponding correct treebank parse T as follows:  correct constituents in P Recall   constituents in T  correct constituents in P Precision   constituents in P A constituent in P is correct if there exists a constituent in T of the same label that spans the same words	0	Table 5 shows results using the PARSEVAL measures, as well as results using the slightly more forgiving measures of <REF>Collins, 1996</REF> and <TREF>Magerman, 1995</TREF>	1	Table 5 shows that the maximum entropy parser performs better than the parsers presented in <REF>Collins, 1996</REF> and <TREF>Magerman, 1995</TREF> , which have the best previously published parsing accuracies on the Wall St Journal domain	1	It is often advantageous to produce the top N parses instead of just the top 1, since additional information can be used in a secondary model that reorders the top N and hopefully improves the quality of the top ranked parse	0	4	2
W97-0301	P95-1037	1997	Table 5 shows results using the PARSEVAL measures, as well as results using the slightly more forgiving measures of <REF>Collins, 1996</REF> and <TREF>Magerman, 1995</TREF>	1	Table 5 shows that the maximum entropy parser performs better than the parsers presented in <REF>Collins, 1996</REF> and <TREF>Magerman, 1995</TREF> , which have the best previously published parsing accuracies on the Wall St Journal domain	1	It is often advantageous to produce the top N parses instead of just the top 1, since additional information can be used in a secondary model that reorders the top N and hopefully improves the quality of the top ranked parse	0	Suppose there exists a perfect reranking scheme that, for each sentence, magically picks the best parse from the top N parses produced by the maximum entropy parser, where the best parse has the highest average precision and recall when compared to the treebank parse	0	4	2
W97-0301	P95-1037	1997	For example, an actual contextual predicate based on the template cons0 might be Does cons0   NP, he  	0	Constituent head words are found, when necessary, with the algorithm in <TREF>Magerman, 1995</TREF>	1	Contextual predicates which look at head words, or especially pairs of head words, may not be reliable predictors for the procedure actions due to their sparseness in the training sample	0	Therefore, for each lexically based contextual predicate, there also exist one or more corresponding less specific, or backed-off, contextual predicates which look at the same context, but omit one or more words	0	6	1
P99-1047	P95-1037	1999	The algorithm exploits robust lexical, syntactic, and semantic knowledge sources	0	I Introduction The application of decision-based learning techniques over rich sets of linguistic features has improved significantly the coverage and performance of syntactic and to various degrees semantic parsers <REF>Simmons and Yu, 1992</REF>; <TREF>Magerman, 1995</TREF>; <REF>Hermjakob and Mooney, 1997</REF>	1	In this paper, we apply a similar paradigm to developing a rhetorical parser that derives the discourse structure of unrestricted texts	1	Crucial to our approach is the reliance on a corpus of 90 texts which were manually annotated with discourse trees and the adoption of a shift-reduce parsing model that is well-suited for learning	0	4	2
P99-1047	P95-1037	1999	The matrix shows that the segmenter has problems mostly with identifying the beginning of parenthetical units and the intra-sentential edu boundaries; for example, it correctly identifies only 133 of the 220 ZLeaming from binary representations of features in the Brown corpus was too computationally expensive to terminate -the Brown data file had about 05GBytes	0	5 The shift-reduce action identifier, 51 Generation of learning examples The learning cases were generated automatically, in the style of <TREF>Magerman 1995</TREF>, by traversing inorder the final rhetorical structures built by annotators and by generating a sequence of discourse parse actions that used only SHIFT and REDUCE operations of the kinds discussed in section 3	1	When a derived sequence is applied as described in the parsing model, it produces a rhetorical tree that is a one-to-one copy of the original tree that was used to generate the sequence	0	For example, the tree at the bottom of figure 1 -the tree found at the top of the stack at step i  4 -can be built if the following sequence of operations is performed: SHIFT 12; SHIFT 13; REDUCE-ATTRIBUTION-NS; SHIFT 14; REDUCE-JOINT-NN; SHIFT 15; REDUCE-CONTRASTSN, SHIFT 16, SHIFT 7; REDUCE-CONDITIONSN; SHIFT 18; SHIFT 19; REDUCE-APPOSITION-NS; REDUCE-ATTRIBUTION-NS; REDUCE-ELABORATIONNS	0	6	1
A00-2002	P95-1037	2000	If for any tuple Ts, Tt, C> such a sequence of actions can be derived, it is then possible to use a corpus of Ts, Tt, C tuples in order to automatically learn to derive from an unseen tree Ts,, which has the same structural properties as the trees Ts, a tree Ttj, which has structural properties similar to those of the trees Tt	0	In order to solve the problem in definition 31, we extend the shift-reduce parsing paradigm applied by <TREF>Magerman 1995</TREF>, <REF>Hermjakob and Mooney 1997</REF>, and <REF>MarcH 1999</REF>	1	In this extended paradigm, the transfer process starts with an empty Stack and an Input List that contains a sequence of elementary discourse trees edts, one edt for each edu in the tree Ts given as input	0	The status and rhetorical relation associated with each edt is undefined	0	3	2
C00-2116	P95-1037	2000	If an erroneous string is extracted, its errors will propagate through the rest of the input :trings	0	:3 Our Approach 31 The C45 Learning Algorithm Decision tree induction algorithms have been successfully applied for NLP problems such as sentence boundary dismnbiguation <REF>Pahner et al 1997</REF>, parsing <TREF>Magerman 1995</TREF> and word segmentation <REF>Mekuavin et al 1997</REF>	1	We employ the c45 <REF>Quinhln 1993</REF> decision tree induction program as the learning algorithm for word extraction	0	The induction algorithm proceeds by evaluating content of a series of attributes and iteratively building a tree fiom the attribute values with the leaves of the decision tree being the value of the goal attribute	0	4	2
P01-1037	P95-1037	2001	By implementing our own version of the publicly available Collins parser <REF>Collins, 1996</REF>, we also learned a dependency model that enables the mapping of parse trees into sets of binary relations between the head-word of each constituent and its sibling-words	1	For example, the parse tree of TREC-9 question Q210: How many dogs pull a sled in the Iditarod  is: JJ S Iditarod VP NP PP NP NNPDTINNN NP DTVBPNNS NP manyHow WRB dogs pull a sled in the For each possible constituent in a parse tree, rules first described in <TREF>Magerman, 1995</TREF> and <REF>Jelinek et al , 1994</REF> identify the head-child and propagate the head-word to its parent	1	For the parse of question Q210 the propagation is: NP sled DT NN DTIN manyHow WRB dogs NNSJJ NP dogs VBP pull a sled in the Iditarod NNP Iditarod NP Iditarod PP Iditarod NP sled VP pull S pull When the propagation is over, head-modifier relations are extracted, generating the following dependency structure, called question semantic form in <REF>Harabagiu et al , 2000</REF>	0	dogs IditarodCOUNT pull sled In the structure above, COUNT represents the expected answer type, replacing the question stem how many	0	4	2
X96-1028	P95-1037	1996	Two new heavyweight algorithms were developed in the last year	1	One is a full parser of English, using a statistically learned decision procedure; SPATTER has achieved the highest scores yet reported on parsing English text <TREF>Magerman, 1995</TREF>	1	Because the measurable improvement in parsing is so great compared to manually constructed parsers, it appears to offer a qualitatively better parser	0	We are looking ormat De scription Message Message Reader I M orphologieal Analyzer  Lexieai Pattern Matcher  Fast Partial Parser  Semantic Interpreter  entene e-Level Pattern Matcher Discourse  Format  S GML Handling Initial Iden tification of Entities Grouping Words into Meaningful Phrases Establish Relationships within sentences Establish Relationships Overall ----Template/Annotation Generator I Output Entities and Relationships  Output Figure 2: PLUM System Architecture: Rectangles represent domain-independent, language-independent algorithms; ovals represent knowledge bases	0	4	2
X96-1028	P95-1037	1996	For example, statistical techniques may have suggested the importance of hire, a verb which many groups did not happen to define	1	Second, since there has been a marked improvement in the quality of full parsers, now achieving an F in the high 80s <TREF>Magerman, 1995</TREF>, we believe it is now feasible to consider using full parsers again	1	The rationale is straightforward: for full templates eg , ST scores have been mired with an F in the 50s ever since MUC-3 in 1991	0	Pattern matching has given us very robust, very portable technology, but has not broken the performance barrier all systems have run up against	0	4	2
X96-1028	P95-1037	1996	137 applicable information extraction functionality such as NE and TE will be a win, maximizing the value of defining reusable knowledge bases for information extraction	0	We developed a full parser of English, using a statistically learned decision procedure; SPATTER has achieved the highest scores yet report on parsing English text <TREF>Magerman, 1995</TREF>	1	The fact that its recall and precision are both in the high 80s represents not just a quantitative improvement in parser performance, but also a qualitative improvement	0	The NLU Shell provides a way for nonprogrammers to build and maintain information extraction systems based on PLUM	0	2	1
W97-0123	P95-1037	1997	B,	0	I I  As in the case of the models of <REF>Black 1993</REF>, <TREF>Magerman 1995</TREF>, and <REF>Collins 1996</REF>, this paper proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis	1	However, unlike the models of <REF>Black 1993</REF>, <TREF>Magerman 1995</TREF>, and <REF>Collins 1996</REF>, we put an assumption that syntactic and lexical/semantie features are independent	0	Then, we focus on extracting lexical/semantic collocational knowledge of verbs which is useful in syntactic analysis	0	4	2
W97-0123	P95-1037	1997	In those research, extracted lexical/semantic collocation is especially useful in terms of ranking parses in syntactic analysis as well as automatic construction of lexicon for NLP	1	For example, in the context of syntactic disambiguation, <REF>Black 1993</REF> and <TREF>Magerman 1995</TREF> proposed statistical parsing models based-on decision-tree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees	1	As lexical/semantic information, <REF>Black 1993</REF> used about 50 semantic categories, while <TREF>Magerman 1995</TREF> used lexical forms of words	0	<REF>Collins 1996</REF> proposed a statistical parser which is based on probabilities of dependencies between head-words in the parse tree	0	4	2
W97-0123	P95-1037	1997	I I  As in the case of the models of <REF>Black 1993</REF>, <TREF>Magerman 1995</TREF>, and <REF>Collins 1996</REF>, this paper proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis	0	However, unlike the models of <REF>Black 1993</REF>, <TREF>Magerman 1995</TREF>, and <REF>Collins 1996</REF>, we put an assumption that syntactic and lexical/semantie features are independent	1	Then, we focus on extracting lexical/semantic collocational knowledge of verbs which is useful in syntactic analysis	0	More specifically, we propose a novel method for learning a probabilistic model of subcategorization preference of verbs	0	2	1
W97-0123	P95-1037	1997	For example, in the context of syntactic disambiguation, <REF>Black 1993</REF> and <TREF>Magerman 1995</TREF> proposed statistical parsing models based-on decision-tree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees	0	As lexical/semantic information, <REF>Black 1993</REF> used about 50 semantic categories, while <TREF>Magerman 1995</TREF> used lexical forms of words	1	<REF>Collins 1996</REF> proposed a statistical parser which is based on probabilities of dependencies between head-words in the parse tree	0	In those works, lexical/semantic collocation are used for ranking parses in syntactic analysis	0	2	1
P98-1048	P95-1037	1998	A distinctive feature of our work is the fact that we used machine learning techniques to improve an existing rule-based natural language processor from the inside	0	This contrasts with approaches where there are essentially no explicit rules, such as neural networks eg <REF>Buo 1996</REF>, or approaches where the machine learning algorithms attempt to infer--via deduction eg <REF>Samuelsson 1994</REF>, induction eg <REF>Theeramunkong et al 1997</REF>; <REF>Zelle  Mooney 1994</REF> under user cooperation eg <REF>Simmons  Yu 1992</REF>; <REF>Hermjakob  Mooney 1997</REF>, transformation-based error-driven learning eg <REF>Brill 1993</REF>, or even decision trees eg <TREF>Magerman 1995</TREF>--a grammar from raw or preprocessed data	1	In our work, we do not wish to acquire a grammar: we have one and want to devise a mechanism to make some of its parts adaptable to the corpus at hand or, to improve some aspect of its performance	0	Other researchers, such as <REF>Lawrence et al 1996</REF>, have compared neural networks and machine learning methods at the task of sentence classification	0	2	1
P97-1062	P95-1037	1997	We have extended their work by significantly increasing the expressiveness of the parse action and feature languages, in particular by moving far beyond the few simple features that were limited to syntax only, by adding more background knowledge and by introducing a sophisticated machine learning component	0	<TREF>Magerman, 1995</TREF> uses a decision tree model similar to ours, training his system SPATTER	1	with parse action sequences for 40,000 Wall Street Journal sentences derived from the Penn Treebank <REF>Marcus et al , 1993</REF>	0	Questioning the traditional n-grams, Magerman already advocates a heavier reliance on contextual information	0	2	1
W98-0701	P95-1037	1998	The key to extraction of the relations is that any phrase can be substituted by the corresponding tree head-word links marked bold in Figure 1	0	To determine the tree head-word we used a set of rules similar to that described by <TREF>Magerman, 1995</TREF><REF>Jelinek et al , 1994</REF> and also used by <REF>Collins, 1996</REF>, which we modified in the following way:  The head of a prepositional phrase PP-IN NP was substituted by a function the name of which corresponds to the preposition, and its sole argument corresponds to the head of the noun phrase NP	1	The head of a subordinate clause was changed to a function named after the head of the first element in the subordinate clause usually that or a NULL element and its sole argument corresponds to the head of its second element usually head of a sentence	0	Because we assumed that the relations within the same phrase are independent, all the relations are between the modifier constituents and the head of a phrase only	0	3	2
W97-1003	P95-1037	1997	When inspecting manually, the binary word tree representation appears to be the most easy to understand	1	A second application of the binary word tree can be found in decision-tree based systems such as the SPATTER parser <TREF>Magerman, 1995</TREF> or the ATR Decision-Tree Part-Of-Speech Tagger, as described by Ushioda <REF>Ushioda, 1996</REF>	1	In this case it is necessary to use a hard-clustering method, such that a binary word tree can be constructed by the clustering process, as we did in the example in the previous sections	0	A decision tree classifies data according to its properties by asking successive often binary questions	0	4	2
W97-1003	P95-1037	1997	The mentioned studies use word-clusters for interpolated n-gram language models	0	Another application of hard clustering methods in particular bottom-up variants is that they can also produce a binary tree, which can be used for decision-tree based systems such as the SPATTER parser <TREF>Magerman, 1995</TREF> or the ATR Decision-Tree Part-OfSpeech Tagger <REF>Black et al , 1992</REF>, <REF>Ushioda, 1996</REF>	1	Hogenhout  Matsumoto 18 Word Clustering from Syntactic Behavior In this case a decision tree contains binary questions to decide the properties of a word	0	We present a hard clustering algorithm, in the sense that every word belongs to exactly one cluster or is one leaf in the binary word-tree of a particular part of speech	0	4	2
P05-1038	P95-1037	2005	These results have important implications for crosslinguistic parsing research, as they allow us to tease apart language-specific and annotationspecific effects	0	Previous work for English eg , <TREF>Magerman, 1995</TREF>; <REF>Collins, 1997</REF> has shown that lexicalization leads to a sizable improvement in parsing performance	1	English is a language with nonflexible word order and with a treebank with a nonflat annotation scheme see Table 2	0	Research on German <REF>Dubey and Keller, 2003</REF> showed that lexicalization leads to no sizable improvement in parsing performance for this language	0	4	2
P05-1038	P95-1037	2005	A second recent strand in parsing research has dealt with the role of lexicalization	0	The conventional wisdom since <TREF>Magerman 1995</TREF> has been that lexicalization substantially improves performance compared to an unlexicalized baseline model eg , a probabilistic context-free grammar, PCFG	1	However, this has been challenged by <REF>Klein and Manning 2003</REF>, who demonstrate that an unlexicalized model can achieve a performance close to the state of the art for lexicalized models	0	<REF>Furthermore, Bikel 2004</REF> provides evidence that lexical information in the form of bi-lexical dependencies only makes a small contribution to the performance of parsing models such as <REF>Collinss 1997</REF>	0	6	1
J97-2002	P95-1037	1997	342 Decision Tree	0	Algorithms for decision tree induction <REF>Quinlan 1986</REF>; <REF>Bahl et al 1989</REF> have been successfully applied to NLP problems such as parsing <REF>Resnik 1993</REF>; <TREF>Magerman 1995</TREF> and discourse analysis <REF>Siegel and McKeown 1994</REF>; <REF>Soderland and Lehnert 1994</REF>	1	We tested the Satz system using the c45 <REF>Quinlan 1993</REF> decision tree induction program as the learning algorithm and compared the results to those obtained previously with the neural network	0	These results are discussed in Section 410	0	4	2
C00-2109	P95-1037	2000	rile detfil of our statistic framework is described ill <REF>Uehimoto et al , 1999</REF>	0	There have been a lot of prolOSfls for statistical analysis, in ninny languages, in particular in English and Japanese <TREF>Magerman, 1995</TREF> <REF>Sekine and Grishman, 1995</REF> <REF>Collins, 1997</REF> I/atnalarkhi, 1997 KShirai etal, 1998 <REF>Fujio and Matsnlnoto, 1998</REF> Itaruno ctal, 1997<REF>Ehara, 1998</REF>	1	One of the most advancet systems in English is lroposed 1y Iatnaparkhi	0	It, uses the Maximum Entropy ME model and both of the accuracy and the speed of the system arc among the best retortcd to date	0	6	1
W00-1307	P95-1037	2000	In order to construct the etrees, which make such distinction, LexTract requires its user to provide additional information in the form of three tables: a Head Percolation Table, an Argument Table, and a Tagset Table	1	A Head Percolation Table has previously been used in several statistical parsers <TREF>Magerman, 1995</TREF>; <REF>Collins, 1997</REF> to find heads of phrases	1	Our strategy for choosing heads is similar to the one in <REF>Collins, 1997</REF>	1	An Argument Table informs LexTract what types of arguments a head can take	0	4	2
W05-1512	P95-1037	2005	To start with performance values, Table 3 displays previous results on parsing Section 23 of the WSJ section of the Penn tree-bank	0	Comparison indicates that our best model is already better than the early lexicalized model of <TREF>Magerman 1995</TREF>	1	It is a bit worse than the unlexicalized PCFGs of <REF>Klein and Manning 2003</REF> and Matsuzaki et al	0	2005, and of course, it is also worse than state-of-the-art lexicalized parsers experience shows that evaluation results on sections 22 and 23 do not differ much	0	1	3
W05-1512	P95-1037	2005	The method of transforming the tree-bank is of major influence on the accuracy and coverage of the statistical parser	1	The most important tree-bank transformation in the literature is lexicalization: Each node in a tree is labeled with its head word, the most important word of the constituent under the node <TREF>Magerman 1995</TREF>, <REF>Collins 1996</REF>, <REF>Charniak 1997</REF>, <REF>Collins 1997</REF>, <REF>Carroll and Rooth 1998</REF>, etc	1	It turns out, however, that lexicalization is not unproblematic: First, there is evidence that full lexicalization does not carry over across different tree-banks for other languages, annotations or domains <REF>Dubey and Keller, 2003</REF>	0	Second, full lexicalization leads to a serious sparse-data problem, which can only be solved by sophisticated smoothing and pruning techniques	0	6	1
W05-1512	P95-1037	2005	We emphasize that our task is to automatically induce a more refined grammar based on a few linguistic principles	1	With automatic refinement it is harder to guarantee improved performance than with manual refinements <REF>Klein and Manning, 2003</REF> or with refinements based on direct lexicalization <TREF>Magerman 1995</TREF>, <REF>Collins 1996</REF>, <REF>Charniak 1997</REF>, etc	1	If, however, our refinement provides improved performance then it has a clear advantage: it is automatically induced, which suggests that it is applicable across different domains, languages and tree-bank annotations	0	Applying our method to the benchmark Penn treebank Wall-Street Journal, we obtain a refined probabilistic grammar that significantly improves over the original tree-bank grammar and that shows performance that is on par with early work on lexicalized probabilistic grammars	1	1	3
W05-1512	P95-1037	2005	Second, estimation from head distributions consistently outperforms estimation from most probable heads for both models	0	Although coarse-grained models clearly benefit from POS information in the heads L  1,2,5, it is surprising that the best models with completely latent heads are on a par with or almost as good as the best ones using POS 122 LP LR F1 Exact CB Model 1 this paper 848 844 846 264 137 <TREF>Magerman 1995</TREF> 849 846 126 Model 2 this paper 857 857 857 293 129 <REF>Collins 1996</REF> 863 858 114 Matsuzaki etal	1	2005 866 867 119 <REF>Klein and Manning 2003</REF> 869 857 863 309 110 <REF>Charniak 1997</REF> 874 875 100 <REF>Collins 1997</REF> 886 881 091 Table 3: Comparison with other parsers sentences of length  40 as head information	0	Finally, our absolutely best model F1857 combines POS tags with latent extra-information L  10 and is estimated from latent-head distributions	0	6	1
W05-1512	P95-1037	2005	Rather, our approach induces head classes for the words h and d from the tree-bank and aims at a exact calculation of rule probabilities prC,classh and dependency probabilities pclassdD,C,classh	1	This is in sharp contrast to the smoothed fixed-word statistics in most lexicalized parsing models derived from sparse data <TREF>Magerman 1995</TREF>, <REF>Collins 1996</REF>, <REF>Charniak 1997</REF>, etc	1	Particularly, class-based dependency probabilities pclassdD,C,classh induced from the tree-bank are not exploited by most of these parsers	0	Second, our method results in an automatic linguistic mark-up of tree-bank grammars	0	2	1
C98-2209	P95-1037	1998	In empirical approaches to parsing, lexical/semantic collocation extracted from corpus has been proved to be quite useful for ranking parses in syntactic analysis	1	For example, <TREF>Magerman 1995</TREF>, <REF>Collins 1996</REF>, and <REF>Charniak 1997</REF> proposed statistical parsing models which incorporated lexical/semantic information	1	In their models, syntactic and lexical/semantic features are dependent on each other and are combined together	0	This paper also proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis	0	4	2
C98-2209	P95-1037	1998	This paper also proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis	0	However, unlike the models of <TREF>Magerman 1995</TREF>, <REF>Collins 1996</REF>, and <REF>Charniak 1997</REF>, we assume that syntactic and lexical/semantic features are independent	1	Then, we focus on extracting lcxical/semantic collocational knowledge of verbs which is useful in syntactic analysis	0	More specifically, we propose a novel method for learning a probability model of subcategorization preference of verbs	0	2	1
C98-1048	P95-1037	1998	A distinctive feature of our work is the fact that we used machine learning techniques to improve an existing rule-based natural language processor from the inside	0	This contrasts with approaches where there are essentially no explicit rules, such as neural networks eg <REF>Buo 1996</REF>, or approaches where the machine learning algorithms attempt to infer--via deduction eg <REF>Samuelsson 1994</REF>, induction eg <REF>Theeramunkong et al 1997</REF>; <REF>Zelle  Mooney 1994</REF> under user cooperation eg <REF>Simmons  Yu 1992</REF>; <REF>Hermjakob  Mooney 1997</REF>, transformation-based error-driven learning eg <REF>Brill 1993</REF>, or even decision trees eg <TREF>Magerman 1995</TREF>--a grammar from raw or preprocessed data	1	In our work, we do not wish to acquire a grammar: we have one and want to devise a mechanism to make some of its parts adaptable to the corpus at hand or, to improve some aspect of its performance	0	Other researchers, such as <REF>Lawrence et al 1996</REF>, have compared neural networks and machine learning methods at the task of sentence classification	0	2	1
P99-1059	P95-1037	1999	2 Notation for context-free grammars The reader is assumed to be familiar with context-free grammars	0	Our notation fol1Other relevant parsers simultaneously consider two or more words that are not necessarily in a dependency relationship <REF>Lafferty et al , 1992</REF>; <TREF>Magerman, 1995</TREF>; <REF>Collins and Brooks, 1995</REF>; <REF>Chelba and Jelinek, 1998</REF>	1	457 lows <REF>Harrison, 1978</REF>; <REF>Hopcroft and Ullman, 1979</REF>	0	A context-free grammar CFG is a tuple G  VN, VT, P, S, where VN and VT are finite, disjoint sets of nonterminal and terminal symbols, respectively, and S E VN is the start symbol	0	1	3
W98-1114	P95-1037	1998	They consider systematically a number of alternative probao bilistic formulations, including those of <REF>Resnik 1992</REF> and <REF>Schabes 1992</REF> and implemented systems based on other underlying grammatical frameworks, evaluating their adequacy from both a theoretical and empirical perspective in terms of their ability to model particular distributions of data that occur in existing treebanks	0	<TREF>Magerman 1995</TREF>, <REF>Collins 1996</REF>, <REF>Ratnaparkhi 1997</REF>, <REF>Charniak 1997</REF> and others describe implemented systems with impressive accuracy on parsing unseen data from the Penn Treebank <REF>Marcus, Santorini  Marcinkiewicz, 1993</REF>	1	These parsers model probabilistically the strengths of association between heads of phrases, and the configurations in which these lexical associations occur	0	The accuracies reported for these systems are substantially better than their non-lexicalised probabilistic context-free grammar analogues, demonstrating clearly the value of lexico-statistical information	0	4	2
C98-1020	P95-1037	1998	In our experiments, the window starts al the sentence prior to that containing the token and extends back W the window size sentences	0	The choice to use sentences as the unit of distance is motivated by our intention to incorporale triggers of this form into a probabilistie treebank based parser and tagger, sneh as <REF>Black et al, 1998</REF>; <REF>Black et al, 1997</REF>; <REF>Brill, 1994</REF>; <REF>Collins, 1996</REF>: aelinek et al, 1994; <TREF>Magerman, 1995</TREF>; blatnaparkhi, 1997	1	All su<h parsers and taggers of which we are aware use only intrasentential information in predicting parses or tags, and we wish to remove this information, as far as possible, from our results ; The window was not allowed to cross a document bmndary	0	The perplexity of lhe task before taking the trigger-pair information into account for tags was 2240 and for rules was 570	0	3	2
P05-1039	P95-1037	2005	In both cases, we report PARSEVAL labeled No suffix With suffix F-score F-score GF Baseline 694 691 Coord GF 702 715 NP case 711 724 PP case 710 727 SBAR 709 726 S GF 713 731 Table 2: Effect of re-annotation and suffix analysis with Markov rules	0	bracket scores <TREF>Magerman, 1995</TREF>, with the brackets labeled by syntactic categories but not grammatical functions	1	Rather than reporting precision and recall of labelled brackets, we report only the F-score, ie the harmonic mean of precision and recall	1	34 Results Table 1 shows the effect of rule type choice, and Table 2 lists the effect of the GF re-annotations	0	2	1
P05-1039	P95-1037	2005	In addition to the standard formulation in Equation 1, we consider two alternative variants of Pr	1	The first is a Markov context-free rule <TREF>Magerman, 1995</TREF>; <REF>Charniak, 2000</REF>	1	A rule may be turned into a Markov rule by first binarizing it, then making independence assumptions on the new binarized rules	0	Binarizing the rule A a0 B1 a8a9a8a9a8 Bn results in a number of smaller rules A a0 B1AB1, AB1 a0 B2AB1B2, a8a9a8a9a8, AB1 a10a10a10 Bn a11 1 a0 Bn	0	2	1
C04-1010	P95-1037	2004	To construct deterministic parsers based on this system, we use classifiers trained on treebank data in order to predict the next transition and dependency type given the current configuration of the parser	0	In this way, our approach can be seen as a form of history-based parsing <REF>Black et al , 1992</REF>; <TREF>Magerman, 1995</TREF>	1	In the experiments reported here, we use memory-based learning to train our classifiers	0	3 Memory-Based Learning Memory-based learning and problem solving is based on two fundamental principles: learning is the simple storage of experiences in memory, and solving a new problem is achieved by reusing solutions from similar previously solved problems <REF>Daelemans, 1999</REF>	0	6	1
C04-1010	P95-1037	2004	used for training and section 23 for testing <REF>Collins, 1999</REF>; <REF>Charniak, 2000</REF>	0	The data has been converted to dependency trees using head rules <TREF>Magerman, 1995</TREF>; <REF>Collins, 1996</REF>	1	We are grateful to Yamada and Matsumoto for letting us use their rule set, which is a slight modification of the rules used by <REF>Collins 1999</REF>	0	This permits us to make exact comparisons with the parser of <REF>Yamada and Matsumoto 2003</REF></REF>, but also the parsers of <REF>Collins 1997</REF> and <REF>Charniak 2000</REF>, which are evaluated on the same data set in <REF>Yamada and Matsumoto 2003</REF></REF>	0	6	1
C98-1088	P95-1037	1998	Second, one might propagate lexical information upward through the productions	1	Examples of formalisms using this approach include the work of <TREF>Magerman 1995</TREF>, <REF>Charniak 1997</REF>, <REF>Collins 1997</REF>, and <REF>Goodman 1997</REF>	1	A more linguistically motivated approach is to expand the domain of productions downward to incorporate more tree structures	0	The Lexicalized Tree-Adjoining Grammar LTAG formalism <REF>Schabes et al, 1988</REF>, <REF>Schabes, 1990</REF> , although not context-free, is the most well-known instance in this category	0	4	2
N03-1030	P95-1037	2003	Our model uses both lexical and syntactic features for determining the probability of inserting discourse boundaries	0	We apply canonical lexical head projection rules <TREF>Magerman, 1995</TREF> in order to lexicalize syntactic trees	1	For each word a45, the upper-most node with lexical head a45 which has a right sibling node determines the features on the basis of which we decide whether to insert a discourse boundary	0	We denote such node a68a70a69, and the features we use are node a68a71a69, its parent a68a73a72, and the siblings of a68a74a69  In the example in Figure 2, we determine whether to insert a discourse boundary after the word says using as features node a68a75a72a65a43a77a76a6a78a79a21a10a80a33a81a33a82a34a80a33a24 and its children a68 a69 a43a83a76a22a84a86a85a34a21a14a80a33a81a26a82a34a80a32a24 and a68a74a87a88a43a90a89a33a84a92a91a6a93a79a21a95a94a8a96a32a97a6a97a22a24  We use our corpus to estimate the likelihood of inserting a discourse boundary between word a45 and the next word using formula 1, a57a58a21a35a59 a60a45a75a37a40a7a55a24a99a98a101a100 a5a8a7a29a21a35a68a73a72a75a102a103a50a52a50a52a50a40a68a104a69a74a42a27a68 a87 a50a52a50a52a50a38a24 a100 a5a8a7a29a21a35a68 a72 a102a105a50a52a50a4a50a55a68 a69 a68a104a87a62a50a4a50a52a50a38a24 1 where the numerator represents all the counts of the rule a68 a72 a102a105a50a52a50a4a50a40a68 a69 a68a104a87a51a50a52a50a52a50 for which a discourse boundary has been inserted after word a45, and the denominator represents all the counts of the rule	0	3	2
W06-1636	P95-1037	2006	Coming to this problem from the standpoint of tree transformation, we naturally view our work as a descendent of <REF>Johnson 1998</REF> and <REF>Klein and Manning 2003</REF>	1	In retrospect, however, there are perhaps even greater similarities to that of <TREF>Magerman, 1995</TREF>; <REF>Henderson, 2003</REF>; <REF>Matsuzaki et al , 2005</REF>	1	Consider the approach of Matsuzaki et al	0	2005	0	2	2
W06-1636	P95-1037	2006	We would like to infer the number of annotations for each nonterminal automatically	0	However, again in retrospect, it is in the work of <TREF>Magerman 1995</TREF> that we see the greatest similarity	1	Rather than talking about clustering nodes, as we do, Magerman creates a decision tree, but the differences between clustering and decision trees are small	1	Perhaps a more substantial difference is that by not casting his problem as one of learning phrasal categories Magerman loses all of the free PCFG technology that we can leverage	0	2	2
W06-1636	P95-1037	2006	<REF>Charniak, 1996</REF>	0	Instead researchers condition parsing decisions on many other features, such as parent phrase-marker, and, famously, the lexical-head of the phrase <TREF>Magerman, 1995</TREF>; <REF>Collins, 1996</REF>; <REF>Collins, 1997</REF>; <REF>Johnson, 1998</REF>; <REF>Charniak, 2000</REF>; <REF>Henderson, 2003</REF>; <REF>Klein and Manning, 2003</REF>; <REF>Matsuzaki et al , 2005</REF> and others	1	One particularly perspicuous way to view the use of extra conditioning information is that of tree-transformation <REF>Johnson, 1998</REF>; <REF>Klein and Manning, 2003</REF>	1	Rather than imagining the parser roaming around the tree for picking up the information it needs, we rather relabel the nodes to directly encode this information	1	2	1
P00-1060	P95-1037	2000	Our experiment quantitatively analyzes several feature types power for syntactic structure prediction and draws a series of interesting conclusions	1	In the field of statistical parsing, various probabilistic evaluation models have been proposed where different models use different feature types <REF>Black, 1992</REF> <REF>Briscoe, 1993</REF> <REF>Brown, 1991</REF> <REF>Charniak, 1997</REF> <REF>Collins, 1996</REF> <REF>Collins, 1997</REF> <REF>Magerman, 1991</REF> <REF>Magerman, 1992</REF> <TREF>Magerman, 1995</TREF> <REF>Eisner, 1996</REF>	1	How to evaluate the different feature types effects for syntactic parsing	0	The paper proposes an information-theory-based feature types analysis model, which uses the measures of predictive information quantity, predictive information gain, predictive information redundancy and predictive information summation to quantitatively analyse the different contextual feature types or feature types combinations predictive power for syntactic structure	0	4	2
P00-1060	P95-1037	2000	Unfortunately, the state of knowledge in this regard is very limited	0	Many probabilistic evaluation models have been published inspired by one or more of these feature types <REF>Black, 1992</REF> <REF>Briscoe, 1993</REF> <REF>Charniak, 1997</REF> <REF>Collins, 1996</REF> <REF>Collins, 1997</REF> <TREF>Magerman, 1995</TREF> <REF>Eisner, 1996</REF>, but discrepancies between training sets, algorithms, and hardware environments make it difficult, if not impossible, to compare the models objectively	1	In the paper, we propose an information-theory-based feature type analysis model by which we can quantitatively analyse the predictive power of different feature types or feature type combinations for syntactic structure in a systematic way	1	The conclusion is expected to provide reliable reference for feature type selection in the probabilistic evaluation modelling for statistical syntactic parsing	0	1	3
W03-1706	P95-1037	2003	PF model describes the probability of each feature in feature set FS taking on specific values when a CFG rule A ->  is given	0	To make the model more practical in parameter estimation, we assume the features in feature set FS are independent from each other, thus:    FSFi AFiPAFSP ,,  5 Under this PCFGPF model, the goal of a parser is to choose a parse that maximizes the following score: ,maxarg 1 AFS i i i n i T PSTScore    6 Our model is thus a simplification of more sophisticated models which integrate PCFGs with features, such as those in <TREF>Magerman1995</TREF>, <REF>Collins1997</REF> and <REF>Goodman1997</REF>	1	Compared with these models, our model is more practical when only small training data is available, since we assume the independence between features	0	For example, in Goodmans probabilistic feature grammar PFG, each symbol in a PCFG is replaced by a set of features, so it can describe specific constraints on the rule	0	4	2
W06-1320	P96-1038	2006	Thematic segmentation also relates to several notions such as speakers intention, topic flow and cohesion	0	Since it is elusive what mental representations humans use in order to distinguish a coherent text, different surface markers <TREF>Hirschberg and Nakatani, 1996</TREF>; <REF>Passonneau and Litman, 1997</REF> and external knowledge sources <REF>Kozima and Furugori, 1994</REF> have been exploited for the purpose of automatic thematic segmentation	1	<REF>Halliday and Hasan 1976</REF> claim that the text meaning is realised through certain language resources and they refer to these resources by the term of cohesion	0	The major classes of such text-forming resources identified in <REF>Halliday and Hasan, 1976</REF> are: substitution, ellipsis, conjunction, reiteration and collocation	0	6	1
J01-1002	P96-1038	2001	A large literature in linguistics and related fields has shown that topic boundaries as well as similar entities such as paragraph boundaries in read speech, or discourselevel boundaries in spontaneous speech are indicated prosodically in a manner that is similar to sentence or utterance boundaries--only stronger	0	Major shifts in topic typically show longer pauses, an extra-high F0 onset or reset, a higher maximum accent peak, greater range in F0 and intensity <REF>Brown, Currie, and Kenworthy 1980</REF>; <REF>Grosz and Hirschberg 1992</REF>; <REF>Nakajima and Allen 1993</REF>; <REF>Geluykens and Swerts 1993</REF>; <REF>Ayers 1994</REF>; <TREF>Hirschberg and Nakatani 1996</TREF></TREF>; <REF>Nakajima and Tsukada 1997</REF>; <REF>Swerts 1997</REF> and shifts in speaking rate <REF>Brubaker 1972</REF>; Koopmans-van geinum and van <REF>Donzel 1996</REF>; <TREF>Hirschberg and Nakatani 1996</TREF></TREF>	1	Such cues are known to be salient for human listeners; in fact, subjects can perceive major discourse boundaries even if the speech itself is made unintelligible via spectral filtering <REF>Swerts, Geluykens, and Terken 1992</REF>	0	Work in automatic extraction and computational modeling of these characteristics has been more limited, with most of the work in computational prosody modeling dealing with boundaries at the sentence level or below	0	6	1
J97-1005	P96-1038	1997	<REF>In Grosz and Hirschberg 1992</REF>, percent agreement see Section 32 among 7 coders on 3 texts under two conditions--text plus speech or text alone--is reported at levels ranging from 743 to 951	0	<REF>In Hirschberg and Nakatani 1996</REF>, average reliability measured using the kappa coefficient discussed in Carletta 1996 of segmentinitial labels among 3 coders on 9 monologues produced by the same speaker, labeled using text and speech, is8 or above for both read and spontaneous speech; values of at least 8 are typically viewed as representing high reliability see Section 32	1	Reliability labeling from text alone is 56 for read and 63 for spontaneous speech	0	Other notions of segment have also been used in evaluating naive or trained coders	0	6	1
J97-1005	P96-1038	1997	Finally, Table 11 shows the results from a set of additional machine learning experiments, in which more conservative definitions of boundary are used	0	For example, using a threshold of seven subjects yields the set of consensus boundaries, as defined in <TREF>Hirschberg and Nakatani 1996</TREF>	1	Comparison with Table 9 shows that for T  5, Learning 1 rather than Learning 2 is the better performer	0	However, the more interesting result is that for T  6 and T  7, the learning approach has an important limitation with respect to the boundary classification task	0	6	1
J97-1005	P96-1038	1997	Many of the studies discussed in the preceding subsection take this approach	0	The types of linguistic features investigated indude prosody <REF>Grosz and Hirschberg 1992</REF>; <REF>Nakatani, Hirschberg, and Grosz 1995</REF>; <TREF>Hirschberg and Nakatani 1996</TREF>; <REF>Swerts 1995</REF>; <REF>Swerts and Ostendorf 1995</REF>, term repetition <REF>Hearst 1994</REF>, cue words <REF>Moser and Moore 1995</REF>; <REF>Whittaker and Stenton 1988</REF>, and discourse anaphora <REF>Walker and Whittaker 1990</REF>	1	<REF>Grosz and Hirschberg 1992</REF> investigate the prosodic structuring of discourse	0	The correlation of various prosodic features with their independently obtained consensus codings of segmental structure codings on which all labelers agreed is analyzed using t-tests; the results support the hypothesis that discourse structure is marked intonationally in read speech	0	6	1
J97-1005	P96-1038	1997	14 Note that the humans did not have access to pause information	0	Other studies have shown that when both speech and text are available to labelers, segmentation is clearer <REF>Swerts 1995</REF> and reliability improves <TREF>Hirschberg and Nakatani 1996</TREF>	1	123 Computational Linguistics Volume 23, Number 1 Table 4 Evaluation for Tj > 4	0	Recall Precision Fallout Error Summed Deviation PAUSE 92 18 54 49 193 CUE 72 15 53 50 216 NP 50 31 15 19 153 Humans 74 55 09 11 91 if cue1  true then boundary else nonboundary Figure 11 Cue word algorithm	0	1	2
J97-1005	P96-1038	1997	For example, pauses tended to precede phrases that initiated segments independent of hierarchical structure and to follow phrases that ended segments	0	Similar results are reported in <REF>Nakatani, Hirschberg, and Grosz 1995</REF> and <TREF>Hirschberg and Nakatani 1996</TREF> for spontaneous speech as well	1	<REF>Grosz and Hirschberg 1992</REF> also use the classification and regression tree system CART <REF>Brieman et al 1984</REF> to automatically construct and evaluate decision trees for classifying aspects of discourse structure from intonational feature values	0	The studies of <REF>Swerts 1995</REF> and <REF>Swerts and Ostendorf 1995</REF> also investigate the prosodic structuring of discourse	0	6	1
J97-1005	P96-1038	1997	The types of discourse units being coded and the relations among them vary	0	Several studies have used trained coders to locally and globally structure spontaneous or read speech using the model of <REF>Grosz and Sidner 1986</REF>, including <REF>Grosz and Hirschberg 1992</REF>; <REF>Nakatani, Hirschberg, and Grosz 1995</REF>; <REF>Stifleman 1995</REF>; <TREF>Hirschberg and Nakatani 1996</TREF>	1	<REF>In Grosz and Hirschberg 1992</REF>, percent agreement see Section 32 among 7 coders on 3 texts under two conditions--text plus speech or text alone--is reported at levels ranging from 743 to 951	0	<REF>In Hirschberg and Nakatani 1996</REF>, average reliability measured using the kappa coefficient discussed in Carletta 1996 of segmentinitial labels among 3 coders on 9 monologues produced by the same speaker, labeled using text and speech, is8 or above for both read and spontaneous speech; values of at least 8 are typically viewed as representing high reliability see Section 32	1	1	2
W97-0601	P96-1038	1997	In 7This tagging can be hand generated, or system generated and hand corrected	0	Preliminary studies indicate that reliability for human tagging is higher for AVM attribute tagging than for other types of discourse segment tagging <REF>Passonneau and Litman, 1997</REF>; <TREF>Hirschberg and Nakatani, 1996</TREF>	1	8Previous work has shown that this can be done with high reliability <REF>Hirschman and Pao, 1993</REF>	0	general, if an utterance U contributes to the information goals of N different attributes, each attribute accounts for 1/N of any costs derivable from U Thus, c2D2 is5	0	6	1
W06-0607	P96-1038	2006	<REF>Wilson and Wiebe 2005</REF> extend this basic annotation scheme to include different types of subjectivity, including Positive Sentiment, Negative Sentiment, Positive Arguing, and Negative Arguing	0	Speech was found to improve inter-annotator agreement in discourse segmentation of monologs <TREF>Hirschberg and Nakatani 1996</TREF>	1	Acoustic clues have been successfully employed for the reliable detection of the speakers emotions, including frustration, annoyance, anger, happiness, sadness, and boredom <REF>Liscombe et al 2003</REF>	0	Devillers et al	0	4	2
P99-1049	P96-1038	1999	Although lexical information is important in English segmentation <REF>Stoleke and Shriberg, 1996</REF>, what other information can help improve such segmentation	0	<TREF>Hirschberg and Nakatani 1996</TREF> showed that prosodic information helps human discourse segmentation	1	<REF>Litman and Passonneau 1995</REF> addressed the usefulness of a multiple knowledge source in human and automatic discourse segmentation	0	<REF>Vendittiand Swerts 1996</REF> stated that the intonational features for many Indo-European languages help cue the structure of spoken discourse	0	6	1
J97-1003	P96-1038	1997	61 Reader Judgments There is a growing concern surrounding issues of intercoder reliability when using human judgments to evaluate discourse-processing algorithms <REF>Carletta 1996</REF>; <REF>Condon and Cech 1995</REF>	0	Proposals have recently been made for protocols for the collection of human discourse segmentation data <REF>Nakatani et al 1995</REF> and for how to evaluate the validity of judgments so obtained <REF>Carletta 1996</REF>; <REF>Isard and Carletta 1995</REF>; Ros6 1995; <REF>Passonneau and Litman 1993</REF>; <REF>Litman and Passonneau 1995</REF>	0	Recently, Hirschberg 52 <REF>Hearst TextTiling and Nakatani 1996</REF> have reported promising results for obtaining higher interjudge agreement using their collection protocols	1	For the evaluation of the TextTiling algorithms, judgments were obtained from seven readers for each of 12 magazine articles that satisfied the length criteria between 1,800 and 2,500 words 9 and that contained little structural demarcation	0	1	2
J97-1003	P96-1038	1997	Proposals have recently been made for protocols for the collection of human discourse segmentation data <REF>Nakatani et al 1995</REF> and for how to evaluate the validity of judgments so obtained <REF>Carletta 1996</REF>; <REF>Isard and Carletta 1995</REF>; Ros6 1995; <REF>Passonneau and Litman 1993</REF>; <REF>Litman and Passonneau 1995</REF>	0	Recently, Hirschberg 52 <REF>Hearst TextTiling and Nakatani 1996</REF> have reported promising results for obtaining higher interjudge agreement using their collection protocols	1	For the evaluation of the TextTiling algorithms, judgments were obtained from seven readers for each of 12 magazine articles that satisfied the length criteria between 1,800 and 2,500 words 9 and that contained little structural demarcation	0	The judges were asked simply to mark the paragraph boundaries at which the topic changed; they were not given more explicit instructions about the granularity of the segmentation	0	1	2
J97-1003	P96-1038	1997	We should expect to see, in grouping together paragraph-sized units instead of utterances, a decrease in the complexity of the feature set and algorithm needed	0	The work described here makes use only of lexical distribution information, in lieu of prosodic cues such as intonational pitch, pause, and duration <TREF>Hirschberg and Nakatani 1996</TREF>, discourse markers such as oh, well, ok, however <REF>Schiffrin 1987</REF>; <REF>Litman and Passonneau 1995</REF>, pronoun reference resolution <REF>Passonneau and Litman 1993</REF>; <REF>Webber 1988</REF> and tense and aspect <REF>Webber 1987</REF>; <REF>Hwang and Schubert 1992</REF>	1	From a computational viewpoint, deducing textual topic structure from lexical occurrence information alone is appealing, both because it is easy to compute, and because discourse cues are sometimes misleading with respect to the topic structure <REF>Brown and Yule 1983</REF>, Section 3	1	4	0	1	3
C04-1020	P96-1038	2004	2 Collecting a database of texts annotated with coherence relations This section describes 1 how we define discourse segments, 2 which coherence relations we used to connect the discourse segments, and 3 how the annotation procedure worked	0	21 Discourse segments Discourse segments can be defined as nonoverlapping spans of prosodic units <TREF>Hirschberg  Nakatani, 1996</TREF>, intentional units <REF>Grosz  Sidner, 1986</REF>, phrasal units <REF>Lascarides  Asher, 1993</REF>, or sentences <REF>Hobbs, 1985</REF>	1	We adopted a sentence unit-based definition of discourse segments	0	However, we also assume that contentful coordinating and subordinating conjunctions cf	0	6	1
W97-0320	P96-1038	1997	The goal in developing the annotation instructions is that they can be used reliably by non-experts after a reasonable amount of training cf	0	<REF>Passonneau  Litman 1993</REF>, <REF>Condon  Cech 1995</REF>, and <TREF>Hirschberg  Nakatani 1996</TREF>, where reliability is measured in terms of the amount of agreement among annotators	1	High reliability indicates that the encoding scheme is reproducible given multiple labelers	0	In addition, the instructions serve to document the annotations	0	6	1
W97-0320	P96-1038	1997	As discussed in <REF>Hays 1988</REF>, J will be 00 when the agreement is what one would expect under independence, and it will be 10 when the agreement is exact	0	A  value of 08 or greater indicates a high level of reliability among raters, with values between 067 and 08 indicating only moderate agreement Hirschberg  <REF>Nakatani 1996</REF>; <REF>Carletta 1996</REF>	1	In addition to measuring intercoder reliability, we compared each coders annotations to the evaluation Temporal Units used to assess the systems performance	0	These evaluation Temporal Units were assigned by an expert working on the project	0	6	1
W97-0320	P96-1038	1997	That is, the systems answers are mapped from its more complex internal representation an ILT, see section 41 into this simpler vector representation before evaluation is performed	0	As in much recent empirical work in discourse processing eg , <REF>Arhenberg et al 1995</REF>; <REF>Isard  Carletta 1995</REF>; <REF>Litman  Passonneau 1995</REF>; <REF>Moser  Moore 1995</REF>; <TREF>Hirschberg  Nakatani 1996</TREF>, we performed an intercoder reliability study investigating agreement in annotating the times	1	The goal in developing the annotation instructions is that they can be used reliably by non-experts after a reasonable amount of training cf	0	<REF>Passonneau  Litman 1993</REF>, <REF>Condon  Cech 1995</REF>, and <TREF>Hirschberg  Nakatani 1996</TREF>, where reliability is measured in terms of the amount of agreement among annotators	1	6	1
P07-1046	P96-1038	2007	Metric F NM S noNM p  user turns 218 53 228 65 065  correct turns 72 18 67 22 059 AsrMis 37 27 46 28 046 SemMis 5 6 12 14 009 Table 2	0	Average standard deviation for objective metrics in the first problem 6 Related work Discourse structure has been successfully used in non-interactive settings eg understanding specific lexical and prosodic phenomena <TREF>Hirschberg and Nakatani, 1996</TREF>, natural language generation <REF>Hovy, 1993</REF>, essay scoring <REF>Higgins et al , 2004</REF> as well as in interactive settings eg predictive/generative models of postural shifts <REF>Cassell et al , 2001</REF>, generation/interpretation of anaphoric expressions <REF>Allen et al , 2001</REF>, performance modeling <REF>Rotaru and Litman, 2006</REF>	1	In this paper, we study the utility of the discourse structure on the user side of a dialogue system	0	One related study is that of <REF>Rich and Sidner, 1998</REF>	0	1	2
P03-1071	P96-1038	2003	Other algorithms exploit a variety of linguistic features that may mark topic boundaries, such as referential noun phrases <REF>Passonneau and Litman, 1997</REF>	0	In work on segmentation of spoken documents, intonational, prosodic, and acoustic indicators are used to detect topic boundaries <REF>Grosz and Hirschberg, 1992</REF>; <REF>Nakatani et al , 1995</REF>; <TREF>Hirschberg and Nakatani, 1996</TREF>; <REF>Passonneau and Litman, 1997</REF>; <REF>Hirschberg and Nakatani, 1998</REF>; <REF>Beeferman et al , 1999</REF>; <REF>Tur et al , 2001</REF>	1	Such indicators include long pauses, shifts in speaking rate, great range in F0 and intensity, and higher maximum accent peak	0	These approaches use different learning mechanisms to combine features, including decision trees <REF>Grosz and Hirschberg, 1992</REF>; <REF>Passonneau and Litman, 1997</REF>; <REF>Tur et al , 2001</REF> exponential models <REF>Beeferman et al , 1999</REF> or other probabilistic models <REF>Hajime et al , 1998</REF>; <REF>Reynar, 1999</REF>	1	2	1
W97-0210	P96-1038	1997	Such observations inform the increasing trend towards analysis of homogeneous corpora to identify linguistic constraints for use in systems intended to understand or generate coherent discourse	0	Recent work in this vein includes identification of lexical constraints from textual tutorial dialogue <REF>Moser and Moore, 1995</REF>, constraints on illocutionary act type from spoken task-oriented dialogue <REF>Allen et al , 1995</REF>, prosodic constraints from spoken information-seeking monologues <TREF>Hirschberg and Nakatani, 1996</TREF>, and constraints on referring expressions from spoken narrative monologue <REF>Passonneau, 1996</REF>	1	Related work suggests that constraints of different types are interdependent <REF>Biber, 1993</REF>; Passonneau and Litman, forthcoming, hence should be investigated together	0	Our ultimate goal is to develop methods to tag lexical semantic features in discourse corpora in order to enhance extraction of constraints of the sort just listed	0	6	1
P07-1128	P96-1038	2007	<REF>Passonneau and Litman 1993</REF> identified that topic shifts often occur after a pause of relatively long duration	0	Other prosodic cues eg , pitch contour, energy have been studied for their correlation with story segments in read speech <REF>Tur et al , 2001</REF>; <REF>Levow, 2004</REF>; <REF>Christensen et al , 2005</REF> and with theory-based discourse segments in spontaneous speech eg , directiongiven monologue <TREF>Hirschberg and Nakatani, 1996</TREF>	1	In addition, head and hand/forearm movements are used to detect group-action based segments <REF>McCowan et al , 2005</REF>; Al-<REF>Hames et al , 2005</REF>	0	However, many other features that we expect to signal segment boundaries have not been studied systematically	0	6	1
N07-1001	P96-1038	2007	In this paper, we describe our framework for building an automatic prosody labeler for English	0	We report results on the Boston University BU Radio Speech Corpus <REF>Ostendorf et al , 1995</REF> and Boston Directions Corpus BDC <TREF>Hirschberg and Nakatani, 1996</TREF>, two publicly available speech corpora with manual ToBI annotations intended for experiments in automatic prosody labeling	1	We condition prosody not only on word strings and their parts-of-speech but also on richer syntactic information encapsulated in the form of Supertags <REF>Bangalore and Joshi, 1999</REF>	0	We propose a maximum entropy modeling framework for the syntactic features	0	6	1
N07-1001	P96-1038	2007	The main drawback of this corpus is that it comprises only read speech	0	Prosody labeling on spontaneous speech corpora like Boston Directions corpus BDC, Switchboard SWBD has garnered attention in <TREF>Hirschberg and Nakatani, 1996</TREF>; <REF>Gregory and Altun, 2004</REF>	1	Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees <REF>Hirschberg, 1993</REF>; <REF>Wightman and Ostendorf, 1994</REF>; <REF>Ma et al , 2003</REF>, rule-based systems <REF>Shimei and McKeown, 1999</REF>, bagging and boosting on CART <REF>Sun, 2002</REF>, hidden markov models <REF>Conkie et al , 1999</REF>, neural networks Hasegawa-<REF>Johnson et al , 2005</REF>,maximum-entropy models <REF>Brenier et al , 2005</REF> and conditional random fields <REF>Gregory and Altun, 2004</REF>	0	Prosody labeling of the BU corpus has been reported in many studies <REF>Hirschberg, 1993</REF>; <REF>HasegawaJohnson et al , 2005</REF>; <REF>Ananthakrishnan and Narayanan, 2005</REF>	0	1	2
W06-1611	P96-1038	2006	In this paper we study the utility of discourse structure as an information source for SDS performance analysis	0	The discourse structure hierarchy has been shown to be useful for other tasks: understanding specific lexical and prosodic phenomena <TREF>Hirschberg and Nakatani, 1996</TREF>; <REF>Levow, 2004</REF>, natural language generation <REF>Hovy, 1993</REF>, predictive/generative models of postural shifts <REF>Cassell et al , 2001</REF>, and essay scoring <REF>Higgins et al , 2004</REF>	1	We perform our analysis on a corpus of speech-based tutoring dialogues	0	A tutoring SDS <REF>Litman and Silliman, 2004</REF>; Pon-<REF>Barry et al , 2004</REF> has to discuss concepts, laws and relationships and to engage in complex subdialogues to correct student misconceptions	0	6	1
W06-1611	P96-1038	2006	For example, in Figure 1, if the student would have answered Tutor 2 correctly, the next tutor turn would have had the same content as Tutor 5 but the Advance label	0	Also, while a human annotation of the discourse structure will be more complex but more time consuming <TREF>Hirschberg and Nakatani, 1996</TREF>; <REF>Levow, 2004</REF>, its advantages are outweighed by the automatic nature of our discourse structure annotation	1	We would like to highlight that our transition annotation is domain independent and automatic	0	Our transition labels capture behavior like starting a new dialogue NewTopLevel, crossing discourse segment boundaries Push, PopUp, PopUpAdv and local phenomena inside a discourse segment Advance, SameGoal	0	1	2
J97-1001	P96-1038	1997	They develop and evaluate three algorithms for producing the target behavior from these features, two hand-developed and one automatically induced	0	Generalizations of this work arise from other research on different speech genres In different environments that also found that coreferential relationships, pausing, and intonation are correlated with discourse structure <REF>Cahn 1992</REF>; <REF>Fox 1987</REF>; <TREF>Hirschberg and Nakatani 1996</TREF>	1	Future work can further test the generalizability of the results reported here: the features used could be examined in other types of spoken monologues, in texts, and in dialogue	0	35 Smith and Gordon Smith and Gordon examine the effect of initiative on dialogue structure in dialogues in which human subjects interact with the computer to diagnose and repair problems with simple circuits	0	6	1
J97-1001	P96-1038	1997	Discourse tagging classifies discourse units in naturally occurring texts or dialogues into one of a set of categories	0	Discourse units range from referring expressions and syntactic constructions <REF>Fox 1987</REF>; <REF>Kroch and Hindle 1982</REF>; <REF>Prince 1985</REF>, to words or phrases <REF>Heeman and Allen 1994</REF>; <REF>Hirschberg and Litman 1993</REF>; <REF>Novick and Sutton 1994</REF>, to utterances and relationships among them <REF>Dahlback 1991</REF>; <REF>Reithinger and Maier 1995</REF>; <REF>Moser and Moore 1995</REF>; <REF>Nagata 1992</REF>; <REF>Rose et al 1995</REF>, to multiutterance units identified by a range of criteria such as speaker intention or initiative <REF>Flammia and Zue 1995a</REF>; <TREF>Hirschberg and Nakatani 1996</TREF>; <REF>Whittaker and Stenton 1988</REF>	1	The article by Carletta et al	0	this volume presents a tagging scheme for three levels of discourse structure	0	6	1
J97-1001	P96-1038	1997	Hearsts algorithm performs comparably to other algorithms on the new task, showing that term repetition may be a more general indicator of subtopic boundaries	0	Future work could test further generalizations; term repetition may also indicate subtopics in other discourse or dialogue environments, and may interact with other features that correlate with topic boundaries, such as pauses, intonation, or cue words <REF>Cahn 1992</REF>; <TREF>Hirschberg and Nakatani 1996</TREF>	1	33 Lester and Porter The target behavior that concerns Lester and Porter is generating paragraph-length explanations in the biology domain	0	Given a goal to explain a biology concept or process, their KNIGHT system selects relevant information from a large knowledge base, organizes it, and then generates it	0	6	1
C08-1129	P96-1038	2008	<REF>Ayers 1992</REF> found that pitch range appears to correlate more closely with hierarchical topic structure in read speech than in spontaneous speech	0	In spontaneous monologue, <REF>Butterworth 1972</REF> found that the beginning of a discourse segment exhibited slower speaking rate; <REF>Swerts 1995</REF>, and <REF>Passonneau and Litman 1997</REF> found that pause length correlates with discourse segment boundaries; <TREF>Hirschberg and Nakatani 1996</TREF> found that the beginning of a discourse segment correlates with higher pitch	1	In humanhuman dialogue, similar behavior was observed: the pitch value tends to be higher for starting a new discourse segment <REF>Nakajima and Allen, 1993</REF>	0	In human-computer dialogue, <REF>Swerts and Ostendorf 1995</REF> found that the first utterance of a discourse segment correlates with slower speaking rate and longer preceding pause	0	6	1
P98-2155	P96-1038	1998	Form of expression feature values areadverbial noun, cardinal, definite NP, demonstrative NP, indefinite NP, pronoun, proper name, quantifier NP, verbal noun, etc 334 Global focus feature The global focusing status of baseNPs is computed using two sets of analyses: discourse segmentations and coreference coding	0	Expert discourse structure analyses are used to derive CONSENSUS SEGMENTATIONS, consisting of discourse boundaries whose coding all three labelers agreed upon <TREF>Hirschberg and Nakatani, 1996</TREF>	1	The consensus labels for segment-initial boundaries provide a linear segmentation of a discourse into discourse segments	0	Coreferential relations are coded by two labelers using DTT Discourse Tagging Tool <REF>Aone and Bennett, 1995</REF>	0	6	1
W06-1612	P96-1038	2006	Information status has generated large interest among researchers because of its complex interaction with other linguistic phenomena, thus affecting several Natural Language Processing tasks	0	Since it correlates with word order and pitch accent <REF>Lambrecht, 1994</REF>; <TREF>Hirschberg and Nakatani, 1996</TREF>, for instance, incorporating knowledge on information status would be helpful for natural language generation, and in particular text-tospeech systems	1	Stober and colleagues, for example, ascribe to the lack of such information the lower performance of text-to-speech compared to concept-to-speech generation, where such knowledge could be made directly available to the system <REF>Stober et al , 2000</REF>	0	Another area where information status can play an important role is anaphora resolution	0	1	2
P07-1064	P96-1038	2007	The segmentation algorithm presented in this paper focuses on one source of linguistic information for discourse analysis  lexical cohesion	0	Multiple studies of discourse structure, however, have shown that prosodic cues are highly predictive of changes in topic structure <TREF>Hirschberg and Nakatani, 1996</TREF>; <REF>Shriberg et al , 2000</REF>	1	In a supervised framework, we can further enhance audio-based segmentation by combining features derived from pattern analysis with prosodic information	0	We can also explore an unsupervised fusion of these two sources of information; for instance, we can induce informative prosodic cues by using distributional evidence	0	2	1
P07-1064	P96-1038	2007	Others are specifically adapted for processing speech input by adding relevant acoustic features such as pause length and speaker change <REF>Galley et al , 2003</REF>; <REF>Dielmann and Renals, 2005</REF>	1	In parallel, researchers extensively study the relationship between discourse structure and intonational variation <TREF>Hirschberg and Nakatani, 1996</TREF>; <REF>Shriberg et al , 2000</REF>	1	However, all of the existing segmentation methods require as input a speech transcript of reasonable quality	0	In contrast, the method presented in this paper does not assume the availability of transcripts, which prevents us from using segmentation algorithms developed for written text	0	2	1
P97-1035	P96-1038	1997	9This tagging can be hand generated, or system generated and hand corrected	0	Preliminary studies indicate that reliability for human tagging is higher for AVM attribute tagging than for other types of discourse segment tagging <REF>Passonneau and Litman, 1997</REF>; <TREF>Hirschberg and Nakatani, 1996</TREF>	1	:EAC, DR, D :AIA9 SEGcr: S3 SMlCr: S4 G0: I GOALS: AC orrcES: A3u5 0TI/ES: A6U6 Figure 4: Task-defined discourse structure of Agent A dialogue interaction utterances that contribute to the success of the whole dialogue, such as greetings, are tagged with all the attributes	0	Since the structure of a dialogue reflects the structure of the task <REF>Carberry, 1989</REF>; <REF>Grosz and Sidner, 1986</REF>; <REF>Litman and Allen, 1990</REF>, the tagging of a dialogue by the AVM attributes can be used to generate a hierarchical discourse structure such as that shown in Figure 4 for Dialogue 1 Figure 2	0	6	1
C98-2150	P96-1038	1998	Form of expression feature values are adverbial noun, cardinal, definite NP, demonstrative NP, indefinite NP,, pronoun, proper name, quantifier NP,, verbal noun, etc 334 Global focus feature The global focusing status of baseNPs is computed using two sets of analyses: discourse segmentations and coreference coding	0	Expert discourse structure analyses are used to derive CONSENSUS SEGMENTATIONS, consisting of discourse boundaries whose coding all three labelers agreed upon <TREF>Hirschberg and Nakatani, 1996</TREF>	1	The consensus labels for segment-initial boundaries provide a linear segmentation of a discourse into discourse segments	0	Coreferential relations are coded by two labelers using DTT Discourse Tagging Tool <REF>Aone and Bennett, 1995</REF>	0	6	1
C96-1001	P96-1038	1996	This talk will begin with a summary of pilot studies that demonstrated reliable correlations of discourse structure and intonational features <REF>Grosz and Hirschberg, 1992</REF>; <REF>Hirschberg and Grosz, 1992</REF>; <REF>Hirschberg and Grosz, 1994</REF>	0	It will then tbcus on a new corpus of directiongiving monologues, the Boston Directions Corpus <REF>Nakatani et al , 1995a</REF>; <TREF>Hirschberg and Nakatani, 1996</TREF>	1	I will describe the methodology we developed to elicit fluent spontaneous direction-giving monologues ranging over a spectrum of planning complexity	0	Next I will describe the development of annotation instructions used to train labelers to segment spoken discourses <REF>Nakatani et al , 1995b</REF> and will discuss agreement among segmentations on the Boston Directions Corpus obtained using these instructions	0	6	1
J02-1002	P96-1038	2002	More recently, a great deal of interest has arisen in using automatic segmentation for the detection of topic and story boundaries in news feeds <REF>Mani et al 1997</REF>; <REF>Merlino, Morey, and Maybury 1997</REF>; <REF>Ponte and Croft 1997</REF>; <REF>Hauptmann and Witbrock 1998</REF>; <REF>Allan et al 1998</REF>; <REF>Beeferman, Berger, and Lafferty 1997, 1999</REF>	0	Sometimes segmentation is done at the clause level, for the purposes of detecting nuances of dialogue structure or for more sophisticated discourse-processing purposes <REF>Morris and Hirst 1991</REF>; <REF>Passonneau and Litman 1993</REF>; <REF>Litman and Passonneau 1995</REF>; <TREF>Hirschberg and Nakatani 1996</TREF>; <REF>Marcu 2000</REF>	1	Some of these algorithms produce hierarchical dialogue segmentations whose evaluation is outside the scope of this discussion	0	11 Evaluating Segmentation Algorithms There are two major difficulties associated with evaluating algorithms for text segmentation	0	6	1
W99-0313	P96-1038	1999	Nine coders provided IU trees starting from identical CGUs	0	Following the methodology in ttirschberg and <REF>Nakatani, 1996</REF>, we measured the reliability of coding for a linearized version of the IU tree, by calculating the reliability of coding of IU beginnings using the kappa metric	1	We calculated the observed pairwise agreement of CGUs marked as the beginnings of IUs, and factored out the expected agreement estimated from the actual data, giving the pairwise kappa score	0	Table 3 gives the raw data on coders marking of IU beginnings	0	3	2
W04-2323	P96-1038	2004	Next, we present several automatic methods to combine multiple human-annotated discourse segmentations into one gold standard	0	21 Flat vs Hierarchical Approaches Most previous work that has combined multiple annotations has used linear segmentations, ie discourse segmentations without hierarchies <TREF>Hirschberg and Nakatani, 1996</TREF>	1	In general, the hierarchical nature of discourse structure has not been considered when computing labeler inter-reliability and in evaluations of agreement with automatic methods	0	Since computational discourse theory relies on the hierarchy of its segments, we will consider it in this paper	0	6	1
W04-2323	P96-1038	2004	<REF>Rotondo 1984</REF> reported that hierarchical segmentation is impractical for naive subjects in discourses longer than 200 words <REF>Passonneau and Litman 1993</REF> conducted a pilot study in which subjects found it difficult and time-consuming to identify hierarchical relations in discourse	0	Other attempts have had more success using improved annotation tools and more precise instructions <REF>Grosz and Hirschberg, 1992</REF>; <TREF>Hirschberg and Nakatani, 1996</TREF>	1	Second, hierarchical segmentation of discourse is subjective	0	While agreement among annotators regarding linear segmentation has been found to be higher than 80 <REF>Hearst, 1997</REF>, with respect to hierarchical segmentation it has been observed to be as low as 60 <REF>Flammia and Zue, 1995</REF>	0	4	2
W04-2323	P96-1038	2004	However, annotation unification approaches have not been formally evaluated, and although manual unification might be the best approach, it can be time-consuming	0	Indeed, much of the work on automatic recognition of discourse structure has focused on linear, rather than hierarchical segmentation <REF>Hearst, 1997</REF>; <TREF>Hirschberg and Nakatani, 1996</TREF>, because of the difficulties of obtaining consistent hierarchical annotations	1	In addition, those approaches that do handle hierarchical segmentation do not address automatic unification methods <REF>Carlson et al , 2001</REF>; <REF>Marcu, 2000</REF>	0	There are several reasons for the prevailing emphasis on linear annotation and the lack of work on automatic methods for unifying hierarchical discourse annotations	0	6	1
C04-1177	P98-2127	2004	Let a28a30a40a30a11a14a28a21a40a30a28a16a31a36a3a41a34 be the set of senses of a3  For each sense of a3 a3a42a28a44a43a46a45a47a28a30a40a30a11a14a28a21a40a30a28a16a31a36a3a41a34  we obtain a ranking score by summing over the a27a48a28a21a28a16a31a32a3a6a15a33a11a50a49a30a34 of each neighbour a11a50a49a51a45a52a4a6a5  multiplied by a weight	0	This weight is the WordNet similarity score a3a42a11a14a28a30a28  between the target sense a3a53a28a35a43  and the sense of a11a54a49 a11a14a28a35a55a56a45a57a28a30a40a30a11a14a28a21a40a30a28a16a31a36a11a54a49a16a34  that maximises this score, divided by the sum of all such WordNet similarity scores for a28a30a40a21a11a19a28a21a40a30a28a26a31a32a3a41a34 and a11a50a49  Thus we rank each sense a3a42a28 a43 a45a10a28a30a40a21a11a19a28a21a40a30a28a26a31a32a3a41a34 using:a58a41a59 a11a14a2a54a60a61a11a50a62a64a63a66a65a35a67a16a68a12a40a26a31a32a3a53a28 a43 a34a69a7 a70 a71a44a72a33a73a16a74a76a75 a27a48a28a21a28a16a31a32a3a6a15a33a11a50a49a30a34a30a77 a3a42a11a14a28a21a28a16a31a32a3a53a28a35a43a36a15a33a11a50a49a30a34 a78 a5a19a79a81a80a39a82 a73 a79a61a83 a71 a79a81a83a61a79a36a84a85a5a19a86 a3a53a11a14a28a30a28a26a31a32a3a42a28 a43 a82 a15a17a11 a49 a34 1 where: a3a42a11a14a28a21a28a16a31a32a3a53a28a35a43a87a15a17a11a54a49a21a34a66a7 a88a46a89a21a90 a71 a79a92a91 a73 a79a81a83 a71 a79a81a83a61a79a93a84 a71a44a72 a86 a31a36a3a42a11a14a28a30a28a26a31a32a3a53a28a35a43a36a15a33a11a14a28a35a55a29a34a87a34 22 Acquiring the Automatic Thesaurus There are many alternative distributional similarity measures proposed in the literature, for this work we used the measure and thesaurus construction method described by <TREF>Lin 1998</TREF>	1	For input we used grammatical relation data extracted using an automatic parser <REF>Briscoe and Carroll, 2002</REF>	0	For each noun we considered the co-occurring verbs in the direct object and subject relation, the modifying nouns in noun-noun relations and the modifying adjectives in adjective-noun relations	0	3	2
N07-3002	P98-2127	2007	Importantly, inter-dependence between links can still be accommodated by exploiting dynamic features in training features that take into account the labels of some of the surrounding components when predicting the label of a target component	0	To cope with the sparse data problem, I use distributional word similarity <REF>Pereira et al , 1993</REF>; <REF>Grefenstette, 1994</REF>; <TREF>Lin, 1998</TREF> to generalize the observed frequency counts in the training corpus	1	The experimental results on the Chinese Treebank 40 show that the accuracy of the conditional model is 136 higher than corresponding joint models, while similarity smoothing also allows the strictly lexicalised approach to outperform corresponding models based on part-of-speech tags	0	4 Extensions to Large Margin Parsing The approach presented above has a limitation: it uses a local scoring function instead of a global scoring function to compute the score for a candidate tree	0	3	2
P06-1129	P98-2127	2006	Realword spelling correction is also referred to as context sensitive spelling correction, which tries to detect incorrect usage of valid words in certain contexts <REF>Golding and Roth, 1996</REF>; <REF>Mangu and Brill, 1997</REF>	0	Distributional similarity between words has been investigated and successfully applied in many natural language tasks such as automatic semantic knowledge acquisition <TREF>Dekang Lin, 1998</TREF> and language model smoothing <REF>Essen and Steinbiss, 1992</REF>; <REF>Dagan et al , 1997</REF>	1	An investigation on distributional similarity functions can be found in <REF>Lillian Lee, 1999</REF>	0	3 Distributional Similarity-Based Models for Query Spelling Correction 31 Motivation Most of the previous work on spelling correction concentrates on the problem of designing better error models based on properties of character strings	0	1	2
C02-1162	P98-2127	2002	The calculation of word semantic similarity scores is also a problem that has attracted a lot of interest	0	The numerous notable approaches can usually be divided into those which utilize the hierarchical information from an ontology, such as <REF>Resnik 1995</REF> and <REF>Agirre and Martinez 2002</REF>; and those which simply use word distribution information from a large corpus, such as <TREF>Lin 1998</TREF> and <REF>Lee 1999</REF>	1	9 Conclusion This paper represents a first step towards a corpusbased approach for cross-lingual identification of word concepts and alignment of ontologies	0	The method borrows from techniques used in machine translation and information retrieval, and does not make any assumptions about the structure of the ontology, or use any but the most basic structural information	0	6	1
P03-1016	P98-2127	2003	The formula is described in Equation 12	0	,,, , 212 2 1 2 2 1 1 1 21 relrelsimeesimeesim eesim colcol  12 where ,, 21 iiiicol erelee   We assume that the relation type keeps the same, so 1, 21 relrelsim  The similarity of the words is calculated with the same method as described in <TREF>Lin, 1998</TREF>, which is rewritten in Equation 13	1	The similarity of the words is calculated through the surrounding context words which have dependency relationships with the investigated words	0	,,,, ,,,, , 2 2, 1 1, 21 21, 21 erelewerelew erelewerelew eeSim eTereleTerel eTeTerel  	0	3	2
P03-1016	P98-2127	2003	Up to now, there have been few researches which directly address the problem of extracting synonymous collocations	0	However, a number of studies investigate the extraction of synonymous words from monolingual corpora <REF>Carolyn et al , 1992</REF>; <REF>Grefenstatte, 1994</REF>; <TREF>Lin, 1998</TREF>; <REF>Gasperin et al , 2001</REF>	0	The methods used the contexts around the investigated words to discover synonyms	0	The problem of the methods is that the precision of the extracted synonymous words is low because it extracts many word pairs such as cat and dog, which are similar but not synonymous	1	1	3
P01-1049	P98-2127	2001	3	0	Semantic Correlations Although there exists many methods to derive the semantic correlations between words <REF>Lee, 1999</REF>; <TREF>Lin, 1998</TREF>; <REF>Karov  Edelman, 1998</REF>; <REF>Resnik, 1995</REF>; <REF>Dagan et al, 1995</REF>, we adopt a relatively simple and yet practical and effective approach to derive three topic -oriented semantic correlations: thesaurus-based, co-occurrence-based and contextbased correlation	1	31 Thesaurus based correlation WordNet is an electronic thesaurus popularly used in many researches on lexical semantic acquisition, and word sense disambiguation <REF>Green, 1999</REF>; <REF>Leacock et al, 1998</REF>	0	In WordNet, the sense of a word is represented by a list of synonyms synset, and the lexical information is represented in the form of a semantic network	0	6	1
P08-1003	P98-2127	2008	In this light, the contributions of this paper are fourfold	0	First, instead of separately addressing the tasks of collecting unlabeled sets of instances <TREF>Lin, 1998</TREF>, assigning appropriate class labels to a given set of instances <REF>Pantel and Ravichandran, 2004</REF>, and identifying relevant attributes for a given set of classes <REF>Pasca, 2007</REF>, our integrated method from Section 2 enables the simultaneous extraction of class instances, associated labels and attributes	1	Second, by exploiting the contents of query logs during the extraction of labeled classes of instances from Web documents, we acquire thousands 4,583, to be exact of open-domain classes covering a wide range of topics and domains	0	The accuracy reported in Section 32 exceeds 80 for both instance sets and class labels, although the extraction of classes requires a remarkably small amount of supervision, in the form of only a few commonly-used Is-A extraction patterns	0	3	2
P06-1038	P98-2127	2006	A first major algorithmic approach is to represent word contexts as vectors in some space and use similarity measures and automatic clustering in that space <REF>Curran and Moens, 2002</REF>	0	<REF>Pereira 1993</REF> and <TREF>Lin 1998</TREF> use syntactic features in the vector definition	1	<REF>Pantel and Lin, 2002</REF> improves on the latter by clustering by committee	0	<REF>Caraballo 1999</REF> uses conjunction and appositive annotations in the vector representation	0	6	1
D07-1034	P98-2127	2007	One is automatic thesaurus acquisition, that is, to identify synonyms or topically related words from corpora based on various measures of similarity eg <REF>Riloff and Shepherd, 1997</REF>; <REF>Thelen and Riloff, 2002</REF>	0	For instance, <TREF>Lin 1998</TREF> used dependency relation as word features to compute word similarities from large corpora, and compared the thesaurus created in such a way with WordNet and Roget classes	1	<REF>Caraballo 1999</REF> selected head nouns from conjunctions and appositives in noun phrases, and used the cosine similarity measure with a bottomup clustering technique to construct a noun hierarchy from text	0	<REF>Curran and Moens 2002</REF> explored a new similarity measure for automatic thesaurus extraction which better compromises with the speed/performance tradeoff	0	6	1
C04-1116	P98-2127	2004	There have been many approachs to automatic detection of similar words from text	0	Our method is similar to <REF>Hindle, 1990</REF>, <TREF>Lin, 1998</TREF>, and <REF>Gasperin, 2001</REF> in the use of dependency relationships as the word features	1	Another approach used the words distribution to cluster the words <REF>Pereira, 1993</REF>, and Inoue <REF>Inoue, 1991</REF> also used the word distributional information in the Japanese-English word pairs to resolve the polysemous word problem	0	Wu <REF>Wu, 2003</REF> shows one approach to collect synonymous collocation by using translation information	0	5	2
J06-3003	P98-2127	2006	The WMTS is well suited to LRA, because the WMTS scales well to large corpora one terabyte, in our case, it gives exact frequency counts unlike most Web search engines, it is designed for passage retrieval rather than document retrieval, and it has a powerful query syntax	0	53 Thesaurus As a source of synonyms, we use <TREF>Lins 1998a</TREF> automatically generated thesaurus	1	This thesaurus is available through an on-line interactive demonstration or it can be downloaded	0	5 We used the on-line demonstration, since the downloadable version seems to contain fewer words	0	3	2
J06-3003	P98-2127	2006	Analogy is a high degree of relational similarity	0	382 Turney Similarity of Semantic Relations 22 Measuring Attributional Similarity Algorithms for measuring attributional similarity can be lexicon-based <REF>Lesk 1986</REF>; <REF>Budanitsky and Hirst 2001</REF>; <REF>Banerjee and Pedersen 2003</REF>, corpus-based <REF>Lesk 1969</REF>; <REF>Landauer and Dumais 1997</REF>; <TREF>Lin 1998a</TREF>; <REF>Turney 2001</REF>, or a hybrid of the two <REF>Resnik 1995</REF>; <REF>Jiang and Conrath 1997</REF>; <REF>Turney et al 2003</REF>	1	Intuitively, we might expect that lexicon-based algorithms would be better at capturing synonymy than corpusbased algorithms, since lexicons, such as WordNet, explicitly provide synonymy information that is only implicit in a corpus	0	However, experiments do not support this intuition	0	6	1
J06-3003	P98-2127	2006	The LRA algorithm consists of the following 12 steps: 1	0	Find alternates: For each word pair A:B in the input set, look in <TREF>Lins 1998a</TREF> thesaurus for the top num sim words in the following experiments, num sim is 10 that are most similar to A For each A prime that is similar to A, make a new word pair A prime :B Likewise, look for the top num sim words that are most similar to B, and for each B prime , make a new word pair A:B prime  A:B is called the original pair and each A prime :B or A:B prime is an alternate pair	1	The intent is that alternates should have almost the same semantic relations as the original	0	For each input pair, there will now be 2  num sim alternate pairs	0	3	2
J06-3003	P98-2127	2006	For each input pair, there will now be 2  num sim alternate pairs	0	When looking for similar words in <TREF>Lins 1998a</TREF> thesaurus, avoid words that seem unusual eg, hyphenated words, words with three characters or less, words with non-alphabetical characters, multiword phrases, and capitalized words	1	The first column in Table 7 shows the alternate pairs that are generated for the original pair quart:volume	0	2	0	3	2
J06-3003	P98-2127	2006	If the number of hits for a query is x, then the corresponding element in the vector r is logx  1	0	Several authors report that the logarithmic transformation of frequencies improves cosine-based similarity measures <REF>Salton and Buckley 1988</REF>; <REF>Ruge 1992</REF>; <TREF>Lin 1998b</TREF>	1	<REF>Turney and Littman 2005</REF> evaluated the VSM approach by its performance on 374 SAT analogy questions, achieving a score of 47	0	Since there are five choices for each question, the expected score for random guessing is 20	0	6	1
J06-3003	P98-2127	2006	They are included for comparison	0	Algorithm Type Precision Recall F Hirst and St-<REF>Onge 1998</REF> Lexicon-based 349 321 334 <REF>Jiang and Conrath 1997</REF> Hybrid 298 273 285 <REF>Leacock and Chodorow 1998</REF> Lexicon-based 328 313 320 <TREF>Lin 1998b</TREF> Hybrid 312 273 291 <REF>Resnik 1995</REF> Hybrid 357 332 344 <REF>Turney 2001</REF> Corpus-based 350 350 350 <REF>Turney and Littman 2005</REF> Relational VSM 477 471 474 Random Random 200 200 200 385 Computational Linguistics Volume 32, Number 3 structured analogies	1	SME takes representations of a source domain and a target domain and produces an analogical mapping between the source and target	0	The domains are given structured propositional representations, using predicate logic	0	3	1
J06-3003	P98-2127	2006	As a courtesy to other users of Lins on-line system, we insert a 20-second delay between each two queries	1	Lins thesaurus was generated by parsing a corpus of about 5  10 7 English words, consisting of text from the Wall Street Journal, San Jose Mercury,andAP Newswire <TREF>Lin 1998a</TREF>	0	The parser was used to extract pairs of words and their grammatical relations	0	Words were then clustered into synonym sets, based on the similarity of their grammatical relations	0	3	2
J06-3003	P98-2127	2006	Street and riverbed are only moderately attributionally similar	0	Many algorithms have been proposed for measuring the attributional similarity between two words <REF>Lesk 1969</REF>; <REF>Resnik 1995</REF>; <REF>Landauer and Dumais 1997</REF>; <REF>Jiang and Conrath 1997</REF>; <TREF>Lin 1998b</TREF>; <REF>Turney 2001</REF>; <REF>Budanitsky and Hirst 2001</REF>; <REF>Banerjee and Pedersen 2003</REF>	1	Measures of attributional similarity have been studied extensively, due to their applications in problems such as recognizing synonyms <REF>Landauer and Dumais 1997</REF>, information retrieval <REF>Deerwester et al 1990</REF>, determining semantic orientation <REF>Turney 2002</REF>, grading student essays <REF>Rehder et al 1998</REF>, measuring textual cohesion <REF>Morris and Hirst 1991</REF>, and word sense disambiguation <REF>Lesk 1986</REF>	0	On the other hand, since measures of relational similarity are not as well developed as measures of attributional similarity, the potential applications of relational similarity are not as well known	0	6	1
W06-0504	P98-2127	2006	Although there is no univocally accepted definition for the OP task, a useful approximation has been suggested by <REF>Bontcheva and Cunningham, 2005</REF> as Ontology Driven Information Extraction with the goal of extracting and classifying instances of concepts and relations defined in a Ontology, in place of filling a template	0	A similar task has been approached in a variety of perspectives, including term clustering <TREF>Lin, 1998</TREF> and <REF>Almuhareb and Poesio, 2004</REF> and term categorization <REF>Avancini et al 2003</REF>	1	A rather different task is Ontology Learning, where new concepts and relations are supposed to be acquired, with the consequence of changing the definition of the Ontology itself <REF>Velardi et al 2005</REF>	0	However, since mentions have been introduced as an evolution of the traditional Named Entity Recognition task see <REF>Tanev and Magnini, 2006</REF>, they guarantee a reasonable level of difficulty, which makes OPTM challenging both for the Computational Linguistic side and the Knowledge Representation community	0	6	1
P06-1102	P98-2127	2006	All digits in both patterns and sentences are replaced with a common marker, such 810 that any two numerical values with the same number of digits will overlap during matching	0	Many methods have been proposed to compute distributional similarity between words, eg, <REF>Hindle, 1990</REF>, <REF>Pereira et al , 1993</REF>, <REF>Grefenstette, 1994</REF> and <TREF>Lin, 1998</TREF>	1	Almost all of the methods represent a word by a feature vector, where each feature corresponds to a type of context in which the word appeared	0	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed	0	6	1
P06-1102	P98-2127	2006	The first word class in the sequence, CL1, consists of words such as was, is, could, whereas the second class includes February, April, June, Aug , November and other similar words	0	The classes of words are computed on the fly over all sequences of terms in the extracted patterns, on top of a large set of pairwise similarities among words <TREF>Lin, 1998</TREF> extracted in advance from around 50 million news articles indexed by the Google search engine over three years	1	All digits in both patterns and sentences are replaced with a common marker, such 810 that any two numerical values with the same number of digits will overlap during matching	0	Many methods have been proposed to compute distributional similarity between words, eg, <REF>Hindle, 1990</REF>, <REF>Pereira et al , 1993</REF>, <REF>Grefenstette, 1994</REF> and <TREF>Lin, 1998</TREF>	0	3	2
P06-1057	P98-2127	2006	The most commonly used resource for lexical substitution is the manually constructed WordNet <REF>Fellbaum, 1998</REF>	0	Another option is to use statistical word similarities, such asin thedatabaseconstructed byDekang Lin<TREF>Lin, 1998</TREF>	1	We generically refer to such resources as substitution lexicons	0	When using a substitution lexicon it is assumed that there are some contexts in which the given synonymous words share the same meaning	0	6	1
P99-1067	P98-2127	1999	524 German test word Baby Brot Frau gelb Hiuschen Kind Kohl Krankheit Midchen Musik Ofen pfeifen Religion Schaf Soldat StraBe siiB Tabak weiB Whisky expected translation and rank baby 1 bread 1 woman 2 yellow 1 cottage 2 child 1 cabbage 17074 sickness 86 baby bread man yellow bungalow child Major disease top five translations as automatically generated child mother daughter father cheese meat food butter woman boy friend wife blue red pink green cottage house hut village daughter son father mother Kohl Thatcher Gorbachev Bush illness Aids patient doctor girl 1 girl music 1 music dance stove 3 heat oven stove house whistle 3 linesman referee whistle blow offside religion 1 sheep 1 soldier 1 street 2 boy man brother lady theatre musical song burn religion culture faith religious belief sheep cattle cow pig goat soldier army troop force civilian road street city town walk sweet smell delicious taste love sweet 1 tobacco 1 white 46 whiskey 11 tobacco cigarette consumption nicotine drink know say thought see think whisky beer Scotch bottle wine Table 1: Results for 20 of the 100 test words for full list see http://wwwfaskuni-mainzde/user/rappl 5 Discussion and Conclusion The method described can be seen as a simple case of the gradient descent method proposed by <REF>Rapp 1995</REF>, which does not need an initial lexicon but is computationally prohibitively expensive	0	It can also be considered as an extension from the monolingual to the bilingual case of the well-established methods for semantic or syntactic word clustering as proposed by <REF>Schtitze 1993</REF>, <REF>Grefenstette 1994</REF>, <REF>Ruge 1995</REF>, <REF>Rapp 1996</REF>, <TREF>Lin 1998</TREF>, and others	1	Some of these authors perform a shallow or full syntactical analysis before constructing the cooccurrence vectors	0	Others reduce the size of the co-occurrence matrices by performing a singular value decomposition	0	6	1
C02-1114	P98-2127	2002	Theaccuracyachievedinthisexperimentissometimesashighas78andisthereforecomparabletotheresultsreportedinthis paper	0	Anotherwaytoobtainword-sensesdirectly from corpora is to use clustering algorithms onfeature-vectorsLin,1998; Sch utze, 1998	1	Clusteringtechniquescanalsobeusedtodiscriminatebetweendi erentsensesofanambiguousword	0	Ageneralproblemforsuchclusteringtechniquesliesinthequestionofhowmany clustersoneshouldhave,ie howmanysenses areappropriateforaparticularwordinagiven domainManningandSch utze,1999,Ch14	0	6	1
C02-1114	P98-2127	2002	Ageneralproblemforsuchclusteringtechniquesliesinthequestionofhowmany clustersoneshouldhave,ie howmanysenses areappropriateforaparticularwordinagiven domainManningandSch utze,1999,Ch14	0	LinsapproachtothisproblemLin,1998is tobuildasimilaritytreeusingwhatisineffectahierarchicalclusteringmethodofwords relatedtoatargetwordinthiscasetheword dutyDi erentsensesofdutycanbediscerned asdi erentsub-treesofthissimilaritytreeWe presentanewmethodforword-sensediscriminationinSection6	1	3 Building a Graph from a PoS-tagged Corpus Inthissectionwedescribehowagrapha collection of nodesand links  was built to representtherelationshipsbetweennounsThe modelwasbuiltusingtheBritishNationalCorpuswhichisautomaticallytaggedforpartsof speech	0	Initially,grammaticalrelationsbetweenpairs ofwordswereextracted	0	5	2
W05-1516	P98-2127	2005	This is known as the Distributional Hypothesis in linguistics <REF>Harris, 1968</REF>	0	For example, the words test and exam are similar because both of them follow verbs such as administer, cancel, cheat on, conduct,  and both of them can be preceded by adjectives such as academic, comprehensive, diagnostic, difficult,  Many methods have been proposed to compute distributional similarity between words <REF>Hindle, 1990</REF>; <REF>Pereira et al , 1993</REF>; <REF>Grefenstette, 1994</REF>; <TREF>Lin, 1998</TREF>	1	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared	0	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed	0	6	1
P07-1068	P98-2127	2007	538 ture for NPi whose value is the most likely NE type	0	7 NEIGHBOR: Research in lexical semantics suggests that the SC of an NP can be inferred from its distributionally similar NPs see <TREF>Lin 1998a</TREF>	1	Motivated by this observation, we create for each of NPis ten most semantically similar NPs a NEIGHBOR feature whose value is the surface string of the NP	0	To determine the ten nearest neighbors, we use the semantic similarity values provided by Lins dependency-based thesaurus, which is constructed using a distributional approach combined with an information-theoretic de nition of similarity	0	4	2
P07-1068	P98-2127	2007	An example extraction would be <Eastern Airlines, the carrier>, where the rst entry is a proper noun labeled with either one of the seven MUC-style NE types4 or OTHERS5 and the second entry is a common noun	0	We then infer the SC of a common noun as follows: 1 we compute the probability that the common noun co-occurs with each of the eight NE types6 based on the extracted appositive relations, and 2 if the most likely NE type has a co-occurrence probability above a certain threshold we set it to 07, we create a INDUCED CLASS fea1This is motivated by <TREF>Lins 1998c</TREF> observation that a coreference resolver that employs only the rst WordNet sense performs slightly better than one that employs more than one sense	1	2The keywords are obtained via our experimentation with WordNet and the ACE SCs of the NPs in the ACE training data	0	3We used 1 the BLLIP corpus 30M words, which consists of WSJ articles from 1987 to 1989, and 2 the Reuters Corpus 37GB data, which has 806,791 Reuters articles	0	5	2
P07-1068	P98-2127	2007	2 SUBJ VERB: If NPi is involved in a subjectverb relation, we create a SUBJ VERB feature whose value is the verb participating in the relation	0	We use <TREF>Lins 1998b</TREF> MINIPAR dependency parser to extract grammatical relations	1	Our motivation here is to coarsely model subcategorization	0	3 VERB OBJ: A VERB OBJ feature is created in a similar fashion as SUBJ VERB if NPi participates in a verb-object relation	0	3	2
W06-2910	P98-2127	2006	1993 and Rooth et al	0	1999 referring to a direct object noun for describing verbs, or used any syntactic relationship detected by a chunker or a parser such as <TREF>Lin 1998</TREF> and McCarthy et al	1	2003	0	We used a statistical grammar Schulte im <REF>Walde, 2003</REF> to lter all verb-noun pairs where the nouns represent nominal heads in NPs or PPs in syntactic relation to the verb subject, object, adverbial function, etc, and to lter all verb-adverb pairs where the adverbs modify the verbs	0	6	1
W06-2910	P98-2127	2006	 6615 5779 913 172 3927 1551 Table 3: Coverage of verb association features by grammar/window resources	0	were considered as verb features, such as <TREF>Lin 1998</TREF> and McCarthy et al	1	2003	0	Of the adverb associations, we nd only a small proportion among the parsed adverbs	0	3	2
W06-2904	P98-2127	2006	This is known as the Distributional Hypothesis in linguistics <REF>Harris, 1968</REF>	0	For example, the words test and exam are similar because both of them can follow verbs such as administer, cancel, cheat on, conduct, etc Many methods have been proposed to compute distributional similarity between words, eg, <REF>Hindle, 1990</REF>; <REF>Pereira et al , 1993</REF>; <REF>Grefenstette, 1994</REF>; <TREF>Lin, 1998</TREF>	1	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared	0	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed	0	6	1
D07-1039	P98-2127	2007	pointwise mutual information <REF>Church and Hanks, 1990</REF>, 3	0	least mutual information difference with similar collocations, based on <REF>Lin, 1999</REF> and using Lins thesaurus <TREF>Lin, 1998</TREF> for obtaining the similar collocations	1	4	0	The distributed frequency of an object, which takes an average of the frequency of occurrence with an object over all verbs occurring with the object above a threshold	0	3	2
D07-1039	P98-2127	2007	Most previous work using distributional approaches to compositionality either contrasts distributional information of candidate phrases with constituent words <REF>Schone and Jurafsky, 2001</REF>; <REF>Bannard et al , 2003</REF>; <REF>Baldwin et al , 2003</REF>; <REF>McCarthy et al , 2003</REF> or uses distributionally similar words to detect nonproductive phrases <REF>Lin, 1999</REF>	0	<REF>Lin 1999</REF> used his method <TREF>Lin, 1998</TREF> for automatic thesaurus construction	1	He identi ed candidate phrases involving several open-class words output from his parser and ltered these by the loglikelihood statistic	0	Lin proposed that if there is a phrase obtained by substitution of either the head or modi er in the phrase with a nearest neighbour from the thesaurus then the mutual information of this and the original phrase must be signi cantly different for the original phrase to be considered noncompositional	0	6	1
D07-1039	P98-2127	2007	We used three different types of probabilistic models, which vary in the classes selected for representation over which the probability distribution of the argument heads 2 is estimated	0	Two use WordNet and the other uses the entries in a thesaurus of distributionally similar words acquired automatically following <TREF>Lin, 1998</TREF>	1	The rst method is due to <REF>Li and Abe 1998</REF>	0	The classes over which the probability distribution is calculated are selected according to the minimum description length principle MDL which uses the argument head tokens for nding the best classes for representation	0	3	2
D07-1039	P98-2127	2007	We cannot show the full WNPROTO due to lack of space, but we show some of the classes with higher probability which cover some typical nouns that occur as objects of park	0	373 Algorithm 1 WNPROTO algorithm C  classes in WNPROTO D   disambiguated ty  TY  fD  0 frequency of disambiguated items TY  argument head types nouns occurring as objects of verb, with associated frequencies C1  WordNet where ty  TY occurring in c  C1 > 1 for all ty  TY do nd c  classesty  C1 where c  argmaxc typeratioc if c  c / C then add c to C add ty  c to D Disambiguated ty with c end if end for for all c  C do if ty  c  D > 1 then fD  fD  frequencytysum frequencies of types under classes to be used in model else remove c from C classes with less than two disambiguated nouns are removed end if end for for all c  C do pc  frequency-of-all-tys-disambiguated-to-classc,DfD calculating class probabilities end for Algorithm 2 DSPROTO algorithm C  classes in DSPROTO D   disambiguated ty  TY  fD  0 frequency of disambiguated items TY  argument head types nouns occurring as objects of verb, with associated frequencies C1  cty  TY where num-types-in-thesauruscty,TY  > 1 order C1 by num-types-in-thesauruscty,TY  classes ordered by coverage of argument head types for all cty  ordered C1 do Dcty   disambiguated for this class for all ty  TY where in-thesaurus-entrycty,ty do if ty / D then add ty to Dcty types disambiguated to this class only if not disambiguated by a class used already end if end for if Dcty > 1 then add cty to C for all ty  Dcty do add ty  cty to D Disambiguated ty with cty fD  fD  frequencyty end for end if end for for all cty  C do pcty  frequency-of-all-tys-disambiguated-to-classcty,DfD calculating class probabilities end for 374 33 DSPROTOs We use a thesaurus acquired using the method proposed by <TREF>Lin 1998</TREF>	1	For input we used the grammatical relation data from automatic parses of the BNC	0	For each noun we considered the cooccurring verbs in the object and subject relation, the modifying nouns in noun-noun relations and the modifying adjectives in adjective-noun relations	0	3	2
P06-2095	P98-2127	2006	One way to generalise the query is by using similarity classes, ie groups of words with lexically similar behaviour	0	In his work on distributional similarity <TREF>Lin, 1998</TREF> designed a parser to identify grammatical relationships between words	1	However, broad-coverage parsers suitable for processing BNC-like corpora are not available for many languages	0	Another, resource-light approach treats the context as a bag of words BoW and detects the similarity of contexts on the basis of collocations in a window of a certain size, typically 3-4 words, eg	0	1	3
D07-1052	P98-2127	2007	Similarity and association measures can provide greater coverage for these near-synonym relations	0	The measures both of <TREF>Lin 1998</TREF> and of Pado and Lapata 2003, 2007 are distributional methods; for each word, they create a distribution of the contexts they occur in, and similarity between two words is calculated as the similarity of these distributions2 The difference in these two methods is the representation of the contexts	1	While Lin uses contexts that are expected to determine semantic preferences like being in the direct object position of one verb, Pado and Lapata only use the co-occuring words, weighted by syntax-based distance	0	For example, in 3 Peter subj likes dobj ice-cream	0	6	1
D07-1052	P98-2127	2007	Similarity and association measures can help for the cases of near-synonymy	0	However, while similarity measures such as WordNet distance or Lins similarity metric only detect cases of semantic similarity, association measures such as the ones used by Poesio et al , or by Garera and Yarowsky also find cases of associative bridg497 Lin98 RFF TheY TheY:G2 PL03 Land country/state/land Staat Staat Kemalismus Regierung Kontinent state state Kemalism government continent Stadt Stadt Bauernfamilie Prasident Region city city agricultural family president region Region Landesregierung Bankgesellschaft Dollar Stadt region country government banking corporation dollar city Bundesrepublik Bundesregierung Baht Albanien Staat federal republic federal government Baht Albania state Republik Gewerkschaft Gasag Hauptstadt Bundesland republic trade union a gas company capital state Medikament medical drug Arzneimittel Pille RU Patient Arzneimittel pharmaceutical pill a drug patient pharmaceutical Praparat Droge Abtreibungspille Arzt Lebensmittel preparation drug non-medical abortion pill doctor foodstuff Pille Praparat Viagra Pille Praparat pill preparation Viagra pill preparation Hormon Pestizid Pharmakonzern Behandlung Behandlung hormone pesticide pharmaceutical company treatment treatment Lebensmittel Lebensmittel Praparat Abtreibungspille Arznei foodstuff foodstuff preparation abortion pill drug highest ranked words, with very rare words removed : RU 486, an abortifacient drug Lin98: Lins distributional similarity measure <TREF>Lin, 1998</TREF> RFF: Geffet and Dagans Relative Feature Focus measure <REF>Geffet and Dagan, 2004</REF> TheY: association measure introduced by <REF>Garera and Yarowsky 2006</REF> TheY:G2: similar method using a log-likelihood-based statistic see <REF>Dunning 1993</REF> this statistic has a preference for higher-frequency terms PL03: semantic space association measure proposed by <REF>Pado and Lapata 2003</REF> Table 1: Similarity and association measures: most similar items ing like 1a,b; the result of this can be seen in table 2: while the similarity measures Lin98, RFF list substitutable terms which behave like synonyms in many contexts, the association measures Garera and Yarowskys TheY measure, Pado and Lapatas association measure also find non-compatible associations such as countrycapital or drugtreatment, which is why they are commonly called relationfree	1	For the purpose of coreference resolution, however we do not want to resolve the door to the antecedent the house as the two descriptions do not corefer, and it may be useful to filter out non-similar associations	0	12 Information Sources Different resources may be differently suited for the recognition of the various relations	0	3	2
D07-1052	P98-2127	2007	While none of the information sources can match the precision of the hypernymy information encoded in GermaNet, or that of using a combination of high-precision patterns with the World Wide Web as a very large corpus, it is possible to achieve a considerable improvement in terms of recall without sacrificing too much precision by combining these methods	0	Very interestingly, the distributional methods based on intra-sentence relations <TREF>Lin, 1998</TREF>; <REF>Pado and Lapata, 2003</REF> outperformed <REF>Garera and Yarowskys 2006</REF> association measure when used for ranking, which may due to sparse data problems or simply too much noise for the latter	1	For the association measures, the fact that they are relation-free also means that they can profit from added semantic filtering	0	The novel distance-bounded semantic similarity method where we use the most similar words in the previous discourse together with a semantic classbased filter and a distance limit comes near the precision of using surface patterns, and offers better accuracy than Gasperin and Vieiras method of using the globally most similar words	0	2	2
D07-1052	P98-2127	2007	Other approaches use large corpora to get an indication for bridging relations: Poesio et al	0	1998 use a general word association metric based on common terms occuring in a fixed-width window, <REF>Gasperin and Vieira 2004</REF> use syntactic contexts of words in a large corpus to induce a semantic similarity measure similar to the one introduced by <TREF>Lin, 1998</TREF>, and then use lists of the n nouns that are globally most similar to a given noun	1	<REF>Markert and Nissim 2005</REF> mine the World Wide Web for shallow patterns like China and other countries, indicating an is-a relationship	0	<REF>Finally, Garera and Yarowsky 2006</REF> propose an association-based approach using nouns that occur in a 2-sentence window before a definite description that has no same-head antecedent	0	6	1
E06-1050	P98-2127	2006	32 Contexts The context in which a word appears often imposesconstraintsonthesemantictypeoftheword	0	This basic idea has been exploited by many proposals for distributional similarity and clustering, eg, <REF>Church and Hanks, 1989</REF>; <TREF>Lin, 1998</TREF>; <REF>Pereira et al , 1993</REF>	1	Similar to <REF>Lin and Pantel 2001</REF>, we define the contexts of a word to be the undirected paths in dependency trees involving that word at either the beginning or the end	0	The following diagram shows an example dependency tree: Which city hosted the 1988 Winter Olympics	0	6	1
P06-1134	P98-2127	2006	Note, however, that <REF>McCarthy et al , 2004</REF> used the information about distributionally similar words to approximate corpus frequencies for word senses, whereas we target the estimation of a property of a given word sense the subjectivity	0	Starting with a given ambiguous word w, we first find the distributionally similar words using the method of <TREF>Lin, 1998</TREF> applied to the automatically parsed texts of the British National Corpus	1	Let DSW  dsw1, dsw2,  , dswn be the list of top-ranked distributionally similar words, sorted in decreasing order of their similarity	0	Next, for each sense wsi of the word w, we determine the similarity with each of the words in the list DSW, using a WordNet-based measure of semantic similarity wnss	0	3	2
C04-1115	P98-2127	2004	Still, despite a wide variety of feature weighting methods existing in machine learning, these methods are poorly explored in application to lexical acquisition	0	There have been a few studies eg , <TREF>Lin, 1998</TREF>; <REF>Ciaramita, 2002</REF>; <REF>Alfonseca and Manandhar, 2002</REF> where word representations are modified through this or that kind of feature weighting	0	But in these studies it is performed only as a standard pre-processing step on the analogy with similar tasks like text categorization, and the choice of a particular weighting procedure is seldom motivated	0	To our knowledge, there is no work yet on evaluation and comparison of different weighting methods for lexical acquisition	0	6	0
D08-1095	P98-2127	2008	41 Weight Tuning There are several motivations for learning the graph weights  in this domain	0	First, some dependency relations  foremost, subject and object  are in general more salient than others <TREF>Lin, 1998</TREF>; <REF>Pado and Lapata, 2007</REF>	1	In addition, dependency relations may have varying importance per different notions of word similarity eg, noun vs verb similarity <REF>Resnik and Diab, 2000</REF>	0	Weight tuning allows the adaption of edge weights to each task ie, distribution of queries	0	4	2
D08-1095	P98-2127	2008	The learning methods described in this paper can be readily applied to 911 other directed and labelled entity-relation graphs7 The graph representation described in this paper is perhaps most related to syntax-based vector space models, which derive a notion of semantic similarity from statistics associated with a parsed corpus <REF>Grefenstette, 1994</REF>; <TREF>Lin, 1998</TREF>; <REF>Pado and Lapata, 2007</REF>	0	In most cases, these models construct vectors to represent each word wi, where each element in the vector for wi corresponds to particular context c, and represents a count or an indication of whether wi occurred in context c A context can refer to simple co-occurrence with another word wj, to a particular syntactic relation to another word eg, a relation of direct object to wj, etc Given these word vectors, inter-word similarity is evaluated using some appropriate similarity measure for the vector space, such as cosine vector similarity, or Lins similarity <TREF>Lin, 1998</TREF>	1	Recently, Pado and Lapata <REF>Pado and Lapata, 2007</REF> have suggested an extended syntactic vector space model called dependency vectors, in which rather than simple counts, the components of a word vector of contexts consist of weighted scores, which combine both co-occurrence frequency and the importance of a context, based on properties of the connecting dependency paths	0	They considered two different weighting schemes: a length weighting scheme, assigning lower weight to longer connecting paths; and an obliqueness weighting hierarchy <REF>Keenan and Comrie, 1977</REF>, assigning higher weight to paths that include grammatically salient relations	0	3	2
D08-1095	P98-2127	2008	Instead, we include learning techniques to optimize the graphwalk based similarity measure	0	The learning methods described in this paper can be readily applied to 911 other directed and labelled entity-relation graphs7 The graph representation described in this paper is perhaps most related to syntax-based vector space models, which derive a notion of semantic similarity from statistics associated with a parsed corpus <REF>Grefenstette, 1994</REF>; <TREF>Lin, 1998</TREF>; <REF>Pado and Lapata, 2007</REF>	0	In most cases, these models construct vectors to represent each word wi, where each element in the vector for wi corresponds to particular context c, and represents a count or an indication of whether wi occurred in context c A context can refer to simple co-occurrence with another word wj, to a particular syntactic relation to another word eg, a relation of direct object to wj, etc Given these word vectors, inter-word similarity is evaluated using some appropriate similarity measure for the vector space, such as cosine vector similarity, or Lins similarity <TREF>Lin, 1998</TREF>	1	Recently, Pado and Lapata <REF>Pado and Lapata, 2007</REF> have suggested an extended syntactic vector space model called dependency vectors, in which rather than simple counts, the components of a word vector of contexts consist of weighted scores, which combine both co-occurrence frequency and the importance of a context, based on properties of the connecting dependency paths	0	3	2
N07-1065	P98-2127	2007	To further enhance the quality of co-occurrence data, we search on the specific phrase a16 is measured in in which a16 is one of the related concepts of a14  This allows for the simultaneous discovery of unknown units and the retrieval of their co-occurrence counts	0	Sentences in which the pattern occurs are parsed using Minipar <TREF>Lin, 1998b</TREF> so that we can obtain the word related to measured via the prepositional in relation	1	This allows us to handle sentential constructions that may intervene between measured and a meaningful unit	0	For each unit a17 that is related to measured via in, we increment the co-occurrence count a18a20a19a21a17a23a22a24a16a26a25, thereby collecting frequency counts for each a17 with a16  The patterns precision prevents incidental cooccurrence between a related concept and some unit that may occur simply because of the general topic of the document	0	3	2
N07-1065	P98-2127	2007	Thus, there is strong motivation to expand the list of units obtained from Google by automatically considering similar units	0	519 We gather similar units from an automaticallyconstructed thesaurus of distributionally similar words <TREF>Lin, 1998a</TREF>	1	The similar word expansion can add a term like gigs as a unit for size by virtue of its association with gigabytes, which is on the original list	0	Unit similarity can be thought of as a mapping a18 a1 a6 a4 a0 a8 in which a6 is a set of units and a0 a8 is sets of related units	0	3	2
A00-2011	P98-2127	2000	CLUSTER CLUSTERED SIMILAR WORDS OF DUTY WITH SIMILARITY SCORE responsibility 016, obligation 0109, task 0101, function 0098, role 0091, post 0087, position 0086, job 0084, chore 008, mission 008, assignment 0079, liability 0077  tariff0091, restriction 0089, tax 0086, regulation 0085, requirement 0081, procedure 0079, penalty 0079, quota 0074, rule 007, levy 0061  fee 0085, salary 0081, pay 0064, fine 0058 personnel 0073, staff0073 training 0072, work 0064, exercise 0061 privilege 0069, right 0057, license 0056 22	0	Corpus-based thesaurus Using the collocation database, Lin used an unsupervised method to construct a corpusbased thesaurus <TREF>Lin, 1998a</TREF> consisting of 11839 nouns, 3639 verbs and 5658 adjectives/adverbs	1	Given a word w, the thesaurus returns a clustered list of similar words of w along with their similarity to w For example, the clustered similar words of duty are shown in Table 1	0	23	0	3	2
A00-2011	P98-2127	2000	2	0	Resources The input to our algorithm includes a collocation database <TREF>Lin, 1998b</TREF> and a corpus-based thesaurus <TREF>Lin, 1998a</TREF>, which are both available on the Interne0	1	In addition, we require a bilingual thesaurus	0	Below, we briefly describe these resources	0	3	2
A00-2011	P98-2127	2000	78 Table 1	0	Clustered similar words of duty as given by <TREF>Lin, 1998a</TREF>	1	CLUSTER CLUSTERED SIMILAR WORDS OF DUTY WITH SIMILARITY SCORE responsibility 016, obligation 0109, task 0101, function 0098, role 0091, post 0087, position 0086, job 0084, chore 008, mission 008, assignment 0079, liability 0077  tariff0091, restriction 0089, tax 0086, regulation 0085, requirement 0081, procedure 0079, penalty 0079, quota 0074, rule 007, levy 0061  fee 0085, salary 0081, pay 0064, fine 0058 personnel 0073, staff0073 training 0072, work 0064, exercise 0061 privilege 0069, right 0057, license 0056 22	0	Corpus-based thesaurus Using the collocation database, Lin used an unsupervised method to construct a corpusbased thesaurus <TREF>Lin, 1998a</TREF> consisting of 11839 nouns, 3639 verbs and 5658 adjectives/adverbs	0	3	2
W06-1621	P98-2127	2006	It then assigns a score of 1 if the text contains a synonym, hyponym or derived form of the target word and a score of 0 otherwise	0	42 Similarity As a second measure we used the distributional similarity measure of <TREF>Lin, 1998</TREF>	1	For a text t and a word u we assign the max similarity score as follows: similarityt,u  maxvt simu,v 1 where simu,v is the similarity score for u and v4	0	43 Alignment model <REF>Glickman et al , 2006</REF> was among the top scoring systems on the RTE-1 challenge and supplies a probabilistically motivated lexical measure based on word co-occurrence statistics	0	3	2
W06-1621	P98-2127	2006	<REF>Bos and Markert, 2005</REF>; <REF>Corley and Mihalcea, 2005</REF>; Jijkoun and de <REF>Rijke, 2005</REF>; <REF>Glickman et al , 2006</REF> applied or utilized lexical based word overlap measures	0	Various word-to-word similarity measures where applied, including distributional similarity such as <TREF>Lin, 1998</TREF>, web-based co-occurrence statistics and WordNet based similarity measures such as <REF>Leacock et al , 1998</REF>	1	23 Paraphrase Acquisition A substantial body of work has been dedicated to learning patterns of semantic equivalency between different language expressions, typically considered as paraphrases	0	Recently, several works addressed the task of acquiring paraphrases semi- automatically from corpora	0	6	1
W06-1621	P98-2127	2006	Lexical similarity measures eg	0	<TREF>Lin, 1998</TREF> have also been suggested to measure semantic similarity	1	They are based on the distributional hypothesis, suggestingthatwordsthatoccurwithinsimilar contexts are semantically similar	0	22 Textual Entailment TheRecognisingTextualEntailmentRTE-1challenge <REF>Dagan et al , 2006</REF> is an attempt to promote anabstractgenerictaskthatcapturesmajorsemantic inference needs across applications	0	6	1
N06-3007	P98-2127	2006	We are going to extend the set of content bearing words and to include verbs	0	We will take advantage of the flexibility provided by our framework and use syntax based measure of similarity in the computation of the verb vectors, following <TREF>Lin, 1998</TREF>	1	Currently we are using string matching to compute the named entity based measure of similarity	0	We are planning to integrate more sophisticated techniques in our framework	0	5	2
P08-3001	P98-2127	2008	Distributional similarity represents the relatedness of two words by the commonality of contexts the words share, based on the distributional hypothesis <REF>Harris, 1985</REF>, which states that semantically similar words share similar contexts	0	A number of researches which utilized distributional similarity have been conducted, including <REF>Hindle, 1990</REF>; <TREF>Lin, 1998</TREF>; <REF>Geffet and Dagan, 2004</REF> and many others	1	Although they have been successful in acquiring related words, various parameters such as similarity measures and weighting are involved	0	As Weeds et al	0	6	1
P08-3001	P98-2127	2008	2 Distributional Features In this section, we firstly describe how we extract contexts from corpora and then how distributional features are constructed for word pairs	0	21 Context Extraction We adopted dependency structure as the context of words since it is the most widely used and wellperforming contextual information in the past studies <REF>Ruge, 1997</REF>; <TREF>Lin, 1998</TREF>	1	In this paper the sophisticated parser RASP Toolkit 2 <REF>Briscoe et al, 2006</REF> was utilized to extract this kind of word relations	0	We use the following example for illustration purposes: The library has a large collection of classic books by such authors as Herrick and Shakespeare	0	3	2
J05-1005	P98-2127	2005	Before explaining the following process Clustering 2, let us describe the measure used to calculate the similarity between syntactic positions	0	We use a particular weighted version of the <TREF>Lin 1998</TREF> coefficient	1	Our version, however, does not use pointwise mutual information to characterize the weight on position-word pairs	0	As Manning and Schu tze 1999 argued, this does not seem to be a good measure of the strength of association between a word and a local position	0	3	2
E06-1043	P98-2127	2006	Inspired by <REF>Lin1999</REF>, weexamine the strength of association between the verb and noun constituents of the target combination and its variants, as an indirect cue to their idiomaticity	0	We use the automatically-built thesaurus of <TREF>Lin 1998</TREF> to find similar words to the noun of the target expression, in order to automatically generate variants	1	Only the noun constituent is varied, since replacing the verb constituent of a VNIC with a semantically related verb is more likely to yield another VNIC, as in keep/lose ones cool <REF>Nunberg et al , 1994</REF>	0	Let a0a2a1a4a3a6a5a8a7a10a9a12a11a14a13a16a15a17a9a18a5a20a19a22a21a24a23a26a25a27a23a29a28a31a30 be the set of the a28 most similar nouns to the noun a9 of the target pair a32a34a33a36a35 a9a38a37	0	3	2
W07-1104	P98-2127	2007	The measurement is used to rank candidates relative to their compositionality	0	Building on <TREF>Lin 1998</TREF>, McCarthy et al	0	2003 measure the semantic similarity between expressions verb particles as a whole and their component words verb	1	They exploit contextual features and frequency information in order to assess meaning overlap	0	6	1
W07-1104	P98-2127	2007	<REF>Fazly and Stevenson 2006</REF> use lexical and syntactic fixedness as partial indicators of noncompositionality	0	Their method uses Lins 1998 automatically generated thesaurus to compute a metric of lexical fixedness	1	Lexical fixedness measures the deviation between the pointwise mutual information of a verb-object phrase and the average pointwise mutual information of the expressions resulting from substituting the noun by its synonyms in the original phrase	0	This measure is similar to Lins 1999 proposal for finding noncompositional phrases	0	6	1
E06-1003	P98-2127	2006	Comparative evaluation in <REF>Cimiano and Volker, 2005</REF> shows that syntactic features lead to better performance	0	Feature weights can be calculated either by Machine Learning algorithms <REF>Fleischman and Hovy, 2002</REF> or by statistical measures, like Point Wise Mutual Information or the Jaccard coefficient <TREF>Lin, 1998a</TREF>	1	A hybrid approach using both pattern-based, term structure, and contextual feature methods is presented in <REF>Cimiano et al , 2005</REF>	0	State-of-the-art approaches may be divided in two classes, according to different use of training data: Unsupervised approaches see <REF>Cimiano et al , 2005</REF> for details and supervised approaches which use manually tagged training data, eg	0	6	1
E06-1003	P98-2127	2006	4 Representing Syntactic Information Since both the Class-Word and the Class-Example methods work with syntactic features, the main source of information is a syntactically parsed corpus	0	We parsed about half a gigabyte of a news corpus with MiniPar <TREF>Lin, 1998b</TREF>	1	It is a statistically based dependency parser which is reported to reach 89 precision and 82 recall on press reportage texts	0	MiniPar generates syntactic dependency structures directed labeled graphs whose 20 g1 g2 SyntNetg1,g2 loves1 s d15d15 o d37d37d74d74d74 d74d74d74d74 d74d74d74d74 loves4 o d47d47 s d15d15 Jane6 loves1,4 1,24,5 d15d15 4,6 o d47d47 1,3 o d42d42d84d84d84d84d84d84d84d84d84 d84d84d84d84d84d84 d84d84 Jane6 John2 Mary3 John5 John2,5 Mary3 Figure 2: Two syntactic graphs and their Syntactic Network	0	3	2
E06-1003	P98-2127	2006	Moreover, we used virtually all the words connected syntactically to a term, not only the modifiers	0	A syntactic feature is a pair: word, syntactic relation <TREF>Lin, 1998a</TREF>	1	We use two feature types: First order features, which are directly connected to the training or test examples in the dependency parse trees of Corpus; second order features, which are connected to the training or test instances indirectly byskipping one wordthe verbin the dependency tree	0	As an example, lets consider two sentences: Edison invented the phonograph and Edison created the phonograph	0	3	2
E06-1003	P98-2127	2006	17 According with the demand for weakly supervised approaches to OP, we propose a method, called Class  Example, which learns a classification model from a set of classified terms, exploiting lexico-syntactic features	0	Unlike most of theapproacheswhichconsiderpairwisesimilarity between terms <REF>Cimiano and Volker, 2005</REF>; <TREF>Lin, 1998a</TREF>, the Class-Example method considers the similarity between a term ti and a set of training examples which represent a certain class	1	This results in a great number of class features and opens the possibility to exploit more statistical data, such asthefrequencyofappearance ofaclassfeature in different training terms	0	In order to show the effectiveness of the ClassExample approach, it has been compared against twodifferentapproaches: iaClass-Patternunsupervised approach, in the style of <REF>Hearst, 1998</REF>; ii an unsupervised approach that considers the word of the class as a pivot word for acquiring relevant contexts for the class we refer to this methodasClassWord	0	6	1
E06-1003	P98-2127	2006	Context feature approaches use a corpus to extract features from the context in which a semantic class tends to appear	0	Contextual features may be superficial <REF>Fleischman and Hovy, 2002</REF> or syntactic <TREF>Lin, 1998a</TREF>, <REF>Almuhareb and Poesio, 2004</REF>	1	Comparative evaluation in <REF>Cimiano and Volker, 2005</REF> shows that syntactic features lead to better performance	0	Feature weights can be calculated either by Machine Learning algorithms <REF>Fleischman and Hovy, 2002</REF> or by statistical measures, like Point Wise Mutual Information or the Jaccard coefficient <TREF>Lin, 1998a</TREF>	0	6	1
E06-1003	P98-2127	2006	The task has been approached in a variety of similar perspectives, including term clustering eg	0	<TREF>Lin, 1998a</TREF> and <REF>Almuhareb and Poesio, 2004</REF> and term categorization eg	1	<REF>Avancini et al , 2003</REF>	0	A rather different task is Ontology Learning OL, where new concepts and relations are supposed to be acquired, with the consequence of changing the definition of the Ontology itself see, for instance, <REF>Velardi et al , 2005</REF>	0	6	1
P06-2111	P98-2127	2006	However, this is not always the case	0	Several researchers <REF>Curran and Moens 2002</REF>, <TREF>Lin 1998</TREF>, van der <REF>Plas and Bouma 2005</REF> have used large monolingual corpora to extract distributionally similar words	1	They use grammatical relations1 to determine the context of a target word	0	We will refer to such systems as monolingual syntax-based systems	0	6	1
P06-2111	P98-2127	2006	In this paper we use both monolingual syntaxbased approaches and multilingual alignmentbased approaches and compare their performance when using the same similarity measures and evaluation set	0	Monolingual syntax-based distributional similarity is used in many proposals to nd semantically related words <REF>Curran and Moens 2002</REF>, <TREF>Lin 1998</TREF>, van der <REF>Plas and Bouma 2005</REF>	1	Several authors have used a monolingual parallel corpus to nd paraphrases Ibrahim et al	0	2003, <REF>Barzilay and McKeown 2001</REF>	0	6	1
P08-1002	P98-2127	2008	As a baseline, we implemented the non-referential it detector of <REF>Lappin and Leass 1994</REF>, labelled as LL in the results	0	This is a syntactic detector, a point missed by <REF>Evans 2001</REF> in his criticism: the patterns are robust to intervening words and modi ers eg  it was never thought by the committee that  provided the sentence is parsed correctly7 We automatically parse sentences with Minipar, a broad-coverage dependency parser <TREF>Lin, 1998b</TREF>	1	We also use a separate, extended version of the LL detector, implemented for large-scale nonreferential detection by <REF>Cherry and Bergsma 2005</REF>	0	This system, also for Minipar, additionally detects instances of it labelled with Minipars pleonastic category Subj	0	3	2
P08-1002	P98-2127	2008	Our approach avoids hand-crafting a set of spe11 ci c indicator features; we simply use the distribution of the pronouns context	0	Our method is thus related to previous work based on <REF>Harris 1985</REF>s distributional hypothesis2 It has been used to determine both word and syntactic path similarity <REF>Hindle, 1990</REF>; <TREF>Lin, 1998a</TREF>; <REF>Lin and Pantel, 2001</REF>	1	Our work is part of a trend of extracting other important information from statistical distributions	0	<REF>Dagan and Itai 1990</REF> use the distribution of a pronouns context to determine which candidate antecedents can  t the context	0	5	2
P01-1008	P98-2127	2001	These definitions are valid in the context of particular applications; however, in general, the correspondence between paraphrasing and types of lexical relations is not clear	0	The same question arises with automatically constructed thesauri <REF>Pereira et al , 1993</REF>; <TREF>Lin, 1998</TREF>	1	While the extracted pairs are indeed similar, they are not paraphrases	0	For example, while dog and cat are recognized as the most similar concepts by the method described in <TREF>Lin, 1998</TREF>, it is hard to imagine a context in which these words would be interchangeable	0	1	3
P01-1008	P98-2127	2001	While the extracted pairs are indeed similar, they are not paraphrases	0	For example, while dog and cat are recognized as the most similar concepts by the method described in <TREF>Lin, 1998</TREF>, it is hard to imagine a context in which these words would be interchangeable	0	The first attempt to derive paraphrasing rules from corpora was undertaken by <REF>Jacquemin et al , 1997</REF>, who investigated morphological and syntactic variants of technical terms	0	While these rules achieve high accuracy in identifying term paraphrases, the techniques used have not been extended to other types of paraphrasing yet	0	1	3
C02-1090	P98-2127	2002	For this reason, knowledge-poor approaches such as the distributional approach are particularly suited for this task	0	Its previous applications eg , <REF>Grefenstette 1993</REF>, <REF>Hearst and Schuetze 1993</REF>, <REF>Takunaga et al 1997</REF>, <TREF>Lin 1998</TREF>, <REF>Caraballo 1999</REF> demonstrated that cooccurrence statistics on a target word is often sufficient for its automatical classification into one of numerous classes such as synsets of WordNet	0	Distributional techniques, however, are poorly applicable to rare words, ie, those words for which a corpus does not contain enough cooccurrence data to judge about their meaning	1	Such words are the primary concern of many practical NLP applications: as a rule, they are semantically focused words and carry a lot of important information	0	1	3
D07-1086	P98-2127	2007	We also extensively investigated other corpusbased features, such as the number of times the phrase occurred hyphenated or capitalized, and the 4We exclude counts from the training, development, and testing queries discussed in Section 41	1	822 corpus-based distributional similarity <TREF>Lin, 1998</TREF> between a pair of tokens	0	These features are not available from search-engine statistics because search engines disregard punctuation and capitalization, and collecting page-count-based distributional similarity statistics is computationally infeasible	0	Unfortunately, none of the corpus-based features improved performance on the development set and are thus excluded from further consideration	0	3	2
P07-2011	P98-2127	2007	1 Thesaurus creation Over the last ten years, interest has been growing in distributional thesauruses hereafter simply thesauruses	0	Following initial work by <REF>Sparck Jones, 1964</REF> and <REF>Grefenstette, 1994</REF>, an early, online distributional thesaurus presented in <TREF>Lin, 1998</TREF> has been widely used and cited, and numerous authors since have explored thesaurus properties and parameters: see survey component of <REF>Weeds and Weir, 2005</REF>	1	A thesaurus is created by  taking a corpus  identifying contexts for each word  identifying which words share contexts	0	For each word, the words that share most contexts according to some statistic which also takes account of their frequency are its nearest neighbours	0	3	2
W04-1106	P98-2127	2004	22 Compound Similarity As a critical technique, word similarity is generally used in the example-based models of semantic classification	0	The measure of word similarity can be divided into two major approaches: taxonomy-based lexical approach <REF>Resnik 1995</REF>, <TREF>Lin 1998a</TREF>, <REF>Chen and Chen 1998</REF> and context-based syntactic approach <TREF>Lin 1998b</TREF>,<REF>Chen and You 2002</REF>, which is not the concern in this context-free model	1	However, two problems arise here for the taxonomy-based lexical approach	0	First, such similarity measures risk the failure to capture the similarity among some semantically highly related words, if they happen to be put under classes distant from each other according to a specific ontology4	0	1	3
W06-1603	P98-2127	2006	We then calculate normalized tuple similarity scores over the tuple pairs using a metric that accounts for similarities in both syntactic structure and content of each tuple	0	A thesaurus constructed from corpus statistics <TREF>Lin, 1998</TREF> is utilized for the content similarity	1	We utilize this metric to greedily pair together the most similar predicate argument tuples across Figure 2: System architecture sentences	0	Any remaining unpaired tuples represent extra information and are passed to a dissimilarity classi er to decide whether such information is signi cant	0	3	2
W06-1603	P98-2127	2006	Although the 24 MSR corpus used strict means of resolving interrater disagreements during its construction, the annotators agreed with the MSR corpus labels only 935 187/200 of the time	0	One weakness of our system is that we rely on a thesaurus <TREF>Lin, 1998</TREF> for word similarity information for predicate argument tuple pairing	1	However, it is designed to provide similarity scores between pairs of individual words rather than phrases	0	If a predicate argument tuples target or one argument is realized as a phrase borrow  check out, for instance, the thesaurus is unable to provide an accurate similarity score	0	1	3
P05-1016	P98-2127	2005	We collected the statistics on the grammatical relations contexts output by Minipar and used these as the feature vectors	0	<REF>Following Lin 1998</REF>, we measure each feature f for a word e not by its frequency but by its pointwise mutual information, mi ef : 126    fPeP feP mi ef  , log 4 Inducing ontological features The resource described in the previous section yields lexical feature vectors for each word in a corpus	1	We term these vectors lexical because they are collected by looking only at the lexicals in the text ie no sense information is used	0	We use the term ontological feature vector to refer to a feature vector whose features are for a particular sense of the word	0	3	2
P05-1016	P98-2127	2005	We believe that this framework will be useful for a variety of applications, including adding additional semantic information to existing semantic term banks by disambiguating lexical-semantic resources	0	Ontologizing semantic resources Recently, researchers have applied textand web-mining algorithms for automatically creating lexical semantic resources like similarity lists <TREF>Lin 1998</TREF>, semantic lexicons <REF>Riloff and Shepherd 1997</REF>, hyponymy lists <REF>Shinzato and Torisawa 2004</REF>; <REF>Pantel and Ravichandran 2004</REF>, partwhole lists <REF>Girgu et al 2003</REF>, and verb relation graphs <REF>Chklovski and Pantel 2004</REF>	1	However, none of these resources have been directly linked into an ontological framework	0	For example, in VERBOCEAN <REF>Chklovski and Pantel 2004</REF>, we find the verb relation to surpass is-stronger-than to hit, but it is not specified that it is the achieving sense of hit where this relation applies	0	6	1
P05-1016	P98-2127	2005	The hypothesis states that words that occur in the same contexts tend to have similar meaning	0	Researchers have mostly looked at representing words by their surrounding words <REF>Lund and Burgess 1996</REF> and by their syntactical contexts <REF>Hindle 1990</REF>; <TREF>Lin 1998</TREF>	0	However, these representations do not distinguish between the different senses of words	1	Our framework utilizes these principles and representations to induce disambiguated feature vectors	0	1	3
W07-1422	P98-2127	2007	ii Sentence splitting, using mxterminator <REF>Reynar and Ratnaparkhi, 1997</REF>	0	iii Dependency parsing, using Minipar <TREF>Lin, 1998b</TREF>	1	The proof search is implemented as a depth-first search, with maximal depth ie proof length of 4	0	If the text contains more than one sentence, the prover aims to prove h from each of the parsed sentences, and entailment is determined based on the minimal cost	0	3	2
W07-1422	P98-2127	2007	summationtext lh Scorel OpenClassWordsh 2 2We set the threshold to 001 3The active verbal form with direct modifiers where Scorel is 1 if it appears in p, or if it is a derivation of a word in p according to WordNet	0	Otherwise, Scorel is the maximal Lin dependency-basedsimilarityscorebetweenlandthe lemmas of p <TREF>Lin, 1998a</TREF> synonyms and hypernyms/hyponyms are handled by the lexical rules	1	7 System Implementation Deriving the initial propositions t and h from the input text fragments consists of the following steps: i Anaphora resolution, using the MARS system <REF>Mitkov et al , 2002</REF>	0	Each anaphor was replaced by its antecedent	0	3	2
W07-1422	P98-2127	2007	Figure 1: Application of inference rules	0	POS and relation labels are based on Minipar <TREF>Lin, 1998b</TREF> If a complete proof is found h was generated, the prover concludes that entailment holds	1	Otherwise, entailment is determined by comparing the minimal cost found during the proof search to some threshold 	0	3 Proof System Like logic-based systems, our proof system consists of propositions t, h, and intermediate premises, and inference entailment rules, which derive new propositions from previously established ones	0	3	2
P07-1025	P98-2127	2007	As a striking example, the 14 most syntactically similar verbs to believe in order are think, guess, hope, feel, wonder, theorize, fear, reckon, contend, suppose, understand, know, doubt, and suggest  all mental action verbs	0	This observation further supports the distributional hypothesis of word similarity and corresponding technologies for identifying synonyms by similarity of lexical-syntactic context <TREF>Lin, 1998</TREF>	1	Verb pairs instances Cosine bind 83 bound 95 0950 plunge 94 tumble 87 0888 dive 36 plunge 94 0867 dive 36 tumble 87 0866 jump 79 tumble 87 0865 fall 84 fell 102 0859 intersperse 99 perch 81 0859 assail 100 chide 98 0859 dip 81 fell 102 0858 buffet 72 embroil 100 0856 embroil 100 lock 73 0856 embroil 100 superimpose 100 0856 fell 102 jump 79 0855 fell 102 tumble 87 0855 embroil 100 whipsaw 63 0850 pluck 100 whisk 99 0849 acquit 100 hospitalize 99 0849 disincline 70 obligate 94 0848 jump 79 plunge 94 0848 dive 36 jump 79 0847 assail 100 lambaste 100 0847 festoon 98 strew 100 0846 mar 78 whipsaw 63 0846 pluck 100 whipsaw 63 0846 ensconce 101 whipsaw 63 0845 Table 2	0	Top 25 most syntactically similar pairs of the 3257 verbs in PropBank	0	3	2
P07-1025	P98-2127	2007	Our approach is strictly empirical; the similarity of verbs is determined by examining the syntactic contexts in which they appear in a large text corpus	0	Our approach is analogous to previous work in extracting collocations from large text corpora using syntactic information <TREF>Lin, 1998</TREF>	1	In our work, we utilized the GigaWord corpus of English newswire text Linguistic <REF>Data Consortium, 2003</REF>, consisting of nearly 12 gigabytes of textual data	0	To prepare this corpus for analysis, we extracted the body text from each of the 41 million entries in the corpus and applied a maximum-entropy algorithm to identify sentence boundaries <REF>Reynar and Ratnaparkhi, 1997</REF>	0	5	2
W06-2503	P98-2127	2006	There have been several attempts to group WordNet senses using various different types of information sources	0	This paper describes work to automatically relate WordNet word senses using automatically acquired thesauruses <TREF>Lin, 1998</TREF> and WordNet similarity measures <REF>Patwardhan and Pedersen, 2003</REF>	1	This work proposes using graded word sense relationships rather than fixed groupings clusters	0	Previous research has focused on clustering WordNet senses into groups	0	3	2
W06-2503	P98-2127	2006	This is transformed from a distance measure in the WN-Similarity package by taking the reciprocal: jcns1,s2  1/Djcns1,s2 We use raw BNC data for calculating IC values	0	DIST We use a distributional similarity measure <TREF>Lin, 1998</TREF> to obtain a fixed number 50 of the top ranked nearest neighbours for the target nouns	1	For input we used grammatical relation data extracted using an automatic parser <REF>Briscoe and Carroll, 2002</REF>	0	We used the 90 million words of written English from the British National Corpus BNC <REF>Leech, 1992</REF>	0	3	2
W04-2103	P98-2127	2004	To do this, many approaches to lexical acquisition employ the distributional model of word meaning induced from the distribution of the word across various lexical contexts of its occurrence found in the corpus	0	The approach is now being actively explored for a wide range of semantics-related tasks including automatic construction of thesauri <TREF>Lin, 1998</TREF>; <REF>Caraballo, 1999</REF>, their enrichment <REF>Alfonseca and Manandhar, 2002</REF>; <REF>Pekar and Staab, 2002</REF>, acquisition of bilingual lexica from nonaligned <REF>Kay and Rscheisen, 1993</REF> and nonparallel corpora <REF>Fung and Yee, 1998</REF>, learning of information extraction patterns from un-annotated text <REF>Riloff and Schmelzenbach, 1998</REF>	1	However, because of irregularities in corpus data, corpus statistics cannot guarantee optimal performance, notably for rare lexical items	0	In order to improve robustness, recent research has attempted a variety of ways to incorporate external knowledge into the distributional model	0	1	3
C04-1111	P98-2127	2004	Also, the patterns are learned with the specific goal of scaling to the terascale see Table 2	0	22 Co-occurrence-based approaches The second class of algorithms uses cooccurrence statistics <REF>Hindle 1990</REF>, <TREF>Lin 1998</TREF>	1	These systems mostly employ clustering algorithms to group words according to their meanings in text	0	Assuming the distributional hypothesis <REF>Harris 1985</REF>, words that occur in similar grammatical contexts are similar in meaning	0	6	1
W03-0418	P98-2127	2003	Other researchers have also clustered words to create semantic lexicons	0	<TREF>Lin 1998</TREF> created a thesaurus using syntactic relationships with other words	1	Rooth et al	0	1999 used clustering to create clusters similar to Levin verb classes <REF>Levin, 1993</REF>	0	6	1
P99-1041	P98-2127	1999	The number of unique collocations in the resulting database 2 is about 11 million	0	Using the similarity measure proposed in <TREF>Lin, 1998</TREF>, we constructed a corpus-based thesaurus 3 consisting of 11839 nouns, 3639 verbs and 5658 adjective/adverbs which occurred in the corpus at least 100 times	1	3 Mutual Information of a Collocation We define the probability space to consist of all possible collocation triples	0	We use LH R M L to denote the 1 available at http://wwwcsumanitobaca/-lindek/miniparhtm/ 2available at http://wwwcsumanitobca/-lindek/nlldemohtm/ 3available at http://wwwcsumanitobaca/-lindek/nlldemohtm/ 317 frequency count of all the collocations that match the pattern H R M, where H and M are either words or the wild card  and R is either a dependency type or the wild card	0	3	2
P99-1041	P98-2127	1999	Mutual information has often been used to separate systematic associations from accidental ones	0	It was also used to compute the distributional similarity between words CHin dle, 1990; <TREF>Lin, 1998</TREF>	1	A method to determine the compositionality of verb-object pairs is proposed in <REF>Tapanainen et al , 1998</REF>	0	The basic idea in there is that if an object appears only with one verb of few verbs in a large corpus we expect that it has an idiomatic nature <REF>Tapanainen et al , 1998</REF>, p1290	0	6	1
P99-1041	P98-2127	1999	We briefly describe the process of obtaining this input	0	More details about the construction of the collocation database and the thesaurus can be found in <TREF>Lin, 1998</TREF>	1	We parsed a 125-million word newspaper corpus with Minipar, 1 a descendent of Principar <REF>Lin, 1993</REF>; <REF>Lin, 1994</REF>, and extracted dependency relationships from the parsed corpus	0	A dependency relationship is a triple: head type modifier, where head and modifier are words in the input sentence and type is the type of the dependency relation	0	3	2
P99-1041	P98-2127	1999	One possibility is to compare the automatically identified relationships with relationships listed in a manually compiled dictionary	0	For example, <TREF>Lin, 1998</TREF> compared automatically created thesaurus with the WordNet <REF>Miller et al , 1990</REF> and Rogets Thesaurus	1	However, since the lexicon used in our parser is based on the WordNet, the phrasal words in WordNet are treated as a single word	0	For example, take advantage of is treated as a transitive verb by the parser	0	6	1
P06-1045	P98-2127	2006	From this tree structure, the similarity is obtained: simhill,coast  2355  06	0	4 The similarity between word w with senses w1,,wn and word v with senses v1,,vm is defined as the maximum similarity between all the pairs of word senses: simw,v  maxi,j simwi,vj, 5 whose idea came from Lins method <TREF>Lin, 1998</TREF>	1	42 Discrimination Rate The following two sections describe two evaluation measures based on the reference similarity	0	The first one is discrimination rate DR	0	5	2
P06-1045	P98-2127	2006	For example, <REF>Hindle 1990</REF> used cooccurrences between verbs and their subjects and objects, and proposed a similarity metric based on mutual information, but no exploration concerning the effectiveness of other kinds of word relationship is provided, although it is extendable to any kinds of contextual information	0	<TREF>Lin 1998</TREF> also proposed an information theorybased similarity metric, using a broad-coverage parser and extracting wider range of grammatical relationship including modifications, but he didnt further investigate what kind of relationships actually had important contributions to acquisition, either	1	The selection of useful contextual information is considered to have a critical impact on the performance of synonym acquisition	0	This is an independent problem from the choice of language model or acquisition method, and should therefore be examined by itself	0	6	1
P06-1045	P98-2127	2006	Among many kinds of lexical relations, synonyms are especially useful ones, having broad range of applications such as query expansion technique in information retrieval and automatic thesaurus construction	0	Various methods <REF>Hindle, 1990</REF>; <TREF>Lin, 1998</TREF>; <REF>Hagiwara et al , 2005</REF> have been proposed for synonym acquisition	1	Most of the acquisition methods are based on distributional hypothesis <REF>Harris, 1985</REF>, which states that semantically similar words share similar contexts, and it has been experimentally shown considerably plausible	0	However, whereas many methods which adopt the hypothesis are based on contextual clues concerning words, and there has been much consideration on the language models such as Latent Semantic Indexing <REF>Deerwester et al , 1990</REF> and Probabilistic LSI <REF>Hofmann, 1999</REF> and synonym acquisition method, almost no attention has been paid to what kind of categories of contextual information, or their combinations, are useful for word featuring in terms of synonym acquisition	0	6	1
W04-0837	P98-2127	2004	The method is described in <REF>McCarthy et al , 2004</REF>, which we summarise here	0	We acquire thesauruses for nouns, verbs, adjectives and adverbs based on the method proposed by <TREF>Lin 1998</TREF> using grammatical relations output from the RASP parser <REF>Briscoe and Carroll, 2002</REF>	1	The grammatical contexts used are listed in table 3, but there is scope for extending or restricting the contexts for a given PoS	0	We use the thesauruses for ranking the senses of the target words	0	3	2
H05-1113	P98-2127	2005	To measure the compositionality, semantically similar words are more suitable than synomys	0	Hence, we choose to use Lins thesaurus <TREF>Lin, 1998</TREF> instead of Wordnet <REF>Miller et al , 1990</REF>	1	902 614 Distributed Frequency of Object a0  The distributed frequency of object is based on the idea that if an object appears only with one verb or few verbs in a large corpus, the collocation is expected to have idiomatic nature <REF>Tapanainen et al , 1998</REF>	0	For example, sure in make sure occurs with very few verbs	0	3	2
H05-1113	P98-2127	2005	The higher the value of a38, the more is the likelihood of the collocation to be a MWE	0	2obtained from Lins <TREF>Lin, 1998</TREF> automatically generated thesaurus http://wwwcsualbertaca/a66 lindek/downloadshtm	1	We obtained the best results section 8 when we substituted top-5 similar words for both the verb and the object	0	To measure the compositionality, semantically similar words are more suitable than synomys	0	3	2
W06-2907	P98-2127	2006	As a representative of this approach we use Lins dependency-baseddistributionalsimilaritydatabase	1	Lins database was created using the particular distributionalsimilaritymeasurein<TREF>Lin, 1998</TREF>, applied to a large corpus of news data 64 million words 4	0	Two words obtain a high similarity score if they occur often in the same contexts, as captured by syntactic dependency relations	0	For example, two verbs willbeconsideredsimilariftheyhavelargecommon sets of modifying subjects, objects, adverbs etc Distributional similarity does not capture directly meaning equivalence and entailment but rather a looser notion of meaning similarity <REF>Geffet and Dagan, 2005</REF>	0	3	2
W06-2907	P98-2127	2006	The setting allowed us to analyze different types of state of the art models and their behavior with respect to characteristic sub-cases of the problem	0	The major conclusion that seems to arise from our experiments is the effectiveness of combining a knowledge based thesaurus such as WordNet with distributional statistical information such as <TREF>Lin, 1998</TREF>, overcoming the known deficiencies of each method alone	1	Furthermore, modeling the a priori substitution likelihood captures the majority of cases in the evaluated setting, mostly because WordNet provides a rather noisy set of substitution candidates	0	On the other hand, successfully incorporating local and global contextual information, as similar to WSD methods, remains a challenging task for future research	0	3	2
D07-1060	P98-2127	2007	Gurevych 10 JSD and ASD calculate the difference in distributions of words that co-occur with the targets	0	Lin dist distributional measure and Lin GN GermaNet measure follow from <TREF>Lins 1998b</TREF> information-theoretic definition of similarity	1	11 Information content measures rely on finding the lowest common subsumer lcs of the target synsets in a hypernym hierarchy and using corpus counts to determine how specific or general this concept is In general, the more specific the lcs is and the smaller the difference of its specificity with that of the target concepts, the closer the target concepts are	0	12 As GermaNet does not have glosses for synsets, <REF>Gurevych 2005</REF> proposed a way of creating a bag-of-words-type pseudogloss for a synset by including the words in the synset and in synsets close to it in the network	0	6	1
D07-1060	P98-2127	2007	They used these DPCs to implement an unsupervised nave Bayes word sense classifier that placed first among all unsupervised systems taking part in the Multilingual Chinese English Lexical Sample Task task 5 of SemEval07 <REF>Jin et al , 2007</REF>	0	4 Evaluation We evaluated the newly proposed cross-lingual distributional measures of concept-distance on the tasks of 1 measuring semantic distance between German words and ranking German word pairs according to semantic distance, and 2 solving German Word Power questions from Readers DigestInorder to compare results with state-of-the-art monolingual approaches we conducted experiments using Ger575 Cross-lingual Distributional Measures Monolingual GermaNet Measures Information Contentbased Lesk-like -skew divergence <REF>Lee, 2001</REF> ASD <REF>Jiang and Conrath 1997</REF> JC hypernym pseudo-gloss HPG cosine <REF>Schutze and Pedersen, 1997</REF> Cos <TREF>Lin 1998b</TREF> Lin GN  radial pseudo-gloss RPG Jensen-Shannon divergence JSD <REF>Resnik 1995</REF> Res Lins measure 1998a Lin dist  Table 1: Distance measures used in our experiments	1	Dataset Year Language  pairs PoS Scores  subjects Correlation Gur65 2005 German 65 N discrete 0,1,2,3,4 24 810 Gur350 2006 German 350 N, V, A discrete 0,1,2,3,4 8 690 Table 2: Comparison of datasets used for evaluating semantic distance in German	0	maNet measures as well	0	3	1
P08-1037	P98-2127	2008	The method we use to predict the rst sense is that of McCarthy et al	0	2004, which was obtained using a thesaurus automatically created from the British National Corpus BNC applying the method of <TREF>Lin 1998</TREF>, coupled with WordNetbased similarity measures	1	This method is fully unsupervised and completely unreliant on any annotations from our dataset	0	In the case of SFs, we perform full synset WSD based on one of the above options, and then map the prediction onto the corresponding unique SF	0	3	2
C02-1161	P98-2127	2002	2 Related Research The vocabulary mis-match between user queries and indexed documents is often addressed through query expansion	0	Two common techniques for query expansion are blind relevance feedback <REF>Buckley et al , 1995</REF>; <REF>Mitra et al , 1998</REF> and word sense disambiguation WSD <REF>Mihalcea and Moldovan, 1999</REF>; <REF>Lytinen et al , 2000</REF>; <REF>Schutze and Pedersen, 1995</REF>; <TREF>Lin, 1998</TREF>	1	Blind relevance feedback consists of retrieving a small number of documents using a query given by a user, and then constructing an expanded query that includes content words that appear frequently in these documents	0	This expanded query is used to retrieve a new set of documents	0	6	1
C02-1161	P98-2127	2002	<REF>Mihalcea and Moldovan 1999</REF> and Lytinen et al	0	2000 used a machine readable thesaurus, specifically WordNet <REF>Miller et al , 1990</REF>, to obtain the sense of a word, while <REF>Schutze and Pedersen 1995</REF> and <TREF>Lin 1998</TREF> used automatically constructed thesauri	1	The improvements in retrieval performance reported in <REF>Mitra et al , 1998</REF> are comparable to those reported here note that these researchers consider precision, while we consider recall	0	The results obtained by <REF>Schutze and Pedersen 1995</REF> and by Lytinen et al	0	6	1
P04-1036	P98-2127	2004	A noun, a4, is thus described by a set of co-occurrence triples a94 a4a7a14 a55 a14a32a95a97a96 and associated frequencies, where a55 is a grammatical relation and a95 is a possible cooccurrence with a4 in that relation	0	For every pair of nouns, where each noun had a total frequency in the triple data of 10 or more, we computed their distributional similarity using the measure given by <TREF>Lin 1998</TREF>	1	If a98a56a30a31a4 a33 is the set of co-occurrence types a30 a55 a14a16a95 a33 such that a99a100a30a42a4a43a14 a55 a14a32a95 a33 is positive then the similarity between two nouns, a4 and a10, can be computed as: a26a41a28a15a28a27a30a42a4a43a14a16a10 a33 a8 a75 a83a102a101a42a103a50 a85 a70a11a104 a83a102a6a13a85a106a105 a104 a83 a67 a85 a30a78a99a100a30a31a4a7a14 a55 a14a16a95 a33a41a107 a99a108a30a31a10a109a14 a55 a14a16a95 a33a86a33 a75 a83a102a101a42a103a50 a85 a70a11a104 a83a102a6a13a85 a99a108a30a31a4a7a14 a55 a14a32a95 a33a45a107 a75 a83a84a101a42a103a50 a85 a70a11a104 a83 a67 a85 a99a108a30a31a10a109a14 a55 a14a16a95 a33 where: a99a108a30a31a4a7a14 a55 a14a32a95 a33 a8a111a110a21a112a114a113 a54 a30a31a95a73a115a116a4a118a117 a55 a33 a54 a30a42a95a73a115 a55 a33 A thesaurus entry of size a3 for a target noun a4 is then defined as the a3 most similar nouns to a4  22 The WordNet Similarity Package We use the WordNet Similarity Package 005 and WordNet version 16	0	2 The WordNet Similarity package supports a range of WordNet similarity scores	0	3	2
P04-1036	P98-2127	2004	We describe some related work in section 6 and conclude in section 7	0	In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of <TREF>Lin 1998</TREF>	1	This provides the a3 nearest neighbours to each target word, along with the distributional similarity score between the target word and its neighbour	0	We then use the WordNet similarity package <REF>Patwardhan and Pedersen, 2003</REF> to give us a semantic similarity measure hereafter referred to as the WordNet similarity measure to weight the contribution that each neighbour makes to the various senses of the target word	0	3	2
P04-1036	P98-2127	2004	Let a28a15a34a20a10a18a28a20a34a15a28a25a30a31a4 a33 be the set of senses of a4  For each sense of a4 a4a35a28a37a36a39a38a40a28a20a34a15a10a13a28a15a34a20a28a27a30a31a4 a33  we obtain a ranking score by summing over the a26a41a28a15a28a27a30a42a4a43a14a16a10a45a44 a33 of each neighbour a10a46a44a47a38a48a5 a6  multiplied by a weight	0	This weight is the WordNet similarity score a4a49a10a13a28a15a28  between the target sense a4a35a28a37a36  and the sense of a10a45a44 a10a13a28a37a50a51a38a52a28a15a34a15a10a13a28a20a34a15a28a27a30a42a10a45a44 a33  that maximises this score, divided by the sum of all such WordNet similarity scores for a28a20a34a15a10a13a28a15a34a20a28a27a30a31a4 a33 and a10a46a44  Thus we rank each sense a4a49a28 a36 a38a53a28a15a34a20a10a18a28a20a34a15a28a25a30a31a4 a33 using: a54a56a55 a34a15a57a41a58a41a59a60a34a15a10a13a61a37a34a63a62a64a61a37a65 a55 a34a27a30a31a4a35a28a37a36 a33 a8 a66 a67a69a68a32a70a27a71a73a72 a26a29a28a20a28a27a30a31a4a7a14a32a10 a44 a33a15a74 a4a49a10a13a28a20a28a27a30a31a4a35a28a37a36a42a14a32a10a46a44 a33 a75 a6a18a76a78a77a80a79 a70 a76a82a81 a67 a76a78a81a82a76a42a83a84a6a18a85 a4a35a10a13a28a15a28a25a30a31a4a49a28 a36 a79 a14a16a10a45a44 a33 1 where: a4a49a10a13a28a20a28a27a30a31a4a35a28a37a36a86a14a16a10a45a44 a33 a8 a87a89a88a20a90 a67 a76a92a91 a70 a76a78a81 a67 a76a78a81a82a76a93a83 a67a69a68 a85 a30a42a4a49a10a13a28a15a28a25a30a31a4a35a28a37a36a42a14a32a10a13a28a37a50 a33a86a33 21 Acquiring the Automatic Thesaurus The thesaurus was acquired using the method described by <TREF>Lin 1998</TREF>	1	For input we used grammatical relation data extracted using an automatic parser <REF>Briscoe and Carroll, 2002</REF>	0	For the experiments in sections 3 and 4 we used the 90 million words of written English from the BNC	0	3	2
P06-1099	P98-2127	2006	In this paper, we will discuss data which reveals that purely statistics-based measures exhibit virtually no difference compared with frequency of occurrence counts, while linguistically more informed measures do reveal such a marked difference  for the problem of term and collocation mining at least	0	Although there has been a fair amount of work employing linguistically sophisticated analysis of candidate items eg , on CE by <TREF>Lin 1998</TREF> and <REF>Lin 1999</REF> as well as on ATR by <REF>Daille 1996</REF>, <REF>Jacquemin 1999</REF>, and <REF>Jacquemin 2001</REF>, these approaches are limited by the difficulty to port grammatical specifications to other domains in the case of ATR or by the error-proneness of full general-language parsers in the case of CE	0	Therefore, most recent approaches in both areas have backed off to more shallow linguistic filtering techniques, such as POS tagging and phrase chunking eg , Frantzi et al	0	2000, <REF>Krenn and Evert 2001</REF>, Nenadic et al	0	6	1
W07-1102	P98-2127	2007	by comparing its strength of association measured by PMI with those of its lexical variants	0	<REF>Like Lin 1999</REF>, we generate lexical variants of the target automatically by replacing either the verb or the noun constituent by a semantically similar word from the automatically-built thesaurus of <TREF>Lin 1998</TREF>	1	We then use a standard statistic, the z-score, to calculate Fixednesslex: Fixednesslexv, n  PMIv, nPMIstd 2 where PMI is the mean and std the standard deviation over the PMI of the target and all its variants	0	Fixednesssyn quantifies the degree of syntactic fixedness of the target combination, by comparing its behaviour in text with the behaviour of a typical verbobject, both defined as probability distributions over a predefined set of patterns	0	3	2
W05-0604	P98-2127	2005	In particular, by associating each word with a distribution over the words observed in its context, we can distinguish synonyms from non-synonyms with fair reliability	0	This capability may be exploited to generate corpus-based thesauri automatically <TREF>Lin, 1998</TREF>, or used in any other application of text that might benefit from a measure of lexical semantic similarity	1	And synonymy is a logical first step in a broader research program that seeks to account for natural language semantics through distributional means	0	Previous research into corpus-analytic approaches to synonymy has used the Test of English as a Foreign Language TOEFL	0	6	1
W05-0604	P98-2127	2005	We seek to overcome these difficulties by generating TOEFL-like tests automatically from WordNet <REF>Fellbaum, 1998</REF>	0	While WordNet has been used before to evaluate corpus-analytic approaches to lexical similarity <TREF>Lin, 1998</TREF>, the metric proposed in that study, while useful for comparative purposes, lacks an intuitive interpretation	0	In contrast, we emulate the TOEFL using WordNet and inherit the TOEFLs easy interpretability	1	Given a corpus, we first derive a list of words occurring with sufficient marginal frequency to support a distributional comparison	0	2	3
H05-1053	P98-2127	2005	et al	0	2004 we use a3a5a4a7a6a9a8 and obtain our thesaurus using the distributional similarity metric described by <TREF>Lin 1998</TREF>	1	We use WordNet WN as our sense inventory	0	The senses of a worda2 are each assigned a ranking score which sums over the distributional similarity scores of the neighbours and weights each neighbours score by a WN Similarity score <REF>Patwardhan and Pedersen, 2003</REF> between the sense of a2 and the sense of the neighbour that maximises the WN Similarity score	0	3	2
W06-1406	P98-2127	2006	The distributional hypothesis <REF>Harris, 1968</REF> says the following: The meaning of entities, and the meaning of grammatical relations among them, is related to the restriction of combinations of these entities relative to other entities	0	Over recent years, many applications <TREF>Lin, 1998</TREF>, <REF>Lee, 1999</REF>, <REF>Lee, 2001</REF>, <REF>Weeds et al , 2004</REF>, and <REF>Weeds and Weir, 2006</REF> have been investigating the distributional similarity of words	1	Similarity means that words with similar meaning tend to appear in similar contexts	0	In NLG, the considerationofsemanticsimilarityisusuallypreferred to just distributional similarity	0	6	1
E99-1013	P98-2127	1999	A word w possesses the feature f if f and w belong to the same Roget category	0	The similarity between two words is then defined as the Dice coefficient of the two feature vectors <TREF>Lin, 1998</TREF>	1	simwl,w2  21Rwl n Rwl tnw,l  Inw l where Rw is the set of words that belong to the same Roget category as w 23 Corpus-based Thesaurus 231 Co-occurrence-based Thesaurus This method is based on the assumption that a pair of words that frequently occur together in the same document are related to the same subject	0	Therefore word co-occurrence information can be used to identify semantic relationships between words <REF>Schutze and Pederson, 1997</REF>; <REF>Schutze and Pederson, 1994</REF>	0	6	1
E99-1013	P98-2127	1999	232 Syntactically-based Thesaurus In contrast to the previous section, this method attempts to gather term relations on the basis of linguistic relations and not document cooccurrence statistics	0	Words appearing in similax grammatical contexts are assumed to be similar, and therefore classified into the same class <TREF>Lin, 1998</TREF>; <REF>Grefenstette, 1994</REF>; <REF>Grefenstette, 1992</REF>; <REF>Ruge, 1992</REF>; <REF>Hindle, 1990</REF>	1	First, all the documents are parsed using the Apple Pie Parser	0	The Apple Pie Parser is a natural language syntactic analyzer developed by Satoshi Sekine at New York University <REF>Sekine and Grishman, 1995</REF>	0	6	1
W02-0908	P98-2127	2002	When these are used with weighted attributes, if the weight is greater than zero, then it is considered in the set	0	Other measures, such as LIN and JACCARD have previously been used for thesaurus extraction <TREF>Lin, 1998a</TREF>; <REF>Grefenstette, 1994</REF>	1	Finally, we have generalised some set measures using similar reasoning to <REF>Grefenstette 1994</REF>	0	Alternative generalisations are marked with a dagger	0	6	1
W02-0908	P98-2127	2002	Section 5 reports on the trade-off between the minimum cutoff and execution time	0	Early experiments in thesaurus extraction <REF>Grefenstette, 1994</REF> suffered from the limited size of available corpora, but more recent experiments have used much larger corpora with greater success <TREF>Lin, 1998a</TREF>	1	For these experiments we ran our relation extractor over the British National Corpus BNC consisting of 114 million words in 62 million sentences	0	The POS tagging and chunking took 159 minutes, and the relation extraction took an addiSETCOSINE jwm; ; wn; ; jpjw m; ; j jwn; ; j COSINE P r;w0 wgtwm; r; w0 wgtwn; r; w0pP wgtwm; ; 2 Pwgtwn; ; 2 SETDICE 2jwm; ; wn; ; jjwm; ; jjwn; ; j DICE P r;w0 wgtwm; r; w0 wgtwn; r; w0P r;w0 wgtwm; r; w0wgtwn; r; w0 DICEy 2 P r;w0 minwgtwm; r; w0;wgtwn; r; w0P r;w0 wgtwm; r; w0wgtwn; r; w0 SETJACCARD jwm; ; wn; ; jjwm; ; wn; ; j JACCARD P r;w0 minwgtwm; r; w0;wgtwn; r; w0P r;w0 maxwgtwm; r; w0;wgtwn; r; w0 JACCARDy P r;w0 wgtwm; r; w0 wgtwn; r; w0P r;w0 wgtwm; r; w0wgtwn; r; w0 LIN P r;w0 wgtwm; r; w0wgtwn; r; w0P wgtwm; ; Pwgtwn; ;  Table 1: Measure functions evaluated tional 7:5 minutes	0	1	2
W02-0908	P98-2127	2002	The list of measure and weight functions we compared against is not complete, and we hope to add other functions to provide a general framework for thesaurus extraction experimentation	0	We would also like to expand our evaluation to include direct methods used by others <TREF>Lin, 1998a</TREF> and using the extracted thesaurus in NLP tasks	1	We have also investigated the speed/performance trade-off using frequency cutoffs	0	This has lead to the proposal of a new approximate comparison algorithm based on canonical attributes and a process of coarseand ne-grained comparisons	0	5	2
W02-0908	P98-2127	2002	These experiments also cover a range of weight functions as de ned in Table 2	0	The weight functions LIN98A, LIN98B, and GREF94 are taken from existing systems <TREF>Lin, 1998a</TREF>; <TREF>Lin, 1998b</TREF>; <REF>Grefenstette, 1994</REF>	1	Our proposed weight functions are motivated by our intuition that highly predictive attributes are strong collocations with their terms	0	Thus, we have implemented many of the statistics described in the Collocations chapter of Manning and Schcurrency1utze 1999, including the T-Test, 2-Test, Likelihood Ratio, and Mutual Information	0	3	2
W02-0908	P98-2127	2002	The resultant representation contained a total of 28 million relation occurrences over 10 million different relations	0	We describe the functions evaluated in these experiments using an extension of the asterisk notation used by <TREF>Lin 1998a</TREF>, where an asterisk indicates a set ranging over all existing values of that variable	1	For example, the set of attributes of the term w is: w; ;  fr;w0j9w;r;w0g For convenience, we further extend the notation for weighted attribute vectors	0	A subscripted asterisk indicates that the variables are bound together: X r;w0 wgtwm; r; w0 wgtwn; r; w0 which is a notational abbreviation of: X r;w02wm; ; wn; ;  wgtwm;r;w0 wgtwn;r;w0 For weight functions we use similar notation: f w; ;  X r;w02w; ;  f w;r;w0 nw; ;  jw; ; j Nw jfwj9w; ; ,;gj Table 1 de nes the measure functions evaluated in these experiments	0	3	2
W02-0908	P98-2127	2002	Some systems de ne the context as a window of words surrounding each thesaurus term <REF>McDonald, 2000</REF>	0	Many systems extract grammatical relations using either a broad coverage parser <TREF>Lin, 1998a</TREF> or shallow statistical tools <REF>Grefenstette, 1994</REF>; <REF>Curran and Moens, 2002</REF>	1	Our experiments use a shallow relation extractor based on <REF>Grefenstette, 1994</REF>	0	We de ne a context relation instance as a tuple w;r;w0 where w is the thesaurus term, which occurs in some grammatical relation r with another word w0 in the sentence	0	6	1
W02-0908	P98-2127	2002	These systems differ primarily in their de nition of context and the way they calculate similarity from the contexts each term appears in	0	Most systems extract co-occurrence and syntactic information from the words surrounding the target term, which is then converted into a vector-space representation of the contexts that each target term appears in <REF>Pereira et al , 1993</REF>; <REF>Ruge, 1997</REF>; <TREF>Lin, 1998b</TREF>	1	Other systems take the whole document as the context and consider term co-occurrence at the document level <REF>Crouch, 1988</REF>; <REF>Sanderson and Croft, 1999</REF>	0	Once these contexts have been dened, these systems then use clustering or nearest neighbour methods to nd similar terms	0	6	1
W06-1317	P98-2127	2006	431 Corpus-based Lexical Similarity Lexical similarity was computed using the Word Sketch Engine WSE <REF>Killgarrif et al , 2004</REF> similarity metric applied over British National Corpus	0	The WSE similarity metric implements the word similarity measure based on grammatical relations as defined in <TREF>Lin, 1998</TREF> with minor modifications	1	432 The Brandeis Semantic Ontology As a second source of lexical coherence, we used the Brandeis Semantic Ontology or BSO <REF>Pustejovsky et al , 2006</REF>	0	The BSO is a lexicallybased ontology in the Generative Lexicon tradition <REF>Pustejovsky, 2001</REF>; <REF>Pustejovsky, 1995</REF>	0	3	2
D07-1107	P98-2127	2007	<REF>Mihalcea and Moldovan, 2001</REF> implements six semantic rules, using twin and autohyponym features, in addition to other WordNet-structure-based rules such as whether two synsets share a pertainym, antonym, or are clustered together in the same verb group	0	A large body of work has attempted to capture corpus-based estimates of word similarity <REF>Pereira et al , 1993</REF>; <TREF>Lin, 1998</TREF>; however, the lack of large sense-tagged corpora prevent most such techniques from being used effectively to compare different senses of the same word	1	Some corpus-based attempts that are capable of estimating similarity between word senses include the topic signatures method; here, <REF>Agirre and Lopez, 2003</REF> collect contexts for a polysemous word based either on sensetagged corpora or by using a weighted agglomeration of contexts of a polysemous words monosemous relatives ie , single-sense synsets related by hypernym, hyponym, or other relations from some large untagged corpus	0	Other corpus-based techniques developed specifically for sense clustering include <REF>McCarthy, 2006</REF>, which uses a combination of word-to-word distributional similarity combined with the JCN WordNet-based similarity measure, and work by <REF>Chugur et al , 2002</REF> in finding co-occurrences of senses within documents in sense-tagged corpora	0	1	3
D07-1107	P98-2127	2007	Much work has gone into methods for measuring synset similarity; early work in this direction includes <REF>Dolan, 1994</REF>, which attempted to discover sense similarities between dictionary senses	0	A variety of synset similarity measures based on properties of WordNet itself have been proposed; nine such measures are discussed in <REF>Pedersen et al , 2004</REF>, including gloss-based heuristics <REF>Lesk, 1986</REF>; <REF>Banerjee and Pedersen, 2003</REF>, information-content based measures <REF>Resnik, 1995</REF>; <TREF>Lin, 1998</TREF>; <REF>Jiang and Conrath, 1997</REF>, and others	1	Other approaches have used specific cues from WordNet structure to inform the construction of semantic rules; for example, <REF>Peters et al , 1998</REF> suggest clustering two senses based on a wide variety of structural cues from WordNet, including if they are twins if two synsets share more than one word in their synonym list or if they represent an example of autohyponymy if one sense is the direct descendant of the other	0	<REF>Mihalcea and Moldovan, 2001</REF> implements six semantic rules, using twin and autohyponym features, in addition to other WordNet-structure-based rules such as whether two synsets share a pertainym, antonym, or are clustered together in the same verb group	0	6	1
D07-1107	P98-2127	2007	3 Learning to merge word senses 31 WordNet-based features Here we describe the feature space we construct for classifying whether or not a pair of synsets should be merged; first, we employ a wide variety of linguistic features based on information derived from WordNet	0	We use eight similarity measures implemented within the WordNet::Similarity package5, described in <REF>Pedersen et al , 2004</REF>; these include three measures derived from the paths between the synsets in WordNet: HSO Hirst and St-<REF>Onge, 1998</REF>, LCH <REF>Leacock and Chodorow, 1998</REF>, and WUP <REF>Wu and Palmer, 1994</REF>; three measures based on information content: RES <REF>Resnik, 1995</REF>, LIN <TREF>Lin, 1998</TREF>, and JCN <REF>Jiang and Conrath, 1997</REF>; the gloss-based Extended Lesk Measure LESK, <REF>Banerjee and Pedersen, 2003</REF>, and finally the gloss vector similarity measure VECTOR <REF>Patwardan, 2003</REF>	1	We implement the TWIN feature <REF>Peters et al , 1998</REF>, which counts the number of shared synonyms between the two synsets	0	Additionally we produce pairwise features indicating whether two senses share an ANTONYM, PERTAINYM, or derivationally-related forms DERIV	0	3	2
N07-1045	P98-2127	2007	Our thesaurus brings up only alternatives that have the same part-of-speech with the target word	0	The choices could come from various inventories of near-synonyms or similar words, for example the Roget thesaurus Roget, 1852, dictionaries of synonyms <REF>Hayakawa, 1994</REF>, or clusters acquired from corpora <TREF>Lin, 1998</TREF>	1	In this paper we focus on the task of automatically selecting the best near-synonym that should be used in a particular context	0	The natural way to validate an algorithm for this task would be to ask human readers to evaluate the quality of the algorithms output, but this kind of evaluation would be very laborious	0	2	2
W04-0849	P98-2127	2004	For more details on hypernym collocations, see OHara, forthcoming	0	Word-similarity classes <TREF>Lin, 1998</TREF> derived from clustering are also used to expand the pool of potential collocations; this type of semantic relatedness among words is expressed in the SimilarColl feature	1	For the DictColl features, definition analysis OHara, forthcoming is used to determine the semantic relatedness of the defining words	0	Dierences between these two sources of word relations are illustrated by looking at the information they provide for ballerina: word-clusters: dancer:0115 baryshnikov:0072 pianist:0056 choreographer:0049  18 other words nicole:0041 wrestler:0040 tibetans:0040 clown:0040 definition words: dancer:00013 female:00013 ballet:00004 This shows that word clusters capture a wider range of relatedness than the dictionary definitions at the expense of incidental associations eg , nicole	0	3	2
W04-0849	P98-2127	2004	Again, because context words are not disambiguated, the relations for all senses of a context word are conflated	0	For details on the extraction of word clusters, see <TREF>Lin, 1998</TREF>; and, for details on the definition analysis, see OHara, forthcoming	1	When formulating the features SimilarColl and DictColl, the words related to each context word are considered as potential collocations <REF>Wiebe et al , 1998</REF>	0	Co-occurrence freSense Distinctions Precision Recall Fine-grained 566 565 Course-grained 660 658 Table 1: Results for Senseval-3 test data	0	3	2
J04-3002	P98-2127	2004	A set of seed words begins the process	0	For each seed s i, the precision of the set s i C i,n in the training data is calculated, where C i,n is the set of n words most similar to s i, according to <TREF>Lins 1998</TREF> method	1	If the precision of s i C i,n is greater than a threshold T, then the words in this set are retained as PSEs	0	If it is not, neither s i nor the words in C i,n are retained	0	3	2
J04-3002	P98-2127	2004	Many variants of distributional similarity have been used in NLP <REF>Lee 1999</REF>; <REF>Lee and Pereira 1999</REF>	0	<TREF>Dekang Lins 1998</TREF> method is used here	1	In contrast to many implementations, which focus exclusively on verb-noun relationships, Lins method incorporates a variety of syntactic relations	0	This is important for subjectivity recognition, because PSEs are not limited to verb-noun relationships	0	3	2
J04-3002	P98-2127	2004	We are not aware of other work that uses such collocations as we do	0	Features identified using distributional similarity have previously been used for syntactic and semantic disambiguation <REF>Hindle 1990</REF>; <REF>Dagan, Pereira, and Lee 1994</REF> and to develop lexical resources from corpora <TREF>Lin 1998</TREF>; <REF>Riloff and Jones 1999</REF>	1	We are not aware of other work identifying and using density parameters as described in this article	0	Since our experiments, other related work in NLP has been performed	0	6	1
J04-3002	P98-2127	2004	The method is then used to identify an unusual form of collocation: One or more positions in the collocation may be filled by any word of an appropriate part of speech that is unique in the test data	0	The third type of subjectivity clue we examine here are adjective and verb features identified using the results of a method for clustering words according to distributional similarity <TREF>Lin 1998</TREF> Section 34	1	We hypothesized that two words may be distributionally similar because they are both potentially subjective eg , tragic, sad, and poignant are identified from bizarre	0	In addition, we use distributional similarity to improve estimates of unseen events: A word is selected or discarded based on the precision of it together with its n most similar neighbors	0	3	2
J04-3002	P98-2127	2004	We also presented a procedure for automatically identifying potentially subjective collocations, including fixed collocations and collocations with placeholders for unique words	0	In addition, we used the results of a method for clustering words according to distributional similarity <TREF>Lin 1998</TREF> to identify adjectival and verbal clues of subjectivity	1	Table 9 summarizes the results of testing all of the above types of PSEs	0	All show increased precision in the evaluations	0	3	2
N04-1030	P98-2127	2004	The verbs were clustered into 64 classes using the probabilistic co-occurrence model of <REF>Hofmann and Puzicha 1998</REF>	0	The clustering algorithm uses a database of verb-direct-object relations extracted by <TREF>Lin 1998</TREF>	1	We then use the verb class of the current predicate as a feature	0	4	0	3	2
W04-0910	P98-2127	2004	Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries	0	For these or for a specific domain, basic synonymic dictionaries can be complemented using learning methods based on distributional similarity <REF>Pereira et al , 1993</REF>; <TREF>Lin, 1998</TREF>	1	techniques	0	For intercategorial synonymy involving a derivational morphology link, some resources are available which however are only partial in that they only store morphological families that is, sets of items that are morphologically related	0	6	1
C04-1036	P98-2127	2004	The experiment was conducted using an 18 million tokens subset of the Reuters RCV1 corpus,2 parsed by Lins Minipar dependency parser <REF>Lin, 1993</REF>	0	We considered first an evaluation based on WordNet data as a gold standard, as in <TREF>Lin, 1998</TREF>; <REF>Weeds and Weir, 2003</REF>	0	However, we found that many word pairs from the Reuters Corpus that are clearly substitutable are not linked appropriately in WordNet	1	We therefore conducted a manual evaluation based on the judgments of two human subjects	0	2	3
C04-1036	P98-2127	2004	Typical feature weighting functions include the logarithm of the frequency of word-feature cooccurrence <REF>Ruge, 1992</REF>, and the conditional probability of the feature given the word within probabilistic-based measures <REF>Pereira et al , 1993</REF>, <REF>Lee, 1997</REF>, <REF>Dagan et al , 1999</REF>	0	Probably the most widely used association weight function is point-wise Mutual Information MI <REF>Church et al , 1990</REF>, <REF>Hindle, 1990</REF>, <TREF>Lin, 1998</TREF>, <REF>Dagan, 2000</REF>, defined by:  ,log, 2 fPwP fwPfwMI  A known weakness of MI is its tendency to assign high weights for rare features	1	Yet, similarity measures that utilize MI showed good performance	0	In particular, a common practice is to filter out features by minimal frequency and weight thresholds	0	1	3
C04-1036	P98-2127	2004	Finally, a novel feature weighting and selection function is presented, which yields superior feature vectors and better word similarity performance	0	Distributional Similarity has been an active research area for more than a decade <REF>Hindle, 1990</REF>, <REF>Ruge, 1992</REF>, <REF>Grefenstette, 1994</REF>, <REF>Lee, 1997</REF>, <TREF>Lin, 1998</TREF>, <REF>Dagan et al , 1999</REF>, <REF>Weeds and Weir, 2003</REF>	1	Inspired by Harris distributional hypothesis <REF>Harris, 1968</REF>, similarity measures compare a pair of weighted feature vectors that characterize two words	0	Features typically correspond to other words that co-occur with the characterized word in the same context	0	6	1
C04-1036	P98-2127	2004	We picked the widely cited and competitive eg	1	<REF>Weeds and Weir, 2003</REF> measure of <TREF>Lin 1998</TREF> as a representative case, and utilized it for our analysis and as a starting point for improvement	0	21 Lins 98 Similarity Measure Lins similarity measure between two words, w and v, is defined as follows:,,, ,, ,           fvweightfwweight fvweightfwweight vwsim vFfwFf vFwFf where Fw and Fv are the active features of the two words and the weight function is defined as MI	0	A feature is defined as a pair <term, syntacCountryState Ranks CountryEconomy Ranks Broadcast Goods Civilservant Bloc Nonaligned Neighboring Statistic Border Northwest 24 140 64 30 55 15 165 10 41 50 16 54 77 60 165 43 247 174 Devastate Developed Dependent Industrialized Shattered Club Black Million Electricity 81 36 101 49 16 155 122 31 130 8 78 26 85 141 38 109 245 154 Table 3: The top-10 common features for the word pairs country-state and country-economy, along with their corresponding ranks in the sorted feature lists of the two words	0	3	2
E06-1016	P98-2127	2006	These categories represent the coarse senses of bark	0	Note that published thesauri are structurally quite different from the thesaurus automatically generated by <TREF>Lin 1998</TREF>, wherein a word has exactly one entry, and its neighbors may be semantically related to it in any of its senses	1	All future mentions of thesaurus will refer to a published thesaurus	0	While other sense inventories such as WordNet exist, use of a published thesaurus has three distinct advantages: i coarse sensesit is widely believed that the sense distinctions of WordNet are far too fine-grained Agirre and Lopez de <REF>Lacalle Lekuona 2003</REF> and citations therein; ii computational easewith just around a thousand categories, the wordcategory matrix has a manageable size; iii widespread availabilitythesauri are available or can be created with relatively less effort in numerous languages, while WordNet is available only for English and a few romance languages	0	6	1
E06-1016	P98-2127	2006	2004 automatically determine domainspecific predominant senses of words, where the domain may be specified in the form of an untagged target text or simply by name for example, financial domain	0	The system Figure 1 automatically generates a thesaurus <TREF>Lin, 1998</TREF> using a measure of distributional similarity and an untagged corpus	1	The target text is used for this purpose, provided it is large enough to learn a thesaurus from	0	Otherwise a large corpus with sense distribution similar to the target text text pertaining to the specified domain must be used	0	3	2
E06-1016	P98-2127	2006	This requires large amounts of partof-speech-tagged and chunked data from that domain	0	Further, the target text must be large enough to learn a thesaurus from <TREF>Lin 1998</TREF> used a 64million-word corpus, or a large auxiliary text with a sense distribution similar to the target text must be provided McCarthy et al	1	2004 separately used 90-, 325-, and 91-million-word corpora	0	By contrast, in this paper we present a method that accurately determines sense dominance even in relatively small amounts of target text a few hundred sentences; although it does use a corpus, it does not require a similarly-sense-distributed corpus	0	2	3
C02-1063	P98-2127	2002	Furthermore, whereas we expect to yield different trees modeling the connotations of different texts, MSTs ignore this aspect dependency since they focus on a unique spanning tree of the underlying feature space	0	Another candidate is given by dependency trees <REF>Rieger, 1984</REF> which are equal to similarity trees <TREF>Lin, 1998</TREF>: for a given root x, the nodes are inserted into its similarity tree ST in descending order of their similarity to x, where the predecessor of any node z is chosen to be the node y already inserted, to which z is most similar	1	Although STs already capture the aspect dependency induced by their varying roots, the path criterion is still not met	0	Thus, we generalize the concept of a ST to that of a cohesion tree as follows: First, we observe that the construction of STs uses two types of order relations: the first, let it call 1x, determines the order of the nodes inserted dependent on root x; the second, let it call 2y, varies with node y to be inserted and determines its predecessor	0	6	1
W06-1605	P98-2127	2006	2003	0	Typical relation-constrained DPs are those of <TREF>Lin 1998</TREF> and <REF>Lee 2001</REF>	1	Below are contrived, but plausible, examples of each for the word pulse; the numbers are conditional probabilities	0	relation-free DP pulse: beat 28, racing 2, grow 13, beans 09, heart 04,   	0	3	2
W06-1605	P98-2127	2006	Co-occurrence counts less than 5 were reset to 0, and words that co-occurred with more than 2000 other words were stoplisted 543 in all	0	We used ASD cp  BP 0BM99, Cos cp, JSD cp,andLin pmi 4 to populate corresponding conceptconcept distance matrices and 4 <REF>Whereas Lin 1998</REF> used relation-constrained DPs, in our experiments all DPs are relation-free	1	Table 2: Correlation of distributional measures with human ranking	0	Best results for each measure-type are shown in boldface	0	2	1
W06-1605	P98-2127	2006	The distance between two words, given their DPs, is calculated using a measure of DP distance, such as cosine	0	While any of the measures of DP distance may be used with any of the measures of strength of association see Table 1, in practice -skew divergence ASD, cosine, and JensenShannon divergence JSD are used with conditional probability CP, whereas Lin is used with PMI, resulting in the distributional measures ASD cp <REF>Lee, 2001</REF>, Cos cp <REF>Schutze and Pedersen, 1997</REF>, JSD cp,andLin pmi <TREF>Lin, 1998</TREF>, respectively	1	ASD cp is a modification of Kullback-Leibler divergence that overcomes the latters problem of division by zero, which can be caused by data sparseness	0	JSD cp is another relative entropybased measure like ASD cp  but it is symmetric	0	3	2
H05-1077	P98-2127	2005	Given this assumption, identifying the types of information provided by speakers and distinguishing and quantifying the relationships between stimulus and response can serve a number of purposes for NLP applications	0	First, the notion of semantic verb relations is crucial for many NLP tasks and applications such as verb clustering <REF>Pereira et al , 1993</REF>; <REF>Merlo and Stevenson, 2001</REF>; <TREF>Lin, 1998</TREF>; Schulte im <REF>Walde, 2003</REF>, thesaurus extraction <REF>Lin, 1999</REF>; <REF>McCarthy et al , 2003</REF>, word sense discrimination <REF>Schutze, 1998</REF>, text indexing <REF>Deerwester et al , 1990</REF>, and summarisation <REF>Barzilay et al , 2002</REF>	1	Different applications incorporate different semantic verb relations, varying with respect to their demands	0	To date, limited effort has been spent on specifying the range of verb-verb relations	0	6	1
H05-1077	P98-2127	2005	As mentioned before, most previous work on distributional similarity has focused either on a specific word-word relation such as Pereira et al	0	1993 referring to a direct object noun for describing verbs, or used any syntactic relationship detected by the chunker or parser such as Lin 1999; 1998 and McCarthy et al	1	2003	0	Naturally, the contribution of distributional features depends on the distributional objects and the application, but our results suggest that it is worth determining a task-specific set of prominent features	0	6	1
H05-1077	P98-2127	2005	The features in the distributional descriptions can be varied in nature: words co-occurring in a document, in a context window, or with respect to a word-word relationship, such as syntactic structure, syntactic and semantic valency, etc Most previous work on distributional similarity has either focused on a specific word-word relation such as Pereira et al	0	1993 referring to a direct object noun for describing verbs, or used any dependency relation detected by the chunker or parser such as Lin 1999; 1998, and McCarthy et al	1	2003	0	Little effort has been spent on varying the mostly nominal types of verb features	0	6	1
P08-1050	P98-2127	2008	We therefore decide to break it into two individual dependency relations: PPwith, PP-fork	0	Although dependency relations have been widelyusedinautomaticacquisitionoflexicalinformation, such as detection of polysemy <TREF>Lin, 1998</TREF> and WSD <REF>McCarthy et al, 2004</REF>, their utility in AVC still remains untested	1	Co-occurrence CO: CO features mostly convey lexical information only and are generally considered not particularly sensitive to argument structures <REF>Rohde et al, 2004</REF>	0	Nevertheless, it is worthwhile testing whether the meaning components that are brought out by syntactic alternations are also correlated to the neighboring words	0	6	1
C04-1146	P98-2127	2004	The related Dice Coe cient Frakes and Baeza-<REF>Yates, 1992</REF> is omitted here since it has been shown van <REF>Rijsbergen, 1979</REF> that Dice and Jaccards Coe cients are monotonic in each other	0	Lins Measure <TREF>Lin, 1998</TREF> is based on his information-theoretic similarity theorem, which states, the similarity between A and B is measured by the ratio between the amount of information needed to state the commonality of A and B and the information needed to fully describe what A and B are	1	The nal three measures are settings in the additive MI-based Co-occurrence Retrieval Model AMCRM <REF>Weeds and Weir, 2003</REF>; <REF>Weeds, 2003</REF>	0	We can measure the precision and the recall of a potential neighbours retrieval of the co-occurrences of the target word, where the sets of required and retrieved cooccurrences Fw1 and Fw2 respectively are those co-occurrences for which MI is positive	0	6	1
C04-1146	P98-2127	2004	We then generated ranked sets of nearest neighbours of size k  200 and where a word is excluded from being a neighbour of itself for each word and each measure	0	For a given word, we compute the overlap between neighbour sets using a comparison technique adapted from <TREF>Lin 1998</TREF>	1	Given a word w, each word w0 in WScomp is assigned a rank score of k rank if it is one of the k nearest neighbours of w using measure m and zero otherwise	0	If NSw;m is the vector of such scores for word w and measure m, then the overlap, CNSw;m1;NSw;m2, of two neighbour sets is the cosine between the two vectors: CNSw;m1;NSw;m2  P w0rm1w0;w rm2w0;wP k i1i2 The overlap score indicates the extent to which sets share members and the extent to which they are in the same order	0	3	2
C04-1146	P98-2127	2004	In the simplest case, the features of a word are de ned as the contexts in which it has been seen to occur	0	simjami is a variant <TREF>Lin, 1998</TREF> in which the features of a word are those contexts for which the pointwise mutual information MI between the word and the context is positive, where MI can be calculated using Ic;w  log PcjwPc	1	The related Dice Coe cient Frakes and Baeza-<REF>Yates, 1992</REF> is omitted here since it has been shown van <REF>Rijsbergen, 1979</REF> that Dice and Jaccards Coe cients are monotonic in each other	0	Lins Measure <TREF>Lin, 1998</TREF> is based on his information-theoretic similarity theorem, which states, the similarity between A and B is measured by the ratio between the amount of information needed to state the commonality of A and B and the information needed to fully describe what A and B are	0	5	2
C04-1146	P98-2127	2004	Other potential applications apply the hypothesised relationship <REF>Harris, 1968</REF> between distributional similarity and semantic similarity; ie, similarity in the meaning of words can be predicted from their distributional similarity	0	One advantage of automatically generated thesauruses <REF>Grefenstette, 1994</REF>; <TREF>Lin, 1998</TREF>; <REF>Curran and Moens, 2002</REF> over large-scale manually created thesauruses such as WordNet <REF>Fellbaum, 1998</REF> is that they might be tailored to a particular genre or domain	0	However, due to the lack of a tight de nition for the concept of distributional similarity and the broad range of potential applications, a large number of measures of distributional similarity have been proposed or adopted see Section 2	1	Previous work on the evaluation of distributional similarity methods tends to either compare sets of distributionally similar words to a manually created semantic resource <TREF>Lin, 1998</TREF>; <REF>Curran and Moens, 2002</REF> or be oriented towards a particular task such as language modelling <REF>Dagan et al , 1999</REF>; <REF>Lee, 1999</REF>	0	1	3
C04-1146	P98-2127	2004	However, due to the lack of a tight de nition for the concept of distributional similarity and the broad range of potential applications, a large number of measures of distributional similarity have been proposed or adopted see Section 2	0	Previous work on the evaluation of distributional similarity methods tends to either compare sets of distributionally similar words to a manually created semantic resource <TREF>Lin, 1998</TREF>; <REF>Curran and Moens, 2002</REF> or be oriented towards a particular task such as language modelling <REF>Dagan et al , 1999</REF>; <REF>Lee, 1999</REF>	0	The rst approach is not ideal since it assumes that the goal of distributional similarity methods is to predict semantic similarity and that the semantic resource used is a valid gold standard	1	Further, the second approach is clearly advantageous when one wishes to apply distributional similarity methods in a particular application area	0	1	3
P07-1028	P98-2127	2007	Let Seenrp be the set of seen headwords for an argument rp of a predicate p Then we model the selectional preference S of rp for a possible headword w0 as a weighted sum of the similarities between w0 and the seen headwords: Srpw0  summationdisplay wSeenrp simw0,wwtrpw simw0,w is the similarity between the seen and the potential headword, and wtrpw is the weight of seen headword w Similarity simw0,w will be computed on the generalization corpus, again on the basis of extracted tuples p,rp,w	0	We will be using the similarity metrics shown in Table 1: Cosine, the Dice and Jaccard coefficients, and <REF>Hindles 1990</REF> and <TREF>Lins 1998</TREF> mutual information-based metrics	1	We write f for frequency, I for mutual information, and Rw for the set of arguments rp for which w occurs as a headword	0	In this paper we only study corpus-based metrics	0	3	2
P07-1028	P98-2127	2007	Some approaches have used WordNet for the generalization step <REF>Resnik, 1996</REF>; <REF>Clark and Weir, 2001</REF>; <REF>Abe and Li, 1993</REF>, others EM-based clustering <REF>Rooth et al , 1999</REF>	0	In this paper we propose a new, simple model for selectional preference induction that uses corpus-based semantic similarity metrics, such as Cosine or <TREF>Lins 1998</TREF> mutual informationbased metric, for the generalization step	1	This model does not require any manually created lexical resources	0	In addition, the corpus for computing the similarity metrics can be freely chosen, allowing greater variation in the domain of generalization than a fixed lexical resource	0	5	2
W02-1410	P98-2127	2002	The use of synonyms is another way of increasing the coverage of question terminology;; while semantic features try to achieve it by generalization, synonyms do it by lexical expansion	0	Our plan is to use the synonyms obtained from very large corpora reported in <TREF>Lin, 1998</TREF>	1	We are also planning to compare the lexical and semantic features we derived automatically in this work with manually selected features	0	In our previous work, manually selected lexical featuresshowedslightlybetterperformanceforthe training data but no signi cant dierence for the test data	0	3	2
W07-2036	P98-2127	2007	In addition, a lot of methods have been proposed to automatically construct thesauri of synonyms	0	For example, <TREF>Lin 1998</TREF> clustered words with similar meanings by calculating the dependency similarity	1	<REF>Barzilay and McKeown 2001</REF> extracted paraphrases using multiple translations of literature works	0	<REF>Wu and Zhou 2003</REF> extracted synonyms with multiple resources, including a monolingual dictionary, a bilingual corpus, and a monolingual corpus	0	6	1
N03-1032	P98-2127	2003	The boundaries for determining cooccurrence will affect the estimates and as a consequence the word similarity measures	0	Statistical word similarity measures play an important role in information retrieval and in many other natural language applications, such as the automatic creation of thesauri <REF>Grefenstette, 1993</REF>; <REF>Li and Abe, 1998</REF></REF>; <TREF>Lin, 1998</TREF> and word sense disambiguation <REF>Yarowsky, 1992</REF>; <REF>Li and Abe, 1998</REF></REF>	1	<REF>Pantel and Lin 2002</REF> use word similarity to create groups of related words, in order to discover word senses directly from text	0	Recently, Tan et al	0	6	1
P05-1077	P98-2127	2005	In the next section, we proceed to apply this technique for generating noun similarity lists	0	4 Building Noun Similarity Lists A lot of work has been done in the NLP community on clustering words according to their meaning in text <REF>Hindle, 1990</REF>; <TREF>Lin, 1998</TREF>	1	The basic intuition is that words that are similar to each other tend to occur in similar contexts, thus linking the semantics of words with their lexical usage in text	0	One may ask why is clustering of words necessary in the first place	0	6	1
W06-3811	P98-2127	2006	Other approaches usually consider either given sets of synonyms among which one is to be chosen for a translation for instance <REF>Edmonds and Hirst, 2002</REF> or must choose a synonym word against unrelated terms in the context of a synonymy test <REF>Freitag et al , 2005</REF>, a seemingly easier task than actually proposing synonyms	0	<TREF>Lin, 1998</TREF> proposes a different methodology for evaluation of candidate synonyms, by comparing similarity measures of the terms he provides with the similarity measures between them in Wordnet, using various semantic distances	1	This makes for very complex evaluation procedures without an intuitive interpretation, and there is no assessment of the quality of the automated thesaurus	0	6 Conclusion We have developed a general method to extract nearsynonyms from a dictionary, improving on the two baselines	0	1	3
W06-3811	P98-2127	2006	A measure of similarity is almost always used to rank possible candidates	0	In the case of distributional approaches, similarity if determined from the appearance in similar contexts <TREF>Lin, 1998</TREF>; in the case of dictionary-based methods, lexical relations are deduced from the links between words expressed in definitions of entries	1	Approaches that rely on distributional data have two major drawbacks: they need a lot of data, generally syntactically parsed sentences, that is not always available for a given language English is an exception, and they do not discriminate well among lexical relations mainly hyponyms, antonyms, hypernyms <REF>Weeds et al , 2004</REF>  Dictionary-based 70 approaches address the first problem since dictionaries are readily available for a lot of language, even electronically, and this is the raison dtre of our effort	0	As we have seen here, it is not an obvious task to sort related terms with respect to synonymy, hypernymy, etc, just as with distribution approaches	0	6	1
W06-3811	P98-2127	2006	5 Related work Among the methods proposed to collect synonymy information, two families can be distinguished according to the input they consider	0	Either a general dictionary is used or more than one <REF>Wu and Zhou, 2003</REF>, or a corpus of unconstrained texts from which lexical distributions are computed simple collocations or syntactic dependencies <TREF>Lin, 1998</TREF>; <REF>Freitag et al , 2005</REF>  The approach of <REF>Barzilay and McKeown, 2001</REF> uses a related kind of resource: multiple translations of the same text, with additional constraints on availability, and problems of text alignment, for only a third of the results being synonyms when compared to Wordnet	1	A measure of similarity is almost always used to rank possible candidates	0	In the case of distributional approaches, similarity if determined from the appearance in similar contexts <TREF>Lin, 1998</TREF>; in the case of dictionary-based methods, lexical relations are deduced from the links between words expressed in definitions of entries	0	6	1
P06-2022	P98-2127	2006	<REF>Mihalcea, 2003</REF>; <REF>Riloff and Wiebe, 2003</REF>	0	Severalapproachesmakeuseofdependency triples <TREF>Lin, 1998</TREF>; <REF>Gorman and Curran, 2005</REF>	0	Our vector representation of the behavior of a word type across all its instances in a corpus is based on <TREF>Lin 1998</TREF>s DESCRIPTION OF A WORD	1	<REF>Yarowsky 1995</REF> uses a conceptually similar technique for WSD that learns from a small set of seed examples and then increases recall by bootstrapping, evaluated on 12 idiosyncratically polysemous words	0	3	2
P06-2022	P98-2127	2006	Severalapproachesmakeuseofdependency triples <TREF>Lin, 1998</TREF>; <REF>Gorman and Curran, 2005</REF>	0	Our vector representation of the behavior of a word type across all its instances in a corpus is based on <TREF>Lin 1998</TREF>s DESCRIPTION OF A WORD	1	<REF>Yarowsky 1995</REF> uses a conceptually similar technique for WSD that learns from a small set of seed examples and then increases recall by bootstrapping, evaluated on 12 idiosyncratically polysemous words	0	In that task, often a single disambiguating feature can be found in the context of a polysemous word instance, motivating his use of the decision list algorithm	0	3	2
W07-2109	P98-2127	2007	It allows us to identify triple instances	0	Each triple have the form w1Rw2 where w1 and w2 are lexical units and R is a syntactic relation <TREF>Lin, 1998</TREF>; Kilgarriff  al 2004	1	Our approach can be distinguished from classical distributional approach by different points	0	First, we use triple occurrences to build a distributional space one triple implies two contexts and two lexical units, but we use the transpose of the classical space: each point x i of this space is a syntactical context with the form Rw, each dimension j is a lexical units, and each value x i j is the frequency of corresponding triple occurrences	0	3	2
N03-1003	P98-2127	2003	2 Related work Previous work on automated paraphrasing has considered different levels of paraphrase granularity	0	Learning synonyms via distributional similarity has been well-studied <REF>Pereira et al , 1993</REF>; <REF>Grefenstette, 1994</REF>; <TREF>Lin, 1998</TREF>	1	<REF>Jacquemin 1999</REF> and <REF>Barzilay and McKeown 2001</REF> identify phraselevel paraphrases, while <REF>Lin and Pantel 2001</REF> and Shinyama et al	0	2002 acquire structural paraphrases encoded as templates	0	6	1
P03-1017	P98-2127	2003	The model is highly general and can be optimised for different tasks	0	It extends prior work on syntax-based models <REF>Grefenstette, 1994</REF>; <TREF>Lin, 1998</TREF>, by providing a general framework for defining context so that a large number of syntactic relations can be used in the construction of the semantic space	1	Our approach differs from <TREF>Lin 1998</TREF> in three important ways: a by introducing dependency paths we can capture non-immediate relationships between words ie , between subjects and objects, whereas Lin considers only local context dependency edges in our terminology; the semantic space is therefore constructed solely from isolated head/modifier pairs and their inter-dependencies are not taken into account; b Lin creates the semantic space from the set of dependency edges that are relevant for a given word; by introducing dependency labels and the path value function we can selectively weight the importance of different labels eg , subject, object, modifier and parametrize the space accordingly for different tasks; c considerable flexibility is allowed in our formulation for selecting the dimensions of the semantic space; the latter can be words see the leaves in Figure 1, parts of speech or dependency edges; in Lins approach, it is only dependency edges features in his terminology that form the dimensions of the semantic space	0	Experiment 1 revealed that the dependency-based model adequately simulates semantic priming	0	5	2
P03-1017	P98-2127	2003	Write A for the lexical association function which computes the value of a cell of the matrix from a co-occurrence frequency: Ki j  A f bi;t j 3 Evaluation 31 Parameter Settings All our experiments were conducted on the British National Corpus BNC, a 100 million word collection of samples of written and spoken language <REF>Burnard, 1995</REF>	0	We used <TREF>Lins 1998</TREF> broad coverage dependency parser MINIPAR to obtain a parsed version of the corpus	1	MINIPAR employs a manually constructed grammar and a lexicon derived from WordNet with the addition of proper names 130,000 entries in total	0	Lexicon entries contain part-of-speech and subcategorization information	0	3	2
P03-1017	P98-2127	2003	This makes semantic spaces more flexible, different types of contexts can be selected and words do not have to physically co-occur to be considered contextually relevant	0	However, existing models either concentrate on specific relations for constructing the semantic space such as objects eg , <REF>Lee, 1999</REF> or collapse all types of syntactic relations available for a given target word <REF>Grefenstette, 1994</REF>; <TREF>Lin, 1998</TREF>	1	Although syntactic information is now used to select a words appropriate contexts, this information is not explicitly captured in the contexts themselves which are still represented by words and is therefore not amenable to further processing	0	A commonly raised criticism for both types of semantic space models ie , word-based and syntaxbased concerns the notion of semantic similarity	0	6	1
P03-1017	P98-2127	2003	It extends prior work on syntax-based models <REF>Grefenstette, 1994</REF>; <TREF>Lin, 1998</TREF>, by providing a general framework for defining context so that a large number of syntactic relations can be used in the construction of the semantic space	1	Our approach differs from <TREF>Lin 1998</TREF> in three important ways: a by introducing dependency paths we can capture non-immediate relationships between words ie , between subjects and objects, whereas Lin considers only local context dependency edges in our terminology; the semantic space is therefore constructed solely from isolated head/modifier pairs and their inter-dependencies are not taken into account; b Lin creates the semantic space from the set of dependency edges that are relevant for a given word; by introducing dependency labels and the path value function we can selectively weight the importance of different labels eg , subject, object, modifier and parametrize the space accordingly for different tasks; c considerable flexibility is allowed in our formulation for selecting the dimensions of the semantic space; the latter can be words see the leaves in Figure 1, parts of speech or dependency edges; in Lins approach, it is only dependency edges features in his terminology that form the dimensions of the semantic space	0	Experiment 1 revealed that the dependency-based model adequately simulates semantic priming	0	Experiment 2 showed that a model that relies on rich context specifications can reliably distinguish between different types of lexical relations	0	5	2
P03-1017	P98-2127	2003	Contexts are defined as a small number of words surrounding the target word <REF>Lund and Burgess, 1996</REF>; <REF>Lowe and McDonald, 2000</REF> or as entire paragraphs, even documents <REF>Landauer and Dumais, 1997</REF>	0	Context is typically treated as a set of unordered words, although in some cases syntactic information is taken into account <TREF>Lin, 1998</TREF>; <REF>Grefenstette, 1994</REF>; <REF>Lee, 1999</REF>	1	A word can be thus viewed as a point in an n-dimensional semantic space	0	The semantic similarity between words can be then mathematically computed by measuring the distance between points in the semantic space using a metric such as cosine or Euclidean distance	0	6	1
P03-1043	P98-2127	2003	However, at structural level, the concept-based seeds share the same or similar linguistic patterns eg Subject-Verb-Object patterns with the corresponding types of proper names	0	The rationale behind using concept-based seeds in NE bootstrapping is similar to that for parsingbased word clustering <TREF>Lin 1998</TREF>: conceptually similar words occur in structurally similar context	1	In fact, the anaphoric function of pronouns and common nouns to represent antecedent NEs indicates the substitutability of proper names by the corresponding common nouns or pronouns	0	For example, this man can be substituted for the proper name John Smith in almost all structural patterns	0	4	2
P06-2075	P98-2127	2006	Distributional Similarity Score: The GD04 similarity score of the pair was used as a feature	0	We 583 also attempted adding Lins 1998 similarity scores but they appeared to be redundant	1	Intersection Feature: A binary feature indicating candidate pairs acquired by both methods, which was found to indicate higher entailment likelihood	0	In summary, the above feature types utilize mutually complementary pattern-based and distributional information	0	3	3
P06-2075	P98-2127	2006	For the distributional similarity component we employ the similarity scheme of <REF>Geffet and Dagan, 2004</REF>, which was shown to yield improved predictions of non-directional lexical entailment pairs	0	This scheme utilizes the symmetric similarity measure of <TREF>Lin, 1998</TREF> to induce improved feature weights via bootstrapping	1	These weights identify the most characteristic features of each word, yielding cleaner feature vector representations and better similarity assessments	0	22 Pattern-based <REF>Approaches Hearst 1992</REF> pioneered the use of lexicalsyntactic patterns for automatic extraction of lexical semantic relationships	0	3	2
P06-2075	P98-2127	2006	The degree of similarity between two target words is then determined by a vector comparison function	0	Amongst the many proposals for distributional similarity measures, <TREF>Lin, 1998</TREF> is maybe the most widely used one, while <REF>Weeds et al , 2004</REF> provides a typical example for recent research	1	Distributional similarity measures are typically computed through exhaustive processing of a corpus, and are therefore applicable to corpora of bounded size	0	It was noted recently by Geffet and Dagan 2004, 2005 that distributional similarity captures a quite loose notion of semantic similarity, as exemplified by the pair country  party identified by Lins similarity measure	0	1	2
W07-2068	P98-2127	2007	The method uses a thesaurus obtained from the text by parsing, extracting grammatical relations and then listing each word w with its top k nearest neighbours, where k is a constant	0	Like <REF>McCarthy et al , 2004</REF> we use k  50 and obtain our thesaurus using the distributional similarity metric described by <TREF>Lin, 1998</TREF> and we use WordNet WN as our sense inventory	1	The senses of a word w are each assigned a ranking score which sums over the distributional similarity scores of the neighbours and weights each neighbours score by a WN Similarity score <REF>Patwardhan and Pedersen, 2003</REF> between the sense of w and the sense of the neighbour that maximises the WN Similarity score	0	This weight is normalised by the sum of such WN similarity scores between all senses of w and the senses of the neighbour that maximises this score	0	3	2
P08-1116	P98-2127	2008	Besides, the automatically constructed thesauri can also be used	0	<TREF>Lin 1998</TREF> constructed a thesaurus by automatically clustering words based on context similarity	1	<REF>BarzilayandMcKeown 2001</REF>usedmonolingual parallel corpora for identifying paraphrases	0	They exploited a corpus of multiple English translations ofthesamesourcetextwritteninaforeignlanguage, from which phrases in aligned sentences that appear in similar contexts were extracted as paraphrases	0	6	1
P08-1116	P98-2127	2008	Therefore, we keep at most 20 paraphrases for a phrase when extracting phrasal paraphrases using each resource	0	1 Thesaurus: The thesaurus4 used in this work was automatically constructed by <TREF>Lin 1998</TREF>	1	The similarity of two words e1 and e2 was calculated through the surrounding context words that have dependency relations with the investigated words: Sime1,e2  P r,eTre1Tre2Ie1,r,eIe2,r,eP r,eTre1 Ie1,r,e P r,eTre2 Ie2,r,e 5 where Trei denotes the set of words that have dependency relation r with word ei	0	Iei,r,e is the mutual information between ei, r and e For each word, we keep 20 most similar words as paraphrases	0	3	2
C02-1007	P98-2127	2002	Those words that obtain the best values are considered to be most similar	0	Practical implementations of algorithms based on this principle have led to excellent results as documented in papers by <REF>Ruge 1992</REF>, <REF>Grefenstette 1994</REF>, <REF>Agarwal 1995</REF>, <REF>Landauer  Dumais 1997</REF>, <REF>Schtze 1997</REF>, and <TREF>Lin 1998</TREF>	1	21 Human Data In this section we relate the results of our version of such an algorithm to similarity estimates obtained by human subjects	0	Fortunately, we did not need to conduct our own experiment to obtain the humans similarity estimates	0	1	2
P08-1119	P98-2127	2008	Given the great deal of similar work in information extraction and ontology learning, we focus here only on techniques for weakly supervised or unsupervised semantic class ie, supertype-based learning, since that is most related to the work in this paper	0	Fully unsupervised semantic clustering eg, <TREF>Lin, 1998</TREF>; <REF>Lin and Pantel, 2002</REF>; <REF>Davidov and Rappoport, 2006</REF> has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user	1	Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes eg, <REF>Caraballo, 1999</REF>; <REF>Cimiano and Volker, 2005</REF>; <REF>Mann, 2002</REF>, and learning semantic relations such as meronymy <REF>Berland and Charniak, 1999</REF>; <REF>Girju et al, 2003</REF>	0	Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class eg, lists of FISH or VEHICLE words	0	1	3
N07-1043	P98-2127	2007	This is evident for word-pairs where at least one of the words is a polysemous word eg , pairs that include cock, brother	0	Page counts-based measures do not consider the context in which the words appear in a page, thus cannot disambiguate Table 4: Comparison with taxonomy based methods Method correlation Human replication 0901 <REF>Resnik 1995</REF> 0745 <TREF>Lin 1998</TREF> 0822 <REF>Li et al 2003</REF> 0891 Edge-counting 0664 Information content 0745 <REF>Jiang  Conrath 1998</REF> 0848 proposed SVM 0834 the multiple senses	1	As summarized in Table 43, proposed method is comparable with the WordNet based methods	0	In fact, the proposed method outperforms simple WordNet based approaches such as Edge-Counting and Information Content measures	0	6	1
N07-1043	P98-2127	2007	The study of semantic similarity between words has been an integral part of natural language processing and information retrieval for many years	0	Semantic similarity measures are vital for various applications in natural language processing such as word sense disambiguation <REF>Resnik, 1999</REF>, language modeling <REF>Rosenfield, 1996</REF>, synonym extraction <TREF>Lin, 1998a</TREF> and automatic thesaurus extraction <REF>Curran, 2002</REF>	1	Pre-compiled taxonomies such as WordNet 1 and text corpora have been used in previous work on semantic similarity <TREF>Lin, 1998a</TREF>; <REF>Resnik, 1995</REF>; <REF>Jiang and Conrath, 1998</REF>; <TREF>Lin, 1998b</TREF>	0	However, semantic similarity between words change over time as new senses and associations of words are constantly created	0	6	1
N07-1043	P98-2127	2007	Semantic similarity measures are vital for various applications in natural language processing such as word sense disambiguation <REF>Resnik, 1999</REF>, language modeling <REF>Rosenfield, 1996</REF>, synonym extraction <TREF>Lin, 1998a</TREF> and automatic thesaurus extraction <REF>Curran, 2002</REF>	1	Pre-compiled taxonomies such as WordNet 1 and text corpora have been used in previous work on semantic similarity <TREF>Lin, 1998a</TREF>; <REF>Resnik, 1995</REF>; <REF>Jiang and Conrath, 1998</REF>; <TREF>Lin, 1998b</TREF>	0	However, semantic similarity between words change over time as new senses and associations of words are constantly created	0	One major issue behind taxonomies and corpora oriented approaches is that they might not necessarily capture similarity between proper names such as named entities eg , personal names, location names, product names and the new uses of existing words	0	6	1
W01-1626	P98-2127	2001	Five part-of-speech features, two lexical features, and a paragraph feature were used	0	Toidentify richer features, <REF>Wiebe, 2000</REF> used Lins 1998 method for clustering words according to distributional similarity,seededby a small amount of detailed manual annotation, to automatically identify adjective PSEs	1	There are two parameters of this process, neither of whichwas varied in <REF>Wiebe, 2000</REF>: C, the cluster size considered, andFT, a lteringthreshold, such that, if the seed word and the words in its cluster have, as a set, lower precision than the ltering threshold on the training data, the entire cluster, including the seed word, is ltered out	0	This process is adapted for use in the current paper, as described in section 7	0	3	2
C04-1141	P98-2127	2004	Secondly, our kind of syntactic preprocessing which is standard nowadays allows collocation extraction algorithms to better control the structural types of collocations	0	<TREF>Lin 1998</TREF> acquires a lexical dependency database by assembling dependency relationships from a parsed corpus	1	An entry in this database is classified as collocation if its log-likelihood value is greater than some threshold	0	Using an automatically constructed similarity thesaurus, <REF>Lin 1999</REF> then separates compositional from non-compositional collocations by taking into account the second linguistic property described in Section 1, viz	0	6	1
W03-1610	P98-2127	2003	,, iwcount : frequency of the triples including word iw  N: number of triples in the corpus	0	We use it instead of point-wise mutual information in <TREF>Lin 1998</TREF> because the latter tends to overestimate the association between two parts with low frequencies	1	Weighted mutual information meliorates this effect by adding , ji attwp  24 Combining the Three Extractors In terms of combining the outputs of the different methods, the ensemble method is a good candidate	0	Originally, the ensemble method is a machine learning technique of combining the outputs of several classifiers to improve the classification performance <REF>Dietterich, 2000</REF>	0	2	3
W03-1610	P98-2127	2003	However, many studies investigate synonym extraction from only one resource	0	The most frequently used resource for synonym extraction is large monolingual corpora <REF>Hindle, 1990</REF>; <REF>Crouch and Yang, 1992</REF>; <REF>Grefenstatte, 1994</REF>; <REF>Park and Choi, 1997</REF>; <REF>Gasperin et al , 2001</REF> and <TREF>Lin, 1998</TREF>	1	The methods used the contexts around the investigated words to discover synonyms	0	The problem of the methods is that the precision of the extracted synonymous words is low because it extracts many word pairs such as cat and dog, which are similar but not synonymous	0	6	1
W07-0907	P98-2127	2007	The similarity is the sum of the WordNet similarities between all attribute keywords in the two exhibits K1, K2, normalised over the length of both keyword sets: summationtext k1K1 summationtext k2K2 WNsimk1,k2 K1K2 For the purposes of this experiment we have chosen to use three WordNet similarity/relatedness measures to simulate the conceptual connections that visitors make between exhibits	0	The Lin <TREF>Lin, 1998</TREF> and Leacock-Chodorow <REF>Leacock et al , 1998</REF> similarity measures and the BanerjeePedersen <REF>Patwardhan and Pedersen, 2003</REF> relatedness measures were used	1	The similarities were normalised and transformed into probability matrices such that summationtextj PWNsimecj  1 for each next exhibit ci	0	The use of WordNet measures is intended to simulate the mental connections that visitors make between exhibit content, given that each visit can interpret content in a number of different ways	0	3	2
N07-4002	P98-2127	2007	Using Language Weavers 1 English-to-Spanish machine translation system, English marginal notes can be translated into Spanish	0	22 Vocabulary Support Synonyms for lower frequency more difficult words are output using a statistically-generated word similarity matrix <TREF>Lin, 1998</TREF>	1	ATA v10 generates antonyms for vocabulary in the text using WordNet 	0	2 Cognates are words which have the same spelling and meaning in two languages eg , animal in English and Spanish	0	3	2
W07-2066	P98-2127	2007	While WordNet has its advantages, we aimed to create a knowledge-light 304 system	0	A more knowledge-free system would have used a machine readable dictionary or a large natural language sample to retrieve its synonyms see, for example, <TREF>Lin 1998</TREF>, but our system falls short of this, relying on Rogets New Millennium Thesaurus1 henceforth RT as a source of synonyms	1	Though this thesaurus is similar to WordNet in some ways, it does not contain semantic relationships beyond synonyms and antonyms	0	One important advantage of a thesaurus over WordNet is that it is easier to obtain for languages other than English	0	6	1
C02-1144	P98-2127	2002	The parameters K and T are usually considered to be small numbers	0	3 Word Similarity Following <TREF>Lin 1998</TREF>, we represent each word by a feature vector	1	Each feature corresponds to a context in which the word occurs	0	For example, threaten with  is a context	0	3	2
P99-1004	P98-2127	1999	Variations of the value difference metric <REF>Stanfill and Waltz, 1986</REF> have been employed for supervised disambiguation Ng and HB <REF>Lee, 1996</REF>; <REF>Ng, 1997</REF>; but it is not reasonable in language modeling to expect training data tagged with correct probabilities	0	The Dice coejcient <REF>Smadja et al , 1996</REF>; D <REF>Lin, 1998a, 1998b</REF> is monotonic in Jaccards coefficient van <REF>Rijsbergen, 1979</REF>, so its inclusion in our experiments would be redundant	1	Finally, we did not use the KL divergence because it requires a smoothed base language model	0	SZero would also be a reasonable choice, since it indicates zero correlation between q and r However, it would then not be clear how to average in the estimates of negatively correlated words in equation 1	0	6	1
P99-1004	P98-2127	1999	Furthermore, by using a restricted version of model 1 that stripped incomparable parameters, we were able to empirically demonstrate that the confusion probability is fundamentally worse at selecting useful similar words	0	D Lin also found that the choice of similarity function can affect the quality of automatically-constructed thesauri to a statistically significant degree 1998a and the ability to determine common morphological roots by as much as 49 in precision 1998b	1	1The term similarity-based, which we have used previously, has been applied to describe other models as well L <REF>Lee, 1997</REF>; <REF>Karov and Edelman, 1998</REF>	0	These empirical results indicate that investigating different similarity measures can lead to improved natural language processing	0	6	1
P99-1004	P98-2127	1999	In essence, Smadja et al argue that information from the union of supports, rather than the just the intersection, is important	0	D Lin 1997; 1998a takes an axiomatic approach to determining the characteristics of a good similarity measure	1	Starting with a formalization based on certain assumptions of the intuition that the similarity between two events depends on both their commonality and their differences, he derives a unique similarity function schema	0	The 04 038 I 036  034 032 03 028 026 100 Error rates averages and ranges L1 JS 0 300 0 0 600 700 800 0 1000 k Figure 4: Performance of the skew divergence with respect to the best functions from Figure 2	0	6	1
P99-1004	P98-2127	1999	3 It is worth noting at this point that there are several well-known measures from the NLP literature that we have omitted from our experiments	0	Arguably the most widely used is the mutual information <REF>Hindle, 1990</REF>; <REF>Church and Hanks, 1990</REF>; <REF>Dagan et al , 1995</REF>; <REF>Luk, 1995</REF>; D <TREF>Lin, 1998a</TREF>	0	It does not apply in the present setting because it does not measure the similarity between two arbitrary probability distributions in our case, PVIn  and PVIm, but rather the similarity between a joint distribution PX1,X2 and the corresponding product distribution PX1PX2	0	Hamming-type metrics <REF>Cardie, 1993</REF>; <REF>Zavrel and Daelemans, 1997</REF> are intended for data with symbolic features, since they count feature label mismatches, whereas we are dealing feature Values that are probabilities	0	6	1
W05-1202	P98-2127	2005	Words cannot be substituted between the two phrases because they are composed in different ways	0	3 Proposal Recently, there has been much interest in finding words which are distributionally similar eg, <TREF>Lin 1998</TREF>, <REF>Lee 1999</REF>, <REF>Curran and Moens 2002</REF>, <REF>Weeds 2003</REF> and <REF>Geffet and Dagan 2004</REF>	1	Two words are said to be distributionally similar if they appear in similar contexts	0	For example, the two words apple and pear are likely to be seen as the objects of the verbs eat and peel, and this adds to their distributional similarity	0	6	1
W05-1202	P98-2127	2005	The reason for choosing this measure is that it can be used to compute the distance between any two co-occurrence vectors independent of any information about other words	0	This is in contrast to many other measures, eg, <TREF>Lin 1998</TREF>, which use the co-occurrences of features with other words to compute a weighting function such as mutual information MI <REF>Church and Hanks, 1989</REF>	1	Since we only have corpus data for the target phrases, it is not possible for us to use such a measure	0	However, the -skew divergence measure has been shown <REF>Weeds, 2003</REF> to perform comparably with measures which use MI, particularly for lower frequency target words	0	2	1
W05-1202	P98-2127	2005	Table 1 shows the number of feature types and tokens extracted for each phrase	0	This shows that we have extracted a reasonable number of features for each phrase, since distributional similarity techniques have been shown to work well for words which occur more than 100 times in a given corpus <TREF>Lin, 1998</TREF>; <REF>Weeds and Weir, 2003</REF>	1	We then computed the distributional similarity between each co-occurrence vector using the -skew divergence measure <REF>Lee, 1999</REF>	0	The -skew divergence measure is an approximation to the KullbackLeibler KL divergence meassure between two distributions p and q: Dpq  summationdisplay x pxlogpxqx 5We currently retain all of the distinctions between grammatical relations output by RASP	0	4	2
W05-1202	P98-2127	2005	In their work on QA, Lin and Pantel restrict the grammatical relations considered to two slots at either end of the path where the word occupying the slot is a noun	0	Co-occurrence vectors for paths are then built up using evidence from multiple occurrences of the paths in corpus data, for which similarity can then be calculated using a standard metric eg , <TREF>Lin 1998</TREF>	1	In our work, we extend the notion of distributional similarity from linear paths to trees	0	This allows us to compute distributional similarity for any part of an expression, of arbitrary length and complexity although, in practice, we are still limited by data sparseness	0	5	2
P00-1014	P98-2127	2000	W ORD S IMILAR W ORDS  WITH SIMILARITY SCORE  EAT cook 0127, drink 0108, consume 0101, feed 0094, taste 0093, like 0092, serve 0089, bake 0087, sleep 0086, pick 0085, fry 0084, freeze 0081, enjoy 0079, smoke 0078, harvest 0076, love 0076, chop 0074, sprinkle 0072, Toss 0072, chew 0072 SALAD soup 0172, sandwich 0169, sauce 0152, pasta 0149, dish 0135, vegetable 0135, cheese 0132, dessert 013, entree 0121, bread 0116, meat 0116, chicken 0115, pizza 0114, rice 0112, seafood 011, dressing 0109, cake 0107, steak 0105, noodle 0105, bean 0102 the collocation database for the words eat and salad  The database contains a total of 11 million unique dependency relationships	0	22 Corpus-based thesaurus Using the collocation database, <TREF>Lin 1998b</TREF> used an unsupervised method to construct a corpusbased thesaurus consisting of 11839 nouns, 3639 verbs and 5658 adjectives/adverbs	1	Given a word w, the thesaurus returns a set of similar words of w along with their similarity to w  For example, the 20 most similar words of eat and salad are shown in Table 1	0	3 Training Data Extraction We parsed a 125-million word newspaper corpus with Minipar 3, a descendent of Principar <REF>Lin, 1994</REF>	0	3	2
P00-1014	P98-2127	2000	Below, we briefly describe these resources	0	21 Collocation database Given a word w in a dependency relationship such as subject or object , the collocation database is used to retrieve the words that occurred in that relationship with w, in a large corpus, along with their frequencies <TREF>Lin, 1998a</TREF>	1	Figure 1 shows excerpts of the entries in 2 Available at wwwcsualbertaca/lindek/demoshtm	0	eat : object: almond 1, a pple 25, bean 5, beam 1, binge 1, bread 13, cake 17, cheese 8, dish 14, disorder 20, egg 31, grape 12, grub 2, hay 3, junk 1, meat 70, poultry 3, rabbit 4, soup 5, sandwich 18, pasta 7, vegetable 35,  subject: adult 3, animal 8, beetle 1, cat 3, child 41, decrease 1, dog 24, family 29, guest 7, kid 22, patient 7, refugee 2, rider 1, Russian 1, shark 2, something 19, We 239, wolf 5,  salad : adj-modifier: assorted 1, crisp 4, fresh 13, good 3, grilled 5, leftover 3, mixed 4, olive 3, prepared 3, side 4, small 6, special 5, vegetable 3,  object-of: add 3, consume 1, dress 1, grow 1, harvest 2, have 20, like 5, love 1, mix 1, pick 1, place 3, prepare 4, return 3, rinse 1, season 1, serve 8, sprinkle 1, taste 1, test 1, Toss 8, try 3,  Figure 1	0	3	2
P00-1014	P98-2127	2000	eat : object: almond 1, a pple 25, bean 5, beam 1, binge 1, bread 13, cake 17, cheese 8, dish 14, disorder 20, egg 31, grape 12, grub 2, hay 3, junk 1, meat 70, poultry 3, rabbit 4, soup 5, sandwich 18, pasta 7, vegetable 35,  subject: adult 3, animal 8, beetle 1, cat 3, child 41, decrease 1, dog 24, family 29, guest 7, kid 22, patient 7, refugee 2, rider 1, Russian 1, shark 2, something 19, We 239, wolf 5,  salad : adj-modifier: assorted 1, crisp 4, fresh 13, good 3, grilled 5, leftover 3, mixed 4, olive 3, prepared 3, side 4, small 6, special 5, vegetable 3,  object-of: add 3, consume 1, dress 1, grow 1, harvest 2, have 20, like 5, love 1, mix 1, pick 1, place 3, prepare 4, return 3, rinse 1, season 1, serve 8, sprinkle 1, taste 1, test 1, Toss 8, try 3,  Figure 1	0	Excepts of entries in the collocation database for eat and salad  Table 1  The top 20 most similar words of eat and salad as given by <TREF>Lin, 1998b</TREF>	1	W ORD S IMILAR W ORDS  WITH SIMILARITY SCORE  EAT cook 0127, drink 0108, consume 0101, feed 0094, taste 0093, like 0092, serve 0089, bake 0087, sleep 0086, pick 0085, fry 0084, freeze 0081, enjoy 0079, smoke 0078, harvest 0076, love 0076, chop 0074, sprinkle 0072, Toss 0072, chew 0072 SALAD soup 0172, sandwich 0169, sauce 0152, pasta 0149, dish 0135, vegetable 0135, cheese 0132, dessert 013, entree 0121, bread 0116, meat 0116, chicken 0115, pizza 0114, rice 0112, seafood 011, dressing 0109, cake 0107, steak 0105, noodle 0105, bean 0102 the collocation database for the words eat and salad  The database contains a total of 11 million unique dependency relationships	0	22 Corpus-based thesaurus Using the collocation database, <TREF>Lin 1998b</TREF> used an unsupervised method to construct a corpusbased thesaurus consisting of 11839 nouns, 3639 verbs and 5658 adjectives/adverbs	0	3	2
J06-1003	P98-2127	2006	5 We also attempted to implement Sussnas 1993, 1997 measure Section 251, but ran into problems because a key element depended closely on the particulars of an earlier version of WordNet; see <REF>Budanitsky 1999</REF> for details	0	We did not include Wu and Palmers measure Section 252 because <TREF>Lin 1998b</TREF> has shown it to be a special case of his measure in which all childparent probabilities are equal	1	6 In their original experiments, Lin and Jiang and Conrath used SemCor, a sense-tagged subset of the Brown Corpus, as their empirical data; but we decided to follow Resnik in using the full and untagged corpus	0	While this means trading accuracy for size, we believe that using a non-disambiguated corpus constitutes a more-general approach, as the availability and size of disambiguated texts such as SemCor is highly limited	0	6	1
J06-1003	P98-2127	2006	Expanding the sum in the right-hand side of equation 14, plugging in the expression for parentchild distance from equation 13, and performing necessary eliminations results in the following final formula for the semantic distance between concepts c 1 and c 2 : dist JC c 1 , c 2   ICc 1   ICc 2   2  IClsoc 1 , c 2  15  2logplsoc 1 , c 2  log pc 1   log pc 2  16 263 Lins Universal Similarity Measure	0	Noticing that all of the similarity measures known to him were tied to a particular application, domain, or resource, <TREF>Lin 1998b</TREF> attempted to define a measure of similarity that would be both universal applicable to arbitrary objects and not presuming any form of knowledge representation and theoretically justified derived from a set of assumptions, instead of directly by a formula, so that if the assumptions are deemed reasonable, the similarity measure necessarily follows	1	He used the following three intuitions as a basis: 1	0	The similarity between arbitrary objects A and B is related to their commonality; the more commonality they share, the more similar they are	0	6	1
J06-1003	P98-2127	2006	22 Words that are distributionally similar do indeed often represent semantically related concepts, and vice versa, as the following examples demonstrate	0	<REF>Weeds 2003</REF>, in her study of 15 distributional-similarity measures, found that words distributionally similar to hope noun included confidence, dream, feeling, and desire; <TREF>Lin 1998b</TREF> found pairs such as earningsprofit, biggestlargest, nylonsilk, and pilltablet	1	It is intuitively clear why these results occur: if two concepts are similar or related, it is likely that their role in the world will be similar, so similar things will be said about them, and so the contexts of occurrence of the corresponding words will be similar	0	And conversely albeit with less certainty, if the contexts of occurrence of two words are similar, then similar things are being said about each, so they are playing similar roles in the world and hence are semantically similar  at least to the extent of these roles	0	6	1
J06-1003	P98-2127	2006	Imbalance in the corpus and data sparseness is an additional source of anomalous results even for good measures	0	For example, <TREF>Lin 1998b</TREF> found peculiar similarities that were reasonable for his corpus of news articles, such as captivewesterner because in the news articles, more than half of the westerners mentioned were being held captive and auditionrite because both were infrequent and were modified by uninhibited	1	We now turn to the hypothesis that distributional similarity can usefully stand in for semantic relatedness in NLP applications such as malapropism detection	0	<REF>Weeds 2003</REF> considered the hypothesis in detail	0	6	1
J06-1003	P98-2127	2006	For example, Weeds 2003; <REF>Weeds and Weir, 2005</REF> see below took verbs as contexts for nouns in object position: so they regarded two nouns to be similar to the extent that they occur as direct objects of the same set of verbs	0	Lin 1998b, 1998a considered other syntactic relationships as well, such as subjectverb and modifier noun, and looked at both roles in the relationship	1	Given this framework, many different methods of measuring distributional similarity have been proposed; see <REF>Dagan 2000</REF>, <REF>Weeds 2003</REF>, or <REF>Mohammad and Hirst 2005</REF> for a review	0	For example, the set of words that co-occur with w 1 and those that co-occur with w 2 may be regarded as a feature vector of each and their similarity measured as the cosine between the vectors; or a measure may be based on the KullbackLeibler divergence between the probability distributions Pww 1 andPww 2 , as, for example, <REF>Lees 1999</REF> -skew divergence	0	6	1
J06-1003	P98-2127	2006	For example, the set of words that co-occur with w 1 and those that co-occur with w 2 may be regarded as a feature vector of each and their similarity measured as the cosine between the vectors; or a measure may be based on the KullbackLeibler divergence between the probability distributions Pww 1 andPww 2 , as, for example, <REF>Lees 1999</REF> -skew divergence	0	<TREF>Lin 1998b</TREF> uses his similarity theorem equation 19 above to derive a measure based on the degree of overlap of the sets of words with which w 1 and w 2 , respectively, have positive mutual information	1	22 Words that are distributionally similar do indeed often represent semantically related concepts, and vice versa, as the following examples demonstrate	0	<REF>Weeds 2003</REF>, in her study of 15 distributional-similarity measures, found that words distributionally similar to hope noun included confidence, dream, feeling, and desire; <TREF>Lin 1998b</TREF> found pairs such as earningsprofit, biggestlargest, nylonsilk, and pilltablet	0	6	1
J06-1003	P98-2127	2006	Three kinds of approaches are prevalent in the literature	0	The first kind <REF>Wei 1993</REF>; <TREF>Lin 1998b</TREF> is a chiefly theoretical examination of a proposed measure for those mathematical properties thought desirable, such as whether it is a metric or the inverse of a metric, whether it has singularities, whether its parameter-projections are smooth functions, and so on	0	In our opinion, such analyses act at best as a coarse filter in the comparison of a set of measures and an even coarser one in the assessment of a single measure	1	The second kind of evaluation is comparison with human judgments	0	1	3
J06-1003	P98-2127	2006	Notice that because dist JC measures distance, the JiangConrath plot has a slope opposite to the rest of each group	0	9 <REF>Resnik 1995</REF>, <REF>Jiang and Conrath 1997</REF>, and <TREF>Lin 1998b</TREF> report the coefficients of correlation between their measures and the MillerCharles ratings to be 07911, 08282, and 08339, respectively, which differ slightly from the corresponding figures in Table 3	1	These discrepancies can be explained by possible minor differences in implementation eg, the compound-word recognition mechanism used in collecting the frequency data, differences between the versions of WordNet used in the experiments Resnik, and differences in the corpora used to obtain the frequency data Jiang and Conrath, Lin	0	Also, the coefficients reported by Resnik and Lin are actually based on only 28 out of the 30 MillerCharles pairs because of a noun missing from an earlier version of WordNet	0	6	1
N03-4011	P98-2127	2003	The Distributional Hypothesis <REF>Harris 1985</REF> states that words that occur in the same contexts tend to be similar	0	There have been many approaches to compute the similarity between words based on their distribution in a corpus <REF>Hindle 1990</REF>; <REF>Landauer and Dumais 1997</REF>; <TREF>Lin 1998</TREF>	1	The output of these programs is a ranked list of similar words to each word	0	For example, Lins approach outputs the following similar words for wine and suit: wine: beer, white wine, red wine, Chardonnay, champagne, fruit, food, coffee, juice, Cabernet, cognac, vinegar, Pinot noir, milk, vodka, suit: lawsuit, jacket, shirt, pant, dress, case, sweater, coat, trouser, claim, business suit, blouse, skirt, litigation,  The similar words of wine represent the meaning of wine	0	6	1
N03-4011	P98-2127	2003	Each cluster corresponds to a sense of the headword	0	2 Feature Representation Following <TREF>Lin 1998</TREF>, we represent each word by a feature vector	1	Each feature corresponds to a context in which the word occurs	0	For example, sip  is a verbobject context	0	3	2
P08-1018	P98-2127	2008	All words in the vocabulary sharing the same root form are grouped together	0	Then we do corpus analysis to filter out the words which are clustered incorrectly, according to word distributional similarity, following <REF>Xu and Croft, 1998</REF>; <TREF>Lin 1998</TREF>	1	The rationale behind this is that words sharing the same meaning tend to occur in the same contexts	0	The context of each word in the vocabulary is represented by a vector containing the frequencies of the context words which co-occur with the word within a predefined window in a training corpus	0	3	2
P06-1113	P98-2127	2006	<REF>Tanev et al , 2004</REF> used an algorithm for partial matching of syntactic structures	0	For lexical variations they used a dependency based thesaurus of similar words <TREF>Lin, 1998</TREF>	1	Hang et al	0	<REF>Cui et al , 2004</REF> used an algorithm to compute the similarity between dependency relation paths from a parse tree to rank the candidate answers	0	6	1
P08-1078	P98-2127	2008	Thus, correct match of an argument corresponds to correct role identification	0	The templates were represented as Minipar <TREF>Lin, 1998b</TREF> dependency parse-trees	1	The Contextual Preferences for h were constructed manually: the named-entity types for cpv:nh were set by adapting the entity types given in the guidelines to the types supported by the Lingpipe NER described in Section 32	0	cpgh was generated from a short list of nouns and verbs that were extracted from the verbal event definition in the ACE guidelines	0	3	2
P08-1078	P98-2127	2008	As a more natural ranking method, we also utilize SCBC directly, denoted rankedCBC, having mv:er,t  SCBCr,t	0	In addition, we tried a simpler method that directly compares the terms in two cpv:e lists, utilizing the commonly-used term similarity metric of <TREF>Lin, 1998a</TREF>	1	This method, denoted LIN, uses the same raw distributional data as CBC but computes only pair-wise similarities, without any clustering phase	0	We calculated the scores of the 1000 most similar terms for every term in the Reuters RVC1 corpus3	0	3	2
D08-1094	P98-2127	2008	A comparison of the upper half BOW with the lower half SYN shows that the dependency-based space generally shows better correlation with human judgements	0	This corresponds to a beneficial effect of syntactic information found for other applications of semantic spaces <TREF>Lin, 1998</TREF>; <REF>Pado and Lapata, 2007</REF>	1	All instances of the SELPREF model show highly significant correlations	0	SELPREF and SELPREF-CUT show very similar performance	0	6	1
W04-1216	P98-2127	2004	3 Distributional Word Similarity Words that tend to appear in the same contexts tend to have similar meanings <REF>Harris 1968</REF>	0	For example, the words corruption and abuse are similar because both of them can be subjects of verbs like arouse, become, betray, cause, continue, cost, exist, force, go on, grow, have, increase, lead to, and persist, etc, and both of them can modify nouns like accusation, act, allegation, appearance, and case, etc Many methods have been proposed to compute distributional similarity between words, eg, <REF>Hindle, 1990</REF>, <REF>Pereira et al 1993</REF>, <REF>Grefenstette 1994</REF> and <TREF>Lin 1998</TREF>	1	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared	0	84 31 Proximity-based Similarity It is natural to use dependency relationship Meluk, 1987 as features, but a parser has to be available	0	6	1
D07-1026	P98-2127	2007	First of all, it allows us to provide both positive and negative examples, avoiding the use of one-class classification algorithms that in practice perform poorly <REF>Dagan et al , 2006</REF>	0	Second, the large availability of manually constructed substitution lexica, such as WordNet <REF>Fellbaum, 1998</REF>, or the use of repositories based on statistical word similarities, such as the database constructed by <TREF>Lin 1998</TREF>, allows us to find an adequate substitution lexicon for each target word in most of the cases	1	For example, as shown in Table 1, the word job has different senses depending on its context, some of them entailing its direct hyponym position eg , looking for permanent job, others entailing the word task eg , the job of repairing	0	The problem of deciding whether a particular instance of job can be replaced by position, and not by the word place, can be solved by looking for the most similar contexts where either position or place occur in the training data, and then selecting the class ie , the entailed word characterized by the most similar ones, in an instance based style	0	3	2
D07-1026	P98-2127	2007	<REF>Cimiano and Volker 2005</REF> assign a particular entity to the fine-grained class suchthatthecontextualsimilarityismaximalamong the set of fine-grained subclasses of a coarse-grained category	0	Contextual similarity has been measured by adopting lexico-syntactic features provided by a dependency parser, as proposed in <TREF>Lin, 1998</TREF>	1	3 Instance Based Lexical Entailment Dagan et al	0	2006 adapted the classical supervised WSD setting to approach the sense matching problem ie , the binary lexical entailment problem of deciding whether a word, such as position, entails a different word, such as job, in a given context by defining a one-class learning algorithm based on support vector machines SVM	0	3	2
D07-1026	P98-2127	2007	It is worthwhile to remark that, due to the ambiguity of the entailed words eg , position could also entail either perspective or place, not every occurrence of them should be taken into account, in order to avoid misleading predictions caused by the irrelevant senses	0	Therefore, approaches based on a more classical contextual similarity technique <TREF>Lin, 1998</TREF>; <REF>Dagan, 2000</REF>, where words are described globally by context vectors, are doomed to fail	1	We will provide empirical evidence of this in the evaluation section	0	Choosing an appropriate similarity function for the contexts of the words to be substituted is a primary issue	0	1	3
J05-4002	P98-2127	2005	Hence, neighbor sets derived using sim hind are identical to those obtained using recall  0,  0 in the difference-weighted MI-based CRM	0	46 Lins <REF>Measure Lin 1998a</REF> proposed a measure of lexical distributional similarity based on his information-theoretic similarity theorem <REF>Lin 1997, 1998b</REF>: The similarity between A and B is measured by the ratio between the amount of information needed to state the commonality of A and B and the information needed to fully describe what A and B are	1	459 Computational Linguistics Volume 31, Number 4 If the features of a word are grammatical relation contexts, the similarity between two words w 1 and w 2 can be written according to Lins measure as: sim lin w 1, w 2   summationtext Tw 1 Tw 2  Iw 1, c  Iw 2, c summationtext Tw 1  Iw 1, c  summationtext Tw 2  Iw 2, c 41 where Tw c : Iw, c > 0	0	There are parallels between sim lin and sim dice in that both measures compute a ratio between what is shared by the descriptions of both nouns and the sum of the descriptions of each noun	0	6	1
J05-4002	P98-2127	2005	There are a number of ways to measure the distance between two nouns in the WordNet noun hierarchy see Budanitsky 1999 for a review	0	In previous work <REF>Weeds and Weir 2003b</REF>, we used the WordNet-based similarity measure first proposed in <REF>Lin 1997</REF> and used in <TREF>Lin 1998a</TREF>: wn sim lin w 1, w 2   max c 1 Sw 1 c 2 Sw 2  parenleftbigg max csupc 1 supc 2  2logPc log Pc 1   log Pc 2  parenrightbigg 49 where Sw is the set of senses of the word w in WordNet, supc is the set of possibly indirect super-classes of concept c in WordNet, and Pc is the probability that a randomly selected word refers to an instance of concept c estimated over some corpus such as SemCor <REF>Miller et al 1994</REF>	1	However, in other research <REF>Budanitsky and Hirst 2001</REF>; <REF>Patwardhan, Banerjee, and Pedersen 2003</REF>; <REF>McCarthy, Koeling, and Weeds 2004</REF>, it has been shown that the distance measure of <REF>Jiang and Conrath 1997</REF> referred to herein as the JC measure is a superior WordNet-based semantic similarity measure: wn dist JC w 1, w 2   max c 1 Sw 1 c 2 Sw 2  parenleftbigg max csupc 1 supc 2  2logc  log Pc 1   log Pc 2  parenrightbigg 50 In our work, we make an empirical comparison of neighbors derived using a WordNet-based measure and each of the distributional similarity measures using the technique discussed in Section 3	0	We have carried out the same experiments using both the Lin measure and the JC measure	0	3	2
J05-4002	P98-2127	2005	The underlying idea is based largely on the central claim of the distributional hypothesis <REF>Harris 1968</REF>, that is: The meaning of entities, and the meaning of grammatical relations among them, is related to the restriction of combinations of these entities relative to other entities	0	This hypothesized relationship between distributional similarity and semantic similarity has given rise to a large body of work on automatic thesaurus generation <REF>Hindle 1990</REF>; <REF>Grefenstette 1994</REF>; <TREF>Lin 1998a</TREF>; <REF>Curran and Moens 2002</REF>; <REF>Kilgarriff 2003</REF>	1	There are inherent problems in evaluating automatic thesaurus extraction techniques, and much research assumes a gold standard that does not exist see Kilgarriff 2003 and Weeds 2003 for more discussion of this	0	A further problem for distributional similarity methods for automatic thesaurus generation is that they do not offer any obvious way to distinguish between linguistic relations such as synonymy, antonymy, and hyponymy see Caraballo 1999 and Lin et al 2003 for work on this	0	6	1
J05-4002	P98-2127	2005	45 Hindles <REF>Measure Hindle 1990</REF> proposed an MI-based measure, which he used to show that nouns could be reliably clustered based on their verb co-occurrences	0	We consider the variant of 458 Weeds and Weir Co-occurrence Retrieval Figure 1 Variation with parameters  and  in development set mean similarity between neighbor sets of the additive t-test based CRM and of dist   Hindles Measure proposed by <TREF>Lin 1998a</TREF>, which overcomes the problem associated with calculating MI for word-feature combinations that do not occur: sim hind w 1, w 2   summationdisplay Tw 1 Tw 2  minIc, w 1 , Ic, w 2  38 where Tw 1  c : Ic, n > 0	1	This expression is the same as the numerator in the expressions for precision and recall in the difference-weighted MI-based CRM: P dw mi w 1, w 2   summationtext TP Iw 1, c  minIw 1, c,Iw 2, c Iw 1, c summationtext Fw 1  Iw 1, c  summationtext TP minIw 1, c, Iw 2, c summationtext Fw 1  Iw 1, c 39 R dw mi w 1, w 2   summationtext TP Iw 2, c  minIw 2, c,Iw 1, c Iw 2, c summationtext Fw 2  Iw 2, c  summationtext TP minIw 2, c, Iw 1, c summationtext Fw 2  Iw 2, c 40 since TP  Tw 1   Tw 2 	0	However, we also note that the denominator in the expression for recall depends only on w 2, and therefore, for a given w 2, is a constant	0	3	2
J05-4002	P98-2127	2005	Further, the noun hyponymy hierarchy in WordNet, which will be used as a pseudo-gold standard for comparison, is widely recognized in this area of research	0	Some previous work on distributional similarity between nouns has used only a single grammatical relation eg , <REF>Lee 1999</REF>, whereas other work has considered multiple grammatical relations eg , <TREF>Lin 1998a</TREF>	1	We consider only a single grammatical relation because we believe that it is important to evaluate the usefulness of each grammatical relation in calculating similarity before deciding how to combine information from 5 This results in a single 80:20 split of the complete data set, in which we are guaranteed that the original relative frequencies of the target nouns are maintained	0	6 The use of grammatical relations to model context precludes finding similarities between words of different parts of speech	0	3	2
J02-2001	P98-2127	2002	Second, as we noted in Section 22, standard dictionary definitions are not usually fine-grained enough they define the core meaning but not all the nuances of a word and can even be circular, defining each of several nearsynonyms in terms of the other near-synonyms	0	And third, although corpus-based methods eg , Lins 1998 do compute different similarity values for different pairs of near-synonyms of the same cluster, Church et al	0	1994 and <REF>Edmonds 1997</REF> show that such methods are not yet capable of uncovering the more subtle differences in the use of near-synonyms for lexical choice	1	But one benefit of the clustered model of lexical knowledge is that it naturally lends itself to the computation of explicit differences or degrees of similarity between near-synonyms	0	1	3
J02-2001	P98-2127	2002	Recent research in computational linguistics has focused more on developing methods to compute the degree of semantic similarity between any two words, or, more precisely, between the simple or primitive concepts 15 denoted by any two words	0	There are many different similarity measures, which variously use taxonomic lexical hierarchies or lexical-semantic networks, large text corpora, word definitions in machine-readable dictionaries or other semantic formalisms, or a combination of these <REF>Dagan, Marcus, and Markovitch 1993</REF>; <REF>Kozima and Furugori 1993</REF>; <REF>Pereira, Tishby, and Lee 1993</REF>; <REF>Church et al 1994</REF>; <REF>Grefenstette 1994</REF>; <REF>Resnik 1995</REF>; <REF>McMahon and Smith 1996</REF>; <REF>Jiang and Conrath 1997</REF>; Sch utze 1998; <TREF>Lin 1998</TREF>; <REF>Resnik and Diab 2000</REF>; <REF>Budanitsky 1999</REF>; <REF>Budanitsky and Hirst 2001, 2002</REF>	0	Unfortunately, these methods are generally unhelpful in computing the similarity of near-synonyms because the measures lack the required precision	1	First, taxonomic hierarchies and semantic networks inherently treat near-synonyms as absolute synonyms in grouping near-synonyms into single nodes eg , in WordNet	0	1	3
W03-1812	P98-2127	2003	This is calculated over a corpus of text	0	<TREF>Lin 1998c</TREF> also employs the idea of corpusderived information content, and defines the similarity between two concepts in the following way: simC1; C2  2 log PC0log PC 1  log PC2 1 where C0 is the lowest class in the hierarchy that subsumes both classes	1	2http://wwwdumnedu/tpederse/ distancehtml Hirst and St-<REF>Onge 1998</REF> use a system of relations of different strength to determine the similarity of word senses, conditioned on the type, direction and relative distance of edges separating them	0	The Patwardhan et al	0	6	1
W03-1812	P98-2127	2003	One interesting exception is <REF>Lin 1999</REF>, whose approach is explained as follows: The intuitive idea behind the method is that the metaphorical usage of a noncompositional expression causes it to have a different distributional characteristic than expressions that are similar to its literal meaning	0	The expressions he uses are taken from a collocation database <TREF>Lin, 1998b</TREF>	1	These expressions that are similar to their literal meaning are found by substituting each of the words in the expression with the 10 most similar words according to a corpus derived thesaurus <TREF>Lin, 1998a</TREF>	0	Lin models the distributional difference as a significant difference in mutual information	0	6	1
W03-1812	P98-2127	2003	The expressions he uses are taken from a collocation database <TREF>Lin, 1998b</TREF>	0	These expressions that are similar to their literal meaning are found by substituting each of the words in the expression with the 10 most similar words according to a corpus derived thesaurus <TREF>Lin, 1998a</TREF>	1	Lin models the distributional difference as a significant difference in mutual information	0	Significance here is defined as the absence of overlap between the 95 confidence interval of the mutual information scores	0	6	1
N04-1041	P98-2127	2004	2 Previous Work There have been several approaches to automatically discovering lexico-semantic information from text <REF>Hearst 1992</REF>; <REF>Riloff and Shepherd 1997</REF>; <REF>Riloff and Jones 1999</REF>; <REF>Berland and Charniak 1999</REF>; <REF>Pantel and Lin 2002</REF>; <REF>Fleischman et al 2003</REF>; <REF>Girju et al 2003</REF>	0	One approach constructs automatic thesauri by computing the similarity between words based on their distribution in a corpus <REF>Hindle 1990</REF>; <TREF>Lin 1998</TREF>	1	The output of these programs is a ranked list of similar words to each word	0	For example, Lins approach outputs the following top-20 similar words of orange: D peach, grapefruit, yellow, lemon, pink, avocado, tangerine, banana, purple, Santa Ana, strawberry, tomato, red, pineapple, pear, Apricot, apple, green, citrus, mango A common problem of such lists is that they do not discriminate between the senses of polysemous words	0	6	1
P06-1129	P99-1004	2006	Distributional similarity between words has been investigated and successfully applied in many natural language tasks such as automatic semantic knowledge acquisition <REF>Dekang Lin, 1998</REF> and language model smoothing <REF>Essen and Steinbiss, 1992</REF>; <REF>Dagan et al , 1997</REF>	0	An investigation on distributional similarity functions can be found in <TREF>Lillian Lee, 1999</TREF>	1	3 Distributional Similarity-Based Models for Query Spelling Correction 31 Motivation Most of the previous work on spelling correction concentrates on the problem of designing better error models based on properties of character strings	0	This direction ever evolves from simple Damerau-Levenshtein distance <REF>Damerau, 1964</REF>; <REF>Levenshtein, 1966</REF> to probabilistic models that estimate string edit probabilities from corpus <REF>Church and Gale, 1991</REF>; <REF>Mayes et al, 1991</REF>; <REF>Ristad and Yianilos, 1997</REF>; <REF>Brill and Moore, 2000</REF>; and <REF>Ahmad and Kondrak, 2005</REF>	0	6	1
C02-1162	P99-1004	2002	The calculation of word semantic similarity scores is also a problem that has attracted a lot of interest	0	The numerous notable approaches can usually be divided into those which utilize the hierarchical information from an ontology, such as <REF>Resnik 1995</REF> and <REF>Agirre and Martinez 2002</REF>; and those which simply use word distribution information from a large corpus, such as <REF>Lin 1998</REF> and <TREF>Lee 1999</TREF>	1	9 Conclusion This paper represents a first step towards a corpusbased approach for cross-lingual identification of word concepts and alignment of ontologies	0	The method borrows from techniques used in machine translation and information retrieval, and does not make any assumptions about the structure of the ontology, or use any but the most basic structural information	0	6	1
P01-1049	P99-1004	2001	A number of simple linguistic techniques has been developed to alleviate such problems, ranging from the use of stemming, lexical chain and thesaurus <REF>Jing  Tzoukermann, 1999</REF></REF>; <REF>Green, 1999</REF>, to word-sense disambiguation <REF>Chen  Chang, 1998</REF>; <REF>Leacock et al, 1998</REF>; <REF>Ide  Veronis, 1998</REF> and context <REF>Cohen  Singer, 1999</REF>; <REF>Jing  Tzoukermann, 1999</REF></REF>	0	The connectionist approach has been widely used to extract knowledge in a wide range of information processing tasks including natural language processing, information retrieval and image understanding <REF>Anderson, 1983</REF>; <REF>Lee  Dubin, 1999</REF>; <REF>Sarkas  Boyer, 1995</REF>; <REF>Wang  Terman, 1995</REF>	1	Because the connectionist approach closely resembling human cognition process in text processing, it seems natural to adopt this approach, in conjunction with linguistic analysis, to perform topic spotting	0	However, there have been few attempts in this direction	0	6	1
P08-1003	P99-1004	2008	33 Evaluation of Class Attributes Extraction Parameters: Given a target class specified as a set of instances and a set of five seed attributes for a class eg, quality, speed, number of users, market share, reliability for SearchEngine, the method described in Section 22 extracts ranked lists of class attributes from the input query logs	0	Internally, the ranking uses Jensen-Shannon <TREF>Lee, 1999</TREF> to compute similarity scores between internal representations of seed attributes, on one hand, and each of the candidate attributes, on the other hand	1	Evaluation Procedure: To remove any possible bias towards higher-ranked attributes during the assessment of class attributes, the ranked lists of attributes to be evaluated are sorted alphabetically into a merged list	0	Each attribute of the merged list is  0  02  04  06  08  1  0  10  20  30  40  50 Precision Rank Class: Holiday manually assembled instances automatically extracted instances  0  02  04  06  08  1  0  10  20  30  40  50 Precision Rank Class: Average-Class manually assembled instances automatically extracted instances  0  02  04  06  08  1  0  10  20  30  40  50 Precision Rank Class: Mountain manually assembled instances automatically extracted instances  0  02  04  06  08  1  0  10  20  30  40  50 Precision Rank Class: Average-Class manually assembled instances automatically extracted instances Figure 3: Accuracy of attributes extracted based on manually assembled, gold standard M vs automatically extracted E instance sets, for a few target classes leftmost graphs and as an average over all 37 target classes rightmost graphs	0	3	2
C08-1051	P99-1004	2008	The first and second row shows the number of distinct words and word pairs used for the distributional and pattern-based word clustering respectively	0	Three K-means algorithms using different distributional similarity or dissimilarity measures: cosine, -skew divergence <TREF>Lee, 1999</TREF> 4 , and Lins similarity <REF>Lin, 1998</REF>	1	The CBC algorithm <REF>Lin and Pantel, 2002</REF>; <REF>Pantel and Lin, 2002</REF>	0	53 Evaluation procedure All the nouns in the data set were clustered by the proposed and baseline systems	0	6	1
C08-1051	P99-1004	2008	et al, 1999; <REF>Torisawa, 2002</REF>	0	Others proposed distributional similarity measures between words <REF>Hindle, 1990</REF>; <REF>Lin, 1998</REF>; <TREF>Lee, 1999</TREF>; <REF>Weeds et al, 2004</REF>	1	Once such similarity is defined, it is trivial to perform clustering	0	On the other hand, some researchers utilized co-occurrence for word clustering	0	6	1
C08-1029	P99-1004	2008	Moreover, it may not work well for dealing with general predicate phrases because it is hard to enumerate all phrases to determine the weights of features w,fWe thus simply adopted the co-occurrence frequency of the phrase and the feature as in <REF>Fujita and Sato, 2008</REF>	0	Skew divergence The skew divergence, a variant of KL divergence, was proposed in <TREF>Lee, 1999</TREF> based on an insight: the substitutability of one word for another need not be symmetrical	1	The divergence is given by the following formula: d skew t,sD P s bardblP t 1 P s , where P s and P t are the probability distributions of features for the given original and substituted words s and t, respectively	0	0    1 is a parameter for approximating KL divergence DThe score can be recast into a similarity score via, for example, the following function <REF>Fujita and Sato, 2008</REF>: Par skew stexpd skew t,s	0	6	1
J02-3004	P99-1004	2002	We preferred taxonomic class-based methods over distributional clustering mainly because we wanted to compare directly methods that use distributional information inherent in the corpus without making external assumptions with regard to how concepts and their similarity are represented with methods that quantify similarity relationships based on information present in a hand-crafted taxonomy	0	Furthermore, as <REF>Lee and Pereiras 1999</REF> results indicate that distributional clustering 365 Lapata The Disambiguation of Nominalizations and distance-weighted averaging obtain similar levels of performance, we restricted ourselves to the latter	1	We evaluated the contribution of the different smoothing methods on the nominalization task by exploring how each method and their combination influences disambiguation performance	0	Sections 3133 review discounting, class-based smoothing, and distance-weighted averaging	0	2	1
J02-3004	P99-1004	2002	The problem arises when the probability of word combinations that do not occur in the training data needs to be estimated	0	The smoothing methods proposed in the literature overviews are provided by <REF>Dagan, Lee, and Pereira 1999</REF> and <TREF>Lee 1999</TREF> can be generally divided into three types: discounting <REF>Katz 1987</REF>, class-based smoothing <REF>Resnik 1993</REF>; <REF>Brown et al 1992</REF>; 364 Computational Linguistics Volume 28, Number 3 <REF>Pereira, Tishby, and Lee 1993</REF>, and distance-weighted averaging <REF>Grishman and Sterling 1994</REF>; <REF>Dagan, Lee, and Pereira 1999</REF>	1	Discounting methods decrease the probability of previously seen events so that the total probability of observed word co-occurrences is less than one, leaving some probability mass to be redistributed among unseen co-occurrences	0	Class-based smoothing and distance-weighted averaging both rely on an intuitively simple idea: interword dependencies are modeled by relying on the corpus evidence available for words that are similar to the words of interest	0	6	1
J02-3004	P99-1004	2002	Furthermore, some nominalizations are conventionalized eg , business administration, health organization and are therefore attested more frequently than their verb-subject or verb-object counterparts	0	We re-created the frequencies of unseen verb-argument pairs by experimenting with three types of smoothing techniques proposed in the literature: back-off smoothing <REF>Katz 1987</REF>, class-based smoothing <REF>Resnik 1993</REF>; <REF>Lauer 1995</REF>, and distanceweighted averaging <REF>Grishman and Sterling 1994</REF>; <REF>Dagan, Lee, and Pereira 1999</REF>	1	We present these three smoothing variants and their underlying assumptions in the following section	0	3	0	3	1
J02-3004	P99-1004	2002	A key feature of this type of smoothing is the function that measures distributional similarity from co-occurrence frequencies	0	Several measures of distributional similarity have been proposed in the literature <REF>Dagan, Lee, and Pereira 1999</REF>; <TREF>Lee 1999</TREF>	1	We used two measures, the Jensen-Shannon divergence and the confusion probability	0	The choice of these two measures was motivated by work described in <REF>Dagan, Lee, and Pereira 1999</REF>, in which the JensenShannon divergence outperforms related similarity measures such as the confusion probability or the L 1 norm on a pseudodisambiguation task that uses verb-object pairs	0	6	1
J02-3004	P99-1004	2002	<REF>Grishman and Sterling 1994</REF> in particular employ the confusion probability to re-create the frequencies of verb-noun co-occurrences in which the noun is the object or the subject of the verb in question	0	In the following we describe these two similarity measures and show how they can be used to re-create the frequencies for unseen verb-argument tuples for a more detailed description see <REF>Dagan, Lee, and Pereira 1999</REF>	1	331 Confusion Probability	0	The confusion probability P C is an estimate of the probability that a word w 1 can be substituted for a word w prime 1, in the sense of being found in the same contexts	0	6	1
J02-3004	P99-1004	2002	In class-based smoothing, classes are used as the basis according to which the co-occurrence probability of unseen word combinations is estimated	0	Classes can be induced directly from the corpus using distributional clustering <REF>Pereira, Tishby, and Lee 1993</REF>; <REF>Brown et al 1992</REF>; <REF>Lee and Pereira 1999</REF> or taken from a manually crafted taxonomy <REF>Resnik 1993</REF>	1	In the latter case the taxonomy is used to provide a mapping from words to conceptual classes	0	Distance-weighted averaging differs from distributional clustering in that it does not explicitly cluster words	0	3	2
J02-3004	P99-1004	2002	33 Distance-Weighted Averaging Distance-weighted averaging induces classes of similar words from word co-occurrences without making reference to a taxonomy	0	Instead, it is based on the assumption that if a word w prime 1 is similar to word w 1, then w prime 1 can provide information about the frequency of unseen word pairs involving w 1 <REF>Dagan, Lee, and Pereira 1999</REF>	0	A key feature of this type of smoothing is the function that measures distributional similarity from co-occurrence frequencies	0	Several measures of distributional similarity have been proposed in the literature <REF>Dagan, Lee, and Pereira 1999</REF>; <TREF>Lee 1999</TREF>	1	6	1
J02-3004	P99-1004	2002	In language modeling, smoothing techniques are typically evaluated by showing that a language model that uses smoothed estimates incurs a reduction in perplexity on test data over a model that does not employ smoothed estimates <REF>Katz 1987</REF>	0	<REF>Dagan, Lee, and Pereira 1999</REF> use perplexity to compare back-off smoothing against distance-weighted averaging methods within the context of language modeling for speech recognition and show that the latter outperform the former	1	They also compare different distance-weighted averaging methods on a pseudoword disambiguation task in which the language model decides which of two verbs v 1 and v 2 is more likely to take a noun n as its object	0	The method being tested must reconstruct which of the unseen v 1, n and v 2, n is a valid verb-object combination	0	6	1
J02-3004	P99-1004	2002	The method being tested must reconstruct which of the unseen v 1, n and v 2, n is a valid verb-object combination	0	The same task is used by <REF>Lee and Pereira 1999</REF> in a detailed comparison between distributional clustering and distance-weighted averaging that demonstrates that the two methods yield comparable results	1	In our experiments we re-created co-occurrence frequencies for unseen verb-subject and verb-object pairs using three maximally different approaches: back-off smoothing, class-based smoothing using a predefined taxonomy, and distance-weighted averaging	0	We preferred taxonomic class-based methods over distributional clustering mainly because we wanted to compare directly methods that use distributional information inherent in the corpus without making external assumptions with regard to how concepts and their similarity are represented with methods that quantify similarity relationships based on information present in a hand-crafted taxonomy	0	6	1
J02-3004	P99-1004	2002	We used two measures, the Jensen-Shannon divergence and the confusion probability	0	The choice of these two measures was motivated by work described in <REF>Dagan, Lee, and Pereira 1999</REF>, in which the JensenShannon divergence outperforms related similarity measures such as the confusion probability or the L 1 norm on a pseudodisambiguation task that uses verb-object pairs	1	The confusion probability has been used by several authors to smooth word co367 Lapata The Disambiguation of Nominalizations occurrence probabilities <REF>Essen and Steinbiss 1992</REF>; <REF>Grishman and Sterling 1994</REF> and shown to give promising performance	0	<REF>Grishman and Sterling 1994</REF> in particular employ the confusion probability to re-create the frequencies of verb-noun co-occurrences in which the noun is the object or the subject of the verb in question	0	5	2
W04-2411	P99-1004	2004	McCarthy determines the sense profile of a verb/slot pair using a minimum description length tree cut model over the frequency-populated hierarchy <REF>Li and Abe, 1998</REF>	0	The two profiles for a verb are aligned to permit comparison using skew divergence as a probability distance measure <TREF>Lee 1999</TREF>	1	This step is explained in more detail in the next section, with an example	0	The value of the distance measure is compared to a threshold, which determines classification of a verb as causative the two profiles are similar or non-causative the two profiles are dissimilar, leading to best performance of 73 accuracy, on a set of hand-selected verbs	0	6	1
W04-2411	P99-1004	2004	<REF>Briefly, Clark and Weir 2002</REF> populate the WordNet hierarchy based on corpus frequencies of all nouns for a verb/slot pair, and then determine the appropriate probability estimate at each node in the hierarchy by using a24 a102 to determine whether to generalize an estimate to a parent node in the hierarchy	0	We compare SPD to other measures applied directly to the unpropagated probability profiles given by the Clark-Weir method: the probability distribution distance given by skew divergence skew <TREF>Lee, 1999</TREF>, as well as the general vector distance given by cosine cos	1	These are the measures aside from SPD that performed best in our pilot experiments	1	It is worth noting that the method of <REF>Clark and Weir 2002</REF> does not yield a tree cut, but instead generally populates the WordNet hierarchy with non-zero probabilities	0	2	2
W04-2411	P99-1004	2004	A drawback of this approach for generalizing to other sense profile comparisons is the assumption in relative entropy of an asymmetry between the two probability distributions	0	<REF>Similarly, McCarthy 2000</REF> uses skew divergence a variant of KL divergence proposed by <TREF>Lee, 1999</TREF> to compare the sense profile of one argument of a verb eg , the subject position of the intransitive to another argument of the same verb eg , the object position of the transitive, to determine if the verb participates in an argument alternation involving the two positions	1	For example, the causative alternation in sentences 1 and 2 illustrates how the subject of the intransitive is the same underlying semantic argument ie , the Themethe argument undergoing the action as the object of the transitive: 1 The snow melted	0	2 The sun melted the snow	0	6	1
W06-0101	P99-1004	2006	Due to the original KL distance is asymmetric and is not defined when zero frequency occurs	0	Some enhanced KL models were developed to prevent these problems such as Jensen-Shannon <REF>Jianhua, 1991</REF>, which introducing a probabilistic variable m, or  -Skew Divergence <TREF>Lee, 1999</TREF>, by adopting adjustable variable 	1	Research shows that Skew Divergence achieves better performance than other measures	1	<REF>Lee, 2001</REF> 1yxS rgenceDSkewDive yxxKL aaa  2/,2/yx,JS Shannon-DJensen yxm myKLmxKL   To convert distance to similarity value, we adopt the formula inspired by <REF>Mochihashi, and Matsumoto 2002</REF>	0	4	2
A00-2034	P99-1004	2000	Figure 2 exemplifies this process for two TOMs TCM1 and TCM2 in an imaginary hierarchy	0	The UBC is at the classes B, c and D To quantify the similarity between the probability distributions for the target slots we use the a-skew divergence aSD proposed by <TREF>Lee 1999</TREF>	1	1 This measure, defined in equation 2, is a smoothed version of the Kulback-Liebler divergence, plx and p2x are the two probability distributions which are being compared	0	The  constant is a value between 0 and 1 We also experimented with euclidian distance, the L1 norm, and cosine measures	0	3	2
W07-2009	P99-1004	2007	synonyms from the hypernyms verbs and nouns or closely related classes adjectives of all synsets of the target, ranked with the BNC frequency data	0	We also produced best and oot baselines using the distributional similarity measures l1, jaccard, cosine, lin <REF>Lin, 1998</REF> and SD <TREF>Lee, 1999</TREF> 4	1	We took the word with the largest similarity or smallest distance for SD and l1 for best and the top 10 for oot	0	For mw detection and identification we used WordNet to detect if a multiword in WordNet which includes the target word occurs within a window of 2 words before and 2 words after the target word	0	3	1
D07-1042	P99-1004	2007	All counts are log-likelihood transformed	0	We experiment with two distance measures to compute vector similarity, namely the Jaccard Coefficient and Cosine Distance, both of which have been shown to yield good performance in NLP tasks <TREF>Lee, 1999</TREF>; <REF>McDonald and Lowe, 1998</REF>	1	Evaluation Procedure	0	We evaluate our models by correlating the predicted plausibility values with the human judgements, which range between 1 and 7	0	6	1
C02-1090	P99-1004	2002	The distributional similarity was measured by means of three different similarity measures: the Jaccards coefficient, L1 distance, and the skew divergence	0	This choice of similarity measures was motivated by results of studies by <REF>Levy et al 1998</REF> and <TREF>Lee 1999</TREF> which compared several well known measures on similar tasks and found these three to be superior to many others	1	Another reason for this choice is that there are different ideas underlying these measures: while the Jaccards coefficient is a binary measure, L1 and the skew divergence are probabilistic, the former being geometrically motivated and the latter being a version of the information theoretic Kullback Leibler divergence cf	0	, <TREF>Lee 1999</TREF>	0	5	2
W06-1105	P99-1004	2006	The same procedure is applied for symmetric KL divergence and JS divergence	0	The second approach is from <TREF>Lee 1999</TREF>	1	Here similarity for KL is defined as Simp,q  C KLpq, where C is a free parameter to be tuned	0	4 Experimental Setup 41 Materials Following Chen et al	0	6	1
W06-1105	P99-1004	2006	Comparing the different divergence measures for LDA, we found that KL and JS perform significantly better than symmetrised KL divergence	0	Interestingly, the performance of the asymmetric KL divergence and the symmetric JS divergence is very close, which makes it difficult to conclude whether the relation discovery domain is a symmetric domain or an asymmetric domain like <TREF>Lees 1999</TREF> task of improving probability estimates for unseen word co-occurrences	1	A shortcoming of all the models we will describe here is that they are derived from the basic bag-of-words models and as such do not account for word order or other notions of syntax	1	Related work on relation discovery by Zhang et al	0	1	3
W06-1105	P99-1004	2006	The optimal configuration varies by the divergence measure with D  50 and C  14 for KL divergence, D  200 and C  4 for symmetrised KL, and D  150 and C  2 for JS divergence	0	For all divergence measures, <TREF>Lees 1999</TREF> method outperformed Dagan et als 1997 method	1	Also for all divergence measures, the model hyper-parameter  was found to be optimal at 00001	0	The  hyper-parameter was always set to 50/T following <REF>Griffiths and Steyvers 2004</REF>	0	4	2
I08-1070	P99-1004	2008	wx,f stands for the weight frequency in our experiment of f in F x  While Par Lin is symmetric, it has been argued that itisimportant todetermine thedirection ofparaphrase	0	As an asymmetric measure, we examine skew divergence defined by the following equation <TREF>Lee, 1999</TREF>: d skew t,sD P s bardblP t 1 P s , where P x denotes a probability distribution estimated 6 from a feature set F x HowwellP t approximates P s is calculated based on the KL divergence, D The parameter  is set to 099, following tradition, because the optimization of  is difficult	1	To take consistent measurements, we define the paraphrasability score Par skew as follows: Par skew stexpd skew t,s	0	6 We estimate them simply using maximum likelihood estimation, ie, P x fwx,f/ P f prime F x wx,f prime 	0	6	1
W05-0604	P99-1004	2005	Note that if any a56 a8 a64a80a50, then a57 a11a81a1a59a55a60a52a61a56a4a5 is infinite; in general, the KLdivergence is very sensitive to small probabilities, and careful attention must be paid to smoothing if it is to be used with text co-occurrence data	0	The Jensen-Shannon divergencean average of the divergences of a55 and a56 from their mean distribution does not share this sensitivity and has previously been used in tests of lexical similarity <TREF>Lee, 1999</TREF>	1	Furthermore, unlike the KL-divergence, it is symmetric, presumably a desirable property in this setting, since synonymy is a symmetric relation, and our test design exploits this symmetry	0	However, a57 a11a83a82a45a17 a1a59a55a60a52a61a56a4a5, the Hellinger distance 3, is also symmetric and robust to small or zero estimates	0	6	1
W05-0604	P99-1004	2005	For a48 a49 a1a51a50a23a52a54a53a19a5 and word-conditional context distributions a55 and a56, we have the so-called a48 -divergences <REF>Zhu and Rohwer, 1998</REF>: a57 a58 a1a59a55a60a52a61a56a4a5a63a62a59a64 a53a65a14 a7 a55 a58 a56 a11a38a66 a58 a48a67a1a45a53a18a14a16a48a42a5 1 Divergences a57 a68 and a57 a11 are defined as limits as a48a6a69 a50 and a48a6a69a70a53 :a57 a11 a1a59a55a60a52a61a56a4a5a71a64 a57 a68 a1a51a56a67a52a51a55a72a5a71a64a74a73 a55a76a75a78a77a47a79 a55 a56 In other words, a57 a11a19a1a59a55a60a52a61a56a4a5 is the KL-divergence of a55 from a56  Members of this divergence family are in some sense preferred by theory to alternative measures	0	It can be shown that the a48 -divergences or divergences defined by combinations of them, such as the Jensen-Shannon or skew divergences <TREF>Lee, 1999</TREF> are the only ones that are robust to redundant contexts ie , only divergences in this family are invariant <REF>Csiszar, 1975</REF>	1	Several notions of lexical similarity have been based on the KL-divergence	0	Note that if any a56 a8 a64a80a50, then a57 a11a81a1a59a55a60a52a61a56a4a5 is infinite; in general, the KLdivergence is very sensitive to small probabilities, and careful attention must be paid to smoothing if it is to be used with text co-occurrence data	0	1	2
W05-0604	P99-1004	2005	By default, we bracket a token sequence with pseudo-tokens <bos> and <eos>2 Contextual tokens in the window may be either observed or disregarded, and the policy governing which to admit is one of the dimensions we explore here	0	The decision whether or not to observe a particular contextual token is made before counting commences, and is not sensitive to the circumstances of a particular occurrence eg , its participation in some syntactic relation <REF>Lin, 1997</REF>; <TREF>Lee, 1999</TREF>	1	When a contextual token is observed, it is always counted as a single occurrence	0	Thus, in contrast with earlier approaches <REF>Sahlgren, 2001</REF>; <REF>Ehlert, 2003</REF>, we do not use a weighting scheme that is a function of distance from the reference token	0	6	1
W05-0604	P99-1004	2005	We do not know whether or to what extent this particular parameter setting is universally best, best only for English, best for newswire English, or best only for the specific test we have devised	0	We have restricted our attention to a relatively small space of similarity measures, excluding many previously proposed measures of lexical affinity but see Weeds, et al 2004, and <TREF>Lee 1999</TREF> for some empirical comparisons	1	Lee observed that measures from the space of invariant divergences particularly the JS and skew divergences perform at least as well as any of a wide variety of alternatives	1	As noted, we experimented with the JS divergence and observed accuracies that tracked those of the Hellinger closely	0	3	2
H05-1053	P99-1004	2005	One could look at differences in the ranking over all words, using a meaTraining Testing FINANCE SPORTS Finance 355 Sports 409 SemCor 142 153 100 Table 4: WSD accuracy for words with a different first sense to the BNC	0	sure such as pairwise agreement of rankings or a ranking correlation coefficient, such as Spearmans One could also use the rankings to estimate probability distributions and compare the distributions with measures such as alpha-skew divergence <TREF>Lee, 1999</TREF>	1	A simple definition would be where the rankings assign different predominant senses to a word	0	Taking this simple definition of deviation, we demonstrate how this might be done for our corpora	0	2	1
W06-1406	P99-1004	2006	The distributional hypothesis <REF>Harris, 1968</REF> says the following: The meaning of entities, and the meaning of grammatical relations among them, is related to the restriction of combinations of these entities relative to other entities	0	Over recent years, many applications <REF>Lin, 1998</REF>, <TREF>Lee, 1999</TREF>, <REF>Lee, 2001</REF>, <REF>Weeds et al , 2004</REF>, and <REF>Weeds and Weir, 2006</REF> have been investigating the distributional similarity of words	1	Similarity means that words with similar meaning tend to appear in similar contexts	0	In NLG, the considerationofsemanticsimilarityisusuallypreferred to just distributional similarity	0	6	1
P06-2007	P99-1004	2006	The pairs are generally either related in one type of relationship, or completely unrelated	0	In general we may be able to identify related phrases for example with distributional similarity <TREF>Lee, 1999</TREF>, but would like to be able to automatically classify the related phrases by the type of the relationship	1	For this task we identify a larger set of candidate-related phrases	0	32 Query Log Data To find phrases that are similar or substitutable for web searchers, we turn to logs of user search sessions	0	6	1
P06-2007	P99-1004	2006	We draw a distinction between the task of identifying terms which are topically related and identifying the specific semantic class	0	For example, the terms dog, puppy, canine, schnauzer, cat and pet are highly related terms, which can be identified using techniques that include distributional similarity <TREF>Lee, 1999</TREF> and withindocument cooccurrence measures such as pointwise mutual information <REF>Turney et al , 2003</REF>	1	These techniques, however, do not allow us to distinguish the more specific relationships:  hypernymdog,puppy This work was carried out while these authors were at Yahoo	1	Research	0	1	3
W01-0502	P99-1004	2001	In all studies done so far, however, the first classifier  the confusion sets  were constructed manually by the researchers	0	Other word predictions tasks have also constructed manually the list of confusion sets <REF>Lee and Pereira, 1999</REF>; <REF>Dagan et al , 1999</REF>; <TREF>Lee, 1999</TREF> and justifications where given as to why this is a reasonable way to construct it	1	Even-<REF>Zohar and Roth, 2000</REF> present a similar task in which the confusion sets generation was automated	0	Their study also quantified experimentally the advantage in using early classifiers to restrict the size of the confusion set	0	6	1
D07-1061	P99-1004	2007	Therefore, the  term in skew divergence implicitly defines a parameter stating how many orders of magnitude smaller than pj to count qj if qj  0	0	We define the Zero-KL divergence with respect to 2<REF>In Lees 1999</REF> original presentation, skew divergence is defined not as sp,q but rather as sq,p	1	We reverse the argument order for consistency with the other measures discussed here	0	586 gamma: ZKLp,q  summationdisplay i pi braceleftbigg logpi qi qi negationslash 0  qi  0 Note that this is exactly KL-divergence when KLdivergence is defined and, like skew divergence, approximates KL divergence in the limit as   	0	3	1
D07-1061	P99-1004	2007	One is Jensen-Shannon divergence <REF>Lin, 1991</REF>, a symmetric measure based on KL-divergence defined as the average of the KL divergences of each distribution to their average distribution	0	Jensen-Shannon is well defined for all distributions becausetheaverageofpi andqi isnon-zerowhenevereither number is These measures and others are surveyed in <REF>Lee, 2001</REF>, who finds that Jensen-Shannon is outperformed by the Skew divergence measure introduced by Lee in 1999	1	The skew divergence2 accounts for zeros in q by mixing in a small amount of p sp,q  Dp bardbl q  1p  summationtexti pi log piqi1pi Lee found that as   1, the performance of skew divergence on natural language tasks improves	0	In particular, it outperforms most other models and even beats pure KL divergence modified to avoid zeros with sophisticated smoothing models	0	2	2
P99-1005	P99-1004	1999	22 Nearest-neighbors averaging As noted earlier, the nearest-neighbors averaging method is an alternative to clustering for estimating the probabilities of unseen cooccurfences	0	Given an unseen pair n, v, we calculate an estimate 15vln  as an appropriate average of pvln I where n I is distributionally similar to n Many distributional similarity measures can be considered <TREF>Lee, 1999</TREF>	1	In this paper, we focus on the one that gave the best results in our earlier work <REF>Dagan et al , 1999</REF>, the Jensen-Shannon divergence <REF>Rao, 1982</REF>; <REF>Lin, 1991</REF>	0	The Jensen-Shannon divergence of two discrete distributions p and q over the same domain is defined as 1 gSp, q   It is easy to see that JSp, q is always defined	0	6	1
J04-3002	P99-1004	2004	Opinion-piece data are used for training, and a different set of opinion-piece data and the subjective-element data are used for testing	0	With distributional similarity, words are judged to be more or less similar based on their distributional patterning in text <TREF>Lee 1999</TREF>; <REF>Lee and Pereira 1999</REF>	1	Our Table 5 Random sample of fixed-3-gram collocations in OP1	0	one-noun of-prep his-det worst-adj of-prep all-det quality-noun of-prep the-det to-prep do-verb so-adverb in-prep the-det company-noun you-pronoun and-conj your-pronoun have-verb taken-verb the-det rest-noun of-prep us-pronoun are-verb at-prep least-adj but-conj if-prep you-pronoun as-prep a-det weapon-noun continue-verb to-to do-verb purpose-noun of-prep the-det could-modal have-verb be-verb it-pronoun seem-verb to-prep to-pronoun continue-verb to-prep have-verb be-verb the-det do-verb something-noun about-prep cause-verb you-pronoun to-to evidence-noun to-to back-adverb that-prep you-pronoun are-verb i-pronoun be-verb not-adverb of-prep the-det century-noun of-prep money-noun be-prep 291 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language Table 6 Random sample of unique generalized collocations in OP1	0	3	2
J04-3002	P99-1004	2004	Thus, to decide whether to retain a word as a PSE, we consider the precision not of the individual word, but of the word together with a cluster of words similar to it	0	Many variants of distributional similarity have been used in NLP <TREF>Lee 1999</TREF>; <REF>Lee and Pereira 1999</REF>	1	<REF>Dekang Lins 1998</REF> method is used here	0	In contrast to many implementations, which focus exclusively on verb-noun relationships, Lins method incorporates a variety of syntactic relations	0	6	1
A00-2017	P99-1004	2000	To evaluate word prediction as a simple language model	0	We chose the verb prediction task which is similar to other word prediction tasks eg ,<REF>Golding and Roth, 1999</REF> and, in particular, follows the paradigm in <REF>Lee and Pereira, 1999</REF>; <REF>Dagan et al , 1999</REF>; <TREF>Lee, 1999</TREF>	1	There, a list of the confusion sets is constructed first, each consists of two different verbs	0	The verb vl is coupled with v2 provided that they occur equally likely in the corpus	0	5	1
A00-2017	P99-1004	2000	Results are shown in percentage of improvement in accuracy over the baseline	0	Table 2 compares our method to methods that use similarity measures <REF>Dagan et al , 1999</REF>; <TREF>Lee, 1999</TREF>	1	Since we could not use the same corpus as in those experiments, we compare the ratio of improvement and not the WER	0	The baseline in this studies is different, but other than that the experiments are identical	0	2	1
C04-1146	P99-1004	2004	The cosine measure <REF>Salton and McGill, 1983</REF> returns the cosine of the angle between two vectors	0	The Jensen-Shannon JS divergence measure <REF>Rao, 1983</REF> and the -skew divergence measure <TREF>Lee, 1999</TREF> are based on the Kullback-Leibler KL divergence measure	1	The KL divergence, or relative entropy, Dpjjq, between two probability distribution functions p and q is de ned <REF>Cover and Thomas, 1991</REF> as the ine ciency of assuming that the distribution is q when the true distribution is p: Dpjjq  Pcplog pq	0	However, Dpjjq  1 if there are any contexts c for which pc > 0 and qc  0	0	6	1
C04-1146	P99-1004	2004	However, due to the lack of a tight de nition for the concept of distributional similarity and the broad range of potential applications, a large number of measures of distributional similarity have been proposed or adopted see Section 2	0	Previous work on the evaluation of distributional similarity methods tends to either compare sets of distributionally similar words to a manually created semantic resource <REF>Lin, 1998</REF>; <REF>Curran and Moens, 2002</REF> or be oriented towards a particular task such as language modelling <REF>Dagan et al , 1999</REF>; <TREF>Lee, 1999</TREF>	1	The rst approach is not ideal since it assumes that the goal of distributional similarity methods is to predict semantic similarity and that the semantic resource used is a valid gold standard	0	Further, the second approach is clearly advantageous when one wishes to apply distributional similarity methods in a particular application area	1	1	2
C08-1082	P99-1004	2008	As the vector for each target word must sum to 1, the marginal distributions of target words have little effect on the resulting similarity estimates	0	Many 649 similarity measures and weighting functions have been proposed for distributional vectors; comparative studies include <TREF>Lee 1999</TREF>, <REF>Curran 2003</REF> and <REF>Weeds and Weir 2005</REF>	1	22 Kernel Methods for Computing Similarity and Distance In this section we describe two classes of functions, positive semi-definite and negative semidefinite kernels, and state some relationships between these classes	0	The mathematical treatment follows Berg et al	0	6	1
C08-1082	P99-1004	2008	It seems likely that distance measures that are known to work well for comparing co-occurrence distributions will also give us suitable psd similarity measures	0	Negative semi-definite kernels are bydefinitionsymmetric, whichrulestheKullbackLeibler divergence and <TREF>Lees 1999</TREF>-skew divergence out of consideration	1	The nsd condition 2 ismetifthedistancefunctionisasquaredmetricin a Hilbert space	0	In this paper we use a parametric familyofsquaredHilbertianmetricsonprobability distributions that has been discussed by <REF>Hein and Bousquet 2005</REF>	0	1	3
C08-1082	P99-1004	2008	23 Distributional Kernels Given the effectiveness of distributional similarity measures for numerous tasks in NLP and the interpretation of kernels as similarity functions, it seems natural to consider the use of kernels tailored for co-occurrence distributions when performing semantic classification	0	As shown in Section 22 the standardly used linear and Gaussian kernelsderivefromtheL2 distance, yet<TREF>Lee1999</TREF> has shown that this distance measure is relatively poor at comparing co-occurrence distributions	1	Information theory provides a number of alternative distance functions on probability measures, of which the L1 distance also called variational distance, Kullback-Leibler divergence and JensenShannon divergence are well-known in NLP and 1Negated nsd functions are sometimes called conditionally psd; they constitute a superset of the psd functions	0	650 Distance Definition Derived linear kernel L2 distance2 summationtextcPcw1Pcw22 summationtextc Pcw1Pcw2 L1 distance summationtextcPcw1Pcw2 summationtextc minPcw1,Pcw2 Jensen-Shannon summationtextc Pcw1log2 2Pcw1Pcw1Pcw2  summationtextc Pcw1log2 Pcw1Pcw1Pcw2  divergence Pcw2log2 2Pcw2Pcw1Pcw2 Pcw2log2 Pcw2Pcw1Pcw2 Hellinger distance summationtextcradicalbigPcw1radicalbigPcw22 summationtextcradicalbigPcw1Pcw2 Table 1: Squared metric distances on co-occurrence distributions and corresponding linear kernels were shown by Lee to give better similarity estimates than the L2 distance	0	1	2
P01-1046	P99-1004	2001	A key feature of this type of smoothing is the function which measures distributional similarity from cooccurrence frequencies	0	Several measures of distributional similarity have been proposed in the literature <REF>Dagan et al , 1999</REF>; <TREF>Lee, 1999</TREF>	1	We used two measures, the Jensen-Shannon divergence and the confusion probability	0	Those two measures have been previously shown to give promising performance for the task of estimating the frequencies of unseen verb-argument pairs <REF>Dagan et al , 1999</REF>; <REF>Grishman and Sterling, 1994</REF>; <REF>Lapata, 2000</REF>; <TREF>Lee, 1999</TREF>	1	2	2
P01-1046	P99-1004	2001	We used two measures, the Jensen-Shannon divergence and the confusion probability	0	Those two measures have been previously shown to give promising performance for the task of estimating the frequencies of unseen verb-argument pairs <REF>Dagan et al , 1999</REF>; <REF>Grishman and Sterling, 1994</REF>; <REF>Lapata, 2000</REF>; <TREF>Lee, 1999</TREF>	1	In the following we describe these two similarity measures and show how they can be used to recreate the frequencies for unseen adjective-noun pairs	0	Jensen-Shannon Divergence	0	2	2
W02-1030	P99-1004	2002	If a bigram is unseen in a given corpus, conventional approaches recreate its frequency using techniques such as back-off, linear interpolation, class-based smoothing or distance-weighted averaging see Dagan et al	1	1999 and <TREF>Lee 1999</TREF> for overviews	1	The approach proposed here does not recreate the missing counts, but instead retrieves them from a corpus that is much larger but also much more noisy than any existing corpus: it launches queries to a search engine in order to determine how often a bigram occurs on the web	0	We systematically investigated the validity of this approach by using it to obtain frequencies for predicate-argument bigrams adjective-noun, nounnoun, and verb-object bigrams	0	6	1
P03-1017	P99-1004	2003	The two measures are shown in Figure 2	0	The Skew divergence represents a generalisation of the Kullback-Leibler divergence and was proposed by <TREF>Lee 1999</TREF> as a linguistically motivated distance measure	1	We use a value of   :99	0	We explored in detail the influence of different types and sizes of context by varying the context specification and path value functions	0	6	2
P03-1017	P99-1004	2003	This makes semantic spaces more flexible, different types of contexts can be selected and words do not have to physically co-occur to be considered contextually relevant	0	However, existing models either concentrate on specific relations for constructing the semantic space such as objects eg , <TREF>Lee, 1999</TREF> or collapse all types of syntactic relations available for a given target word <REF>Grefenstette, 1994</REF>; <REF>Lin, 1998</REF>	1	Although syntactic information is now used to select a words appropriate contexts, this information is not explicitly captured in the contexts themselves which are still represented by words and is therefore not amenable to further processing	0	A commonly raised criticism for both types of semantic space models ie , word-based and syntaxbased concerns the notion of semantic similarity	0	2	1
P03-1017	P99-1004	2003	Contexts are defined as a small number of words surrounding the target word <REF>Lund and Burgess, 1996</REF>; <REF>Lowe and McDonald, 2000</REF> or as entire paragraphs, even documents <REF>Landauer and Dumais, 1997</REF>	0	Context is typically treated as a set of unordered words, although in some cases syntactic information is taken into account <REF>Lin, 1998</REF>; <REF>Grefenstette, 1994</REF>; <TREF>Lee, 1999</TREF>	1	A word can be thus viewed as a point in an n-dimensional semantic space	0	The semantic similarity between words can be then mathematically computed by measuring the distance between points in the semantic space using a metric such as cosine or Euclidean distance	0	6	1
W04-1507	P99-1004	2004	There are a number of studies that, starting from this hypothesis, have built automatic or semi-automatic procedures for clustering words <REF>Brill and Marcus, 1992</REF>; <REF>Pereira et al , 1993</REF>; <REF>Martin et al , 1998</REF>, especially in the field of cognitive sciences <REF>Redington et al , 1998</REF>; <REF>Gobet and Pine, 1997</REF>; <REF>Clark, 2000</REF>	0	They examine the distributional behaviour of some target words, comparing the lexical distribution of their respective collocates using quantitative measures of distributional similarity <TREF>Lee, 1999</TREF>	1	In <REF>Brill and Marcus, 1992</REF> it is given a semiautomatic procedure that, starting from lexical statistical data collected from a large corpus, aims to arrange target words in a tree more precisely a dendrogram, instead of clustering them automatically	0	This procedure requires a linguistic examination of the resulting tree, in order to identify the word classes that are most appropriate to describe the phenomenon under investigation	0	3	2
W04-1808	P99-1004	2004	The formula is symmetric but does not satisfy the triangle inequality	0	For speed the estimate may be calculated from the shared features alone <TREF>Lee, 1999</TREF>	1	After calculating all the pairwise estimates, we retained lists of the 100 most similar nouns for each of the nouns in the corpus data	0	No other data is used in the similarity calculations	0	1	2
W04-1808	P99-1004	2004	There are many approaches to computing semantic similarity between words based on their distribution in a corpus	0	For a general overview of similarity measures, see <REF>Manning and Schutze, 1999</REF>, and for some recent and extensive overviews and evaluations of similarity measures for ia automatic thesaurus construction, see <REF>Weeds, 2003</REF>; <REF>Curran, 2003</REF>; <REF>Lee, 2001</REF>; <REF>Dagan et al , 1999</REF>	1	They show that the information radius and the skew distance are among the best for finding distributional proxies for words	0	If we assume that a word w is represented as a sum of its contexts and that we can calculate the similarities between such word representations, we get a list Lw of words with quantifications of how similar they are to w Each similarity <REF>CompuTerm 2004</REF> 3rd International Workshop on Computational Terminology 63 list Lw contains a mix of words related to the senses of the word w If we wish to identify groups of synonyms and other related words in a list of similarityrated words, we need to find clusters of similar words that are more similar to one another than they are to other words	0	6	1
P08-3011	P99-1004	2008	The intuition behind the cosine measure is that the similarity between two distributions of words should be independent of the length of either document	0	However, researchers have demonstrated that cosine is not the best relevance metric for other applications, so we evaluated two other topical similarity scores: Jacquards coefficient, which performed better than most other similarity measures in a different task for <TREF>Lee 1999</TREF> and Nave Bayes, which gave better results than cosine in topic-adapted language models for <REF>Seymore and Rosenfeld 1997</REF>	1	We evaluated all three similarity metrics using Switchboard topics as the training data and each of our corpora for testing using cross-validation	0	We found that cosine is consistently better than both Jacquards coefficient and Nave Bayes, across all corpora tested	0	6	1
P06-1116	P99-1004	2006	1993 and <TREF>Lee 1999</TREF>, among others	0	We use the cosine similarity measure for windowbased contexts and the following commonly used similarity measures for the syntactic vector space: <REF>Hindles 1990</REF> measure, the weighted Lin measure <REF>Wu and Zhou, 2003</REF>, the -Skew divergence measure <TREF>Lee, 1999</TREF>, the Jensen-Shannon JS divergence measure <REF>Lin, 1991</REF>, Jaccards coef cient van <REF>Rijsbergen, 1979</REF> and the Confusion probability <REF>Essen and Steinbiss, 1992</REF>	1	The Jensen-Shannon measure JS x1, x2  summationtext yY summationtext xx1,x2 parenleftbigg P yx log parenleftbigg Pyx 1 2 Pyx1Pyx2 parenrightbiggparenrightbigg subsequently performed best for our task	1	We compare the different ranking methodologies and data sets with respect to a manually-de ned gold standard list of 20 goal-type verbs and 20 nouns	0	1	3
P06-1116	P99-1004	2006	We use verb-object relations in both active and passive voice constructions as did Pereira et al	0	1993 and <TREF>Lee 1999</TREF>, among others	0	We use the cosine similarity measure for windowbased contexts and the following commonly used similarity measures for the syntactic vector space: <REF>Hindles 1990</REF> measure, the weighted Lin measure <REF>Wu and Zhou, 2003</REF>, the -Skew divergence measure <TREF>Lee, 1999</TREF>, the Jensen-Shannon JS divergence measure <REF>Lin, 1991</REF>, Jaccards coef cient van <REF>Rijsbergen, 1979</REF> and the Confusion probability <REF>Essen and Steinbiss, 1992</REF>	1	The Jensen-Shannon measure JS x1, x2  summationtext yY summationtext xx1,x2 parenleftbigg P yx log parenleftbigg Pyx 1 2 Pyx1Pyx2 parenrightbiggparenrightbigg subsequently performed best for our task	1	3	3
P06-1116	P99-1004	2006	Although -Skew outperforms the simpler measures in ranking nouns, its performance on verbs is worse than the performance of Weighted Lin	0	<REF>While Lee 1999</REF> argues that -Skews asymmetry can be advantageous for nouns, this probably does not hold for verbs: verb hierarchies have much shallower structure than noun hierarchies with most verbs concentrated on one level <REF>Miller et al , 1990</REF>	1	This would explain why JS, which is symmetric compared to the -Skew metric, performed better in our experiments	1	In the evaluation presented here we therefore use Google Scholar data and the JS measure	0	1	3
P05-1019	P99-1004	2005	Table 1 summarises our expectations of the values of KL divergence and V, for the various substitutability relationships	0	KL divergence, unlike most similarity functions, is sensitive to the order of arguments related by hyponymy <TREF>Lee, 1999</TREF>	1	The 152 Something happened and something else happened	0	Something happened or something else happened	0	6	1
P05-1019	P99-1004	2005	149 This paper proposes that substitutability can be predicted through statistical analysis of the contexts in which connectives appear	0	Similar methods have been developed for predicting the similarity of nouns and verbs on the basis of their distributional similarity, and many distributional similarity functions have been proposed for these tasks <TREF>Lee, 1999</TREF>	1	However substitutability is a more complex notion than similarity, and we propose a novel variance-based function for assisting in this task	0	This paper constitutes a first step towards predicting substitutability of cnonectives automatically	0	6	1
C08-1053	P99-1004	2008	Here, xi and yj denote two words and c stands for a context	0	Similarly to <TREF>Lee, 1999</TREF>, we use unsmoothed relative frequencies to derive probability estimates P In the de nition of the dice coef cient, Fxi  c : Pcxi > 0	1	We are mainly interested in the symmetric measures dxi, yj  dyj, xi because of a symmetric positive semi-de nite matrix required by kernel methods	0	Consequently, such measures as the skew divergence were excluded from the consideration <TREF>Lee, 1999</TREF>	0	6	1
C08-1053	P99-1004	2008	There are a number of measures proposed over the years, including such metrics as cosine, dice coef cient, and Jaccard distance	0	Distributional similarity measures have been extensively studied in <TREF>Lee, 1999</TREF>; <REF>Weeds et al, 2004</REF>	1	We have chosen the following metrics: dice, cosine and l2 euclidean whose de nitions are given in Table 1	0	Here, xi and yj denote two words and c stands for a context	0	6	1
C08-1053	P99-1004	2008	We are mainly interested in the symmetric measures dxi, yj  dyj, xi because of a symmetric positive semi-de nite matrix required by kernel methods	0	Consequently, such measures as the skew divergence were excluded from the consideration <TREF>Lee, 1999</TREF>	1	The Euclidean measure as de ned in Table 1 does not necessarily vary from 0 to 1	0	It was therefore normalized by dividing an l2 score in Table 1 by a maximum score and retracting it from 1	0	1	3
C08-1053	P99-1004	2008	42 Experiment I: Distributional measures and their impact on the final performance Distributional similarity measures have been used for various tasks in the past	0	For instance, <TREF>Lee, 1999</TREF> employs them to detect similar nouns based on the verb-object cooccurrence pairs	1	The results suggest the Jaccards coef cient to be one of the best performing measures followed by some others including cosine	0	Euclidean distance fell into the group with the largest error rates	0	6	1
W05-1202	P99-1004	2005	This shows that we have extracted a reasonable number of features for each phrase, since distributional similarity techniques have been shown to work well for words which occur more than 100 times in a given corpus <REF>Lin, 1998</REF>; <REF>Weeds and Weir, 2003</REF>	0	We then computed the distributional similarity between each co-occurrence vector using the -skew divergence measure <TREF>Lee, 1999</TREF>	1	The -skew divergence measure is an approximation to the KullbackLeibler KL divergence meassure between two distributions p and q: Dpq  summationdisplay x pxlogpxqx 5We currently retain all of the distinctions between grammatical relations output by RASP	0	10 The -skew divergence measure is designed to be used when unreliable maximum likelihood estimates MLE of probabilities would result in the KL divergence being equal to 	0	3	2
J06-1003	P99-1004	2006	Given this framework, many different methods of measuring distributional similarity have been proposed; see <REF>Dagan 2000</REF>, <REF>Weeds 2003</REF>, or <REF>Mohammad and Hirst 2005</REF> for a review	0	For example, the set of words that co-occur with w 1 and those that co-occur with w 2 may be regarded as a feature vector of each and their similarity measured as the cosine between the vectors; or a measure may be based on the KullbackLeibler divergence between the probability distributions Pww 1 andPww 2 , as, for example, <TREF>Lees 1999</TREF> -skew divergence	1	<REF>Lin 1998b</REF> uses his similarity theorem equation 19 above to derive a measure based on the degree of overlap of the sets of words with which w 1 and w 2 , respectively, have positive mutual information	0	22 Words that are distributionally similar do indeed often represent semantically related concepts, and vice versa, as the following examples demonstrate	0	6	1
J06-1003	P99-1004	2006	Second, whereas semantic relatedness is symmetric, distributional similarity is a potentially asymmetrical relationship	0	If distributional similarity is conceived of as substitutability, as <REF>Weeds and Weir 2005</REF> and <TREF>Lee 1999</TREF> emphasize, then asymmetries arise when one word appears in a subset of the contexts in which the other appears; for example, the adjectives that typically modify apple are a subset of those that modify fruit,sofruit substitutes for apple better than apple substitutes for fruit	1	While some distributional similarity measures, such as cosine, are symmetric, many, such as -skew divergence and the co-occurrence retrieval models developed by Weeds and Weir, are not	0	But this is simply not an adequate model of semantic relatedness, for which substitutability is far too strict a requirement: window and house are semantically related, but they are not plausibly substitutable in most contexts	1	1	3
J06-1003	P99-1004	2006	As a means of acknowledging the polysemy of language, in this paper the term concept will refer to a particular sense of a given word	0	We want to be very clear that, throughout this paper, when we say that two words are similar, this is a short way of saying that they denote similar concepts; we are not talking about similarity of distributional or co-occurrence behavior of the words, for which the term word similarity has also been used <REF>Dagan 2000</REF>; <REF>Dagan, Lee, and Pereira 1999</REF>	1	While similarity of denotation might be inferred from similarity of distributional or co-occurrence behavior <REF>Dagan 2000</REF>; <REF>Weeds 2003</REF>, the two are distinct ideas	0	We return to the relationship between them in Section 62	0	6	1
W04-1216	P99-1004	2004	Baseline1 and Baseline2 in our system use different back-off schema	0	The following formula is introduced in <TREF>Lee 1999</TREF> for word similarity-based smoothing: 4 , ,    1         tt tt wSw tt wSw tttt tt wwsim wtagPwwsim wtagP where Sw is a set of candidate similar words and simw,w is the similarity between word w and w	1	Word similarity-based smoothing approach is used in our system to make advantage of the huge unlabeled corpus	0	In order to plug the word similarity-based smoothing into our HMM model, we made several extensions to formula 4	1	5	2
J05-4002	P99-1004	2005	The constant and multiplying factors are required, since the CRM defines a similarity in the range 0,1, whereas the L 1 Norm defines a distance in the range 0,2 where 0 distance is equivalent to 1 on the similarity scale	0	44 The -skew Divergence Measure The -skew divergence measure <REF>Lee 1999, 2001</REF> is a popular approximation to the Kullback-Leibler divergence measure 8 <REF>Kullback and Leibler 1951</REF>; <REF>Cover and Thomas 1991</REF>	0	It is an approximation developed to be used when unreliable MLE probabilities 7 Distance measures, also referred to as divergence and dissimilarity measures, can be viewed as the inverse of similarity measures; that is, an increase in distance correlates with a decrease in similarity	0	8 The Kullback-Leibler divergence measure is also often referred to as relative entropy 456 Weeds and Weir Co-occurrence Retrieval would result in the actual Kullback-Leibler divergence measure being equal to Itis defined <TREF>Lee 1999</TREF> as: dist  q, r  Drq  1 r 35 for 0    1, and where: Dpq  summationdisplay x pxlog px qx 36 In effect, the q distribution is smoothed with the r distribution, which results in it always being non-zero when the r distribution is non-zero	1	6	1
J05-4002	P99-1004	2005	In our experiments, the development-set similarity using the harmonic mean in the additive MI-based CRM was 0312 for high-frequency nouns and 0153 for low-frequency nouns, and the development-set similarity using the harmonic mean in the additive t-test based CRM was 0294 for high-frequency nouns and 0129 for low-frequency nouns	0	52 Pseudo-Disambiguation Task Pseudo-disambiguation tasks have become a standard evaluation technique <REF>Gale, Church, and Yarowsky 1992</REF>; Sch utze 1992; <REF>Pereira, Tishby, and Lee 1993</REF>; Sch utze 1998; <TREF>Lee 1999</TREF>; <REF>Dagan, Lee, and Pereira 1999</REF>; <REF>Golding and Roth 1999</REF>; <REF>Rooth et al 1999</REF>; <REF>EvenZohar and Roth 2000</REF>; <REF>Lee 2001</REF>; <REF>Clark and Weir 2002</REF> and, in the current setting, we may use a nouns neighbors to decide which of two co-occurrences is the most likely	1	Although pseudo-disambiguation is an artificial task, it has relevance in at least two application areas	0	First, by replacing occurrences of a particular word in a test suite with 465 Computational Linguistics Volume 31, Number 4 a pair of words from which a technique must choose, we recreate a simplified version of the word sense disambiguation task; that is, we choose between a fixed number of homonyms based on local context	0	6	1
J05-4002	P99-1004	2005	In order to study the relationship between parameter settings and error rate, we combine three of the sets to form a development set and two of the sets to form a test set	0	The development set is used to optimize parameters and the test set 10 <REF>Unlike Lee 1999</REF>, we do not delete instances from the test data that occur in the training data	1	This is discussed in detail in <REF>Weeds 2003</REF>, but our main justification for this approach is that a single co-occurrence of n, v 1  compared to zero co-occurrences of n, v 2  is not necessarily sufficient evidence to conclude that the population probability of n, v 1  is greater than that of n, v 2 	1	11 Ten being less than the minimum number 14 of possibly indistinct co-occurrences for any target noun in the original test data	0	2	1
J05-4002	P99-1004	2005	This is advantageous in the computation of similarity, since computing the sums over all co-occurrence types rather than just those co-occurring with at least one of the words is 1 very computationally expensive and 2 due to their vast number, the effect of these zero frequency co-occurrence types tends to outweigh the effect of those co-occurrence types that have actually occurred	0	Giving such weight to these shared non-occurrences seems unintuitive and has been shown by <TREF>Lee 1999</TREF> to be undesirable in the calculation of distributional similarity	1	Hence, when using the 448 Weeds and Weir Co-occurrence Retrieval ALLR as the weight function, we use the additional restriction that Pc, w > 0 when selecting features	1	24 Difference-Weighted Models In additive models, no distinction is made between features that have occurred to the same extent with each word and features that have occurred to different extents with each word	0	3	2
J05-4002	P99-1004	2005	It is an approximation developed to be used when unreliable MLE probabilities 7 Distance measures, also referred to as divergence and dissimilarity measures, can be viewed as the inverse of similarity measures; that is, an increase in distance correlates with a decrease in similarity	0	8 The Kullback-Leibler divergence measure is also often referred to as relative entropy 456 Weeds and Weir Co-occurrence Retrieval would result in the actual Kullback-Leibler divergence measure being equal to Itis defined <TREF>Lee 1999</TREF> as: dist  q, r  Drq  1 r 35 for 0    1, and where: Dpq  summationdisplay x pxlog px qx 36 In effect, the q distribution is smoothed with the r distribution, which results in it always being non-zero when the r distribution is non-zero	1	The parameter  controls the extent to which the measure approximates the Kullback-Leibler divergence measure	0	When  is close to 1, the approximation is close while avoiding the problem with zero probabilities associated with using the Kullback-Leibler divergence measure	0	6	1
J05-4002	P99-1004	2005	Further, the noun hyponymy hierarchy in WordNet, which will be used as a pseudo-gold standard for comparison, is widely recognized in this area of research	0	Some previous work on distributional similarity between nouns has used only a single grammatical relation eg , <TREF>Lee 1999</TREF>, whereas other work has considered multiple grammatical relations eg , <REF>Lin 1998a</REF>	1	We consider only a single grammatical relation because we believe that it is important to evaluate the usefulness of each grammatical relation in calculating similarity before deciding how to combine information from 5 This results in a single 80:20 split of the complete data set, in which we are guaranteed that the original relative frequencies of the target nouns are maintained	1	6 The use of grammatical relations to model context precludes finding similarities between words of different parts of speech	0	2	2
J05-4002	P99-1004	2005	A statistical technique using a language model that assigns a zero probability to these previously unseen events will rule the correct parse or interpretation of the utterance impossible	0	Similarity-based smoothing <REF>Hindle 1990</REF>; <REF>Brown et al 1992</REF>; <REF>Dagan, Marcus, and Markovitch 1993</REF>; <REF>Pereira, Tishby, and Lee 1993</REF>; <REF>Dagan, Lee, and Pereira 1999</REF> provides an intuitively appealing approach to language modeling	1	In order to estimate the probability of an unseen co-occurrence of events, estimates based on seen occurrences of similar events can be combined	1	For example, in a speech recognition task, we might predict that cat is a more likely subject of growl than the word cap, even though neither co-occurrence has been seen before, based on the fact that cat is similar to words that do occur as the subject of growl eg , dog and tiger, whereas cap is not	0	1	2
J03-3005	P99-1004	2003	However, the next section will present a small-scale study that compares the performance of several smoothing techniques with the performance of Web counts on a standard task from the literature	0	34 Pseudodisambiguation In the smoothing literature, re-created frequencies are typically evaluated using pseudodisambiguation <REF>Clark and Weir 2001</REF>; <REF>Dagan, Lee, and Pereira 1999</REF>; <TREF>Lee 1999</TREF>; <REF>Pereira, Tishby, and Lee 1993</REF>; <REF>Prescher, Riezler, and Rooth 2000</REF>; <REF>Rooth et al 1999</REF>	1	477 Keller and Lapata Web Frequencies for Unseen Bigrams The aim of the pseudodisambiguation task is to decide whether a given algorithm re-creates frequencies that make it possible to distinguish between seen and unseen bigrams in a given corpus	0	A set of pseudobigrams is constructed according to a set of criteria detailed below that ensure that they are unattested in the training corpus	0	6	1
J03-3005	P99-1004	2003	Conclusions This article explored a novel approach to overcoming data sparseness	0	If a bigram is unseen in a given corpus, conventional approaches re-create its frequency using techniques such as back-off, linear interpolation, class-based smoothing or distanceweighted averaging see Dagan, Lee, and Pereira 1999 and Lee 1999 for overviews	1	The approach proposed here does not re-create the missing counts but instead retrieves them from a corpus that is much larger but also much more noisy than any existing corpus: it launches queries to a search engine in order to determine how often the bigram occurs on the Web	0	We systematically investigated the validity of this approach by using it to obtain frequencies for predicate-argument bigrams adjective-noun, noun-noun, and verbobject bigrams	0	6	1
J03-3005	P99-1004	2003	Other, more sophisticated class-based methods do away with the simplifying assumption that the argument co-occurring with a given predicate adjective, noun, verb is distributed evenly across its conceptual classes and attempt to find the right level of generalization in a concept hierarchy, by discounting, for example, the contribution of very general classes <REF>Clark and Weir 2001</REF>; <REF>McCarthy 2000</REF>; <REF>Li and Abe 1998</REF>	0	Other smoothing approaches such as discounting <REF>Katz 1987</REF> and distance-weighted averaging <REF>Grishman and Sterling 1994</REF>; <REF>Dagan, Lee, and Pereira 1999</REF> re-create counts of unseen word combinations by exploiting only corpus-internal evidence, without relying on taxonomic information	1	Our goal was to demonstrate that frequencies retrieved from the Web are a viable alternative to conventional smoothing methods when data are sparse; we do not claim that our Web-based method is necessarily superior to smoothing or that it should be generally preferred over smoothing methods	1	However, the next section will present a small-scale study that compares the performance of several smoothing techniques with the performance of Web counts on a standard task from the literature	0	2	1
J03-3005	P99-1004	2003	They demonstrate that the counts re-created using this smoothing technique correlate significantly with plausibility judgments for adjective-noun bigrams	0	They also show that this class-based approach outperforms distance-weighted averaging <REF>Dagan, Lee, and Pereira 1999</REF>, a smoothing method that re-creates unseen word co-occurrences on the basis of distributional similarity without relying on a predefined taxonomy, in predicting plausibility	1	In the current study, we used the smoothing technique of <REF>Lapata, Keller, and McDonald 2001</REF> to re-create not only adjective-noun bigrams, but also noun-noun 475 Keller and Lapata Web Frequencies for Unseen Bigrams Table 12 Correlation of counts re-created using class-based smoothing with Web counts	0	Adjective-Noun Noun-Noun Verb-Object Seen Bigrams AltaVista 344 362 361 Google 330 343 349 Unseen Bigrams AltaVista 439 386 412 Google 444 421 397 p <05 one-tailed	0	1	3
J03-3005	P99-1004	2003	Despite their imperfect output, heuristic methods for the extraction of syntactic relations are relatively common in statistical NLP	0	Several statistical models employ frequencies obtained from the output of partial parsers and other heuristic methods; these include models for disambiguating the attachment site of prepositional phrases <REF>Hindle and Rooth 1993</REF>; <REF>Ratnaparkhi 1998</REF>, models for interpreting compound nouns <REF>Lauer 1995</REF>; <REF>Lapata 2002</REF> and polysemous adjectives <REF>Lapata 2001</REF>, models for the induction of selectional preferences <REF>Abney and Light 1999</REF>, methods for automatically clustering words according to their distribution in particular syntactic contexts <REF>Pereira, Tishby, and Lee 1993</REF>, automatic thesaurus extraction <REF>Grefenstette 1994</REF>; <REF>Curran 2002</REF>, and similarity-based models of word co-occurrence probabilities <TREF>Lee 1999</TREF>; <REF>Dagan, Lee, and Pereira 1999</REF>	1	In this article we investigate alternative ways for obtaining bigram frequencies that are potentially useful for such models despite the fact that some of these bigrams are identified in a heuristic manner and may be noisy	0	22 Sampling Bigrams from the NANTC We also obtained corpus counts from a second corpus, the North American News Text Corpus NANTC	0	6	1
C04-1135	P99-1016	2004	By using Japanese HTML documents, we empirically show that our proposed method can obtain a significant number of hyponymy relations which would otherwise be missed by alternative methods	1	Hyponymy relations can play a crucial role in various NLP systems, and there have been many attempts to develop automatic methods to acquire hyponymy relations from text corpora <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>; <REF>Imasumi, 2001</REF>; <REF>Fleischman et al , 2003</REF>; <REF>Morin and Jacquemin, 2003</REF>; <REF>Ando et al , 2003</REF>	1	Most of these techniques have relied on particular linguistic patterns, such as NP such as NP The frequencies of use for such linguistic patterns are relatively low, though, and there can be many expressions that do not appear in such patterns even if we look at large corpora	0	The effort of searching for other clues indicating hyponymy relations is thus significant	0	4	2
P06-1038	P99-1016	2006	<REF>Pantel and Lin, 2002</REF> improves on the latter by clustering by committee	0	<TREF>Caraballo 1999</TREF> uses conjunction and appositive annotations in the vector representation	1	2We did not compare against methods that use richer syntactic information, both because they are supervised and because they are much more computationally demanding	1	3We are not aware of any multilingual evaluation previously reported on the task	0	6	1
D07-1034	P99-1016	2007	For instance, <REF>Lin 1998</REF> used dependency relation as word features to compute word similarities from large corpora, and compared the thesaurus created in such a way with WordNet and Roget classes	0	<TREF>Caraballo 1999</TREF> selected head nouns from conjunctions and appositives in noun phrases, and used the cosine similarity measure with a bottomup clustering technique to construct a noun hierarchy from text	1	<REF>Curran and Moens 2002</REF> explored a new similarity measure for automatic thesaurus extraction which better compromises with the speed/performance tradeoff	0	<REF>You and Chen 2006</REF> used a feature clustering method to create a thesaurus from a Chinese newspaper corpus	0	6	1
C08-1058	P99-1016	2008	Previous work on automatic methods for building semantic lexicons could be divided into two main groups	1	One is automatic thesaurus acquisition, that is, to identify synonyms or topically related words from corpora based on various measures of similarity eg <REF>Riloff and Shepherd, 1997</REF>; <REF>Lin, 1998</REF>; <TREF>Caraballo, 1999</TREF>; <REF>Thelen and Riloff, 2002</REF>; <REF>You and Chen, 2006</REF>	1	Another line of research, which is more closely related to the current study, is to extend existing thesauri by classifying new words with respect to their given structures eg <REF>Tokunaga et al, 1997</REF>; <REF>Pekar, 2004</REF>	0	An early effort along this line is <REF>Hearst 1992</REF>, who attempted to identify hyponyms from large text corpora, based on a set of lexico-syntactic patterns, to augment and critique the content of WordNet	0	4	2
N07-1031	P99-1016	2007	In contrast, in this paper we focus on the problem of determining the categories of interest	0	Another thread of work is on finding synonymous terms and word associations, as well as automatic acquisition of IS-A or genus-head relations from dictionary definitions and free text <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>	1	That work focuses on finding the right position for a word within a lexicon, rather than building up comprehensible and coherent faceted hierarchies	1	A major class of solutions for creating subject hierarchies uses data clustering	0	4	2
W02-0904	P99-1016	2002	One way to overcome this problem might be to give judges information about a sequence of higher ancestors, in order to make the judgement easier	0	It is difficult to compare these results with results from other studies such as that of <TREF>Caraballo 1999</TREF>, as the data used is not the same	1	However, it seems that our figures are in the same range as those reported in previous studies	1	<REF>Charniak  Roark 1998</REF>, evaluating the semantic lexicon against gold standard resources the MUC-4 and the WSJ corpus, reports that the ratio of valid to total entries for their system lies between 20 and 40	0	4	2
W02-0904	P99-1016	2002	For example, while the plural form of the word boy ie boys is a valid hyponym of the hypernym group, the singular form would not be	1	As was also reported by <TREF>Caraballo 1999</TREF>, the judges sometimes found proper nouns as hyponyms hard to evaluate	1	Eg it might be hard to tell if Simon Le Bon is a valid hyponym to the hypernym rock star if his identity is unknown to the judge	0	One way to overcome this problem might be to give judges information about a sequence of higher ancestors, in order to make the judgement easier	1	6	1
W02-0904	P99-1016	2002	Generally, principle 1-2 above are meant to prevent the hierarchies from containing ambiguity	0	The built-in ambiguity in the hyponymy hierarchy presented in <TREF>Caraballo, 1999</TREF> is primarily an effect of the fact that all information is composed into one tree	1	Part of the ambiguity could have been solved if the requirement of building one tree had been relaxed	0	Principle 2, regarding keeping the hierarchy ambiguity-free, is especially important, as we are working with acquisition from a corpus that is not domain restricted	0	6	1
W02-0904	P99-1016	2002	<REF>Charniak  Roark 1998</REF>, evaluating the semantic lexicon against gold standard resources the MUC-4 and the WSJ corpus, reports that the ratio of valid to total entries for their system lies between 20 and 40	0	<TREF>Caraballo 1999</TREF> let three judges evaluate ten internal nodes in the hyponymy hierarchy, that had at least twenty descendants	1	Cases where judges had problems with proper nouns as hyponyms, corresponding to these mentioned above, were corrected	0	When the best hypernym was evaluated, the result reported for a majority of the judges was 33	0	6	1
W02-0904	P99-1016	2002	Continue at 1	0	<TREF>Caraballo 1999</TREF> uses a hierarchical clustering technique to build a hyponymy hierarchy of nouns	1	The internal nodes are labeled by the syntactic constructions from <REF>Hearst 1992</REF>	0	Each internal node in the hierarchy can be represented by up to three nouns	0	6	1
J06-2003	P99-1016	2006	Automatically extracting world knowledge from MRDs was attempted by projects such as MindNet at Microsoft Research <REF>Richardson, Dolan, and Vanderwende 1998</REF>, and Barrierre and <REF>Popowichs 1996</REF> project, which learns from childrens dictionaries	0	IS-A hierarchies have been learned automatically from MRDs <REF>Hearst 1992</REF> and from corpora Caraballo 1999 among others	1	14 http://wwwclcamacuk/Research/NL/acquilex/acqhomehtml 240 Inkpen and Hirst A Lexical Knowledge Base of Near-Synonym Differences Research on merging information from various lexical resources is related to the present work in the sense that the consistency issues to be resolved are similar	0	One example is the construction of Unified Medical Language System UMLS 15 <REF>Lindberg, Humphreys, and McCray 1993</REF>, in the medical domain	0	6	1
W08-2113	P99-1016	2008	Based on these seeds, she proposes a bootstrapping algorithm to semi-automatically acquire new more specific patterns	1	Similarly, <TREF>Caraballo, 1999</TREF> uses predefined patterns such as X is a kind of Y or X, Y, and other Zs to identify hypernym/hyponym relationships	1	This approach to information extraction is based on a technique called selective concept extraction as defined by <REF>Riloff, 1993</REF>	0	Selective concept extraction is a form of text skimming that selectively processes relevant text while effectively ignoring surrounding text that is thought to be irrelevant to the domain	0	2	1
W08-2113	P99-1016	2008	However, it is well known that any knowledge-based system suffers from the so-called knowledge acquisition bottleneck, ie the difficulty to actually model the domain in question	0	As stated in <TREF>Caraballo, 1999</TREF>, WordNet has been an important lexical knowledge base, but it is insufficient for domain specific texts	1	So, many attempts have been made to automatically produce taxonomies <REF>Grefenstette, 1994</REF>, but <TREF>Caraballo, 1999</TREF> is certainly the first work which proposes a complete overview of the problem by 1 automatically building a hierarchical structure of nouns based on bottom-up clustering methods and 2 labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as B is a kind of A	0	2008	0	1	3
W08-2113	P99-1016	2008	As stated in <TREF>Caraballo, 1999</TREF>, WordNet has been an important lexical knowledge base, but it is insufficient for domain specific texts	1	So, many attempts have been made to automatically produce taxonomies <REF>Grefenstette, 1994</REF>, but <TREF>Caraballo, 1999</TREF> is certainly the first work which proposes a complete overview of the problem by 1 automatically building a hierarchical structure of nouns based on bottom-up clustering methods and 2 labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as B is a kind of A	1	2008	0	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 30 Unported license http://creativecommonsorg/licenses/by-ncsa/30/	0	1	3
W05-1006	P99-1016	2005	For example, the phrase France, Germany, Italy, and other European countries suggests that France, Germany and Italy are part of the class of European countries	0	Such hierarchical examples are quite sparse, and greater coverage was later attained by <REF>Riloff and Shepherd 1997</REF> and <REF>Roark and Charniak 1998</REF> in extracting relations not of hierarchy but of similarity, by finding conjunctions or co-ordinations such as cloves, cinammon, and nutmeg and cars and trucks This work was extended by <TREF>Caraballo 1999</TREF>, who built classes of related words in this fashion and then reasoned that if a hierarchical relationship could be extracted for any member of this class, it could be applied to all members of the class	1	This technique can often mistakenly reason across an ambiguous middle-term, a situation that was improved upon by <REF>Cederberg and Widdows 2003</REF>, by combining pattern-based extraction with contextual filtering using latent semantic analysis	0	Prior work in discovering non-compositional phrases has been carried out by <REF>Lin 1999</REF> and Baldwin et al	0	6	2
W03-0404	P99-1016	2003	The extraction patterns used in our research are linguistically richer patterns, requiring shallow parsing and syntactic role assignment	1	In recent years several techniques have been developed for semantic lexicon creation eg , <REF>Hearst, 1992</REF>; <REF>Riloff and Shepherd, 1997</REF>; <REF>Roark and Charniak, 1998</REF>; <TREF>Caraballo, 1999</TREF>	1	Semantic word learning is different from subjective word learning, but we have shown that MetaBootstrapping and Basilisk could be successfully applied to subjectivity learning	1	Perhaps some of these other methods could also be used to learn subjective words	1	3	2
C02-1090	P99-1016	2002	For this reason, knowledge-poor approaches such as the distributional approach are particularly suited for this task	0	Its previous applications eg , <REF>Grefenstette 1993</REF>, <REF>Hearst and Schuetze 1993</REF>, <REF>Takunaga et al 1997</REF>, <REF>Lin 1998</REF>, <TREF>Caraballo 1999</TREF> demonstrated that cooccurrence statistics on a target word is often sufficient for its automatical classification into one of numerous classes such as synsets of WordNet	1	Distributional techniques, however, are poorly applicable to rare words, ie, those words for which a corpus does not contain enough cooccurrence data to judge about their meaning	0	Such words are the primary concern of many practical NLP applications: as a rule, they are semantically focused words and carry a lot of important information	0	6	1
W02-1111	P99-1016	2002	<REF>Hearst 1992</REF> used textual patterns eg such as to identify common class members	0	<REF>Caraballo and Charniak 1999</REF> and <TREF>Caraballo 1999</TREF> augmented these lexical patterns with more general lexical co-occurrence statistics such as relative entropy	1	<REF>Berland and Charniak 1999</REF> use Hearst style techniques to learn meronym relationships part-whole from corpora	0	There has also been work in building ontologies from structured Correct Answer Question Debbie Reynolds What actress once held the title of Miss Burbank	0	6	1
C00-2104	P99-1016	2000	In addition, <REF>Strzalkowski and Wang 1996</REF> used a bootstrapping technique to identify types of references, and <REF>Riloff and Jones 1999</REF> adapted bootstrapping techniques to lexicon building targeted to information extraction	1	In the same vein, researchers at Brown University <REF>Caraballo and Charniak, 1999</REF> <REF>Berland and Charniak, 1999</REF>, <TREF>Caraballo, 1999</TREF> and <REF>Roark and Charniak, 1998</REF> focused on target constructions, in particular complex noun thrases, and searched for information not only on identifying classes of nouns, lint also hypernyms, noun specificity and meronymy	1	We have a diflbrent perspective than these lines of inquiry	1	They were specifying various semantic relationships and seeking ways to collect similar pairs	0	2	1
W04-2103	P99-1016	2004	To do this, many approaches to lexical acquisition employ the distributional model of word meaning induced from the distribution of the word across various lexical contexts of its occurrence found in the corpus	1	The approach is now being actively explored for a wide range of semantics-related tasks including automatic construction of thesauri <REF>Lin, 1998</REF>; <TREF>Caraballo, 1999</TREF>, their enrichment <REF>Alfonseca and Manandhar, 2002</REF>; <REF>Pekar and Staab, 2002</REF>, acquisition of bilingual lexica from nonaligned <REF>Kay and Rscheisen, 1993</REF> and nonparallel corpora <REF>Fung and Yee, 1998</REF>, learning of information extraction patterns from un-annotated text <REF>Riloff and Schmelzenbach, 1998</REF>	1	However, because of irregularities in corpus data, corpus statistics cannot guarantee optimal performance, notably for rare lexical items	0	In order to improve robustness, recent research has attempted a variety of ways to incorporate external knowledge into the distributional model	0	6	1
C04-1111	P99-1016	2004	However, such clustering algorithms fail to name their classes	1	<TREF>Caraballo 1999</TREF> was the first to use clustering for labeling is-a relations using conjunction and apposition features to build noun clusters	1	<REF>Recently, Pantel and Ravichandran 2004</REF> extended this approach by making use of all syntactic dependency features for each noun	0	3 Syntactical co-occurrence approach Much of the research discussed above takes a similar approach of searching text for simple surface or lexico-syntactic patterns in a bottom-up approach	0	1	3
P07-2038	P99-1016	2007	larity measure could be defined so that, for example: simexecutives, spouses > simbusloads, spouses then it is potentially useful for coordination disambiguation	0	The idea that nouns co-occurring in conjunctions tend to be semantically related has been noted in <REF>Riloff and Shepherd, 1997</REF> and used effectively to automatically cluster semantically similar words <REF>Roark and Charniak, 1998</REF>; <TREF>Caraballo, 1999</TREF>; <REF>Widdows and Dorow, 2002</REF>	1	The tendency for conjoined nouns to be semantically similar has also been exploited for coordinate noun phrase disambiguation by <REF>Resnik 1999</REF> who employed a measure of similarity based on WordNet to measure which were the head nouns being conjoined in certain types of coordinate noun phrase	0	In this paper we look at different measures of word similarity in order to discover whether they can detect empirically a tendency for conjoined nouns to be more similar than nouns which co-occur but are not conjoined	1	2	1
J05-3004	P99-1016	2005	This includes the extraction of hyponymy and synonymy relations <REF>Hearst 1992</REF>; <TREF>Caraballo 1999</TREF>, among others as well as meronymy <REF>Berland and Charniak 1999</REF>; <REF>Meyer 2001</REF>	0	10 One approach to the extraction of instances of a particular lexical relation is the use of patterns that express lexical relations structurally explicitly in a corpus <REF>Hearst 1992</REF>; <REF>Berland and Charniak 1999</REF>; <TREF>Caraballo 1999</TREF>; <REF>Meyer 2001</REF>, and this is the approach we focus on here	1	As an example, the pattern NP 1 and other NP 2 usually expresses a hyponymy/similarity relation between the hyponym NP 1 and its hypernym NP 2 <REF>Hearst 1992</REF>, and it can therefore be postulated that two noun phrases that occur in such a pattern in a corpus should be linked in an ontology via a hyponymy link	0	Applications of the extracted relations to anaphora resolution are less frequent	0	3	2
J05-3004	P99-1016	2005	372 Markert and Nissim Knowledge Sources for Anaphora Resolution consuming hand-modeling	0	This includes the extraction of hyponymy and synonymy relations <REF>Hearst 1992</REF>; <TREF>Caraballo 1999</TREF>, among others as well as meronymy <REF>Berland and Charniak 1999</REF>; <REF>Meyer 2001</REF>	1	10 One approach to the extraction of instances of a particular lexical relation is the use of patterns that express lexical relations structurally explicitly in a corpus <REF>Hearst 1992</REF>; <REF>Berland and Charniak 1999</REF>; <TREF>Caraballo 1999</TREF>; <REF>Meyer 2001</REF>, and this is the approach we focus on here	1	As an example, the pattern NP 1 and other NP 2 usually expresses a hyponymy/similarity relation between the hyponym NP 1 and its hypernym NP 2 <REF>Hearst 1992</REF>, and it can therefore be postulated that two noun phrases that occur in such a pattern in a corpus should be linked in an ontology via a hyponymy link	0	3	2
N04-4030	P99-1016	2004	The literature on automated text categorization is enormous, but assumes that a set of categories has already been created, whereas the problem here is to determine the categories of interest	0	There has also been extensive work on finding synonymous terms and word associations, as well as automatic acquisition of IS-A or genus-head relations from dictionary definitions and glosses <REF>Klavans and Whitman, 2001</REF> and from free text <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>	1	<REF>Sanderson and Croft 1999</REF> propose a method called subsumption for building a hierarchy for a set of documents retrieved for a query	0	For two terms x and y, x is said to subsume y if the following conditions hold: a2a4a3a6a5a8a7a9a11a10a13a12a15a14a17a16a18a20a19a21a2a4a3a6a9a22a7a5a23a10a25a24a27a26	0	6	2
W02-0903	P99-1016	2002	Other kinds of models that have been studied in the context of lexical acquisition are those based on lexico-syntactic patterns of the kind X, Y and other Zs, as in the phrase bluejays, robins and other birds	0	These types of models have been used for hyponym discovery <REF>Hearst, 1992</REF>; <REF>Roark and Charniak, 1998</REF>, meronym discovery <REF>Berland and Charniak, 1999</REF>, and hierarchy building <TREF>Caraballo, 1999</TREF>	1	These methods are very interesting but of limited applicability, because nouns that do not appear in known lexico-syntactic patterns cannot be learned	1	7 Conclusion All the approaches cited above focus on some aspect of the problem of lexical acquisition	0	1	3
W02-1028	P99-1016	2002	Hale, Ge, and Charniak <REF>Ge et al , 1998</REF> devised a technique to learn the gender of words	0	Caraballo <TREF>Caraballo, 1999</TREF> and Hearst <REF>Hearst, 1992</REF> created techniques to learn hypernym/hyponym relationships	1	None of these previous algorithms used extraction patterns or similar contexts to infer semantic class associations	1	Several learning algorithms have also been developed for named entity recognition eg , <REF>Collins and Singer, 1999</REF>; <REF>Cucerzan and Yarowsky, 1999</REF>	0	6	1
W02-0908	P99-1016	2002	Alternatively, some systems are based on the observation that related terms appear together in particular contexts	0	These systems extract related terms directly by recognising linguistic patterns eg X, Y and other Zs which link synonyms and hyponyms <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>	1	Our previous work <REF>Curran and Moens, 2002</REF> has evaluated thesaurus extraction performance and ef ciency using several different context models	1	In this paper, we evaluate some existing similarity metrics and propose and motivate a new metric which outperforms the existing metrics	0	3	2
P06-1015	P99-1016	2006	These methods use clustering algorithms to group words according to their meanings in text, label the clusters using its members lexical or syntactic dependencies, and then extract an is-a relation between each cluster member and the cluster label	1	<TREF>Caraballo 1999</TREF> proposed the first attempt, which used conjunction and apposition features to build noun clusters	1	<REF>Recently, Pantel and Ravichandran 2004</REF> extended this approach by making use of all syntactic dependency features for each noun	1	The advantage of clustering approaches is that they permit algorithms to identify is-a relations that do not explicitly appear in text, however they generally fail to produce coherent clusters from fewer than 100 million words; hence they are unreliable for small corpora	0	4	2
W03-0415	P99-1016	2003	In Section 3, we show how latent semantic analysis can be used to filter potential relationships according to their semantic plausibility	0	In Section 4, we show how correctly extracted relationships can be used as seed-cases to extract several more relationships, thus improving recall; this work shares some similarities with that of <TREF>Caraballo 1999</TREF>	1	In Section 5 we show that combining the techniques of Section 3 and Section 4 improves both precision and recall	0	Section 6 demonstrates that 1Another possible view is that hyponymy should only refer to core relationships, not contingent ones so pheasant a60 bird might be accepted but pheasant a60 food might not be, because it depends on context and culture	0	2	2
W03-0415	P99-1016	2003	We use the broader subset definition because contingent relationships are an important part of world-knowledge and are therefore worth learning, and because in practice we found the distinction difficult to enforce	1	Another definition is given by <TREF>Caraballo 1999</TREF>: 	1	a word A is said to be a hypernym of a word B if native speakers of English accept the sentence B is a kind of A  linguistic tools such as lemmatization can be used to reliably put the extracted relationships into a normalized or canonical form for addition to a semantic resource	1	2 Pattern-Based Hyponymy Extraction The first major attempt to extract hyponyms from text was that of <REF>Hearst 1992</REF>, described in more detail in <REF>Hearst, 1998</REF>, who extracted relationships from the text of Groliers Encyclopedia	0	2	1
W03-0415	P99-1016	2003	4 Improving Recall Using Coordination Information One of the main challenges facing hyponymy extraction is that comparatively few of the correct relations that might be found in text are expressed overtly by the simple lexicosyntactic patterns used in Section 2, as was apparent in the results presented in that section	1	This problem has been addressed by <TREF>Caraballo 1999</TREF>, who describes a system that first builds an unlabelled hierarchy of noun clusters using agglomerative bottom-up clustering of vectors of noun coordination information	1	The leaves of this hierarchy corresponding to nouns are assigned hypernyms using Hearst-style lexicosyntactic patterns	0	Internal nodes in the hierarchy are then labelled with hypernyms of the leaves they subsume according to a vote of these subsumed leaves	0	4	2
W03-0415	P99-1016	2003	This paper suggests many possibilities for future work	1	First of all, it would be interesting to apply LSA to a system for building an entire hypernym-labelled ontology in roughly the way described in <TREF>Caraballo, 1999</TREF>, perhaps by using an LSA-weighted voting method to determine which hypernym would be used to label each node	1	We are considering how to extend our techniques to such a task	1	Also, systematic comparison of the lexicosyntactic patterns used for extraction to determine the relative productiveness and accuracy of each pattern might prove illuminating, as would comparison across different corpora to determine the impact of the topic area and medium/format of documents on the effectiveness of hyponymy extraction	0	5	2
C04-1146	P99-1016	2004	Further, we explore a problem faced by the automatic thesaurus generation community, which is that distributional similarity methods do not seem to o er any obvious way to distinguish between the semantic relations of synonymy, antonymy and hyponymy	1	Previous work on this problem <TREF>Caraballo, 1999</TREF>; <REF>Lin et al , 2003</REF> involves identifying speci c phrasal patterns within text eg, Xs and other Ys is used as evidence that X is a hyponym of Y Our work explores the connection between relative frequency, distributional generality and semantic generality with promising results	1	The rest of this paper is organised as follows	0	In Section 2, we present ten distributional similarity measures that have been proposed for use in NLP	0	2	1
W99-0609	P99-1016	1999	The sparseness of these patterns prevents this from being an effective approach to the problem we address here	1	<REF>In Caraballo 1999</REF>, we construct a hierarchy of nouns, including hypernym relations	1	However, there are several areas where that work could benefit from the research presented here	0	The hypernyms used to label the internal nodes of that hierarchy are chosen in a simple fashion; pattern-matching as in <REF>Hearst 1992</REF> is used to identify candidate hypernyms of the words dominated by a particular node, and a simple voting scheme selects the hypernyms to be used	0	1	3
W99-0609	P99-1016	1999	This project is meant to provide a tool to support other methods	1	<REF>See Caraballo 1999</REF> for a detailed description of a method to construct such a hierarchy	1	2 Previous work To the best of our knowledge, this is the first attempt to automatically rank nouns based on specificity	0	<REF>Hearst 1992</REF> found individual pairs of hypernyms and hyponyms from text using pattern-matching techniques	0	4	2
W05-1003	P99-1016	2005	our disposal, WordNet <REF>Fellbaum, 1998</REF> contains very little information that would be considered as being about attributesonly information about parts, not about qualities such as height, or even to the values of such attributes in the adjective networkand this information is still very sparse	0	On the other hand, the only work on the extraction of lexical semantic relations we are aware of has concentrated on the type of relations found in WordNet: hyponymy <REF>Hearst, 1998</REF>; <TREF>Caraballo, 1999</TREF> and meronymy <REF>Berland and Charniak, 1999</REF>; <REF>Poesio et al, 2002</REF>	1	2 The work discussed here could be perhaps best described as an example of empirical ontology: using linguistics and philosophical ideas to improve the results of empirical work on lexical / ontology acquisition, and vice versa, using findings from empirical analysis to question some of the assumptions of theoretical work on ontology and the lexicon	0	Specifically, we discuss work on the acquisition of nominal concept attributes whose goal is twofold: on the one hand, to clarify the notion of attribute and its role in lexical semantics, if any; on the other, to develop methods to acquire such information automatically eg , to supplement WordNet	0	4	2
P02-1030	P99-1016	2002	Finally, some systems extract synonyms directly without extracting and comparing contextual representations for each term	1	Instead, these systems recognise terms within certain linguistic patterns eg X, Y and other Zs which associate synonyms and hyponyms <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>	1	Thesaurus extraction is a good task to use to experiment with scaling context spaces	0	The vectorspace model with nearest neighbour searching is simple, so we neednt worry about interactions between the contexts we select and a learning algorithm such as independence of the features	0	2	1
P04-2001	P99-1016	2004	Node numbers represent hierarchical structure of terms Contextual information has been mainly used to represent the characteristics of terms	0	<TREF>Caraballo, 1999</TREF>A <REF>Grefenstette, 1994</REF> <REF>Hearst, 1992</REF> <REF>Pereira, 1993</REF> and <REF>Sanderson, 1999</REF> used contextual information to find hyponymy relation between terms	1	<TREF>Caraballo, 1999</TREF>B also used contextual information to determine the specificity of nouns	1	Contrary, compositional information of terms has not been commonly discussed	0	6	1
P03-2011	P99-1016	2003	This paper describes a classifier that assigns semantic thesaurus categories to unknown Chinese words	0	<REF>The Caraballo 1999</REF>s system adopted the contextual information to assign nouns to their hyponyms	1	<REF>Roark and Charniak 1998</REF> used the co-occurrence of words as features to classify nouns	0	While context is clearly an important feature, this paper focuses on non-contextual features, which may play a key role for unknown words that occur only once 1 The Sinica Corpus is a balanced corpus contained five million part-of-speech words in Mandarin Chinese	1	2	1
P03-2011	P99-1016	2003	My analysis of the Sinica Corpus shows that contrary to expectation, most of unknown words in Chinese are common nouns, adjectives, and verbs rather than proper nouns	1	Other previous research has focused on features related to unknown word contexts <TREF>Caraballo 1999</TREF>; <REF>Roark and Charniak 1998</REF>	1	While context is clearly an important feature, this paper focuses on non-contextual features, which may play a key role for unknown words that occur only once and hence have limited context	0	The feature I focus on, following <REF>Ciaramita 2002</REF>, is morphological similarity to words whose semantic category is known	0	4	2
W04-1806	P99-1016	2004	The existing approaches to ontology induction include those that start from structured data, merging ontologies or database schemas <REF>Doan et al 2002</REF>	1	Other approaches use natural language data, sometimes just by analyzing the corpus <REF>Sanderson and Croft 1999</REF>, <TREF>Caraballo 1999</TREF> or by learning to expand WordNet with clusters of terms from a corpus, eg, <REF>Girju et al 2003</REF>	1	Information extraction approaches that infer labeled relations either require substantial handcreated linguistic or domain knowledge, eg, <REF>Craven and Kumlien 1999</REF> <REF>Hull and Gomez 1993</REF>, or require human-annotated training data with relation information for each domain <REF>Craven et al 1998</REF>	0	The number of relations in H that our system missed relations that were more than distance 1 away in the system ontology, is 3493	0	2	1
W04-1806	P99-1016	2004	<REF>CompuTerm 2004</REF> 3rd International Workshop on Computational Terminology 49 234 Explicit Patterns Relations This knowledge source infers specific relations between terms based on characteristic cue-phrases which relate them	1	For example, the cue-phrase such as <REF>Hearst 1992</REF> <TREF>Caraballo 1999</TREF> suggest a kind-of relation, eg, a ligand such as triethylphosphine tells us that triethylphosphene is a kind of ligand	1	Likewise, in the TREC domain, air toxics such as benzene can suggest that benzene is a kind of air toxic	0	However, since such cue-phrase patterns tend to be sparse in occurrence, we do not use them in the evaluations described below	1	1	3
W04-1806	P99-1016	2004	Corpus statistics can be used to weight the links	1	For example, based on <TREF>Caraballo 1999</TREF>, each parent of a leaf node could be viewed as a cluster label for its children, with the weight of a parent-child link being determined based on how strongly the child is associated with the cluster	1	10 The mean distance in H between terms that are distance 1 apart in M is 517, with a standard deviation of 212	0	The mean distance in M between terms which are distance 1 apart in H is 385, with a standard deviation of 169	0	6	1
N04-1010	P99-1016	2004	The goal of this work is to become able to automatically acquire hyponymy relations for a wide range of words or phrases from HTML documents on the WWW	0	We do not use particular lexicosyntactic patterns, as previous attempts have <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>; <REF>Imasumi, 2001</REF>; <REF>Fleischman et al , 2003</REF>; <REF>Morin and Jacquemin, 2003</REF>; <REF>Ando et al , 2003</REF>	1	The frequencies of use for such lexicosyntactic patterns are relatively low, and there can be many words or phrases that do not appear in such patterns even if we look at a large number of texts	0	The effort of searching for other clues indicating hyponymy relations is thus significant	0	2	1
P08-1119	P99-1016	2008	Fully unsupervised semantic clustering eg, <REF>Lin, 1998</REF>; <REF>Lin and Pantel, 2002</REF>; <REF>Davidov and Rappoport, 2006</REF> has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user	0	Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes eg, <TREF>Caraballo, 1999</TREF>; <REF>Cimiano and Volker, 2005</REF>; <REF>Mann, 2002</REF>, and learning semantic relations such as meronymy <REF>Berland and Charniak, 1999</REF>; <REF>Girju et al, 2003</REF>	1	Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class eg, lists of FISH or VEHICLE words	1	Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics <REF>Riloff and Shepherd, 1997</REF>; <REF>Roark and Charniak, 1998</REF>, syntactic information <REF>Tanev and Magnini, 2006</REF>; <REF>Pantel and Ravichandran, 2004</REF>; <REF>Phillips and Riloff, 2002</REF>, lexico-syntactic contextual patterns eg, resides in <location> or moved to <location> <REF>Riloff and Jones, 1999</REF>; <REF>Thelen and Riloff, 2002</REF>, and local and global contexts <REF>Fleischman and Hovy, 2002</REF>	0	4	2
P04-3015	P99-1016	2004	Accordingly, we try to extract a hierarchical relation of words automatically and statistically	1	In previous research, ways of extracting from definition sentences in dictionaries <REF>Tsurumaru et al , 1986</REF>; <REF>Shoutsu et al , 2003</REF> or from a corpus by using patterns such as a part of, is-a, or and <REF>Berland and Charniak, 1999</REF>; <TREF>Caraballo, 1999</TREF> have been proposed	1	Also, there is a method that uses the dependence relation between words taken from a corpus <REF>Matsumoto et al , 1996</REF>	0	In contrast, we propose a method based on the inclusion relation of appearance patterns from corpora	1	2	1
W02-1017	P99-1016	2002	Roark and Charniak <REF>Roark and Charniak, 1998</REF> followed up on this work by using a parser to explicitly capture these structures	0	Caraballo <TREF>Caraballo, 1999</TREF> also exploited these syntactic structures and applied a cosine vector model to produce semantic groupings	1	In our view, these previous systems used weak syntactic models because the syntactic structures sometimes identified desirable semantic associations and sometimes did not	1	To compensate, statistical models were used to separate the meaningful semantic associations from the spurious ones	1	1	3
J05-4002	P99-1016	2005	There are inherent problems in evaluating automatic thesaurus extraction techniques, and much research assumes a gold standard that does not exist see Kilgarriff 2003 and Weeds 2003 for more discussion of this	1	A further problem for distributional similarity methods for automatic thesaurus generation is that they do not offer any obvious way to distinguish between linguistic relations such as synonymy, antonymy, and hyponymy see Caraballo 1999 and Lin et al 2003 for work on this	1	Thus, one may question 1 You shall know a word by the company it keeps<REF>Firth 1957</REF> 440 Weeds and Weir Co-occurrence Retrieval the benefit of automatically generating a thesaurus if one has access to large-scale manually constructed thesauri eg , WordNet <REF>Fellbaum 1998</REF>, Rogets <REF>Roget 1911</REF>, the Macquarie <REF>Bernard 1990</REF> and Moby 2 	0	Automatic techniques give us the opportunity to model language change over time or across domains and genres	0	1	3
P02-1042	P99-1069	2002	The number of dependency types may be reduced in future work	0	3 The Probability Model The DAG-like nature of the dependency structures makes it difficult to apply generative modelling techniques <REF>Abney, 1997</REF>; <TREF>Johnson et al , 1999</TREF>, so we have defined a conditional model, similar to the model of <REF>Collins 1996</REF> see also the conditional model in <REF>Eisner 1996b</REF>	1	While the model of <REF>Collins 1996</REF> is technically unsound <REF>Collins, 1999</REF>, our aim at this stage is to demonstrate that accurate, efficient wide-coverage parsing is possible with CCG, even with an over-simplified statistical model	0	Future work will look at alternative models4 4The reentrancies creating the DAG-like structures are fairly limited, and moreover determined by the lexical categories	0	1	3
H05-1064	P99-1069	2005	The features are shown with hidden variables corresponding to wordspecific hidden values, such as shares1 or bought3	0	In our experiments, we made use of features such as those in Figure 2 in combination with the following four definitions of the hiddenvalue 3We also performed some experiments using the conjugate gradient descent algorithm <TREF>Johnson et al , 1999</TREF>	1	However, we did not find a significant difference between the performance of either method	0	Since stochastic gradient descent was faster and required less memory, our final experiments used the stochastic gradient method	0	3	2
P06-2041	P99-1069	2006	Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser <REF>Collins, 1997</REF>; <REF>Collins, 1999</REF>; <REF>Charniak, 2000</REF>	0	These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser <TREF>Johnson et al , 1999</TREF>; <REF>Collins and Duffy, 2005</REF>; <REF>Charniak and Johnson, 2005</REF>	1	Alternatively, discriminative models can be used to search the complete space of possible parses <REF>Taskar et al , 2004</REF>; <REF>McDonald et al , 2005</REF>	0	A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank	0	4	2
W07-1202	P99-1069	2007	A recent development in data-driven parsing is the use of discriminative training methods <REF>Riezler et al , 2002</REF>; <REF>Taskar et al , 2004</REF>; <REF>Collins and Roark, 2004</REF>; <REF>Turian and Melamed, 2006</REF>	0	One popular approach is to use a log-linear parsing model and maximise the conditional likelihood function <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2002</REF>; <REF>Clark and Curran, 2004b</REF>; Malouf and van <REF>Noord, 2004</REF>; <REF>Miyao and Tsujii, 2005</REF>	1	Maximising the likelihood involves calculating feature expectations, which is computationally expensive	0	Dynamic programming DP in the form of the inside-outside algorithm can be used to calculate the expectations, if the features are sufficiently local <REF>Miyao and Tsujii, 2002</REF>; however, the memory requirements can be prohibitive, especially for automatically extracted, wide-coverage grammars	0	6	1
W03-0401	P99-1069	2003	If a complete structure is represented with a feature forest of a tractable size, the parameters can be efficiently estimated by dynamic programming	0	A series of studies on parsing with wide-coverage LFG <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2000</REF>; <REF>Riezler et al , 2002</REF> have had a similar motivation to ours	0	Their models have also been based on a discriminative model to select a parsing result from all candidates given by the grammar	0	A significant difference is that we apply maximum entropy estimation for feature forests to avoid the inherent problem with estimation: the exponential explosion of parsing results given by the grammar	1	2	3
P01-1042	P99-1069	2001	Wellknown computational linguistic models such as MLE MCLE Y  yi; X  xi X  xi Y  yi; X  xi Figure 1: The MLE makes the training data yi; xi as likely as possible relative to , while the MCLE makes yi; xi as likely as possible relative to other pairs y0; xi	0	Maximum-Entropy Markov Models <REF>McCallum et al , 2000</REF> and Stochastic Unification-based Grammars <TREF>Johnson et al , 1999</TREF> are standardly estimated with conditional estimators, and it would be interesting to know whether conditional estimation affects the quality of the estimated model	0	It should be noted that in practice, the MCLE of a model with a large number of features with complex dependencies may yield far better performance than the MLE of the much smaller model that could be estimated with the same computational effort	0	Nevertheless, as this paper shows, conditional estimators can be used with other kinds of models besides MaxEnt models, and in any event it is interesting to ask whether the MLE differs from the MCLE in actual applications, and if so, how	1	3	2
A00-2021	P99-1069	2000	However, because these constraints can be non-local or context-sensitive, developing stochastic versions of UBGs and associated estimation procedures is not as straight-forward as it is for, eg, PCFGs	0	Recent work has shown how to define probability distributions over the parses of UBGs <REF>Abney, 1997</REF> and efficiently estimate and use conditional probabilities for parsing <TREF>Johnson et al , 1999</TREF>	0	Like most other practical stochastic grammar estimation procedures, this latter estimation procedure requires a parsed training corpus	1	Unfortunately, large parsed UBG corpora are not yet available	1	1	3
W02-2018	P99-1069	2002	Maximum entropy ME models, variously known as log-linear, Gibbs, exponential, and multinomial logit models, provide a general purpose machine learning technique for classification and prediction which has been successfully applied to fields as diverse as computer vision and econometrics	0	In natural language processing, recent years have seen ME techniques used for sentence boundary detection, part of speech tagging, parse selection and ambiguity resolution, and stochastic attribute-value grammars, to name just a few applications <REF>Abney, 1997</REF>; <REF>Berger et al , 1996</REF>; <REF>Ratnaparkhi, 1998</REF>; <TREF>Johnson et al , 1999</TREF>	1	A leading advantage of ME models is their flexibility: they allow stochastic rule systems to be augmented with additional syntactic, semantic, and pragmatic features	0	However, the richness of the representations is not without cost	0	6	1
W02-2018	P99-1069	2002	2 Maximum likelihood estimation Suppose we are given a probability distribution p over a set of events X which are characterized by a d dimensional feature vector function f : X Rd In addition, we have also a set of contexts W and a function Y which partitions the members of X In the case of a stochastic context-free grammar, for example, X might be the set of possible trees, the feature vectors might represent the number of times each rule applied in the derivation of each tree, W might be the set of possible strings of words, and Yw the set of trees whose yield is w2W	0	A conditional maximum entropy model qxjw for p has the parametric form <REF>Berger et al , 1996</REF>; <REF>Chi, 1998</REF>; <TREF>Johnson et al , 1999</TREF>: qxjw  exp T f x y2Yw expT f y 1 where  is a d-dimensional parameter vector and T f x is the inner product of the parameter vector and a feature vector	1	Given the parametric form of an ME model in 1, fitting an ME model to a collection of training data entails finding values for the parameter vector  which minimize the Kullback-Leibler divergence between the model q and the empirical distribution p: Dpjjq   w;x px;wlog pxjwq xjw or, equivalently, which maximize the log likelihood: L   w;x pw;xlogqxjw 2 The gradient of the log likelihood function, or the vector of its first derivatives with respect to the parameter  is: G  Ep f  Eq f  3 Since the likelihood function 2 is concave over the parameter space, it has a global maximum where the gradient is zero	0	Unfortunately, simply setting G  0 and solving for  does not yield a closed form solution, so we proceed iteratively	0	6	1
D07-1071	P99-1069	2007	23 Log-Linear CCGs We can generalize CCGs to weighted, or probabilistic, models as follows	0	Our models are similar to several other approaches <REF>Ratnaparkhi et al , 1994</REF>; <TREF>Johnson et al , 1999</TREF>; <REF>Lafferty et al , 2001</REF>; <REF>Collins, 2004</REF>; <REF>Taskar et al , 2004</REF>	1	We will write x to denote a sentence, and y to denote a CCG parse for a sentence	0	We use GENx; to refer to all possible CCG parses for x under some CCG lexicon 	0	6	1
W02-2030	P99-1069	2002	Therefore there are a large number of features available that could be used by stochastic models for disambiguation	0	Other researchers have worked on extracting features useful for disambiguation from unification grammar analyses and have built log linear models aka Stochastic Unification Based Grammars <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2000</REF>	0	Here we also use log linear models to estimate conditional probabilities of sentence analyses	1	Since feature selection is almost prohibitive for these models, because of high computational costs, we use PCFG models to select features for log linear models	0	3	2
N03-1033	P99-1069	2003	One is for a simple model with a relatively small number of features, and the other is for a model with a large number of features	0	The usefulness of priors in maximum entropy models is not new to this work: Gaussian prior smoothing is advocated in <REF>Chen and Rosenfeld 2000</REF>, and used in all the stochastic LFG work <TREF>Johnson et al , 1999</TREF>	0	However, until recently, its role and importance have not been widely understood	1	For example, <REF>Zhang and Oles 2001</REF> attribute the perceived limited success of logistic regression for text categorization to a lack of use of regularization	0	4	2
N03-1026	P99-1069	2003	After filtering by the generator, the remaining fstructures were weighted by the stochastic disambiguation component	0	Similar to stochastic disambiguation for constraint-based parsing <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2002</REF>, an exponential aka log-linear or maximumentropy probability model on transferred structures is estimated from a set of training data	1	The data for estimation consists of pairs of original sentences y and goldstandard summarized f-structures s which were manually selected from the transfer output for each sentence	0	For training data sj,yjmj1 and a set of possible summarized structures Sy for each sentence y, the objective was to maximize a discriminative criterion, namely the conditional likelihood L of a summarized f-structure given the sentence	0	2	2
P07-1104	P99-1069	2007	If on the other hand most features are noisy but at least weakly correlated with the target, it may be reasonable to attempt to reduce noise by averaging over all of the features	0	ME estimators with L2 regularization, which have been widely used in NLP tasks eg , <REF>Chen and Rosenfeld 2000</REF>; <REF>Charniak and Johnson 2005</REF>; <TREF>Johnson et al 1999</TREF>, tend to produce models that have this property	1	In addition, the perceptron algorithm and its variants, eg, the voted or averaged perceptron, is becoming increasingly popular due to their competitive performance, simplicity in implementation and low computational cost in training eg , <REF>Collins 2002</REF>	0	While recent studies claim advantages for L1 regularization, this study is the first of which we are aware to systematically compare it to a range of estimators on a diverse set of NLP tasks	0	6	1
J05-1003	P99-1069	2005	The problems with history-based models and the desire to be able to specify features as arbitrary predicates of the entire tree have been noted before	0	In particular, previous work <REF>Ratnaparkhi, Roukos, and Ward 1994</REF>; <REF>Abney 1997</REF>; Della Pietra, <REF>Della Pietra, and Lafferty 1997</REF>; <TREF>Johnson et al 1999</TREF>; <REF>Riezler et al 2002</REF> has investigated the use of Markov random fields MRFs or log-linear models as probabilistic models with global features for parsing and other NLP tasks	1	Log-linear models are often referred to as maximum-entropy models in the NLP literature	0	Similar methods have also been proposed for machine translation <REF>Och and Ney 2002</REF> and language understanding in dialogue systems <REF>Papineni, Roukos, and Ward 1997, 1998</REF>	0	6	1
W08-2102	P99-1069	2008	Experiments on the Penn WSJ treebank show that the model achieves state-of-the-art performance, for both constituent and dependency accuracy	0	In global linear models GLMs for structured prediction, eg, <TREF>Johnson et al, 1999</TREF>; <REF>Lafferty et al, 2001</REF>; <REF>Collins, 2002</REF>; <REF>Altun et al, 2003</REF>; <REF>Taskar et al, 2004</REF>, the optimal label y for an input x is y  arg max yYx w fx,y 1 where Yx is the set of possible labels for the input x; fx,y  Rd is a feature vector that represents the pair x,y; and w is a parameter vector	0	This paper describes a GLM for natural language parsing, trained using the averaged perceptron	1	The parser we describe recovers full syntactic representations, similar to those derived by a probabilistic context-free grammar PCFG	0	5	2
W08-2102	P99-1069	2008	This section describes the relationship between our work and this previous work	0	In reranking approaches, a first-pass parser is used to enumerate a small set of candidate parses for an input sentence; the reranking model, which is a GLM, is used to select between these parses eg, <REF>Ratnaparkhi et al, 1994</REF>; <TREF>Johnson et al, 1999</TREF>; <REF>Collins, 2000</REF>; <REF>Charniak and Johnson, 2005</REF>	0	A crucial advantage of our approach is that it considers a very large set of alternatives in Yx, and can thereby avoid search errors that may be made in the first-pass parser1 Another approach that allows efficient training of GLMs is to use simpler syntactic representations, in particular dependency structures McDon1Some features used within reranking approaches may be difficult to incorporate within dynamic programming, but it is nevertheless useful to make use of GLMs in the dynamicprogramming stage of parsing	1	Our parser could, of course, be used as the first-stage parser in a reranking approach	0	5	2
W07-1203	P99-1069	2007	Moreover, property design can be carried out in a targeted way, ie properties can be designed in order to improve the disambiguation of grammatical relations that, so far, are disambiguated particularly poorly or that are of special interest for the task that the systems output is used for	0	By demonstrating that property design is the key to good log-linear models for deepsyntactic disambiguation, our work confirms that specifying the features of a SUBG stochastic unification-based grammar is as much an empirical matter as specifying the grammar itself<TREF>Johnson et al , 1999</TREF>	1	Acknowledgements The work described in this paper has been carried out in the DLFG project, which was funded by the German Research Foundation DFG	0	Furthermore, I thank the audiences at several ParGram meetings, at the Research Workshop of the Israel Science Foundation on Large-scale Grammar Development and Grammar Engineering at the University of Haifa and at the SFB 732 Opening Colloquium in Stuttgart for their important feedback on earlier versions of this work	0	4	2
W07-2208	P99-1069	2007	Note that HPSG is one of the lexicalized grammar formalisms, in which lexical entries determine the dominant syntactic structures	0	Previous studies <REF>Abney, 1997</REF>; <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2000</REF>; Malouf and van <REF>Noord, 2004</REF>; <REF>Kaplan et al , 2004</REF>; <REF>Miyao and Tsujii, 2005</REF> defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model <REF>Berger et al , 1996</REF>	1	The probability that a parse result T is assigned to a given sentence w  w1,,wn is Probabilistic HPSG phpsgTw  1Z w exp parenleftBiggsummationdisplay u ufuT parenrightBigg Zw  summationdisplay Tprime exp parenleftBiggsummationdisplay u ufuTprime parenrightBigg, where u is a model parameter, fu is a feature function that represents a characteristic of parse tree T, and Zw is the sum over the set of all possible parse trees for the sentence	0	Intuitively, the probability is defined as the normalized product of the weights expu when a characteristic corresponding to fu appears in parse result T The model parameters, u, are estimated using numerical optimization methods <REF>Malouf, 2002</REF> to maximize the log-likelihood of the training data	0	6	1
W07-2208	P99-1069	2007	The main difficulty of developing parsers in these formalisms was how to model a well-defined probabilistic model for graph structures such as feature structures	0	This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model <REF>Berger et al , 1996</REF> with many features for parse trees <REF>Abney, 1997</REF>; <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2000</REF>; Malouf and van <REF>Noord, 2004</REF>; <REF>Kaplan et al , 2004</REF>; <REF>Miyao and Tsujii, 2005</REF>	1	Following this discriminative approach, techniques for efficiency were investigated for estimation <REF>Geman and Johnson, 2002</REF>; <REF>Miyao and Tsujii, 2002</REF>; Malouf and van <REF>Noord, 2004</REF> and parsing <REF>Clark and Curran, 2004b</REF>; <REF>Clark and Curran, 2004a</REF>; <REF>Ninomiya et al , 2005</REF>	0	An interesting approach to the problem of parsing efficiency was using supertagging Clark and Cur60 ran, 2004b; <REF>Clark and Curran, 2004a</REF>; <REF>Wang, 2003</REF>; <REF>Wang and Harper, 2004</REF>; <REF>Nasr and Rambow, 2004</REF>; <REF>Ninomiya et al , 2006</REF>; <REF>Foth et al , 2006</REF>; <REF>Foth and Menzel, 2006</REF>, which was originally developed for lexicalized tree adjoining grammars LTAG <REF>Bangalore and Joshi, 1999</REF>	0	6	1
P02-1035	P99-1069	2002	Firstly, the rudimentary character of functional annotations in standard treebanks has hindered the direct use of such data for statistical estimation of linguistically fine-grained statistical parsing systems	0	Rather, parameter estimation for such models had to resort to unsupervised techniques <REF>Bouma et al , 2000</REF>; <REF>Riezler et al , 2000</REF>, or training corpora tailored to the specific grammars had to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences <TREF>Johnson et al , 1999</TREF>	0	Furthermore, the effort involved in coding broadcoverage grammars by hand has often led to the specialization of grammars to relatively small domains, thus sacrificing grammar coverage ie the percentage of sentences for which at least one analysis is found on free text	0	The approach presented in this paper is a first attempt to scale up stochastic parsing systems based on linguistically fine-grained handcoded grammars to the UPenn Wall Street Journal henceforth WSJ treebank <REF>Marcus et al , 1994</REF>	1	5	2
P02-1035	P99-1069	2002	The clustering model itself is then used to yield smoothed probabilities as values for property functions on head-argument-relation tuples of LFG parses	0	32 Discriminative Estimation Discriminative estimation techniques have recently received great attention in the statistical machine learning community and have already been applied to statistical parsing <TREF>Johnson et al , 1999</TREF>; <REF>Collins, 2000</REF>; <REF>Collins and Duffy, 2001</REF>	1	In discriminative estimation, only the conditional relation of an analysis given an example is considered relevant, whereas in maximum likelihood estimation the joint probability of the training data to best describe observations is maximized	0	Since the discriminative task is kept in mind during estimation, discriminative methods can yield improved performance	0	6	1
P02-1062	P99-1069	2002	Recent work in statistical approaches to parsing and tagging has begun to consider methods which incorporate global features of candidate structures	0	Examples of such techniques are Markov Random Fields <REF>Abney 1997</REF>; Della <REF>Pietra et al 1997</REF>; <TREF>Johnson et al 1999</TREF>, and boosting algorithms <REF>Freund et al 1998</REF>; <REF>Collins 2000</REF>; <REF>Walker et al 2001</REF>	0	One appeal of these methods is their flexibility in incorporating features into a model: essentially any features which might be useful in discriminating good from bad structures can be included	1	A second appeal of these methods is that their training criterion is often discriminative, attempting to explicitly push the score or probability of the correct structure for each training sentence above the score of competing structures	0	1	2
P02-1062	P99-1069	2002	A second appeal of these methods is that their training criterion is often discriminative, attempting to explicitly push the score or probability of the correct structure for each training sentence above the score of competing structures	0	This discriminative property is shared by the methods of <TREF>Johnson et al 1999</TREF>; <REF>Collins 2000</REF>, and also the Conditional Random Field methods of <REF>Lafferty et al 2001</REF>	1	In a previous paper <REF>Collins 2000</REF>, a boosting algorithm was used to rerank the output from an existing statistical parser, giving significant improvements in parsing accuracy on Wall Street Journal data	0	Similar boosting algorithms have been applied to natural language generation, with good results, in <REF>Walker et al 2001</REF>	0	6	1
P02-1062	P99-1069	2002	The framework is derived by the transformation from ranking problems to a margin-based classification problem in <REF>Freund et al 1998</REF>	0	It is also related to the Markov Random Field methods for parsing suggested in <TREF>Johnson et al 1999</TREF>, and the boosting methods for parsing in <REF>Collins 2000</REF>	1	We consider the following set-up: a15 Training data is a set of example input/output pairs	0	In tagging we would have training examples a147 a71 a28 a30a37a17 a28a19a148 where each a71 a28 is a sentence and each a17 a28 is the correct sequence of tags for that sentence	0	6	1
P05-1011	P99-1069	2005	Experiments of the parsing of realworld sentences can properly evaluate the effectiveness and possibility of parsing models for HPSG	0	2 Disambiguation models for HPSG Discriminative log-linear models are now becoming a de facto standard for probabilistic disambiguation models for deep parsing <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2002</REF>; <REF>Geman and Johnson, 2002</REF>; <REF>Miyao and Tsujii, 2002</REF>; <REF>Clark and Curran, 2004b</REF>; <REF>Kaplan et al , 2004</REF>	1	Previous studies on probabilistic models for HPSG <REF>Toutanova and Manning, 2002</REF>; <REF>Baldridge and Osborne, 2003</REF>; Malouf and van <REF>Noord, 2004</REF> also adopted log-linear models	0	HPSG exploits feature structures to represent linguistic constraints	0	6	1
W03-1013	P99-1069	2003	Following Abney, we propose a loglinear framework which incorporates long-range dependencies as features without loss of consistency	0	Log-linear models have previously been applied to statistical parsing <TREF>Johnson et al , 1999</TREF>; <REF>Toutanova et al , 2002</REF>; <REF>Riezler et al , 2002</REF>; <REF>Osborne, 2000</REF>	0	Typically, these approaches have enumerated all possible parses for model estimation and finding the most probable parse	1	For grammars extracted from the Penn Treebank in our case CCGbank <REF>Hockenmaier, 2003</REF>, enumerating all parses is infeasible	0	4	2
W03-1019	P99-1069	2003	As expected, we observed that the regularization term increases the accuracy, especially when the training data is small; but we did not observe much difference when we used different regularization terms	0	The results we report are with the Gaussian prior regularization term described in <TREF>Johnson et al , 1999</TREF>	1	Our goal in this paper is not to build the best tagger or recognizer, but to compare different loss functions and optimization methods	0	Since we did not spend much effort on designing the most useful features, our results are slightly worse than, but comparable to the best performing models	0	3	2
P05-1022	P99-1069	2005	This method generates 50-best lists that are of substantially higher quality than previously obtainable	0	We used these parses as the input to a MaxEnt reranker <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2002</REF> that selects the best parse from the set of parses for each sentence, obtaining an f-score of 910 on sentences of length 100 or less	1	We describe a reranking parser which uses a regularized MaxEnt reranker to select the best parse from the 50-best parses returned by a generative parsing model	0	The 50-best parser is a probabilistic parser that on its own produces high quality parses; the maximum probability parse trees according to the parsers model have an f-score of 0897 on section 23 of the Penn Treebank <REF>Charniak, 2000</REF>, which is still state-of-the-art	0	3	2
W05-1511	P99-1069	2005	Given set W of words and set F of feature structures, an HPSG is formulated as a tuple, G  L,R, where L  l  w,Fw  W,F  F is a set of lexical entries, and R is a set of schemata, ie, r  R is a partial function: F F  F Given a sentence, an HPSG computes a set of phrasal signs, ie, feature structures, as a result of parsing	0	Previous studies <REF>Abney, 1997</REF>; <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2000</REF>; <REF>Miyao et al , 2003</REF>; Malouf and van <REF>Noord, 2004</REF>; <REF>Kaplan et al , 2004</REF>; <REF>Miyao and Tsujii, 2005</REF> defined a probabilistic model of unification-based grammars as a log-linear model or maximum entropy model <REF>Berger et al , 1996</REF>	1	The probability of parse result T assigned to given sentence w  w1,,,wn is pTw  1Z w exp parenleftBiggsummationdisplay i ifiT parenrightBigg Zw  summationdisplay T prime exp parenleftBiggsummationdisplay i ifiTprime parenrightBigg, where i is a model parameter, and fi is a feature function that represents a characteristic of parse tree T Intuitively, the probability is defined as the normalized product of the weights expi when a characteristic corresponding to fi appears in parse result T Model parameters i are estimated using numer104 ical optimization methods <REF>Malouf, 2002</REF> so as to maximize the log-likelihood of the training data	0	However, the above model cannot be easily estimated because the estimation requires the computation of pTw for all parse candidates assigned to sentence w Because the number of parse candidates is exponentially related to the length of the sentence, the estimation is intractable for long sentences	0	6	1
W99-0621	A88-1019	1999	The second instantiation finds the borders of phrases beginning and end and then pairs them in an optimal way into different phrases	0	These problems formulations are similar to those studied in <REF>Ramshaw and Marcus, 1995</REF> and <TREF>Church, 1988</TREF>; <REF>Argamon et al , 1998</REF>, respectively	1	The experimental results presented using the SNoW based approach compare favorably with previously published results, both for NPs and SV phrases	0	A s important, we present a few experiments that shed light on some of the issues involved in using learned predictors that interact to produce the desired inference	0	6	1
W99-0621	A88-1019	1999	Our earlier example would be marked for base NPs as: I wont to California last May	0	This approach has been studied in <TREF>Church, 1988</TREF>; <REF>Argamon et al , 1998</REF>	1	331 Architecture The architecture used for the Open/Close predictors is shown in Figure 2	0	Two SNoW predictors are used, one to predict if the word currently in consideration is the first in the phrase an open bracket, and the other to predict if it is the last a close bracket	0	6	1
W99-0621	A88-1019	1999	A lot of the work on shallow parsing over the past years has concentrated on manual construction of rules	0	The observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local part-of-speech information has motivated the use of learning methods to recognize these patterns <TREF>Church, 1988</TREF>; <REF>Ramshaw and Marcus, 1995</REF>; <REF>Argamon et al , 1998</REF>; <REF>Cardie and Pierce, 1998</REF>	1	 Research supported by NSF grants IIS-9801638 and SBR-9873450	0	t Research supported by NSF grant CCR-9502540	0	6	1
W02-0102	A88-1019	2002	HMMs have long been central in speech recognition <REF>Rabiner, 1989</REF>	0	Their application to partof-speech tagging <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF> kicked off the era of statistical NLP, and they have found additional NLP applications to phrase chunking, text segmentation, word-sense disambiguation, and information extraction	1	The algorithm is also important to teach for pedagogical reasons, as the entry point to a family of EM algorithms for unsupervised parameter estimation	0	Indeed, it is an instructive special case of 1 the inside-outside algorithm for estimation of probabilistic context-free grammars; 2 belief propagation for training singly-connected Bayesian networks and junction trees <REF>Pearl, 1988</REF>; <REF>Lauritzen, 1995</REF>; 3 algorithms for learning alignment models such as weighted edit distance; 4 general finitestate parameter estimation <REF>Eisner, 2002</REF>	0	6	1
H91-1037	A88-1019	1991	Subsequent analysis suggested that half the errors could be removed with only a little additional work, suggesting that over 90 performance is achievable	0	In a related test, we explored the bracketings produced by Churchs PARTS program <TREF>Church, 1988</TREF>	1	We extracted 200 sentences of WSJ text by taking every tenth sentence from a collection of manually corrected parse trees data from the TREEBANK Project at the University of Pennsylvania	0	We evaluated the NP bracketings in these 200 sentences by hand, and tried to classify the errors	0	6	1
P98-2208	A88-1019	1998	Given that each token has on the average more than 2 possible tags, the procedural description above is very inefficient for all but very short sentences	0	However, the observation that our constraints are localized to a window of a small number of tokens say at most 5 tokens in a sequence, suggests a more efficient scheme originally used by <TREF>Church 1988</TREF>	1	Assume our constraint windows are allowed to look at a window of at most size k sequential parses	0	Let us take the first k tokens of a sentence and generate all possible paths of k arcs spanning k  1 nodes, and apply all constraints to these short paths	0	1	2
P98-2208	A88-1019	1998	Part-of-speech tagging is one of the preliminary steps in many natural language processing systems in which the proper part-of-speech tag of the tokens comprising the sentences are disambiguated using either statistical or symbolic local contextual information	0	Tagging systems have used either a statistical approach where a large corpora is employed to train a probabilistic model which then is used to tag unseen text, eg , <TREF>Church 1988</TREF>, Cutting et al	1	1992, <REF>DeRose 1988</REF>, or a constraint-based approach which employs a large number of hand-crafted linguistic constraints that are used to eliminate impossible sequences or morphological parses for a given word in a given context, recently most prominently exemplified by the Constraint Grammar work <REF>Karlsson et al , 1995</REF>; <REF>Voutilainen, 1995b</REF>; <REF>Voutilainen et al , 1992</REF>; <REF>Voutilainen and Tapanainen, 1993</REF>	0	BriU 1992; 1994; 1995 has presented a transformationbased learning approach	0	6	1
J93-2004	A88-1019	1993	 Right close double quote 231 Automated Stage	0	During the early stages of the Penn Treebank project, the initial automatic POS assignment was provided by PARTS <TREF>Church 1988</TREF>, a stochastic algorithm developed at ATT Bell Labs	1	PARTS uses a modified version of the Brown Corpus tagset close to our own and assigns POS tags with an error rate of 3-5	0	The output of PARTS was automatically tokenized 8 and the tags assigned by PARTS were automatically mapped onto the Penn Treebank tagset	0	3	1
W96-0305	A88-1019	1996	Various methods for POS tagging have been proposed in recent years	0	For simplicity, we adapted the method proposed by <REF>Churchl1988</REF> to tag the definition sentence	1	In the second stage, we select the label which is associated with word lists most similar to the definition as the result	0	We sum up the above descriptions and outline the procedure for labeling a dictionary sense	0	3	1
P97-1030	A88-1019	1997	The experimental results show the proposed method significantly outperforms both hand-crafted and conventional statistical methods	0	The last few years have seen the great success of stochastic part-of-speech POS taggers <TREF>Church, 1988</TREF>: <REF>Kupiec, 1992</REF>; Charniak et M , 1993; <REF>Brill, 1992</REF>; <REF>Nagata, 1994</REF>	1	The stochastic approach generally attains 94 to 96 accuracy and replaces the labor-intensive compilation of linguistics rules by using an automated learning algorithm	0	However, 1NTT is an abbreviation of Nippon Telegraph and Telephone Corporation	0	1	2
P96-1008	A88-1019	1996	1	0	A recent trend in natural language processing has been toward a greater emphasis on statistical approaches, beginning with the success of statistical part-of-speech tagging programs <TREF>Church 1988</TREF>, and continuing with other work using statistical part-of-speech tagging programs, such as BBN PLUM <REF>Weischedel et al 1993</REF> and NYU Proteus <REF>Grishman and Sterling 1993</REF>	1	More recently, statistical methods have been applied to domain-specific semantic parsing <REF>Miller et al 1994</REF>, and to the more difficult problem of wide-coverage syntactic parsing <REF>Magerman 1995</REF>	0	Nevertheless, most natural language systems remain primarily rule based, and even systems that do use statistical techniques, such as ATT Chronus <REF>Levin and Pieraccini 1995</REF>, continue to require a significant rule based component	0	1	2
C96-2114	A88-1019	1996	The training is performed on ambiguity classes and not on individual word tokens	0	<REF>Kallgren 1996</REF> gives a more covering description of how XPOST is used on the Swedish material and also sketches the major differences between this algorithm and some others used for tagging, such as PARTS <TREF>Church 1988</TREF> and VOLSUNGA <REF>DeRose 1988</REF>	1	A characteristic tbature of the SUC is its high number of different tags	0	The number of part-ofspeech tags used in the SUC is 21	0	6	1
J02-3002	A88-1019	2002	Disambiguation of capitalized words is usually handled by POS taggers, which treat capitalized words in the same way as other categories, that is, by accounting for the immediate syntactic context and using estimates collected from a training corpus	0	<REF>As Church 1988</REF> rightly pointed out, however, Proper nouns and capitalized words are particularly problematic: some capitalized words are proper nouns and some are not	1	Estimates from the Brown Corpus can be misleading	0	For example, the capitalized word Acts is found twice in the Brown Corpus, both times as a proper noun in a title	0	1	2
C98-1060	A88-1019	1998	The morphological ambiguity will differ depending on the level of tagging used in each case, as shown in table 2	0	There are two kinds of methods for morphological disambiguation: on one hand, statistical methods need little effort and obtain very good results <TREF>Church, 1988</TREF>; Cutting el al, 1992, at least when applied to English, but when we try to apply them to Basque we encounter additional problems; on the other hand, some rule-based systems <REF>Brill, 1992</REF>; <REF>Voutilainen et al, 1992</REF> are at least as good as statistical systems and are better adapted to free-order languages and agglutinative languages	1	So, we 381 have selected one of each group: Constraint Grammar formalism <REF>Karlsson et al, 1995</REF> and the HMM based TATOO tagger <REF>Armstrong et al, 1995</REF>, which has been designed to be applied it to the output of a morphological analyser and the tagset can be switched easily without changing the input text	0	second  third 70 ks I M M MCG MCG Figure 1-Initial ambiguity3	0	1	2
H90-1055	A88-1019	1990	We are tagging this material with a much simpler tagset than used by previous projects, as discussed at the Oct 1989 DARPA Workshop	0	The material is first processed using Ken Churchs tagger <TREF>Church 1988</TREF>, which labels it as if it were Brown Corpus material, and then is mapped to our tagset by a SEDscript	1	Because of fundamental differences in tagging strategy between the Penn Treebank Project and the Brown project, the resulting mapping is about 9 inaccurate, given the tagging guidelines of the Penn Treebank project as given in 40 pages of explicit tagging guidelines	0	This material is then hand-corrected by our annotators; the result is consistent within annotators to about 3 cf	0	3	2
H90-1055	A88-1019	1990	H90-1055:17	0	Deducing Linguistic Structure from the Statistics of Large Corpora Eric Brill David Magerman Mitchell Marcus Beatrice Santorini Department of Computer and Information Science University of Pennsylvania Philadelphia, PA 19104 1 Introduction Within the last two years, approaches using both stochastic and symbolic techniques have proved adequate to deduce lexical ambiguity resolution rules with less than 3-4 error rate, when trained on moderate sized 500K word corpora of English text eg <TREF>Church, 1988</TREF>; <REF>Hindle, 1989</REF>	1	The success of these techniques suggests that much of the grammatical structure of language may be derived automatically through distributional analysis, an approach attempted and abandoned in the 1950s	0	We describe here two experiments to see how far purely distributional techniques can be pushed to automatically provide both a set of part of speech tags for English, and a grammatical analysis of free English text	0	3	2
H90-1055	A88-1019	1990	This line of research was motivated by a series of successful applications of mutual information statistics to other problems in natural language processing	0	In the last decade, research in speech recognition <REF>Jelinek 1985</REF>, noun classification <REF>Hindle 1988</REF>, predicate argument relations <REF>Church  Hanks 1989</REF>, and other areas have shown that mutual information statistics provide a wealth of information for solving these problems	1	22 Mutual Information Statistics The mutual information statistic <REF>Fano 1961</REF> is a measure of the interdependence of two signals in a message	0	It is a function of the probabilities of the two events: Mz, u  log u xzPvy In this paper, the events x and y will be part-of-speech n-grams instead of single parts-of-speech, as in some earlier work	0	4	2
W97-0902	A88-1019	1997	Each of these three steps will be described below	0	3 The preprocessing stage The noun phrase parser identifies simple non-recursive noun phrases such as DetAdjN or NN The method used for this process involves an algorithm of the type described in <TREF>Church 1988</TREF> which was trained on a manually marked part of our corpus	1	The module is thus geared to the particular type of second language text the checker needs to deal with	0	The resulting information is passed on to a preprocessing module consisting of a number of automata groups	0	3	1
P00-1015	A88-1019	2000	Measures/NNS of/IN manufacturing/VBG activity/NN fell/VBD more/RBR than/IN the/DT overall/JJ measures/NNS/	0	Figure 1: An example sentence with baseNP brackets A number of researchers have dealt with the problem of baseNP identification <TREF>Church 1988</TREF>; <REF>Bourigault 1992</REF>; <REF>Voutilainen 1993</REF>; <REF>Justeson  Katz 1995</REF>	1	Recently some researchers have made experiments with the same test corpus extracted from the 20 th section of the Penn Treebank Wall Street Journal Penn Treebank	0	<REF>Ramshaw  Markus 1998</REF> applied transformbased error-driven algorithm <REF>Brill 1995</REF> to learn a set of transformation rules, and using those rules to locally updates the bracket positions	0	6	1
P07-2053	A88-1019	2007	4 Concluding remarks Though there can be little doubt that the ruling system of bakeoffs actively encourages a degree of oneupmanship, our paper and our software are not offered in a competitive spirit	0	As we said at the out211 set, we dont necessarily believe HunPos to be in any way better than TnT, and certainly the main ideas have been pioneered by <REF>DeRose 1988</REF>, <TREF>Church 1988</TREF>, and others long before this generation of HMM work	1	But to improve the results beyond what a basic HMM can achieve one needs to tune the system, and progress can only be made if the experiments are end to end replicable	0	There is no doubt many other systems could be tweaked further and improve on our results what matters is that anybody could now also tweak HunPos without any restriction to improve the state of the art	0	1	2
P99-1009	A88-1019	1999	In this paper we describe experiments we performed to ascertain how well humans, given an annotated training set, can generate rules for base noun phrase chunking	0	Much previous work has been done on this problem and many different methods have been used: Churchs PARTS 1988 program uses a Markov model; <REF>Bourigault 1992</REF> uses heuristics along with a grammar; Voutilainens NP<REF>Tool 1993</REF> uses a lexicon combined with a constraint grammar; <REF>Juteson and Katz 1995</REF> use repeated phrases; <REF>Veenstra 1998</REF>, Argamon, Dagan  <REF>Krymolowski1998</REF> and Daelemaus, van den <REF>Bosch  Zavrel 1999</REF> use memory-based systems; Ramshaw  Marcus In Press and <REF>Cardie  Pierce 1998</REF> use rule-based systems	1	2 Learning Base Noun Phrases by Machine We used the base noun phrase system of Ramshaw and Marcus RM as the machine learning system with which to compare the human learners	0	It is difficult to compare different machine learning approaches to base NP annotation, since different definitions of base NP are used in many of the papers, but the RM system is the best of those that have been tested on the Penn Treebank	0	6	1
P91-1030	A88-1019	1991	The suggestion which we want to explore is that the association revealed by textual distribution whether its source is a complementation relation, a modification relation, or something else gives us information needed to resolve the prepositional attachment	0	Discovering Lexical Association in Text A 13 million word sample of Associated Press new stories from 1989 were automatically parsed by the Fidditch parser <REF>Hindle 1983</REF>, using Churchs part of speech analyzer as a preprocessor <TREF>Church 1988</TREF>	1	From the syntactic analysis provided by the parser for each sentence, we extracted a table containing all the heads of all noun phrases	0	For each noun phrase head, we recorded the following preposition if any occurred ignoring whether or not the parser attached the preposition to the noun phrase, and the preceding verb if the noun phrase was the object of that verb	0	3	1
J93-3003	A88-1019	1993	We also looked at whether the token constituted an entire intermediate or intonational phrase--possibly with other cue phrases--or not, and what each tokens position within its intermediate phrase and larger intonational phrase was--first-inphrase again, including tokens preceded only by other cue phrases as well as tokens that were absolutely first in intermediate phrase, last, or other	0	We also examined each items part of speech, using Churchs 1988 part-of-speech tagger	1	Finally, we investigated orthographic features of the transcript that might be associated with a discourse/sentential distinction, such as immediately preceding and succeeding punctuation and paragraph boundaries	0	In both the syntactic and orthographic analyses we were particularly interested in discovering how successful nonprosodic features that might be obtained automatically from a text would be in differentiating discourse from sentential uses	0	3	1
J93-3003	A88-1019	1993	While the use of orthographic and part-of-speech data represents only a fractional improvement over orthographic information alone, it is possible that, since the latter is not subject to transcriber idiosyncracy, such an approach may prove more reliable than orthography alone in the general case	0	And, for text-to-speech applications, it 7 The parbof-speech tagger employed in this analysis <TREF>Church 1988</TREF> uses a subset of the part-of-speech tags used in Francis and Kuera 1982	1	We have translated these for Table 12	0	Note that intensifier corresponds to QU in Francis and Kuera 1982	0	3	1
W97-0110	A88-1019	1997	Research on corpus-based natural language learning and processing is rapidly accelerating following the introduction of large on-line corpora, faster computers, and cheap storage devices	0	Recent work involves novel ways to employ annotated corpus in part of speech tagging <TREF>Church 1988</TREF> <REF>Derose 1988</REF> and the application of mutual information statistics on the corpora to uncover lexical information <REF>Church 1989</REF>	1	The goal of the research is the construction of robust and portable natural language processing systems	0	The wide range of topics available on the Internet calls for an easily adaptable information extraction system for different domains	0	6	1
C96-1041	A88-1019	1996	Part-of-speech tagging is to assign the correct tag to each word in the context of the sentence	0	here are three main approaches in tagging problem: rule-based approach Klein and Simmons 13; <REF>Brodda 1982</REF>; <REF>Paulussen and Martin 1992</REF>; <REF>Brill et al 1990</REF>, statistical approach Church :1988; <REF>Merialdo 1994</REF>; <REF>Foster 1991</REF>; <REF>Weischedel et al 1993</REF>; <REF>Kupiec 1992</REF> and connectionist approach <REF>Benello et al 1989</REF>; <REF>Nakanmra et al 1989</REF>	1	In these approaches, statistical approach has the following advantages :  a theoretical framework is provided  automatic learning facility is provided  the probabilities provide a straightforward way to disambiguate Many information sources must be combined to solve tagging problem with statistical approach	0	It is a significant assumption that tire correct tag can generally be chosen from Ihe local context	0	6	1
P96-1041	A88-1019	1996	In this study, we measure performance solely through the cross-entropy of test data; it would be interesting to see how these cross-entropy differences correlate with performance in end applications such as speech recognition	0	In addition, it would be interesting to see whether these results extend to fields other than language modeling where smoothing is used, such as prepositional phrase attachment <REF>Collins and Brooks, 1995</REF>, part-of-speech tagging <TREF>Church, 1988</TREF>, and stochastic parsing <REF>Magerman, 1994</REF>	1	317 Acknowledgements The authors would like to thank Stuart Shieber and the anonymous reviewers for their comments on previous versions of this paper	0	We would also like to thank William Gale and Geoffrey Sampson for supplying us with code for Good-Turing frequency estimation without tears	0	6	1
P96-1041	A88-1019	1996	In addition, we introduce two novel smoothing techniques, one a variation of Jelinek-Mercer smoothing and one a very simple linear interpolation technique, both of which outperform existing methods	0	Smoothing is a technique essential in the construction of n-gram language models, a staple in speech recognition <REF>Bahl, Jelinek, and Mercer, 1983</REF> as well as many other domains <TREF>Church, 1988</TREF>; <REF>Brown et al , 1990</REF>; <REF>Kernighan, Church, and Gale, 1990</REF>	1	A language model is a probability distribution over strings Ps that attempts to reflect the frequency with which each string s occurs as a sentence in natural text	0	Language models are used in speech recognition to resolve acoustically ambiguous utterances	0	6	1
P98-2123	A88-1019	1998	In practice, computational limitations do not allow the enumeration of all possible assignments for long sentences, and smoothing is required for infrequent events	1	This is described in more detail in the original publication <TREF>Church, 1988</TREF>	0	Although more sophisticated algorithms for unsupervised learning which can be trained on plain text instead on manually tagged corpora are well established see eg <REF>Merialdo, 1994</REF>, we decided not to use them	0	The main reason is that with large tag sets, the sparse-data-problem can become so severe that unsupervised training easily ends up in local minima, which can lead to poor results without any indication to the user	0	1	3
P98-2123	A88-1019	1998	<REF>Lezius, Rapp  Wettler 1996</REF> give an overview on some German tagging projects	0	Although we considered a number of algorithms, we decided to use the trigram algorithm described by <TREF>Church 1988</TREF> for tagging	1	It is simple, fast, robust, and among the statistical taggers still more or less unsurpassed in terms of accuracy	0	Conceptually, the Church-algorithm works as follows: For each sentence of a text, it generates all possible assignments of part-of-speech tags to words	0	3	1
J99-2004	A88-1019	1999	A more detailed discussion of LTAGs with an example and some of the key properties of elementary trees is presented in Appendix A 4	0	Supertags Part-of-speech disambiguation techniques POS taggers <TREF>Church 1988</TREF>; <REF>Weischedel et al 1993</REF>; <REF>Brill 1993</REF> are often used prior to parsing to eliminate or substantially reduce the part-of-speech ambiguity	1	The POS taggers are all local in the sense that they use information from a limited context in deciding which tags to choose for each word	0	As is well known, these taggers are quite successful	0	6	1
J99-2004	A88-1019	1999	We tested the performance of the unigram model on the previously discussed two sets of data	0	The words are first assigned standard parts of speech using a conventional tagger <TREF>Church 1988</TREF> and then are assigned supertags according to the unigram model	1	A word in a sentence is considered correctly supertagged if it is assigned the same supertag as it is associated with in the correct parse of the sentence	0	The results of these experiments are tabulated in Table 4	0	3	1
W00-0721	A88-1019	2000	Some external mechanism is assumed to consistently or stochastically annotate substrings as phrases 2	0	Our goal is to come up with a mechanism that, given an input string, identifies the phrases in this string, this is a fundamental task with applications in natural language <TREF>Church, 1988</TREF>; <REF>Ramshaw and Marcus, 1995</REF>; <REF>Mufioz et al , 1999</REF>; <REF>Cardie and Pierce, 1998</REF>	1	The identification mechanism works by using classifiers that process the input string and recognize in the input string local signals which  This research is supported by NSF grants IIS-9801638, SBR-9873450 and IIS-9984168	0	1Full version is in <REF>Punyakanok and Roth, 2000</REF>	0	6	1
C00-1046	A88-1019	2000	Much research has been donc Oll knowledge acquisition fiom large-scalc annotated corpora as a rich source of linguistic knowledge	0	Mtior works done to create English POS taggers henceforth, taggers, for example, include <TREF>Church 1988</TREF>, <REF>Kupicc 1992</REF>, <REF>Brill 1992</REF>and <REF>Voutilaincn et al 1992</REF>	0	The problem with this framework, however, is that such reliable corpora are hardly awdlable duc to a huge amount of the labor-intensive work required	1	In case of the acquisition of non-core knowledge, such as specific, lexically or dolnain dependent knowledge, preparation of annotated corpora becomes more serious problem	0	1	3
W96-0209	A88-1019	1996	2	0	PART:OF-SPEECH TAG SEQUENCE GRAMMAR We utilised the ANLT metagrammatical formalism to develop a feature-based, declarative description of part-of-speech PoS label sequences see eg <TREF>Church, 1988</TREF> for English	1	This grammar compiles into a DCG-like grammar of approximately 400 rules	0	It has been designed to enumerate possible valencies for predicates verbs, adjectives and nouns by including separate rules for each pattern of possible complementation in English	0	6	1
N03-1035	A88-1019	2003	But dictionaries of technical terminology have many one-word terms	0	Simplex or complex NPs eg , <TREF>Church 1988</TREF>; <REF>Hindle and Rooth 1991</REF>; <REF>Wacholder 1998</REF> identify simplex or base NPs  NPs which do not have any component NPs -at least in part because this bypasses the need to solve the quite difficult attachment problem, ie, to determine which simpler NPs should be combined to output a more complex NP	0	But if people find complex NPs more useful than simpler ones, it is important to focus on improvement of techniques to reliably identify more complex terms	1	Semantic and syntactic terms variants	0	1	3
J00-4004	A88-1019	2000	As described in Section 3, each indicator has a unique value for each verb, which corresponds to the frequency of the aspectual marker with the verb except verb frequency, which is an absolute measure over the corpus	0	6 Similar baselines for comparison have been used for many classification problems <REF>Duda and Hart 1973</REF>, eg, part-of-speech tagging <TREF>Church 1988</TREF>; <REF>Allen 1995</REF>	1	611 Computational Linguistics Volume 26, Number 4 The second and third columns of Table 9 show the average value for each indicator over stative and event clauses, as measured over the training examples which exclude be and have	0	These values are computed solely over the 739 training cases in order to avoid biasing the classification experiments in the sections below, which are evaluated over the unseen test cases	0	6	1
J97-3003	A88-1019	1997	To assign capitalized unknown words the category proper noun seems a good heuristic, but may not always work	0	As argued in <TREF>Church 1988</TREF>, who proposes a more elaborated heuristic, <REF>Dermatas and Kokkinakis 1995</REF> proposed a simple probabilistic approach to unknown-word guessing: HCRC, Language Technology Group, University of Edinburgh, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, UK	1	Q 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 3 Table 1 The most frequent open-class tags from the Penn tag set	0	Tag Meaning Example Tag Meaning Example NN common noun table NNS noun plural tables NNP proper noun John NNPS plural proper noun Vikings JJ adjective green RB adverb naturally VB verb base form take VBD verb past took VBG gerund taking VBN past participle taken VBZ verb present, 3d person takes VBP verb, present, non-3d take the probability that an unknown word has a particular Pos-tag is estimated from the probability distribution of hapax words words that occur only once in the previously seen texts	0	6	1
J97-3003	A88-1019	1997	Although our primary goal was not to compare the taggers themselves but rather their performance with the guessing components, we attribute the difference in their performance to the fact that Brills tagger uses the information about the most likely tag for a word whereas the HMM tagger did not have this information and instead used the priors for a set of POS-tags ambiguity class	0	When we removed from the lexicon all the hapax words and, following the recommendation of <TREF>Church 1988</TREF>, all the capitalized words with frequency less than 20, we obtained some 51,522 unknown word-tokens 25,359 wordtypes out of more than a million word-tokens in the Brown Corpus	1	We tagged the fifteen subcorpora of the Brown Corpus by the four combinations of the taggers and the guessers using the lexicon of 22,260 word-types	0	42 Results of the Experiment Table 4 displays the tagging results on the unknown words obtained by the four different combinations of taggers and guessers	0	3	1
N06-1042	A88-1019	2006	In the 329 rule-based approach a large number of hand crafted rules are used to select the correct morphological parse or POS tag of a given word in a given context <REF>Karlsson et al , 1995</REF>; Oflazer and Tcurrency1ur, 1997	0	In the statistical approach a hand tagged corpus is used to train a probabilistic model which is then used to select the best tags in unseen text <TREF>Church, 1988</TREF>; Hakkani-Tcurrency1ur et al , 2002	1	Examples of statistical and machine learning approaches that have been used for tagging include transformation based learning <REF>Brill, 1995</REF>, memory based learning <REF>Daelemans et al , 1996</REF>, and maximum entropy models <REF>Ratnaparkhi, 1996</REF>	0	It is also possible to train statistical models using unlabeled data with the expectation maximization algorithm <REF>Cutting et al , 1992</REF>	0	6	1
P97-1023	A88-1019	1997	After presenting our results and evaluation, we discuss simulation experiments that show how our method performs under different conditions of sparseness of data	0	3 Data Collection For our experiments, we use the 21 million word 1987 Wall Street Journal corpus 4, automatically annotated with part-of-speech tags using the PARTS tagger <TREF>Church, 1988</TREF>	1	In order to verify our hypothesis about the orientations of conjoined adjectives, and also to train and evaluate our subsequent algorithms, we need a 3Certain words inflected with negative affixes such as inor un- tend to be mostly negative, but this rule applies only to a fraction of the negative words	0	Furthermore, there are words so inflected which have positive orientation, eg, independent and unbiased	0	3	1
C00-1044	A88-1019	2000	For example, ve O, dead can be used tkr emphasis, and relet am relet as in her lhce became redder and redder can be used to indicate a progression of coloring, qb distinguish between truly gradablc adjectives and non-gradable adjectives in these exceptional contexts, we have developed a trainable log-linear statistical model that lakes into account tile number of times an adiective has been observed in a form or context indicating gradability relative to the number of limes it has been seen in non-gradable contexts	0	We use a shallow parser to retrieve from a large corpus tagged for part-of-speech with Churchs PARTS tagger <TREF>Church, 1988</TREF> all adjectives and their modifiers	1	Although the most common use of an adverb modifying an adjective is to function as an intensilier or diminisher <REF>Quirk et al , 1985</REF>, p 445, adverbs can also add to tile semantic content of the adjectival phrase instead of providing a grading effect eg , immediately available, politically vuhmrable, or function as cmphasizers, adding to the force o1 tile base adjective and not lo its degree eg , virtually impossible; compare re O, impossible	0	Therefore, we compiled by hand a list of 73 adverbs and noun phrases such as a little, exceedingly, somewhat, and veo that are fiequently used as grading moditicrs	0	3	1
P96-1010	A88-1019	1996	More precisely, assume that the word wh occurs in a sentence W  wlWkwn, and that w is a word we are considering substituting for it, yielding sentence W I Word w is then preferred over wk iff PW > PW, where PW and PW are the probabilities of sentences W and W f respectively	0	1 We calculate PW using the tag sequence of W as an intermediate quantity, and summing, over all possible tag sequences, the probability of the sentence with that tagging; that is: PW   PW, T T where T is a tag sequence for sentence W The above probabilities are estimated as is traditionally done in trigram-based part-of-speech tagging <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF>: PW,T  PWITPT  1  HPwiti HPt, lt,2t,l2 i i where T  tltn, and Ptitl-2ti-1 is the prob ability of seeing a part-of-speech tag tl given the two preceding part-of-speech tags ti-2 and ti-1	1	Equations 1 and 2 will also be used to tag sentences W and W  with their most likely part-of-speech sequences	0	This will allow us to determine the tag that 1To enable fair comparisons between sequences of different length as when considering maybe and may be, we actually compare the per-word geometric mean of the sentence probabilities	0	6	1
E95-1022	A88-1019	1995	Its recall is very high 997 of all words receive the correct morphological analysis, but this system leaves 3-7 of all words ambiguous, trading precision for recall	0	157 ena or the linguists abstraction capabilities eg knowledge about what is relevant in the context, they tend to reach a 95-97 accuracy in the analysis of several languages, in particular English <REF>Marshall 1983</REF>; Black et aL 1992; <TREF>Church 1988</TREF>; <REF>Cutting et al 1992</REF>; de <REF>Marcken 1990</REF>; <REF>DeRose 1988</REF>; <REF>Hindle 1989</REF>; <REF>Merialdo 1994</REF>; <REF>Weischedel et al 1993</REF>; <REF>Brill 1992</REF>; <REF>Samuelsson 1994</REF>; Eineborg and Gambick 1994, etc	1	Interestingly, no significant improvement beyond the 97 barrier by means of purely data-driven systems has been reported so far	0	In terms of the accuracy of known systems, the data-driven approach seems then to provide the best model of part-of-speech distribution	0	6	1
C98-1034	A88-1019	1998	Figure 1: Base NP Examples base noun phrases with initial determiners and modifiers removed: <REF>Justeson  Katz 1995</REF> look for repeated phrases; <REF>Bourigault 1992</REF> uses a handcrafted noun phrase grammar in conjunction with heuristics for finding maximal length noun phrases; Voutilainens NP<REF>Tool 1993</REF> uses a handcrafted lexicon and constraint grammar to find terminological noun phrases that include phrase-final prepositional phrases	0	Churchs PARTS program 1988, on the other hand, uses a probabilistic model automatically trained on the Brown corpus to locate core noun phrases as well as to assign parts of speech	1	More recently, Ramshaw  Marcus In press apply transformation-based learning <REF>Brill, 1995</REF> to the problem	0	Unfortunately, it is difficult to directly compare approaches	0	6	1
A00-1026	A88-1019	2000	1993 call the core noun phrase, that is a noun phrase with no modification to the right of the head	0	Several approaches provide similar output based on statistics <TREF>Church 1988</TREF>, <REF>Zhai 1997</REF>, for example, a finite-state machine <REF>AitMokhtar and Chanod 1997</REF>, or a hybrid approach combining statistics and linguistic rules <REF>Voutilainen and Padro 1997</REF>	1	The SPECIALIST parser is based on the notion of barrier words <REF>Tersmette et al 1988</REF>, which indicate boundaries between phrases	0	After lexical look-up and resolution of category label ambiguity by the Xerox tagger, complementizers, conjunctions, modals, prepositions, and verbs are marked as boundaries	0	6	1
W00-0737	A88-1019	2000	Finally, memory-based learning is adopted to further improve the performance of the chunk tagger	0	The idea of using statistics for chunking goes back to <TREF>Church1988</TREF>, who used corpus frequencies to determine the boundaries of simple nonrecursive noun phrases	1	Skut and <REF>Brants1998</REF> modified Churchs approach in a way permitting efficient and reliable recognition of structures of limited depth and encoded the structure in such a way that it can be recognised by a Viterbi tagger	0	Our approach follows Skut and Brants way by employing HMM-based tagging method to model the chunking process	0	6	1
W00-1320	A88-1019	2000	Thus, Examples 3-5 illustrate how the syntactic context of a word can help determine its meaning	0	22 Motivation from previous work 221 Parsing In recent years, the success of statistical parsing techniques can be attributed to several factors, such as the increasing size of computing machinery to accommodate larger models, the availability of resources such as the Penn Treebank <REF>Marcus et al , 1993</REF> and the success of machine learning techniques for lowerlevel NLP problems, such as part-of-speech tagging <TREF>Church, 1988</TREF>; <REF>Brill, 1995</REF>, and PPattachment <REF>Brill and Resnik, 1994</REF>; <REF>Collins and Brooks, 1995</REF>	1	However, perhaps even more significant has been the lexicalization of the grammar formalisms being probabilistically modeled: crucially, all the recent, successful statistical parsers have in some way made use of bilexical dependencies	0	This includes both the parsers that attach probabilities to parser moves <REF>Magerman, 1995</REF>; <REF>Ratnaparkhi, 1997</REF>, but also those of the lexicalized PCFG variety <REF>Collins, 1997</REF>; <REF>Charniak, 1997</REF>	0	1	2
W01-0706	A88-1019	2001	to  NP only  18 billion  PP in  NP September  While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information  by examining the pattern itself, its nearby context and the local part-of-speech information	0	Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <REF>Collins, 1997</REF>; <REF>Charniak, 1997a</REF>; <REF>Charniak, 1997b</REF>; <REF>Ratnaparkhi, 1997</REF>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns  syntactic phrases or words that participate in a syntactic relationship <TREF>Church, 1988</TREF>; <REF>Ramshaw and Marcus, 1995</REF>; <REF>Argamon et al , 1998</REF>; <REF>Cardie and Pierce, 1998</REF>; <REF>Munoz et al , 1999</REF>; <REF>Punyakanok and Roth, 2001</REF>; <REF>Buchholz et al , 1999</REF>; Tjong <REF>Kim Sang and Buchholz, 2000</REF>	1	Research on shallow parsing was inspired by psycholinguistics arguments <REF>Gee and Grosjean, 1983</REF> that suggest that in many scenarios eg , conversational full parsing is not a realistic strategy for sentence processing and analysis, and was further motivated by several arguments from a natural language engineering viewpoint	0	First, it has been noted that in many natural language applications it is sufficient to use shallow parsing information; information such as noun phrases NPs and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization <REF>Grishman, 1995</REF>; <REF>Appelt et al , 1993</REF>	0	6	1
J00-3003	A88-1019	2000	33 Dialogue Act Decoding The HMM representation allows us to use efficient dynamic programming algorithms to compute relevant aspects of the model, such as  the most probable DA sequence the Viterbi algorithm  the posterior probability of various DAs for a given utterance, after considering all the evidence the forward-backward algorithm The Viterbi algorithm for HMMs <REF>Viterbi 1967</REF> finds the globally most probable state sequence	0	When applied to a discourse model with locally decomposable likelihoods and Markovian discourse grammar, it will therefore find precisely the DA 348 Stolcke et al Dialogue Act Modeling sequence with the highest posterior probability: U  argmaxPUIE  4 u The combination of likelihood and prior modeling, HMMs, and Viterbi decoding is fundamentally the same as the standard probabilistic approaches to speech recognition <REF>Bahl, Jelinek, and Mercer 1983</REF> and tagging <TREF>Church 1988</TREF>	1	It maximizes the probability of getting the entire DA sequence correct, but it does not necessarily find the DA sequence that has the most DA labels correct <REF>Dermatas and Kokkinakis 1995</REF>	0	To minimize the total number of utterance labeling errors, we need to maximize the probability of getting each DA label correct individually, ie, we need to maximize PUilE for each i  1  n We can compute the per-utterance posterior DA probabilities by summing: PuE  E PUIE 5 U: Uiu where the summation is over all sequences U whose ith element matches the label in question	0	6	1
J98-1003	A88-1019	1998	Various methods for POS tagging have been proposed in recent years	0	For simplicity, we adopted the method proposed by <TREF>Church 1988</TREF> to tag definition sentences	1	Experiments indicated an average error rate for tagging of less than 10	0	Tagging errors have limited negative impact, because words in the LLOCE are organized primarily according to topic, not part of speech	0	3	1
P94-1041	A88-1019	1994	I think we I need l to uh I I I need l r I m I et I r m I Algorithm Our algorithm for labeling potential repair patterns encodes the assumption that speech repairs can be processed one at a time	0	The algorithm runs in lockstep with a part-of-speech tagger <TREF>Church, 1988</TREF>, which is used for deciding possible word replacements	1	Words are fed in one at a time	0	The detection clues are checked first	0	3	1
P94-1041	A88-1019	1994	7About half of the difference between the detection recall rate and the correction recall rate is due to abridged repairs being misclassified as modification repairs	0	299 Part-of-speech tagging is the process of assigning to a word the category that is most probable given the sentential context <TREF>Church, 1988</TREF>	1	The sentential context is typically approximated by only a set number of previous categories, usually one or two	0	Good part-of-speech results can be obtained using only the preceding category <REF>Weischedel et al , 1993</REF>, which is what we will be using	0	6	1
A92-1020	A88-1019	1992	Recent research advances may lead to the development of viable book indexing methods for Chinese books	0	These include the availability of efficient and high precision word segmentation methods for Chinese text <REF>Chang et al , 1991</REF>; <REF>Sproat and Shih, 1990</REF>; <REF>Wang et al , 1990</REF>, the availability of statistical analysis of a Chinese corpus <REF>Liu et al , 1975</REF> and large-scale electronic Chinese dictionaries with partof-speech information <REF>Chang et al , 1988</REF>; BDC, 1992, the corpus-based statistical part-of-speech tagger <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF>; <REF>Beale, 1988</REF>, as well as phrasal and clausal analyzers <TREF>Church 1988</TREF>; <REF>Ejerhed 1990</REF> 2	1	Problem description As being pointed out in <REF>Salton, 1988</REF>, back-of-book indexes may consist of more than one word that are derived from a noun phrase	0	Given the text of a book, an indexing system, must perform some kind of phrasal and statistical analysis in order to produce a list of candidate indexes and their occurrence statistics in order to generate indexes as shown in Figure 1 which is an excerpt from the reconstruction of indexes of a book on transformational grammar for Mandarin Chinese <REF>Tang, 1977</REF>	0	1	2
W95-0107	A88-1019	1995	NPtool parse Apparent correct parse less time less time the other hand the other hand many advantages many advantages bnary addressing binary addressing and and instruction formats instruction formats a purely binary computer a purely binary computer Table 1: Apparent errors made by Voutilainens N<REF>Ptool Kupiec 1993</REF> also briefly mentions the use of finite state NP recognizers for both English and French to prepare the input for a program that identified the correspondences between NPs in bilingual corpora, but he does not directly discuss their performance	0	Using statistical methods, Churchs Parts program 1988, in addition to identifying parts of speech, also inserted brackets identifying core NPs	1	These brackets were placed using a statistical model trained on Brown corpus material in which NP brackets had been inserted semi-automatically	0	In the small test sample shown, this system achieved 98 recall for correct brackets	0	3	1
W95-0107	A88-1019	1995	In the small test sample shown, this system achieved 98 recall for correct brackets	0	At about the same time, <REF>Ejerhed 1988</REF>, working with Church, performed comparisons between finite state methods and Churchs stochastic models for identifying both non-recursive clauses and non-recursive NPs in English text	1	In those comparisons, the stochastic methods outperformed the hand built finite-state models, with claimed accuracies of 935 clauses and 986 NPs for the statistical models compared to to 87 clauses and 978 NPs for the finite-state methods	0	Running Churchs program on test material, however, reveals that the definition of NP embodied in Churchs program is quite simplified in that it does not include, for example, structures or words conjoined within NP by either explicit conjunctions like and and or, or implicitly by commas	0	6	1
J94-1002	A88-1019	1994	They consider a range of input variables, including textderived information such as detailed POS labels and syntactic constituent structure, and in some experiments, acoustic information	0	POS labels were given by Churchs tagger <TREF>Church 1988</TREF> and syntactic constituents by Hindles parser <REF>Hindle 1987</REF>	1	The acoustic information previous boundary location, pitch accent location, and phrase duration, which was based on hand-labeled prosodic markers, did not improve performance but resulted in a much smaller tree for prediction	0	All of these approaches have influenced the model proposed here	0	3	1
J96-1001	A88-1019	1996	These tools can then be used by other systems to address more complex tasks	0	For example, previous work has addressed low-level tasks such as tagging a free-style corpus with part-of-speech information <TREF>Church 1988</TREF>, aligning a bilingual corpus <REF>Gale and Church 1991b</REF>; <REF>Brown, Lai, and Mercer 1991</REF>, and producing a list of collocations <REF>Smadja 1993</REF>	1	While each of these tools is based on simple statistics and tackles elementary tasks, we have demonstrated with our work on Champollion that by combining them, one can reach new levels of complexity in the automatic treatment of natural languages	0	Acknowledgments This work was supported jointly by the Advanced Research Projects Agency and the Office of Naval Research under grant N00014-89-J-1782, by the Office of Naval Research under grant N00014-95-1-0745, by the National Science Foundation under grant GER-90-24069, and by the New York State Science and Technology Foundation under grants NYSSTF-CAT91-053 and NYSSTF-CAT94-013	0	6	1
W94-0107	A88-1019	1994	The parser will eventually disambiguate all the descriptions and pick one per object, for a given reading of the sentence	0	This is what the parser is expected to do for disambiguating the standard POS, unless a separate POS disambiguation module is used <TREF>Church, 1988</TREF>	1	Many parsers, including XTAG, use such a module alhd a POS tagger	0	LTAGs present a novel opportunity to reduce the amount of disambiguation done by the parser	0	6	1
W97-0201	A88-1019	1997	Much recent research in the field of natural language processing NLP has focused on an empirical, corpus-based approach <REF>Church and Mercer, 1993</REF>	0	The high accuracy achieved by a corpus-based approach to part-of-speech tagging and noun phrase parsing, as demonstrated by <TREF>Church, 1988</TREF>, has inspired similar approaches to other problems in natural language processing, including syntactic parsing and word sense disambiguation WSD	1	The availability of large quantities of part-ofspeech tagged and syntactically parsed sentences like the Penn Treebank corpus <REF>Marcus, Santorini, and Marcinkiewicz, 1993</REF> has contributed greatly to the development of robust, broad coverage partof-speech taggers and syntactic parsers	0	The Penn Treebank corpus contains a sufficient number of partof-speech tagged and syntactically parsed sentences to serve as adequate training material for building broad coverage part-of-speech taggers and parsers	0	1	2
H90-1069	A88-1019	1990	One method of handling large vocabularies is simply increasing the size of the lexicon	0	Research efforts at IBM Chodorow, et al 1988; Neff, et al 1989, Bell Labs Church, et al 1989, New Mexico State University <REF>Wilks 1987</REF>, and elsewhere have used mechanical processing of on-line dictionaries to infer at least minimal syntactic and semantic information from dictionary definitions	0	However, even assuming a very large lexicon already exists, it can never be complete	1	Systems aiming for coverage of unrestricted language in broad domains must continually deal with new words and novel word senses	0	1	3
J96-2003	A88-1019	1996	In order to make these improvements, we need access to word-class information Pos information <REF>Johansson et al 1986</REF>; <REF>Black, Garside, and Leech 1993</REF> or semantic information <REF>Beckwith et al 1991</REF>, which is usually obtained in three main ways: Firstly, we can use corpora that have been manually tagged by linguistically informed experts <REF>Derouault and Merialdo 1986</REF>	0	Secondly, we can construct automatic part-ofspeech taggers and process untagged corpora <REF>Kupiec 1992</REF>; <REF>Black, Garside, and Leech 1993</REF>; this method boasts a high degree of accuracy, although often the construction of the automatic tagger involves a bootstrapping process based on a core corpus which has been manually tagged <TREF>Church 1988</TREF>	1	The third option is to derive a fully automatic word-classification system from untagged corpora	0	Some advantages of this last approach include its applicability to any natural language for which some corpus exists, independent of the degree of development of its grammar, and its parsimonious commitment to the machinery of modern linguistics	0	1	3
W06-1701	A88-1019	2006	If an external resource is used in the form of a morphological analyzer MA, this will almost always overgenerate, yielding false ambiguity	0	But even if the MA is tight, a considerable proportion of ambiguous tokens will come from legitimate but rare analyses of frequent types <TREF>Church, 1988</TREF>	1	For example the word nem, can mean both not and gender, so both ADV and NOUN are valid analyses, but the adverbial reading is about five orders of magnitude more frequent than the noun reading, 12596 vs 4 tokens in the 1 m word manually annotated Szeged Korpusz <REF>Csendes et al , 2004</REF>	0	Thus the difficulty of the task is better measured by the average information required for disambiguating a token	0	6	3
N03-1033	A88-1019	2003	Almost all approaches to sequence problems such as partof-speech tagging take a unidirectional approach to conditioning inference along the sequence	0	Regardless of whether one is using HMMs, maximum entropy conditional sequence models, or other techniques like decision trees, most systems work in one direction through the sequence normally left to right, but occasionally right to left, eg, <TREF>Church 1988</TREF>	1	There are a few exceptions, such as Brills transformation-based learning <REF>Brill, 1995</REF>, but most of the best known and most successful approaches of recent years have been unidirectional	0	Most sequence models can be seen as chaining together the scores or decisions from successive local models to form a global model for an entire sequence	0	6	1
E95-1003	A88-1019	1995	Part-of-speech tagging is required to detect new terms formed through conversion	0	This is quite feasible using statistical taggers like those of <REF>Garside 1987</REF>, <TREF>Church 1988</TREF> or <REF>Foster 1991</REF> which achieve performance upwards of 97 on unrestricted text	1	Terms formed through semantic drift are the wolves in sheeps clothing stealing through terminological pastures	0	They are well enough conceMcd to allude at times even the human reader and no automatic term-recognition system has attempted to distinguish such terms, despite the prevalence ofpolysemy in such fields as the social sciences Riggs, 1993 and the importance for purposes of terminological standardization that deviant usage be tracked	0	1	2
H94-1034	A88-1019	1994	4	0	Partof-Speech Tagging Part-of-speech tagging is the process of assigning to a word the category that is most probable given the sentential context <TREF>Church, 1988</TREF>	1	The sentential context is typically approximated by only a set number of previous categories, usually one or two	0	Since the context is limited, we are making the Markov assumption, that the next transition depends only on the input, which is the word that we the following changes: 1 we -parated Weposifiom from subordinating conjunctions; 2 we separated uses of to as a preposition from in me as part of a to-infinilive; 3 rather than classify verbs by tense, we classified them into four groups, conjugations of be, conjugations of have, verbs that are followed by a to-infinitive, and verbs that are followed immediately by another verb	0	6	1
W00-1201	A88-1019	2000	On sentences with <40 words, the former model performs at 69 precision, 75 recall, and the latter at 77 precision and 78 recall	0	Ever since the success of HMMs application to part-of-speech tagging in <TREF>Church, 1988</TREF>, machine learning approaches to natural language processing have steadily become more widespread	1	This increase has of course been due to their proven efficacy in many tasks, but also to their engineering effiCacy	0	Many machine learning approaches let the data speak for itself data ipsa loquuntur, as it were, allowing the modeler to focus on what features of the data are important, rather than on the complicated interaction of such features, as had often been the case with hand-crafted NLP systems	0	1	2
A00-2013	A88-1019	2000	In conclusion, we argue strongly that the use of an independent morphological dictionary is the preferred choice to more annotated data under such circumstances	0	1 Full Morphological Tagging English Part of Speech POS tagging has been widely described in the recent past, starting with the <TREF>Church, 1988</TREF> paper, followed by numerous others using various methods: neural networks <REF>Julian Benello and Anderson, 1989</REF>, HMM tagging <REF>Merialdo, 1992</REF>, decision trees <REF>Schmid, 1994</REF>, transformation-based error-driven learning <REF>Brill, 1995</REF>, and maximum entropy <REF>Ratnaparkhi, 1996</REF>, to select just a few	1	However different the methods were, English dominated in these tests	0	Unfortunately, English is a morphologically impoverished language: there are no complicated agreement relations, word order variation is minireal, and the morphological categories are either extremely simple -s for plural of nouns, for example, or almost nonexistent cases expressed by inflection, for example with not too many exceptions and irregularities	0	6	1
H90-1052	A88-1019	1990	The suggestion which we want to explore is that the association revealed by textual distribution whether its source is a complementation relation, a modification relation, or something else gives us information needed to resolve the prepositional attachment	0	Discovering Lexical Association in Text A 13 million word sample of Associated Press new stories from 1989 were automatically parsed by the Fidditch parser <REF>Hindle 1983</REF>, using Churchs part of speech analyzer as a preprocessor <TREF>Church 1988</TREF>	1	From the syntactic analysis provided by the parser for each sentence, we extracted a table containiffg all the heads of all noun phrases	0	For each noun phrase head, we recorded the following preposition if any occurred ignoring whether or not the parser attached the preposition to the noun phrase, and the preceding verb if the noun phrase was the object of that verb	0	3	1
P97-1059	A88-1019	1997	460 of this data has an impact on the tagging accuracy of both the HMM itself and the derived transducer	0	The training of the HMM can be done on either a tagged or untagged corpus, and is not a topic of this paper since it is exhaustively described in the literature <REF>Bahl and Mercer, 1976</REF>; <TREF>Church, 1988</TREF>	1	An HMM can be identically represented by a weighted FST in a straightforward way	0	We are, however, interested in non-weighted transducers	0	6	1
W00-0726	A88-1019	2000	In the early nineties, <REF>Abney 1991</REF> proposed to approach parsing by starting with finding related chunks of words	0	By then, <TREF>Church 1988</TREF> had already reported on recognition of base noun phrases with statistical methods	1	<REF>Ramshaw and Marcus 1995</REF> approached chunking by using a machine learning method	0	Their work has inspired many others to study the application of learning methods to noun phrase chunking 5	0	6	1
C00-2141	A88-1019	2000	Realizing the difficulties o1 complete parsing, many researches turned to explore the partial parsing techniques	0	<TREF>Church1988</TREF> proposed a silnple stochastic technique for lecognizing the non-recursive base noun phrases in English	1	;outilaimen1993 designed an English noun phrase recognition tool -- NPTbol	0	<REF>Abney1997</REF> applied both rule-based and statistics-based approaches for parsing chunks in English	0	6	1
W96-0102	A88-1019	1996	Several approaches have been proposed to construct automatic taggers	0	Most work on statistical methods has used n-gram models or Hidden Markov Model-based taggers eg <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF>; <REF>Cutting et al 1992</REF>; <REF>Merialdo, 1994</REF>, etc	1	In 14 these approaches, a tag sequence is chosen for a sentence that maximizes the product of lexical and contextual probabilities as estimated from a tagged corpus	0	In rule-based approaches, words are assigned a tag based on a set of rules and a lexicon	0	6	1
H91-1077	A88-1019	1991	Categorical ambiguity, however, is of a different kind and is resolved in a different way	0	For the purposes of the present paper, it will be assumed that only content words are at issue, and that the syntactic category of all content words in the text that is under study can be determined automatically <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF>	1	The problem is simply to decide which sense of a content word--noun, verb, adjective, or adverb---is appropriate in a given linguistic context	0	It will also be assumed that sense resolution for individual words can be accomplished on the basis of information about the irnrnediate linguistic context	0	6	1
W98-1117	A88-1019	1998	The program can be trained even with a relatively small amount of treebank data; then it can be J used for parsing unrestricted pre-tagged text	0	As far as coverage is concerned, our parser can handle recursive structures, which is an advantage compared to simpler techniques such as that described by <TREF>Church 1988</TREF>	1	On the other hand, the Markov assumption underlying our approach means that only strictly local dependencies are recognised	0	For full parsing, one would probably need non-local contextual information, such as the long-range trigrams in Link Grammar Della <REF>Pietra et al , 1994</REF>	0	1	3
W98-1117	A88-1019	1998	Regardless of whether or not abstractions such as phrases occur in the model, most of the relevant information is contained directly in the sequence of words and part-of-speech tags to be processed	0	An archetypal representative of this approach is the method described by <TREF>Church 1988</TREF>, who used corpus frequencies to determine the boundaries of simple non, recursive NPs	1	For each pair of part-of-speech tags ti, tj, the probability of an NP boundary   or  occurring between ti and tj is computed	0	On the basis of these context probabilities, the program inserts the symbols  and  into sequences of part-of-speech tags	0	6	1
J93-2006	A88-1019	1993	However, it does undeniably reduce confusion with respect to the proper noun category	0	Some well-known previous efforts <TREF>Church 1988</TREF>; de <REF>Marcken 1990</REF> have dealt with unknown words using various heuristics	1	For instance, Churchs program PARTS has a prepass prior to applying the tri-tag probability model that predicts proper nouns based on capitalization	0	The new aspects of our work are 1 incorporating the treatment of unknown words uniformly within the probability model, 2 approximating the component probabilities for unknowns directly from the training data, and 3 measuring the contribution of the tri-tag model, of the ending, and of capitalization	0	6	1
J93-2006	A88-1019	1993	Purely rule-based techniques seemed too brittle for dealing with the variety of constructions, the long sentences averaging 29 words per sentence, and the degree of unexpected input	0	Statistical models based on local information eg , <REF>DeRose 1988</REF>; <TREF>Church 1988</TREF> might operate effectively in spite of sentence length and unexpected input	1	To see whether our four hypotheses in italics above effectively addressed the four concerns above, we chose to test the hypotheses on two well-known problems: ambiguity both at the structural level and at the part-of-speech level and inferring syntactic and semantic information about unknown words	0	Guided by the past success of probabilistic models in speech processing, we have integrated probabilistic models into our language processing systems	0	1	2
J93-2006	A88-1019	1993	We report in Section 2 on our experiments on the assignment of part of speech to words in text	0	The effectiveness of such models is well known <REF>DeRose 1988</REF>; <TREF>Church 1988</TREF>; <REF>Kupiec 1989</REF>; <REF>Jelinek 1985</REF>, and they are currently in use in parsers eg de <REF>Marcken 1990</REF>	1	Our work is an incremental improvement on these models in three ways: 1 Much less training data than theoretically required proved adequate; 2 we integrated a probabilistic model of word features to handle unknown words uniformly within the probabilistic model and measured its contribution; and 3 we have applied the forward-backward algorithm to accurately compute the most likely tag set	0	In Section 3, we demonstrate that probability models can improve the performance of knowledge-based syntactic and semantic processing in dealing with structural ambiguity and with unknown words	0	1	2
P98-1080	A88-1019	1998	1 is a typical example of the ambiguities encountered in a running text: little POS ambiguity, but a lot of gender, number and case ambiguity columns 3 to 5	0	485 3 The Model Instead of employing the source-channel paradigm for tagging more or less explicitly present eg in <REF>Merialdo, 1992</REF>, <TREF>Church, 1988</TREF>, Hajji, Hladk, 1997 used in the past notwithstanding some exceptions, such as Maximum Entropy and rule-based taggers, we are using here a direct approach to modeling, for which we have chosen an exponential probabilistic model	1	Such model when predicting an event 5 y E Y in a context x has the general form PAC,e YIX  exp-in----1 Aifi y, x Zx 3 where fi Y, x is the set of size n of binary-valued yes/no features of the event value being predicted and its context, hi is a weigth in the exponential sense of the feature fi, and the normalization factor Zx is defined naturally as zx  exp z x 4 yEY i----1 ,Ve use a separate model for each ambiguity class AC which actually appeared in the training data of each of the 13 morphological categories 6	0	The final PAC Yix distribution is further smoothed using unigram distributions on subtags again, separately for each category	0	2	1
P94-1013	A88-1019	1994	This was expanded upon by <REF>Gale et al , 1992</REF>, and in a class-based variant by <REF>Yarowsky, 1992</REF>	0	Decision trees <REF>Brown, 1991</REF> have been usefully applied to word-sense ambiguities, and HMM part-of-speech taggers <REF>Jelinek 1985</REF>, <TREF>Church 1988</TREF>, <REF>Merialdo 1990</REF> have addressed the syntactic ambiguities presented here	1	<REF>Hearst 1991</REF> presented an effective approach to modeling local contextual evidence, while <REF>Resnik 1993</REF> gave a classic treatment of the use of word classes in selectional constraints	0	An algorithm for combining syntactic and semantic evidence in lexical ambiguity resolution has been realized in <REF>Chang et al , 1992</REF>	0	1	2
H89-2012	A88-1019	1989	Preprocessing the Corpus with a Part of Speech Tagger Phrasal verbs involving the preposition to raise an interesting problem because of the possible confusion with the infinitive marker to	0	We have found that if we first tag every word in the corpus with a part of speech using a method such as <TREF>Church 1988</TREF> or <REF>DeRose 1988</REF>, and then measure associations between tagged words, we can identify interesting contrasts between verbs associated with a following preposition toin and verbs associated with a following infinitive marker toto	1	Part of speech notation is borrowed from <REF>Francis and Kucera 1982</REF>; m  preposition; to  infinitive marker; vb  bare verb; vbg  verb  ing; vbd  verb  ed; vbz  verb  s; vbn  verb  en	0	The score identifies quite a number of verbs associated in an interesting way with to; restricting our attention to pairs with a score of 30 or more, there are 768 verbs associated with the preposition toin and 551 verbs with the infinitive marker toto	0	3	2
P99-1021	A88-1019	1999	In the partof-speech tagging field, the disambiguation of capitalized words is treated similarly to the disambiguation of common words	0	However, as <TREF>Church 1988</TREF> rightly pointed out Proper nouns and capitalized words are particularly problematic: some capitalized words are proper nouns and some are not	1	Estimates from the Brown Corpus can be misleading	0	For example, the capitalized word Acts is found twice in Brown Corpus, both times as a proper noun in a title	0	1	2
P97-1029	A88-1019	1997	Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora	0	There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, eg, <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1992</REF>; <REF>DeRose, 1988</REF>, constraint-based techniques <REF>Karlsson et al , 1995</REF>; <REF>Voutilainen, 1995b</REF>; Voutilainen, Heikkil/i, and <REF>Anttila, 1992</REF>; <REF>Voutilainen and Tapanainen, 1993</REF>; <REF>Oflazer and KuruSz, 1994</REF>; <REF>Oflazer and Till 1996</REF> and transformation-based techniques <REF>Brilt, 1992</REF>; <REF>Brill, 1994</REF>; <REF>Brill, 1995</REF>	1	This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements	0	The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item	0	6	1
C98-2203	A88-1019	1998	Given that each token has on the average more than 2 possible tags, the procedural description above is very inefficient for M1 but very short sentences	0	However, the observation that our constraints are localized to a window of a small number of tokens say at most 5 tokens in a sequence, suggests a more efficient scheme originally used by <TREF>Church 1988</TREF>	1	Assume our constraint windows are allowed to look at a window of at most size k sequential parses	0	Let us take the first k tokens of a sentence and generate all possible paths of k arcs spanning k  1 nodes, and apply all constraints to these short paths	0	1	2
C98-2203	A88-1019	1998	Part-of-speech tagging is one of the preliminary steps in many natural language processing systems in which the proper part-of-speech tag of the tokens comprising the sentences are disambiguated using either statistical or symbolic local contextual information	0	Tagging systems have used either a statistical approach where a large corpora is employed to train a probabilistic model which then is used to tag unseen text, eg, <TREF>Church 1988</TREF>, Cutting et al	1	1992, DeR,ose 1988, or a constraint-based approach which employs a large number of hand-crafted linguistic constraints that are used to eliminate impossible sequences or morphological parses for a given word in a given context, recently most prominently exemplified by the Constraint Grammar work <REF>Karlsson et al, 1995</REF>; <REF>Voutilainen, 1995b</REF>; <REF>Voutilainen et al, 1992</REF>; <REF>Voutilainen and Tapanainen, 1993</REF>	0	Brill 1992; 1994; 1995 has presented a transformationbased learning approach	0	6	1
H93-1046	A88-1019	1993	Models G and C For model G, I induced a simple grammar from the training corpus	0	I used Ken Churchs tagger <TREF>Church 1988</TREF> to 234 assign part-of-speech probabilities to words	1	The grammar contains a rule x ---> T for every Treebank chunk x t in the training corpus	0	x is the syntactic category of the chunk, and y is the part-of-speech sequence assigned to the words of the chunk	0	3	1
P93-1024	A88-1019	1993	The corpus used in our first experiment was derived from newswire text automatically parsed by 183 Hindles parser Fidditch <REF>Hindle, 1993</REF>	0	More recently, we have constructed similar tables with the help of a statistical part-of-speech tagger <TREF>Church, 1988</TREF> and of tools for regular expression pattern matching on tagged corpora <REF>Yarowsky, 1992</REF>	1	We have not yet compared the accuracy and coverage of the two methods, or what systematic biases they might introduce, although we took care to filter out certain systematic errors, for instance the misparsing of the subject of a complement clause as the direct object of a main verb for report verbs like say	0	We will consider here only the problem of classifying nouns according to their distribution as direct objects of verbs; the converse problem is formally similar	0	3	1
W94-0111	A88-1019	1994	1; they closely replicate Brills results 1993b, page 96, allowing for the fact that his tests used more templates, including templates like if one of the three previous tags is A	0	Brills results demonstrate that this approach can outperform the Hidden Markov Model approaches that are frequently used for part-of-speech tagging <REF>Jelinek, 1985</REF>; <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF>; <REF>Cutting et al , 1992</REF>; <REF>Weischedel et al , 1993</REF>, as well as showing promise for other applications	1	The resulting model, encoded as a list of rules, is also typically more compact and for some purposes more easily interpretable than a table of HMM probabilities	0	An Incremental Algorithm It is worthwhile noting first that it is possible in some circumstances to significantly speed up the straightforward algorithm described above	0	1	3
A94-1013	A88-1019	1994	We show the method to be efficient and easily adaptable to different text genres, including single-case texts	0	Labeling of sentence boundaries is a necessary prerequisite for many natural language processing NLP tasks, including part-of-speech tagging <TREF>Church, 1988</TREF>, <REF>Cutting et al , 1991</REF>, and sentence alignment <REF>Gale and Church, 1993</REF>, Kay and R<REF>Sscheisen, 1993</REF>	1	End-of-sentence punctuation marks are ambiguous; for example, a period can denote an abbreviation, the end of a sentence, or both, as shown in the examples below: 1 The group included Dr JM Freeman and T Boone Pickens Jr	0	2 This issue crosses party lines and crosses philosophical lines	0	6	1
A94-1013	A88-1019	1994	21 Assignment of Descriptors The first stage of the process is lexical analysis, which breaks the input text a stream of characters into tokens	0	Our implementation uses a slightlymodified version of the tokenizer from the PARTS part-of-speech tagger <TREF>Church, 1988</TREF> for this task	1	A token can be a sequence of alphabetic characters, a sequence of digits numbers containing periods acting as decimal points are considered a single token, or a single non-alphanumeric character	0	A lookup module then uses a lexicon with part-of-speech tags for each token	0	3	1
A94-1006	A88-1019	1994	The list of candidate terms contains both multi-word noun phrases and single words	0	The multi-word terms match a small set of syntactic patterns defined by regular expressions and are found by searching a version of the document tagged with parts of speech <TREF>Church, 1988</TREF>	1	The set of syntactic patterns is considered as a parameter and can be adopted to a specific domain by the user	0	Currently our patterns match only sequences of nouns, which seem to yield the best hit rate in our environment	0	3	1
A94-1006	A88-1019	1994	This current practice is very laborious and runs the risk of missing many important terms	0	Termight uses a part of speech tagger <TREF>Church, 1988</TREF> to identify a list of candidate terms which is then filtered by a manual pass	1	We have found, however, that the manual pass dominates the cost of the monolingual task, and consequently, we have tried to design an interactive user interface see Figure 1 that minimizes the burden on the expert terminologist	0	The terminologist is presented with a list of candidate terms, and corrects the list with a minimum number of key strokes	0	6	1
J99-4003	A88-1019	1999	We rewrite this term as follows: PrW1,ND1,N N  I-IPrWiDilWl,ilDl,il i1 N  l-I PrWilWl,i-lDl,i PrDilWl,i-lDl,i-1 i1 7 Equation 7 involves two probability distributions that need to be estimated	0	These are the same distributions that are needed by previous POS-based language models Equation 5 and POS taggers <TREF>Church 1988</TREF>; <REF>Charniak et al 1993</REF>	0	However, these approaches simplify the context so that the lexical probability is just conditioned on the POS category of the word, and the POS probability is conditioned on just the preceding POS tags, which leads to the following two approximations	0	PrWiIWl,ilDl,i  PrWilDi 8 PrDiIWulDl,il  PrDiIDul 9 However, to successfully incorporate POS information, we need to account for the full richness of the probability distributions, as will be demonstrated in Section 344	1	1	3
P98-1034	A88-1019	1998	Figure 1: Base NP Examples base noun phrases with initial determiners and modifiers removed: <REF>Justeson  Katz 1995</REF> look for repeated phrases; <REF>Bourigault 1992</REF> uses a handcrafted noun phrase grammar in conjunction with heuristics for finding maximal length noun phrases; Voutilainens NP<REF>Tool 1993</REF> uses a handcrafted lexicon and constraint grammar to find terminological noun phrases that include phrase-final prepositional phrases	0	Churchs PARTS program 1988, on the other hand, uses a probabilistic model automatically trained on the Brown corpus to locate core noun phrases as well as to assign parts of speech	1	More recently, Ramshaw  Marcus In press apply transformation-based learning <REF>Brill, 1995</REF> to the problem	0	Unfortunately, it is difficult to directly compare approaches	0	6	1
C94-1025	A88-1019	1994	The recursive expansion of the tree stops if either the information gained by consulting further fv-pairs or the frequencies upon which the calculus is based are smaller than defined thresholds	0	4 TAGGING ALGORITHM Starting point for the implementation of a feature structure tagger was a second-0rdcr-IIMM tagger trigrams based on a modified version of the Viterbi algorithm <REF>Viterbi, 1967</REF>; <TREF>Church, 1988</TREF> which we had earlier implemented in C Kempe,1994	1	There we replaced the function which estimated the contextual probability of a tag state transition probability hy dividing a trigram frequency by a bigram frequency eq	0	3 with a flmction which accomplished this calculus either using PF1Ls in the above-described way eqs 6, 7 or by consulting a decision tree fig	0	5	1
C94-1027	A88-1019	1994	1992 circumvent this problem by training their taggers on untagged data using tile Itaum-Welch algorithm also know as the forward-backward algorithm	0	They report rates of correctly tagged words which are comparable to that presented by <TREF>Church 1988</TREF> and <REF>Kempe 1993</REF>	1	A third and rather new approach is tagging with artificial neural networks	0	In the area of speech recognition neural networks have been used for a decade r, ow	0	4	2
P97-1008	A88-1019	1997	For example, if we choose to create a pseudo-word out of the words make and take, we would change the test data like this: make plans  make, take plans take action  make, take action The method being tested must choose between the two words that make up the pseudo-word	0	32 Data We used a statistical part-of-speech tagger <TREF>Church, 1988</TREF> and pattern matching and concordancing tools due to David Yarowsky to identify transitive main verbs and head nouns of the corresponding direct objects in 44 million words of 1988 Associated Press newswire	1	We selected the noun-verb pairs for the 1000 most frequent nouns in the corpus	0	These pairs are undoubtedly somewhat noisy given the errors inherent in the part-of-speech tagging and pattern matching	0	3	1
J93-1007	A88-1019	1993	151 Computational Linguistics Volume 19, Number 1 <REF>Garside and Leech 1987</REF> have been shown to reach 95-99 performance on free-style text	0	We preprocessed the corpus with a stochastic part-of-speech tagger developed at Bell Laboratories by Ken Church <TREF>Church 1988</TREF>	1	9 In the rest of this section, we describe the algorithm used for the first stage of Xtract in some detail	0	We assume that the corpus is preprocessed by a part of speech tagger and we note wi a collocate of w if the two words appear in a common sentence within a distance of 5 words	0	3	1
J93-1007	A88-1019	1993	Such techniques have various applications	0	Speech recognition <REF>Bahl, Jelinek, and Mercer 1983</REF> and text compression eg , <REF>Bell, Witten, and Cleary 1989</REF>; <REF>Guazzo 1980</REF> have been of long-standing interest, and some new applications are currently being investigated, such as machine translation <REF>Brown et al 1988</REF>, spelling correction <REF>Mays, Damerau, and Mercer 1990</REF>; <REF>Church and Gale 1990</REF>, parsing <REF>Debili 1982</REF>; <REF>Hindle and Rooth 1990</REF>	1	As pointed out by <REF>Bell, Witten, and Cleary 1989</REF>, these applications fall under two research paradigms: statistical approaches and lexical approaches	0	In the statistical approach, language is modeled as a stochastic process and the corpus is used to estimate probabilities	0	6	1
E99-1018	A88-1019	1999	On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms usually with the aid of corpora <REF>Green and Rubin, 1971</REF>; <REF>Voutilainen 1995</REF>	0	On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1992</REF>, rules <REF>Hindle, 1989</REF>; <REF>Brill, 1995</REF>, decision trees <REF>Cardie, 1994</REF>; <REF>Daelemans et al , 1996</REF> or neural networks <REF>Schmid, 1994</REF>	1	In order to increase their robusmess, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon	0	As a common strategy, POS guessers examine the endings of unknown words <REF>Cutting et al 1992</REF> along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech Weischedel et aL, 1993	0	6	1
C98-2118	A88-1019	1998	In practice, computational limitations do not allow the enumeration of all possible assignments for long sentences, and smoothing is required for infrequent events	1	This is described in more detail in the original publication <TREF>Church, 1988</TREF>	0	Although more sophisticated algorithms for unsupervised learning which can be trained on plain text instead on manually tagged corpora are well established see eg <REF>Merialdo, 1994</REF>, we decided not to use them	0	The main reason is that with large tag sets, the sparse-data-problem can become so severe that unsupervised training easily ends up in local minima, which call lead to poor results without any indication to the user	0	1	3
C98-2118	A88-1019	1998	<REF>Lezius, Rapp  Wettler 1996</REF> give an overview on some German tagging projects	0	Although we considered a number of algorithms, we decided to use the trigram algorithm described by <TREF>Church 1988</TREF> for tagging	1	It is simple, fast, robust, and among the statistical taggers still more or less unsurpassed in terms of accuracy	0	Conceptually, the Church-algorithm works as follows: For each sentence of a text, it generates all possible assignments of part-of-speech tags to words	0	3	1
J99-4005	A88-1019	1999	2	0	Part-of-Speech Tagging The prototype source-channel application in natural language is part-of-speech tagging <TREF>Church 1988</TREF>	1	We review it here for purposes of comparison with machine translation	0	Source strings comprise sequences of part-of-speech tags like noun, verb, etc A simple source model assigns a probability to a tag sequence tl tm based on the probabilities of the tag pairs inside it	0	6	1
P89-1015	A88-1019	1989	Indeed, recent increased interest in the problem of disambiguating lexical category in English has led to significant progress in developing effective programs for assigning lexical category in unrestricted text	0	The most successful and comprehensive of these are based on probabilistic modeling of category sequence and word category <REF>Church 1987</REF>; <REF>Garside, Leech and Sampson 1987</REF>; <REF>DeRose 1988</REF>	1	These stochastic methods show impressive performance: Church reports a success rate of 95 to 99, and shows a sample text with an error rate of less than one percent	0	What may seem particularly surprising is that these methods succeed essentially without reference to syntactic structure; purely surface lexical patterns are involved	0	1	2
J93-1001	A88-1019	1993	Part-of-Speech Tagging Many of the very same methods are being applied to problems in natural language processing by many of the very same researchers	0	As a result, the empirical approach has been adopted by almost all contemporary part-of-speech programs: <REF>Bahl and Mercer 1976</REF>, <REF>Leech, Garside, and Atwell 1983</REF>, <REF>Jelinek 1985</REF>, <REF>Deroualt and Merialdo 1986</REF>, <REF>Garside, Leech, and Sampson 1987</REF>, <TREF>Church 1988</TREF>, <REF>DeRose 1988</REF>, <REF>Hindle 1989</REF>, Kupiec 1989, 1992, Ayuso et al	1	1990, de<REF>Marcken 1990</REF>, <REF>Karlsson 1990</REF>, <REF>Boggess, Agarwal, and Davis 1991</REF>, <REF>Merialdo 1991</REF>, and <REF>Voutilainen, Heikkila, and Anttila 1992</REF>	0	These programs input a sequence of words, eg, The chair will table the motion, and output a sequence of part-of-speech tags, eg, art noun modal verb art noun	0	6	1
P03-1065	A88-1019	2003	English parsing is divided into two tasks: shallow parsing and deep parsing	0	The shallow parser constructs Verb Groups VGs and basic Noun Phrases NPs, also called BaseNPs <TREF>Church 1988</TREF>	1	The deep parser utilizes syntactic subcategorization features and semantic features of a head eg , VG to decode both syntactic and logical dependency relationships such as Verb-Subject, Verb-Object, Head-Modifier, etc Part-of-Speech POS Tagging General Lexicon Lexical lookup Named Entity NE Taggig Shallow Parsing PV Identification Deep parsing General Lexicon PV Expert Lexicon Figure 1	0	System Architecture The general lexicon lookup component involves stemming that transforms regular or irregular inflected verbs into the base forms to facilitate the later phrasal verb matching	0	6	1
W96-0205	A88-1019	1996	We redistribute the probability mass of low count sequences to unseen sequences	0	Generalized Forward Backward Reestimation Generalization of the Forward and Viterbi Algorithm In English part of speech taggers, the maximization of Equation 1 to get the most likely tag sequence, is accomplished by the Viterbi algorithm <TREF>Church, 1988</TREF>, and the maximum likelihood estimates of the parameters of Equation 2 are obtained from untagged corpus by the ForwardBackward algorithm <REF>Cutting et al , 1992</REF>	0	However, it is impossible to apply the Viterbi algorithm and the Forward-Backward algorithm for word segmentation of those languages that have no delimiter between words, such as Japanese and Chinese, because word segmentation hypotheses overlap one another	1	Figure 3 shows an example of overlapping word hypotheses and possible word segmentations for the string Ntig-f all prefectures in the nation	0	1	3
W98-0702	A88-1019	1998	An event greater improvement over the baseline is illustrated by the increase in the number of event clauses correctly classified, ie event rrall	0	As shown in Table 7, an event recall of 677 was achieved by the classification rule, as compared to speech tagging <TREF>Church, 1988</TREF>; <REF>Alien, 1995</REF>	1	13 I I I I I I I I I I I I I I I I I I the 00 event recall achieved by the baseline, while suffering no loss in overall accuracy	0	This difference in recall is more dramatic than the accuracy improvement because of the dominance of stative clauses in the test set	0	2	1
W98-1207	A88-1019	1998	What can be done at the present stage is the recognition of relatively simple structures such as NPs and PPs	0	<TREF>Church, 1988</TREF> used a simple mechanism to mark the boundaries of NPs	1	He used part-of-speech tagging and added two flags to the part-of-speech tags to mark the beginning and the end of an NP	0	Our goal is more ambitious in that we mark not only the phrase boundaries of NPs but also the complete structure of a wider class of phrases, starting with APs, NPs and PPs	0	6	1
P91-1023	A88-1019	1991	For a larger dataset, such as the Canadian Hansards, it was not possible to check the results by hand	0	We used the same procedure which is used in <TREF>Church, 1988</TREF>	1	This procedure was developed by Kathryn Baker private communication	0	ratio	0	3	1
J95-2004	A88-1019	1995	In fact, whereas stochastic taggers have to store word-tag, bigram, and trigram probabilities, the rule-based tagger and therefore the finite-state one only have to encode a small number of rules between 200 and 300	0	We empirically compared our tagger with Eric Brills implementation of his tagger, and with our implementation of a trigram tagger adapted from the work of <TREF>Church 1988</TREF> that we previously implemented for another purpose	1	We ran the three programs on large files and piped their output into a file	0	In the times reported, we included the time spent reading the input and writing the output	0	3	1
J95-2004	A88-1019	1995	Although finite-state machines have been used for part-of-speech tagging <REF>Tapanainen and Voutilainen 1993</REF>; <REF>Silberztein 1993</REF>, none of these approaches has the same flexibility as stochastic techniques	0	Unlike stochastic approaches to part-of-speech tagging <TREF>Church 1988</TREF>; <REF>Kupiec 1992</REF>; <REF>Cutting et al 1992</REF>; <REF>Merialdo 1990</REF>; <REF>DeRose 1988</REF>; <REF>Weischedel et al 1993</REF>, up to now the knowledge found in finite-state taggers has been handcrafted and was not automatically acquired	1	<REF>Recently, Brill 1992</REF> described a rule-based tagger that performs as well as taggers based upon probabilistic models and overcomes the limitations common in rule-based approaches to language processing: it is robust and the rules are automatically ac Mitsubishi Electric Research Laboratories, 201 Broadway, Cambridge, MA 02139	0	E-mail: rocbe/schabesmerlcom	0	6	1
W96-0206	A88-1019	1996	A corpus is manually tagged with the categories and transition probabilities between two or three categories are estimated from their relative frequencies	0	This method is commonly used for part-of-speech tagging <TREF>Church, 1988</TREF>	1	The fourth method is a variation of the third method and is also used for part-of-speech tagging	0	This method does not need a pre-annotated corpus for parameter estimation	0	3	1
P94-1032	A88-1019	1994	2	0	Previous <REF>Works Church 1988</REF> proposes a part of speech tagger and a simple noun phrase extractor	1	His noun phrase extractor brackets the noun phrases of input tagged texts according to two probability matrices: one is starting noun phrase matrix; the other is ending noun phrase matrix	0	The methodology is a simple version of Garside and Leechs probabilistic parser 1985	0	6	1
P94-1032	A88-1019	1994	The testing scale is large enough about 150,000 words	0	In contrast, <TREF>Church 1988</TREF> tests a text and extracts the simple noun phrases only	1	Bourigaults work 1992 is evaluated manually, and dose not report the precision	0	Hence, the real performance is not known	0	6	1
W99-0608	A88-1019	1999	For more details, we refer the reader to <REF>Mgrquez and Rodrfguez, 1997</REF>	0	22 STT: A Statistical Tree-based Tagger The aim of statistical or probabilistic tagging <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1992</REF> is to assign the most likely sequence of tags given the observed sequence of words	1	For doing so, two kinds of information are used: the lexical probabilities, ie, the probability of a particular tag conditional on the particular word, and the contextual probabilities, which describe the probability of a particular tag conditional on the surrounding tags	0	Contextual or transition probabilities are usually reduced to the conditioning of the preceding tag bigrams, or pair of tags trigrams, however, the general formulation allows a broader definition of context	0	6	1
A94-1024	A88-1019	1994	based approach implemented with finite-state machines <REF>Koskenniemi et al , 1992</REF>; <REF>Voutilainen and Tapanainen, 1993</REF>	0	A completely different approach to tagging uses statistical methods, eg , <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1993</REF>	1	These systems essentially train a statistical model using a previously hand-tagged corpus and provide the capability of resolving ambiguity on the basis of most likely interpretation	0	The models that have been widely used assume that the part-ofspeech of a word depends on the categories of the two preceding words	0	6	1
J01-4004	A88-1019	2001	As far as coreference resolution is concerned, the goal of these NLP modules is to determine the boundary of the markables, and to provide the necessary information about each markable for subsequent generation of features in the training examples	0	Our part-of-speech tagger is a standard statistical tagger based on the Hidden Markov Model HMM <TREF>Church 1988</TREF>	1	Similarly, we built a statistical HMM-based noun phrase identification module that determines the noun phrase boundaries solely based on the part-of-speech tags assigned to the words in a sentence	0	We also implemented a module that recognizes MUC-style named entities, that is, organization, person, location, date, time, money, and percent	0	3	1
W95-0101	A88-1019	1995	There has recently been a great deal of work exploring methods for automatically training part of speech taggers, as an alternative to laboriously hand-crafting rules for tagging, as was done in the past <REF>Klein and Simmons, 1963</REF>; <REF>Harris, 1962</REF>	0	Almost all of the work in the area of automatically trained taggers has explored Markov-model based part of speech tagging <REF>Jelinek, 1985</REF>; <TREF>Church, 1988</TREF>; <REF>Derose, 1988</REF>; <REF>DeMarcken, 1990</REF>; <REF>Cutting et al , 1992</REF>; <REF>Kupiec, 1992</REF>; <REF>Charniak et al , 1993</REF>; <REF>Weischedel et al , 1993</REF>; <REF>Schutze and Singer, 1994</REF>; <REF>Lin et al , 1994</REF>; <REF>Elworthy, 1994</REF>; <REF>Merialdo, 1995</REF>	1	2 For a Markov-model based tagger, training consists of learning both lexical probabilities Pwordltag and contextual probabilities Ptagiltagil tagi-n	0	Once trained, a sentence can be tagged by searching for the tag sequence that maximizes the product of lexical and contextual probabilities	0	6	1
C92-1033	A88-1019	1992	In the examples ahove, tagging of presents as vbz in the first sentence cuts off a potentially long and cosily garden path with presents as a plural noun followed by a headless relative clause starting with that a proposal  In the second sentence, tagging resolves ambiguity of used vim vs vbd, and associates vbz vs nns	0	Perhaps more imlxmantly, elimination of word-level lexical ambiguity allows the parser to make projection about the input which is yet to be parsed, using a simple lookabead; in particular, phrase boundaries can be determined with a degree of confidence <TREF>Church, 1988</TREF>	1	This latter property is critical for implementing skip-and-fit recovery technique outlined in the previous section	0	Tagging of input also helps to reduce the number of parse structures that can be assigned to a sentence, decreases the demand for consulting of the dictionary, and simplifies dealing with unknown words	0	6	1
W00-1211	A88-1019	2000	The typical examples are the recognition of BaseNP in English and Chinese	0	In English BNP base noun phrase is defined as simple and non-nesting noun phrases, ie noun phrases that do not contain other noun phrase descendants <TREF>Church, 1988</TREF>	1	After that researches on BNP identification reports promising results for such task in English	0	Observing that the Chinese BNP is different form English, <REF>Zhao  Huang, 1999</REF> puts forward the definition of Chinese BNP in terms of combination of determinative modifier and head noun	0	6	1
A94-1011	A88-1019	1994	More sophisticated linguistic information comes in several forms, all of which may need to be represented if performance in an automatic categorisation experiment is to be improved	0	Typical examples of linguistically sophisticated annotation include tagging words with their syntactic category although this has not been found to be effective for 1R, lemma of the word eg corpus for corpora, phrasal information eg identifying noun groups and phrases <REF>Lewis 1992c</REF>, <TREF>Church 1988</TREF>, and subject-predicate identification eg <REF>Hindle 1990</REF>	1	For the RAPRA corpus, we currently identify noun groups and adjective groups	0	This is achieved in a manner similar to Churchs 1988 PARTS algorithm used by Lewis 1992bc, in the sense that its main properties are robustness and corpus sensitivity	0	6	1
A94-1011	A88-1019	1994	For the RAPRA corpus, we currently identify noun groups and adjective groups	0	This is achieved in a manner similar to Churchs 1988 PARTS algorithm used by Lewis 1992bc, in the sense that its main properties are robustness and corpus sensitivity	1	All that is important for this paper is that the technique identifies various groupings of words for example, noun-groups, adjective groups, and so on with a high level of accuracy	0	Major parts of the technique are described in detail in <REF>Finch, 1993</REF>	0	3	1
W93-0111	A88-1019	1993	problem	0	Excellent methods have been developed for part-of-speech POS tagging using stochastic models trained on partially tagged corpora <TREF>Church, 1988</TREF>; Cutting, <REF>Kupiec, Pedersen  Sibun, 1992</REF>	1	Semantic issues have been addressed, particularly for sense disambiguation, by using large contexts, eg, 50 nearby words <REF>Gale, Church  Yarowsky, 1992</REF> or by reference to on-line dictionaries <REF>Krovetz, 1991</REF>; <REF>Lesk, 1986</REF>; <REF>Liddy  Paik, 1992</REF>; <REF>Zernik, 1991</REF>	0	More recently, methods to work with entirely untagged corpora have been developed which show great promise <REF>Brill  Marcus, 1992</REF>; <REF>Finch  Chater, 1992</REF>; <REF>Myaeng  Li, 1992</REF>; <REF>Schutze, 1992</REF>	0	1	2
J01-2002	A88-1019	2001	Although methods for unsupervised training of HMMs do exist, training is usually done in a supervised way by estimation of the above probabilities from relative frequencies in the training data	0	The HMM approach to tagging is by far the most studied and applied <TREF>Church 1988</TREF>; <REF>DeRose 1988</REF>; <REF>Charniak 1993</REF>	1	In van <REF>Halteren, Zavrel, and Daelemans 1998</REF> we used a straightforward implementation of HMMs, which turned out to have the worst accuracy of the four competing methods	0	In the present work, we have replaced this by the TnT system we will refer to this tagger as HMM below	0	6	1
J98-3005	A88-1019	1998	Two-Word Descriptions Three-Word Descriptions Stage Entities Unique Entities Entities Unique Entities POS tagging only 9,079 1,546 2,617 604 After WordNet checkup 1,509 395 81 26  Extraction of candidates for proper nouns	0	After tagging the corpus using the POS part-of-speech tagger <TREF>Church 1988</TREF>, we used a CREP <REF>Duford 1993</REF> regular grammar to first extract all possible candidates for entities	1	These consist of all sequences of words that were tagged as proper nouns NP by POS	0	Our manual analysis showed that out of a total of 2150 entities recovered in this way, 1139 529 are not names of entities	0	3	1
J93-2002	A88-1019	1993	A trained system would probably be more accurate in classifying new verbs	0	Finally, the lexical ambiguity problem could probably be reduced substantially in the applied context by using a statistical tagging program <REF>Brill 1992</REF>; <TREF>Church 1988</TREF>	1	For addressing basic questions in machine learning of natural language the solutions outlined above are not attractive	0	All of those solutions provide the learner with additional specific knowledge of English, whereas the goal for the machine learning effort should be to replace specific knowledge with general knowledge about the types of regularities to be found in natural language	0	6	1
P92-1032	A88-1019	1992	to appear, <REF>Hearst 1991</REF>, <REF>Lesk 1986</REF>, <REF>Smadja and McKeown 1990</REF>, <REF>Walker 1987</REF>, <REF>Veronis and Ide 1990</REF>, <REF>Yarowsky 1992</REF>, Zemik 1990, 1991	0	Much of this work offers the prospect that a disambiguation system might be able to input unrestricted text and tag each word with the most likely sense with fairly reasonable accuracy and efficiency, just as part of speech taggers eg , <TREF>Church 1988</TREF> can now input unrestricted text and assign each word with the most likely part of speech with fairly reasonable accuracy and efficiency	1	The availability of massive lexicographic databases offers a promising route to overcoming the knowledge acquisition bottleneck	0	More than thirty years ago, BarI-<REF>Iillel 1960</REF> predicted that it would be futile to write expert-system-like rules by-hand as they had been doing at Georgetown at the time because there would be no way to scale up such rules to cope with unrestricted input	0	1	2
J95-3004	A88-1019	1995	<REF>Choueka and Lusignan 1985</REF> presented a system for the morphological tagging of large texts that is based on the short context of the word but also depends heavily on human interaction	0	Methods using the short context of a word in order to resolve ambiguity usually categorical ambiguity are very common in English and other languages <REF>DeRose 1988</REF>; <TREF>Church 1988</TREF>; <REF>Karlsson 1990</REF>	1	A system using this approach was developed by Levinger and Ornan in order to serve as a component in their project of morphological disambiguation in Hebrew <REF>Levinger 1992</REF>	0	The main resource, used by this system for disambiguation, is a set of syntactic constraints that were defined manually by the authors and followed two theoretical works that defined short context rules for Hebrew <REF>Pines 1975</REF>; <REF>Albeck 1992</REF>	0	6	1
J95-3004	A88-1019	1995	Another application which is more difficult in Hebrew than in other languages is text-to-speech systems, which cannot be implemented in Hebrew without first solving the morphological ambiguity, since in many cases different analyses of a word imply different pronunciations	0	A much simpler problem occurs in English, where for some words the correct syntactic tag is necessary for pronunciation <TREF>Church 1988</TREF>	1	The notion that this ambiguity problem in Hebrew is very complicated and that it can be dealt with only by using vast syntactic and semantic knowledge has led researchers to look for solutions involving a considerable amount of human interaction	0	<REF>Ornan 1986</REF> for instance, developed a new writing system for Hebrew, called The Phonemic Script	0	6	1
J96-2001	A88-1019	1996	Estimating the Lexical Priors for Rare Forms For a common form such as lopen walk a reasonable estimate of the lexical prior probabilities is the MLE, computed over all occurrences of this form	0	So, in the UdB corpus, lopen occurs 92 times as an infinitive and 43 times as a finite plural, so the MLE 1 Even models of disambiguation that make use of context, such as statistical n-gram taggers, often presume some estimate of lexical priors, in addition to requiring estimates of the transition probabilities of sequences of lexical tags <TREF>Church 1988</TREF>; <REF>DeRose 1988</REF>; <REF>Kupiec 1992</REF>, and this again brings up the question of what to do about unseen or low-frequency forms	1	In working taggers, a common approach is simply to apply a uniform small probability to the various senses of unseen or low-frequency forms: this was done in the tagger discussed in <TREF>Church 1988</TREF>, for example	0	156 Baayen and Sproat Lexical Priors for Low-Frequency Forms to> 8 Figure 1 I I I I 0 2 4 6 log frequency class Relative frequency of Dutch infinitives versus finite plurals in the Uit den Boogaart corpus, as a function of the natural log of the frequency of the word forms	0	6	1
J96-2001	A88-1019	1996	So, in the UdB corpus, lopen occurs 92 times as an infinitive and 43 times as a finite plural, so the MLE 1 Even models of disambiguation that make use of context, such as statistical n-gram taggers, often presume some estimate of lexical priors, in addition to requiring estimates of the transition probabilities of sequences of lexical tags <TREF>Church 1988</TREF>; <REF>DeRose 1988</REF>; <REF>Kupiec 1992</REF>, and this again brings up the question of what to do about unseen or low-frequency forms	0	In working taggers, a common approach is simply to apply a uniform small probability to the various senses of unseen or low-frequency forms: this was done in the tagger discussed in <TREF>Church 1988</TREF>, for example	1	156 Baayen and Sproat Lexical Priors for Low-Frequency Forms to> 8 Figure 1 I I I I 0 2 4 6 log frequency class Relative frequency of Dutch infinitives versus finite plurals in the Uit den Boogaart corpus, as a function of the natural log of the frequency of the word forms	0	The horizontal solid line represents the overall MLE, the relative frequency of the infinitive as computed over all tokens; the horizontal dashed line represents the relative frequency of the infinitive among the hapax legomena	0	6	1
C90-3010	A88-1019	1990	Statistical anMyses of linguistic data were very popular in the 50s and 60s, mainly, even though not only, for literary types of analyses and for studies on the lexicon <REF>Guiraud 1959</REF>, <REF>Muller 1964</REF>, <REF>Moskovich 1977</REF>	0	Stochastic approaches to linguistic analyses have been strongly reevaluated in the past few years, either for syntactic analysis Gmside et al 1987, <TREF>Church 1988</TREF>, or for NLP applications <REF>Brown et al 1988</REF>, or for semantic analysis <REF>Zemik 1989</REF>, <REF>Smadja 1989</REF>	1	Quantitative not statistical evidence on eg word-sense occurrences in a large corpus have been taken into account for lexicographic descriptions Cobuild 17	0	I llere and in the following we have not translated idiomatic phrases and compounds, because there is no point in giving the literal translation of the single words	0	6	1
P91-1037	A88-1019	1991	Furthermore, we might expect that some words, such as prepositions and determiners, for example, do not constitute the typical end to an intonational phrase	0	We test these possibilities by examining part-of-speech in a window of four words surrounding each potential phrase break, using Churchs part-of-speech tagger 1988	1	Recall that each intermediate phrase is composed of one or more pitch accents plus a phrase accent, and each intonational phrase is composed of one or more intermediate phrases plus a boundary tone	0	Informal observation suggests that phrase boundaries are more likely to occur in some accent contexts than in others	0	3	1
P91-1037	A88-1019	1991	Discussion The application of CART techniques to the problem of predicting and detecting phrasing boundaries not only provides a classification procedure for predicting intonational boundaries from text, but it increases our understanding of the importance of several among the numerous variables which might plausibly be related to boundary location	0	In future, we plan to extend the set of variables for analysis to include counts of stressed syllables, automatic NP-detection <TREF>Church, 1988</TREF>, MUTUAL INFORMATION, GENERALIZED MUTUAL INFORMATION scores can serve as indicators of intonational phrase boundaries <REF>Magerman and Marcus, 1990</REF>	1	We will also examine possible interactions among the statistically important variables which have emerged from our initial study	0	CART techniques have worked extremely well at classifying phrase boundaries and indicating which of a set of potential variables appear most important	0	6	1
C00-2089	A88-1019	2000	The main atvantage of the linguistic approach is that the model is constructed from a linguistic Ioint of view and contains many and complex kinds of knowledge iI1 tim lemning approach, tile most extended tbrmalism is based on n-grains or IIMM	0	In tiffs case, the language inodel can be estimated from a labelled corpus supervised methods <TREF>Church, 1988</TREF>Weisehedel et al , 1993 or from a nonlabelled corpus unsupervised methods Cutting et 21	1	, 1992	0	In the first; case, the model is trained from the relative observed Dequencies	0	6	1
C00-2089	A88-1019	2000	122 LKarning Techniques These allnoachcs automatically :onstruel; a language model from a labellod alld brackKted corpus	0	The lirst probabilistic approach was proposed in <TREF>Church, 1988</TREF>	1	This method learn; a bigram model for detecting simph3 noun phrasKs on the Brown corpus	0	Civn a sequene of parts of st3eeh as inlug, the Church program inserts the most prolable openings and Kndings of NPs, using a Viterbiqiko	0	6	1
C90-3030	A88-1019	1990	It shows the descriptive power of low-level morphology-based constraints	0	The most successful achievements so far in the domain of large-scale morphological disambiguation of running text have been those for English reported by <REF>Garside, Leech, and Sampson 1987</REF>, on tagging the LOB corpus, and <TREF>Church 1988</TREF>, on assigning part-of-speech labels and parsing noun phrases	1	Success rates ranging between 95-99 are reported, depending on how success is defined	0	These approaches are probabilistic and based on transitional probabilities calculated from extensive pretagged corpora	0	1	2
P96-1042	A88-1019	1996	The methods we investi1This gives the Viterbi model <REF>Merialdo, 1994</REF>, which we use here	0	2This version of the method uses Bayes theorem  <TREF>Church, 1988</TREF>	1	Pwdt, o Pt, J gate approach this evaluation implicitly, measuring an examples informativeness as the uncertainty in its classification given the current training data <REF>Seung, Opper, and Sompolinsky, 1992</REF>; <REF>Lewis and Gale, 1994</REF>; <REF>MacKay, 1992</REF>	0	The reasoning is that if an examples classification is uncertain given current training data then the example is likely to contain unknown information useful for classifying similar examples in the future	0	6	1
P96-1042	A88-1019	1996	Our work focuses on sample selection for training probabilistic classifiers	0	In statistical NLP, probabilistic classifiers are often used to select a preferred analysis of the linguistic structure of a text for example, its syntactic structure <REF>Black et al , 1993</REF>, word categories <TREF>Church, 1988</TREF>, or word senses <REF>Gale, Church, and Yarowsky, 1993</REF>	1	As a representative task for probabilistic classification in NLP, we experiment in this paper with sample selection for the popular and well-understood method of stochastic part-of-speech tagging using Hidden Markov Models	0	We first review the basic approach of committeebased sample selection and its application to partof-speech tagging	0	6	1
P95-1039	A88-1019	1995	Additionally, there is a slight but not significant improvement of tagging accuracy	0	Statistical part-of-speech disambiguation can be efficiently done with n-gram models <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1992</REF>	1	These models are equivalent to Hidden Markov Models HMMs <REF>Rabiner, 1989</REF> of order n 1	0	The states represent parts of speech categories, tags, there is exactly one state for each category, and each state outputs words of a particular category	0	1	2
W01-0712	A88-1019	2001	A specialised version of the chunking task is NP CHUNKING or baseNP identification in which the goal is to identify the base noun phrases	0	The first work on this topic was done back in the eighties <TREF>Church, 1988</TREF>	1	The data set that has become standard for evaluation machine learning approaches is the one first used by <REF>Ramshaw and Marcus 1995</REF>	0	It consists of the same training and test data segments of the Penn Treebank as the chunking task respectively sections 15-18 and section 20	0	6	1
H91-1065	A88-1019	1991	We report in this paper on one application of probabilistic models to language processing, the assignment of part of speech to words in open text	0	The effectiveness of such models is well known <TREF>Church 1988</TREF> and they are currently in use in parsers eg de <REF>Marcken 1990</REF>	0	Our work is an incremental improvement on these models in two ways: 1 We have run experiments regarding the amount of training data needed in moving to a new domain; 2 we have added probabilistic models of word features to handle unknown words effectively	1	We describe POST and its algorithms and then we describe our extensions, showing the results of our experiments	0	5	1
H91-1065	A88-1019	1991	Using the Viterbi algorithm, we selected the path whose overall probability was highest, and then took the tag predictions from that path	0	We replicated the result <TREF>Church 1988</TREF> that this process is able to predict the parts of speech with only a 3-4 error rate when the possible parts of speech of each the words in the corpus are known	1	This is in fact about the rate of discrepancies among human taggers on the TREEBANK project <REF>Marcus, Santorini  Magerman 1990</REF>	0	22 Quantity of training data While supervised training is shown here to be very effective, it requires a correctly taed corpus	0	6	1
W97-0314	A88-1019	1997	They mainly differ in the emphasis they give to syntactic and statistical control of the induction process	0	In Church,1988 a well-know purely statistical method for POS tagging is applied to the derivation of simple noun phrases that are relevant in the underlying corpus	1	On the contrary more language oriented methods are those where specialized grammar are used	0	LEXTER Bourigault,1992 extracts maximal length noun phrases mlnp from a corpus, and then applies a special purpose noun phrase parsing to hem in order to focus on significant complex nominals	0	6	1
J95-4004	A88-1019	1995	There are a number of large tagged corpora available, allowing for a variety of experiments to be run	0	Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years eg , <REF>Jelinek 1985</REF>; <TREF>Church 1988</TREF>; <REF>Derose 1988</REF>; <REF>Hindle 1989</REF>; <REF>DeMarcken 1990</REF>; <REF>Merialdo 1994</REF>; <REF>Brill 1992</REF>; <REF>Black et al 1992</REF>; <REF>Cutting et al 1992</REF>; <REF>Kupiec 1992</REF>; <REF>Charniak et al 1993</REF>; <REF>Weischedel et al 1993</REF>; <REF>Schutze and Singer 1994</REF>	1	Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography	0	Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation	0	6	1
J95-4004	A88-1019	1995	It has recently become clear that automatically extracting linguistic information from a sample text corpus can be an extremely powerful method of overcoming the linguistic knowledge acquisition bottleneck inhibiting the creation of robust and accurate natural language processing systems	0	A number of part-of-speech taggers are readily available and widely used, all trained and retrainable on text corpora <TREF>Church 1988</TREF>; <REF>Cutting et al 1992</REF>; <REF>Brill 1992</REF>; <REF>Weischedel et al 1993</REF>	1	Endemic structural ambiguity, which can lead to such difficulties as trying to cope with the many thousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules <REF>Fujisaki et al 1989</REF>; <REF>Sharman, Jelinek, and Mercer 1990</REF>; <REF>Black et al 1993</REF> and by computing statistical measures of lexical association <REF>Hindle and Rooth 1993</REF>	0	Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic and world knowledge, can now in some cases be done with high accuracy when all information is derived automatically from corpora <REF>Brown, Lai, and Mercer 1991</REF>; <REF>Yarowsky 1992</REF>; Gale, Church, and <REF>Yarowsky 1992</REF>; <REF>Bruce and Wiebe 1994</REF>	0	6	1
J95-4004	A88-1019	1995	However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics	0	Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging <REF>Jelinek 1985</REF>; <TREF>Church 1988</TREF>; <REF>Derose 1988</REF>; <REF>DeMarcken 1990</REF>; <REF>Merialdo 1994</REF>; <REF>Cutting et al 1992</REF>; <REF>Kupiec 1992</REF>; <REF>Charniak et al 1993</REF>; <REF>Weischedel et al 1993</REF>; <REF>Schutze and Singer 1994</REF>	1	41 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows	0	9 The initial-state annotator assigns each word its most likely tag as indicated in the training corpus	0	6	1
A97-1033	A88-1019	1997	Extraction of candidates for proper nouns	0	After tagging the corpus using the POS part-of-speech tagger <TREF>Church, 1988</TREF>, we used a CREP <REF>Duford, 1993</REF> regular grammar to first extract all possible candidates for entities	1	These consist of all sequences of words that were tagged as proper nouns NP by POS	0	Our manual analysis showed that out of a total of 2150 entities recovered in this way, 1139 529 are not names of entities	0	3	1
A97-1029	A88-1019	1997	In the past decade, the speech recognition community has had huge successes in applying hidden Markov models, or HMMs to their problems	0	More recently, the natural language processing community has effectively employed these models for part-ofspeech tagging, as in the seminal <TREF>Church, 1988</TREF> and other, more recent efforts <REF>Weischedel et al , 1993</REF>	1	We would now propose that HMMs have successfully been applied to the problem of name-finding	0	We have built a named-entity NE recognition system using a slightly-modified version of an HMM; we call our system Nymble	0	1	2
W97-0318	A88-1019	1997	For example, there is less than a 005 chance that the difference between stative and event means for the first four indicators listed 2This test was suggested by Judith Klavans personal communication	0	3Similar baselines for comparison have been used for many classification problems <REF>Duda and Hart, 1973</REF>, eg, part-of-speech tagging <TREF>Church, 1988</TREF>; <REF>Allen, 1995</REF>	1	159 is due to chance	0	Overall, this shows that the differences in stative and event averages are statistically significant for the first seven indicators listed p < 01	0	6	1
C90-3063	A88-1019	1990	Both types of ambiguity, syntactic and lexical, may cause the system to acquire or use inappropriate patterns	0	This problems is consid ered very important when dealing with a corpus: it was the re,Leon for the substantial human intervention in the procedure of <REF>Grishman et al 1986</REF>, and it is the reason why other techniques use manually tagged corpora eg <TREF>Church 1988</TREF>	1	In practice, however, we have discovered that the problem is not so cruciah semantically vMid patterns have occurred many more times in syntactically unambiguous constructs than in mnbiguous ones	0	Thus, they could be identified without the need of first disambiguating the sentences	0	6	1
J90-1003	A88-1019	1990	6 PREPROCESSING WITH A PART OF SPEECH TAGGER Phrasal verbs involving the preposition to raise an interesting problem because of the possible confusion with the infinitive marker to	0	We have found that if we first tag every word in the corpus with a part of speech using a method such as <TREF>Church 1988</TREF>, and then measure associations between tagged words, we can identify interesting contrasts between verbs associated with a following preposition toin and verbs associated with a following infinitive marker toto	1	Part of speech notation is borrowed from <REF>Francis and Kucera 1982</REF>; in  preposition; to  infinitive marker; vb  bare verb; vbg  verb  ing; vbd  verb  ed; vbz  verb  s; vbn  verb  en	0	The association ratio identifies quite a number of verbs associated in an interesting way with to; restricting our attention to pairs with a score of 30 or more, there are 768 verbs associated with the preposition toin and 551 verbs with the infinitive marker to/to	0	3	1
J90-1003	A88-1019	1990	The computational tools available for studying machinereadable corpora are at present still rather primitive	1	These are concordancing programs see Figure 1, which are basically KWIC key word in context; <REF>Aho et al 1988</REF> indexes with additional features such as the ability to extend the context, sort leftward as well as rightward, and so on	0	There is very little interactive software	0	In a typical situation in the lexicography of the 1980s, a lexicographer is giwen the concordances for a word, marks up the printout with colored pens to identify the salient senses, and then writes syntactic descriptions and definitions	0	1	3
W00-1309	A88-1019	2000	/3 2	0	precision  recall 1 HMM-based Chunk Tagger The idea of using statistics for chunking goes back to <TREF>Church1988</TREF>, who used corpus frequencies to determine the boundaries of simple non-recursive noun phrases	1	Skut and <REF>Brants1998</REF> modified Churchs approach in a way permitting efficient and reliable recognition of structures of limited depth and encoded the structure in such a way that it can be recognised by a Viterbi tagger	0	This makes the process run in time linear to the length of the input string	0	6	1
J97-2002	A88-1019	1997	Input Text Tokenization Part-of-speech Lookup Descriptor array construction Classification by learning algorithm Text withsentence boundaries disambiguated 31 Tokenization The first stage of the process is lexical analysis, which breaks the input text a stream of characters into tokens	0	The Satz tokenizer is implemented using the UNIX tool LEX <REF>Lesk and Schmidt 1975</REF> and is modeled on the tokenizer used by the PARTS part-of-speech tagger <TREF>Church 1988</TREF>	1	The tokens returned by the LEX program can be a sequence of alphabetic characters, a sequence of digits, 8 or a sequence of one or more non-alphanumeric characters such as periods or quotation marks	0	32 Part-of-Speech Lookup The individual tokens are next assigned a series of possible parts of speech, based on a lexicon and simple heuristics described below	0	6	1
J97-2002	A88-1019	1997	The lexicon and thus the frequency counts used to calculate the descriptor arrays were derived from the Brown corpus <REF>Francis and Kucera 1982</REF>	0	In initial experiments we used the extensive lexicon from the PARTS part-of-speech tagger <TREF>Church 1988</TREF>, which contains 30,000 words	1	We later experimented with a much smaller lexicon, and these results are discussed in Section 44	0	In Sections 41-49 we describe the results of our experiments with the Satz system using the neural network as the learning algorithm	0	3	1
W96-0303	A88-1019	1996	We regard our use of probabilities as being consistent with Bauers claim that accounting for semi-productivity is an issue of performance, not competence <REF>Bauer 1983</REF>:71f	0	The frequency with which a given word form is associated with a particular lexical entry ie sense or grammatical realization is often highly skewed; <TREF>Church 1988</TREF> points out that a model of part-of-speech assignment in context will be 90 accurate for English if it simply chooses the lexically most frequent part-of-speech for a given word	1	<REF>Briscoe and Carroll 1995</REF> found in one corpus that there were about 18 times as many instances of believe in the most common subcategorizati0n class as in the 4 least common classes combined	0	In the absence of other factors, it seems very likely that language users utilize frequency information to resolve indeterminacies in both generation and interpretation	0	6	1
I05-2022	A88-1019	2005	12 Survey of Related Work Chunking has been studied for English and other languages, though not very extensively	0	The earliest work on chunking based on machine learning goes to Church K, 1988 for English	1	<REF>Ramshaw and Marcus, 1995</REF> used transformation based learning using a large annotated corpus for English	0	<REF>Skut and Brants, 1998</REF> modi ed Churchs approach, and used standard HMM based tagging methods to model the chunking process	0	6	1
P99-1004	A88-1019	1999	27 3 Empirical Comparison We evaluated the similarity functions introduced in the previous section on a binary decision task, using the same experimental framework as in our previous preliminary comparison <REF>Dagan et al , 1999</REF>	0	That is, the data consisted of the verb-object cooccurrence pairs in the 1988 Associated Press newswire involving the 1000 most frequent nouns, extracted via Churchs 1988 and Yarowskys processing tools	1	587,833 80 of the pairs served as a training set from which to calculate base probabilities	0	From the other 20, we prepared test sets as follows: after discarding pairs occurring in the training data after all, the point of similarity-based estimation is to deal with unseen pairs, we split the remaining pairs into five partitions, and replaced each nounverb pair n, vl with a noun-verb-verb triple n, vl, v2 such that Pv2  Pvl	0	3	1
P03-1003	A88-1019	2003	In this paper, we propose a new space and a new metric for computing this distance	0	Being inspired by the success of noisy-channel-based approaches in applications as diverse as speech recognition <REF>Jelinek, 1997</REF>, part of speech tagging <TREF>Church, 1988</TREF>, machine translation <REF>Brown et al , 1993</REF>, information retrieval <REF>Berger and Lafferty, 1999</REF>, and text summarization <REF>Knight and Marcu, 2002</REF>, we develop a noisy channel model for QA	1	This model explains how a given sentence S A that contains an answer sub-string A to a question Q can be rewritten into Q through a sequence of stochastic operations	0	Given a corpus of questionanswer pairs Q, S A , we can train a probabilistic model for estimating the conditional probability PQ  S A 	0	2	1
C96-2136	A88-1019	1996	7 0 7 3 Word Segmentation Algorithm 31 Statistical Language Model For the language model in Equation 1, we used the part of speech trigram nlodel POS trigranl or 2nd-order HMM	0	It is used,as tagging mode in English <TREF>Church, 1988</TREF>; <REF>Cutting et al , 1992</REF> and morphological analysis nlodel word segmentation and tagging in Japanese <REF>Nagata, 1994</REF>	1	Let the input character sequence be /  ccec  We approxinlate PCby PW, 7, the joint prol>ability of word sequence W  wlw2u, and part of speech sequence   tlte, t,,	0	PW,T is then approximated t>y the product of parts of speech trigram probabilities Ptiti-2, i-l and word output probabilities for given part of speech Pwiltl, 71 pc pw, -- IX pt, lt,-,t,-,p,lt, 5 i1 Ptilti-,e,ti- and /-wlti  are estimated >y computing the relative frequencies of the corresponding events in training corpus a 32 Forward-DP Backward-A Algorithm /sing the language model 5, Japanese morplological analysis can be detined,as finding tile set of word segmentation and parts of speech 1/, 7 that maximizes the joint probability of word sequence and tag sequence PW, 7	0	6	1
C96-1058	A88-1019	1996	In this seelion, we will outline the three lexicalist, linguistically perspicuous, qualitatiwly different models that we have leveloped a, nd tested	0	21 Model A: Bigram lexieal affinities N-gram tatters like <TREF>Church, 1988</TREF>; lelinek 1985; <REF>Kupiec 1992</REF>; <REF>Merialdo 1990</REF> take the following view of row /, tagged sentctrce enters the worhl	1	Iirst, a setuenee of tags is gnexated aecordittg to a Markov lrocess, with th random choice of ech tag conditioned ou the previous two tags	0	Second, a word is choseu conditional on each tag	0	6	1
J95-2001	A88-1019	1995	Nevertheless, if a large POS set is specified, the number of rules increases significantly and rule definition becomes highly costly and cumbersome	0	Stochastic taggers use both contextual and morphological information, and the model parameters are usually defined or updated automatically from tagged texts Cerf-Danon and E1-<REF>Beze 1991</REF>; <TREF>Church 1988</TREF>; <REF>Cutting et al 1992</REF>; <REF>Dermatas and Kokkinakis 1988, 1990, 1993, 1994</REF>; <REF>Garside, Leech, and Sampson 1987</REF>; <REF>Kupiec 1992</REF>; Maltese  Department of Electrical Engineering, Wire Communications Laboratory WCL, University of Patras, 265 00 Patras, Greece	1	E-mail: dermataswcleeupatrasgr	0	 1995 Association for Computational Linguistics Computational Linguistics Volume 21, Number 2 and <REF>Mancini 1991</REF>; <REF>Meteer, Schwartz, and Weischedel 1991</REF>; <REF>Merialdo 1991</REF>; <REF>Pelillo, Moro, and Refice 1992</REF>; <REF>Weischedel et al 1993</REF>; <REF>Wothke et al 1993</REF>	0	6	1
W07-0813	A88-1019	2007	2 Relation to Previous Works Quite a few works have dealt with extending a given POS tagger, mainly by smoothing it using extra-information about untreated words	0	For example, <TREF>Church, 1988</TREF> uses the simple heuristic of predicting proper nouns from capitalization	0	This method is not applicable to Arabic and Hebrew, which lack typographical marking of proper nouns	1	More advanced methods like those described by Weischedel et al	0	1	3
W96-0208	A88-1019	1996	In particular, it would be interesting to see if the accuracy ranking of the seven algorithms is affected by a change in the representation	0	Similar comparisons of a range of algorithms should also be performed on other natural language problems such as part-of-speech tagging <TREF>Church, 1988</TREF>, prepositional phrase attachment <REF>Hindle  Rooth, 1993</REF>, anaphora resolution Anoe  <REF>Bennett, 1995</REF>, etc Since the requirements of individual tasks vary, different algorithms may be suitable for different sub-problems in natural language processing	1	87 o 0 : 0 0  / 350 300 250 200 150 1 O0 50 I I I I I 	0	Naive Bales o J 3 Nearest Neighbor --0-- Perceptron -m- C45 ---x   PFOIL-DNF ---1 PFOIL-CNF ---1 PFOIL-DLIST --- I  G    :::::-;    ii212  x2C:222Z/2: 200 400 600 800 1000 1200 Training Examples Figure 3: Testing Time for Line Corpus Conclusions This paper has presented fairly comprehensive experiments comparing seven quite different empirical methods on learning to disambiguate words in context	0	6	1
W99-0634	A88-1019	1999	As far as coreference resolution is concerned, the goal of these NLP modules is to determine the boundary of the markables, and to provide the necessary information about each markable for subsequent generation of features in the training examples	0	Our part-of-speech tagger is a standard sta285 tistical bigram tagger based on the Hidden Markov Model HMM <TREF>Church, 1988</TREF>	1	Similarly, we built a statistical HMM-based noun phrase identification module where the noun phrase boundaries are determined solely based on the part-of-speech tags assigned to the words in a sentence	0	We also implemented a module that recognizes MUC-style named entities, ie, organization, person, location, date, time, money, and percent	0	3	1
C98-1077	A88-1019	1998	1 is a typical example of the ambiguities encountered in a running text: little POS ambiguity, but a lot of gender, number and case ambiguity columns 3 to 5	0	485 3 The Model Instead of employing the source-channel paradigm for tagging more or less explicitly present eg in <REF>Merialdo, 1992</REF>, <TREF>Church, 1988</TREF>, <REF>HajiS, HladkA, 1997</REF> used in the past notwithstanding some exceptions, such as Maximum Entropy and rule-based taggers, we are using here a direct approach to modeling, for which we have chosen an exponential probabilistic model	1	Such model when predicting an event  y E Y in a context x has the general form PAC,eYl x  expEiI ifiy,x Zx 3 where fiY, x is the set of size n of binary-valued yes/no features of the event value being predicted and its context, Ai is a weigth in the exponential sense of the feature fi, and the normalization factor Zx is defined naturally as n Zx   exp Aifiy,x 4 yEY i:1 We use a separate model for each ambiguity class AC which actually appeared in the training data of each of the 13 morphological categories 6	0	The final PAC YlX distribution is further smoothed using unigram distributions on subtags again, separately for each category	0	2	1
J93-1004	A88-1019	1993	For a larger dataset, such as the Canadian Hansards, it was not possible to check the results by hand	0	We used the same procedure that is used in <TREF>Church 1988</TREF>	1	This procedure was developed by Kathryn Baker unpublished	0	79 Computational Linguistics Volume 19, Number 1 fefQ t e E 0 0 0 0 P, o Ol I 0 	0	3	1
W98-1205	A88-1019	1998	The accuracy of this data has an impact on the tagging accuracy of both the HMM itself and the derived transducer	0	The training of the HMM can be done on either a tagged or untagged corpus, and is not a topic of this paper since it is exhaustively described in the literature <REF>Bahl and Mercer, 1976</REF>; <TREF>Church, 1988</TREF>	1	An HMM can be identically represented by a weighted FST in a straightforward way	0	We are, however, interested in non-weighted transducers	0	6	1
A00-1024	A88-1019	2000	The first feature represents the part of speech of the word	0	Vve use an in-house statistical tagger based on <TREF>Church, 1988</TREF> to tag the text in which the unknown word occurs	1	The tag set used is a simplified version of the tags used in the machinereadable version of the Oxford Advanced Learners Dictionary OALD	0	The tag set contains just one tag to identify nouns	0	3	1
A94-1009	A88-1019	1994	The first major use of HMMs for part of speech tagging was in CLAWS <REF>Garside et al , 1987</REF> in the 1970s	0	With the availability of large corpora and fast computers, there has been a recent resurgence of interest, and a number of variations on and alter53 natives to the FB, Viterbi and BW algorithms have been tried; see the work of, for example, Church <TREF>Church, 1988</TREF>, Brill <REF>Brill and Marcus, 1992</REF>; <REF>Brill, 1992</REF>, DeRose <REF>DeRose, 1988</REF> and gupiec <REF>Kupiec, 1992</REF>	1	One of the most effective taggers based on a pure HMM is that developed at Xerox <REF>Cutting et al , 1992</REF>	0	An important aspect of this tagger is that it will give good accuracy with a minimal amount of manually tagged training data	0	6	1
W03-1706	A88-1019	2003	Specifically speaking, the content chunking contains two subtasks: 1 to recognize the maximum phrase in a sequence of content words; 2 to analyze the hierarchical structure within the phrase down to words	0	Like baseNP chunking<TREF>Church, 1988</TREF>; <REF>Ramshaw  Marcus 1995</REF>, content chunk parsing is also a kind of shallow parsing	1	Content chunk parsing is deeper than baseNP chunking in two aspects: 1 a content chunk may contain verb phrases and other phrases even a full sentence as long as the all the components are content words; 2 it may contain recursive NPs	0	Thus the content chunk can supply more structural information than a baseNP	0	6	1
W05-1510	C88-2121	2005	From the perspective of using a lexicalized grammar developed for parsing and importing parsing techniques, our method is similar to the following approaches	1	The Fergus system <REF>Bangalore and Rambow, 2000</REF> uses LTAG Lexicalized Tree Adjoining Grammar <TREF>Schabes et al , 1988</TREF> for generating a word lattice containing realizations and selects the best one using a trigram model	0	<REF>White and Baldridge 2003</REF> developed a chart generator for CCG Combinatory Categorial Grammar <REF>Steedman, 2000</REF> and proposed several techniques for efficient generation such as best-first search, beam thresholding and chunking the input logical forms <REF>White, 2004</REF>	0	Although some of the techniques look effective, the models to rank candidates are still limited to simple language models	0	6	1
W90-0102	C88-2121	1990	Work on the use of synchronous TAGs to capture quantifier scoping possibilities makes use of so-called multicomponent TAGs	0	Finally, the base TAGs may be lexicalized <TREF>Schabes et al , 1988</TREF> or not	1	Once the base formalism has been decided upon we currently are using lexicalized multi-component TAGs with substitution and adjunction, a simple translation strategy from a source string to a target is to parse the string using an appropriate TAG parser for the base formalism	1	Each derivation of the source string can be mapped according to the synchronizing links in the grammar to a target derivation	0	3	2
C96-1085	C88-2121	1996	Also, the provision of conceptual entities which are incrementally generated by the semantic interpretation process supplies the necessary anchoring points for the continuous resolution of textual anaphora and ellipses <REF>Strube  Hahn, 1995</REF>; <REF>Hahn et al , 1996</REF>	0	The lexical distribution of grammatical knowledge one finds in many lexiealized grammar formalisms eg , LTAGS <TREF>Schabes et al , 1988</TREF> or HPSG <REF>Pollard  Sag, 1994</REF> is still constrained to declarative notions	1	Given that the control flow of text understanding is globally unpredictable and, also, needs to be purposefully adapted to critical states of the analysis eg , cases of severe extragrammaticality, we drive lexicalization to its limits in that we also incorporate procedural control knowledge at the lexical gr,unmar level	0	The specification of lexiealized communication primitives allows heterogeneous and local lorms of interaction among groups of lexical items	0	1	3
C92-1034	C88-2121	1992	This will allow for easy maintenance and facilitate updates to the grammar	0	1 Motivations Lexicalized tree-adjoining grammar LTAG <TREF>Schabes et al , 1988</TREF>; <REF>Schabes, 1990</REF> is a tree-rewriting formalism used for specifying the syntax of natural languages	1	It combines elementary lexical trees with two operations, adjoining and substitution	0	In a LTAG, lexical itenm are associated with complex syntactic structures in the form of trees that define the various phrase structures they can participate in	0	6	1
W03-0401	C88-2121	2003	Formally, a derivation tree is represented as a set of dependencies: D   i,  j,r i , where  i is an elementary tree,   i represents a node in  j where substitution/adjunction has occurred, and r i is a label of the applied rule, ie, adjunction or substitution	0	A probability of derivation tree D   i,  j,r i  is generally defined as follows <TREF>Schabes et al , 1988</TREF>; <REF>Chiang, 2000</REF>	1	pD productdisplay i p i   j,r i  Note that each probability on the right represents the syntactic/semantic preference of a dependency of two lexical items	0	We can readily see that the model is very similar to LPCFG models	0	4	2
W03-0401	C88-2121	2003	That is, the models are still based on decomposition into primitive lexical dependencies	1	Derivation trees, the structural description in LTAG <TREF>Schabes et al , 1988</TREF>, represent the association of lexical items ie, elementary trees	1	In LTAG, all syntactic constraints of words are described in an elementary tree, and the dependencies of elementary trees, ie, a derivation tree, describe the semantic relations of words more directly than lexicalized parse trees	0	For example, Figure 3 has a derivation tree corresponding to the parse tree in Figure 1 2	0	5	2
P98-1091	C88-2121	1998	A more linguistically motivated approach is to expand the domain of productions downward to incorporate more tree structures	0	The Lexicalized Tree-Adjoining Grammar LTAG formalism <TREF>Schabes et al , 1988</TREF>, <REF>Schabes, 1990</REF>, although not context-free, is the most well-known instance in this category	1	PLTIGs belong to this third category and generate only context-free languages	0	LTAGs and LTIGs are tree-rewriting systems, consisting of a set of elementary trees combined by tree operations	0	1	2
H91-1035	C88-2121	1991	Thus CCG assigns the following two groupings to John likes apples: 2 John likes apples 3 John likes apples The work on CCG was presented by Mark Steedman in an earlier DARPA SLS Workshop <REF>Steedman, 1989</REF>	0	In this paper, we show how a CCG-like account for coordination can be constructed in the framework of lexicalized tree-adjoining grammars TAGs <REF>Joshi, 1987</REF>; <TREF>Schabes et al , 1988</TREF>; <REF>Schabes, 1990</REF>	1	2	0	In particular, we show how a fixed constituency can be maintained at the level of the elementary trees of lexicalized TAGs and yet be able to achieve the kind of flexibility needed for dealing with the so-called non-constituents	0	4	2
A94-1022	C88-2121	1994	which cannot be felicitously uttered except in a context where there is something in the discourse that a restriction could apply to	0	Conventional approaches to subcategorization, such as Definite Clause Grammar <REF>Pereira and Warren, 1980</REF>, Categorial Grammar <REF>Ades and Steedman, 1982</REF>, PATR-II <REF>Shieber, 1986</REF>, and lexicalized TAG <TREF>Schabes et al, 1988</TREF> all deal with complementation by including in one form or another a notion of subcategorization frame that specifies a sequence of complement phrases and constraints on them	0	Handling all the possible variations in complement distribution in such formalisms inevitably leads to an explosion in the number of such frames, and a correspondingly more difficult task in porting to a new domain	0	In our approach, on the other hand, it becomes possible to view subcategorization of a lexical item as a set of constraints on the outgoing arcs of its semantic graph node	1	2	3
P93-1017	C88-2121	1993	Recently there has been a gain in interest in the so-called mildly context-sensitive formalisms Vijay-<REF>Shanker, 1987</REF>; <REF>Weir, 1988</REF>; <REF>Joshi, VijayShanker, and Weir, 1991</REF>; Vijay-<REF>Shanker and Weir, 1993a</REF> that generate only a small superset of context-free languages	0	One such formalism is lexicalized tree-adjoining grammar LTAG Schabes, Abeill, and <REF>Joshi, 1988</REF>; <REF>Abeillfi et al , 1990</REF>; <REF>Joshi and Schabes, 1992</REF>, which provides a number of attractive properties at the cost of decreased efficiency, On6-time in the worst case <REF>VijayShanker, 1987</REF>; <REF>Schabes, 1991</REF>; <REF>Lang, 1990</REF>; <REF>VijayShanker and Weir, 1993b</REF>	1	An LTAG lexicon consists of a set of trees each of which contains one or more lexical items	0	These elementary trees can be viewed as the elementary clauses including their transformational variants in which the lexical items participate	0	4	2
P07-1079	C88-2121	2007	Much of the appeal of these approaches is tied to the use of a simple formalism, which allows for the use of efficient parsing algorithms, as well as straightforward ways to train discriminative models to perform disambiguation	0	At the same time, there is growing interest in parsing with more sophisticated lexicalized grammar formalisms, such as Lexical Functional Grammar LFG <REF>Bresnan, 1982</REF>, Lexicalized Tree Adjoining Grammar LTAG <TREF>Schabes et al , 1988</TREF>, Headdriven Phrase Structure Grammar HPSG <REF>Pollard and Sag, 1994</REF> and Combinatory Categorial Grammar CCG <REF>Steedman, 2000</REF>, which represent deep syntactic structures that cannot be expressed in a shallower formalism designed to represent only aspects of surface syntax, such as the dependency formalism used in current mainstream dependency parsing	0	We present a novel framework that combines strengths from surface syntactic parsing and deep syntactic parsing, specifically by combining dependency and HPSG parsing	1	We show that, by using surface dependencies to constrain the application of wide-coverage HPSG rules, we can benefit from a number of parsing techniques designed for high-accuracy dependency parsing, while actually performing deep syntactic analysis	0	5	2
W07-2213	C88-2121	2007	This paper will concentrate on context-free grammars CFG and their associated parsers	0	However, virtually all Tree Adjoining Grammars TAG, see eg, <TREF>Schabes et al , 1988</TREF> used in NLP applications can almost be seen as lexicalized Tree Insertion Grammars TIG, which can be converted into strongly equivalent CFGs <REF>Schabes and Waters, 1995</REF>	1	Hence, the parsing techniques and tools described here can be applied to most TAGs used for NLP, with, in the worst case, a light over-generation which can be easily and efficiently eliminated in a complementary pass	0	This is indeed what we have achieved with a TAG automatically extracted from Villemonte de <REF>La Clergerie, 2005</REF>s large-coverage factorized French TAG, as we will see in Section 4	0	4	2
C90-3001	C88-2121	1990	We can thus define lexical transfer rules that avoid the defects of a mere word-to-word approach but still benefit from the simplicity and elegance of a lexical approach	0	We rely on the French and English LTAG grammars Abeille 1988, Abeille 1990 b, Abeilld et al 1990, Abeill6 and Schabes 1989, 1990 that have been designed over the past two years jointly at University of Pennsylvania and University of Paris 7-Jussieu	1	1 Strategy for Machine Translation with LTAGs The idea of using grammars written with lexicalist formalisms for machine translation is not new This research was partially ftmded by ARO grant DAAG29-84-K-0061, DARPA grant N00014-85-K0018, and NSF grant MCS-82-19196 at the University of Pen nsylvania	0	We are indebted to Stuart Shieber for his valuable comments	0	5	2
E91-1005	C88-2121	1991	3 A TAG Analysis The TAG formalism for a recent introduction, see <REF>Joshi 1987a</REF> is well suited for linguistic description because 1 it provides a larger domain of locality than a CFG or other augmented CFG-based formalisms such as tlPSG or LFG, and 2 it allows factoring of recursion from the domain of dependencies	0	This extended domain of locality, provided by the elementary trees of TAG, allows us to lexicalize a TAG grammar: we can associate each tree in a grammar with a lexical item <TREF>Schabes et al 1988</TREF>, <REF>Schabes 1990</REF> 4	1	The tree will contain the lexical item, and all of its syntac3Some verbs allow scrambling out of their Complements more freely than others	0	It appears that all subject-control verbs and most object-control verbs governing the dative allow scrambling fairly fely, while scrambling with objectcontrol verbs governing the accusative is more restricted cir	0	4	2
P95-1036	C88-2121	1995	In Section 8 we conclude with some directions for future work	0	2 Lexicalized Tree-Adjoining Grammar Lexicalized Tree-Adjoining Grammar LTAG <TREF>Schabes et al , 1988</TREF>; <REF>Schabes, 1990</REF> consists of ELEMENTARY TREES, with each elementary tree having a lexical item anchor on its frontier	1	An elementary tree serves as a complex description of the anchor and provides a domain of locality over which the anchor can specify syntactic and semantic predicate-argument constraints	0	Elementary trees are of two kinds a INITIAL TREES and b AUXILIARY TREES	0	6	1
P98-1026	C88-2121	1998	178 6 Comparison to PSG Approaches One feature of word order domains is that they factor ordering alternatives from the syntactic tree, much like feature annotations do for morphological alternatives	0	Other lexicalized grammars collapse syntactic and ordering information and are forced to represent ordering alternatives by lexical ambiguity, most notable L-TAG <TREF>Schabes et al , 1988</TREF> and some versions of CG <REF>Hepple, 1994</REF>	0	This is not necessary in our approach, which drastically reduces the search space for parsing	1	This property is shared by the proposal of <REF>Reape 1993</REF> to associate HPSG signs with sequences of constituents, also called word order domains	0	2	3
P05-2024	C88-2121	2005	This high coverage allowed us to evaluate the parser in terms of the accuracy of dependency analysis on real-world texts, the evaluation measure that is previously used for more statistically-oriented parsers	0	2 HPSG Head-Driven Phrase Structure Grammar HPSG is classified into lexicalized grammars <TREF>Schabes et al , 1988</TREF>	1	It attempts to model linguistic phenomena by interactions between a small number of grammar rules and a large number of lexical entries	0	Figure 1 shows an example of an HPSG derivation of a Japanese sentence kare ga shinda, which means, He died In HPSG, linguistic entities such as words and phrases are represented by typed feature structures called signs, and the grammaticality of a sentence is verified by applying grammar rules to a sequence of signs	0	6	1
P03-2036	C88-2121	2003	We also investigate the reason for that difference	0	Various parsing techniques have been developed for lexicalized grammars such as Lexicalized Tree Adjoining Grammar LTAG <TREF>Schabes et al , 1988</TREF>, and Head-Driven Phrase Structure Grammar HPSG <REF>Pollard and Sag, 1994</REF>	0	Along with the independent development of parsing techniques for individual grammar formalisms, some of them have been adapted to other formalisms <TREF>Schabes et al , 1988</TREF>; van <REF>Noord, 1994</REF>; <REF>Yoshida et al , 1999</REF>; <REF>Torisawa et al , 2000</REF>	0	However, these realizations sometimes exhibit quite different performance in each grammar formalism <REF>Yoshida et al , 1999</REF>; <REF>Yoshinaga et al , 2001</REF>	1	1	3
P03-2036	C88-2121	2003	Various parsing techniques have been developed for lexicalized grammars such as Lexicalized Tree Adjoining Grammar LTAG <TREF>Schabes et al , 1988</TREF>, and Head-Driven Phrase Structure Grammar HPSG <REF>Pollard and Sag, 1994</REF>	0	Along with the independent development of parsing techniques for individual grammar formalisms, some of them have been adapted to other formalisms <TREF>Schabes et al , 1988</TREF>; van <REF>Noord, 1994</REF>; <REF>Yoshida et al , 1999</REF>; <REF>Torisawa et al , 2000</REF>	0	However, these realizations sometimes exhibit quite different performance in each grammar formalism <REF>Yoshida et al , 1999</REF>; <REF>Yoshinaga et al , 2001</REF>	0	If we could identify an algorithmic difference that causes performance difference, it would reveal advantages and disadvantages of the different realizations	1	5	2
A92-1030	C88-2121	1992	The parser achieves an OGn6-time worst case behavior, OG2n4-time for unambiguous grammars and linear time for a large class of grammars	0	The parser uses the following two-pass parsing strategy originally defined for lexicalized grammars <TREF>Schabes et al , 1988</TREF> which improves its performance in practice <REF>Schabes and Joshi, 1990</REF>:  In the first step the parser will select, the set of structures corresponding to each word in the sentence	1	Each structure can be considered as encoding a set of rules	0	In the second step, the parser tries to see whether these structures can be combined to obtain a wellformed structure	0	3	2
A92-1030	C88-2121	1992	XTAG runs under Common Lisp and X Window CLX	0	Tree-adjoining grammar TAG <REF>Joshi et al , 1975</REF>; <REF>Joshi, 1985</REF>; <REF>Joshi, 1987</REF> and its lexicalized variant <TREF>Schabes et al , 1988</TREF>; <REF>Schabes, 1990</REF>; <REF>Joshi and Schabes, 1991</REF> are tree-rewriting systems in which the syntactic properties of words are encoded as tree structured-objects of extended size	0	TAG trees can be combined with adjoining and substitution to form new derived trees	0	1 Tree-adjoining grammar differs from more traditional tree-generating systems such as context-free grammar in two ways: 1	0	6	1
A92-1030	C88-2121	1992	This information is particularly useful for a top-down component of the parser <REF>Schabes and Joshi, 1990</REF>	0	XTAG provides all the utilities required for designing a lexicalized TAG structured as in Schabes et al 1988	1	All the syntactic concepts of lexicalized TAG such as the grouping of the trees in tree families which represents the possible variants on a basic subcategorization frame are accessible through mouse-sensitive items	0	Also, all the operations required to build a grammar such as load trees, define tree families, load syntactic and morphological lexicon can be predefined with a macro-like language whose instructions can be loaded from a file See Figure 5	0	4	2
A92-1030	C88-2121	1992	See the introduction by Joshi 1987 for an introduction to tree-adjoining grammar	0	We refer the reader to Joshi 1985, Joshi 1987, Kroch and Joshi 1985, Abeill et al 1990a, Abeill 1988 and to Joshi and Schabes 1991 for more information on the linguistic characteristics of TAG such as its lexicalization and factoring recursion out of dependencies	1	2The TAG derivation tree is the basis for semantic interpretation <REF>Shieber and Schabes, 1990b</REF>, generation <REF>Shieber and Schabes, 1991</REF> and machine translation Abeill et al , 1990b since the information given in this data-structure is richer than the one found in the derived tree	0	Furthermore, it is at the level of the derivation tree that ambiguity must be defined	0	5	2
C04-1204	C88-2121	2004	Interestingly, several studies suggested that the identification of PropBank annotations would require linguistically-motivated features that can be obtained by deep linguistic analysis <REF>Gildea and Hockenmaier, 2003</REF>; <REF>Chen and Rambow, 2003</REF>	0	They employed a CCG <REF>Steedman, 2000</REF> or LTAG <TREF>Schabes et al , 1988</TREF> parser to acquire syntactic/semantic structures, which would be passed to statistical classifier as features	0	That is, they used deep analysis as a preprocessor to obtain useful features for training a probabilistic model or statistical classifier of a semantic argument identifier	0	These results imply the superiority of deep linguistic analysis for this task	1	4	2
E91-1006	C88-2121	1991	All errors are of course our own	0	As for Lexicalized TAGs, in <TREF>Schabes et al , 1988</TREF> a two step algorithm has been presented: during the first step the trees corresponding to the input string are selected and in the second step the input string is parsed with respect to this set of trees	0	Another paper by <REF>Schabes and Joshi 1989</REF> shows how parsing strategies can take advantage of lexicalization in order to improve parsers performance	0	Two major advantages have been discussed in the cited work: grammar filtering the parser can use only a subset of the entire grammar and bottom-up information further constraints are imposed on the way trees can be combined	1	1	2
E91-1006	C88-2121	1991	In <REF>Kroch and Joshi, 1985</REF> a detailed discussion of the linguistic relevance of TAGs can be found	0	Lexicalized Tree Adjoining Grammars <TREF>Schabes et al , 1988</TREF> are a refinement of TAGs such that each elementary tree is associated with a lexieal item, called the anchor of the tree	1	Therefore, Lexicalized TAGs conform to a common tendency in modem theories of grammar, namely the attempt to embed grammatical information within lexical items	0	Notably, the association between elementary trees and anchors improves also parsing performance, as will be discussed below	0	4	2
P99-1059	C88-2121	1999	Early mechanisms of this sort included categorial grammar Bar-<REF>Hillel, 1953</REF> and subcategorization frames <REF>Chomsky, 1965</REF>	0	Other lexicalized formalisms include <TREF>Schabes et al , 1988</TREF>; Meluk, 1988; <REF>Pollard and Sag, 1994</REF>	1	Besides the possible arguments of a word, a natural-language grammar does well to specify possible head words for those arguments	0	Convene requires an NP object, but some NPs are more semantically or lexically appropriate here than others, and the appropriateness depends largely on the NPs head eg , meeting	0	6	1
C98-1088	C88-2121	1998	A more linguistically motivated approach is to expand the domain of productions downward to incorporate more tree structures	0	The Lexicalized Tree-Adjoining Grammar LTAG formalism <TREF>Schabes et al, 1988</TREF>, <REF>Schabes, 1990</REF> , although not context-free, is the most well-known instance in this category	1	PLTIGs belong to this third category and generate only context-free languages	0	LTAGs and LTIGs are tree-rewriting systems, consisting of a set of elementary trees combined by tree operations	0	1	2
W98-1125	J86-3001	1998	It is somewhat tempting to take the results as indicating that clues have bad effects on the performance more discussion on this later	0	This, however, appears to run counter to what we expect from results reported in prior work on discourse<REF>Kurohashi and Nagao, 1994</REF>; <REF>Litman and Passonneau, 1995</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Marcu, 1997</REF>, where the notion of clues or cue phrases forms an important part of identifying a structure of discourse7 Table 4 shows how the confidence value CF affects the performance of discourse models	0	The CF 7 One problem with earlier work is that evaluations are done on very small data; 9 sections from a scientific writing approx	0	300 sentences <REF>Kurohashi and Nagao, 1994</REF>: 15 narrathes I113 clauses Lhman and Passonneau	0	0	0
W04-0211	J86-3001	2004	Largely formal methods involving manipulating information in lexical ontologies and the output of sentential syntactic and semantic analysis are sufficient to account for most cases of discourse continuity, and give rise to only limited ambiguity in most other cases	0	2 The assignment of correct temporal, personal and spatial interpretation to utterances, which relies in large part on the relative location of referential expression and their 2 Complex default logic based reasoning as in Structured Discourse Representation Theory <REF>Asher 1993</REF>; <REF>Asher and Lascarides 2003</REF>, speculations about the intentions or beliefs of speakers as in <TREF>Grosz and Sidner 1986</TREF>, or the intricate node labeling exercises familiar from Rhetorical Structure Theory <REF>Mann and Thompson 1988</REF>; <REF>Marcu 1999, 2000</REF> are not necessary	0	referents in the DPT representation of the structure of the discourse, can then often be recovered	0	From a computational point of view, this is good news	0	0	0
P89-1025	J86-3001	1989	standing have recognized the need for such information	0	In their work on discourse analysis, <TREF>Grosz and Sidner 1986</TREF> argue that it is necessary to represent the intentional structure, the attentional structure knowledge about which aspects of a dialogue are in focus at each point, and the linguistic structure of The research described in this paper was supported by the Defense Advanced Research Projects Agency DARPA under a NASA Ames cooperative agreement number NCC 2-520	0	The authors would like to thank William Swartout for comments on earlier versions of this paper	0	203 the discourse	0	0	0
P89-1025	J86-3001	1989	There is thus a need for a text plan to contain a specification of the intended effect of individual parts of the text on the hearer and how the parts relate to one another	0	We have developed a text planner that records the following information about the responses it produces:  the information that <TREF>Grosz and Sidner 1986</TREF> have presented as the basics of a discourse structure: intentional structure: a representation of the effect each part of the text is intended to have on the hearer and how the complete text achieves the overall discourse purpose eg , describe entity, persuade hearer to perform an action	0	attentional structure: information / about which objects, properties and events are salient at each point in the discourse	0	Users followup questions are often ambiguous	0	0	0
W93-0236	J86-3001	1993	INTENTIONALITY IN A TOPICAL APPROACH OF DISCOURSE STRUCTURE 1 Jan van Kuppevelt University of Nijmegen Department of Philosophy e-mail: JVKUPPEV KUNRC1URCKUNNL  Position paper The alternative to be outlined provides a proposal to solve a central problem in research on discourse structure and discourse coherence, namely, as pointed out by many authors, that of the relationship between linguistic and intentional structure, or, in other words, between subject matter and presentational relations <REF>Mann and Thompson 1988</REF> or informational and intentional relations <REF>Moore and Pollack 1992</REF>	0	As is argued for in <REF>Van Kuppevelt 1993</REF>, this alternative not only implies uniformity on the structural levels involved, ie the linguistic and intentional level, but also on the level of attentional states <TREF>Grosz and Sidner 1986</TREF>	0	2 The latter is ruled by the dynamics of topic constitution and topic termination, determining which discourse units are in focus of attention during the development of the discourse	0	3 We will see that both linguistic relations and intentions are defined in a uniform way by topic-forming questions in discourse, thereby automatically satisfying the need for a multi-level analysis as is argued for in <REF>Moore and Paris 1992</REF>, and as is signalled by Dale this volume, avoiding differences in discourse segmentation between RST analyses and intentional approaches	0	0	0
W97-0402	J86-3001	1997	Discourse structures of dialogues are usually represented as hierarchical structures which This research is supported in part by the ministry of information and communication of Korea	0	reflect embedding subdialogues <TREF>Grosz and Sidner 1986</TREF>	0	Many researchers have studied the way how to analyze dialogues	0	One of the representative approaches is the plan-based method <REF>Litman et al 1987</REF>; <REF>Caberry 1989</REF>	0	0	0
W03-2121	J86-3001	2003	 extended monologues	0	There are several overtly	0	 declarative theories of the structure of such texts	0	 many of them stemming from the work of Mann	0	0	0
P02-1012	J86-3001	2002	Furthermore, current pronominalization strategies are ill-equipped to deal with the wide variety of reasons that pronouns are used in naturally occurring texts	0	Almost without exception, they focus on anaphoric pronouns as described in Focus/Centering Theory <REF>Webber, 1979</REF>; <REF>Sidner, 1983</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Walker, 1998</REF>, ignoring the multitude of other possible types	0	However, it is certainly true that authors make use of pronouns which are not motivated by anaphoric reference	0	In addition, because such approaches are oriented towards anaphora resolution during parsing, they ignore structures such as the discourse plan which are present during generation but not parsing	0	0	0
P02-1012	J86-3001	2002	Indeed, most work on pronouns in computational linguistics has come under the heading of anaphora resolution as an element of parsing rather than the heading of pronominalization as an element of generation	0	Since discourse anaphora resolution was first studied theoretically <REF>Grosz, 1977</REF>; <REF>Webber, 1979</REF>; <REF>Sidner, 1983</REF>; <TREF>Grosz and Sidner, 1986</TREF>, it has come to be dominated by Centering Theory <REF>Grosz et al , 1995</REF>; <REF>Di Eugenio, 1998</REF>; <REF>Walker, 1998</REF> which proposes rules for the determination of focus and salience within a given segment of discourse	0	Relatively little work has been done on alternate approaches to pronoun resolution <REF>Hobbs, 1976</REF>; <REF>Baldwin, 1995</REF>	0	While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation <REF>Not, 1996</REF>; <REF>Yeh and Mellish, 1997</REF>; <REF>McCoy and Strube, 1999</REF>; <REF>Henschel et al , 2000</REF>; <REF>Kibble and Power, 2000</REF>, there has yet been no substantial return contribution to the field of anaphora resolution	0	0	0
P97-1013	J86-3001	1997	out because unit I is not an important unit for span 1,2 and, as mentioned at the beginning of this section, a rhetorical relation that holds between two spans of a valid text structure must also hold between their most important units: the important unit of span 1,2 is unit 2, ie, the nucleus of the relation rhetrelCONCESSlON, 1,2	0	3 A corpus analysis of discourse markers 31 Materials We used previous work on cue phrases <REF>Halliday and Hasan, 1976</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Martin, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1995</REF>; <REF>Fraser, 1996</REF> to create an initial set of more than 450 potential discourse markers	0	For each potential discourse marker, we then used an automatic procedure that extracted from the Brown corpus a set of text fragments	0	Each text fragment contained a window of approximately 200 words and an emphasized occurrence of a marker	0	0	0
P97-1013	J86-3001	1997	In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs	0	Such constructs can include tense 96 and aspect <REF>Moens and Steedman, 1988</REF>; <REF>Webber, 1988</REF>; <REF>Lascarides and Asher, 1993</REF>, certain patterns of pronominalization and anaphoric usages <REF>Sidner, 1981</REF>; <TREF>Grosz and Sidner, 1986</TREF></TREF>; <REF>Sumita et al , 1992</REF>; <REF>Grosz, Joshi, and Weinstein, 1995</REF>,/t-clefts <REF>Delin and Oberlander, 1992</REF>, and discourse markers or cue phrases <REF>Ballard, Conrad, and Longacre, 1971</REF>; <REF>Halliday and Hasan, 1976</REF>; <REF>Van Dijk, 1979</REF>; <REF>Longacre, 1983</REF>; <TREF>Grosz and Sidner, 1986</TREF></TREF>; <REF>Schiffrin, 1987</REF>; <REF>Cohen, 1987</REF>; <REF>Redeker, 1990</REF>; <REF>Sanders, Spooren, and Noordman, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1995</REF>; <REF>Fraser, 1996</REF>; <REF>Moser and Moore, 1997</REF>	0	In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts	0	The intuition behind our choice relies on the following facts:  Psycholinguistic and other empirical research <REF>Kintsch, 1977</REF>; <REF>Schiffrin, 1987</REF>; <REF>Segal, Duchan, and Scott, 1991</REF>; <REF>Cahn, 1992</REF>; <REF>Sanders, Spooren, and Noordman, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1995</REF>; <REF>Costermans and Fayol, 1997</REF> has shown that discourse markers are consistently used by human subjects both as cohesive ties between adjacent clauses and as macroconnectors between larger textual units	0	0	0
P97-1013	J86-3001	1997	Despite the formal elegance of these approaches, they are very domain dependent and, therefore, unable to handle more than a few restricted exampies	0	On the other hand, although the theories described by <TREF>Grosz and Sidner 1986</TREF>, <REF>Polanyi 1988</REF>, and <REF>Mann and Thompson 1988</REF> are successfully applied manually, they,are too informal to support an automatic approach to discourse analysis	0	In contrast with this previous work, the rhetorical parser that we present builds discourse trees for unrestricted texts	0	We first discuss the key concepts on which our approach relies section 2 and the corpus analysis section 3 that provides the empirical data for our rhetorical parsing algorithm	0	0	0
P99-1046	J86-3001	1999	The prime motivation for identifying such units is to improve performance on languageprocessing or IR tasks	0	Discourse segmentation, on the other hand, is often finer-grained, and focuses on identifying relations between utterances eg <TREF>Grosz and Sidner, 1986</TREF> or <REF>Hirschberg and Grosz, 1992</REF>	0	Many topic segmentations algorithms have been proposed in the literature	0	There is not enough space to review them all here, so we will focus on describing a representative sample that covers most of the features used to predict the location of boundaries	0	0	0
P04-1019	J86-3001	2004	BRIDGING REFERENCES BR <REF>Clark, 1977</REF> anaphoric expressions that cannot be resolved purely on the basis of string matching and thus require the reader to bridge the gap using commonsense inferencesare arguably the most interesting and, at the same time, the most challenging problem in anaphora resolution	0	Work such as <REF>Poesio et al , 1998</REF>; <REF>Poesio et al , 2002</REF>; <REF>Poesio, 2003</REF> provided an experimental confirmation of the hypothesis first put forward by <REF>Sidner 1979</REF> that BRIDGING DESCRIPTIONS BD1 are more similar to pronouns than to other types of definite descriptions, in that they are sensitive to the local rather than the global focus <TREF>Grosz and Sidner, 1986</TREF>	0	This previuous work also suggested that simply choosing the entity whose description is lexically closest to that of the bridging description among those in the current focus space gives poor results; in fact, better results are obtained by always choosing as ANCHOR of the bridging reference2 the first-mentioned entity of the previous sentence <REF>Poesio, 2003</REF>	0	But neither source of information in isolation resulted in an accuracy over 40	0	0	0
P04-1019	J86-3001	2004	<REF>Poesio 2003</REF> used the Web to choose between the hypotheses concerning the anchors of mereological BDs in the GNOME corpus generated on the basis of Centering information see below	0	22 Salience One of the motivations behind <REF>Grosz and Sidners 1986</REF> distinction between two aspects of the attentional state the LOCAL FOCUS and the GLOBAL FOCUSis the difference between the interpretive preferences of pronouns and definite descriptions	0	According to Grosz and Sidner, the interpretation for pronouns is preferentially found in the local focus, whereas that of definite descriptions is preferentially found in the global focus	0	4A similar approach was pursued in parallel by <REF>Berland and Charniak 1999</REF>	0	0	0
P93-1041	J86-3001	1993	For example, cue phrases play an important role in signaling segment changes	0	<TREF>Grosz and Sidner, 1986</TREF> However, such clues are not directly based on coherence which forms the clauses or sentences into a segment	0	<REF>Youmans 1991</REF> proposed VMP vocabulary management profile as an indicator of segment boundaries	0	VMP is a record of the number of new vocabulary terms introduced in an interval of text	0	0	0
A00-1008	J86-3001	2000	Robust natural language understanding in Atlas-Andes is provided by Ros6s CARMEL system Ros6 2000; it uses the spelling correction algorithm devised by <REF>Elmi and Evens 1998</REF>	0	52 Structure of human tutorial dialogues In an earlier analysis <REF>Kim, Freedman and Evens 1998</REF> we showed that a significant portion of human-human tutorial dialogues can be modeled with the hierarchical structure o f task-oriented dialogues <TREF>Grosz and Sidner 1986</TREF>	0	Furthermore, a main building block o f the discourse hierarchy, corresponding to the transaction level in Conversation Analysis <REF>Sinclair and Coulthard 1975</REF>, matches the tutoring episode defined by VanLehn et al	0	1998	0	0	0
A00-1008	J86-3001	2000	Second, Hierarchical decomposition minimizes search time	0	Third, our dialogues are task-oriented and have a hierarchical structure <TREF>Grosz and Sidner 1986</TREF>	0	In such a case, matching the structure of the domain simplifies operator development because they can often be derived from transcripts of human tutoring sessions	0	The hierarchy information is also useful in determining appropriate referring expressions	0	0	0
J89-2001	J86-3001	1989	For example, Mann, Moore, and Levin <REF>Mann et al 1977</REF> used a knowledge structure called a dialog game to model goal-related use of language in joint interactions such as buying/selling and learning/teaching	0	Grosz and Sidner <REF>Grosz et al 1986</REF> and <REF>Reichman 1984</REF> have investigated discourse structure and have shown that a coherent discourse can be segmented into units that have well-defined relationships to one another	0	Reichman contended further that the existing discourse structure established expectations about appropriate next conversational moves	0	Our analysis of naturally occurring dialog indicates that such expectations about appropriate next steps in the dialog form a third component of factual knowledge that plays a major role in comprehending elliptical fragments	0	0	0
J00-3005	J86-3001	2000	1995, <REF>Salton and Allan 1995</REF>, and <REF>Hearst 1997</REF> have shown that word cooccurrences and more sophisticated forms of lexical cohesion can be used to determine segments of topical and thematic continuity	0	<REF>And Morris and Hirst 1991</REF> have also shown that there is a correlation between cohesion-defined textual segments and hierarchical, intentionally defined segments <TREF>Grosz and Sidner 1986</TREF>	0	For example, if the first three paragraphs of a text talk about the moon and the subsequent two paragraphs talk about the Earth, it is possible that the rhetorical structure of the text is characterized by two spans that subsume these two sets of paragraphs and that a rhetorical relation of JOINT or LIST holds between the two spans	0	Also, studies by Harabagiu, Moldovan, and Maiorano <REF>Harabagiu and Maiorano 1996</REF>; <REF>Harabagiu and Moldovan 1999</REF> show that cohesion can be used to determine rhetorical relations that hold between smaller discourse constituents as well	0	0	0
J00-3005	J86-3001	2000	In Section 4, I explain how the annotated data was used to derive algorithms that identify connective occurrences Section 42, determine elementary units of discourse and determine which connectives have a discourse function Section 43, and hypothesize rhetorical relations that hold between elementary units and spans of texts Section 44	0	405 Computational Linguistics Volume 26, Number 3 31 Materials Many researchers have published lists of potential discourse markers and cue phrases <REF>Halliday and Hasan 1976</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Martin 1992</REF>; <REF>Hirschberg and Litman 1993</REF>; <REF>Knott 1995</REF>; <REF>Fraser 1996</REF>	0	I took the union of their lists and created an initial set of more than 450 potential discourse markers	0	For each potential discourse marker, I then used an automatic procedure that extracted from the Brown corpus a set of text fragments	0	0	0
J00-3005	J86-3001	2000	Despite their formal elegance, implementations of these theories cannot yet handle naturally occurring texts, such as that shown in 1	0	On the other hand, the theories aimed at characterizing the constraints that pertain to the structure of unrestricted texts and the computational mechanisms that would enable the derivation of these structures van <REF>Dijk 1972</REF>; <REF>Zock 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Mann and Thompson 1988</REF>; <REF>Polanyi 1988, 1996</REF>; <REF>Hobbs 1990</REF> are either too informal or incompletely specified to support a fully automatic approach to discourse analysis	0	In this paper, I explore the ground found at the intersection of these two lines of research	0	More precisely, I explore the extent to which rhetorical structures of the kind shown in Figure 1 can be built automatically by relying only on cohesion and connectives, ie, phrases such as for example, and, although, and however that are used to link linguistic units at any level <REF>Crystal 1991</REF>, 74	0	0	0
W06-1408	J86-3001	2006	Referring expressions to be generated are required to be distinguishing descriptions, that is, descriptions of the entities being referred to, but not to any other object in the context set	0	A context set is defined as the set of the entities the addressee is currently assumed to be attending to  this is similar to the concept of focus spaces of the discourse focus stack in <REF>Grosz  Sidners 1986</REF> theory of discourse structure	0	Moreover, the contrast set the set of potential distractors <REF>McDonald 1981</REF> is defined to entail all elements of the context set except the intended referents	0	Generating referring expressions is pursued since the eighties eg , <REF>Appelt 1985</REF>, among several others	0	0	0
J93-4004	J86-3001	1993	In addition, the relationships between these intentions are not represented	0	To make clear what is missing, we have represented in Figure 5 the intentional structure of this text using Grosz and Sidners 1986 notions of dominance and satisfaction-precedence	0	In Grosz and Sidners theory 1986, p 179, if an action that satisfies one intention, h, is intended to provide part of the satisfaction of another intention,/2, then/2 dominates h h satisfaction-precedes 12 whenever h must be satisfied before/2	0	The representation shown in Figure 5 makes it clear that the expert systems E top-level intention I0 is to get the user U to intend to replace SETQ X 1 with SETF X 1, and this intention dominates Es intentions to recommend this act /1 and to persuade U to perform it /2	0	0	0
J93-4004	J86-3001	1993	It is impossible to tell from the sets of effects at each level of the decomposition how effects are related to one another	0	<TREF>Grosz and Sidner 1986</TREF> argue that such relations between intentions are a crucial part of intentional structure	0	Contrast Mayburys plans with those produced by our system	0	Our text plans explicitly represent the intended effects of actions and the relationships between these intentions	0	0	0
J93-4004	J86-3001	1993	This may be a communicative goal, such as The speaker intends to 11 Note that rhetorical structure is not the only source of discourse markers	0	They may be used to mark shifts in attentional structure, discourse segment boundaries, or aspects of the exchange structure in interactive discourse <TREF>Grosz and Sidner 1986</TREF>; <REF>Redeker 1990</REF>; <REF>Schiffrin 1987</REF>	0	670 Johanna D Moore and C6cile L Paris Planning Text for Advisory Dialogs achieve the state in which the hearer believes a proposition or a linguistic goal, such as Establish motivation between an act and a goal or Inform the user of a proposition	0	a constraint list: a list of conditions that should be true in order for the operator to have the intended effect	0	0	0
J93-4004	J86-3001	1993	To make clear what is missing, we have represented in Figure 5 the intentional structure of this text using Grosz and Sidners 1986 notions of dominance and satisfaction-precedence	0	In Grosz and Sidners theory 1986, p 179, if an action that satisfies one intention, h, is intended to provide part of the satisfaction of another intention,/2, then/2 dominates h h satisfaction-precedes 12 whenever h must be satisfied before/2	0	The representation shown in Figure 5 makes it clear that the expert systems E top-level intention I0 is to get the user U to intend to replace SETQ X 1 with SETF X 1, and this intention dominates Es intentions to recommend this act /1 and to persuade U to perform it /2	0	In addition, for this schema, the recommendation h must be satisfied before the persuade /2 is attempted	0	0	0
J93-4004	J86-3001	1993	The systems that have been built within 653 Computational Linguistics Volume 19, Number 4 this framework to date <REF>Cohen 1978</REF>; <REF>Appelt 1985</REF> plan short oneor two-sentence texts to achieve the speakers goals	0	In this approach, the intentional structure describing the speakers purposes and the relationships between them <TREF>Grosz and Sidner 1986</TREF> is explicitly represented	0	However, this approach does not represent or use rhetorical knowledge about how speech acts may be combined into larger bodies of coherent text to achieve a speakers goals	0	It assumes that appropriate axioms could be added to generate longer texts, and that the text produced will be coherent as a byproduct of the planning process	0	0	0
J93-4004	J86-3001	1993	To perform these tasks, our system must understand how the previous responses stored in its discourse history relate to one another	0	That is, we must address issues of how to build a representation of the intentional structure of the dialogue that is emerging across conversational turns <TREF>Grosz and Sidner 1986</TREF> and to track global focus <REF>Grosz 1977</REF>	0	In addition, we will need communicative strategies for managing the dialogue, eg, strategies for introducing a topic, strategies for returning to a topic, etc 9	0	Conclusions We have presented an approach to natural language generation that extends previous theories and implementations in order to enable a computational system to play the role of a dialogue participant in an advisory setting	0	0	0
W06-1611	J86-3001	2006	The resulting corpus had 2334 student turns and a comparable number of system turns	0	21 Discourse structure We base our annotation of discourse structure on the Grosz  Sidner theory of discourse structure <TREF>Grosz and Sidner, 1986</TREF>	0	A critical ingredient of this theory is the intentional structure	0	According to the theory, each discourse has a discourse purpose/intention	0	0	0
P98-1090	J86-3001	1998	In this paper we look the phenomenon of long-distance pronominalisation in some detail, examining data from different domains, and consider 550 its implications for GSs theory	0	2 Theories of focus Space unfortunately prevents a full discussion of Groszs 1977, Sidners 1979, and GSs 1986 theories of focus and the attentional state in this abstract	0	The crucial aspects of these theories, for the purpose of the discussion below, are as follows	0	First of all, GS propose a distinction between two components of the attentional state: the GLOBAL FOCUS, structured as a stack of focus spaces and accessed to interpret definite descriptions; and the LOCAL FOCUS, consisting of the information preferentially used to interpret pronouns In addition, they adopt CENTERING THEORY <REF>Grosz et al , 1995</REF> as a theory of the local focus	0	0	0
P98-1090	J86-3001	1998	All 7 long-distance pronouns in the ILEX dialogues we have studied refer to discourse entities introduced in background text in this way	0	Unlike Sidners theory of focus <REF>Sidner, 1979</REF>, the theory of the attentional state in <TREF>Grosz and Sidner, 1986</TREF> henceforth: GS does not include explicit provision for long-distance pronominalisations, although some of the necessary tools are potentially already there, as we will see	0	The component of the theory that deals with pronominal reference, centering theory <REF>Grosz et al , 1995</REF>, only accounts for cases in which the antecedent of a pronoun is introduced by the previous sentence; cases such as 1 have to be handled by different mechanisms	0	In this paper we look the phenomenon of long-distance pronominalisation in some detail, examining data from different domains, and consider 550 its implications for GSs theory	0	0	0
W06-1320	J86-3001	2006	In this paper, we examine one form of lexical cohesion, namely lexical reiteration	0	Following some of the most prominent discourse theories in literature <TREF>Grosz and Sidner, 1986</TREF>; <REF>Marcu, 2000</REF>, a hierarchical representation of the thematic episodes can be proposed	0	The basis for this is the idea that topics can be recursively divided into subtopics	0	Real texts exhibit a more intricate structure, including semantic returns by which a topic is suspended at one point and resumed later in the discourse	0	0	0
W96-0109	J86-3001	1996	INTRODUCTION Topic identification concerns a problem of predicting terms in text which indicate its subject or theme	0	In the past, the problem has been addressed mostly by computational linguists in relation to issues like coreference <REF>Hobbs, 1978</REF>, anaphora resolution <TREF>Grosz and Sidner, 1986</TREF>; <REF>Lappin and Leass, 1994</REF>, or discourse center <REF>Joshi and Weinstein, 1981</REF>; <REF>Walker et al , 1994</REF>	0	In information retrieval, predicting important terms in document is crucial for an effective retrieval of relevant documents<REF>Salton et al , 1993</REF>, though they do not necessarily correspond to the subject or the theme	0	Predicting important terms involves numerical weighting of terms in document	0	0	0
C00-2112	J86-3001	2000	But, according to Familiarity Theory Helm, 1983, reti;rring expressions need not denote mfiquely by virtue of their meaning as they refer to individuals made familiar by the discourse or other context	0	This observation plays a key role in Centering Theory <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al , 1995</REF> and other computational altroaches in which rethrring expressions are resolved by locating their antecedents in the discourse	0	The reference of pronouns like he, definite descriptions like the woman, and referential tenses like had clearly has more to do with salience ill context thml with uniqueness of meaning	0	Similarly, while names like Mary need not denote individuals prominent in the discourse context,  Ve would like to thank the anonymous reviewers for their detailed and helpful comments	0	0	0
P06-2051	J86-3001	2006	The dialog system classi es this input into different categories as eg, instruction, query or social interaction	0	For this purpose we use discourse segments proposed by Grosz and Sidner <TREF>Grosz and Sidner, 1986</TREF> to describe the kind of utterances during the interaction	0	Then the dialog manager can react appropriately if it knows whether the user asked a question or instructed the robot	0	As gesture and object detection in our scenario is not very reliable and time-consuming, the system needs verbal hints of scene information such as pointing gestures or object descriptions to gather information of the gesture detection and object attention system	0	0	0
P89-1030	J86-3001	1989	Any communicative act, be it spoken, written, gestured, or system-initiated, can give rise to DEs	0	As a discourse progresses, an adequate discourse model must represent the relevant entities, and the relationships between them <TREF>Grosz and Sidner, 1986</TREF>, A speaker may then felicitously refer anaphorically to an object subject to focusing or centering constraints <REF>Grosz et al , 1983</REF>, <REF>Sidner 1981, 1983</REF>, <REF>Brennan et al 1987</REF>  if there is an existing DE representing it, or if a corresponding DE may be directly inferred from an existing DE	0	For example, the utterance Every senior in Milford High School has a car gives rise to at least 3 entities, describable in English as the seniors in Milford High School, Milford High School, and the set of cars each of which is owned by some senior in Milford High School	0	These entities may then be accessed by the following next utterances, respectively: They graduate in June	0	0	0
W97-1301	J86-3001	1997	A blind WordNet search for semantic relations is also very expensive computationally	0	A mechanism for focus tracking <TREF>Grosz and Sidner, 1986</TREF> or a clustering algorithm should be applied first in order to minimise the costs	0	In order to have proper names available for resolution of future references, it is useful to create discourse referents for them which contain their entity types	0	Up to now we have identified an entity type for 69 of the names in our corpus, and we resolved 53 of the DDs referring back to proper names with the help of WordNet	0	0	0
W93-0237	J86-3001	1993	The first characteristic of the IMACENE project was its focus on local rhetorical relations in written instructional text in English	0	There are a number of sub-issues related to this focus of concern, all of which tend to lend themselves to a traditional RST approach: Written rather than interactive discourse D A number of studies in the context of interactive discourse have emphasized the need for separate representation of intentions <REF>Fox, 1988</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Moore and Paris, 1989</REF>	0	This mechanism allows the system to deal with, for example, conversational repair, an issue which is not prevalent in written text	0	Instructional text rather than other genres -Instructional text does not tend to make use of the deep and multi-faceted intentions that are common in argumentative and persuasive text such as was the case in the Come home by 5:00 example cited by Moore and Pollack	0	0	0
W00-1433	J86-3001	2000	We are eliminating the joint relation, as it gives no helpful information from a content-planning perspective and annotators are tempted to over-use it	0	One of the criticisms of RST is that there is an infinite set of relations <TREF>Grosz and Sidner, 1986</TREF>	0	The goal is to arrive at a mutually-exclusive, clearlydefined set of relations with discriminatory power in each domain, so we expect that for each new domain, it may be necessary to start with an initial set of high-level relations selected from different categories, examine a small set of texts or dialogs in that domain, and then revise the set of relations by mak ing relevant high-leve	0	relations morespecificWe used this process to develop our annotation scheme	0	0	0
W00-1433	J86-3001	2000	The relationships between many of these statements are unclear without a model of rhetorical structure	0	<REF>In 1999</REF>, Nakatani and Traum describe a hierarchical annotation of dialog for I-units, based on the  domination and satisfaction-precedence relations of <TREF>Grosz and Sidner, 1986</TREF>	0	Other researchers have shown that Grosz and Sidners model of discourse structure GST and RST are similar in many respects <REF>Moser and Moore, 1996</REF>, <REF>Marcu, 1999</REF>	0	However, RST provides more specific relations than GST, and this is useful for content planning	0	0	0
D08-1035	J86-3001	2008	338 without labeled data	0	We are especially interested in cue phrases, which are explicit markers for discourse structure, such as now or first <TREF>Grosz and Sidner, 1986</TREF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1996</REF>	0	Cue phrases have previously been used in supervised topic segmentation eg, <REF>Galley et al 2003</REF>; we show how they can be used in an unsupervised setting	0	The previous section modeled lexical cohesion by treating the bag of words in each sentence as a series of draws from a multinomial language model indexed by the topic segment	0	0	0
D08-1035	J86-3001	2008	But despite the effectiveness of lexical cohesion for unsupervised topic segmentation, it is clear that there are other important indicators that are ignored by the current generation of unsupervised systems	0	For example, consider cue phrases, which are explicit discourse markers such as now or however <TREF>Grosz and Sidner, 1986</TREF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1996</REF>	0	Cue phrases have been shown to be a useful feature for supervised topic segmentation <REF>Passonneau and Litman, 1993</REF>; <REF>Galley et al, 2003</REF>, but cannot be incorporated by current unsupervised models	0	One reason for this is that existing unsupervised methods use arbitrary, hand-crafted metrics for quantifying lexical cohesion, such as weighted cosine similarity <REF>Hearst, 1994</REF>; <REF>Malioutov and Barzilay, 2006</REF>	0	0	0
C96-2158	J86-3001	1996	There are, however, implementability limitations	0	At discourse level, determining the set of admissible antecedents requires a representation which is ordered according to pragmatic relations <TREF>Grosz and Sidner, 1986</TREF>; <REF>Wehber, 1989</REF>	0	Although various theoretical frmneworks have been suggested, the recognition of these relations in the case of unrestricted discourse is still beyond the state-of the-art	0	Moreover, there arc cases ill which antecedent decisions can only be made on the grounds of domain knowledge and inferencing, and although there have been various attempts to integrate components of these kinds into anaphor resolution approaches, a satisfying solution l;o this problem is not available by now	0	0	0
W00-0402	J86-3001	2000	The function of discourse analysis is to divide a text into discourse segments, and to recognize and re-construct the discourse structure of the text as intended by its author	0	Results of discourse analysis can be used to solve many important NLP problems such as anaphoric reference <REF>Hirst 1981</REF>, tense and aspect analysis <REF>Hwang and Schubert 1992</REF>, intention recognition <TREF>Grosz and Sidner 1986</TREF>; <REF>Litman and Allen 1990</REF>, orcan be directly applied to computational NLP applications such as text abstraction <REF>Ono et al 1994</REF>; Tsou et al 1996 and text generation <REF>McKeown 1985</REF>; <REF>Lin et al 1991</REF>	0	Automatic text abstraction has received considerable attention see <REF>Paice 1990</REF> for a comprehensive review	0	While some statistical approaches have had some success in extracting one or more sentences which can serve as a summary <REF>Brandow et al 1995</REF>; <REF>Kupiec et al 1995</REF>; <REF>Salton et al 1997</REF>, summarization in general has remained an elusive task	0	0	0
W04-0713	J86-3001	2004	An example of a rule identifying IPAs is the following: adjectival constructions in which the prepositional complement only subcategorises for concrete entities such as let for x easy for x, fuld af x full of x	0	4 The DAR-algorithm 41 Search Space and DE lists dar presupposes the discourse structure described by <TREF>Grosz and Sidner 1986</TREF>	0	The minimal discourse unit is the utterance U Paragraphs correspond to discourse segments in texts	0	Discourse segments in dialogues were manually marked	0	0	0
J94-2006	J86-3001	1994	This difference is evident in the examples discussed in this paper involving discourse-initial text, and even in an example discussed in this paper that we believe does not involve a discourse segment boundary	0	Note that because the centering literature claims that centering should operate only within a discourse segment, and because this claim is used to explain some otherwise problematic cases of pronoun use, not being able to adequately handle discourse seg1 Notice that we use the term focusing to cover all local focusing frameworks, Sidners focusing framework <REF>Sidner 1979</REF>, Carters extensions to Sidners framework <REF>Carter 1987</REF>, the centering framework <REF>Grosz, Joshi, and Weinstein 1983</REF> and others, our framework RAFT/RAPR, PUNDIT Dahl 1986 and others, etc We use uppercase Focusing, or Local Focusing, or Sidners Focusing Algorithm/Framework to refer to Sidners work	0	We use RAFT/RAPR to refer to our work	0	302 Linda Z Suri and Kathleen F McCoy RAFT/RAPR and Centering ment initial text is much more of a problem for the centering frameworks than may at first be apparent	0	0	0
J94-2006	J86-3001	1994	Pronoun resolution within the centering framework is largely based on an ordering of preferred focus centering moves	0	Other research on discourse eg , <REF>Grosz 1981</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Reichman 1978</REF> has studied another phenomenon, the global focus of discourse	0	The term global focus generally refers to the entity or set of entities that are relevant to or salient in the overall discourse; the identification of global focus typically interacts with the identification of discourse segments	0	Global focus and discourse segmentation are distinct from the phenomenon of local focusing that is addressed in this paper	0	0	0
P98-1100	J86-3001	1998	Lexical cohesion relations <REF>Halliday and Hasan, 1976</REF> between words were identified in RT and used to construct lexical chains of related words in five texts <REF>Morris and Hirst, 1991</REF>	0	It was reported that the lexical chains closely correlated to the intentional structure <TREF>Grosz and Sidner, 1986</TREF> of the texts, where the start and end of chains coincided with the intention ranges	0	However, RT does not capture all types of lexical cohesion relations	0	In previous work, it was found that collocation a lexical cohesion relation was under-represented in the thesaurus	0	0	0
W93-0240	J86-3001	1993	as literally as possible, from their native theories; Then, without any iredefined fram,wolk, w observe the emergence of an integral discourse model encompassing these structures and iJltelltills via necessary bridging knowledge and inferences	0	Thus, on the one hand, our integrative vi,ws toward discourse structures and intentions are similar to <TREF>Grosz and Sidner, 1986</TREF> and Moore a llI <REF>Pollack, 1992</REF> in the sense that we hold  The separation of attentional and intentional tracks of discourse 	0	The stratification of coherence informational and rhetorical intentional relatiJlls	0	On the other hand, unlike previous work, we formulate knowledge sources which expl:,il, how the, emergence of integrated discourse model is possible, rather than just identifying such integrati	0	0	0
W93-0240	J86-3001	1993	we follow existing theories and by identifying the necessary bridging knowledge and interences, we just observe the integration emerging out of the individual discourse structures and intentions ;is defined in their native theories	0	This integrative view is similar to others, eg, <TREF>Grosz and Sidner, 1986</TREF> and Moore and Pollack	0	1992	0	Due to the lack of space, we did not deal with the full ranges of issues, but many of our positions are identical to others, in particular: 1	0	0	0
E93-1030	J86-3001	1993	Thus the open clauses are those on the 251 right frontier of the discourse structure cf	0	<REF>Polanyi 1985</REF>, <TREF>Grosz and Sidner 1986</TREF>, <REF>Webber 1991</REF>, assuming that it is built in a depth first left to right manner	0	SDRT specifies which parts of the SDRS are available to the representation of the current sentence for attachment via a discourse relation	0	DICE provides the means to infer from the readers knowledge resources which discourse relation should be used to do attachment	0	0	0
P08-1097	J86-3001	2008	Finally, topic segmentation provides only an outline of the discourse structure	0	Richer models of discourseincludehierarchicalstructure<REF>GroszandSidner, 1986</REF> and Rhetorical Structure Theory <REF>Mann and Thompson, 1988</REF>	0	The application of gestural analysis to such models may lead to fruitful areas of future research	0	Acknowledgments We thank Aaron Adler, C Mario Christoudias, Michael Collins, Lisa Guttentag, Igor Malioutov, Brian Milch, Matthew Rasmussen, Candace Sidner, Luke Zettlemoyer, and the anonymous reviewers	0	0	0
J96-2005	J86-3001	1996	The utterances in 22b and 22c realize propositions previously established as mutually believed, so they are IRUs	0	2 The cue word but in utterance 22a indicates a push, a new intention <TREF>Grosz and Sidner 1986</TREF>	0	The phrase as far as the certificates are concerned indicates that this new intention is subordinate to the previous discussion of the certificates	0	Thus, utterance 22a, but as far as the certificates are concerned, has the effect that the focus space related to the discussion of retirement investments, corresponding to utterances 8 to 21, is popped from the stack	0	0	0
J96-2005	J86-3001	1996	A representation of an utterance A is hierarchically recent for a representation of an utterance B if A is adjacent to B in the tree structure of the discourse	0	Of all theories based on hierarchical recency, only Grosz and Sidners theory of discourse structure provides an operationalization of hierarchical recency in terms of their stack model of attentional state <REF>Sidner 1979</REF>; <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	Thus, below, the relationship between limited attention and hierarchical recency will be discussed in terms of their stack model, but the discussion should also apply to claims about the role of hierarchical recency in other work	0	In the remainder of this squib, I will argue that the limited attention constraint must account for three types of evidence: 1 the occurrence of informationally redundant utterances in naturally occurring dialogues <REF>Walker 1993</REF>; 2 the infelicity of discourses that depend on accessing discourse entities that are not linearly recent; and 3 experiments that show that humans have limited attentional capacity <REF>Miller 1956</REF>; <REF>Baddeley 1986</REF>	0	0	0
J96-2005	J86-3001	1996	258 Walker Attention and Discourse tentions and the hearers recognition of intention; 2 expectations about what will be discussed	0	The cache model maintains the distinction between intentional structure and attentional state first proposed by <TREF>Grosz and Sidner 1986</TREF>	0	This distinction is critical	0	Just as a cache can be used for processing the references and operations of a hierarchically structured program, so can a cache be used to model attentional state when discourse intentions are hierarchically structured	0	0	0
C98-1062	J86-3001	1998	Approaches that address this problem can be classified in knowledge-based approaches or word-based approaches	0	Knowledge-based systems as Grosz and Sidners 1986 require an extensive manual knowledge engineering effort to create the knowledge base semantic network and/or frames and this is only possible in very limited and well-known domains	0	To overcome this limitation, and to process a large amount of texts, word-based approaches have been developed	0	<REF>Hearst 1997</REF> and <REF>Masson 1995</REF> make use of the word distribution in a text to find a thematic segmentation	0	0	0
P94-1050	J86-3001	1994	DAAL 0389-C0031 PRI	0	tempted to confirm the theories of discourse structure outlined in <TREF>Grosz and Sidner, 1986</TREF> using information from a thesaurus	0	In addition, <REF>Kozima 1993</REF> speculated that segmenting text along topic boundaries may be useful for anaphora resolution and text summarization	0	This paper is about an automatic method of finding discourse boundaries based on the repetition of lexical items	0	0	0
P94-1050	J86-3001	1994	In all but the shortest texts, the topic will be expounded upon through the discussion of multiple subtopics	0	Whether the organization of the text is hierarchical in nature, as described in <TREF>Grosz and Sidner, 1986</TREF>, or linear, as examined in Skorochodko, 1972, boundaries between subtopics will generally exist	0	In some cases, these boundaries will be explicit and will correspond to paragraphs, or in longer texts, sections or chapters	0	They can also be implicit	0	0	0
W93-0208	J86-3001	1993	Structuring Two-Medium Dialog for Learning Language and Other Things Henry Hamburger George Mason University; Fairfax, VA, USA Dan Tufts Research Institute for Informatics; Bucharest, Romania Raza Hashim Bridgewater College; Bridgewater, VA, USA OVERVIEW: Naturalistic two-medium communication with a computational system, using both language and interactive graphics <REF>Cohen, 1991</REF>; <REF>Maier, 1993</REF>; <REF>McKeown, 1993</REF>, is an important practical complement to studies that involve only language, only graphics and/or only people	0	Integrative two-medium work should build on insights and findings in the one-medium disciplines of graphical manipulative interfaces eg , <REF>Hutchins et al , 1986</REF>; <REF>Sullivan and Tyler, 1991</REF> and natural language discourse eg , <TREF>Grosz and Sidner, 1986</TREF>; <REF>Litman and Allen, 1987</REF>; <REF>Hovy, 1988</REF>; <REF>Lambert and Carberry, 1991</REF>; <REF>Paris, 1991</REF>	0	In addition to its general use with a variety of systems, two-medium communication provides an essential foundation for a pedagogically important form of foreign language learning experience <REF>Hamburger and Hashim, 1992</REF>	0	Specifically, it permits a supportive dialog practice system for naturalistic acquisition of various language aspects, by combining discourse constraints with independently comprehensible situational contexts	0	0	0
P92-1001	J86-3001	1992	She pursues a view that task structure, or more generally, domain structure, is sufficient to account for many discourse phenomena but cf	0	<TREF>Grosz and Sidner 1986</TREF>:182	0	She examines in detail the generation of paragraph-length texts describing the layout of a house	0	Houses have structure, following from a basic relation of spatial proximity, and there are also hierarchical levels to the structure rooms can be listed without describing whats in them, or the objects within each room can be detailed	0	0	0
P92-1001	J86-3001	1992	Discourse Interpretation and Commonsense Entailment DICE Discourse and Commonsense Entailment starts with traditional discourse representation structures cf	0	<REF>Kamp 1981</REF>, but goes on to assume with <TREF>Grosz and Sidner 1986</TREF> that candidate discourses possess hierarchical structure, with units linked by discourse relations modelled after those proposed by IIobbs 1979, 1985 cf	0	also <REF>Thompson and Mann 1987</REF>, <REF>Scha and Polanyi 1988</REF>	0	1 <REF>Lascarides and Asher 1991a</REF> use Narration, Explanation, Background, Result and Elaboration	0	0	0
W99-0108	J86-3001	1999	A pronoun interpretation algorithm based on centering which relied on centering transition preferences was developed in Brennan et aL 1987 Using transition preferences in a pronoun generation rule would cover more cases of pronoun use than is covered by Rule 1, but the application of such transition preferences also proved unhelpful in explaining pronoun patterns in our corpus	0	<REF>Reichman 1985</REF> and <TREF>Grosz  Sidner 1986</TREF> indicate that discourse segmentation has an effect on the linguistic realization of referring expressions	0	While this is intuitively appealing, it is unclear how to apply this to the generation problem in part because it is unclear how to define discourse segments to a generation system	0	<REF>Passonneau 1996</REF> argues for the use of the principles of information adequacy and economy	0	0	0
W99-0108	J86-3001	1999	The threading device used to structure will be different for different kinds ofdisc0urses	0	For instance, in the kinds of discourses studied in <TREF>Grosz  Sidner 1986</TREF> the threading device may be the intentional structures and each of their discourse segments would constitute a thread of the discourse, in the discourses that we studied New York Times acles, threads defined in terms of the time referenced in a clause appeared to be quite prominent	0	In this paper we present our preliminary work in uncovering factors that affect pronoun generation decisions	0	Our work so far has led us to hypothesize several factors including: Sentence Boundaries pronouns appear to be the preferred referring form for subsequent reference to an item within the same sentence	0	0	0
W99-0108	J86-3001	1999	However, we argue that a single definition of disburse segment is not sufficient to explain the patterns of pronoun use found, and seek a more general notion	0	Here, to distingnih o notion from other notions of discmuse segmentation found in the literature eg , <REF>Reidmum 1985</REF> or <TREF>Grosz  Sidner 1986</TREF>, we use the term discomae thread to capture the structuring notion to whidz we refer	0	We propose that a discourse generally contains multiple threads which run through the discourse and can serve to structure the discourse	0	In general, a single thread is evident at a particular point in the discourse, but this thread may be replaced by another thread and then picked up again at another point in the discourse cf	0	0	0
C98-2174	J86-3001	1998	3 Deductive Operators The choice of operators implemented in the ftetorica system has been influenced by a number of factors	0	The rules of inference are clear candidates for operationalisation: moves such as Modus Ponens are clearly vital components of any argument though, as noted in <TREF>Grosz and Sidner 1986</TREF>, p201, it is inappropriate to view the implication step as one of conventional material implication	0	The relationship is rather one of support the hearer must be brought to believe that given the current context and domain of discourse the first proposition warrants, in part, concluding the second	0	Even given this weaker, predicate-based reading of a Modus Ponens argument, it is still unclear that any of the other rules of inference which are, after all, formally redundant should be necessary	0	0	0
C98-2174	J86-3001	1998	Belief goals are used to build the content of an argument as in much other NLG work; saliency goals to express the intention to convey information to the hearer following a notion of saliency similar to that proposed in <REF>Walker, 1996</REF>; and topic manipulation goals to control the focus of attention through the discourse	0	The roles of these goals and their interrelationships are explored in relation to the informationintention-attention model of <TREF>Grosz and Sidner 1986</TREF> in more detail in <REF>Reed and Long 1997a</REF>	0	3 Deductive Operators The choice of operators implemented in the ftetorica system has been influenced by a number of factors	0	The rules of inference are clear candidates for operationalisation: moves such as Modus Ponens are clearly vital components of any argument though, as noted in <TREF>Grosz and Sidner 1986</TREF>, p201, it is inappropriate to view the implication step as one of conventional material implication	0	0	0
P93-1009	J86-3001	1993	One such question is how the postulated representations should be further formalized, and how reasoning with these formalizations is to be performed	0	A second question is how this conception of discourse processing may be integrated with theories of discourse structure <TREF>Grosz and Sidner, 1986</TREF>; <REF>Scha and Polanyi, 1988</REF>; <REF>Webber, 1991</REF>	0	While we have looked primarily at two-clause structures, the ramifications that the claims have on multi-clause discourse structure require further investigation	0	Such studies will form the basis for further characterization of the role of coherence establishment in anaphoric processing	0	0	0
W90-0116	J86-3001	1990	For example, an analysis of the texts using Mann and Thompsons 1987 Rhetorical Structure Theory RST would result primarily in the relations sequence and joint and would contain few of the the relations like evidence or justify that give RST its descriptive power	0	Similarly, it is unclear what work a system like that of <TREF>Grosz and Sidner 1986</TREF> would do in analyzing a description	0	Since the structure of descriptions cannot be analyzed adequately with rhetorical relations, perhaps it can be explained in terms of the domain	0	Houses, chips, and families are strongly structured	0	0	0
E91-1015	J86-3001	1991	NorthHolland	0	Gross, BJ and CL <REF>Sidner 1986</REF> Attention, Intentions, and the structure of discourse s  Computational Linguistics, Vol	0	12, No 3, <REF>JulySeptember, 1986</REF>, pp	0	175-204	0	0	0
E91-1015	J86-3001	1991	The partners in this project are CAP GEMINI INNOVATION, CNET, CSELT, DAIMLER-BENZ, ERLANGEN University, INFOVOXj IRISA, LOGICA, PO- LITECHNICO DI TORINOj SARIN, SIEMENS, SUR-, REY University ented dialogues planning techniques have received a fair amount of attention <REF>Allen et al, 1982</REF>; <REF>Litman  Allen, 1984</REF>	0	In the latter approach there is no means to describe and deal with pure discursive phenomena meta-communication such as oral misunderstanding, initiative keeping, initiative giving etc, Whilst in the first approaches there is no attempt to develop a full dialogue system, except in Groszs and Sidners 1986 model that unfortunately does not cover all oral dialogue phenomena <REF>Bilange et al, 1990b</REF>	0	In oral conversation, meta-communication represents a large proportion of all possible phenomena and is not simple to deal with, especially if we strive to obtain natural dialogues	0	Therefore, we developed a computational model able to have clear views on happenings at the task level and at the level of the communication itself	0	0	0
E91-1015	J86-3001	1991	In the domain of travel planning, transactions could be : book a one-way, a return, etc The transaction level is then tied to the plan/sub-plan paradigm	0	A transaction can be viewed as a discourse segment Grosz  Sidner 1986	0	Ezchange level: transactions are achieved through exchanges which may be considered 84Dialogue excerpt of example in section 4 2 when would you like to leave 7 U2 next thursday Sa next tuesday the 30th of November ; and at what time 7 Us no, thursday december the 2nd towards the end of the afternoon St ok december the 2nd around six  initiativesystem, openrequest, getparanteter depdate reactionuser, answer, depdate : 1 El  initiative sstem, echo, 1 evaluation : E2  reactionuser, correct, I, 2 Tl L evaluationsystem, echo, 2 initiativesystem, openrequest, getparameterdeptime Ea reactionuser, answer, deptime : 3 ealuationsste,,, echo,  El : exchangeOwner: system, Intention: getdepdate, Attention: departure, date E2 exchangeOwner: system, Intention: clarifyvaluedepdate, Attention: departure, date Ea exchangeOwner: system, Intention: getdeptime, Attention: departure, time Tl  transactionIntention:problemdescription, Attention:departure, arrival, city, date, time, flight Figure 2	0	Dialogue history representation as negotiations	0	0	0
C08-1129	J86-3001	2008	Two types of cues have been identified for signaling topic shifts	0	The first type is discourse markers <REF>Moser and Moore, 1995</REF>; <REF>Schiffrin, 1987</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Passonneau and Litman, 1997</REF>; <REF>Bangerter and Clark, 2003</REF>	0	Discourse markers can be used to signal the start of a new discourse segment and its relation to other discourse segments	0	For example, now might signal moving on to the next topic, while well might signal 1026 a negative or unexpected response	0	0	0
W00-1001	J86-3001	2000	In this scheme, dialogue acts, the elements of the exchange structure, are classified into the tags shown in Figure 7	0	6 Dialogue Structure and Constraints on Multiple Exchanges 61 Dialogue Segment In the previous discourse model<TREF>Grosz and Sidner, 1986</TREF>, a discourse segment has a beginning and an ending utterances and may have smaller discourse segments in it	0	It is not an easy task to identify such segments with the nesting structure for spoken dialogues, because the structure of a dialogue is often very complicated due to the interaction of two speakers	0	In a preliminary experiment of coding segments in spoken dialogues, there were a lot of disagreements on the granularity or the relation of the segments and on identifying ending utterances of the segment	0	0	0
C90-2069	J86-3001	1990	First, we are developing psychological experiments to test whether the regularities on which the algorithm is based influence the readers recognition of subjective sentences and identification of subjective characters	0	Second, we are extending the algorithm to make connections with work on focus of attention and discomse structure such as <TREF>Grosz  Sidner 1986</TREF>; in particular, we are investigating how resolving anaphora and tracking the current point of view are related <REF>Stark 1987</REF>, <REF>Hewitt 1988</REF>	0	An important direction for future research is reasoning about the plausibility of a suggested interpretation, that is, whether it is plausible that the con tent of a subjective sentence is a particular characters thought or perception	0	We lmve presented part of an algorithm for identifying subjective characters that is based on regularities in the ways that texts initiate, resume, and continue a characters point of view	0	0	0
C08-1123	J86-3001	2008	We show that our automatically acquired cues are general enough to serve as a cross-domain classification mechanism	0	A number of researchers <REF>Hirschberg and Litman, 1993</REF>; <TREF>Grosz and Sidner, 1986</TREF> speak of cue or key phrases in utterances that can serve as useful indicators of discourse structure	0	We have previously investigated the use of such cue phrases to predict dialogue acts or DAs functional tags which represent the communicative intentions behind each user utterance <REF>Webb et al, 2005a</REF>	0	We developed an approach, in common with the work of Samuel et al	0	0	0
J97-1005	J86-3001	1997	Site before after pause duration cue1 wordl cue2 word2 corer infer globaLpro cue-prosody 224,231  t 055 t and f 231,232 f 0 t and f 232,233 t 0 t and f 233,234  f 0 f NA f Figure 7 Example feature coding of potential boundary sites	0	NA   t NA   f NA NA NA NA t NA   f studies on data from corpora <REF>Passonneau 1993</REF> or published excerpts <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	Unlike the cue and pause features, the NP features were thus not directly based on simplifications of existing results	0	Cue-prosody, which encodes a combination of prosodic and cue word features, was motivated by an analysis of errors on our training data, as described in Section 431	0	0	0
J97-1005	J86-3001	1997	We conclude each review by summarizing the differences between our study and previous work	0	21 Characterizing the Notion of a Segment A number of alternative proposals have been presented, which relate segments to intentions <TREF>Grosz and Sidner 1986</TREF>, Rhetorical Structure Theory RST relations <REF>Mann and Thompson 1988</REF> or other semantic relations <REF>Polanyi 1988</REF>; <REF>Hobbs 1979</REF>	0	The linguistic structure of Grosz and Sidners 1986 discourse model consists of multiutterance segments and structural relations among them, yielding a discourse tree structure	0	The hierarchical relations of their linguistic structure are isomorphic with the two other levels of their model, intentional structure and attentional state	0	0	0
J97-1005	J86-3001	1997	Finally, we quantify our results using a significance 106 Passonneau and Litman Discourse Segmentation test, a reliability measure, and, for purposes of comparison with other work, percent agreement	0	22 Correlation of Segmentation with Utterance Features The segmental structure of discourse has been claimed to constrain and be constrained by disparate phenomena, eg, cue phrases <REF>Hirschberg and Litman 1993</REF>; <TREF><TREF>Grosz and Sidner 1986</TREF></TREF></TREF>; <REF>Reichman 1985</REF>; <REF>Cohen 1984</REF>, plans and intentions <REF>Carberry 1990</REF>; <REF>Litman and Allen 1990</REF>; <TREF><TREF>Grosz and Sidner 1986</TREF></TREF></TREF>, prosody <REF>Hirschberg and Pierrehumbert 1986</REF>; <REF>Butterworth 1980</REF>, nominal reference <REF>Webber 1991</REF>; <TREF><TREF>Grosz and Sidner 1986</TREF></TREF></TREF>; <REF>Linde 1979</REF>, and tense <REF>Webber 1988</REF>; <REF>Hwang and Schubert 1992</REF>; <REF>Song and Cohen 1991</REF>	0	However, just as with the early proposals regarding segmentation, many of these proposals are based on fairly informal studies	0	It is only recently that attempts have been made to quantitatively evaluate how utterance features correlate with independently justified segmentations	0	0	0
J97-1005	J86-3001	1997	However, in <REF>Whittaker and Stenton 1988</REF>, a higher level of discourse structure based on topic shifts was agreed upon by at least 4 of 5 judges for 46 of the 56 control shifts	0	In sum, relatively few quantitative empirical studies have been made of how to annotate discourse corpora with features of discourse structure, and those recent ones that exist use various models such as the Grosz and Sidner model 1986, an informal notion of topic <REF>Hearst 1994</REF>; <REF>Flammia and Zue 1995</REF>, transactions <REF>Isard and Carletta 1995</REF>, Relational Discourse Analysis <REF>Moser and Moore 1995</REF>, or control <REF>Whittaker and Stenton 1988</REF>; <REF>Walker and Whittaker 1990</REF>	0	The modalities of the corpora investigated include dialogic or monologic, written, spontaneous or read, and the genres also vary	0	Quantitative evaluations of subjects annotations using notions of agreement, interrater reliability, and/or significance show that good results can be difficult to achieve	0	0	0
J97-1005	J86-3001	1997	<REF>Polanyi 1988</REF> distinguishes among four types of Discourse Constituent Units DCUs based on different types of structural relations eg , sequence	0	As in Grosz and Sidners 1986 model, <REF>Polanyi 1988</REF> proposes that DCUs analogous to segments are structured as a tree, and in both models, the tree structure of discourse constrains how the discourse evolves, and how referring expressions are processed	0	Recent work <REF>Moore and Paris 1993</REF>; <REF>Moore and Pollack 1992</REF> has argued that to account for explanation dialogues, it is necessary to independently model both RST relations and intentions	0	Researchers have begun to investigate the ability of humans to agree with one another on segmentation, and to propose methodologies for quantifying their findings	0	0	0
J97-1005	J86-3001	1997	What we also discuss here, which has not been presented in previous work, is a preliminary evaluation of the reliability of our method where we give a conservative lower bound suggesting that the method is reliable	0	108 Passonneau and Litman Discourse Segmentation 31 Methodology: Empirically Derived Segmentation The claim has been made that different people investigators or subjects are likely to assign similar segment boundaries or segment relations to a discourse <TREF>Grosz and Sidner 1986</TREF>; <REF>Reichman 1985</REF>; <REF>Mann and Thompson 1988</REF>, but it has also been observed that discourse structure can be ambiguous <REF>Pierrehumbert and Hirschberg 1987</REF>	0	Studies asking subjects to assign topical units to sample discourses have shown that the resulting segments vary widely in both size and location <REF>Rotondo 1984</REF>	0	Yet until recently, there has been little attempt to quantify the degree of variability among subjects in performing such a task	0	0	0
J97-1005	J86-3001	1997	Our corpus consists of transcripts of spontaneous spoken monologues, produced by 20 different speakers	0	We use an informal notion of communicative intention as the segmentation criterion, motivated by <TREF>Grosz and Sidner 1986</TREF> and <REF>Polanyi 1988</REF>, who argue that defining a segment as having a coherent goal is more general than establishing a repertoire of specific types of segment goals	0	We do not, however, ask coders to identify hierarchical relations among segments	0	The hypothesis that discourse has a tree structure has frequently been questioned <REF>Dale 1992</REF>; <REF>Moore and Pollack 1992</REF>; <REF>Hearst 1994</REF>; <REF>Walker 1995</REF>, and the magnitude of our segmentation task precludes asking subjects to specify hierarchical relations	0	0	0
J97-1005	J86-3001	1997	21 Characterizing the Notion of a Segment A number of alternative proposals have been presented, which relate segments to intentions <TREF>Grosz and Sidner 1986</TREF>, Rhetorical Structure Theory RST relations <REF>Mann and Thompson 1988</REF> or other semantic relations <REF>Polanyi 1988</REF>; <REF>Hobbs 1979</REF>	0	The linguistic structure of Grosz and Sidners 1986 discourse model consists of multiutterance segments and structural relations among them, yielding a discourse tree structure	0	The hierarchical relations of their linguistic structure are isomorphic with the two other levels of their model, intentional structure and attentional state	0	Rhetorical relations do not play a role in their model	0	0	0
J97-1005	J86-3001	1997	5	0	Conclusion and Future Directions Our initial hypotheses regarding discourse segmentation were that multiutterance segment units reflect discourse coherence, and that while the semantic dimensions of this coherence may vary, it arises partly from consistency in the speakers communicative goals <TREF>Grosz and Sidner 1986</TREF>; <REF>Polanyi 1988</REF>	0	The results from the first part of our study Section 3 support these hypotheses	0	On a relatively unconstrained linear segmentation task, the number of times different naive subjects identify the same segment boundaries in a given narrative transcript is extremely significant	0	0	0
J97-1005	J86-3001	1997	The types of discourse units being coded and the relations among them vary	0	Several studies have used trained coders to locally and globally structure spontaneous or read speech using the model of <TREF>Grosz and Sidner 1986</TREF>, including <REF>Grosz and Hirschberg 1992</REF>; <REF>Nakatani, Hirschberg, and Grosz 1995</REF>; <REF>Stifleman 1995</REF>; <REF>Hirschberg and Nakatani 1996</REF>	0	<REF>In Grosz and Hirschberg 1992</REF>, percent agreement see Section 32 among 7 coders on 3 texts under two conditions--text plus speech or text alone--is reported at levels ranging from 743 to 951	0	<REF>In Hirschberg and Nakatani 1996</REF>, average reliability measured using the kappa coefficient discussed in Carletta 1996 of segmentinitial labels among 3 coders on 9 monologues produced by the same speaker, labeled using text and speech, is8 or above for both read and spontaneous speech; values of at least 8 are typically viewed as representing high reliability see Section 32	0	0	0
J97-1005	J86-3001	1997	No statistical analysis of the significance of the differences was presented, however	0	By statistically analyzing distributions of discourse anaphora with respect to control-based discourse segments, <REF>Walker and Whittaker 1990</REF> showed that shifts of attentional state <TREF>Grosz and Sidner 1986</TREF> occurred when shifts in control were accepted by all dialogue participants	0	In sum, relatively few studies correlate linguistic devices with empirically justified discourse segmentations	0	Quantitative evaluations of the correlations include the use of statistical measures and information retrieval metrics	0	0	0
E93-1031	J86-3001	1993	SDRT starts with traditional VltSs cf	0	<REF>Kamp 1981</REF>, but goes on to assume with <TREF>Grosz and Sidner 1986</TREF> that candidate discourses possess hierarchical structure, with units linked by discourse relations modelled after those proposed by <REF>Hobbs 1985</REF> cf	0	also <REF>Mann and Thompson 1987</REF>, <REF>Scha and Polanyi 1988</REF>	0	The resultant representations are called segmented DRSs or SDPSs	0	0	0
P98-2155	J86-3001	1998	This paper presents an empirically motivated theory of the discourse focusing function of accent	0	The theory describes for the first time the interacting contributions to accent prediction made by factors related to the local and global attentional status of discourse referents in a discourse model <TREF>Grosz and Sidner, 1986</TREF>	0	The ability of the focusing features to predict accent for a blind test corpus is examined using machine learning	0	Because attentional status is a property of referring expressions, a novel approach to accent prediction is proposed to allow for the integration of word-based and constituent-based linguistic features in the models to be learned	0	0	0
P98-2155	J86-3001	1998	<REF>Terken, 1984</REF>; <REF>Hirschberg, 1993</REF>	0	We propose a new theory of the relationship between accent and attention, based on an enriched taxonomy of given/new information status provided by both the LOCAL centering and GLOBAL focus stack model attentional state models in Grosz and Sidners discourse modeling theory 1986	0	939 Analysis of a 20-minute spontaneous story-telling monologue t identified separate but interacting contributions of grammatical function, form of referring expression and accentuation 2 in conveying the attentional status of a discourse referent	0	These interactions can be formally expressed in the framework of attentional modeling by the following principles of interpretation:  The LEXICAL FORM OF A REFERRING EXPRESSION indicates the level of attentional processing, ie, pronouns involve local focusing while full lexical forms involve global focusing <REF>Grosz et al , 1995</REF>	0	0	0
C02-1035	J86-3001	2002	Furthermore, MIND also identifies how an input relates to the overall conversation discourse through discourse understanding	0	In particular, MIND uses a representation called conversation segment to group together inputs that contribute to a same goal or sub-goal <TREF>Grosz and Sidner, 1986</TREF>	0	The result of discourse understanding is an evolving conversation history that reflects the overall progress of a conversation	0	Figure 2 shows a conversation fragment between a user and MIND	0	0	0
C04-1019	J86-3001	2004	Some research groups confirm the suitability of Java for the development of interactive, agentbased systems  for example COLLAGEN <REF>Rich et al 2001</REF>	0	Indeed, the COLLAGEN architecture, like that of the Queens Communicator, manages discourse using a focus stack, a classical idea in the theory of discourse structure <TREF>Grosz and Sidner, 1986</TREF>	0	For dialogues that are not primarily transactionbased or frame-based, and where the system must establish the users broader objectives before offering advice or presenting options, a discourse management strategy based on problem-solving PS objects objectives, recipes, actions and resources is appropriate <REF>Blaylock et al , 2003</REF>	0	We are currently investigating means of using PS objects to orient a dialogue, before using expertise like that currently encapsulated in our domain agents to complete those frame-filling tasks that are needed to support the users objectives	0	0	0
J98-2001	J86-3001	1998	The architecture of our own classifier see below is also consistent with Frauruds hypothesis that these methods are not just used when no suitable antecedent can be found, but more extensive investigations will be needed before we can conclude that this architecture significantly outperforms other ones	0	The presence of such a large number of discourse-new definite descriptions is also problematic for the idea that definite descriptions are interpreted with respect to the global focus <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	A significant percentage of the larger situation definite descriptions encountered in our corpus cannot be said to be in the globai focus in any significant sense: as we observed above, in many of these cases the writer seems to rely on the readers capability to add a new object such as the Illinois Commerce Commission to her or his model of the world, rather than expecting that object to be already present	0	52 A SemiAutomatic Classifier As already mentioned, we are in the course of implementing a system capable of performing the classification task semiautomatically <REF>Vieira 1998</REF>	0	0	0
P95-1040	J86-3001	1995	Both attentional Cf and propositional mutual beliefs structures are updated throughout	0	However, unlike attentional structures which are ephemeral in various time scales and empty at the end of the discourse <TREF>Grosz and Sidner, 1986</TREF>, mutual beliefs persist throughout the conversation, preserving at the end the semantic and pragmatic outcome of the discourse	0	In addition, while propositions can be excluded from the mutual beliefs because they fail to meet some inclusion criterion, no lexical denotation is excluded from Cf regardless of its propositional value	0	This is because the salience most relevant to the attentional state is the proximity of a discourse entity to the head of Cf -the closer it is, the more it is centered and therefore, attentionally salient	0	0	0
P95-1040	J86-3001	1995	This distinction underlies my proposals about the attentional consequences of pitch accents when applied to pronominals, in particular, that while most pitch accents may weaken or reinforce a cospecifiers status as the center of attention, a contrastively stressed pronominal may force a shift, even when contraindicated by textual features	0	To predict and track the center of attention in discourse, theories of centering <REF>Grosz et al , 1983</REF>; <REF>Brennan et al , 1987</REF>; <REF>Grosz et al , 1989</REF> and immediate focus <REF>Sidner, 1986</REF> rely on syntactic and grammatical features of the text such as pronominalization and surface sentence position	0	This may be sufficient for written discourse	0	For oral discourse, however, we must also consider the way intonation affects the interpretation of a sentence, especially the cases in which it alters the predictions of centering theories	0	0	0
C98-1087	J86-3001	1998	In this paper we look the phenomenon of long-distance pronominalisation in some detail, examining data flom different domains, and consider 550 its implications for GSs theory	0	2 Theories of focus Space unfortunately prevents a full discussion of Groszs 1977, Sidners 1979, and GSs 1986 theories of focus and the attentional state in this abstract	0	The crucial aspects of these theories, for the purpose of the discussion below, are as follows	0	First of all, GS propose a distinction between two components of the attentional state: the GLOBAL FOCUS, structured as a stack of focus spaces and accessed to interpret definite descriptions; and the LOCAL FOCUS, consisting ot the information preferentially used to interpret pronouns	0	0	0
C98-1087	J86-3001	1998	All 7 long-distance pronouns in the ILEX dialogues we have studied refer to discourse entities introduced in background text in this way	0	Unlike Sidners theory of focus Sidnet; 1979, tile theory of the attentional state in <TREF>Grosz and Sidner, 1986</TREF> henceforth: GS does not include explicit provision for long-distance pronominalisations, although some of the necessary tools am potentially already there, as we will see	0	The component of the theory that deals with pronominal reference, centering theory <REF>Grosz et al, 1995</REF>, only accounts for cases in which the antecedent of a pronoun is introduced by the previous sentence; cases such as 1 have to be handled by different mechanisms	0	In this paper we look the phenomenon of long-distance pronominalisation in some detail, examining data flom different domains, and consider 550 its implications for GSs theory	0	0	0
J88-3010	J86-3001	1988	OK--now you can slip in the pliers 6	0	And the whole pole comes off Plan of Speaker: The top level goal is get pole off, which succeeds if the following hierarchy of subgoals succeeds: get po off  loosen screw with wrench - slip in pliers identi/scr/ew  identify wrench know chars, of screw know chars, of wrench Intentional structure of discourse as in <TREF>Grosz and Sidner 1986</TREF>: Primary Intentions: I1: intend H get pole off; I2: intend H loosen screw with wrench I3: intend H identify screw Computational Linguistics, Volume 14, Number 3, <REF>September 1988</REF> 89 Robin Cohen On the Relationship Between User Models and Discourse Models Segmentation Structure:    1 2 ds3 3 4 ds2 5 6 dsl There are three segments: ds3 with 13, ds2 with 12, and dsl with I1, where 12 DOM 13 and I1 DOM 12 ie 13 contributes to the satisfaction of 12, etc	0	There are two main sources of difference between the plan of the speaker and the intentional structure of discourse, illustrated by the above example: i there may be no direct match from the utterances to the units subgoals of the plan; here, there is no utterance corresponding to identify wrench, on top of utterance 4, which serves to let the hearer know characteristics of the wrench; ii the intentions recorded for the intentional structure may be at a higher level of detail	0	The examples provided in <TREF>Grosz and Sidner 1986</TREF>, for instance, only record those attached to segments of more than one utterance	0	0	0
J88-3010	J86-3001	1988	The discourse model must thus contain the following key elements: an indication of the structure of the discourse and an organization of the objects of the real world mentioned in the discourse to help anaphora resolution, for example	0	As soon as this kind of history of objects is included covered in the model of <TREF>Grosz and Sidner 1986</TREF> by tracking attentional state and the objects currently in focus, there are elements that are not specifically attached to the user himself	0	The structure of the discourse is essentially provided in two different ways	0	Which of the actual utterances of the discourse group together into logical segments is covered by the linguistic structure of <TREF>Grosz and Sidner 1986</TREF>	0	0	0
J88-3010	J86-3001	1988	Intentional structure should indicate the intentional relations between, again, actual utterances	0	For instance, it is important to determine the cases where the goal underlying an utterance contributes to the satisfaction of the goal underlying another utterance--eg , getting the hearer to believe some proposition p contributes to the satisfaction of getting the hearer to believe some proposition q determined as dominance relations in <TREF>Grosz and Sidner 1986</TREF>	0	In this sense, my interpretation of the derivation of intentional structure agrees well with Wahlsters appeal for an incremental derivation of the discourse model	0	I believe that the intentional structure is related to, but not identical with, the plan of the speaker underlying discourse	0	0	0
J88-3010	J86-3001	1988	I feel that the definition of discourse model here is too narrow--there is more to a model of discourse than an indication of the underlying entities objects, events	0	Schuster seems to suggest that some of the structuring provided in <TREF>Grosz and Sidner 1986</TREF> is there only to highlight the entities, In my view, the actual utterances themselves are worth examining as participating in some structure	0	I also find Schusters definition for user model--the information a system has about the userAsomewhat problematic	0	I think that the user model must concentrate on dynamic information, that is, which has some potential for change	0	0	0
J88-3010	J86-3001	1988	There are two main sources of difference between the plan of the speaker and the intentional structure of discourse, illustrated by the above example: i there may be no direct match from the utterances to the units subgoals of the plan; here, there is no utterance corresponding to identify wrench, on top of utterance 4, which serves to let the hearer know characteristics of the wrench; ii the intentions recorded for the intentional structure may be at a higher level of detail	0	The examples provided in <TREF>Grosz and Sidner 1986</TREF>, for instance, only record those attached to segments of more than one utterance	0	There are, indeed, many issues regarding the relationship of plans and discourse structure; we will not elaborate further here	0	Our main point is that the two terms should be related, but distinct	0	0	0
J88-3010	J86-3001	1988	In this sense, I focus on the interpretation of a discourse from the point of view of one of the conversants	0	I essentially include in the discourse all the components covered by the model of <TREF>Grosz and Sidner 1986</TREF>	0	For the definition of the user model, I also ground the discussion in the point of view of one conversant	0	The model is thus an analysis of the other conversant subsequently referred to as the speaker	0	0	0
J88-3010	J86-3001	1988	The structure of the discourse is essentially provided in two different ways	0	Which of the actual utterances of the discourse group together into logical segments is covered by the linguistic structure of <TREF>Grosz and Sidner 1986</TREF>	0	Often clue words such as but anyway will indicate how to segment the utterances into logical segments, without concern for how individual utterances within that segment relate	0	In addition, there is an indication of the intentional structure	0	0	0
J88-3010	J86-3001	1988	In addition, there is an indication of the intentional structure	0	Here, I would reinterpret slightly the term as used in <TREF>Grosz and Sidner 1986</TREF> see <REF>Cohen 1986</REF>	0	Intentional structure should indicate the intentional relations between, again, actual utterances	0	For instance, it is important to determine the cases where the goal underlying an utterance contributes to the satisfaction of the goal underlying another utterance--eg , getting the hearer to believe some proposition p contributes to the satisfaction of getting the hearer to believe some proposition q determined as dominance relations in <TREF>Grosz and Sidner 1986</TREF>	0	0	0
W02-1702	J86-3001	2002	It is widely accepted that content selection plays a crucial role in text generation <REF>Reiter and Dale 2000</REF>	0	This process is normally seen as a goal-directed activity in which text segments are fit into the discourse structure of the text so as to convey a coherent communicative goal <TREF>Grosz and Sidner 1986</TREF>	0	Content planning techniques, such as textual schemas <REF>McKeown 1985</REF> or plan operators <REF>Moore and Paris 1993</REF>, have been successfully used as models of text generation	0	There are cases, though, in which these techniques may face some limitations, for example, when the structure of the discourse is difficult to anticipate <REF>Mellish et al 1998</REF>	0	0	0
P95-1018	J86-3001	1995	4 Conclusions We have introduced Relational Discourse Analysis, a coding scheme for the exhaustive analysis of text or single speaker discourse	0	RDA is a synthesis of ideas from two theories of discourse structure <TREF>Grosz and Sidner, 1986</TREF>; <REF>Mann and Thompson, 1988</REF>	0	It provides a system for analyzing discourse and formulating hypotheses about cue selection and placement	0	The corpus study results in rules for cue selection and placement that will then be exercised by our text generator	0	0	0
P95-1018	J86-3001	1995	There are three types of simpler functional elements: 1 units, which are descriptions of domain states and actions, 2 matrix elements, which express a mental attitude, a prescription or an evaluation by embedding another element, and 3 relation clusters, which are otherwise like segments except that they have no core:coatributor structure	0	This approach synthesizes ideas which were previously thought incompatible from two theories of discourse structure, the theory proposed by <TREF>Grosz and Sidner 1986</TREF> and Rhetorical Structure Theory RST proposed by <REF>Mann and Thompson 1988</REF>	0	The idea that the hierarchical segment structure of discourse originates with intentions of the speaker, and thus the defining feature of a segment is that there be a recognizable segment purpose, is due to Grosz and Sidner	0	The idea that discourse is hierarchically structured by palrwise relations in which one relatum the nucleus is more central to the speakers purpose is due to Mann and Thompson	0	0	0
P95-1018	J86-3001	1995	The study of cues must begin with descriptive work using intuition and observation to identify the factors affecting cue usage	0	Previous research <REF>Hobbs, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Schiffrin, 1987</REF>; <REF>Mann and Thompson, 1988</REF>; <REF>Elhadad and McKeown, 1990</REF> suggests that these factors include structural features of the discourse, intentional and informational relations in that structure, givenness of information in the discourse, and syntactic form of discourse constituents	0	In order to devise an algorithm for cue selection and placement, we must determine how cue usage is affected by combinations of these factors	0	The corpus study is intended to enable us to gather this information, and is therefore conducted directly in terms of the factors thought responsible for cue selection and placement	0	0	0
W99-0103	J86-3001	1999	Figure 6: Motivational example 2 In this paper, the ranking of the items in Cf also follows Figure 5	0	If the items have the same priority, the algorithm ranks them by the obliqueness of grammatical relation of the subcategorized functions of the main verb: that is, first the subject, object, and objects2, followed by other subcategorized fenons, and finally, adjuncts <TREF>Grosz and Sidner 1986</TREF>, Brennan et ul	0	1987	0	The centering algorithm is based on constraints and rules as well as Cbs and C	0	0	0
C92-2096	J86-3001	1992	The communicative goals associated with the leaves of the structure are then used to retrieve the content of each proposition fiom an underlying knowledge base	0	By making the intentional structure of a paragraph explicit, this work follows the discourse structure theory advanced in <TREF>Grosz  Sidner, 1986</TREF>	0	Note also that, since in RST with planning, the structure of paragraphs is dynamically derived, it is possible to view schemas as the compilation of RST configurations with some information abswacted out, as pointed out in <REF>Mann, 1987</REF>	0	We found that schemas and RST were not appropriate for planning and generating argumentative paragraphs because argument selection cannot be easily performed	0	0	0
W07-0301	J86-3001	2007	However, past work has been confined to slot-filling tasks and has not tackled the troubleshooting domain	0	Conversely, dialog systems for troubleshooting in the literature have not attempted to model uncertainty directly <TREF>Grosz and Sidner, 1986</TREF>; <REF>Lochbaum, 1998</REF>	0	The contribution of this paper is to show how to model a troubleshooting spoken dialog system as a partially observable Markov decision process POMDP	0	We argue that past work in the general troubleshooting literature represents simplifications or special cases of a POMDP, then we show how a troubleshooting POMDP can be combined with a dialog system POMDP to create a unified framework that admits global optimization	0	0	0
W04-0214	J86-3001	2004	While this method may be the best way to go ultimately, empirical work has shown that it has been difficult to put into practice	0	There are many different schemes to choose from, for example Rhetorical Structure Theory <REF>Mann and Thompson, 1986</REF> or the stack model <TREF>Grosz and Sidner, 1986</TREF> and manually annotating with these schemes has variable reliability	0	Finally, annotating these schemes requires real-world knowledge, reasoning, and knowledge of salience and semantics, all of which make automatic segmentation difficult	0	However, past studies such as <REF>Tetreault and Allen 2003</REF> show that for reference resolution, a highlystructured tree may be too constraining, so a shallower approach may be acceptable for studying the effect of discourse segmentation on resolution	0	0	0
W04-0214	J86-3001	2004	23 Discourse Segmentation Another research area that can benefit from a discourse-annotated corpus is discourse structure	0	There has been plenty of theoretical work such as <TREF>Grosz and Sidner, 1986</TREF>, <REF>Moser and Moore, 1996</REF> which shows that just as sentences can be decomposed into smaller constituents, a discourse can be decomposed into smaller units called discourse segments	0	Though there are many different ways to segment discourse, the common themes are that some sequences are more closely related than others discourse segments and that a discourse can be organized as a tree, with the leaves being the individual utterances and the interior nodes being discourse segments	0	The embeddedness of a segment effects which previous segments, and thus their entities, are accessible	0	0	0
W97-0601	J86-3001	1997	As a convention of this type of tagging, utterances that contribute to the success of the whole dialogue, such as greetings, are tagged with all the attributes	0	Thus the goal of the tagging is to show how the structure of the dialogue reflects the structure of the task <REF>Carbelrry, 1989</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Litman and Allen, 1990</REF>	0	Tagging by AVM attributes is required to calculate costs over subdialogues, since for any subdialogue, task attributes define the subdialogue	0	For example, the subdialogue about the attribute arrival-city SA consists of utterances A6 and U6, its cost Cl SA is 2	0	0	0
P01-1014	J86-3001	2001	This strongly suggests that there are critical differences between thesis statements and summary sentences, at least in first-draft essay writing	0	It is possible that thesis statements reflect an intentional facet <TREF>Grosz and Sidner, 1986</TREF> of language, while summary sentences reflect a semantic one <REF>Martin, 1992</REF>	0	More detailed experiments need to be carried out though before proper conclusions can be derived	0	Table 1a: Agreement between human judges on thesis and summary sentence identification	0	0	0
W04-0712	J86-3001	2004	By a group, we understand a collection of information that is orthogonal to other information	0	By 4The reader may recognize a certain similarity of the considerations in this section with the approach of <TREF>Grosz and Sidner, 1986</TREF>	0	An example: We restrict ourself to some remarks: Grosz  Sidner focus on the segmentation of discourse along the hierarchical structure of a task, while we focus on problems concerning repetition this section and variation of tasks next section	0	Grosz  Sidner are mainly concerned with anaphoric reference while we are concerned with ellipsis and related implicit inheritance of information	0	0	0
W99-0304	J86-3001	1999	One reason for this is that our experiments were done with untrained subjects, which means that there can be more room for improvements on the reliability	0	23 m m m  m m  m m m m m m  m m mm m m h Data Map task group scheduling route direction telephone shopping appointment scheduling Total II  l umber of utterance II P A PE Table 1: Evaluation of utterance unit tagging scheme first version second version agree 3 agree 2 disagree agree 3 60 51 1 41 38 8 0 3 35 86 24 1 26 28 6 30 31 87 29 245 119  ii 218 375 agree 2 disagree 54 18 12 4 6 9 20 4 21 11 i13 46 377 076 068 044 012 057 064 3 Discourse Structure 31 First annotation scheme Grosz and Sidner proposed a model of discourse structure, in which discourse structure is composed of the linguistic structure, the intentional structure, and the attentional state <TREF>Grosz and Sidner, 1986</TREF>	0	We built the first annotation scheme of discourse structure in dialogue based on this model	0	The written instruction of the scheme describes as follows	0	0	0
W97-0621	J86-3001	1997	11 Subdialogue behaviors Traditional analyses of human-human dialogue decompose sequences into segments which are locally coherent and which individually address their own subgoals in the overall dialogue structure	0	<REF>Hobbs, 1979</REF>; <REF>Reichman, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Lochbaurn, 1991</REF>	0	Such a segment is opened for a specific purpose, may involve a series of interactions between participants, and may be closed having successfuUy achieved the target subgoal	0	Such a segment may be interrupted for the purpose of achieving a new, locally discovered, subgoal or for approaching a different goal	0	0	0
H92-1089	J86-3001	1992	Third, not every intonational feature which is varied to convey structural information is perceptually salient	0	We present results of a study of the relationship between intonational features including pitch range, timing, and amplitude and aspects of discourse structure defined in terms of Grosz and Sidners 1986 model of discourse	0	We compare structural labelings of AP news text with prosodic/acoustic features examined from recordings of the same text read by a professional newscaster	0	We find significant correlations between prosodic/acoustic characteristics and both local and global aspects of discourse structure identified by our labelers	0	0	0
J95-1003	J86-3001	1995	In Section 4, we go into the process of interpreting deictic and anaphoric expressions in some detail	0	Subsequently, in Section 5, we present some user interactions with EDWARD and we compare the results of EDWARDs referent resolution model with two other models including that of <TREF>Grosz and Sidner 1986</TREF>	0	2	0	Overview of EDWARD EDWARD is implemented in Allegro Common Lisp and runs on DECstations	0	0	0
J95-1003	J86-3001	1995	71 Computational Linguistics Volume 21, Number 1 5	0	Assessing the Quality of EDWARDs Referent Resolution Model To assess the quality of EDWARDs referent resolution model, we collected a series of referring expressions, which were processed by three different referent resolution models, namely that of EDWARD, as described above, a very simplistic model, and the sophisticated and often applied model proposed by <TREF>Grosz and Sidner 1986</TREF>	0	Since there are no benchmarks available to evaluate referent resolution models, we had subjects interact with EDWARD to compile a set of referring expressions	0	Usually, NL test sentences are made up by evaluators/designers themselves, but we think made-up test sentences may to some extent be unconsciously biased	0	0	0
J95-1003	J86-3001	1995	The application domain is military tactical air control	0	Like XTRA, CUBRICON uses two models to interpret deictic expressions: an attentional discourse focus space representation adapted from <TREF>Grosz and Sidner 1986</TREF> and a display model	0	<REF>Stock 1991</REF> describes ALFresco, a prototype built for the exploration of frescoes, using NL Italian and pictures	0	For referent resolution in ALFresco, topic spaces <REF>Grosz, 1978</REF> are combined with Hajiovs 1987 approach, in which entities are assumed to fade away slowly	0	0	0
J95-1003	J86-3001	1995	The proposed model for reference resolution elaborates on Alshawis 1987 notions of context factors and salience and integrates both linguistic and perceptual context effects	0	The model is contrasted with two alternative referent resolution models, namely, a simplistic one and the more sophisticated model proposed by <TREF>Grosz and Sidner 1986</TREF>	0	Based on empirical and analytical grounds, we conclude that the model we propose is preferable from a computational and engineering point of view	0	1	0	0	0
J95-1003	J86-3001	1995	First, EDWARDs Context Model and the Simplistic Model do not make any predictions about discourse intention	0	Discourse intentions play a primary role in explaining discourse structure, defining discourse coherence, and providing a coherent conceptualization of the term discourse <TREF>Grosz and Sidner 1986</TREF>	0	Discourse intentions can provide clues for the beginning and ending of dialogues and subdialogues	0	Referent resolution can make use of this structure to exclude referents to subdialogues that are ended	0	0	0
J95-1003	J86-3001	1995	To prevent uncontrolled growing of the stack, we had the system discard the object at the bottom of the stack as soon as the stack length exceeded a certain maximum	0	The second alternative referent resolution model is that of <TREF>Grosz and Sidner 1986</TREF>	0	Their model consists of two separate mechanisms, each resolving a specific type of referring expression	0	The first mechanism is called focusing	0	0	0
J95-2003	J86-3001	1995	In this section we describe the larger research context of this work and then briefly discuss the previous work that led to it	0	Centering fits within the theory of discourse structure developed by <TREF>Grosz and Sidner 1986</TREF>	0	Grosz and Sidner distinguish among three components of discourse structure: a linguistic structure, an intentional structure, and an attentional state	0	At the level of linguistic structure, discourses divide into constituent discourse segments; an embedding relationship may hold between two segments	0	0	0
J94-2003	J86-3001	1994	Centering has its computational foundations in the work of Grosz and Sidner <REF>Grosz 1977</REF>; <REF>Sidner 1979</REF>; <TREF>Grosz and Sidner 1986</TREF> and was further developed by Grosz, Joshi, and Weinstein 1983, unpublished and <REF>Joshi and Weinstein 1981</REF>	0	Centering is intended to reflect aspects of ATYENTIONAL STATE in a tripartite view of discourse structure that also includes INTENTIONAL STRUCTURE and LINGUISTIC STRUCTURE <TREF>Grosz and Sidner 1986</TREF>	0	In Grosz and Sidners theory of discourse structure, discourses can be segmented based on intentional structure, and a discourse segment exhibits both local and global coherence	0	Global coherence depends on how each segment relates to the overall purpose of the discourse; local coherence depends on aspects such as the syntactic structure of the utterances in that segment, the choice of referring expressions, and the use of ellipses	0	0	0
J94-2003	J86-3001	1994	Centering Theory Within a theory of discourse, CENTERING is a computational model of the process by which conversants coordinate attention in discourse Grosz, Joshi, and Weinstein unpublished	0	Centering has its computational foundations in the work of Grosz and Sidner <REF>Grosz 1977</REF>; <REF>Sidner 1979</REF>; <TREF>Grosz and Sidner 1986</TREF> and was further developed by Grosz, Joshi, and Weinstein 1983, unpublished and <REF>Joshi and Weinstein 1981</REF>	0	Centering is intended to reflect aspects of ATYENTIONAL STATE in a tripartite view of discourse structure that also includes INTENTIONAL STRUCTURE and LINGUISTIC STRUCTURE <TREF>Grosz and Sidner 1986</TREF>	0	In Grosz and Sidners theory of discourse structure, discourses can be segmented based on intentional structure, and a discourse segment exhibits both local and global coherence	0	0	0
J96-3006	J86-3001	1996	1	0	Within the computational discourse community, there is a long-standing debate between proponents of theories based on domain-independent rhetorical relations most notably Rhetorical Structure <REF>Theory, Mann and Thompson 1988</REF>, henceforth RST; see also <REF>Hobbs 1985</REF> and those who subscribe to theories based on intentionality most notably that of <TREF>Grosz and Sidner 1986</TREF>, henceforth GS	0	While some researchers have tried to integrate the two approaches <REF>Moore and Paris 1993</REF>; <REF>Asher and Lascarides 1994</REF>; <REF>Hobbs 1993</REF>, the two are usually viewed as competing theories	0	Here we argue that GS and RST are essentially similar in what they say about how speakers intentions determine a structure of their discourse	0	0	0
J96-3006	J86-3001	1996	Toward a Synthesis of Two Accounts of Discourse Structure Megan Moser University of Pittsburgh Johanna D Moore t University of Pittsburgh Among researchers interested in computational models of discourse, there has been a long-standing debate between proponents of approaches based on domain-independent rhetorical relations, and those who subscribe to approaches based on intentionality	0	In this paper, we argue that the main theories representing these two approaches, RST <REF>Mann and Thompson 1988</REF> and GS <TREF>Grosz and Sidner 1986</TREF>, make similar claims about how speakers intentions determine a structure of their discourse	0	The similarity occurs because the nucleus-satellite relation among text spans in RST corresponds to the dominance relation among intentions in GS Building on this similarity, we sketch a partial mapping between the two theories to show that the main points of the two theories are equivalent	0	Furthermore, the additional claims found in only RST or only GS are largely consistent	0	0	0
J96-3006	J86-3001	1996	E-mail: jmoorecspittedu  1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 3 Prior research has established that recognition of intentional structure, and therefore appropriate generation of cues to such structure, is crucial for many discourseprocessing tasks	0	<TREF>Grosz and Sidner 1986</TREF> argued that intentional structure is crucial for anaphora resolution and plan recognition	0	Hirschberg et al	0	1987 show that intentional structure plays a role in intonation	0	0	0
J96-3006	J86-3001	1996	Intentions encode what the speaker was trying to accomplish with a given portion of discourse	0	The relations between intentions indicate whether one intention contributes to the satisfaction of another dominance or whether one intention must be satisfied before another satisfaction-precedence <TREF>Grosz and Sidner 1986</TREF>	0	In contrast, informational structure is concerned with domain relations among the things being talked about	0	<REF>Moore and Pollack 1992</REF> argue that both intentional and informational analyses are needed simultaneously	0	0	0
J01-4003	J86-3001	2001	Accuracy increased to 917 with the inclusion of selectional constraints	0	22 Centering Theory and BFPs Algorithm Centering theory is part of a larger theory of discourse structure developed by <TREF>Grosz and Sidner 1986</TREF>	0	These researchers assert that discourse structure has three compo508 Tetreault Centering and Pronoun Resolution nents: 1 a linguistic structure, which is the structure of the sequence of utterances; 2 the intentional structure, which is a structure of discourse-relevant purposes; and 3 the attentional state, which is the state of focus	0	The attentional state models the discourse participants focus of attention determined by the other two structures at any one time	0	0	0
P98-2135	J86-3001	1998	2	0	Broadcast News Analysis Human communication is characterized by distinct discourse structure <TREF>Grosz and Sidner 1986</TREF> which is used for a variety of purposes including managing interaction between participants, mitigating limited attention, and signaling topic shifts	0	In processing genre such as technical or journalistic texts, programs can take advantage of explicit discourse cues eg , the first, the most important to perform tasks such as summarization <REF>Paice 1981</REF>	0	Our initial inability to segment topics in closed caption news text using thesaurus based subject assessments <REF>Liddy and Myaeng 1992</REF> motivated an investigation of explicit turn taking signals eg , anchor to reporter handoff	0	0	0
J88-2006	J86-3001	1988	Getting a listener to resume a DS via the stack mechanism is taken to require less effort on a speakers part than returning to elaborate an argument or subtask description later on	0	The significance of <REF>Sidner 1983</REF> and <TREF>Grosz and Sidner 1986</TREF> for the current enterprise is that: Computational Linguistics, Volume 14, Number 2, <REF>June 1988</REF> 63 Bonnie Lynn Webber Tense as Discourse Anaphor  Sidner essentially shows how DF can move gradually among the discourse entities that make up a focus space, as the listener is processing its associated discourse segment;  Grosz and Sidner show how DF can make a radical jump to a different possibly newly evoked discourse entity as the listener moves to process the next discourse segment	0	o I reinterpret this in the current framework in terms of the anaphoric function aNPb,Ea	0	Within a discourse segment, the entity that is the DF is the most likely E a Over the discourse segment, other discourse entities in the segments focus space may in turn become DF	0	0	0
J88-2006	J86-3001	1988	9 <REF>In Sidner 1983</REF> DFs always are stacked for possible resumption later	0	<REF>In Grosz and Sidner 1986</REF> it is an entire focus space FS <REF>Grosz 1977</REF> that gets stacked ie , the collection of entities L is attending to by virtue of the current discourse segment DS but only when the 9purpose of the current DS is taken to dominate that of the one upcoming	0	Dominance relations are also specified further according to the type of discourse	0	In Grosz and Sidner, they are defined for task-related dialogues and arguments	0	0	0
E06-3001	J86-3001	2006	Overview of the data used	0	5 Preliminary Model Overviews The models evaluated in this paper are based on Centering Theory <REF>Grosz et al , 1995</REF>; <TREF>Grosz  Sidner, 1986</TREF> and the algorithms devised by Brennan and colleagues 1987 and adapted by <REF>Tetreault 2001</REF>	0	We examine a language-only model based on Tetreaults Left-Right Centering LRC model, a visual-only model that uses a measure of visual salience to rank the objects in the visual field as possible referential anchors, and an integrated model that balances the visual information along with the linguistic information to generate a ranked list of possible anchors	0	51 The Language-Only Model We chose the LRC algorithm <REF>Tetreault, 2001</REF> to serve as the basis for our language-only model	0	0	0
E87-1042	J86-3001	1987	E87-1042:140	1	TEMPORAL REASONING IN NATURAL LANGUAGE UNDERSTANDING: THE TEMPORAL STRUCTURE OF THE NARRATIVE Alexander Nakhimovsky Department of Computer Science Colgate University Hamilton, NY 13346 USA CSNet: sashacolgate Abstract This paper proposes a new framework for discourse analysis, in the spirit of <TREF>Grosz and Sidner 1986</TREF>, Webber 1987a,b but differentiated with respect to the type or genre of discourse	0	It is argued that different genres call for different representations and processing strategies; particularly important is the distinction between subjective, pefformative discourse and objective discourse, of which narrative is a primary example	1	This paper concentrates on narratives and introduces the notions of temporal focus proposed also in <REF>Webber 1987b</REF> and narrative move	1	1	3
J95-3001	J86-3001	1995	For example, the expectation that the user is going to report the setting of a switch would be represented as obsphysstatepropswitchl,state, PropValue, TruthStatus	0	Expectation of user responses provides a model of the attentional state described by <TREF>Grosz and Sidner 1986</TREF>	0	It contains the list of semantic structures that have meaning for the current subdialog and for other active subdialogs	0	For example, after the computer produces an utterance that is an attempt to have a specific task step S performed, there are expectations for any of the following types of responses: 1 2 3 4 5 6 A statement about missing or uncertain background knowledge necessary for the accomplishment of S A statement about a subgoal of S A statement about the underlying purpose for S A statement about ancestor task steps of which accomplishment of S is a part	0	0	0
J95-3001	J86-3001	1995	10	0	Theoretical Issues from the <REF>Literature Grosz and Sidner 1986</REF> have given a high-level theory of dialog	0	The theory specifies three components, the linguistic, intentional, and attentional structures, and describes their nature and relationships to each other	0	However, their theory leaves a whole variety of issues undetermined; without a full implementation, the question of its applicability remains unanswered	0	0	0
J95-3001	J86-3001	1995	310 Smith, Hipp, and Biermann An Architecture for Voice Dialog Systems The intentional component specifies the purpose of the dialog	0	<TREF>Grosz and Sidner 1986</TREF> use the notation DP and DSP to stand for discourse purpose and discourse segment purpose	0	These entities correspond to the predicate goals that our system poses and then builds the dialog around	0	Our system, in fact, constructs a set of partial proofs and these are our instantiation of the intentional component	0	0	0
J95-3001	J86-3001	1995	Efficient dialog requires that each participant understand the purpose of the interaction and have the necessary prerequisites to cooperate in its achievement	0	This is the intentional structure of <TREF>Grosz and Sidner 1986</TREF>, the goaloriented mechanism that gives direction to the interaction	0	The primary required facilities are a problem solver that can deduce the necessary action sequences and a set of subsystems capable of carrying out those sequences	0	Subdialogs and effective movement between them	0	0	0
J95-3001	J86-3001	1995	In fact, the current subdialog specifies the focus of the interaction, the set of all objects and actions that are locally appropriate	0	This is the attentional structure described by <TREF>Grosz and Sidner 1986</TREF>, and its most important function in our system is to predict the meaning structures the user is likely to communicate in an input	0	For illustration, the opening of a chassis cover plate will often evoke comments about the objects behind the cover; the measurement of a voltage is likely to include references to a voltmeter, leads, voltage range, and the locations of measurement points	0	Thus the subdialog structure provides a set of expected utterances at each point in the conversation, and these have two important roles: 1 2 The expected utterances provide strong guidance for the speech recognition system so that error correction can be enhanced	0	0	0
J95-3001	J86-3001	1995	Efficient human dialog is usually segmented into utterance sequences, subdialogs, that are individually aimed at achieving relevant subgoals <REF>Grosz 1978</REF>; <REF>Linde and Goguen 1978</REF>; <REF>Polanyi and Scha 1983</REF>; <REF>Reichman 1985</REF>	0	These are called segments by <TREF>Grosz and Sidner 1986</TREF> and constitute the linguistic structure defined in their paper	0	The global goal is approached by a series of attempts at subgoals each of which involves a set of interactions, the subdialogs	0	An aggressive strategy for global success is to choose the subgoals judged most likely to lead to success and carry out their associated subdialogs	0	0	0
W99-0106	J86-3001	1999	In other cases, these modules are integrated by means of statistical <REF>Ge et al , 1998</REF> or uncertainty reasoning techniques <REF>Mitkov, 1997</REF>	0	The fact that current anaphora resolution systems rely exclusively on the linear nature of texts in Order to determine the LPA of an anaphor seems odd, given that several studies have claimed that there is a strong relation between discourse structure and reference <REF>Sidner, 1981</REF>; <REF>Gmsz and Sidner, 1986</REF>; Grosz et aL, 1995; <REF>Fox, 1987</REF>; <REF>Vonk et al , 1992</REF>; <REF>Azzam et al , 1998</REF>; Hitzeman and Poesio, 1998	0	These studies claim, on the one hand, that the use of referents in naturally occurring texts imposes constmints on the interpretation of discourse; and, on the other, that the structure of discourse constrains the HAs to which anaphors can be resolved	0	The oddness of the situation can be explained by the fact that both groups seem primafacie to be righL Empkical experiments studies that employ linear techniques for determining the LPAs of anaphom report recall and precision anaphora resolution results in the range of 80 in and Ieass, 1994; <REF>Ge et al , 1998</REF>	0	0	0
W94-0324	J86-3001	1994	Itowever, no elaborate interaction models are provided in this field except simplistic iterative question-answer models	0	In the area of conversational analysis and discourse theory, on the other hand, we find various discourse and dialogue models which address local dialogue structures eg , <REF>Fawcett et al , 1988</REF>; <REF>Grosz and Sidner, 1986, 1990</REF>; <REF>Reichman, 1985</REF>	0	To be able to design a flexible dialogue system which can engage in cooperative information-seeking dialogues we    4 use the Conversational Poles model COR developed by <REF>Sitter and Stein 1992</REF>	0	It has been used to design the interface of a multimedia information system, called MERIT cf	0	0	0
W94-0324	J86-3001	1994	A system which is capable of performing dialogues with a user on the basis of speech, was proposed by <REF>Smith, Hipp and Biermann 1992</REF>	0	Its domain is the maintenance of electrical appliances, and the emphasis in this approach lies on nested communicative goals, and concepts such as intentional, attentional and linguistic structures <TREF>Grosz and Sidner, 1986</TREF>	0	Another system for the treatment of spoken dialogues is reported in <REF>Bilange 1991</REF>	0	The approach, which has been developed in the framework of the SUNDIAL project, 207 7th International Generation Workshop  Kennebunkport, Maine  June 21-24, 1994 is based on the assumption that dialogues can best be described by means of a multi-level approach	0	0	0
W00-1007	J86-3001	2000	One of the most popular approaches to anaphora resolution is centering <REF>Grosz et al , 1995</REF>, henceforth GJW95, which accounts for the relation between the saliency of entities in discourse and the use of referring expressions, incorporating syntax, semantics and pragmatics	0	Centering fits into Grosz and Sidners model of discourse structure <TREF>Grosz and Sidner, 1986</TREF>	0	In this model a discourse is composed of segments which exhibit global coherence	0	A discourse 1This work has been carried out under Staging, an on-going Danish project funded by the Danish Research Councils	0	0	0
J93-3003	J86-3001	1993	The recognition and appropriate generation of cue phrases is of particular interest to research in discourse structure	0	The structural information conveyed by these phrases is crucial to many tasks, such as anaphora resolution <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF></TREF>; <REF>Reichman 1985</REF>, the inference of speaker intention and the recognition of speaker plans <TREF>Grosz and Sidner 1986</TREF></TREF>; <REF>Sidner 1985</REF>; <REF>Litman and Allen 1987</REF>, and the generation of explanations and other text <REF>Zuckerman and Pearl 1986</REF>	0	Despite the crucial role that cue phrases play in theories of discourse and their implementation, however, many questions about how cue phrases are identified and defined remain to be examined	0	In particular, the question of cue phrase polysemy has yet to receive a satisfactory solution	0	0	0
J93-3003	J86-3001	1993	<REF>Alternatively, Cohen 1984</REF> adopts a taxonomy of connectives based on <REF>Quirk 1972</REF> to assign each class of cue phrase a function in her model of argument understanding	0	<TREF>Grosz and Sidner 1986</TREF>, in their tripartite model of discourse structure, classify cue phrases based on the changes they signal to the attentional and intentional states	0	<REF>Zukerman 1986</REF> presents a taxonomy of cue phrases based on three functions in the generation of tutorial explanations: knowledge organization, knowledge acquisition, and affect maintenance	0	Table 14 in the Appendix compares the characterization of items classed as cue phrases in a number of these classification schemes	0	0	0
J93-3003	J86-3001	1993	Previous Studies of Cue Phrases The critical role that cue phrases play in understanding and generating discourse has often been noted in the computational linguistics literature	0	For example, it has been shown that cue phrases can assist in the resolution of anaphora, by indicating the presence of a structural boundary or a relationship between parts of a discourse <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Reichman 1985</REF>	0	In Example 7 RJB86, interpretation of the anaphor it as co-indexed with the system is facilitated by the presence of the cue phrases say and then, marking potential antecedents in as an expert database for an expert system as structurally unavailable	0	503 Computational Linguistics Volume 19, Number 3 Example 7 If the system attempts to hold rules, say as an expert database for an expert system, then we expect it not only to hold the rules but to in fact apply them for us in appropriate situations	0	0	0
J93-3003	J86-3001	1993	The corpus consisted of a keynote address given from notes by Ronald Brachman at the First International Conference on Expert Database Systems in 1986	0	This talk yielded 953 tokens, based upon a set of possible cue phrases derived from <REF>Cohen 1984</REF>, <TREF>Grosz and Sidner 1986</TREF>, <REF>Litman and Hirschberg 1990</REF>, <REF>Reichman 1985</REF>, <REF>Schiffrin 1987</REF>, <REF>Warner 1985</REF>, and <REF>Zuckerman and Pearl 1986</REF>	0	The frequency distribution of the tokens is shown in Table 5	0	By far the most frequent cue phrase occurring in our corpus is the conjunction and, representing 320 336 tokens	0	0	0
P06-2097	J86-3001	2006	For example,  add salt is assigned to ireru:1 add and A  carve with a knife is assigned to case frame ireru:2 carve	0	312 Cue phrases As Grosz and Sidner <TREF>Grosz and Sidner, 1986</TREF> pointed out, cue phrases such as now and well serve to indicate a topic change	0	We use approximately 20 domain-independent cue phrases, such as pxthen, xnext and fO hthen	0	313 Noun Chaining In text segmentation algorithms such as TextTiling HearstM, 1997, lexical chains are widely utilized for detecting a topic shift	0	0	0
J04-2001	J86-3001	2004	1	0	Centering has been proposed as a model of the local attentional states of speakers and hearers involved in the mutual construction of conversation <REF>Brennan, Friedman, and Pollard 1987</REF>; <REF>Grosz and Sidner 1986, 1998</REF>; <REF>Walker 1998</REF>	0	Centering mechanisms are designed to model the coherence of discourse by characterizing transitions between utterances in terms of their inferential load and hence their naturalness	0	These characterizations are intended to capture intuitions about the flow <REF>Chafe 1979</REF> or the ongoing process of meaning <REF>Halliday 1994</REF> in discourse	0	0	0
C98-2183	J86-3001	1998	Dialogue Act Tagging To address a significant concern in machine learning, called the sparse data problem, we nmst select an appropriate set of features	0	Researchers in discourse, such as <TREF>Grosz and Sidner 1986</TREF>, <REF>Lambert 1993</REF>, <REF>Hirschberg and Litman 1993</REF>, <REF>Chen 1995</REF>, <REF>Andernach 1996</REF>, <REF>Samuel 1996</REF>, and Chu-<REF>Carroll 1998</REF> have suggested several features that might be relevant for the task of computing dialogue acts	0	Our system can consider the following features of an utterance: 1 tile cue phrases a in the utterance; 2 the word n-grams a in the utterance; 3 the dialogue act cues 3 in the utterance; 4 the entire utterance for one-, two-, or three-word utterances; 5 speaker information 4 for the utter2The part-of-speech tag of a word is dependent on the words internal features and on the surrounding words; similarly, the dialogue act of an utterance is dependent on the utterances internal features and on tile surrounding utterances	0	3This feature is defined later in this section	0	0	0
J88-3008	J86-3001	1988	Since a discourse has relatively short duration, the discourse model that supports the interaction contains short term or temporary information	0	It is important to note that the representations of entities, as they appear in the discourse have a structure as proposed by <TREF>Grosz and Sidner 1986</TREF>	0	While Grosz and Sidner do not specifically deal with discourse models, their view on discourse is applicable to discourse models	0	The discourse model reflects the structure of the dialog	0	0	0
J87-1002	J86-3001	1987	It is more an indication of the motivation behind each utterance towards the ultimate goal of convincing the hearer	0	The difficulties in plan inference for discourse are discussed in more detail in <TREF>Grosz and Sidner 1986</TREF>, and are in fact a topic of our current concern see discussion of future work in Section 6	0	There is in fact a whole spectrum of problems the hearer must face in recognizing evidence relationships between propositions	0	The four main tests for the hearer can be described as:  use logic,  relax the logic,  stereotype the speaker,  judge plausibility reason as a hypothetical person	0	0	0
J87-1002	J86-3001	1987	We are interested in specifying a processing model for discourse understanding that operates at the level of individual utterances, in the manner of the argument model, to gain insight into how to derive linguistic and intentional structure simultaneously	0	This research is of significance to the current work of <TREF>Grosz and Sidner 1986</TREF>	0	ACKNOWLEDGMENTS This work was supported in part by the Natural Sciences and Engineering Research Council of Canada	0	I am grateful to the anonymous referees for their valuable comments and to Ray Perrault for his initial supervision of this research	0	0	0
J87-1002	J86-3001	1987	For future work, we are studying how to specify this process more precisely	0	See also <TREF>Grosz and Sidner 1986</TREF>	0	Finally, if the hearer is testing a possible evidence relation between two propositions, does not believe the missing premise, and has no prior knowledge of the speaker, the best option available is to try to judge the plausibility of the unstated information	0	Essentially, the hearer must postulate new facts which he may not be sure he wants to also believe and consider relationships between these facts as plausible or not	0	0	0
J87-1002	J86-3001	1987	Both active and 9Pen spaces are tracked, similar to our tracking candidates eligible to be relatives to the current proposition	0	Because of similarities in the representations and techniques for controlling search for interpretations, it is worth investigating as future work the precise relationship among coherence, reference resolution and focus determination for dialogues some of this is being done <TREF>Grosz and Sidner 1986</TREF>	0	53 PSYCHOLOGICAL RESEARCH Although our model is not designed according to psychological studies of discourse comprehension, there are some interesting parallels with existing psychological research	0	<REF>Labov and Fanshel 1977</REF> investigate therapeutic discourse, dialogue between a psychologist and his patient	0	0	0
J87-1002	J86-3001	1987	This approach to the study of clue words is much more detailed than the initial suggestions of <REF>Hobbs 1976</REF> on how to interpret a few connectives such as and in his framework	0	It is also distinct from the investigations of <REF>Reichman 1981</REF> and recently <TREF>Grosz and Sidner 1986</TREF>	0	Grosz and Sidner acknowledge the existence of clues and discuss various discourse structures that can be formed in the presence of clues	0	Reichman also gives a longer list of clue words and the particular conversational moves they signal	0	0	0
C88-2114	J86-3001	1988	A receiver makes use of these classificatory devices to classify and understand any speeifle CS with which he or she is presented	0	Focus space k Speaker Display OAct Act type Act structure  Figure 1 Structural components of the model 23 Cotmmunicative Situation Structures The Conmtunicative Situation Structure CSS is equivalent in level of analysis to the discourse segment of the <TREF>Grosz and Sidner 1986</TREF> model	0	The three components of the CSS see Figure I are the conmnicative act component CAct, the communicative situation component CS, and certain properties specific to the CSS itself	0	A CSS can consist of a number of CSs, and these in turn can consist of a number of CAets	0	0	0
W93-0225	J86-3001	1993	In its broadest outline, the goaJ is to uulerstaad the precise iH:eraction between features of tbrm, meaning and ffim:tion ill the creatioll of discourse coherem:e What kiuld o1 tbrm, meaning tnti flmction links occur etween utteraJlces and how are these thre, ki,lIs of links recognized	0	In a tirst step towards the synthesis we wouhl like to see, we will discuss the lerspective which the GS <TREF>Grosz and Sidner 1986</TREF> and RST RhetoricaJ Structure Theory, Mann and <REF>Thompson 1988</REF> theories take on links of meaning and function	0	We conclude with a brief description of an empiricaJ study suggested by this theory comparison	0	Note that we consider only monologic discourse at this time, believing generalizztions between this and multi-agent discourse to be premature	0	0	0
W03-2101	J86-3001	2003	 is a discourse-level problem	0	Grosz and Sid-	0	 ner<TREF>Grosz and Sidner, 1986</TREF> claim that a robust	0	 model of discourse understanding must use mul-	0	0	0
W03-2101	J86-3001	2003	 has a structure comprised of discourse segments	0	Each discourse segment has a discourse seg-	0	 ment purpose that contributes to the discourse	0	 purpose or intention underlying the overall dis-	0	0	0
C90-3018	J86-3001	1990	other features of non-cue usage: does a connective loose its normal meaning when used as a cue	0	Some researchers <TREF>Grosz  Sidner, 1986</TREF>, <REF>Hirschberg  Litman, 1987</REF> seem to argue that it does: the cue and non-cue usages are actually two distinct words	0	If that is the case, it would be difficult for a generator to choose among the different cue words that can perform the same structural task	0	On the other hand, we have no evidence at this point that cue words are not interchangeable eg , that but is used for one kind of pop and now another	0	0	0
C90-3018	J86-3001	1990	In this paper, we concentrate on the distinctions between similar connectives rather than on the general properties of the class of connectives	0	Work on the structure of discourse <REF>Cohen, 1984</REF>, <REF>Reichman, 1985</REF>, <TREF>Grosz  Sidner, 1986</TREF> has identified the role of connectives in marking structural shifts	0	This work generally relies on the notion that hearers maintain a discourse model which is often represented using stacks	0	Connectives give instructions to the hearer on how to update the discourse model	0	0	0
W00-1013	J86-3001	2000	And of course we will never reach a system in which every user need can be anticipated but then even human beings are not that type of system	0	4See <TREF>Grosz and Sidner, 1986</TREF> for a discussion of the importance of task plans in more explanatory dialogue	0	5It would also need tools that make it easy to model the relation between the linguistic expressions used in the various renderings of the base document	0	One can see this task as akin to that of multilingual generation or even simple document rendering	0	0	0
P95-1005	J86-3001	1995	Otherwise the entity which the expression refers to would have already been popped from the stack by the time the reference would need to be resolved	0	We develop our theory of discourse structure in the spirit of <TREF>Grosz and Sidner 1986</TREF> which has played an influential role in the analysis of discourse entity saliency and in the development of dialogue processing systems	0	Before we make our argument, we will argue for our approach to discourse segmentation	0	In a recent extension to Grosz and Sidners original theory, described in <REF>Lochbaum 1994</REF>, each discourse segment purpose corresponds to a partial or full shared plan 3 <REF>Grosz and Kraus 1993</REF>	0	0	0
P95-1005	J86-3001	1995	There are two main contributions of the work we will discuss in this paper	0	From a theoretical standpoint, we will demonstrate that theories which postulate a strict tree structure of discourse henceforth, Tree Structure Theory, or TST on either the intentional level or the attentional level <TREF>Grosz and Sidner 1986</TREF> are not totally adequate for covering spontaneous dialogues, particularly negotiation dialogues which are composed of multiple threads	0	These are negotiation dialogues in which multiple propositions are negotiated in parallel	0	We will discuss our proposea extension to TST which handles these structures in a perspicuous manner	0	0	0
P95-1005	J86-3001	1995	Notice that in both of these examples, the speakers negotiate over multiple alternatives in parallel	0	We challenge an assumption underlying the best known theories of discourse structure <TREF>Grosz and Sidner 1986</TREF>; <REF>Scha and <REF>Polanyi 1988</REF></REF>; <REF>Polanyi 1988</REF>; <REF>Mann and Thompson 1986</REF>, namely that discourse has a recursive, tree-like structure	0	<REF>Webber 1991</REF> points out that Attentional State i is modeled equivalently as a stack, as in Grosz and Sidners approach, or by constraining the current discourse segment to attach on the rightmost frontier of the discourse structure, as in Polanyi and Schas approach	0	This is because attaching a leaf node corresponds to pushing a new element on the stack; adjoining a node Di to a node Dj corresponds to popping all the stack elements through the one corresponding to Dj and pushing Di on the stack	0	0	0
J92-4007	J86-3001	1992	However, recent work by <REF>Moore and Paris 1992</REF> noted that RST cannot be used as the sole means of controlling discourse structure in an interactive dialogue system, because RST representations provide insufficient information to support the generation of appropriate responses to follow-up questions	0	The basic problem is that an RST representation of a discourse does not fully specify the intentional structure <TREF>Grosz and Sidner 1986</TREF> of that discourse	0	Intentional structure is crucial for responding effectively to questions that address a previous utterance: without a record of what an utterance was intended to achieve, it is impossible to elaborate or clarify that utterance	0	1 Further consideration has led us to conclude that the difficulty observed by Moore and Paris stems from a more fundamental problem with RST analyses	0	0	0
J92-4007	J86-3001	1992	An interpretation system therefore needs the capability of maintaining both levels of relation	0	4 <REF>In Grosz and Sidner 1986</REF>, dominates and satisfaction-precedence are the intentional relations, while supports and generates are the informational relations	0	5 The hearer also needs to believe that it is plausible the speaker holds the same belief; see <REF>Konolige and Pollack 1989</REF>	0	6 This is thus an example of what Sadock calls modus brevis <REF>Sadock 1977</REF>	0	0	0
J92-4007	J86-3001	1992	RST presumes that, in general, there will be a single, preferred rhetorical relation holding between consecutive discourse elements	0	In fact, as has been noted in other work on discourse structure <TREF>Grosz and Sidner 1986</TREF>, discourse elements are related simultaneously on multiple levels	0	In this paper, we focus on two levels of analysis	0	The first involves the relation between the information conveyed in consecutive elements of a coherent discourse	0	0	0
P98-2179	J86-3001	1998	3 Deductive Operators The choice of operators implemented in the Rhetorica system has been influenced by a number of factors	0	The rules of inference are clear candidates for operationalisation: moves such as Modus Ponens are clearly vital components of any argument though, as noted in <TREF>Grosz and Sidner 1986</TREF>, p201, it is inappropriate to view the implication step as one of conventional material implication	0	The relationship is rather one of support the hearer must be brought to believe that given the current context and domain of discourse the first proposition warrants, in part, concluding the second	0	Even given this weaker, predicate-based reading of a Modus Ponens argument, it is still unclear that any of the other rules of inference which are, after all, formally redundant should be necessary	0	0	0
P98-2179	J86-3001	1998	Belief goals are used to build the content of an argument as in much other NLG work; saliency goals to express the intention to convey information to the hearer following a notion of saliency similar to that proposed in <REF>Walker, 1996</REF>; and topic manipulation goals to control the focus of attention through the discourse	0	The roles of these goals and their interrelationships are explored in relation to the informationintention-attention model of <TREF>Grosz and Sidner 1986</TREF> in more detail in <REF>Reed and Long 1997a</REF>	0	3 Deductive Operators The choice of operators implemented in the Rhetorica system has been influenced by a number of factors	0	The rules of inference are clear candidates for operationalisation: moves such as Modus Ponens are clearly vital components of any argument though, as noted in <TREF>Grosz and Sidner 1986</TREF>, p201, it is inappropriate to view the implication step as one of conventional material implication	0	0	0
P07-1101	J86-3001	2007	However, acoustic features capturing the pitch excursion at the right edge of okay feature prominently in disambiguation, whether other contextual cues are present or not	0	CUE PHRASES also known as DISCOURSE MARKERS are linguistic expressions that can be used to convey explicit information about the structure of a discourse or to convey a semantic contribution <TREF>Grosz and Sidner, 1986</TREF>; <REF>Reichman, 1985</REF>; <REF>Cohen, 1984</REF>	0	For example, the word okay can be used to convey a satisfactory evaluation of some entity in the discourse the movie was okay; as a backchannel in a dialogue to indicate that one interlocutor is still attending to another; to convey acknowledgment or agreement; or, in its cue use, to start or nish a discourse segment <REF>Jefferson, 1972</REF>; <REF>Schegloff and Sacks, 1973</REF>; <REF>Kowtko, 1997</REF>; <REF>Ward and Tsukahara, 2000</REF>	0	A major question is how speakers indicate and listeners interpret such variation in meaning	0	0	0
C94-2187	J86-3001	1994	Thus a discourse should look like Figure 1, where G denotes a discourse segment	0	Fnrthermore, we do not intend the disD Figure 1: Discourse Structure course structure to be anything close to the ones that rhetorical theories of discourse t<REF>Iovy, 1990</REF>; <REF>Mann and Tholnpson, 1987</REF>; <REF>Itobbs, 1979</REF> claim it to be, or inteulional structure <TREF>Grosz and Sidner, 1986</TREF> ; indeed we do not assmne any functional relation, ie causation, elaboration, extension, etc , among the segments that constitute a discourse structure	0	The present theory is not so much about the rhetoric or the function of discourse as about the way anaphora are interpreted	0	It is quite possible that a set of discourse segments are not aggregated into a single discourse but may have diverse discourse groupings <REF>Nomoto and Nitta, 1993</REF>	0	0	0
W99-0101	J86-3001	1999	2 Background: Discourse Structure We assume the general theoretical framework of <REF>Roberts 1996</REF>, where discourse is formally characterized as a game of intentional inquiry	0	As in <TREF>Grosz  Sidner 1986</TREF>, discourse is organized by the interlocutors goals and intentions and the plans, or strategies, which conversational participants develop to achieve them	0	<REF>Following Stalnaker 1979</REF>, the primary goal of the language game is communal inquiry, ie, interlocutors attempting to share information about their world, with the repository of that shared information characterized as the interlocutors common groun CG	0	The set of acceptable moves in the game are defined by the conventional and conversational rules of the game, and are classified on the basis of their relationblp to the goals	0	0	0
W00-1430	J86-3001	2000	Indeed, knowing which kind of activity the user is involved in at each moment ie the ontology instances involved in that activity we hypothesise on which person and keyword the users attention is focused on	0	22 Attention focus and Information Structure Theory   Other researchers have investigated attention focus in larger spans of discourse <REF>McCoy and Cheng, 1991</REF>; <TREF>Grosz and Sidner, 1986</TREF> and in dialogue <REF>Jokinen et al , 1998</REF>	0	Corpus analysis <REF>Rats, 1996</REF> confirms the existence of a mechanism called topic, through which interlocutors strive at discourse coherence to reduce the cognitive effort of the hearer	0	The terminology used in the different frameworks is confusing, even contradictory Bosch and van der <REF>Sandt, 1999</REF>	0	0	0
W97-1411	J86-3001	1997	82 D He, G Ritchie and J Lee price band about the depictive mapping, since the user is querying a directly depicted world property	0	Coherence The coherence of the proceeding dialogue should not be damaged by an object becoming the referent of the expression <TREF>Grosz and Sidner, 1986</TREF>	0	It follows that the disambiguation process should be based on the following information sources: the world model and the display model for the sources of candidates and the examination of various restrictions, the dialogue model for providing coherence information about the dialogue and the user model for the modelling of mutual beliefs	0	In practice, our project is too limited to explore all of these issues, and we intend to leave aside issues of mutual belief that is, our user model will be degenerately simple	0	0	0
W06-1309	J86-3001	2006	Ony if these factors are represented in an effective and efficient formal language, dialogue systems can be implemented	0	Examples of such models and their implementation are the informationstate-update approach an implemented system is described in <REF>Larsson, 2002</REF>, or  more linguisticallyorientedapproachesliketheadjacency-pair models or intentional models such as GROSZ and SIDNERs see <TREF>Grosz and Sidner, 1986</TREF>	0	Even if it has been noted often that discourse structure and task structure are not isomorphic, only a few contributions to dialogue research focus on the question of how both structures interfere see Sect	0	2	0	0	0
C96-1052	J86-3001	1996	cl Avoid conveying redundant information	0	:2 Pronominalize objects in the focus of attention <TREF>Grosz and Sidner 1986</TREF>	0	c3 Be relevant according to the attentionM state	0	he context model records the information that has been conveyed and tracks the attentional state	0	0	0
W04-2318	J86-3001	2004	Keywords Dialogue Systems, Discourse structure, Prosody in understanding 1 Introduction Contemporary theories of discourse, both computational and descriptive, postulate a tree-structured hierarchical model of discourse	0	These structures may be viewed as corresponding tointentional structure of discourse segment purposes in the view of <TREF>Grosz and Sidner, 1986</TREF>, to plan and subplan structure directly in the view of <REF>Allen and Litman, 1990</REF>, to nuclei and satellite rhetorical relations in the Rhetorical Structure Theory of <REF>Mann and Thompson, 1987</REF>, or to information structures as in <REF>Traum and Hinkelman, 1992</REF>	0	Despite this diversity of views on the sources of structural organization, these theories agree on the decomposition of discourse into segments and subsegments in a hierarchical structure	0	Discourse segments help to establish the domain of interpretation for referents or anaphors	0	0	0
J88-3013	J86-3001	1988	The discourse model is then also needed to provide the links between the four, which support calls from one to another	0	A shifting focus of attention like that represented by the point of interaction between participants and discourse in Grosz and Sidners 1986 account is naturally presupposed here	0	But my argument is that we need to separate a participants in this case, the systems view of itself from its views of the world and of the user	0	The way these interact with the text model will then be reflected in a subset of relations and hence entities in the discourse model which constitutes the focus of attention	0	0	0
W07-1408	J86-3001	2007	In: ROMAND 206 1th EACL	0	Geneva, 206 3-10 Grosz B and C <REF>Sidner 1986</REF>	0	Atention, Intentions, and the Structure of Discourse, Computational Linguistics 12 3, 175-204	0	Raina, R , et al: Robust Textual Inference using Diverse Knowledge Sources	0	0	0
W07-1408	J86-3001	2007	Step A is identical and is recursively repeated until all clauses are processed	0	31 Focusing Revisited Our version of the focusing algorithm folows Sidners proposal Sidner C , 1983; Grosz B , Sidner C , 1986, to use a Focus Stack, a certain Focus Algorithm with Focus movements and data structures to allow for processing simple inferential relations between different linguistic descriptions co-specifying or coreferring to a given entity	0	Our Focus Algorithm is organized as folows: for each uterance, we assert three hierarchically ordered centersthat we call Main, Secondary and the first Potential Topic, which represent the best three referring expressions as they have been weighted in the candidate list used for pronominal binding; then we also keep a list of Potential Topics for the remaining best candidates	0	These 51 three best candidates repositories are renovated at each new uterance, and are used both to resolve pronominal and nominal cospecification and coreference: this is done both in case of strict identity of linguistic description and of nonidentity	0	0	0
W00-1420	J86-3001	2000	o <context> This is the context input/output	0	The context contains a stack for objects in focus, handled as described in <TREF>Grosz and Sidner, 1986</TREF>	0	Additionally we put the generated information on a history list <REF>Dale, 1995</REF>	0	The context supports the generation of, eg, pronouns see below	0	0	0
W93-0229	J86-3001	1993	Some people <REF>Searle and Vanderveken 1985</REF>, <REF>Cohen and Levesque 1990</REF> have assumed that the recognition of the speakers intention and other mental states in producing an utterance is extremely important to understand its meaning, but have limited their work on one single speech act	0	Because a conversation is a temporal sequence of connected illocutionary acts 110 <REF>Moulin, Rousseau and Vanderveken 1991</REF> where each speech act plays a precise role in the context of other speech acts, some researchers have studied the structure of a conversation and they all agreed that there are several interrelated components in it and many subconversations of different types <TREF>Grosz and Sidner 1986</TREF>, <REF>Litman and Allen 1987</REF>	0	The planning approach has been used by some scientists to produce speech acts in the context of a dialogue <REF>Allen 1983</REF>, <REF>Appelt 1985</REF>, <REF>Litman and Allen 1987</REF>, <REF>Lambert and Carberry 1992</REF>	0	Starting from the approaches mentioned above, the model of speech act planner we propose takes into consideration the following problems: multiagent planning, reasoning on other agents mental states and on ones own mental states, recognition of intentions behind direct and indirect speech acts, use of plans integrating linguistic and non-linguistic actions, coherence of the conversation between two or more agents, handling of subeonversations and modeling of the conversational context	0	0	0
E06-3002	J86-3001	2006	Coherence relations, such as Elaboration, Explanation and Contrast, are relations between discourse units that bind segments of text into one global structure	0	<TREF>Grosz and Sidner, 1986</TREF> incorporates two more important notions into its model the idea of intention and focus	0	The Rhetorical Structure Theory, introduced in <REF>Mann and Thompson, 1987</REF>, binds text spans with rhetorical relations, which are discourse connectives similar to coherence relations	0	The Discourse Representation Theory DRT <REF>Kamp, 1984</REF> computes inter-sentential anaphora and attempts to maintain text cohesion through sets of predicates, termed Discourse Representation Structures DRSs, that represent discourse 32 No one does He can still walk by himself Explanation Who supports Gorbachev	0	0	0
J97-1006	J86-3001	1997	The axioms may then be used by the theorem prover	0	Finally, integration of theorems, the utterances relevant to these theorems, and the expectations for responses that supply missing axioms yields a constructive method for creating and using a discourse model first proposed by <TREF>Grosz and Sidner 1986</TREF>, but for which they did not offer a method of dynamic construction during the course of a dialogue	0	Furthermore, the model enables the system to engage in variable initiative dialogue as outlined in Section 2	0	The interested reader is referred to <REF>Smith, Hipp, and Biermann 1995</REF> for further details about the overall model	0	0	0
J00-4003	J86-3001	2000	13 Only plural nouns ending in s are handled by the system	0	549 Computational Linguistics Volume 26, Number 4 In general, it is not sufficient to look at the most recent antecedents only: this is because segments are organized hierarchically, and the antecedents introduced in a segment at a lower level are typically not accessible from a segment at a higher level <REF>Fox 1987</REF>; <REF>Grosz 1977</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Reichman 1985</REF>, whereas the antecedents introduced in a prior segment at the same level may be	0	Later in 8, for example, the housej in sentence 50 becomes inaccessible again, and in sentence 65, the text starts referring again to the house introduced in sentence 2	0	Automatically recognizing the hierarchical structure of texts is an unresolved problem, as it involves reasoning about intentions; 14 better results have been achieved on the simpler task of chunking the text into sequences of segments, generally by means of lexical density measures <REF>Hearst 1997</REF>; <REF>Richmond, Smith, and Amitay 1997</REF>	0	0	0
J00-4003	J86-3001	2000	Our tests with bridging descriptions resulted in a great number of false positives	0	Our analysis of these data, as well as of other corpora <REF>Hitzeman and Poesio 1998</REF>, suggests that a local focusing mechanism as proposed in <REF>Grosz 1977</REF>, <REF>Sidner 1979</REF>, Grosz, Joshi, and Weinstein 1983, 1995, and <TREF>Grosz and Sidner 1986</TREF> would improve the results obtained by our system	0	There are several reasons why our system does not yet include such a mechanism	0	One problem already mentioned is that Sidners algorithms as stated, and even as implemented by Carter, are difficult to implement, since considerably more lexical information is needed than we have available eg , about the thematic roles of verbs, a rich knowledge base is needed both to resolve bridging descriptions and larger situation uses, and commonsense inference is needed to evaluate the plausibility of hypotheses	0	0	0
W96-0410	J86-3001	1996	Analogously, an entity is either new or old to the DISCOURSE, according to whether the discourse contains an earlier reference to it	0	Second, entities differ in SALIENCE <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al , 1995</REF>	0	At any point, salience assigns each entity a position in a partial order that indicates how accessible it is for reference in the current context	0	Third, entities are related by material PARTIALLY-ORDERED SET POSET RELATIONS to other entities in the context <REF>Hirschberg, 1985</REF>	0	0	0
W98-0301	J86-3001	1998	Most of the algorithmic research in discourse segmentation focused on segments of coarse granularity <REF>Grosz and Hirschberg, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Passonneau and Litman, 1997</REF>; <REF>Hearst, 1997</REF>; <REF>Yaari, 1997</REF>	0	These segments were defined intentionally in terms of Grosz and Sidners theory 1986 or in terms of an intuitive notion of topic	0	However, in case of applications such as anaphora resolution, discourse parsing, and text summarization, even sentences might prove to be too large discourse segments	0	For example, if we are to defive the discourse structure of texts using an RSTlike representation <REF>Mann and Thompson, 1988</REF>, we will need to determine the elementary textual units that contribute rhetorically to the understanding of those texts; usually, these units are clause-like units	0	0	0
H05-1090	J86-3001	2005	b If the first noun phrase is a third person personal pronoun, use the classification in the focus variable	0	Pronouns are known to signal that the same focus continues <TREF>Grosz and Sidner, 1986</TREF>	0	c If the sentence has not met any of the above tests but has a minimum number of content words, shift the focus	0	If all tests above fail and there are a minimum number of content words, with a sum of Tshift shift the focus	0	0	0
J91-1002	J86-3001	1991	This was found to be true	0	The lexical chains computed by the algorithm given in Section 323 correspond closely to the intentional structure produced from the structural analysis method of <TREF>Grosz and Sidner 1986</TREF>	0	This is important, since Grosz and Sidner give no method for computing the intentions or linguistic segments that make up the structure that they propose	0	Hence the concept of lexical cohesion, defined originally by <REF>Halliday and Hasan 1976</REF> and expanded in this work, has a definite use in an automated text understanding system	0	0	0
J91-1002	J86-3001	1991	This section will concentrate on analyzing correspondences between lexical chains and structural units of text, including:  the correspondence of chain boundaries to structural unit boundaries;  returns to existing chains and what they indicate about structural units;  lexical chain strength and reliability of predicting correspondences between chains and structural units;  an analysis of problems encountered, and when extra textual information is required to validate the correspondences between lexical chains and structural components	0	The text structure theory chosen for this analysis was that of <TREF>Grosz and Sidner 1986</TREF>	0	it was chosen because it is an attempt at a general domain-independent theory of text structure that has gained a significant acceptance in the field as a good standard approach	0	The methodology we used in our analyses was as follows: 1	0	0	0
J91-1002	J86-3001	1991	It follows that if lexical chains can be determined, they will tend to indicate the structure of the text	0	We will describe the application of lexical cohesion to the determination of the discourse structure that was proposed by <TREF>Grosz and Sidner 1986</TREF>	0	Grosz and Sidner propose a structure common to all discourse, which could be used along with a structurally dependent focus of attention to delineate and constrain referring expressions	0	In this theory there are three interacting components: linguistic structure, intentional structure, and attentional state	0	0	0
C00-1031	J86-3001	2000	In other cases, these modules are integrated by means of statistical <REF>Ge et al , 1998</REF> or uncertainty reasoning teclmiques <REF>Mitkov, 1997</REF>	0	The fact that current anaphora resolution systems rely exclusively on the linear nature of texts in order to determine the LPA of an anaphor seems odd, given flint several studies have claimed that there is a strong relation between discourse structure and reference <REF>Sidner, 1981</REF> ; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al , 1995</REF>; <REF>Fox, 1987</REF>; Vonk ct al , 1992; Azzam el al , 1998; <REF>Hitzcman and Pocsio, 1998</REF>	0	These studies claim, on the one hand, that the use of referents in naturally occurring texts imposes constraints on the interpretation of discourse; and, on the other, that the structure of discourse constrains the LPAs to which anaphors can be resolved	0	The oddness of the situation can be explained by lho fac	0	0	0
C92-2114	J86-3001	1992	For lack of space, however, we leave out the model of state change management needed to describe recipe ingredients being mixed together and transformed <REF>Kosseim 1992</REF>, ald the focus model used	0	41 Input We limit our scope to the linguistic part of generation; therefore, we assume that onr input is the ontput of a text planner, which has already grouped actions into discourse structures as proposed by <TREF>Grosz and Sidner 1986</TREF> and <REF>Dale 1988</REF>, The input is thus a sequence of actions and states in which participants ingredients, instruments and agent are represented by indices	0	42 Dictionary of concepts The dictionary of concepts has been inspired by <REF>Nirenburg and Raskin 1987</REF>; concepts are mainly subdivided into actions or objects	0	We have added a category of properties, needed to describe relations between concepts eg , temporal limit or attributes eg size	0	0	0
W05-1606	J86-3001	2005	The referring expression to be generated is required to be a distinguishing description, that is a description of the enitties being referred to, but not to any other object in the context set	0	A context set is defined as the set of the entities the addressee is currently assumed to be attending to  this is similar to the set of entities in the focus spaces of the discourse focus stack in Grosz and Sidners 1986 theory of discourse structure	0	Moreover, the contrast set or the set of potential distractors <REF>McDonald 1981</REF> is defined to entail all elements of the context set except the intended referents	0	Generating referring expressions is pursued since the eighties <REF>Appelt 1985</REF>, <REF>Kronfeld 1986</REF>, <REF>Appelt and Kronfeld 1987</REF>	0	0	0
W01-1603	J86-3001	2001	1: room for a lecture: return 42 B: D soreja dai-kaigishitsu de onegai shimasu Ok Please book the large meeting room	0	---------------------------------------TBI:topic name:segment relation Figure 5: An example dialogue with the dialogue segment tags 23 Dialogue segment DialoguesegmentofJDTAGindicatesboundaryof discourse segment introduced in <TREF>Grosz and Sidner, 1986</TREF>	0	A dialogue segment is identied based on the exchange structure explained above	0	A dialoguesegment tag is rst inserted before each initiating utterance	0	0	0
P92-1025	J86-3001	1992	However, 2 would probably still recognize 4 as an expression of doubt because the linguistic clue but suggests that 4 may be some sort of non-acceptance action, there is nothing to suggest that S1 does not believe that Dr Smith winning a teaching award implies that she is not teaching Architecture, and no other interpretation seems more coherent	0	Since linguistic knowledge is present, less evidence is needed from world knowledge to recognize the discourse actions being performed <TREF>Grosz and Sidner, 1986</TREF>	0	In our model, if a new utterance contributes to a discourse action already in the DM, then there must be an inference path from the utterance that links the utterance up to the current tree structure on the discourse level	0	This inference path will contain an action that determines the relationship of the utterance to the DM by introducing new parameters for which there are many possible instantiations, but which must be instantiated based on values from the DM in order for the path to terminate with an action already in the DM	0	0	0
P92-1025	J86-3001	1992	So, our model captures many of the ways in which people infer beliefs: 1 from the surface form of utterances; 2 from stereotype models; and 3 from acceptance explicit or implicit or non-acceptance of previous actions	0	5 Combining Knowledge <REF>Sources Grosz and Sidner 1986</REF> contend that modeling discourse requires integrating different kinds of knowledge in a unified framework in order to constrain the possible role that an utterance might be serving	0	We use three kinds of knowledge, 1 contextual information provided by previous utterances; 2 world knowledge; and 3 the linguistic information contained in each utterance	0	Contextual knowledge in our model is captured by the DM and the current focus of attention within it	0	0	0
W06-3001	J86-3001	2006	It seems that as long as this relation exists, even if there are many segments in between8, the first entity remains in focus of attention and can be referred to by an implicit deictic or definite NP without any additional retrieval cue	0	We can speak of thematic nesting of segments, which seems to be analogous to the intentional structure in taskoriented dialogues as in <TREF>Grosz and Sidner, 1986</TREF>, also allowing for reference with implicit devices to entities in the superordinate segments after the subordinated ones have been closed	0	It seems, thus, that thematic structure, like the discourse goals, also imposes structure on the discourse	0	These cases, although not numerous, suggest that a more complex discourse structure is needed for QA interactions than one simply based on the discourse goals	0	0	0
W06-3001	J86-3001	2006	Upon Ahrenberg et al	0	1990 this is given by the discourse goals, rather than the overall goals of the user, as is the case in task-oriented dialogues, <TREF>Grosz and Sidner, 1986</TREF>	0	Following Ahrenberg et al	0	1990, the QA discourse is structured in segments composed by a pair of initiative-response units, like questionanswer, or question-assertion, in the absence of an answer	0	0	0
W99-0208	J86-3001	1999	As antecedents may also be discourse chunks of varying length, these same categories were used to classify such antecedents as predicates of a given topical role thought to be the dominant entity within the discourse chunk	0	The aim of this attribute is to use the often mentioned relationship between topicality and coreference see <TREF>Grosz and Sidner 1986</TREF> for operational purposes	0	This classification does not claim to be the actual key for the modelling of topicality in dialogues from a psycholinguistic point of view	0	It does claim, however, to be a useful tool for the resolution of particularly hard cases of coreference, in which the antecedent is not the nearest syntactically appropriate candidate, as will be shown in section 3	0	0	0
P97-1027	J86-3001	1997	The referring expression to generate is required to be a distinguishing description, that is a description of the entity being referred to, but not to any other object in the current context set	0	A context set is defined as the set of entities the addressee is currently assumed to be attending to this is similar to the set of entities in the focus spaces of the discourse focus stack in Grosz and Sidners theory of discourse structure <REF>Grosz, Sidner, 1986</REF>	0	Moreover, the contrast set or, the set of potential distractors <REF>McDonald, 1981</REF>, is defined to entail all elements of the context set except the intended 206 referent	0	In the scope of some context set, an attribute or a relation applicable to the intended referent can be assigned its discriminatory power, 3 that is a measure similar to the number of potential distractors that can be removed from the contrast set with confidence, because this attribute or relation does not apply to them	0	0	0
P97-1035	J86-3001	1997	:EAC, DR, D :AIA9 SEGcr: S3 SMlCr: S4 G0: I GOALS: AC orrcES: A3u5 0TI/ES: A6U6 Figure 4: Task-defined discourse structure of Agent A dialogue interaction utterances that contribute to the success of the whole dialogue, such as greetings, are tagged with all the attributes	0	Since the structure of a dialogue reflects the structure of the task <REF>Carberry, 1989</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Litman and Allen, 1990</REF>, the tagging of a dialogue by the AVM attributes can be used to generate a hierarchical discourse structure such as that shown in Figure 4 for Dialogue 1 Figure 2	0	For example, segment subdialogue 2 in Figure 4 is about both depart-city DC and arrivalcity AC	0	It contains segments 3 and 4 within it, and consists of utterances U1 U6	0	0	0
P97-1035	J86-3001	1997	Let Agent As repair dialogue strategy for subdialogues repairing depart-city be RA and Agent Bs repair strategy for depart-city be RB	0	Then using the performance equation above, predicted performance for RA is: PerformanceRa  40  71 -78  72  --028 For Agent B, using the appropriate subpart of Table 4 to calculate , assuming that the average number of depart-city repair utterances is 138, and using similar 12This assumption has a sound basis in theories of dialogue structure <REF>Carberry, 1989</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Litman and Allen, 1990</REF>, but should be tested empirically	0	calculations, yields PerformanceRB  40	0	-71 78  -94  045 Thus the results of these experiments predict that when an agent needs to choose between the repair strategy that Agent B uses and the repair strategy that Agent A uses for repairing depart-city, it should use Agent Bs strategy RB, since the performanceRB is predicted to be greater than the performanceRa	0	0	0
C88-1044	J86-3001	1988	Testing computational algorithms against multiple genres of natural discourse is important, especially given the universal scope of current frameworks cf	0	<TREF>Grosz and Sidner 1986</TREF>	0	We have chosen to systematically examine texts from a broad range of genres, which vary in spoken versus written medium, number of participants, degree of pre-planning, and formality of situation	0	These genres include informal conversation, partiallyspontaneous televised discussion, newspaper articles, and planning and technical documents	0	0	0
C88-1044	J86-3001	1988	216 view that deictic expressions signal a change in focus of attention while anaphoric expressions signal focus continuation cf, <REF>Ehlich 1982</REF>; <REF>Bosch 1983</REF>	0	It is this view which most closely reflects the assumptions underlying computationaUy explicit models of focus-constrained discourse processing eg , <REF>Linde 1979</REF>; <REF>Reichman 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	We turn now to a presentation of specific claims about demonstratives which have been made in the literature	0	Focus shift	0	0	0
C88-1044	J86-3001	1988	Similarly, in the current centering paradigm <REF>Grosz, Joshi and Weinstein 1986</REF>, <REF>Brennan, Friedman and Pollard 1987</REF> elements in the set of forward looking centers can also be considered activated	0	At the global level, <REF>Sidner and Grosz 1986</REF> describe a model of discourse structure which indicates currently activated beliefs and intentions at any  given point in a discourse	0	In Focus	0	Elements in focus are those which are most highly activated	0	0	0
C88-1044	J86-3001	1988	These require a sophisticated user model which keeps a record of beliefs and intentions of discourse participants	0	While such a model could be incorporated into existing discourse structure frameworks eg <TREF>Grosz and Sidner 1986</TREF>, no specific proposals to account for shared familiarity have yet been advanced but see <REF>Sparck Jones 1986</REF>	0	Activation	0	An adequate model of activation must isolate that subset of shared entities which is activated at any given point in the discourse	0	0	0
J88-3012	J86-3001	1988	This is not due to principled limits, however, but rather to a shortcoming in the state of the art	0	On the other hand, the users utterances can also be analyzed from another viewpoint, namely incorporating them into a coherent discourse model as described by, eg, <TREF>Grosz and Sidner 1986</TREF>	0	Also, this model can be used during all processing steps from understanding to generating	0	Both user models and discourse models are built up at least partially from the user utterances	0	0	0
J88-3012	J86-3001	1988	Given the above definition of dialog memories, however, there is a difference between the two notions	0	As opposed to Schuster, who defines a discourse model as containing representations of entities, along with their properties and relations they participate in, which corresponds exactly to our dialog memory, I use discourse model according to the framework of <TREF>Grosz and Sidner 1986</TREF>, where a discourse model is the syntactic structure of a dialog	0	One part of it, though, could be identified with the dialog memory, namely the focus space stack	0	The overall discourse model additionally represents the structure of the dialog with the segments and their relations, which is not part of the user model	0	0	0
P98-1065	J86-3001	1998	Approaches that address this problem can be classified in knowledge-based approaches or word-based approaches	0	Knowledge-based systems as Grosz and Sidners 1986 require an extensive manual knowledge engineering effort to create the knowledge base semantic network and/or frames and this is only possible in very limited and well-known domains	0	To overcome this limitation, and to process a large amount of texts, word-based approaches have been developed	0	<REF>Hearst 1997</REF> and <REF>Masson 1995</REF> make use of the word distribution in a text to find a thematic segmentation	0	0	0
P00-1053	J86-3001	2000	When looking back more than four units, the linear model was equally effective	0	Here, we compare VT to stack-based models of discourse structure based on Grosz and Sidners 1986 GS focus spaces eg , <REF>Hahn and Strbe, 1997</REF>; Azzam, et al , 1998	0	In these approaches, discourse segments are pushed on the stack as they are encountered in a linear traversal of the text	0	Before a dominating segment is pushed, subordinate segments that precede it are popped from the stack	0	0	0
P00-1053	J86-3001	2000	In this paper, we outline a theory of referential accessibility called Veins Theory VT	0	We compare VT to stack-based models based on Grosz and Sidners 1986 focus spaces, and show how VT addresses the problem of left satellites, ie, subordinate discourse segments that appear prior to their nuclei dominating segments in the linear text	0	Left-satellites pose a problem for stack-based models, which remove subordinate segments from the stack before pushing a nuclear or dominating segment, thus rendering them inaccessible	0	The percentage of such cases is typically small, which may account for the fact that their treatment has been largely overlooked in the literature, but the phenomenon nonetheless persists in most texts	0	0	0
C98-2150	J86-3001	1998	This paper presents an empirically motivated theory of the discourse focusing function of accent	0	The theory describes for the first time the interacting contributions to accent prediction made by factors related to the local and global attentional status of discourse referents in a discourse model <TREF>Grosz and Sidner, 1986</TREF>	0	The ability of the focusing features to predict accent tor a blind test corpus is examined using machiue learning	0	Because attentional status is a property of referring expressions, a novel approach to accent prediction is proposed to allow for the integration of word-based and constituent-based linguistic features in the models to be learned	0	0	0
C98-2150	J86-3001	1998	<REF>Terken, 1984</REF>; <REF>Hirschberg, 1993</REF>	0	We propose a new theory of the relationship between accent and attention, based on an enriched taxonomy of given/new information status provided by both the LOCAL centering and GLOBAL foCUS stack model attentional state models in Grosz and Sidners discourse modeling theory 1986	0	939 Analysis of a 20-minute spontaneous story-telling monologue t identified separate but interacting contributions of grammatical function, form of referring expression and accentuation 2 in conveying the attentional status of a discourse referent	0	These interactions can be formally expressed in the framework of attentional modeling by the following principles of interpretation:  The LEXICAL FORM OF A REFERRING EXPRESSION indicates the level of attentional processing, ie, pronouns involve local focusing while full lexical forms involve global focusing <REF>Grosz et al, 1995</REF>	0	0	0
W01-0814	J86-3001	2001	Preference 22 If the gap of the relative clause is not associated with the nominative case, the gap filler is preferred to be topicalized	0	54 Anaphora and ellipsis Several works have explored the relation between rhetorical structure and reference in English <REF>Fox, 1987</REF>; <REF>Cristea et al , 2000</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al , 1995</REF>	0	Japanese reference, on the other hand, has been studied from a different perspective, being associated mainly with the linear nature of texts as in the centering theory <REF>Kameyama, 1986</REF>; <REF>Walker et al , 1994</REF>	0	Considering that choice of referring expressions is in itself a quite large issue, we have been exploring it separately from this paraphrase-based exploration <REF>Hashimoto, 2001</REF>	0	0	0
W04-0203	J86-3001	2004	For both aspects of discourse relations, it is the fact that the non-canonical order marks part of the utterances information as salient or discourseold that assists these inferences	0	21 Syntax of discourse relations One substructure of a coherent discourse structure is its attentional structure, which can be modeled as a stack of focus spaces <TREF>Grosz and Sidner, 1986</TREF>	0	Each segment in the discourse tree has a corresponding focus space containing the currently salient discourse entities	0	When a segment begins, its focus space is pushed onto the stack on top of any other incomplete segments spaces	0	0	0
W04-0203	J86-3001	2004	2 Additional meaning of non-canonical syntax: discourse relations The meaning of a multi-utterance text is composed not only of the meaning of each individual utterance but also of the relations holding between the utterances	0	These relations have syntactic aspects, such that single utterances can be grouped together and combined into segments recursively and are often modeled as a hierarchical tree structure <TREF>Grosz and Sidner, 1986</TREF>; <REF>Webber et al , 1999</REF>	0	Discourse relations may also have a semantic or meaning component; this property, when treated in the literature, is often referred to as coherence, subject matter, or rhetorical relations <REF>Kehler, 2002</REF>; <REF>Halliday, 1985</REF>; <REF>Mann and Thompson, 1988</REF>	0	The use of an utterance with non-canonical word order helps hearers make inferences about both the syntactic and semantic properties of discourse relations between the utterance and the rest of the discourse	0	0	0
C00-2130	J86-3001	2000	See <REF>Vieira, 1998</REF> for a discussion of tile other heuristics used by the sy> tonl	0	Segmentalion In l i IE-spans limited MI,NTS t1131 lllay general, discourse entities have to pramatical ly delermined,Slit; be nested see, eg, <REF>Rcichman, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Fox, 1987</REF>	0	Eg, in our corpus we found that about 10 of direct analhoric detinite descriptions have more than one possible antecedent if segmentalion is nol taken into account <REF>Vieira and Poesio, 1999</REF>	0	Recognizing the hierarchical structure of segments in a text is, howevm; still pretty umch an open problem, kS it involves reasoning about intentions; 2 better results have been achieved on the simpler task of chtlnking the text into approximate segments, generally by means of lexical density measures <REF>Hearst, 1997</REF> In fact, the lnethods Io limit the lifespan of discourse entity we considered for our system were even simplel: One type of heuristics we looked at are window-based techniques, ie, considering as potential antecedents only the discourse entities within fixed-size windows of previous sentences, allowing however for some discourse entities to take a longer life span: we call this method LOOSE SEGMENTATION	0	0	0
C04-1075	J86-3001	2004	Approaches to coreference resolution usually rely on a set of factors which include gender and number agreements, c-command constraints, semantic consistency, syntactic parallelism, semantic parallelism, salience, proximity, etc These factors can be either constraints which discard invalid ones from the set of possible candidates such as gender and number agreements, c-command constraints, semantic consistency, or preferences which gives more preference to certain candidates and less to others such as syntactic parallelism, semantic parallelism, salience, proximity	0	While a number of approaches use a similar set of factors, the computational strategies the way antecedents are determined, ie the algorithm and formula for assigning antecedents may differ, ie from simple co-occurrence rules <REF>Dagan and Itai 1990</REF> to decision trees <REF>Soon, Ng and Lim 2001</REF>; <REF>Ng and Cardie 2002</REF></REF> to pattern induced rules <REF>Ng and Cardie 2002</REF></REF> to centering algorithms <TREF>Grosz and Sidner 1986</TREF>; <REF>Brennan, Friedman and Pollard 1987</REF>; <REF>Strube 1998</REF>; <REF>Tetreault 2001</REF>	0	This paper proposes a simple constraint-based multi-agent system to coreference resolution of general noun phrases in unrestricted English text	0	For a given anaphor and all the preceding referring expressions as the antecedent candidates, a common constraint agent is first presented to filter out invalid antecedent candidates using various kinds of general knowledge	0	0	0
J02-3003	J86-3001	2002	2 Issues and Insights in Anaphora Resolution 21 The BFP Algorithm Brennan, Walker-<REF>Friedman, and Pollard 1987</REF> were the first to use the centering model as the basis for an anaphora resolution algorithm	0	The centering model <TREF>Grosz and Sidner 1986</TREF>; <REF>Grosz, Joshi, and Weinstein 1983</REF> makes the following assumptions: 1	0	A discourse segment consists of a sequence of utterances, U 1,, U n 2	0	For each utterance, a ranked list of evoked discourse entities is constructed, designated as the Cf list	0	0	0
J02-3003	J86-3001	2002	The semantic/pragmatic focusing account runs into the type of problem demonstrated in 4, where the preferred interpretation for he is John, that is, the structural subject, independent of semantic/pragmatic factors	0	3 In such discourses it seems that a structural account is at play in the sense of Grosz and Sidner 1986	0	4 a John criticized Bill	0	b Next, he insulted Susan	0	0	0
J02-3003	J86-3001	2002	3	0	The Proposal: Aposynthesis 31 Outline of the Discourse Model We assume that the discourse is organized hierarchically in linear and embedded segments as specified in <TREF>Grosz and Sidner 1986</TREF>	0	We also adopt the centering view of local-discourse coherence to model topic continuity in discourse	0	According to the centering model each segment consists of a sequence of utterances	0	0	0
W04-2504	J86-3001	2004	Discourse transitions also correspond to the intentional, informational, and presentational perspectives of discourse	0	Intentional transitions are closely related to Grosz and Sidners dominance and satisfaction precedence relations, which are more relevant to plan-based discourse <TREF>Grosz and Sidner, 1986</TREF>	0	Here we focus on informational transitions and presentational transitions that are more relevant to QA systems since they are targeted for information exchange	0	Informational transitions are mainly centered around Topics of questions	0	0	0
W04-2504	J86-3001	2004	In a fully interactive question answering environment, instead of asking questions, a user may need to reply to a clarification question prompted by the system or may need to simply ask for a confirmation	0	Therefore, it is important to capture the intention from the user <TREF>Grosz and Sidner 1986</TREF>	0	The informational perspective relates to the information content of a question, in particular, the topic and the focus based on the semantics of the content	0	In addition to the intentional and informational aspects, there is also a presentational aspect of discourse that relates to both the input modality ie , questions and the output modality ie , answers	0	0	0
P97-1011	J86-3001	1997	Discourse cues are words or phrases, such as because, first, and although, that mark structural and semantic relationships between discourse entities	0	They play a crucial role in many discourse processing tasks, including plan recognition <REF>Litman and Allen, 1987</REF>, text comprehension <REF>Cohen, 1984</REF>; <REF>Hobbs, 1985</REF>; <REF>Mann and Thompson, 1986</REF>; Reichman-<REF>Adar, 1984</REF>, and anaphora resolution <TREF>Grosz and Sidner, 1986</TREF>	0	Moreover, research in reading comprehension indicates that felicitous use of cues improves comprehension and recall <REF>Goldman, 1988</REF>, but that their indiscriminate use may have detrimental effects on recall <REF>Millis, Graesser, and Haberlandt, 1993</REF>	0	Our goal is to identify general strategies for cue usage that can be implemented for automatic text generation	0	0	0
P97-1011	J86-3001	1997	1 RDA is a scheme devised for analyzing tutorial explanations in the domain of electronics troubleshooting	0	It synthesizes ideas from <TREF>Grosz and Sidner, 1986</TREF> and from RST <REF>Mann and Thompson, 1988</REF>	0	Coders use RDA to exhaustively analyze each explanation in the corpus, ie, every word in each explanation belongs to exactly one element in the analysis	0	An explanation may consist of multiple segments	0	0	0
P97-1011	J86-3001	1997	Other hypotheses about cue usage derive from work on discourse coherence and structure	0	Previous research <REF>Hobbs, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Schiffrin, 1987</REF>; <REF>Mann and Thompson, 1988</REF>; <REF>Elhadad and McKeown, 1990</REF>, which has been largely descriptive, suggests factors such as structural features of the discourse eg , level of embedding and segment complexity, intentional and informational relations in that structure, ordering of relata, and syntactic form of discourse constituents	0	Moser and Moore 1995; 1997 coded a corpus of naturally occurring tutorial explanations for the range of features identified in prior work	0	Because they were also interested in the contrast between occurrence and non-occurrence of cues, they exhaustively coded for all of the factors thought to contribute to cue usage in all of the text	0	0	0
A00-1005	J86-3001	2000	Although these systems have been quite successful, they use detailed models of the domain and therefore cannot be used for diverse applications such as the ones required for customer service centers	0	Other related work on dialogue include <REF>Carberry, 1990</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Reichman, 1981</REF>	0	2	0	PartslD: A System for Identification of Parts for Medical Systems Initially, we were approached by the medical systems business of our company for help in reducing the number of calls handled by human operators at their call center	0	0	0
N07-1003	J86-3001	2007	Block b24 is an interruption segment in which conversants switched their conversation to the interruption game	0	No claim is made that the game and card blocks are discourse segments according to Grosz and Sidners definition 1986	0	4 Defining Initiative Conflicts An initiative conflict occurs when a conversants attempt to show initiative fails because someone else is showing initiative at the same time	0	<REF>Following Whittaker and Stenton 1988</REF>, we use utterance tags to determine whether an utterance shows initiative: forward functions show initiative while others do not	0	0	0
N07-1003	J86-3001	2007	To determine whether a group of utterances form a discourse segment, we took into account whether there exists a shared goal introduced by one of the conversants cf	0	<TREF>Grosz and Sidner, 1986</TREF>	0	32 The MTD Corpus The MTD corpus contains dialogues in which a pair of participants play two games via conversation: an ongoing 18 game that takes a relatively long time to finish and an interruption game that can be done in a couple turns but has a time constraint	0	Both games are done on computers	0	0	0
H05-1031	J86-3001	2005	Our hypothesis is that features capturing the frequency and syntactic and lexical forms of references are suf cient to infer the desired cognitive model	0	Intuitively, pronominalization indicates that an entity was particularly salient at a speci c point of the discourse, as has been widely discussed in attentional status and centering literature <TREF>Grosz and Sidner, 1986</TREF>; <REF>Gordon et al , 1993</REF>	0	Modi ed noun phrases with apposition, relative clauses or premodi cation can also signal different status	0	In addition to the syntactic form features, we used two months worth of news articles collected over the web and independent of the DUC collection we use in our experiments here to collect unigram and bigram lexical models of rst mentions of people	0	0	0
J98-4001	J86-3001	1998	The use of Contributes here refers to a relation between actions	0	<TREF>Grosz and Sidner 1986</TREF> also describe a contributes relation between DSPs that is the inverse of the dominates relation	0	In addition, we have been using contributes informally to refer to the inverse of a subsidiary relationship between plans	0	546 Lochbaum A Collaborative Planning Model A recipe for c is comprised of a set of immediate constituent acts ill,,,fin and constraints pl,, pro	0	0	0
J98-4001	J86-3001	1998	712 Recognizing Relationships between Discourse Segments	0	Once an OCP recognizes the initiation of a new discourse segment, it must determine the relationship of that segments DSP to the other DSPs underlying the discourse <TREF>Grosz and Sidner 1986</TREF>	0	In our model, relationships between SharedPlans provide the basis for determining the corresponding relationships between DSPs	0	An OCP must determine how the SharedPlan used to model a segments DSP is related to the other SharedPlans underlying the discourse	0	0	0
J98-4001	J86-3001	1998	Because each utterance of a discourse segment contributes some information towards the purpose of that segment, the segments DSP may not be completely determined until the last utterance of the segment	0	However, as <TREF>Grosz and Sidner 1986</TREF> have argued, the OCP must be able to recognize initially at least a generalization of the DSP so that the proper moves of attentional state can be made	0	Although CDRA provides a limited method of recognizing new segments and their purposes, it does conform to this aspect of Grosz and Sidners theory	0	In particular, the initial purpose of a segment, as recognized by CDRA, is quite generally specified; it consists only of the intention that the agents form a SharedPlan	0	0	0
J98-4001	J86-3001	1998	71 Recognizing Intentional Structure 711 Recognizing Discourse Segments and their Purposes	0	In their paper on discourse structure, Grosz and Sidner give several examples of the types of intentions that could serve as DSPs <TREF>Grosz and Sidner 1986</TREF>, 179: 1	0	Intend that some 2	0	Intend that some 3	0	0	0
J98-4001	J86-3001	1998	This intention is held by the agent who initiates the segment	0	<REF>Following Grosz and Sidner 1986</REF>, we will refer to that agent as the ICP for initiating conversational participant; the other participant is the OCP	0	DSPs are thus represented as intentions of the form IntThICP, FSPICP, OCP, fl in our model	0	Relationships between DSPs derive from relationships between the corresponding SharedPlans	0	0	0
J98-4001	J86-3001	1998	DSPs that do not involve SharedPlans would thus seem to present a problem for our model; however, many such DSPs may still be explained in terms of SharedPlans	0	For example, consider DSPs of the form Intend that some agent intend to perform some physical task, as proposed by Grosz and Sidner 1986, 179	0	It is possible to explain this type of DSP in terms of the IntTo requirement of the FSP definition Clause 2a in Figure 5	0	According to that requirement, each of the single-agent acts in the agents recipe must be intended by one of the two collaborating agents	0	0	0
J98-4001	J86-3001	1998	Before presenting these analyses, however, we first introduce some terminology that will be used throughout the paper	0	A discourse is composed of discourse segments much as a sentence is composed of constituent phrases <TREF>Grosz and Sidner 1986</TREF>	0	The segmental structure of the sample dialogues is indicated by the bold rule grouping utterances into segments	0	Whereas the term discourse segment applies to all types of discourse, the term subdialogue is reserved for segments that occur within dialogues	0	0	0
J98-4001	J86-3001	1998	If additionally the OCP is able to ascribe the various mental attitudes missing from the SharedPlan that corresponds to that segment, then the OCP has further evidence for the segment boundary	0	These mental attitudes may be ascribed on the basis of those of the OCPs beliefs that are in accord with the mental attitudes comprising the SharedPlan <REF>Pollack 1986a</REF>; <REF>Grosz and Sidner 1990</REF>	0	712 Recognizing Relationships between Discourse Segments	0	Once an OCP recognizes the initiation of a new discourse segment, it must determine the relationship of that segments DSP to the other DSPs underlying the discourse <TREF>Grosz and Sidner 1986</TREF>	0	0	0
J98-4001	J86-3001	1998	In our model, a segments focus space contains a DSP of the form IntThICP, FSP ICP, OCP, fl	0	The operations on the focus space stack depend upon subsidiary rela561 Computational Linguistics Volume 24, Number 4 tionships between SharedPlans in the same way that <TREF>Grosz and Sidner 1986</TREF> describe the operations as depending upon DSP relationships	0	As each SharedPlan corresponding to a discourse segment is completed, the segments focus space is popped from the stack	0	Only those SharedPlans in some space on the stack are candidates for subsidiary relationships	0	0	0
J98-4001	J86-3001	1998	In each case, an agent must recognize both the purpose of an embedded subdialogue and the relationship of that purpose to the purposes associated with the preceding discourse	0	These purposes and their interrelationships form the intentional structure of the discourse <TREF>Grosz and Sidner 1986</TREF>	0	In this paper, we present a computational model for recognizing intentional structure and utilizing it in discourse processing	0	Our model is based on the collaborative planning framework of SharedPlans <REF>Grosz and Sidner 1990</REF>; <REF>Lochbaum, Grosz, and Sidner 1990</REF>; <REF>Grosz and Kraus 1993, 1996</REF>	0	0	0
J98-4001	J86-3001	1998	4	0	Grosz and Sidners Theory of Discourse Structure According to Grosz and Sidners 1986 theory, discourse structure is comprised of three interrelated components: a linguistic structure, an intentional structure, and an attentional state	0	The linguistic structure is a structure that is imposed on the utterances themselves; it consists of discourse segments and embedding relationships among them	0	The linguistic structure of the sample dialogues in Section 1 is indicated by the bold rule grouping utterances into segments	0	0	0
J98-4001	J86-3001	1998	agent know some property of an object	0	Intentions such as these, as well as segment beginnings and endings, might be recognized on the basis of linguistic markers, utterance-level intentions, or knowledge about actions and objects in the domain of discourse <TREF>Grosz and Sidner 1986</TREF>	0	In our model, DSPs take the form IntThICP, FSPICP, OCP,fl	0	This type of DSP addresses several problems with the above examples--problems that motivated Grosz and Sidners 1990 subsequent work on SharedPlans--namely the case of one agent intending another to do something and the so-called master/slave assumption	0	0	0
J98-4001	J86-3001	1998	In this paper, we have presented a SharedPlan model for recognizing DSPs and their interrelationships	0	We now show that this model satisfies the requirements set out by Grosz and Sidners 1986 theory of discourse structure	0	We first discuss the process by which intentional structure is recognized	0	Next, we discuss the way in which intentional structure interacts with the attentional state component of discourse structure	0	0	0
J98-4001	J86-3001	1998	The agent must determine whether the utterance begins a new segment of the discourse, completes the current segment, or contributes to it	0	The intentional structure of the discourse, comprised of discourse segment purposes and their interrelationships, plays a central role in this process <TREF>Grosz and Sidner 1986</TREF>	0	In this paper, we provide a computational model for recognizing intentional structure and utilizing it in discourse processing	0	The model is based on the collaborative planning framework of SharedPlans <REF>Grosz and Kraus 1996</REF>	0	0	0
J98-4001	J86-3001	1998	The use of the SharedPlan stack S in the augmentation process of Figure 13 reflects the operations of the focus space stack	0	73 The Contextual Role of Intentional Structure An utterance of a discourse can either begin a new segment of the discourse, complete the current segment, or contribute to it <TREF>Grosz and Sidner 1986</TREF>	0	Each of these possibilities is modeled by a separate case within the augmentation process given in Figure 13	0	The initiation and completion of discourse segments was discussed in Section 71	0	0	0
J98-4001	J86-3001	1998	People engage in dialogues for a reason	0	Their intentions guide their behavior and their conversational partners recognition of those intentions aids in the latters understanding of their utterances <REF>Grice 1969</REF>; <REF>Sidner 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	In this paper, we present a computational model for recognizing the intentional structure of a discourse and utilizing it in discourse processing	0	The embedded subdialogues in Figures 1 through 3 illustrate a variety of intentions that a person or computer system must recognize to respond effectively to its conversational partner	0	0	0
J98-4001	J86-3001	1998	Reasoning with Intentional Structure Intentional structure plays a central role in discourse processing	0	For each utterance of a discourse, an agent must determine whether the utterance begins a new segment of the discourse, completes the current segment, or contributes to it <TREF>Grosz and Sidner 1986</TREF>	0	If the utterance begins a new segment of the discourse, the agent must recognize the DSP of that segment, as well as its relationship to the other DSPs underlying the discourse and currently in focus	0	If the utterance completes the current segment, the agent must come to believe that the DSP of that segment has been satisfied	0	0	0
J00-3003	J86-3001	2000	In addition, we should model more of the nonlocal aspects of discourse structure, despite our negative results so far	0	For example, a context-free discourse grammar could potentially account for the nested structures proposed in <TREF>Grosz and Sidner 1986</TREF>	0	1 The standard n-gram models for DA discrimination with lexical cues are probably suboptimal for this task, simply because they are trained in the maximum likelihood framework, without explicitly optimizing discrimination between DA types	0	This may be overcome by using discriminative training procedures <REF>Warnke et al 1999</REF>; <REF>Ohler, Harbeck, and Niemann 1999</REF>	0	0	0
J94-2004	J86-3001	1994	Examples are evidently, seemingly, must have, appear to be, as if, as though, and look, as in He looked like he might cry 63 Hedges, eg, adverbs such as more or less and sort of when used as modifiers of adjectives and adverbs, as in It was more or less green, or as adverbials <REF>Quirk et al 1985</REF></REF>, as in The man more or less held a large stretch of the border 64 Evidentials that address expectations 641 Signal that expectations have been met, such as of course when used as an emphasizer subjunct <REF>Quirk et al 1985</REF></REF> as in John of course sat down 642 Signal that expectations have not been met	0	Examples are adverbs such as just, merely, and only when used as attitude diminishers <REF>Quirk et al 1985</REF></REF>, as in He just sat and drank it was expected that he would do something more than sit and drink 7 Adverbials that are conjuncts, which connect units of discourse <REF>Quirk et al 1985</REF></REF> ie , cue phrases; <REF>Reichman 1985</REF>, <TREF>Grosz and Sidner 1986</TREF>, <REF>Cohen 1987</REF>	0	Examples are first, in addition, for instance, on the other hand, after all, anyway, and yet as in Yet, they were the pride of the family 8 Conditional clauses 9 Comparative like, as in They followed her like acolytes behind a goddess 10 Habitual sentences, such as Gus himself often joked about it 11 The past perfective, but only in the main verb phrase 12 The progressive, but only in the main verb phrase the progressive, can typically serve only to continue a characters POV and only within a paragraph see Ehrlich 1987 for an analysis of why this is so for the progressive; 2 stronger ones can continue a characters POV after a paragraph break, or resume a characters POV within a paragraph; 3 still stronger ones, such as evidentials and sentence fragments, can resume the last subjective characters POV or initiate the last active characters just as long as they are expected subjective characters; and 4 the strongest subjective elements, such as exclamations and questions, are always subjective, even when there is not an expected subjective character to whom to attribute the 259 Computational Linguistics Volume 20, Number 2 sentence	0	The sets of text situations corresponding to 1-4 are: lts 2ts 3ts 4ts continuing-subjective broken-subjective, interrupted-subjective presubjective-active, postsubjective-nonactive, postsubjective-active presubjective-nonactive Expectations for a subjective sentence are strongest in situation lts and weakest in situation 4ts, so the algorithm takes even the weakest potential subjective elements to be subjective in lts, but only the strongest ones to be subjective in 4ts	0	0	0
W00-0301	J86-3001	2000	1 Collaborative Agents The underlying premise of the Collageff M for Collaborative agent project is that software agents, when they interact with people, should be governed by the same principles that govern human-to-human collaboration	0	To determine the principles governing human collaboration, we have relied on research in computational linguistics on collaborative discourse, specifically within the SharedPlan framework of Grosz and Sidner 1986, 1990 <REF>Grosz and Kraus, 1996</REF>, <REF>Lochbaum, 1998</REF>	0	This work has provided us with a computationally-specified theory that has been empirically validated across a range of User Agent communicate l Application Figure 1: Collaborative interface agent paradigm	0	human tasks	0	0	0
W97-1201	J86-3001	1997	The latter work examines the placement of accents, as constrained by the interaction of discourse, surface structure and lexical form	0	Pitch accent placement on pronouns as well as on explicit forms in the subject position motivate theory that describes new and givenness in terms of a hierarchical discourse structure <TREF>Grosz and Sidner 1986</TREF>	0	Again, the implications of this theoretical framework can be extracted as features for generating conditional probabilities of prosodic events, with reference to the theory	0	One such feature could be an annotation of discourse segmentation in the input text	0	0	0
W04-2906	J86-3001	2004	Formal written discourse signals a hierarchical, tree-based discourse structure explicitly by the division of the text into chapters, sections, paragraphs, and sentences	0	This structure, in turn, identi es domains for interpretation; many systems for anaphora resolution rely on some notion of locality <TREF>Grosz and Sidner, 1986</TREF>	0	Similarly, this structure represents topical organization, and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic	0	Unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse	0	0	0
W90-0118	J86-3001	1990	Finally, relations such as Topic and Conclusion appear to be due to conventions governing writing style which direct focus of attention	0	<TREF>Grosz  Sidner 1986</TREF> made similar criticisms from the standpoint of characterizing discourse coherence	0	They suggested that each rhetorical relation combines domain information with certain general relations between propositions, between actions, and between intentions	0	Implicit Features Unaccounted For	0	0	0
W08-1103	J86-3001	2008	We anticipate that the user will ask follow-up questions after receiving the initial summary	0	Therefore, it is appropriate to close the initial summary with propositions from the computational class so that the whole graphic is in the users focus of attention <TREF>Grosz and Sidner, 1986</TREF>	0	Thus we hypothesize that a good ordering of propositions in the initial summary is the message-related class, the specific class, and finally the computational class	0	This produces a partial ordering of the propositions to be included in the summary	0	0	0
W03-2114	J86-3001	2003	 been implemented	0	4 Top-Level Context Management	0	 The approach to dialogue modeling we have imple-	0	 mented is based on the theory of dialogue games	0	0	0
C00-1083	J86-3001	2000	Therefore, these studies are not concerned with dlanging the content of the discourse to match the users view	0	In some studies of dialogue management <REF>Rich and Sidner, 1998</REF>; Stent et M , 1999, the state of the dialogue is represented using Grosz and Sidners framework <TREF>Grosz and Sidner, 1986</TREF>	0	We also adopt this theory in our dialogue management mechanism	0	However, they do not keep track of the users viewpoint information as a part of the dialogue state because they were not concerned with dialogue management in virtual environments	0	0	0
W98-0317	J86-3001	1998	Therefore, for dialogue generation, we must identify the determining factors of organization cue phrases and select the cue phrases appropriately	0	In previous studies that have investigated the relationship between cue phrases and the types of structural change eg pop, push, the taxonomies of cue phrases have been presented <TREF>Grosz and Sidner, 1986</TREF>; <REF>Cohen, 1984</REF>; <REF>Schiffrin, 1987</REF>	0	These taxonomies are, however, not sufficient for generation because the correspondence between cue phrase and structural change is many-to-many quite often	0	For example, now,and, and next are all classified as the category signaling push in attentional state	0	0	0
W98-0317	J86-3001	1998	32 Annotation of discourse structure As the basis for examining the relationship between cue phrase and dialogue structure, discourse segment boundary and the level of embedding of the segments were annotated in each dialogue	0	We define discourse segment or simply segment as chunks of utterances that have a coherent goal <TREF>Grosz and Sidner, 1986</TREF>; <REF>Nakatani et al , 1995</REF>; <REF>Passonneau and Litman, 1997</REF>	0	The annotation of hierarchical relations among segments was based on <REF>Nakatani et al , 1995</REF>	0	Figure 1 shows an example from the annotated dialogue corpus	0	0	0
W98-0317	J86-3001	1998	2Task structure: Information that estimates the complexity of succeeding dialogue	0	3<REF>Clark 1997</REF> presents a term discourse topic as concept equivalent to focus space in <TREF>Grosz and Sidner, 1986</TREF>, and call their transition discourse transition	0	For example, push is defied as the transition to the sub topic, and next is defined as the transition to the same level proceeding topic	0	102 factor Discourse structure Task structure Dialogue structure Table 1: The learning features feature name Embedding Fla:e l,lace2 Hes-cue les-cue2 D-trans T-hmraxchy ubgoal Fre-exchange Fs-cue values integer mteger mteger nil, ord, Oh, con, chord, conord, conch, other nil, ord, C1, Cou, cnord conord, conch, other pop, push, next, m-pop, A integer mteger conf, req, inf, quest, ui-conf, ui-req, tti-inf, ui-quest, NA nil, oral, ch, con, chord, conord, conch, other Task-hierarchy T-hierarchy The number of goal-subgoal relations from the current goal to primitive actions	0	0	0
W98-0317	J86-3001	1998	Cue phrases are words and phrases, such as first, and, now, that connect discourse spans and add structure to the discourse both in text and dialogue	0	They signal topic shifts and changes in attentional state <TREF>Grosz and Sidner, 1986</TREF> as well as expressing the relation between the individual units of discourse <REF>Moore, 1995</REF>; R<REF>Ssner and Stede, 1992</REF>	0	In this study, we focus on the former kind of cue phrases, organization cue phrases that signal the structural organization of discourse	0	In instruction dialogue, the organization cue phrases play a crucial role in controlling dialogue and making the material easy to understand	0	0	0
W98-0317	J86-3001	1998	There are 31 cue phrases that occur more than five times	0	As the result of classifying these 31 cue phrases based on the classification of Japanese connectives <REF>Ichikawa, 1978</REF>; <REF>Moriyama, 1997</REF> and cue phrase classification in Enghsh <TREF>Grosz and Sidner, 1986</TREF>; <REF>Cohen, 1984</REF>; <REF>Knott and Dale, 1994</REF>; <REF>Moser and Moore, 1995b</REF>, 20 cue phrases, which occurred total of 848 times, were classified into three classes: changeover, such as soredeha, deha now, now then in English, conjunctive, such as sorede, de and, and then, and ordinal, such as mazu, tsugini first, next	0	Besides these simple cue phrases, there are composite cue phrases such as soredeha-tsugini now first	0	Note that meaning and the usage of each of these Japanese cue phrases does not completely correspond to those of the English words and phrases in parentheses	0	0	0
W98-0317	J86-3001	1998	The reason that we examine these three factors is as follows	0	First, discourse structure is indispensable for selecting cue phrase as claimed in previous studies <TREF>Grosz and Sidner, 1986</TREF>; <REF>Cohen, 1984</REF>; <REF>Eugenio et al , 1997</REF>	0	We examine some features concerning this factor such as the global structure of discourse and structural shifts in discourse	0	Second, while the discourse structure provides information about the preceding discourse, <REF>Cawsey 1993</REF> claimed that information about the succeeding discourse eg , length and complexity is also necessary in order to select cue phrases dynamically in dialogue systems	0	0	0
C98-2130	J86-3001	1998	2	0	Broadcast News Analysis Human communication is characterized by distinct discourse structure <TREF>Grosz and Sidner 1986</TREF> which is used lbr a variety of purposes including managing interaction between participants, mitigating limited attention, and signaling topic shifts	0	In processing genre such as technical or journalistic texts, programs can take advantage of explicit discourse cues eg, the first, the most important to perform tasks such as summarization <REF>Paice 1981</REF>	0	Our initial inability to segment topics in closed caption news text using thesaurus based subject assessments <REF>Liddy and Myaeng 1992</REF> motivated an investigation of explicit turn taking signals eg, anchor to reporter handoff	0	0	0
J99-1001	J86-3001	1999	Our recognition algorithm captures the kinds of evidence identified in Section 3: 1 evidence provided by world knowledge, contextual knowledge, and the surface form of the utterance indicating that the applicability conditions for an e-action are satisfied, and 2 linguistic evidence from clue words suggesting a generic discourse action	0	<TREF>Grosz and Sidner 1986</TREF> claim that when evidence is available from one source, less evidence should be required from others	0	Thus, if there is evidence indicating that the applicability conditions for a discourse act hold, then less linguistic evidence suggesting the discourse act should be required	0	This is the case for interpreting 9 repeated below as an expression of doubt	0	0	0
J99-1001	J86-3001	1999	For example, although it does not generally arise in the kind of interactive dialogues that we are studying, world knowledge in the form of stereotypical beliefs might be used as evidence that a speaker believes that a hearer has some belief in the doubted proposition Pdoubt 4	0	The Process <REF>Model Grosz and Sidner 1986</REF> claim that a robust model of understanding must use multiple knowledge sources in order to recognize the complex relationships that utterances have to one another	0	We have developed an algorithm that combines linguistic, world, and contextual knowledge, such as that identified in Section 3, in order to recognize complex discourse acts, including one kind of expression of doubt	0	Linguistic knowledge consists of clue words and the surface form of the utterance; world knowledge includes a set of stereotypical beliefs that users generally hold and recipes for performing discourse acts; and contextual knowledge consists of a model of the users beliefs 8 Carberry and Lambert Modeling Negotiation Subdialogues acquired from the preceding dialogue, the current structure of the discourse, the existing focus of attention that aspect of the task on which the participants attention is currently centered, and the relative salience degree of prominence of propositions in the discourse	0	0	0
J99-1001	J86-3001	1999	Thus, as the conversation continues, only one proposition would remain open for rejection: the proposition that Dr Smith is teaching CS360	0	This claim is supported by a combination of 1 the stack paradigm <REF>Polanyi 1986</REF>; <REF>Reichman 1978</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Litman and Allen 1987</REF>, which treats topic structure as following a stack-like discipline; 2 focusing heuristics <REF>McKeown 1983</REF> that suggest that if a speaker has more to say about a topic, then he should do so before moving back to a topic deeper on the stack; and 3 the notion of implicit acceptance discussed in Section 46 that argues that passing up the opportunity to reject an assertion in a collaborative dialogue communicates acceptance of it	0	Second, contextual knowledge orders propositions according to their relative salience in the current dialogue	0	This salience can be used to arbitrate among discourse acts for which there is equivalent evidence	0	0	0
J99-1001	J86-3001	1999	7	0	Other Related Work 71 Grosz and Sidners Theory of Discourse <REF>Processing Grosz and Sidner 1986</REF> postulated a theory of discourse structure that included linguistic, intentional, and attentional components, and they argued that the dominance and satisfaction-precedes relationships between discourse segments must be identified in order to determine discourse structure	0	They also noted three kinds of information that contribute to determining the purposes of discourse segments and their relationship to one another: linguistic markers, utterance-level intentions, and general knowledge about actions and objects	0	<REF>Subsequently Lochbaum 1994</REF> developed an algorithm based on Grosz and Sidners SharedPlan model <REF>Grosz and Sidner 1990</REF> that recognizes discourse segment purposes and discourse structure	0	0	0
J99-1001	J86-3001	1999	31 Linguistic Knowledge 311 Evidence for a Generic Discourse Act	0	A number of researchers <REF>Reichman 1978, 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Polanyi 1986</REF>; <REF>Cohen 1987</REF>; <REF>Hirschberg and Litman 1987</REF>; <REF>Litman and Allen 1987</REF>; <REF>Schiffrin 1987</REF>; <REF>Hinkelman 1989</REF>; <REF>Litman and Hirschberg 1990</REF>; <REF>Knott and Dale 1994</REF>; <REF>Knott and Mellish 1996</REF>; <REF>Marcu 1997</REF> have investigated the use in discourse of special words and phrases such as but, anyway, and by the way	0	They found that these clue words, or discourse markers, have a number of different functions, including indicating the role of an utterance in the dialogue, conveying the relationship between utterances, suggesting shifts in focus of attention, conveying the structure of the discourse, etc Consider again the dialogue shown in Figure 1	0	If EA had followed 7-8 with 9a 9a EA: Isnt Architecture one of our required courses	0	0	0
A92-1010	J86-3001	1992	The satellite is more easily replaced than the nucleus because of the nucleus central role in the thematical progression of the discourse	0	Even though there are some critics questioning the use of rhetorical relations in discourse structure theory <TREF>Grosz and Sidner, 1986</TREF> we use 75 rl /rst-nonvolitional-result :domain el/ existence :domain cl / concept :number mass :process r2/show :saying cl :speechact denial :tense present :range a/ascription :domain c2 / capacity :owned-by p/pres-form :range ex / exceeded :tense present Figure 5 : SPL-Plan for There are concepts that are not shown, because the presentation-forms capacity is exceeded	0	RST relations because they proved to be quite useful when we link portions of information	0	In KOMET/Penman, RST-relations are treated the same way as other relations, eg ascription which we used in the plan shown in Figure 4	0	0	0
J97-1003	J86-3001	1997	7 For example, the words residential and apartment both index the same thesaural category and can thus be considered to be in a coherence relation with one another	0	The chains are used to structure texts according to the attentional/intentional theory of discourse structure <TREF>Grosz and Sidner 1986</TREF> discussed above	0	The extent of the lexical chains is assumed to correspond to the extent of a segment	0	The algorithm also incorporates the notion of chain returns--repetition of terms after a long hiatus--to complete an intention that spans over a digression	0	0	0
J97-1003	J86-3001	1997	32 Relationship to Segmentation in Hierarchical Discourse Models Much of the current work in empirical discourse processing makes use of hierarchical discourse models, and several prominent theories of discourse assume a hierarchical segmentation model	0	Foremost among these are the attentional/intentional structure of <TREF>Grosz and Sidner 1986</TREF> and the Rhetorical Structure Theory of <REF>Mann and Thompson 1987</REF>	0	The building blocks for these theories are phrasal or clausal units, and the targets of the analyses are usually very short texts, typically one to three paragraphs in length	0	5 Many problems in discourse analysis, such as dialogue generation and turntaking <REF>Moore and Pollack 1992</REF>; <REF>Walker and Whittaker 1990</REF>, require fine-grained, hierarchical models that are concerned with utterance-level segmentation	0	0	0
P04-1049	J86-3001	2004	3 Coherence-based summarization revisited This section will discuss in more detail the data structures we used to represent discourse structure, as well as the algorithms used to calculate sentence importance, based on discourse structures	0	31 Representing coherence structures 311 Discourse segments Discourse segments can be defined as nonoverlapping spans of prosodic units <REF>Hirschberg  Nakatani 1996</REF>, intentional units <TREF>Grosz  Sidner 1986</TREF>, phrasal units <REF>Lascarides  Asher 1993</REF>, or sentences <REF>Hobbs 1985</REF>	0	We adopted a sentence unit-based definition of discourse segments for the coherence-based approach that assumes non-tree graphs	0	For the coherence-based approach that assumes trees, we used <REF>Marcu 2000</REF>s more fine-grained definition of discourse segments because we used the discourse trees from Carlson et al	0	0	0
P98-2163	J86-3001	1998	The use of interpersonal relations is predicated mainly on the interests, beliefs, and attitudes of addressee and/or author	0	To deal with this problem, we must incorporate the notion of intentional structure and focus space structure <TREF>Grosz and Sidner, 1986</TREF>	0	Since we have focused on te-linkage in this paper, we need not to consider how clauses are combined	0	However, to detect the discourse structure, we need to extend the method so as to deal with the relations between sentences	0	0	0
P95-1015	J86-3001	1995	Many have argued that discourse has a global structure above the level of individual utterances, and that linguistic phenomena like prosody, cue phrases, and nominal reference are partly conditioned by and reflect this structure cf	0	<REF>Grosz and Hirschberg, 1992</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Hirschberg and Grosz, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Hirschberg and Pierrehumbert, 1986</REF>; <REF>Hobbs, 1979</REF>; <REF>Lascarides and Oberlander, 1992</REF>; <REF>Linde, 1979</REF>; <REF>Mann and Thompson, 1988</REF>; <REF>Polanyi, 1988</REF>; <REF>Reichman, 1985</REF>; <REF>Webber, 1991</REF>	0	However, an obstacle to exploiting the relation between global structure and linguistic devices in natural language systems is that there is too little data about how they constrain one another	0	We have been engaged in a study addressing this gap	0	0	0
P95-1015	J86-3001	1995	Grosz and Hirschbergs work also used the classification and regression tree system CART <REF>Breiman et al , 1984</REF> to automatically construct and evaluate decision trees for classifying aspects of discourse structure from intonational feature values	0	<REF>Morris and Hirst 1991</REF> structured a set of magazine texts using the theory of <TREF>Grosz and Sidner, 1986</TREF>, developed a thesaurus-based lexical cohesion algorithm to segment text, then qualitatively compared their segmentations with the results	0	<REF>Hearst 1994</REF> presented two implemented segmentation algorithms based on term repetition, and compared the boundaries produced to the boundaries marked by at least 3 of 7 subjects, using information retrieval metrics	0	<REF>Kozima 1993</REF> had 16 subjects segment a simplified short story, developed an algorithm based on lexical cohesion, and qualitatively compared the results	0	0	0
P95-1015	J86-3001	1995	2 Discourse Segmentation 21 Related Work Segmentation has played a significant role in much work on discourse	0	The linguistic structure of Grosz and Sidners 1986 tri-partite discourse model consists of multi-utterance segments whose hierarchical relations are isomorphic with intentional structure	0	In other work eg , <REF>Hobbs, 1979</REF>; <REF>Polanyi, 1988</REF>, segmental structure is an artifact of coherence relations among utterances, and few if any specific claims are made regarding segmental structure per se	0	Rhetorical Structure Theory RST <REF>Mann and Thompson, 1988</REF> is another tradition of defining relations among utterances, and informs much work in generation	0	0	0
C96-1001	J86-3001	1996	C96-1001:289	0	Discovering the Sounds of Discourse Structure Extended Abstract Barbara J Grosz Division of Engineering and Applied Sciences Harvard University 33 Oxford Street Cambridge, MA 02138 USA groszeecsharvardedu It is widely accepted that discourses are composed of segments and that the recognition of segment boundaries is essential to a determination of discourse meaning <TREF>Grosz and Sidner, 1986</TREF>	0	Written language has orthographic cues such as section headings, paragraph boundaries, and punctuation which can assist in identifying discourse structure	0	In spoken language, intonational variation provides essential information about disconrse structure	0	0	0
P98-1044	J86-3001	1998	Acknowledgements Our thanks go to Daniel Marcu who pointed some weak parts and provided RST analysis and to the TELR1 program who facilitated the second meeting of the three authors	0	7 We use Grosz and Sidners 1986 terminology here, but note the equivalence of dominance in GS and nucleus/satellite relations in RST pointed out by <REF>Moser and Moore 1996</REF>	0	285 References Brennan, SE, Walker Friedman, M and Pollard, CJ	0	1987	0	0	0
P98-1044	J86-3001	1998	On the other hand, satellites are dependent on their nuclei for their meaning and hence may refer to entities introduced within them	0	The definition of veins formalizes these relationship, s Given the mapping of <REF>Grosz and Sidners 1986</REF> stackbased model of discourse structure to RST structure trees outlined by <REF>Moser and Moore 1996</REF>, the domains of referentiality defined for left-polarized trees using VT are consistent with those defined using the stack-based model eg <REF>Passonneau 1995</REF>, <REF>Hahn and Strtibe 1997</REF>	0	However, in cases where the discourse structure is not left-polarized, VT provides a more natural account of referential accessibility than the stackbased model	0	In non left-polarized trees, at least one satellite precedes its nucleus in the discourse and is therefore its left sibling in the binary discourse tree	0	0	0
P98-1044	J86-3001	1998	As such, our approach differs from Walkers 1996, whose account of referentialit, within the cache memory model does not rely on discourse structure, but rather on cue phrases and matching constraints together 281 with constraints on the size of the cache imposed to reflect the plausible limits of the attentional span	0	Our approach is closer to that of <REF>Passonneau 1995</REF> and <REF>Hahn and Strtibe 1997</REF>, who both use a stack-based model of discourse structure based on Grosz and Sidners 1986 focus spaces	0	Such a model is equivalent to a dynamic processing model of a tree-like structure reflecting the hierarchical nesting of discourse segments, and thus has significant similarities to discourse structure trees produced by RST see <REF>Moser and Moore 1996</REF>	0	However, using the RST notion of nuclearity, we go beyond previous work by revealing a hidden structure in the discourse tree, which we call veins, that enables us to determine the referential accessibility domain for each discourse unit and ultimately to apply CT globally, without extensions to CT or addltional Oata structures	0	0	0
E89-1022	J86-3001	1989	Note that most DRT-based anaphora resolution processes <REF>Kamp 1984</REF>, <REF>Frey  Kamp 1986</REF> by and large follow this line, with a few modifications concerning structural conditions in terms of an accessibility relation	0	But there is also a different perspective whose key notion is the well-established concept of focus see eg in Computational <REF>Linguistics Grosz  Sidner 1986</REF> 3	0	As is shown by psychological experiments an detailed overview is given by <REF>Guindon 1985</REF>, a very limited number of discourse referents are focussed	0	Referents in the focus, which can be described in psychological terms as short term memory see Guindon, are quickly accessed; especially pronouns are normally used to refer to items in the focus and therefore extensive search is mostly unnecessary	0	0	0
W93-0222	J86-3001	1993	lxt has constituent structure both below the level of the clause studied by syntacticians and above the level of the clause studied by those working in discourse	0	One kind of evidence for constituent structure above the clause level is tile pattern of pronominalization eg Grosz  Sidners 1986 attentional structure	0	Others include orthographic markers eg indenting paragraphs and in ton ation	0	Relations, such ms contrast, sequence, causality exist in the text and are directly evidenced by lexical items, such as cue words leichman 1985	0	0	0
P95-1042	J86-3001	1995	This is harder than it might at first seem	0	A closely related though not identical problem is found in recognising boundaries in discourse, and there seems to be little agreement in the literature as to the properties and functions they possess <REF>Morris and Hirst, 1991</REF>, <TREF>Grosz and Sidner, 1986</TREF>	0	Our system is aimed at documents typified by those in the MUC-4 corpus <REF>Sundheim, 1992</REF>	0	These deal with Latin American terrorist incidents, and vary widely in terms of origin, medium and purpose	0	0	0
W00-1014	J86-3001	2000	We will in this paper not consider user task models, only system task models	0	The Dialogue history records the focus of attention <TREF>Grosz and Sidner, 1986</TREF> and contains information about objects, properties, and relations as well as other dialogue information such as speech act information and system task information	0	32 Domain Knowledge Management If a request is fully specified it can be used to retrieve the desired information from a background system	0	This task is seldom discussed in literature on dialogue systems, perhaps because it is considered a rather straight forward task	0	0	0
W06-2302	J86-3001	2006	Fig	0	1 GETARUNS AR algorithm 32 Focussing Revisited Our version of the focussing algorithm follows Sidners proposal Sidner C , 1983; Grosz B , Sidner C , 1986, to use a Focus Stack, a certain Focus Algorithm with Focus movements and data structures to allow for processing simple inferential relations between different linguistic descriptions co-specifying or coreferring to a given entity	0	Our Focus Algorithm is organized as follows: for each utterance, we assert three centers that we call Main, Secondary and the first Potential Topic, which represent the best three referring expressions as they have been weighted in the candidate list used for pronominal binding; then we also keep a list of Potential Topics for the remaining best candidates	0	These three best candidates repositories are renovated at each new utterance, and are used both to resolve pronominal and nominal cospecification and coreference: this is done both in case of strict identity of linguistic description and of non-identity	0	0	0
W93-0230	J86-3001	1993	Coherence relations and intentions In recent years, accounts of discourse structure have been developed in which the notion of discourse Iurpose or intention is pivotal	0	A good example is the work of <TREF>Grosz  Sidner 1986</TREF>, who present their account as antagonistic to the coherence relation approach as advocated in tiffs paper	0	In my view, it is fat more attractive to view such a discourse intention approach as compatille with a coherence relation approach	0	Such a synthesis would account for several major weaknesses of the discourse intention approach: 1 it does not lead to a descriptively adequate analysis, 2 it is psychologically inlplausible and 3 it has hardly any explanatory power	0	0	0
J94-4002	J86-3001	1994	62 Discourse Based Methods Most of the work in this area seeks to formulate general principles of discourse structure and interpretation and to integrate methods of anaphora resolution into a computational model of discourse interpretation and sometimes of generation as well	0	Sidner 1981, 1983, Grosz, Joshi, and Weinstein 1983, 1986, <TREF>Grosz and Sidner 1986</TREF>, 21 The difficulty that RAP encounters with such cases was discussed in Section 41	0	We are experimenting with refinements in RAPs scoring mechanism to improve its performance in these and other cases	0	556 Shalom Lappin and Herbert J Leass An Algorithm for Pronominal Anaphora Resolution <REF>Brennan, Friedman, and Pollard 1987</REF>, and <REF>Webber 1988</REF> present different versions of this approach	0	0	0
J94-4002	J86-3001	1994	It relies on measures of salience derived from syntactic structure and a simple dynamic model of attentional state to select the antecedent noun phrase NP of a pronoun from a list of candidates	0	It does not employ semantic conditions beyond those implicit in grammatical number and gender agreement or real-world knowledge in evaluating candidate antecedents; nor does it model intentional or global discourse structure as in <TREF>Grosz and Sidner 1986</TREF>	0	 School of Oriental and African Studies, University of London, London WCIH OXG, UK	0	E-mail: slappincluslulccacuk Most of the first authors work on this paper was done while he was a Research Staff Member in the Computer Science Department of the IBM TJ Watson Research Center	0	0	0
N04-4039	J86-3001	2004	For instance, gestures frequently occur at episode boundaries	0	Pushing and popping of a discourse segment <TREF>Grosz  Sidner, 1986</TREF> may also affect gesture occurrence	0	Therefore, by integrating a discourse analyzer into the LTM, more general structural discourse information can be used in the model	0	Another important direction is to evaluate the effectiveness of agent gestures in actual human-agent interaction	0	0	0
W93-0239	J86-3001	1993	Detecting such sntences specilic;dly in third-persoil fictiona narrative text was the focus of previous work; sue Wiele 1990	0	Notice that But in 22 is being used to connect clauses, aM not in addition to mark the beginning of a new discourse segment as the term discourse,:gmcnt is used in Grosz  <REF>Sidner 1986</REF>	0	The question we are asking is what clauses are being connected by But in 2	0	Under the reading described above, the ibllowiug are the clauses participatiug in the relation: Mary had never leen introduced to Sam	0	0	0
W04-1002	J86-3001	2004	This is the case for many graphics appearing in newspapers, such as the graphic shown in Figure 1	0	On the other hand, when an article is comprised of text and graphics, the graphic generally expands on the text and contributes to the discourse purpose <TREF>Grosz and Sidner, 1986</TREF> of the article	0	For example, Figure 2 illustrates a graphic from Newsweek showing that the income of black women has risen dramatically over the last decade and has reached the level of white women	0	Although this information is not conveyed elsewhere in the article, it contributes to the overall communicative intention of this portion of the article  namely, that there has been a monumental shifting of the sands with regard to the achievements of black women	0	0	0
W04-0714	J86-3001	2004	In the last section the conclusions are made	0	2 Centering Model In the centering theory <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al, 1995</REF>; <REF>Walker et al , 1994</REF>; <REF>Strube and Hahn, 1996</REF>, the attentional state was identified as a basic component of discourse structure that consisted of two levels of focusing: global and local	0	For Grosz and Sidner, the centering theory provided a model for monitoring local focus and yielded the centering model which was designed to account for the difference in the perceived coherence of discourses	0	In the centering model, each utterance U in a discourse segment has two structures associated with it, called forwardlooking centers, C f U, and backward-looking center, C b U	0	0	0
J89-3002	J86-3001	1989	This section will illustrate only the contribution of naive semantics and will not delve into the complex problem of the interactions among the several sources of information	0	<TREF>Grosz and Sidner 1986</TREF> argue that coherence relations are not a useful analytical tool because no clear, closed set of them has been discovered	0	However, there is ample psycholinguistic evidence that in constructing the interpretation of a text, and in recalling what it said, coherence relations are inferred and used by readers <REF>Rickheit and Strohner 1985</REF>	0	In terms of computational linguistics, coherence relations are useful for text summarization and relevance reasoning	0	0	0
J89-3002	J86-3001	1989	I dont know Inherent y Figure 3	0	The Query System 5 NAIVE SEMANTICS AND DISCOURSE PHENOMENA 12 Most computational treatments of discourse phenomena acknowledge the role of world knowledge in anaphora resolution, temporal reasoning, and causal reasoning <REF>Reichman 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Wada and Asher 1986</REF>	0	However, in the past the only method for encoding and incorporating world knowledge involved writing a detailed script for every real-life situation, directly encoding the probable sequence of events, participants, and so forth <REF>Schank and Abelson 1977</REF>	0	This section will demonstrate that word level naive semantics offers a principled, transportable alternative to scripts	0	0	0
J89-3002	J86-3001	1989	Along with syntactic, compositional semantic, and discourse cue information, NS can be used to reason heuristically about discourse and drive many of the inferences drawn by people when they read a discourse	0	The role of syntax and compositional semantics will be underplayed in what follows, only because these contributions have been thoroughly treated by others <REF>Reinhart 1982</REF>; <REF>Asher and Wada 1988</REF>; <REF>Kamp 1981</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Reichman 1985</REF>; <REF>Webber 1985</REF>	0	51 ANAPHORA In anaphora resolution, syntactic constraints, accessibility in the sense of <REF>Kamp 1981</REF>, and discourse segmentation work in concert to limit the number of antecedents available to an anaphoric pronoun or definite NP	0	However, it is clear that the resultant saliency stack can end up with more than one member <REF>Asher and Wada 1988</REF>	0	0	0
C96-2101	J86-3001	1996	Also speech act classification is abandoned, in favour of contextual reasoning and rationality considerations	0	Two general approaches can be distinguished in dialogue management: the structural approach, which uses a dialogue grammar to capture regularities of the dialogue in terms of exchanges and moves <REF>Bilange, 1992</REF>; <REF>Cawsey, 1993</REF>; <TREF>Grosz and Sidner, 1986</TREF>, and the intention-based approach, which classifies the speakers beliefs and intentions into speech acts, and uses planning operators to describe them Appel 1985; <REF>Allen and Perrault, 1980</REF>; <REF>Bunt et al , 1984</REF>	0	Both regard natural language as purposeful behaviour, but differ in how this behaviour is to be described	0	The former sees dialogues as products and compiles participants beliefs and intentions into a predefined dialogue structure, whereas the latter focusses on the participants goals, and hides the structure in the relations between acts which contain appropriately chosen sets of beliefs and intentions as their preconditions and effects	0	0	0
W99-0112	J86-3001	1999	As mentioned earlier in this section, the initial account to centering is only concerned with the choice of referring expressions within a discourse segment	0	Since a more general theory to referring expressions is needed, an extension is presented by <TREF>Grosz and Sidner 1986</TREF>	0	They use a stack mechanism for representing the different discourse segments	0	If one segment is closed off	0	0	0
W99-0112	J86-3001	1999	His Segmented DRT SDRT uses a tree-like representation for the discourse sUuctui I Centering Theory CD proposes a//st structure for the entities one preferably refers to in subsequent sentences	0	In order to cover coreference over discourse segments the centering model was extended by a stack mechanism <TREF>Grosz and Sidner, 1986</TREF>	0	Recently, these data structures have been criticized by <REF>Walker 1998</REF>, because they seem to be too restrictive	0	She proposes a cache storage for the referenis in the focus of attention	0	0	0
P94-1002	J86-3001	1994	words residential and apartment both index the same thesaural category and can thus be considered to be in a coherence relation with one another	0	The chains are used to structure texts according to the attentional/intentional theory of discourse structure <TREF>Grosz  Sidner 1986</TREF>, and the extent of the chains correspond to the extent of a segment	0	The algorithm also incorporates the notion of chain returns repetition of terms after a long hiatus to close off an intention that spans over a digression	0	Since the <REF>Morris  Hirst 1991</REF> algorithm attempts to discover attentional/intentional structure, their goals are different than those of TextTiling	0	0	0
P94-1002	J86-3001	1994	rThis might be explained in part by <REF>Stark 1988</REF> who shows that readers disagree measurably about where to place paragraph boundaries when presented with texts with those boundaries removed	0	ogy that occurred in all of them reappears in this one location in the spirit of a Grosz ; <REF>Sidner 1986</REF> pop operation	0	Thus it displays low similarity both to itself and to its neighbors	0	This is an example of a breakdown caused by the assumptions about the subtopic structure	0	0	0
N04-4035	J86-3001	2004	Formal written discourse signals a hierarchical, tree-based discourse structure explicitly by the division of the text into chapters, sections, paragraphs, and sentences	0	This structure, in turn, identifies domains for interpretation; many systems for anaphora resolution rely on some notion of locality <TREF>Grosz and Sidner, 1986</TREF>	0	Similarly, this structure represents topical organization, and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic	0	Unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse	0	0	0
E99-1038	J86-3001	1999	2	0	Defining focus: a eognito-pragmatie category The term focus has been used in various senses, at least six of which can be identified, ie, phonological <REF>Pierrehumbert, 1980</REF>; <REF>Ladd, 1996</REF>, semantic <REF>Jackendoff, 1972</REF>; <REF>Prince, 1985</REF>, syntactic <REF>Rochemont, 1986</REF>, cognitive <REF>Sanford  Garrod, 1981</REF>; <REF>Musseler et al , 1995</REF>, pragmatic <REF>Halliday, 1967</REF>, and AI-focus <TREF>Grosz  Sidner, 1986</TREF> 	0	We argue that, first, these multiple uses of focus, though resulting in conceptual confusion, hint at the central status of the notion in core as well as peripheral linguistics	0	Second, focus as occurs in discourse is best captured by referring to both the interlocutors cognitive computation and constant interaction, in accordance with the dual ie , cognitive and pragmatic nature of discourse per se <REF>Nuyts, 1992</REF>	0	0	0
W04-2322	J86-3001	2004	In Section 6 we present our conclusions and suggest directions for future research	0	2 The Classical Linguistic Discourse Model C-LDM Unlike the Discourse Structures Model DSM of <TREF>Grosz and Sidner 1986</TREF>, a pragmatic and psychological theory that aims to clarify the relationship between speakers intentions and their focus of attention in discourse, or the rhetorical model of Rhetorical Structures Theory <REF>Mann and Thompson, 1988</REF> that is designed to identify the coherence relations between segments of text, the Linguistic Discourse Model LDM <REF>Polanyi and Scha, 1984</REF>; <REF>Polanyi, 1988</REF>; Polanyi and van den <REF>Berg, 1996</REF> is a syntactically informed, semantically driven model developed to provide proper semantic interpretation for every utterance in a discourse despite the apparent discontinuities that are present even in well structured written texts	0	In its focus on understanding discourse meaning, the LDM is close in spirit to Structured Discourse Representation Theory SDRT <REF>Asher, 1993</REF>	0	While S-DRT attempts to account for discourse structure purely semantically, the LDM framework is concerned to maintain a separation between discourse syntactic structure, on the one hand, and discourse interpretation on the other	0	0	0
W04-2322	J86-3001	2004	Antecedents must be available at a node along the right edge of the discourse tree	0	<REF>Polanyi, 1985</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Webber, 1991</REF> The LDM posits three structural relations between discourse units: 1	0	discourse coordination a Units related by bearing a similar relationship to an existing or newly formed common parent in the tree lists, narratives	0	b Available at the C-node is information common to all child nodes	0	0	0
J96-2004	J86-3001	1996	Where no sensible choice of unit is available pretheoretically, measure 1 may still be preferred	0	Secondly, coding discourse and dialogue phenomena, and especially coding segment boundaries, may be inherently more difficult than many previous types of content analysis for instance, 1 There are several variants of the kappa coefficient in the literature, including one, Scotts pi, which actually has been used at least once in our field, to assess agreement on move boundaries in monologues using action assembly theory <TREF>Grosz and Sidner 1986</TREF>	0	Krippendorffs c is more general than Siegel and Castellans K in that Krippendorff extends the argument from category data to interval and ratio scales; this extension might be useful for, for instance, judging the reliability of TOBI break index coding, since some researchers treat these codes as inherently scalar <REF>Silverman et al 1992</REF>	0	Krippendorffs c and Siegel and Castellans K differ slightly when used on category judgments in the assumptions under which expected agreement is calculated	0	0	0
P97-1026	J86-3001	1997	At any point, an entity is either new or old to the HEARER and either new or old to the DISCOURSE	0	Second, entities differ in SALIENCE <TREF>Grosz and Sidner, 1986</TREF>; <REF>Grosz et al , 1995</REF>	0	Salience assigns each entity a position in a partial order that indicates how accessible it is for reference in the current context	0	Third, entities are related by salient PARTIALLYORDERED SET POSET RELATIONS to other entities in the context <REF>Hirschberg, 1985</REF>	0	0	0
J99-3001	J86-3001	1999	At the level of discourse pragmatics, a richer notion than mere reference between terms is needed to account for coherence relations such as those aimed at by Rhetorical Structure Theory 340 Strube and Hahn Functional Centering <REF>Mann and Thompson 1988</REF>	0	In addition, an explicit relation to basic notions from speech act theory is also missing, though it should be considered vital for the global coherence of discourse <TREF>Grosz and Sidner 1986</TREF>	0	In general, it might become increasingly necessary to integrate very deep forms of reasoning, perhaps even nonmonotonic Dunin-<REF>Keplicz and Lukaszewicz 1986</REF> or abductive inference mechanisms <REF>Nagao 1989</REF>, into the anaphora resolution process	0	This might become a sheer necessity when incrementality of processing receives a higher level of attention in the centering community	0	0	0
J99-3001	J86-3001	1999	On the other hand, many of these systems work in a real-world environment <REF>Rich and LuperFoy 1988</REF>; <REF>Lappin and Leass 1994</REF>; <REF>Kennedy and Boguraev 1996</REF> in which noisy data and incomplete, sometimes even faulty, analysis results have to be accounted for	0	The centering model differs from these considerations in that it aims at unfolding a unified theory of discourse coherence at the linguistic, attentional, and intentional level <TREF>Grosz and Sidner 1986</TREF>; hence, the search for a more principled, theory-based solution, but also the need for almost perfect linguistic analyses in terms of parsing and semantic interpretation	0	7	0	Conclusion In this paper, we provided a novel account for ordering the forward-looking center list, a major construct of the centering model	0	0	0
J99-3001	J86-3001	1999	The model requires two constructs, a single backward-looking center and a list of forwardlooking centers, as well as a few rules and constraints that govern the interpretation of centers	0	It is assumed that discourses are composed of constituent segments <TREF>Grosz and Sidner 1986</TREF>, each of which consists of a sequence of utterances	0	Each utterance Ui in a given discourse segment DS is assigned a list of forward-looking centers, CfDS, Ui, and a unique backward-looking center, CbDS, Ui	0	The forward-looking centers of Ui depend only on the discourse entities that constitute the ith utterance; previous utterances provide no constraints on CfDS, Ui	0	0	0
J99-3001	J86-3001	1999	Computational linguists have recognized the need to account for referential ambiguities in discourse and have developed various theories centered around the notion of discourse focus <REF>Grosz 1977</REF>; <REF>Sidner 1983</REF>	0	In a seminal paper, <TREF>Grosz and Sidner 1986</TREF> wrapped up the results of their research and formulated a model in which three levels of discourse coherence are distinguished--attention, intention, and discourse segment structure	0	While this paper gives a comprehensive picture of a complex, yet not explicitly spelled-out theory of discourse coherence, the centering model <REF>Grosz, Joshi, and Weinstein, 1983, 1995</REF> marked a major step in clarifying the relationship between attentional states and local discourse segment structure	0	More precisely, the centering model accounts for the interactions between local coherence and preferential choices of referring expressions	0	0	0
W01-1605	J86-3001	2001	Annotation ranges from broad characterization of document-level information, such as topic or relevance judgments <REF>Voorhees and Harman, 1999</REF>; <REF>Wayne, 2000</REF> to discrete analysis of a wide range of linguistic phenomena	0	However, rich theoretical approaches to discourse/text analysis <REF>Van Dijk and Kintsch, 1983</REF>; <REF>Meyer, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Mann and Thompson, 1988</REF> have yet to be applied on a large scale	0	So far, the annotation of discourse structure of documents has been applied primarily to identifying topical segments <REF>Hearst, 1997</REF>, inter-sentential relations <REF>Nomoto and Matsumoto, 1999</REF>; <REF>Tsou et al , 2000</REF>, and hierarchical analyses of small corpora <REF>Moser and Moore, 1995</REF>; <REF>Marcu et al , 1999</REF>	0	In this paper, we recount our experience in developing a large resource with discourse-level annotation for NLP research	0	0	0
W01-1605	J86-3001	2001	Reseachers in the field have proposed a number of competing hypotheses about what constitutes an elementary discourse unit	0	While some take the elementary units to be clauses <REF>Grimes, 1975</REF>; <REF>Givon, 1983</REF>; <REF>Longacre, 1983</REF>, others take them to be prosodic units <REF>Hirschberg and Litman, 1993</REF>, turns of talk <REF>Sacks, 1974</REF>, sentences <REF>Polanyi, 1988</REF>, intentionally defined discourse segments <TREF>Grosz and Sidner, 1986</TREF>, or the contextually indexed representation of information conveyed by a semiotic gesture, asserting a single state of affairs or partial state of affairs in a discourse world, <REF>Polanyi, 1996</REF>, p5	0	Regardless of their theoretical stance, all agree that the elementary discourse units are non-overlapping spans of text	0	Our goal was to find a balance between granularity of tagging and ability to identify units consistently on a large scale	0	0	0
J99-4006	J86-3001	1999	The statement that the cache retrieves entities related to the prior intention from the main memory to the cache, unless retained in the cache, leaves unanswered two critical processing 3 There are, in addition, several well-recognized problems with the model	0	In particular, as used in computer systems, stacks do not differentiate among different kinds of frames, but interruptions seem to operate differently from normal embeddings <TREF>Grosz and Sidner 1986</TREF> and there are open issues in explaining pronominal reference at discourse segment boundaries	0	621 Computational Linguistics Volume 25, Number 4 questions: 1 How is the cache searched for related entities and how is relatedness determined	0	2 How is a prior intention determined ie, what memory is there for intentional structure and how is that coordinated with information in main memory so that the relevant information can be found	0	0	0
J99-4006	J86-3001	1999	We first examine this evidence from the stack model perspective showing how the data might be accounted for within that model; we then raise some questions about Walkers cache model explanations	0	In earlier work <REF>Grosz 1977a</REF>; <TREF>Grosz and Sidner 1986</TREF> we have argued that it is important to distinguish between two levels of discourse structure and processing: global and local	0	A focus-space stack was proposed as a model for the global level	0	The main claims about its use in processing have been for handling definite descriptions <REF>Grosz 1977a</REF>; <REF>Grosz 1981</REF> and reasoning about intentional structure <REF>Lochbaum 1998</REF>	0	0	0
J99-4006	J86-3001	1999	J99-4006:327	0	Conceptions of Limited Attention and Discourse FocusBarbara J Grosz t Harvard University Peter C Gordon University of North <REF>Carolina Walker 1996</REF> presents a cache model of the operation of attention in the processing of discourse as an alternative to the focus space stack that was proposed previously by Grosz and Sidner <REF>Grosz 1977a</REF>; <TREF>Grosz and Sidner 1986</TREF>	0	In this squib, we present a critical analysis of the cache model and of Walkers supporting evidence from anaphora in discourses with interruptions and from informationally redundant utterances	0	We argue that the cache model is underdetermined in several ways that are crucial to a comparison of the two models and conclude that Walker has not established the superiority of the cache model	0	0	0
J99-4006	J86-3001	1999	A recent article by <REF>Walker 1996</REF> argues that the attentional mechanism has limited capacity, that this limited capacity determines the accessibility of information in discourse processing, and that certain linguistic behavior can only be explained in terms of this limited capacity	0	Walker presents as an alternative to the focus space stack previously proposed to model global attentional state <REF>Grosz 1977a</REF>; <TREF>Grosz and Sidner 1986</TREF> a cache model in which linear recency and a highly constrained cache capacity play primary roles	0	As critical evidence, Walker presents an analysis of anaphora in discourses with interruptions and of informationally redundant utterances IRUs	0	In addition, she cites psychological evidence on the limited capacity of human information processing	0	0	0
C88-2099	J86-3001	1988	The foregoing has sewed to motivate the need for reliable segmentation heuristics	0	Most such heuristics found in the iitera ture are syntactical in nature, relying, in almost Eliza-like fashion, on clue words and phrases see references in <TREF>Grosz  Sidner 1986</TREF>: 177	0	We ptpose that heuristics should be based on semantical considerations such as discontinuities in the representation	0	This paper investigates four kinds of discontinuities: discontinuities of topic, discontinuities of space and time, discontinuities of figure and ground, and discontinuities of the narrative perspective	0	0	0
C88-2099	J86-3001	1988	Nhimovsky 1988 for some discussion	0	<TREF>Grosz  Sidner 1986</TREF> is the first unified approach in which the problem of segmentation is fled up with the notion of atten tional state	0	As argued in <REF>Nakhimovsky 1987b</REF>, some features of their model a stack mechanism for attentional state, the prom inenee of pragmatic notions such as the speakers intentions make it more appropriate for conversation rather than nacative <REF>Webber 1988</REF> and <REF>Naidlimovsky 1988</REF> suggest a model in which the distinction between the top and the rest of die stack is replaced by the distinction between a shnttelm memory and the ESS	0	Ottr work has been developing in close contact with the SUNY Buffalo Graduate Group in Cognitive Sciences pojcct on cognitive and computer systems for understanding narrative text	0	0	0
C88-2099	J86-3001	1988	We thus have three kinds of entities organized into three kinds of structures: linearly ordered stretches of text forming the Linear Text Structure LTS; the Event-Situation Structure ESS, ef	0	<REF>Webber 1987b</REF>, representing the narratives unfolding contents; and the Current Focus Space, which is a collection of focusing mechanisms including the deictic center that together represent the attentional state <TREF>Grosz  Sidner 1986</TREF> of the system	0	The components of the LTS are frequently linked by rbetodcal relationg such as elaboration, resumption or flashback see, eg, <REF>Hobbs 1982</REF>	0	We believe that these rhetorical relations are simply macro labels that stand for certain oft-repeated clusters of discontinuities in the ESS	0	0	0
P07-1075	J86-3001	2007	<REF>Second, Miltsakaki 2003</REF> stated that entities in subordinate clauses are less salient	0	Third, the knowledge of textual structure helps to interpret the meaning of entities in a text <TREF>Grosz and Sidner 1986</TREF>	0	As an example, consider the sentences ABC Co appointed a new chairman	0	Additionally, the current CEO was retired	0	0	0
J00-2001	J86-3001	2000	An example of the type of plan the planner must build is shown in Figure 3 Section 41 discusses the use of this plan in more detail	0	This model of text plans meshes well with the model of discourse structure developed by Grosz and Sidner <REF>Grosz and Sidner 1985, 1986</REF>, in which the purpose of each discourse segment is an important part of the structure	0	9 IGEN constructs its plans using a hierarchical planning algorithm <REF>Nilsson 1980</REF>	0	The planner first checks all of its top-level plans to see which have effects that match the goal	0	0	0
J04-3003	J86-3001	2004	Furthermore, she noted that this identification leads to problems with multiclausal sentences: for example, grammatical function ranking becomes difficult to compute, as a sentence may have more than one subject	0	Kameyama proposed that the local focus be updated after every tensed clause, not after every sentence, and classified tensed clauses into 1 utterances that constitute a permanent update of the local focus, such as coordinated clauses and adjuncts, and 2 embedded utterances that result in temporary updates that are then popped, much as the information introduced into discourse by subordinated discourse segments is popped according to <TREF>Grosz and Sidner 1986</TREF>	0	According to Kameyama, only a few types of clauses, such as the complements of certain verbs, are embedded	0	For example, Kameyama proposes to break up 4 into utterances as follows, and to treat each of these utterances, including subordinate clauses such as U2 or U5, as an update: 4 u1 Her entrance in Scene 2 Act 1 brought some disconcerting applause u2 even before she had sung a note	0	0	0
J04-3003	J86-3001	2004	334 Segmentation	0	According to <TREF>Grosz and Sidner 1986</TREF>, centering is meant to capture preferences only within discourse segments	0	A proper evaluation of the claims of the theory would therefore require a corpus in which discourse segments have been identified	0	Unfortunately, discourse segments are difficult to identify reliably <REF>Passonneau and Litman 1993</REF>, and <TREF>Grosz and Sidner 1986</TREF> do not provide a specification of discourse intentions explicit enough that it can be used to identify the intentional structure of textswhich, according to Grosz and Sidner, determines their segmentation	0	0	0
J04-3003	J86-3001	2004	A proper evaluation of the claims of the theory would therefore require a corpus in which discourse segments have been identified	0	Unfortunately, discourse segments are difficult to identify reliably <REF>Passonneau and Litman 1993</REF>, and <TREF>Grosz and Sidner 1986</TREF> do not provide a specification of discourse intentions explicit enough that it can be used to identify the intentional structure of textswhich, according to Grosz and Sidner, determines their segmentation	0	As a result, only preliminary attempts at annotating texts according to Grosz and Sidners theory have been made	0	For this reason, most previous corpus-based studies of centering either ignored segmentation or used heuristics such as those proposed by <REF>Walker 1989</REF>: Consider every paragraph as a separate discourse segment, except when its first sentence contains a pronoun in subject position or a pronoun whose agreement features are not 18 In previous work <REF>Poesio and Vieira 1998</REF> we came to the conclusion that kappa, while appropriate when the number of categories is fixed and relatively small, is problematic for anaphoric reference, when neither condition applies, and may result in inflated values of agreement	0	0	0
J04-3003	J86-3001	2004	E-mail:hitzemitreorg	0	Submission received: 16 <REF>April 2002</REF>; Revised submission received: 3 <REF>September 2003</REF>; Accepted for publication: 11 <REF>December 2003</REF> 310 Computational Linguistics Volume 30, Number 3 of attention and coherence in discourse <REF>Grosz 1977</REF>; <REF>Sidner 1979</REF>; <TREF>Grosz and Sidner 1986</TREF> concerned with local coherence and salience, that is, coherence and salience within a discourse segment	0	A fundamental characteristic of centering is that it is better viewed as a linguistic theory than a computational one	0	By this we mean that its primary aim is to make cross-linguistically valid claims about which discourses are easier to process, abstracting away from specific algorithms for anaphora resolution or anaphora generation although many such algorithms are based on the theory	0	0	0
J04-3003	J86-3001	2004	Centerings first contention as far as local salience is concerned is that the discourse entities realized by an utterance more on realization below are ranked: that is, that in each utterance some discourse entities are more salient than others	0	This claim, as well, is a basic tenet of much work on discourse <REF>Sidner 1979</REF>; <REF>Prince 1981</REF>; <REF>Givon 1983</REF>; <REF>Gundel, Hedberg, and Zacharski 1993</REF> and is supported by much psychological evidence <REF>Hudson, Tanenhaus, and Dell 1986</REF>; <REF>Gernsbacher and Hargreaves 1988</REF>; <REF>Gordon, Grosz, and Gillion 1993</REF>; <REF>Stevenson, Crawley, and Kleinman 1994</REF>	0	1 Entity-based theories of coherence are so-called by contrast with relation-centered theories of coherence, such as those developed in <REF>Hobbs 1979</REF> and <REF>Mann and Thompson 1988</REF> and used in <REF>Fox 1987</REF> and <REF>Lascarides and Asher 1993</REF>	0	The earliest detailed entity-based theory of coherence we are aware of is by Kintsch and van <REF>Dijk 1978</REF>, who also explicitly mention the need to supplement such theories with a theory of relational coherence more on this in Section 5 312 Computational Linguistics Volume 30, Number 3 These claims about coherence and salience are linked by two further hypotheses: that the identity of the CB is crucially determined by the entities ranking and that the CB is most likely to be realized as a pronoun	0	0	0
C04-1020	J86-3001	2004	Annotator agreement did not differ by text length  2  127; p < 075, arc length  2 < 1, or kind of coherence relation  2 < 1	0	3 Data structures for representing coherence relations Most accounts of discourse coherence assume tree structures to represent coherence relations between discourse segments in a text <REF>Carlson et al , 2002</REF>; Corston-<REF>Oliver, 1998</REF>; <REF>Lascarides  Asher, 1993</REF>; <REF>Longacre, 1983</REF>; <TREF>Grosz  Sidner, 1986</TREF>; <REF>Mann  Thompson, 1988</REF>; <REF>Marcu, 2000</REF>; <REF>Polanyi, 1988</REF>; van <REF>Dijk  Kintsch, 1983</REF>; <REF>Walker, 1998</REF>; <REF>Webber et al , 1999</REF>	0	Other accounts assume less constrained graphs <REF>Hobbs, 1985</REF>	0	The proponents of tree structures argue that trees are easier to formalize and derive than less constrained graphs <REF>Marcu, 2000</REF>	0	0	0
C04-1020	J86-3001	2004	2 Collecting a database of texts annotated with coherence relations This section describes 1 how we define discourse segments, 2 which coherence relations we used to connect the discourse segments, and 3 how the annotation procedure worked	0	21 Discourse segments Discourse segments can be defined as nonoverlapping spans of prosodic units <REF>Hirschberg  Nakatani, 1996</REF>, intentional units <TREF>Grosz  Sidner, 1986</TREF>, phrasal units <REF>Lascarides  Asher, 1993</REF>, or sentences <REF>Hobbs, 1985</REF>	0	We adopted a sentence unit-based definition of discourse segments	0	However, we also assume that contentful coordinating and subordinating conjunctions cf	0	0	0
C04-1020	J86-3001	2004	<REF>Hobbs, 1985</REF>; <REF>Marcu, 2000</REF>; <REF>Webber et al , 1999</REF>	0	Accounts of discourse structure vary greatly with respect to how many discourse relations they assume, ranging from two <TREF>Grosz  Sidner, 1986</TREF> to over 400 different coherence relations, reported in <REF>Hovy and Maier 1995</REF>	0	<REF>However, Hovy and Maier 1995</REF> argue that taxonomies with more relations represent subtypes of taxonomies with fewer relations	0	This means that different taxonomies can be compatible with each other	0	0	0
J97-1007	J86-3001	1997	Although the algorithms would be refined due to the introduction of more discourse structure, they would essentially still serve the purpose of distinguishing potential referents	0	The beginnings of discourse segments, in a sense, indicate shifts of intention in a discourse <TREF>Grosz and Sidner 1986</TREF>	0	In this situation, it may be preferred that subsequent references be full descriptions rather than reduced ones or pronouns, to emphasize the beginning of discourse segments, even if the referents have just been mentioned in the immediately previous utterance	0	<REF>See Grosz and Sidner 1986</REF> and <REF>Dale 1992</REF> for some examples that illustrate this idea	0	0	0
J97-1007	J86-3001	1997	<TREF>Grosz and Sidner 1986</TREF> claim that discourse segmentation is an important factor, though obviously not the only one, governing the use of referring expressions	0	If the idea of context set were restricted to local focus space <TREF>Grosz and Sidner 1986</TREF>, then the resulting descriptions would be to some extent sensitive to local aspects of discourse structure	0	Although the algorithms would be refined due to the introduction of more discourse structure, they would essentially still serve the purpose of distinguishing potential referents	0	The beginnings of discourse segments, in a sense, indicate shifts of intention in a discourse <TREF>Grosz and Sidner 1986</TREF>	0	0	0
J97-1007	J86-3001	1997	Minimal distinguishing descriptions pursue efficiency in producing an adequate description that can identity the intended referent unambiguously with a given context set	0	<REF>Dale 1992</REF> used the global focus space <TREF>Grosz and Sidner 1986</TREF>, as the context set in his domain of small discourse	0	Following this idea, the context set grows as the discourse proceeds	0	Consider, for example, two nominal anaphora referring to the same entity occurring at different places in a discourse	0	0	0
J97-1007	J86-3001	1997	We do not handle the generation of long-distance pronouns, which were rare in our texts	0	A possible solution would be to employ the concept of stacked focus space in Grosz and Sidners discourse structure theory <TREF>Grosz and Sidner 1986</TREF>; <REF>Dale 1992</REF>	0	In the final rule, the implementation of the test of the beginning of a discourse segment is not quite as straightforward as the other constraints	0	In our current implementation, we rely on the hierarchical structure of the message content to be generated as the basis for dividing the message into segments, which is effective in improving the texts generated by our Chinese natural language generation system	0	0	0
J97-1007	J86-3001	1997	In this situation, it may be preferred that subsequent references be full descriptions rather than reduced ones or pronouns, to emphasize the beginning of discourse segments, even if the referents have just been mentioned in the immediately previous utterance	0	<REF>See Grosz and Sidner 1986</REF> and <REF>Dale 1992</REF> for some examples that illustrate this idea	0	Figure 8 indicates that a similar situation may happen in Chinese discourse	0	Among the groups of initial and subsequent references, we focus on the one indexed j, lafengzheng de xian the string pulling the kite	0	0	0
J97-1007	J86-3001	1997	Thus, we employed the notion of discourse structure as the basis for enhancing the rule	0	23 Rule 3: Adding Discourse <REF>Structure Grosz and Sidner 1986</REF> suggest that three structures can be identified within a discourse: linguistic structure, intentional structure, and attentional state	0	The first structure is the sequence of utterances that comprise the discourse	0	Underlying this is the intentional structure, which shows the relationship between the respective purposes of discourse segments	0	0	0
J97-1007	J86-3001	1997	The entity, the big cat, is not a distractor to the black dog because it is of different category, cat	0	<TREF>Grosz and Sidner 1986</TREF> claim that discourse segmentation is an important factor, though obviously not the only one, governing the use of referring expressions	0	If the idea of context set were restricted to local focus space <TREF>Grosz and Sidner 1986</TREF>, then the resulting descriptions would be to some extent sensitive to local aspects of discourse structure	0	Although the algorithms would be refined due to the introduction of more discourse structure, they would essentially still serve the purpose of distinguishing potential referents	0	0	0
W97-0320	J86-3001	1997	This prevents a number of the above errors and suggests that changes in tense, aspect, and modality are promising clues to explore for recognizing subdialogs in this kind of data cf	0	, eg, <TREF>Grosz  Sidner 1986</TREF>; <REF>Nakhimovsky 1988</REF>	0	The CMU data has very little variation in tense and aspect, the reason a mechanism for interpreting them was not incorporated into the Mgorithm	0	Ros et al	0	0	0
W97-0320	J86-3001	1997	In developing the algorithm, our approach was to start with a straightforward, recencybased approach and add complexity as needed to address problems encountered in the data	0	The algorithm does not include a mechanism for handling global focus <TREF>Grosz  Sidner 1986</TREF>, for centering within a discourse segment <REF>Sidner 1979</REF>; <REF>Grosz et al 1995</REF>, or for performing tense and aspect interpretation	0	Instead, the algorithm processes anaphoric references with respect to an Attentional State <TREF>Grosz  Sidner 1986</TREF> structured as a linear list of all times mentioned so far in the current dialog	0	The list is ordered by recency, no entries are ever deleted from the list, and there is no restriction on access	0	0	0
W97-0320	J86-3001	1997	As will be shown in the next section, very few errors can be attributed to the wrong entities being in focus due to not handling subdialogs or multiple threads Ros6 et al 1995	0	6 Global Focus The algorithm is conspicuously lacking in any mechanism for recognizing the global structure of the discourse, such as in Grosz  <REF>Sidner 1986</REF>, <REF>Mann  Thompson 1988</REF>, <REF>Allen  Perranlt 1980</REF>, and their descendants	0	Recently in the literature, <REF>Walker 1996</REF> has argued for a more linear-recency based model of Attentional State though not that discourse structure need not be recognized, while Rosd et al	0	1995 argue for a more complex model of Attentional State than is represented in most current computational theories of discourse	0	0	0
W97-0320	J86-3001	1997	The algorithm does not include a mechanism for handling global focus <TREF>Grosz  Sidner 1986</TREF>, for centering within a discourse segment <REF>Sidner 1979</REF>; <REF>Grosz et al 1995</REF>, or for performing tense and aspect interpretation	0	Instead, the algorithm processes anaphoric references with respect to an Attentional State <TREF>Grosz  Sidner 1986</TREF> structured as a linear list of all times mentioned so far in the current dialog	0	The list is ordered by recency, no entries are ever deleted from the list, and there is no restriction on access	0	The algorithm decides among candidate antecedents based on a combined score reflecting recency, a priori preferences for the type Of anaphoric relations established, and plausibility of the resulting temporal reference	0	0	0
P99-1024	J86-3001	1999	In this case, the background may still contain the open proposition	0	Unlike in dialogue analyses carried out on completed dialogues <TREF>Grosz and Sidner, 1986</TREF>, the dialogue manager needs to maintain a stack of all open discourse segments at each point in an on-going dialogue	0	When a system allows corrections, it can be difficult to determine when a user has completed a discourse segment	0	Ex	0	0	0
P99-1024	J86-3001	1999	This paper describes extensions to CommandTalk to support spoken dialogue	0	While we make no theoretical claims about the nature and structure of dialogue, we are influenced by the theoretical work of <TREF>Grosz and Sidner, 1986</TREF> and will use terminology from that tradition when appropriate	0	We also follow Chu-<REF>Carroll and Brown, 1997</REF> in distinguishing task initiative and dialogue initiative	0	Section 2 demonstrates the dialogue capabilities of CommandTalk by way of an extended example	0	0	0
P99-1077	J86-3001	1999	Much of the relevant linguistic literature is indebted to <REF>Halliday and Hasan 1976</REF>, where cohesion is defined as a network of relationships between locations in the text, arising from i grammatical factors co-reference, use of pro-forms, ellipsis and sentential connectives, and ii lexical factors reiteration and collocation	0	Subsequent work has further developed this taxonomy <REF>Hoey, 1991</REF> and explored its implications in such areas as paragraphing <REF>Longacre, 1979</REF>; <REF>Bond and Hayes, 1984</REF>; <REF>Stark, 1988</REF>, relevance <REF>Sperber and Wilson, 1995</REF> and discourse structure <TREF>Grosz and Sidner, 1986</TREF>	0	The lexical variety of cohesion is semantically defined, invoking a measure of word similarity	0	But this is hard to measure objectively, especially in the case of collocational relationships, which hold between words primarily because they regularly cooccur	0	0	0
A94-1020	J86-3001	1994	Some views concentrate on deriving coherence relations between discourse segments, with the help of world models <REF>Hobbs, 1979</REF>; <REF>Reichman, 1984</REF>	0	Work on Discourse Structure Theory <REF>Grosz, 1977</REF>; <TREF>Grosz and Sidner, 1986</TREF> searches for automatic ways of segmenting discourse based on intentions and purposes embedded in discourse segments	0	Most of the results available are not readily adaptable to the current type of application	0	No world model can be introduced without severe consequences for portability	0	0	0
A94-1020	J86-3001	1994	This number can vary from application to application, and the current limit is set to three	0	<REF>Following Grosz and Sidner 1986</REF>, segments occur in sequence, or are embedded, to allow users to elaborate on a change of focus before returning to the previous topic	0	In case the current segment intersects with the second most recent one on the context list if any, this can be seen as a return to the previous topic segments 1 and 3 in Fig 2	0	The current segment will continue to grow independently, but the candidates in the second most recent segment will become available for reference	0	0	0
P96-1038	J86-3001	1996	The portion of the corpus we report on consists of 494 and 552 intermediate phrases for read and spontaneous speech, respectively	0	33 Discourse Segmentation In our research, the <TREF>Grosz and Sidner 1986</TREF> theory of discourse structure, hereafter GS, provides a foundation for segmenting discourses into constituent parts	0	According to this model, at least three components of discourse structure must be distinguished	0	The utterances composing the discourse divide into segments that may be embedded relative to one another	0	0	0
P96-1038	J86-3001	1996	CDA-94-01024 at Harvard University and by ATT Bell Laboratories	0	that discourse structural information can be inferred from orthographic cues in text, such as paragraphing and punctuation; from linguistic cues in text or speech, such as cue PHIASES 1 <REF>Cohen, 1984</REF>; <REF>Reichman, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF></TREF>; <REF>Passonneau and Litman, 1993</REF></REF>; Passonneau and Litman, to appear and other lexical cues <REF>Hinkelman and Allen, 1989</REF>; from variation in referring expressions <REF>Linde, 1979</REF>; <REF>Levy, 1984</REF>; <TREF>Grosz and Sidner, 1986</TREF></TREF>; <REF>Webber, 1988</REF>; <REF>Song and Cohen, 1991</REF></REF>; <REF>Passonneau and Litman, 1993</REF></REF>, tense, and aspect <REF>Schubert and Hwang, 1990</REF>; <REF>Song and Cohen, 1991</REF></REF>; from knowledge of the domain, especially for taskoriented discourses <REF>Grosz, 1978</REF>; and from speaker intentions <REF>Carberry, 1990</REF>; <REF>Litman and Hirschberg, 1990</REF>; <REF>Lochbaum, 1994</REF>	0	Recent methods for automatic recognition of discourse structure from text have incorporated thesaurus-based and other information retrieval techniques to identify changes in topic <REF>Morris and Hirst, 1991</REF>; <REF>Yarowsky, 1991</REF>; <REF>Iwafiska et al , 1991</REF>; <REF>Hearst, 1994</REF>; <REF>Reynar, 1994</REF>	0	Parallel investigations on prosodic/acoustic cues to discourse structure have investigated the contributions of features such as pitch range, pausal duration, amplitude, speaking rate, and intonational contour to signaling topic change	0	0	0
P96-1038	J86-3001	1996	An intention-based theory of discourse was used in <REF>Hirschberg and Grosz, 1992</REF>; <REF>Grosz and Hirschberg, 1992</REF> to identify intonational correlates of discourse structure in news stories read by a professional speaker	0	Discourse structural elements were determined by experts in the <TREF>Grosz and Sidner 1986</TREF> theory of discourse structure, based on either text alone or text and speech	0	This study revealed strong correlations of aspects of pitch range, amplitude, and timing with features of global and local structure for both segmentation methods	0	Passonneau and Litman to appear analyzed correlations of pause, as well as cue phrases and referential relations, with discourse structure; their segmenters were asked to identify speakers communicative actions	0	0	0
P98-1103	J86-3001	1998	We thus reckon that appropriate context management should provide descriptions of what is said, and that the recognition of the utterance topic is an important task of spoken dialogue systems	0	3 The Topic Model In AI-based dialogue modelling, topics are associated with a particular discourse entity, focus, which is currently in the centre of attention and which the participants want to focus their actions on, eg <TREF>Grosz and Sidner 1986</TREF>	0	The topic focus is a means to describe thematically coherent discourse structure, and its use has been mainly supported by arguments regarding anaphora resolution and processing effort search space limits	0	Our goal is to use topic information in predicting likely content of the next utterance, and thus we are more interested in the topic types that describe the information conveyed by utterances than the actual topic entity	0	0	0
W08-0101	J86-3001	2008	This difficulty in formalizing higher levels of conversation might explain the relatively low interest that conversational analysts have had in semantics and discourse	0	Yet, as conversational analysts focused on micro-levels of dialogue such as turntaking, computational linguists uncovered and formalized macro-level dialogue structure and devised well-defined representations of semantics for at least some forms of dialogues <REF>Allen and Perrault, 1980</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Clark, 1996</REF>, which have in turn been implemented in spoken dialogue systems <REF>Rich and Sidner, 1998</REF>; <REF>Allen et al, 2005</REF>	0	1 12 Current Approaches to Turn-Taking in Spoken Dialogue Systems Unfortunately, while socioand psycho-linguists revealed the complexity of conversational turn-taking behavior, designers of practical spoken dialogue systems have stuck to a simplistic approach to end-ofturn detection hereafter endpointing	0	Typically, silences in user speech are detected using a low-level Voice Activity Detector VAD and a turn is considered finished once a silence lasts longer than a fixed threshold	0	0	0
W02-0226	J86-3001	2002	From the view of GDM, the strategies a dialogue agent may choose can also be classified into three levels, ie, Micro-level strategies how to realize information structure, anaphora, ellipsis, and others, in utterances, Meso-level strategies what to say regarding current group status, so as to complete ongoing group more friendly, Macro-level strategies how to choose discourse topic regarding current task status, so as to complete the underlying task more efficiently	0	6 <TREF>Grosz and Sidner 1986</TREF> proposed a tripartite discourse model consisting of attentional state, intentional structure, and linguistic structure	0	It is influential and covers both dialogue and text	0	But their intentional structure fails to capture the distinction between global level and local level structure	0	0	0
J88-2004	J86-3001	1988	In terms of text structure, the current sentence either continues the same, or starts a new, discourse segment DS; cf	0	<TREF>Grosz and Sidner 1986</TREF>	0	The nature of the processing at the DS juncture is thus quite different from the routine tasks to be performed as long as the text remains in the same DS: the start of new DS prompts, and is prompted by, a shift of attention	0	The circularity here is deliberate	0	0	0
P98-2188	J86-3001	1998	Dialogue Act Tagging To address a significant concern in machine learning, called the sparse data problem, we must select an appropriate set of features	0	Researchers in discourse, such as <TREF>Grosz and Sidner 1986</TREF>, <REF>Lambert 1993</REF>, <REF>Hirschberg and Litman 1993</REF>, <REF>Chen 1995</REF>, <REF>Andernach 1996</REF>, <REF>Samuel 1996</REF>, and Chu-<REF>Carroll 1998</REF> have suggested several features that might be relevant for the task of computing dialogue acts	0	Our system can consider the following features of an utterance: 1 the cue phrases 3 in the utterance; 2 the word n-grams 3 in the utterance; 3 the dialogue act cues 3 in the utterance; 4 the entire utterance for one-, two-, or three-word utterances; 5 speaker information 4 for the utter2The part-of-speech tag of a word is dependent on the words internal features and on the surrounding words; similarly, the dialogue act of an utterance is dependent on the utterances internal features and on the surrounding utterances	0	This feature is defined later in this section	0	0	0
J88-3009	J86-3001	1988	USER MODELS AND DISCOURSE MODELS David N Chin Department of Information and Computer Services University of Hawaii at Manoa 2565 The Mall Honolulu, HI 96822 A user model UM contains information about users, such as users goals, beliefs, knowledge, preferences, and capabilities	0	A discourse model DM contains information about the conversation, such as the linguistic structure, the attentional state, and the intentional structure <TREF>Grosz and Sidner 1986</TREF>	0	Given these definitions, I will argue that the UM intersects the DM	0	That is, the UM contains items that are missing from the UM; the DM contains items that are missing from the DM; and the two share some items	0	0	0
J88-3009	J86-3001	1988	Although both DMs and UMs are built up from propositions expressed in the conversation, the DM expires at the end of the discourse, while parts of the UM are kept for future use	0	<TREF>Grosz and Sidner 1986</TREF> discuss how DMs are built up, and <REF>Chin 1986</REF>, <REF>Litman and Allen 1984</REF>, <REF>Carberry 1983</REF>, and <REF>Allen and Perrault 1980</REF>, among others, discuss this process for different aspects of UMs	0	In summary, the DM and UM are not separate, but rather share common parts	0	Shared parts include the intentional structure of the discourse and the attentional structure of the discourse	0	0	0
W04-1115	J86-3001	2004	Formal written discourse signals a hierarchical, tree-based discourse structure explicitly by the division of the text into chapters, sections, paragraphs, and sentences	0	This structure, in turn, identifies domains for interpretation; many systems for anaphora resolution rely on some notion of locality <TREF>Grosz and Sidner, 1986</TREF>	0	Similarly, this structure represents topical organization, and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic	0	Unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse	0	0	0
D08-1100	J86-3001	2008	Many such models focus on other aspects of a dialog such as coordinated activities, ie turn-taking and grounding, <REF>Traum and Hinkelman, 1992</REF> and regular patterns in the dialog <REF>Carletta et al, 1997</REF> rather than the domain-specific information communicated by participants	0	More complicated dialog representations <TREF>Grosz and Sidner, 1986</TREF>; <REF>Litman and Allen, 1987</REF> model several aspects of a dialog including domain-specific information	0	However, additional components in these models, such as beliefs and intentions, are difficult to observe directly from a conversation and, as for the current technology, may not be learnable through an unsupervised learning approach	0	Since the task-specific information that we would like to model will be used for configuring a dialog system, we can view this information from a dialog system perspective	0	0	0
P93-1020	J86-3001	1993	As in much of the literature on discourse processing, we assume that certain spans of utterances, referred to here as discourse segments, form coherent units	0	The segmental structure of discourse has been claimed to constrain and be constrained by disparate phenomena: cue phrases <REF>Hirschberg and Litman, 1993</REF>; <REF><REF>Gross and Sidner, 1986</REF></REF></REF>; <REF>Reichman, 1985</REF>; <REF>Cohen, 1984</REF>; lexical cohesion <REF>Morris and Hirst, 1991</REF>; plans and intentions <REF>Carberry, 1990</REF>; <REF>Litman and Allen, 1990</REF>; <REF><REF>Gross and Sidner, 1986</REF></REF></REF>; prosody <REF>Grosz and Hirschberg, 1992</REF>; <REF>Hirschberg and Gross, 1992</REF>; <REF>Hirschberg and Pierrehumbert, 1986</REF>; reference <REF>Webber, 1991</REF>; <REF><REF>Gross and Sidner, 1986</REF></REF></REF>; <REF>Linde, 1979</REF>; and tense <REF>Webber, 1988</REF>; <REF>Hwang and Schubert, 1992</REF>; <REF>Song and Cohen, 1991</REF>	0	However, there is weak consensus on the nature of segments and the criteria for recognizing or generating them in a natural language processing system	0	Until recently, little empirical work has been directed at establishing objeively verifiable segment boundaries, even though this is a precondition for 1We use the term utterance to mean a use of a sentence or other linguistic unit, whether in text or spoken language	0	0	0
P93-1020	J86-3001	1993	They then used statistical measures to characterize these discourse structures in terms of acousticprosodic features	0	<REF>Morris and Hirst 1991</REF> structured a set of magazine texts using the theory of <TREF>Grosz and Sidner 1986</TREF>	0	They developed a lexical cohesion algorithm that used the information in a thesaurus to segment text, then qualitatively compared their segmentations with the resuits	0	<REF>Hearst 1993</REF> derived a discourse structure for each text in her study, by incorporating the boundaries agreed upon by the majority of her subjects	0	0	0
P93-1020	J86-3001	1993	RELIABILITY The correspondence between discourse segments and more abstract units of meaning is poorly understood see <REF>Moore and Pollack, 1992</REF>	0	A number of alternative proposals have been presented which directly or indirectly relate segments to intentions <TREF>Grosz and Sidner, 1986</TREF>, RST relations <REF>Mann et al , 1992</REF> or other semantic relations <REF>Polanyi, 1988</REF>	0	We present initial results of an investigation of whether naive subjects can reliably segment discourse using speaker intention as a criterion	0	Our corpus consists of 20 narrative monologues about the same movie, taken from <REF>Chafe 1980</REF> N14,000 words	0	0	0
P93-1020	J86-3001	1993	Several researchers have begun to investigate the ability of humans to agree with one another on segmentation	0	Grosz and Hirschberg <REF>Grosz and Hirschberg, 1992</REF>; <REF>Hirschberg and Grosz, 1992</REF> asked subjects to structure three AP news stories averaging 450 words in length according to the model of <TREF>Grosz and Sidner 1986</TREF>	0	Subjects identified hierarchical structures of discourse segments, as well as local structural features, using text alone as well as text and professionally recorded speech	0	Agreement ranged from 74-95, depending upon discourse feature	0	0	0
W99-0313	J86-3001	1999	IU trees are created by identifying certain kinds of discourse relations	0	Following <TREF>Grosz and Sidner, 1986</TREF>, macro-level analysis captures two fundamental intentional relations between I-units, those of domination or parent-child and satisfactionprecedence or sibling relations	0	The corresponding informational relations are generates and enables <REF>Pollack, 1986</REF>; <REF>Goldman, 1970</REF>	0	More concretely, the domination relation can be elaborated in a planning-based framework as holding between a subsidiary plan and its parent, in which the completion of one plan contributes to the completion of its parent plan; the satisfaction-precedence relation can be elaborated as the temporal dependency between two plans <REF>Lochbaum, 1994</REF>	0	0	0
W99-0313	J86-3001	1999	One scheme which has as content Grounding <REF>Clark and Schaefer, 1989</REF>; <REF>Traum, 1994</REF>, operated at a meso level of granularity, and used non-hierarchical and possibly discontinuous  utterance sets as its structuring principle	0	The second scheme concerned intentional/informational structure <TREF>Grosz and Sidner, 1986</TREF>; <REF>Nakatani et al , 1995</REF> as content, operated at a macro level of granularity, and was structured as hierarchical trees with annotations for capturing discontinuities	0	In addition, these two schemes were linked by using the resulting structures from meso-level analysis as basic input for macro-level analysis	0	There were several factors motivating the decision to use these particular facets of discourse structure for initial analysis	0	0	0
P96-1009	J86-3001	1996	Robust Speech Act Processing The dialogue manager is responsible for interpreting the speech acts in context, formulating responses, and maintaining the systems idea of the state of the discourse	0	It maintains a discourse state that consists of a goal stack with similarities to the plan stack of <REF>Litman  Allen 1987</REF> and the attentional state of <TREF>Grosz  Sidner 1986</TREF>	0	Each element of the stack captures 1	0	the domain or discourse goal motivating the segment 2	0	0	0
E95-1033	J86-3001	1995	We shall illustrate the linguistic aspects of word actor-based parsing by introducing the basic data structures for text-level anaphora as acquaintances of specific word actors, and then turn to the general message-passing protocol that accounts for intraas well as inter-sentential anaphora	0	Our exposition builds on the well-known focusing mechanism <REF>Sidner, 1983</REF>; <TREF>Grosz and Sidner, 1986</TREF>	0	Accordingly, we distinguish each sentences unique focus, a complementary list of alternate potential loci, and a history list composed of discourse elements not in the list of potential loci, but occurring in previous sentences of the current discourse segment	0	These data structures are realized as acquaintances of sentence delimiters to restrict the search space beyond the sentence to the relevant word actors	0	0	0
W00-0310	J86-3001	2000	Further, it embodies and extends theoretical work on intonational meaning in a more general, robust and rigorous way than earlier CTS systems, in an architecture that reflects compositional aspects of dialogue and intonation interpretation	0	2 Theoretical Foundations In this work, we implement and extend the compositional theory of intonational meaning proposed by Pierrehumbert and Hirschberg 1986; 1990, who sought to identify correspondences between the Bell Laboratories, Lucent Technologies 600 Mountain Avenue Murray Hill, NJ 07974 USA chn I j enccresearch, bell-labs, com <TREF>Grosz and Sidner 1986</TREF> computational model of discourse interpretation and Pierrehumberts prosodic grammar for <REF>American English 1980</REF>	0	In the present work, certain aspects of the original theories are modified and adapted to the architecture of the dialogue system in which the CTS component is embedded	0	Below, we present the important fundamental definitions and principles of intonation underlying our CTS system	0	0	0
A92-1040	J86-3001	1992	Co-operative dialogue managemeut, therefore, requires the construction and maintenance of an interactional model: ie a model which specifies the layers of structure which can be distinguished in dialogues	0	<REF>Following Grosz and Sidner 1986</REF> we distinguish linguistic structure, attentional, or belief structure, and intelltionM structure	0	Intentional structure is further differentiated into dialogue structure and task structure <REF>Bunt, 1989</REF>	0	tiowever, rather than using a unitary model where these layers are given as a single structured representation, we have adopted a distributed model where these layers are distributed across a number of modules	0	0	0
P91-1025	J86-3001	1991	1987 for discussions of this parameter	0	llThis parameter may be tied to the intentional aspect of discourse as proposed by <TREF>Grosz and Sidner 1986</TREF>	0	See, eg, <REF>Scha and Polanyi 1988</REF> and <REF>Hobbs 1990</REF> for discourse structure models	0	guage since languages differ in the concepts and real-world entities for which they have words and grammatical constructs	0	0	0
P91-1025	J86-3001	1991	It captures the linguistically significant parameters in the current state of the on-going discourse, s and is especially useful for finding functionally equivalent referring expressions between the source and target languages	0	reference time  the time pivot of the linguistic SOur characterization of the context of utterance draws on a number of existing approaches to discourse representation and discourse processing, most notably those of <TREF>Grosz and Sidner 1986</TREF>, Discourse Representation Theory <REF>Kamp 1981</REF>, <REF>Helm 1982</REF>, Situation Semantics <REF>Barwise and Perry 1983</REF>, <REF>Gawron and Peters 1990</REF>, and Linguistic Discourse Model <REF>Scha and Polanyi 1988</REF>	0	<REF>Lewis 1979</REF> discussed a number of such parameters in a logical framework	0	7Different forms of referring expressions eg pronouns, demonstratives and surface structures ie syntactic and 196 description then s  point of view  the individual from whose viewpoint a situation is described   attentional state -the entities currently in the focus and center of attention   discourse structural context  where the utterance is in the structure of the current discourse I z The specific UTTERANCE SITUATION contains information about those parameters whose values support indexical references and deixes: eg, information about the speaker, hearers, the time and location of the utterance, the perceptually salient context, etc The FTP example text above describes a situation in which a person is typing commands to a computer and it is displaying various things	0	0	0
W97-1408	J86-3001	1997	A context set is defined as the set of entities the addressee is currently assumed to be attending to the contrast set is the same except to the intended referent; an equivalent term is the set of potential distractors <REF>McDonald, 1981</REF>	0	This is similar to the set of entities in the focus spaces of the discourse focus stack in Grosz and Sidners theory of discourse structure <REF>Grosz, Sidner, 1986</REF>	0	The existing algorithms attempt to identify the intended referent by determining a set of descriptors attributed to that referent, that is, a set of attributes	0	Some algorithms also include descriptors in the description that are attributed to other entities related to the original referent, that is, relations from the point of view of the intended referent	0	0	0
W99-0113	J86-3001	1999	In particular: the grammatical hierarchy with subjects ranking higher than objects Grosz, <REF>Joshi, Weinstein 1983</REF>, topic or empathy marking Kameyama 198,5, surface order position 111 <REF>Rainbow, 1993</REF> or grammatical function <REF>Brennan, Friedman and Pollard 1987</REF> of the encoding of discourse entities in the immediately preceding segment	0	<REF>Roberts 1998</REF> argues that C0 is an unordered setof backward-looking centers in terms of classical Discourse Representation Theory notions of familiarity, compatibility and logical accessibility <REF>Kamp 1981</REF>, <REF>Helm 1982</REF>, <REF>Kamp and Reyle 1993</REF>, <REF>Asher 1993</REF>, with an additional constraint that the set of discourse referents are attentionally accessible, a notion taken from <TREF>Grosz and Sidner 1986</TREF>	0	Under Roberts treatment, the set of preferred centers, takes the place of the original C6	0	<REF>Walker 1998</REF> also replaces a unique Ct with a set of possible backward looking centers computed from a set of possible forward looking centers using agreement features, selection constraints of the verb and contra-indexing conditions	0	0	0
J05-2005	J86-3001	2005	the discussion in Marcu 2000	0	Whereas some argue that discourse segments should be prosodic units <REF>Hirschberg and Nakatani 1996</REF>, others argue for intentional units <TREF>Grosz and Sidner 1986</TREF>, phrasal units <REF>Lascarides and Asher 1993</REF>; <REF>Longacre 1983</REF>; <REF>Webber et al 1999</REF>, or sentences <REF>Hobbs 1985</REF>	0	For our database, we mostly adopted a clause-unit-based definition of discourse segments	0	We chose this method of segmenting discourse because it was easy to use	0	0	0
J05-2005	J86-3001	2005	Going beyond the question of how different informational-level accounts can be compatible with each other, <REF>Moser and Moore 1996</REF> discuss the compatibility of rhetorical structure theory RST <REF>Mann and Thompson 1988</REF> with the theory of <TREF>Grosz and Sidner 1986</TREF>	0	However, note that <REF>Moser and Moore 1996</REF> focus on the question of how compatible the claims are that <REF>Mann and Thompson 1988</REF> and <TREF>Grosz and Sidner 1986</TREF> make about intentional-level discourse structure	0	In this article, we aim to develop an easy-to-code representation of informational relations that hold between sentences or other nonoverlapping segments in a discourse monologue	0	We describe an account with a small number of relations in order to achieve more generalizable representations of discourse structures; however, the number is not so small that informational structures that we are interested in are obscured	0	0	0
J05-2005	J86-3001	2005	As a consequence, Knott argues, elaboration relations would be better described in terms of focus structures cf	0	<TREF>Grosz and Sidner 1986</TREF>, which Knott argues are less constrained, than in terms of rhetorical relations cf	0	<REF>Hobbs 1985</REF>; <REF>Mann and Thompson 1988</REF>, which Knott argues are more constrained	0	This hypothesis makes testable empirical claims: Elaboration relations should in some way pattern differently from other coherence relations	0	0	0
J05-2005	J86-3001	2005	contr  contrast ; expv  violated expectation ; ce  causeeffect ; none  no coher e nce re l a t i o n ; gen  generalization ; cond  condition ; examp  example ; ts  temporal s equence ; attr  attribution ; elab  elaboration ; sim  similarity  Annotator 2 Annotator 1 contr e xpv ce none gen c ond e xamp ts attr elab same sim Sum P er centage contr 383 11 0 3 4 0 0 0 2 0 0 0 0 430 447 expv 4 113 0 7 0 0 0 0 0 0 0 0 124 129 ce 0 0 446 14 0 0 0 0 0 5 0 0 465 483 none 66 24 42 0 0 2 2 7 1 6 6 467 1 6 4 715 743 gen 0 0 0 1 21 0 0 0 0 1 0 0 2 3 024 cond 0 0 0 2 0 127 0 1 0 1 0 0 131 136 examp 0 0 1 1 8 0 0 219 0 0 3 0 0 241 251 ts 1 1 2 7 0 0 0 214 0 1 0 0 226 235 attr 0 0 0 5 0 0 0 0 1,387 0 0 0 1,392 1447 elab 0 0 17 260 0 3 0 3 0 3,913 1 0 4,197 4363 same 0 0 2 5 0 0 0 1 0 0 530 1 539 560 sim 7 0 3 4 3 0 0 0 6 0 0 3 1,074 1,136 1181 Sum 461 149 513 396 21 132 246 243 1,393 4,391 535 1,139 Per c entage 479 155 530 412 020 137 256 253 1450 4560 556 1180 261 Computational Linguistics Volume 31, Number 2 3	0	Data Structures for Representing Coherence Relations In order to represent the coherence relations between discourse segments in a text, most accounts of discourse coherence assume tree structures <REF>Britton 1994</REF>; <REF>Carlson, Marcu, and Okurowski 2002</REF>; Corston-<REF>Oliver 1998</REF>; <REF>Longacre 1983</REF>; <TREF>Grosz and Sidner 1986</TREF>; <REF>Mann and Thompson 1988</REF>; <REF>Marcu 2000</REF>; <REF>Polanyi and Scha 1984</REF>; <REF>Polanyi 1996</REF>; <REF>Polanyi et al 2004</REF>; van <REF>Dijk and Kintsch 1983</REF>; <REF>Walker 1998</REF>; some accounts do not allow crossed dependencies but appear to allow nodes with multiple parents <REF>Lascarides and Asher 1991</REF>	0	3 Other accounts assume less constrained graphs that allow crossed dependencies as well as nodes with multiple parents eg , <REF>Bergler 1991</REF>; <REF>Birnbaum 1982</REF>; <REF>Danlos 2004</REF>; <REF>Hobbs 1985</REF>; <REF>McKeown 1985</REF>; <REF>Reichman 1985</REF>; <REF>Zukerman and McConachy 1995</REF>; for dialogue structure, Penstein <REF>Rose et al 1995</REF>	0	Some proponents of tree structures assume that trees are easier to formalize and to derive than less constrained graphs <REF>Marcu 2000</REF>; <REF>Webber et al 2003</REF>	0	0	0
J05-2005	J86-3001	2005	These approaches differ with respect to what kinds of discourse structure they are intended to represent	0	Some accounts aim to represent the intentional-level structure of a discourse; in these accounts, coherence relations reflect how the role played by one discourse segment with respect to the interlocutors intentions relates to the role played by another segment eg , <TREF>Grosz and Sidner 1986</TREF>	0	Other accounts aim to represent the informational structure of a discourse; in these accounts, coherence relations reflect how the meaning conveyed by one discourse segment relates to the meaning conveyed by another discourse segment eg , <REF>Hobbs 1985</REF>; <REF>Marcu 2000</REF>; <REF>Webber et al 1999</REF>	0	Furthermore, accounts of discourse structure vary greatly with respect to how many discourse relations they assume, ranging from 2 <TREF>Grosz and Sidner 1986</TREF> to over 400 different coherence relations reported in Hovy and  Computer Laboratory and Genetics Department, Cambridge, CB3 0FD, UK E-mail: FlorianWolfclcamacuk  Department of Brain and Cognitive Sciences, Cambridge, MA 02139	0	0	0
J05-2005	J86-3001	2005	This means that different informational-level-based taxonomies can be compatible with each other; they differ with respect to how detailed or fine-grained a manner they represent informational structures of texts	0	Going beyond the question of how different informational-level accounts can be compatible with each other, <REF>Moser and Moore 1996</REF> discuss the compatibility of rhetorical structure theory RST <REF>Mann and Thompson 1988</REF> with the theory of <TREF>Grosz and Sidner 1986</TREF>	0	However, note that <REF>Moser and Moore 1996</REF> focus on the question of how compatible the claims are that <REF>Mann and Thompson 1988</REF> and <TREF>Grosz and Sidner 1986</TREF> make about intentional-level discourse structure	0	In this article, we aim to develop an easy-to-code representation of informational relations that hold between sentences or other nonoverlapping segments in a discourse monologue	0	0	0
J05-2005	J86-3001	2005	Other accounts aim to represent the informational structure of a discourse; in these accounts, coherence relations reflect how the meaning conveyed by one discourse segment relates to the meaning conveyed by another discourse segment eg , <REF>Hobbs 1985</REF>; <REF>Marcu 2000</REF>; <REF>Webber et al 1999</REF>	0	Furthermore, accounts of discourse structure vary greatly with respect to how many discourse relations they assume, ranging from 2 <TREF>Grosz and Sidner 1986</TREF> to over 400 different coherence relations reported in Hovy and  Computer Laboratory and Genetics Department, Cambridge, CB3 0FD, UK E-mail: FlorianWolfclcamacuk  Department of Brain and Cognitive Sciences, Cambridge, MA 02139	0	E-mail: egibsonmitedu	0	Submission received: 15th <REF>June 2004</REF>; Revised submission received: 5th <REF>September 2004</REF>; Accepted for publication: 23rd <REF>October 2004</REF>  2005 Association for Computational Linguistics Computational Linguistics Volume 31, Number 2 Maier 1995	0	0	0
J97-1002	J86-3001	1997	A typical transaction is a subdialogue that gets the route follower to draw one route segment on the map	0	Transactions are made up of conversational games, which are often also called dialogue games <REF>Carlson 1983</REF>; <REF>Power 1979</REF>, interactions <REF>Houghton 1986</REF>, or exchanges <REF>Sinclair and Coulthard 1975</REF>, and show the same structure as Grosz and Sidners discourse segments 1986 when applied to task-oriented dialogue	0	All forms of conversational games embody the observation that, by and large, questions are followed by answers, statements by acceptance or denial, and so on	0	Game analysis makes use of this regularity to differentiate between initiations, which set up a discourse expectation about what will follow, and responses, which fulfill those expectations	0	0	0
P98-2145	J86-3001	1998	The global discourse structure of a text can be constructed by relating the discourse segments with each other	0	Therefore, identifying segment boundaries in a text is considered as a first step to construct the discourse structure<TREF>Grosz and Sidner, 1986</TREF>	0	The use of surface linguistic cues in a text for identification of segment boundaries has been extensively researched, since it is impractical to assume the use of world knowledge for discourse analysis of real texts	0	Among a variety of surface cues, lexical cohesion<REF>Halliday and Hasan, 1976</REF>, the surface relationship among words that are semantically similar, has recently received much attention and has been widely used for text segmentation<REF>Morris and Hirst, 1991</REF>; <REF>Kozima, 1993</REF>; <REF>Hearst, 1994</REF>; <REF>Okumura and Honda, 1994</REF>	0	0	0
W06-2708	J86-3001	2006	Each tasks structure includes one or more of the following: giving definitions, formulating a question, obtaining the student answer and remediation by the tutor	0	Generally speaking, the structure of tutorial dialogue is governed by the task structure just as in task-oriented dialogue <TREF>Grosz and Sidner, 1986</TREF>	0	However, the specific annotation structure differs depending on the tutoring method	0	In our basic electricity and electronics domain, a tutorial session consists of a set of teach segments, and within each segment a number of task segments	0	0	0
W02-0105	J86-3001	2002	The discussion of context-free grammars naturally led us to pushdown automata which provided a nice contrast to the Turing machines we studied earlier in the course	0	And, having thus introduced stacks, we then investigated the <TREF>Grosz and Sidner 1986</TREF> stack-based theory of discourse structure, showing that language structures exist at granularities beyond the sentence level	0	Statistical language processing 6 lectures We began this unit by considering word frequency distributions, and in particular, Zipfs law  note that our having studied power-law distributions in the Web unit greatly facilitated this discussion	0	In fact, because we had previously investigated generative models for the Web, it was natural to consider <REF>Millers 1957</REF> monkeys model which demonstrates that very simple generative models can account for Zipfs law	0	0	0
P03-1071	J86-3001	2003	We tried to restrict ourselves to features whose inclusion is motivated by previous work pauses, speech rate and added features that are specific to multi-speaker speech overlap, changes in speaker activity	0	52 Features Cue phrases: previous work on segmentation has found that discourse particles like now, well provide valuable information about the structure of texts <TREF>Grosz and Sidner, 1986</TREF>; <REF>Hirschberg and Litman, 1994</REF>; <REF>Passonneau and Litman, 1997</REF>	0	We analyzed the correlation between words in the meeting corpus and labeled topic boundaries, and automatically extracted utterance-initial cue phrases9 that are statistically correlated with boundaries	0	For every word in the meeting corpus, we counted the number of its occurrences near any topic boundary, and its number of appearances overall	0	0	0
P03-1071	J86-3001	2003	We opted for a linear representation of discourse, since finer-grained discourse structures eg	0	<TREF>Grosz and Sidner, 1986</TREF> are generally considered to be difficult to mark reliably	0	Subjects were asked to mark each speaker change potential boundary as either boundary or non-boundary	0	In the resulting annotation, the agreed segmentation based on majority 1While it would be desirable to have a broader variety of meetings, we hope that experiments on this corpus will still carry some generality	0	0	0
C04-1034	J86-3001	2004	x will one one will	0	3 The DAR Algorithm 31 Search Space and DE lists dar presupposes the discourse structure described by <TREF>Grosz and Sidner 1986</TREF>	0	The minimal discourse unit is the utterance U Paragraphs correspond to discourse segments in texts	0	In dialogues discourse segments were manually marked se section 4	0	0	0
W00-1425	J86-3001	2000	1 Discourse coherence and aggregation hi NLG, theories based on domain-independent rhetorical relations, in particular, Rhetorical Structure Theory <REF>Mann and Thompson, 1987</REF>, are often used in text planning, whose task is to select the relevant information to be expressed and organise it into a hierarchical structure which captures certain discourse preferences such as preferences for the use of rhetorical relations	0	In the theory of discourse structure developed by <TREF>Grosz and Sidner 1986</TREF>, each discourse segment exhibits two types of coherence: local coherence among utterances inside the segment, and global coherence between this segment and other discourse segments	0	Discourse segments are connected by either a dominaTzce relation or a satisfaction-precedence relation	0	There has been an effort to synthesise tile two accounts of discourse structure	0	0	0
P97-1025	J86-3001	1997	7; t1  1u 22	0	IgroupF,  A subgroupU, F,  A unitF, 1,  A unitU, lt,  : 1  It Reason Hyp Def-subgroup 7 Def-unit 7 ::1 9 Hyp Def-unit 7 11 Def-subset 8 11 Def-subset 8 9 Def-group 7 Def-sohition 12 13 14 15 Def-unit 7 13 Def-unit 7 Def-soluti0n 13 17 18 15 Th-solution 17 16 19 Choice 10 20 Ded 7:21 Figure 3: Abstracted Proof about Unit Element of Subgroups of a discourse into an attentional hierarchy, since following the theory of Grosz and Sidner <TREF>Grosz and Sidner, 1986</TREF>, there is a one-to-one correspondence between the intentional hierarchy and the attentional hierarchy	0	In this section, we illustrate the attentional hierarchy with the help of an example, which will be used to discuss reference choices later	0	The input proof in Figure 3 is an ND style proof for the following theorem2: Theorem: Let F be a group and U a subgroup of F If i and lv are unit elements of F and U respectively, then 11u	0	0	0
P97-1025	J86-3001	1997	An explicit reference to a premise or an inference method is not restricted to a nominal phrase, as opposed to many of the treatments of subsequent references found in the literature	0	Despite this difference, the choices to be made here have much in common with the choices of subsequent references discussed in more general frameworks <REF>Reichman, 1985</REF>; <TREF>Grosz and Sidner, 1986</TREF>; <REF>Dale, 1992</REF>: they depend on the availability of the object to be referred to in the context and are sensitive to the segmentation of a context into an attentional hierarchy	0	Therefore, we have first to devise an architecture for natural language generation that facilitates a natural and effective segmentation of discourse	0	The 190 basic idea is to distinguish between language production activities that effect the global shift of attention, and language production activities that involve only local attentional movement	0	0	0
P97-1025	J86-3001	1997	Concretely, PROVERB uses an architecture that models text generation as a combination of hierarchical planning and focus-guided navigation	0	Following <TREF>Grosz and Sidner, 1986</TREF> we further assume that every posting of a new task by the hierarchical planning mechanism creates new attentional spaces	0	Based on this segmentation, PROVERB makes reference choices according to a discourse theory adapted from Reichman <REF>Reichman, 1985</REF>; <REF>Huang, 1990</REF>	0	2 The System PROVERB PROVERB is a text planner that verbalizes natural deduction ND style proofs <REF>Gentzen, 1935</REF>	0	0	0
P94-1006	J86-3001	1994	In SDRT, on the other hand, not all discourse relations induce subordination, and so there is more scope for different discourse relations holding simultaneously in a consistent KB	0	Grosz and Sidners 1986 model of discourse interpretation is one where the same discourse elements are related simultaneously on the informational and intentional levels	0	But using their framework to model 1 is not straightforward	0	<REF>As Grosz and Sidner 1990</REF> point out: any model or theory of the communication situation must distinguish among beliefs and intentions of different agents, but theirs does not	0	0	0
P89-1016	J86-3001	1989	Although text processing systems are explicitly designed to analyze noninteractive discourse, they fail to provide the needed solutions for analyzing noninteractive speech	0	These systems currently have no means for identifying basic discourse elaborations and, to date, they have not incorporated discourse structural cues which could be helpful in signaling the relationship of discourse segments <TREF>Grosz  Sidner, 1986</TREF>; <REF>Litman  Allen, 1989</REF>; <REF>Oviatt  Cohen, 1989</REF>; <REF>Reichman, 1978</REF>	0	In addition, they are restricted to declarative sentences	0	One recent text analysis system called Tacitus Hobbs, <REF>Stickel, Martin  Edwards, 1988</REF> appears uniquely capable of handling some of the elaborative phenomena found in our corpus	0	0	0
P07-1128	J86-3001	2007	The problem is important for two reasons: First, empirical analysis has shown that annotating transcripts with semantic information eg , topics enables users to browse and find information from multimedia archives more efficiently <REF>Banerjee et al , 2005</REF>	0	Second, because the automatically generated segments make up for the lack of explicit orthographic cues eg , story and paragraph breaks in conversational speech, dialogue segmentation is useful in many spoken language understanding tasks, including anaphora resolution <TREF>Grosz and Sidner, 1986</TREF>, information retrieval eg , as input for the TREC Spoken Document Retrieval SDR task, and summarization <REF>Zechner and Waibel, 2000</REF>	0	This study therefore aims to explore whether a Maximum Entropy MaxEnt classifier can integrate multiple knowledge sources for segmenting recorded speech	0	In this paper, we first evaluate the effectiveness of features that have been proposed in previous work, with a focus on features that can be extracted automatically	0	0	0
P97-1014	J86-3001	1997	The data in both studies reveal that only a weak correlation between the SHIFT transitions and segment boundaries can be observed	0	This finding precludes a reliable prediction of segment boundaries based on the occurrence of 1 Our notion of referential discourse segment should not be confounded with the intentional one originating from <TREF>Grosz  Sidner 1986</TREF>, for reasons discussed in Section 2	0	104 SHIFTS and vice versa	0	In order to accommodate to these empirical results divergent solutions are proposed	0	0	0
P97-1014	J86-3001	1997	 RETAIN R ROUGH-SHIFT RS cu	0	Table h Transition Types As a working hypothesis, for the purposes of anaphora resolution we subscribe to Walkers model, in particular to that part which casts doubt on the hypothesized dependency of the attentional from the intentional structure of discourse <TREF>Grosz  Sidner, 1986</TREF>, p 180	0	We diverge from <REF>Walker 1996a</REF>, however, in that we propose an alternative to the caching mechanism, which we consider to be methodologically more parsimonious and, at least, to be equally effective for an elaboration of this claim, cf	0	Section 6	0	0	0
J95-1002	J86-3001	1995	RST was attractive for the IMAGENE project because of its ability to represent the hierarchical structure of text with rhetorical structures that matched the level of analysis required for the study of expressions of procedural relations	0	There is considerable debate in the field of discourse analysis concerning the relative importance of intentional structure and rhetorical relations eg , <TREF>Grosz and Sidner 1986</TREF>; <REF>Moore and Pollack 1992</REF>, most systems focusing on one or the other	0	The current study has conflated them, as the instructional texts have not tended to display the complex intentional structure common to persuasive texts and interactive discourses <REF>Vander Linden 1993b</REF>	0	Finally, RST has been used by many researchers for the purpose of text generation eg , <REF>Moore and Paris 1988</REF>; <REF>Hovy and McCoy 1989</REF>; <REF>Scott and Souza 1990</REF>; R6sner 33 Computational Linguistics Volume 21, Number 1 Precondition  1 Instruct  1 2 Remove uence 3 Grasp 4 Pull Purpose 151 Return 6 Place Figure 1 The RST representation of the Remove-Phone text	0	0	0
W04-2323	J86-3001	2004	The BDC corpus contains transcribed monologues by speakers who were instructed to perform a series of direction-giving tasks	0	The monologues were subsequently annotated by a group of subjects according to the <TREF>Grosz and Sidner 1986</TREF> theory of discourse structure	0	This theory provides a foundation for hierarchical segmentation of discourses into constituent parts	0	Some of the subjects were experts in discourse theory and others were naive annotators	0	0	0
W04-2323	J86-3001	2004	When high recall is preferred, methods requiring a majority are preferable to those that demand full consensus among annotators	0	The linguistic structure of a discourse is composed of utterances that exhibit meaningful hierarchical relationships <TREF>Grosz and Sidner, 1986</TREF>	0	Automatic segmentation of discourse forms the basis for many applications, from information retrieval and text summarization to anaphora resolution <REF>Hearst, 1997</REF>	0	These automatic methods, usually based on supervised machine learning techniques, require a manually annotated corpus of data for training	0	0	0
H89-2012	J88-1003	1989	Preprocessing the Corpus with a Part of Speech Tagger Phrasal verbs involving the preposition to raise an interesting problem because of the possible confusion with the infinitive marker to	0	We have found that if we first tag every word in the corpus with a part of speech using a method such as <REF>Church 1988</REF> or <TREF>DeRose 1988</TREF>, and then measure associations between tagged words, we can identify interesting contrasts between verbs associated with a following preposition toin and verbs associated with a following infinitive marker toto	1	Part of speech notation is borrowed from <REF>Francis and Kucera 1982</REF>; m  preposition; to  infinitive marker; vb  bare verb; vbg  verb  ing; vbd  verb  ed; vbz  verb  s; vbn  verb  en	0	The score identifies quite a number of verbs associated in an interesting way with to; restricting our attention to pairs with a score of 30 or more, there are 768 verbs associated with the preposition toin and 551 verbs with the infinitive marker toto	0	6	1
P97-1029	J88-1003	1997	Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora	0	There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, eg, <REF>Church, 1988</REF>; <REF>Cutting et al , 1992</REF>; <TREF>DeRose, 1988</TREF>, constraint-based techniques <REF>Karlsson et al , 1995</REF>; <REF>Voutilainen, 1995b</REF>; Voutilainen, Heikkil/i, and <REF>Anttila, 1992</REF>; <REF>Voutilainen and Tapanainen, 1993</REF>; <REF>Oflazer and KuruSz, 1994</REF>; <REF>Oflazer and Till 1996</REF> and transformation-based techniques <REF>Brilt, 1992</REF>; <REF>Brill, 1994</REF>; <REF>Brill, 1995</REF>	1	This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements	0	The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item	0	6	1
W02-0102	J88-1003	2002	HMMs have long been central in speech recognition <REF>Rabiner, 1989</REF>	0	Their application to partof-speech tagging <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF> kicked off the era of statistical NLP, and they have found additional NLP applications to phrase chunking, text segmentation, word-sense disambiguation, and information extraction	1	The algorithm is also important to teach for pedagogical reasons, as the entry point to a family of EM algorithms for unsupervised parameter estimation	0	Indeed, it is an instructive special case of 1 the inside-outside algorithm for estimation of probabilistic context-free grammars; 2 belief propagation for training singly-connected Bayesian networks and junction trees <REF>Pearl, 1988</REF>; <REF>Lauritzen, 1995</REF>; 3 algorithms for learning alignment models such as weighted edit distance; 4 general finitestate parameter estimation <REF>Eisner, 2002</REF>	0	6	1
W94-0111	J88-1003	1994	1; they closely replicate Brills results 1993b, page 96, allowing for the fact that his tests used more templates, including templates like if one of the three previous tags is A	0	Brills results demonstrate that this approach can outperform the Hidden Markov Model approaches that are frequently used for part-of-speech tagging <REF>Jelinek, 1985</REF>; <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF>; <REF>Cutting et al , 1992</REF>; <REF>Weischedel et al , 1993</REF>, as well as showing promise for other applications	1	The resulting model, encoded as a list of rules, is also typically more compact and for some purposes more easily interpretable than a table of HMM probabilities	0	An Incremental Algorithm It is worthwhile noting first that it is possible in some circumstances to significantly speed up the straightforward algorithm described above	0	1	3
W96-0101	J88-1003	1996	We describe a part-of-speech tagger built on these principles and we suggest a methodology for developing an adequate training corpus	0	In the part-of-speech hterature, whether taggers are based on a rule-based approach <REF>Klein and Simmons, 1963</REF>, <REF>Brill, 1992</REF>, <REF>Voutilainen, 1993</REF>, or on a statistical one <REF>Bahl and Mercer, 1976</REF>, <REF>Leech et al , 1983</REF>, <REF>Merialdo, 1994</REF>, <TREF>DeRose, 1988</TREF>, <REF>Church, 1989</REF>, <REF>Cutting et al , 1992</REF>, there is a debate as to whether more attention should be paid to lexical probabilities rather than contextual ones	1	<REF>Church, 1992</REF> claims that part-of-speech taggers depend almost exclusively on lexical probabilities, whereas other researchers, such as Voutilainen <REF>Karlsson et al , 1995</REF> argue that word ambiguities vary widely in function of the specific text and genre	0	Indeed, part of Churchs argument is relevant if a system is based on a large corpus such as the Brown corpus Francis and Kuera, 1982 which represents one million surface forms of morpho-syntacticaJly disambiguated words from a range of balanced texts	0	6	1
W97-0127	J88-1003	1997	The work is based on some similarity metrics	0	 Bahl, <REF>Brown, DeSouza and Mercer, 1989</REF>; Brown, Pietra, deSouza and Mercer,1992; <REF>Chang, 1995</REF>; DeRose,1988; <REF>Garside, 1987</REF>; <REF>Hughes, 1994</REF>; Jardino,1993; <REF>Jelinek, Mercer, and Roukos, 1990b</REF>; Wu, <REF>Wang, Yu and Wang, 1995</REF>; <REF>Magerman, 1994</REF>; <REF>McMahon, 1994</REF>; <REF>McMahon, 1995</REF>; <REF>Pereira, 1992</REF>; <REF>Resnik, 1992</REF>; <REF>Zhao, 1995</REF>; <REF>Brill 1993</REF> and <REF>Pop 1996</REF> present a transformation-based tagging	1	Before a part-of-speech tagger can be built, the word classifications are performed to help us choose a set of part-of-speech	0	They use the sum of two relative entropies obtained from neighboring words as the similarity metric to compare two words	0	6	1
C96-2114	J88-1003	1996	The training is performed on ambiguity classes and not on individual word tokens	0	<REF>Kallgren 1996</REF> gives a more covering description of how XPOST is used on the Swedish material and also sketches the major differences between this algorithm and some others used for tagging, such as PARTS <REF>Church 1988</REF> and VOLSUNGA <TREF>DeRose 1988</TREF>	1	A characteristic tbature of the SUC is its high number of different tags	0	The number of part-ofspeech tags used in the SUC is 21	0	2	1
H89-2014	J88-1003	1989	Several workers have addressed the problem of tagging text	0	Methods have ranged from locally-operating rules <REF>Greene and Rubin, 1971</REF>, to statistical methods <REF>Church, 1989</REF>; <TREF>DeRose, 1988</TREF>; <REF>Garside, Leech and Sampson, 1987</REF>; <REF>Jelinek, 1985</REF> and back-propagation <REF>Benello, Mackie and Anderson, 1989</REF>; <REF>Nakamura and Shikano, 1989</REF>	1	The statistical methods can be described in terms of Markov models	0	States in a model represent categories clc n is the number of different categories used	0	6	1
P89-1015	J88-1003	1989	Indeed, recent increased interest in the problem of disambiguating lexical category in English has led to significant progress in developing effective programs for assigning lexical category in unrestricted text	0	The most successful and comprehensive of these are based on probabilistic modeling of category sequence and word category <REF>Church 1987</REF>; <REF>Garside, Leech and Sampson 1987</REF>; <TREF>DeRose 1988</TREF>	1	These stochastic methods show impressive performance: Church reports a success rate of 95 to 99, and shows a sample text with an error rate of less than one percent	1	What may seem particularly surprising is that these methods succeed essentially without reference to syntactic structure; purely surface lexical patterns are involved	1	4	2
J93-1001	J88-1003	1993	Part-of-Speech Tagging Many of the very same methods are being applied to problems in natural language processing by many of the very same researchers	0	As a result, the empirical approach has been adopted by almost all contemporary part-of-speech programs: <REF>Bahl and Mercer 1976</REF>, <REF>Leech, Garside, and Atwell 1983</REF>, <REF>Jelinek 1985</REF>, <REF>Deroualt and Merialdo 1986</REF>, <REF>Garside, Leech, and Sampson 1987</REF>, <REF>Church 1988</REF>, <TREF>DeRose 1988</TREF>, <REF>Hindle 1989</REF>, Kupiec 1989, 1992, Ayuso et al	1	1990, de<REF>Marcken 1990</REF>, <REF>Karlsson 1990</REF>, <REF>Boggess, Agarwal, and Davis 1991</REF>, <REF>Merialdo 1991</REF>, and <REF>Voutilainen, Heikkila, and Anttila 1992</REF>	0	These programs input a sequence of words, eg, The chair will table the motion, and output a sequence of part-of-speech tags, eg, art noun modal verb art noun	0	6	1
P07-2053	J88-1003	2007	4 Concluding remarks Though there can be little doubt that the ruling system of bakeoffs actively encourages a degree of oneupmanship, our paper and our software are not offered in a competitive spirit	0	As we said at the out211 set, we dont necessarily believe HunPos to be in any way better than TnT, and certainly the main ideas have been pioneered by <TREF>DeRose 1988</TREF>, <REF>Church 1988</REF>, and others long before this generation of HMM work	1	But to improve the results beyond what a basic HMM can achieve one needs to tune the system, and progress can only be made if the experiments are end to end replicable	0	There is no doubt many other systems could be tweaked further and improve on our results what matters is that anybody could now also tweak HunPos without any restriction to improve the state of the art	0	5	2
E91-1025	J88-1003	1991	54 29 3 43 40 4 97 69 7 These results are remarkably good, in spite of the fact that many other systems are reported to reach an accuracy of 9697	0	<REF>Garside 1987</REF>, <REF>Marshall 1987</REF>, <TREF>DeRose 1988</TREF>, <REF>Church 1988</REF>, <REF>Ejerhed 1987</REF>, O<REF>Shaughnessy 1989</REF>	0	Those systems, however, all use heavier artillery than MorP, that has been deliberately restricted in accordance with the hypotheses presented above	1	This restrictiveness concerns both the size of the lexicon and the ways of carrying out disambiguation	1	1	3
J95-2004	J88-1003	1995	Although finite-state machines have been used for part-of-speech tagging <REF>Tapanainen and Voutilainen 1993</REF>; <REF>Silberztein 1993</REF>, none of these approaches has the same flexibility as stochastic techniques	1	Unlike stochastic approaches to part-of-speech tagging <REF>Church 1988</REF>; <REF>Kupiec 1992</REF>; <REF>Cutting et al 1992</REF>; <REF>Merialdo 1990</REF>; <TREF>DeRose 1988</TREF>; <REF>Weischedel et al 1993</REF>, up to now the knowledge found in finite-state taggers has been handcrafted and was not automatically acquired	1	<REF>Recently, Brill 1992</REF> described a rule-based tagger that performs as well as taggers based upon probabilistic models and overcomes the limitations common in rule-based approaches to language processing: it is robust and the rules are automatically ac Mitsubishi Electric Research Laboratories, 201 Broadway, Cambridge, MA 02139	0	E-mail: rocbe/schabesmerlcom	0	2	2
W97-0110	J88-1003	1997	Research on corpus-based natural language learning and processing is rapidly accelerating following the introduction of large on-line corpora, faster computers, and cheap storage devices	0	Recent work involves novel ways to employ annotated corpus in part of speech tagging <REF>Church 1988</REF> <REF>Derose 1988</REF> and the application of mutual information statistics on the corpora to uncover lexical information <REF>Church 1989</REF>	1	The goal of the research is the construction of robust and portable natural language processing systems	0	The wide range of topics available on the Internet calls for an easily adaptable information extraction system for different domains	0	6	1
W95-0101	J88-1003	1995	There has recently been a great deal of work exploring methods for automatically training part of speech taggers, as an alternative to laboriously hand-crafting rules for tagging, as was done in the past <REF>Klein and Simmons, 1963</REF>; <REF>Harris, 1962</REF>	0	Almost all of the work in the area of automatically trained taggers has explored Markov-model based part of speech tagging <REF>Jelinek, 1985</REF>; <REF>Church, 1988</REF>; <REF>Derose, 1988</REF>; <REF>DeMarcken, 1990</REF>; <REF>Cutting et al , 1992</REF>; <REF>Kupiec, 1992</REF>; <REF>Charniak et al , 1993</REF>; <REF>Weischedel et al , 1993</REF>; <REF>Schutze and Singer, 1994</REF>; <REF>Lin et al , 1994</REF>; <REF>Elworthy, 1994</REF>; <REF>Merialdo, 1995</REF>	1	2 For a Markov-model based tagger, training consists of learning both lexical probabilities Pwordltag and contextual probabilities Ptagiltagil tagi-n	0	Once trained, a sentence can be tagged by searching for the tag sequence that maximizes the product of lexical and contextual probabilities	0	6	1
J97-3003	J88-1003	1997	Unknown Words Unknown Common Words Unknown Proper Nouns Tagger Guesser Metrics Error Error Coverage Error Coverage HMM Xerox mean 17851643 30022169 37567270 10785563 63797113 s-error 0484710 0469922 1687396 0613745 1714969 HMM Cascade mean 12378716 21266264 36507909 7776456 64795969 s-error 0917656 0403957 2336381 0853958 2206457 Brill Brill mean 14688501 27411736 38998687 6439525 62160917 s-error 0908172 0539634 2627234 0501082 4010992 Brill Cascade mean 11327863 20986240 37933048 5548990 63816586 s-error 0761576 0480798 2353510 0561009 3775991 the Brown Corpus, we obtained the error rate mean 0 4003093 with the standard error deB0155599	0	This agrees with the results on the closed dictionary ie , without unknown words obtained by other researchers for this class of the model on the same corpus <REF>Kupiec 1992</REF>; <TREF>DeRose 1988</TREF>	1	The Brill tagger showed some better results: error rate mean 0 3327366 with the standard error deBO 123903	0	Although our primary goal was not to compare the taggers themselves but rather their performance with the guessing components, we attribute the difference in their performance to the fact that Brills tagger uses the information about the most likely tag for a word whereas the HMM tagger did not have this information and instead used the priors for a set of POS-tags ambiguity class	0	4	2
J94-2001	J88-1003	1994	A lot of effort has been devoted in the past to the problem of tagging text, ie assigning to each word the correct tag part of speech in the context of the sentence	0	Two main approaches have generally been considered: rule-based <REF>Klein and Simmons 1963</REF>; <REF>Brodda 1982</REF>; <REF>Paulussen and Martin 1992</REF>; <REF>Brill et al 1990</REF> probabilistic <REF>Bahl and Mercer 1976</REF>; <REF>Debili 1977</REF>; <REF>Stolz, Tannenbaum, and Carstensen 1965</REF>; <REF>Marshall 1983</REF>; <REF>Leech, Garside, and Atwell 1983</REF>; <REF>Derouault and Merialdo 1986</REF>; <TREF>DeRose 1988</TREF>; <REF>Church 1989</REF>; <REF>Beale 1988</REF>; <REF>Marcken 1990</REF>; <REF>Merialdo 1991</REF>; <REF>Cutting et al 1992</REF>	1	More recently, some work has been proposed using neural networks <REF>Benello, Mackie, and Anderson 1989</REF>; <REF>Nakamura and Shikano 1989</REF>	0	Multimedia Communications Department, Institut EURECOM, 2229 Route des Cretes, BP 193, 06904 Valbonne Cedex France; merialdoeurecomfr	0	6	1
J94-2001	J88-1003	1994	for evaluation at word level, choose the most probable tag for each word in the sentence argmax argmax Wi  t pti  t/W  t  pW, T T:tit where Wi is the tag assigned to word wi by the tagging procedure b in the context of the sentence W, We call this procedure Maximum Likelihood ML tagging	0	It is interesting to note that the most commonly used method is Viterbi tagging see <TREF>DeRose 1988</TREF>; <REF>Church 1989</REF> although it is not the optimal method for evaluation at word level	1	The reasons for this preference are presumably that:  Viterbi tagging is simpler to implement than ML tagging and requires less computation although they both have the same asymptotic complexity  Viterbi tagging provides the best interpretation for the sentence, which is linguistically appealing  ML tagging may produce sequences of tags that are linguistically impossible because the choice of a tag depends on all contexts taken together	1	However, in our experiments, we will show that Viterbi and ML tagging result in very similar performance	0	2	2
J01-2002	J88-1003	2001	Although methods for unsupervised training of HMMs do exist, training is usually done in a supervised way by estimation of the above probabilities from relative frequencies in the training data	0	The HMM approach to tagging is by far the most studied and applied <REF>Church 1988</REF>; <TREF>DeRose 1988</TREF>; <REF>Charniak 1993</REF>	1	In van <REF>Halteren, Zavrel, and Daelemans 1998</REF> we used a straightforward implementation of HMMs, which turned out to have the worst accuracy of the four competing methods	0	In the present work, we have replaced this by the TnT system we will refer to this tagger as HMM below	0	6	2
J95-3004	J88-1003	1995	<REF>Choueka and Lusignan 1985</REF> presented a system for the morphological tagging of large texts that is based on the short context of the word but also depends heavily on human interaction	0	Methods using the short context of a word in order to resolve ambiguity usually categorical ambiguity are very common in English and other languages <TREF>DeRose 1988</TREF>; <REF>Church 1988</REF>; <REF>Karlsson 1990</REF>	1	A system using this approach was developed by Levinger and Ornan in order to serve as a component in their project of morphological disambiguation in Hebrew <REF>Levinger 1992</REF>	0	The main resource, used by this system for disambiguation, is a set of syntactic constraints that were defined manually by the authors and followed two theoretical works that defined short context rules for Hebrew <REF>Pines 1975</REF>; <REF>Albeck 1992</REF>	0	6	1
J95-3004	J88-1003	1995	Most successful methods have followed speech recognition systems <REF>Jelinek, Mercer, and Roukos 1992</REF> and used large corpora to deduce the probability of each part of speech in the current context usually the two previous words--trigrams	0	These methods have reported performance in the range of 95-99 correct by word <TREF>DeRose 1988</TREF>; <REF>Cutting et al 1992</REF>; <REF>Jelinek, Mercer, and Roukos 1992</REF>; <REF>Kupiec 1992</REF>	1	The difference in performance is due to different evaluation methods, different tag sets, and different corpora	0	<REF>See Church 1992</REF> for a survey	0	2	1
P96-1010	J88-1003	1996	More precisely, assume that the word wh occurs in a sentence W  wlWkwn, and that w is a word we are considering substituting for it, yielding sentence W I Word w is then preferred over wk iff PW > PW, where PW and PW are the probabilities of sentences W and W f respectively	0	1 We calculate PW using the tag sequence of W as an intermediate quantity, and summing, over all possible tag sequences, the probability of the sentence with that tagging; that is: PW   PW, T T where T is a tag sequence for sentence W The above probabilities are estimated as is traditionally done in trigram-based part-of-speech tagging <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF>: PW,T  PWITPT  1  HPwiti HPt, lt,2t,l2 i i where T  tltn, and Ptitl-2ti-1 is the prob ability of seeing a part-of-speech tag tl given the two preceding part-of-speech tags ti-2 and ti-1	1	Equations 1 and 2 will also be used to tag sentences W and W  with their most likely part-of-speech sequences	0	This will allow us to determine the tag that 1To enable fair comparisons between sequences of different length as when considering maybe and may be, we actually compare the per-word geometric mean of the sentence probabilities	0	6	1
A92-1018	J88-1003	1992	More recently, Koskenniemi also used a rule-based approach implemented with finite-state machines <REF>Koskenniemi, 1990</REF>	0	Statistical methods have also been used eg , <TREF>DeRose, 1988</TREF>, <REF>Garside et al , 1987</REF>	1	These provide the capability of resolving ambiguity on the basis of most likely interpretation	1	A form of Markov model has been widely used that assumes that a word depends probabilistically on just its part-of-speech category, which in turn depends solely on the categories of the preceding two words	0	6	1
J96-2001	J88-1003	1996	Estimating the Lexical Priors for Rare Forms For a common form such as lopen walk a reasonable estimate of the lexical prior probabilities is the MLE, computed over all occurrences of this form	0	So, in the UdB corpus, lopen occurs 92 times as an infinitive and 43 times as a finite plural, so the MLE 1 Even models of disambiguation that make use of context, such as statistical n-gram taggers, often presume some estimate of lexical priors, in addition to requiring estimates of the transition probabilities of sequences of lexical tags <REF>Church 1988</REF>; <TREF>DeRose 1988</TREF>; <REF>Kupiec 1992</REF>, and this again brings up the question of what to do about unseen or low-frequency forms	1	In working taggers, a common approach is simply to apply a uniform small probability to the various senses of unseen or low-frequency forms: this was done in the tagger discussed in <REF>Church 1988</REF>, for example	0	156 Baayen and Sproat Lexical Priors for Low-Frequency Forms to> 8 Figure 1 I I I I 0 2 4 6 log frequency class Relative frequency of Dutch infinitives versus finite plurals in the Uit den Boogaart corpus, as a function of the natural log of the frequency of the word forms	0	6	1
E95-1022	J88-1003	1995	Its recall is very high 997 of all words receive the correct morphological analysis, but this system leaves 3-7 of all words ambiguous, trading precision for recall	0	157 ena or the linguists abstraction capabilities eg knowledge about what is relevant in the context, they tend to reach a 95-97 accuracy in the analysis of several languages, in particular English <REF>Marshall 1983</REF>; Black et aL 1992; <REF>Church 1988</REF>; <REF>Cutting et al 1992</REF>; de <REF>Marcken 1990</REF>; <TREF>DeRose 1988</TREF>; <REF>Hindle 1989</REF>; <REF>Merialdo 1994</REF>; <REF>Weischedel et al 1993</REF>; <REF>Brill 1992</REF>; <REF>Samuelsson 1994</REF>; Eineborg and Gambick 1994, etc	1	Interestingly, no significant improvement beyond the 97 barrier by means of purely data-driven systems has been reported so far	0	In terms of the accuracy of known systems, the data-driven approach seems then to provide the best model of part-of-speech distribution	0	6	1
C90-3086	J88-1003	1990	This will partly be based on another important step in the process, namely the construction of constituents, in particular noun phrases and prepositional phrases <REF>Church 1988</REF>, <REF>Kfillgren 1984c</REF>, and partly on a more general algorithm that for pairs or longer sequences of tags calculates the relative probability of alternative tag assignments	1	The principles behind such algorithms are known, but they have never been tried on Swedish material <TREF>DeRose 1988</TREF>, <REF>Marshall 1987</REF>, <REF>EegOlofsson 1985</REF>	1	An indispensable step in the disambiguation process is the assignment of clause boundaries, which presupposes established constituents at the same time as it forms an important basis for disambiguating chains of tags	0	Methods for this are being tested out on Swedish material <REF>Ejerhed 1989</REF>	0	6	1
J95-4004	J88-1003	1995	There are a number of large tagged corpora available, allowing for a variety of experiments to be run	0	Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years eg , <REF>Jelinek 1985</REF>; <REF>Church 1988</REF>; <REF>Derose 1988</REF>; <REF>Hindle 1989</REF>; <REF>DeMarcken 1990</REF>; <REF>Merialdo 1994</REF>; <REF>Brill 1992</REF>; <REF>Black et al 1992</REF>; <REF>Cutting et al 1992</REF>; <REF>Kupiec 1992</REF>; <REF>Charniak et al 1993</REF>; <REF>Weischedel et al 1993</REF>; <REF>Schutze and Singer 1994</REF>	1	Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography	0	Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation	0	6	1
J95-4004	J88-1003	1995	However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics	0	Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging <REF>Jelinek 1985</REF>; <REF>Church 1988</REF>; <REF>Derose 1988</REF>; <REF>DeMarcken 1990</REF>; <REF>Merialdo 1994</REF>; <REF>Cutting et al 1992</REF>; <REF>Kupiec 1992</REF>; <REF>Charniak et al 1993</REF>; <REF>Weischedel et al 1993</REF>; <REF>Schutze and Singer 1994</REF>	1	41 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows	0	9 The initial-state annotator assigns each word its most likely tag as indicated in the training corpus	0	6	1
C96-2151	J88-1003	1996	Statistical taggers usually work as follows: First, each word in the input word string 1471,   , W, is assigned all possible tags according to the lexicon, thereby creating a lattice	0	A dynamic programming technique is then used to find tag the sequence 5/,, , that maximizes PT1,,Tn I Wl,   , Wn  tt  IIPTk T1,,Tk-1;Wl,,Wn kl 1:1 PTk Tk-NI,,Tk-1; VIZk  7 PT wk PTk k-Nl,, k-l  kl fl PTk PT, Tk-N,, - PWk I Tk : PWk Since the maximum does not depend on the factors PWk, these can be omitted, yielding the standard statistical PoS tagging task: max - PTk IU-V,,Tk-JPWk JT TI,,T, tl This is well-described in for example <TREF>DeRose 1988</TREF>	1	We thus have to estimate the two following sets of probabilities:  Lexical probabilities: The probability of each tag T i conditional on the word W that is to be tagged, pr I I wr	0	i Often the converse probabilities PW are given instead, but we will for reasons soou to become apparent use the former formulation	0	6	1
A92-1020	J88-1003	1992	Recent research advances may lead to the development of viable book indexing methods for Chinese books	0	These include the availability of efficient and high precision word segmentation methods for Chinese text <REF>Chang et al , 1991</REF>; <REF>Sproat and Shih, 1990</REF>; <REF>Wang et al , 1990</REF>, the availability of statistical analysis of a Chinese corpus <REF>Liu et al , 1975</REF> and large-scale electronic Chinese dictionaries with partof-speech information <REF>Chang et al , 1988</REF>; BDC, 1992, the corpus-based statistical part-of-speech tagger <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF>; <REF>Beale, 1988</REF>, as well as phrasal and clausal analyzers <REF>Church 1988</REF>; <REF>Ejerhed 1990</REF> 2	1	Problem description As being pointed out in <REF>Salton, 1988</REF>, back-of-book indexes may consist of more than one word that are derived from a noun phrase	0	Given the text of a book, an indexing system, must perform some kind of phrasal and statistical analysis in order to produce a list of candidate indexes and their occurrence statistics in order to generate indexes as shown in Figure 1 which is an excerpt from the reconstruction of indexes of a book on transformational grammar for Mandarin Chinese <REF>Tang, 1977</REF>	0	6	1
C96-2192	J88-1003	1996	In this paper, we report on experimental work dealing with the part-of-speech tagging of a corpus of transcribed spoken Swedish	0	The tagger used implements a standard probabilistic biclass model see, e g, <TREF>DeRose 1988</TREF> trained on a tagged subset of the Stockhohn-Ume Corpus of written Swedish <REF>Ejerhed et al 1992</REF>	1	Given that the transcriptions contain many modifications of standard orthography in order to capture spoken language variants, reductions, etc	0	a special lexicon had to be developed to map spoken langnage variants onto their canonical written language forms	0	3	2
W96-0102	J88-1003	1996	Several approaches have been proposed to construct automatic taggers	0	Most work on statistical methods has used n-gram models or Hidden Markov Model-based taggers eg <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF>; <REF>Cutting et al 1992</REF>; <REF>Merialdo, 1994</REF>, etc	1	In 14 these approaches, a tag sequence is chosen for a sentence that maximizes the product of lexical and contextual probabilities as estimated from a tagged corpus	0	In rule-based approaches, words are assigned a tag based on a set of rules and a lexicon	0	6	1
H91-1077	J88-1003	1991	Categorical ambiguity, however, is of a different kind and is resolved in a different way	0	For the purposes of the present paper, it will be assumed that only content words are at issue, and that the syntactic category of all content words in the text that is under study can be determined automatically <REF>Church, 1988</REF>; <TREF>DeRose, 1988</TREF>	1	The problem is simply to decide which sense of a content word--noun, verb, adjective, or adverb---is appropriate in a given linguistic context	0	It will also be assumed that sense resolution for individual words can be accomplished on the basis of information about the irnrnediate linguistic context	0	6	1
J93-2006	J88-1003	1993	Purely rule-based techniques seemed too brittle for dealing with the variety of constructions, the long sentences averaging 29 words per sentence, and the degree of unexpected input	1	Statistical models based on local information eg , <TREF>DeRose 1988</TREF>; <REF>Church 1988</REF> might operate effectively in spite of sentence length and unexpected input	1	To see whether our four hypotheses in italics above effectively addressed the four concerns above, we chose to test the hypotheses on two well-known problems: ambiguity both at the structural level and at the part-of-speech level and inferring syntactic and semantic information about unknown words	0	Guided by the past success of probabilistic models in speech processing, we have integrated probabilistic models into our language processing systems	0	2	2
J93-2006	J88-1003	1993	We report in Section 2 on our experiments on the assignment of part of speech to words in text	0	The effectiveness of such models is well known <TREF>DeRose 1988</TREF>; <REF>Church 1988</REF>; <REF>Kupiec 1989</REF>; <REF>Jelinek 1985</REF>, and they are currently in use in parsers eg de <REF>Marcken 1990</REF>	1	Our work is an incremental improvement on these models in three ways: 1 Much less training data than theoretically required proved adequate; 2 we integrated a probabilistic model of word features to handle unknown words uniformly within the probabilistic model and measured its contribution; and 3 we have applied the forward-backward algorithm to accurately compute the most likely tag set	1	In Section 3, we demonstrate that probability models can improve the performance of knowledge-based syntactic and semantic processing in dealing with structural ambiguity and with unknown words	0	5	2
A94-1009	J88-1003	1994	Trento, Italy, pages 133-140, Association for Computational Linguistics	0	Steven J <TREF>DeRose 1988</TREF>	0	Grammatical Category Disambiguation by Statistical Optimization	0	Computational Linguistics, 141 :31-39	0	6	1
A94-1009	J88-1003	1994	The first major use of HMMs for part of speech tagging was in CLAWS <REF>Garside et al , 1987</REF> in the 1970s	0	With the availability of large corpora and fast computers, there has been a recent resurgence of interest, and a number of variations on and alter53 natives to the FB, Viterbi and BW algorithms have been tried; see the work of, for example, Church <REF>Church, 1988</REF>, Brill <REF>Brill and Marcus, 1992</REF>; <REF>Brill, 1992</REF>, DeRose <TREF>DeRose, 1988</TREF> and gupiec <REF>Kupiec, 1992</REF>	1	One of the most effective taggers based on a pure HMM is that developed at Xerox <REF>Cutting et al , 1992</REF>	0	An important aspect of this tagger is that it will give good accuracy with a minimal amount of manually tagged training data	0	6	1
P02-1041	J88-2003	2002	Different accessibility relations can be modeled, eg to distinguish a local context for resolving reflexive anaphors like himself  from a global context <REF>Kruijff, 2001</REF>	0	Finally, the rich temporal ontology underlying models of tense and aspect such as <TREF>Moens and Steedman 1988</TREF> can be captured using the sorting strategy	1	Earlier work like <REF>Blackburn and Lascarides 1992</REF> already explored such ideas	0	HLDS employs hybrid logic to integrate Moens and Steedmans notion of the event nucleus directly into meaning representations	0	6	1
P00-1010	J88-2003	2000	However, at least 30 of the dates and times in the MUC test were fixed-format ones occurring in document headers, trailers, and copyright notices	0	 Finally, there is a large body of work, eg, <TREF>Moens and Steedman 1988</TREF>, <REF>Passoneau 1988</REF>, <REF>Webber 1988</REF>, <REF>Hwang 1992</REF>, <REF>Song and Cohen 1991</REF>, that has focused on a computational analysis of tense and aspect	1	While the work on event chronologies is based on some of the notions developed in that body of work, we hope to further exploit insights from previous work	1	Conclusion We have developed a temporal annotation specification, and an algorithm for resolving a class of time expressions found in news	0	4	2
J98-3003	J88-2003	1998	Other aspects of our ontology are designed following proposals by <REF>Jackendoff 1990</REF>, in particular his analysis of movement events	0	2 <TREF>Moens and Steedman 1988</TREF> also use this term, but they restrict it to momentaneous events	1	Unfortunately, the terminology used in the literature for these kinds of categories varies so much that a standardization seems out of reach	1	404 Stede Verb Alternations event1 fill conf---- > not-full -state-1    f > pa>btination  fill-state-2   water-1  value > full Figure 2 SitSpec representing a fill-event	0	1	3
J98-3003	J88-2003	1998	As their central feature we take them to always involve some change of state: the building loses its integrity, the book comes into existence, or gets finished	0	<REF>While Bach 1986</REF> did not investigate the internal structure of events, others suggested that this needs to be done eg , <TREF>Moens and Steedman 1988</TREF>; <REF>Parsons 1990</REF>	1	<REF>Pustejovsky 1991</REF> treated Vendlerian accomplishments and achievements as transitions from a state Qy to NOT-Qy, and suggested that accomplishments in addition have an intrinsic agent performing an activity that brings about the change of state	0	We follow this line, but modify it in some ways	0	1	3
P97-1013	J88-2003	1997	In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs	0	Such constructs can include tense 96 and aspect <TREF>Moens and Steedman, 1988</TREF>; <REF>Webber, 1988</REF>; <REF>Lascarides and Asher, 1993</REF>, certain patterns of pronominalization and anaphoric usages <REF>Sidner, 1981</REF>; <REF>Grosz and Sidner, 1986</REF></REF>; <REF>Sumita et al , 1992</REF>; <REF>Grosz, Joshi, and Weinstein, 1995</REF>,/t-clefts <REF>Delin and Oberlander, 1992</REF>, and discourse markers or cue phrases <REF>Ballard, Conrad, and Longacre, 1971</REF>; <REF>Halliday and Hasan, 1976</REF>; <REF>Van Dijk, 1979</REF>; <REF>Longacre, 1983</REF>; <REF>Grosz and Sidner, 1986</REF></REF>; <REF>Schiffrin, 1987</REF>; <REF>Cohen, 1987</REF>; <REF>Redeker, 1990</REF>; <REF>Sanders, Spooren, and Noordman, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1995</REF>; <REF>Fraser, 1996</REF>; <REF>Moser and Moore, 1997</REF>	1	In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts	0	The intuition behind our choice relies on the following facts:  Psycholinguistic and other empirical research <REF>Kintsch, 1977</REF>; <REF>Schiffrin, 1987</REF>; <REF>Segal, Duchan, and Scott, 1991</REF>; <REF>Cahn, 1992</REF>; <REF>Sanders, Spooren, and Noordman, 1992</REF>; <REF>Hirschberg and Litman, 1993</REF>; <REF>Knott, 1995</REF>; <REF>Costermans and Fayol, 1997</REF> has shown that discourse markers are consistently used by human subjects both as cohesive ties between adjacent clauses and as macroconnectors between larger textual units	0	3	2
W00-0205	J88-2003	2000	The feature specification of this ompositionally derived accomplishment is therefore identical to that of a sentence containing a telic accomplishment verb, such as destroy	1	According to many researchers, knowledge of lexical aspect--how verbs denote situations as developing or holding in time-may be used to interpret event sequences in discourse <REF>Dowty, 1986</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Passoneau, 1988</REF>	1	In particular, Dowty suggests that, absent other cues, a relic event is interpreted as completed before the next event or state, as with ran into lhe room in 4a; in contrast, atelic situations, such as run, was hungry in 4b and 4 are interpreted as contemporaneous with the following situations: fell and made a pizza, respectively	0	4 a Mary ran into the room	0	3	2
E93-1030	J88-2003	1993	In 10, s is the consequent state of the event of John greeting Max, and it holds at the time t which precedes now	0	So our semantics of the perfect is like that in <TREF>Moens and Steedman 1988</TREF>: a perfect transforms an event into a consequent state, and asserts that the consequent state holds	1	The pluperfect of a state, such as 11, therefore, is assumed to first undergo a transformation into an event	0	11 John had loved Mary	0	4	2
W99-0108	J88-2003	1999	Other genres of text might depend on other kinds of structuring devices	0	Changes in time scale or time, as we redefined the category, may require world knowledge reasoning to recoguize but are often indicated by either cue words and phrases eg , n/he years ago ,  a year, for months; several months ago, a change in grammatical time of the verb eg , past tense versus present tense, or changes in aspect eg , atomic versus extended events versus states as defined by <TREF>Moens  Steedman 1988</TREF>	1	In considering how time change might affect anaphoric expression choice, we consider the choice for the first mention of a discourse entity in a sentence where that entity has recently been referred to in the discourse	0	Our hypothesis is that: Changes in time reliably signal changes of the thread in newspaper articles; definite descriptions should appear when the current reference to a discourse entity is in a different thread from the last reference to that entity and pronouns should occur when the previous mention is in the same thread 3	0	6	1
P98-1007	J88-2003	1998	The imperfective point of view brought by IMP imposes a change of point of view on the term of the eventuality	0	As for accomplishments, we can assume that they can be decomposed into several stages, according to <TREF>Moens and Steedman, 1988</TREF>: first a preparatory phase, second a culmination or achievement we are not concerned here with the result state	1	We can then say that IMP refers only to the preparatory phase, so that the term of the eventuality loses all relevance	0	This explains the so-called imperfective paradox: it is possible to use IMP even though the eventuality never reaches its term: 6 a I1 traversait la rue quand la voiture la 6cras6 He was crossing the street when the car hit him b  I1 traversa la rue quand la voiture la 6cras6 He crossed the street when the car hit him As for achievements, we can assume that they are reduced to a culmination	0	3	2
E93-1031	J88-2003	1993	Secondly, it has been argued that A when B permits many possible temporal relationships between the eventualities denoted by A and B cf	0	<TREF>Moens and Steedman 1988</TREF>; its for this reason that 2c can be interpreted as denoting El; 260 but given this permissiveness, why is 2d not as acceptable as 2c	0	3 The basic explanation: temporal presuppositions The basic explanation for the inappropriateness of 2b and 2d is actually quite simple	0	Sentences containing temporal connectives are presuppositional: the temporal clause introduces an eventuality that must be presupposed to have occurred, for the sentence as a whole to have a truth-value cf	0	6	1
W04-0212	J88-2003	2004	Second, with when, the almost equal distribution of preposed and postposed tokens suggests either free variation of the two patterns or different uses of the two patterns, with each use favoring a different pattern	1	The latter would accord with a theoretical distinction that has been made between postposed when expressing a purely temporal relation between the two clauses, and preposed when expressing a contingent relation between them <TREF>Moens and Steedman, 1988</TREF>	0	Integrated evidence from the PTB and PropBank may help distinguish the two possibilities	0	Third, there is a striking contrast between the patterning of although and even though, especially if one assumes that even though like even when, even after, even if, etc	0	6	1
W08-1119	J88-2003	2008	Weneedamuchbettermodelofhowtocommunicate time, and how this communication depends on the semantics and linguistic expression of the events being described	0	An obvious first step, which we are currently working on, is to include a linguisticallymotivatedtemporalontology <REF>MoensandSteedman, 1988</REF>, which will be separate from the existing domain ontology	1	We also need better techniques for communicating the temporal relationships between events in cases where they are not listed in chronological order <REF>Oberlander and Lascarides, 1992</REF>	0	6 Discussion Two discourse analysts from Edinburgh University, Dr Andy McKinlay and Dr Chris McVittie, kindly examined and compared some of the human and BT45 texts	0	3	2
E93-1048	J88-2003	1993	The domain is limited to trajectoryof-motion events specified by the verbs run, jog, sit is worth noting that as an alternative to positing a lexical ambiguity, one could just as easily invoke a coercion operator on an event predicate Pz mapping it to the process predicate he	0	plurPx  e, which would bring the present treatment more in line with <TREF>Moens and Steedman 1988</TREF> and <REF>Jackendoff 1991</REF>	1	plod, and walk; the locative prepositions to, towards, from, away from, along, eastwards, westwards, and to and back; various landmarks; the distance adverbials n miles; the frequency adverbials twice and n times; and finally the temporal adverbials for and in	0	Trajectory-of-motion events are modeled as continuous constant rate changes of location in one dimension of the TRAJECTOR relative to one or more LANDMARKS following <REF>Regier 1992</REF> in his use of Langackers 1987 terminology	0	4	2
E93-1048	J88-2003	1993	2 3 Theory 31 Ontology Various authors including <REF>Link, 1983</REF>, <REF>Bach, 1986</REF>, <REF>Krifka, 1989</REF>, <REF>Eberle, 1990</REF> have proposed modeltheoretic treatments in which a parallel ontological distinction is made between substances and things, processes and events, etc A similarly parallel distinction is employed here, but in a rather different way: unlike the above treatments, the present account models substances, processes, and other such entities as abstract kinds whose realizations vary in amount	0	As such, the approach developed here may be seen as building upon the work of <REF>Carlson 1977</REF> and his successors; it also represents one way to further formalize the intuitions found in <TREF>Moens and Steedman 1988</TREF> and <REF>Jackendoff 1991</REF>	1	<REF>Following Schubert and Pelletier 1987</REF>, the present account distinguishes individuals from kinds, but not from stages or quantities	0	Extending their ontology, the same distinction is assumed to hold not only in the domain of materials but also in the domain of eventualities, and derivatively in the domains of space and time as well	0	5	2
E95-1036	J88-2003	1995	Note that in a terminal DRS ready for an embedding test, all the auxiliary Rpts disappear do not participate in the embedding	0	The perfect is analyzed by using the notion of a nucleus <TREF>Moens and Steedman, 1988</TREF> to account for the inner structure of an eventuality	1	A nucleus is defined as a structure containing a preparatory process, culmination and consequent state	0	The categorization of verb phrases into different aspectual classes can be phrased in terms of which part of the nucleus they refer to	0	3	2
W98-0702	J88-2003	1998	Moreover, the semantic category of these features can also play a role	0	For example, Sue played the piano is nonc,lminated, while Sue played the sonata signifies a c-lminated event this example comes from <TREF>Moens and Steedman 1988</TREF>	1	32 Classes of Ambiguous Verbs Placing aspectually ambiguous verbs into semantic categories will help predict how these verbs combine with their arguments to determine aspectual class	1	This is because many verbs with related meanings combine with their arguments in similar ways	0	6	1
W98-0702	J88-2003	1998	For example, shaw denotes a state in, H/ lumbar puncture showed evidence of white cells, but denotes an event in, He showed me the photographs	0	This ambiguity presents a diculty for automatically classifying a verb because the aspectual class of a clause is a function of several clausal constituents in addition to the main verb <REF>Dowry, 1979</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Pustejovsky, 1991</REF>	1	However, previous work that numerically evaluates aspectual classification has looked at verbs in isolation <REF>Klavans and Chodorow, 1992</REF>; <REF>Siegel, 1997</REF>	0	10 The verb have is particularly problematic	0	6	1
W98-0702	J88-2003	1998	For example, I made a fire is culminated, whereas, I gazed at the sunset is non-culminated	1	Aspectual classification is necessary for interpreting temporal modifiers and assessing temporal entailments <TREF>Moens and Steedman, 1988</TREF>; <REF>Dorr, 1992</REF>; <REF>Klavans, 1994</REF>, and is therefore a necessary component for applications that perform certain language interpretation, summarization, information retrieval, and machine translation tasks	1	Aspectual classification is a diflqcult problem because many verbs, like have, are aspectually ambiguous	0	In this paper, I demonstrate that verbs can be disambiguated according to aspect by the semantic category of the direct object	0	3	2
W98-0702	J88-2003	1998	Finally, Section 8 provides conclusions and describes future work	0	2 Aspect in Natural Language Aspectual classification is a key component of models that assess temporal constraints between clauses <TREF>Moens and Steedman, 1988</TREF>; <REF>Hwang and Schubert, 1991</REF>; <REF>Dorr, 1992</REF>; <REF>Hitzeman et al , 1994</REF>	1	For example, stativity must be identified to detect temporal constraints between clauses connected with when	0	For example, in interpreting I, I She had good strength when objectively tested	0	3	1
W91-0222	J88-2003	1991	In 26i, the event is associated with the features d,t,-a, whereas, in 26ii the event is associated with the features d,t,a	0	According to <REF>Bennett et al , 1990</REF> in the spirit of <TREF>Moens and Steedman, 1988</TREF>, predicates are allowed to undergo an atomicity coercion in which an inherently non-atomic predicate such as dio may become atomic under certain conditions	1	These conditions are language-specific in nature, ie, they depend on the lexical-semantic structure of the predicate in question	0	Given the featural scheme that is imposed on top of the lexical-semantic framework, it is easy to specify coercion functions for each language	0	5	2
W91-0222	J88-2003	1991	In light of these observations, the lexicM-semantic structure adopted for UNITRAN is an augmented form of Jackendoffs representation in which events are distinguished from states as before, but they are further subdivided into activities, achievements, and accomplishments	0	The subdivision is achieved by means of three features proposed by <REF>Bennett et al , 1990</REF> following the framework of <TREF>Moens and Steedman, 1988</TREF> in the spirit of <REF>Dowty, 1979</REF> and <REF>Vendler, 1967</REF>: dynamic ie , events vs states, as in the Jackendoff framework, :t:telic i e, culminative events transitions vs nonculminative events activities, and atomic ie , point events vs extended events	1	This featural system is imposed on top of the lexical-semantic framework proposed by Jackendoff	0	For example, the primitive GO would be annotated with the features d,t,-a for the verb destroy, but d,t,a for the verb obliterate, thus providing the appropriate distinction for cases such as 12	0	3	2
W91-0222	J88-2003	1991	Figure 2 relates the four types of lexical-semantic frameworks outlined above	0	Note that the system of features proposed by <REF>Bennett et al , 1990</REF> and <TREF>Moens and Steedman, 1988</TREF> provide the finest tuning given that five distinct categories of predicates are identified by the feature settings	1	This system is essentially equivalent to the Dowty/Vendler proposal, but features are used to distinguish the categories more precisely	0	In the next section, we will see how the tense and aspect structure described in section 21 and the lexicM-semantic representation described in this section are combined to provide the framework for generating a target-language surface form	0	5	2
P99-1064	J88-2003	1999	2b John finished drawing the circle	0	<REF>Dowty 1986</REF> and <TREF>Moens and Steedman 1988</TREF> decisively questioned the coherence of the class of achievement verbs, arguing that not all of them are non-durative	1	As noted above, Vendler identifies punctual events through the conjunction of the positive at and negative finish tests	0	However, they do not always yield comparable results : 3a 3b 4a 4b Karpov beat Kasparov at 1000 PM The Allies beat Germany at I000 PM  Karpov finished beating Kasparov The Allies finished beating Germany	0	3	2
E99-1032	J88-2003	1999	They trigger a change-of-state COS, henceforth, result states RSs, henceforth being entailments of CoSs	0	<TREF>Moens and Steedman 1988</TREF>, <REF>Smith 1991</REF>, <REF>Pustejovsky 1995</REF>, and others argue that it is a defining property of telic events	1	They should therefore include an undergoer argument, whose CoS determines the telicity of the event ie , it acts as a measuring-out argument	1	<REF>Tenny 1987</REF> thus claims that telic events require such an argument, which she calls an affected argument	0	3	2
P92-1033	J88-2003	1992	The subdivision is achieved by means of three features proposed by Bennett etal	0	1990 following the framework of <TREF>Moens and Steedman 1988</TREF>: -t-dynamic ie , events vs states, as in the Jackendoff framework, telic ie , culminative events transitions vs noneulminative events activities, and -I-atomic ie , point events vs extended events	1	We impose this system of features on top of the current lexical-semantic framework	0	For example, the lexical entry for all three verbs, ransack, obliterate, and destroy, would contain the following lexical-semantic representation: 6 Event CAUSE Thing X, Event GOLoc Thing X, Position TOLoc X John, Property DESTROYED The three verbs would then be distinguished by annotating this representation with the aspectual features d,t,-a for the verb ransack, d,t,-a for the verb destroy, and d,t,a for the verb obliterate, thus providing the appropriate distinction for cases such as 4	0	5	2
P92-1033	J88-2003	1992	SUMMARY This paper has examined a two-level knowledge representation model for machine translation that integrates aspectual information based on theories by <REF>Bach 1986</REF>, <REF>Comrie 1976</REF>, <REF>Dowty 1979</REF>, mourelatos 1981, <REF>Passonneau 1988</REF>, Pustejovsky 1988, 1989, 1991, and <REF>Vendler 1967</REF>, and more recently by Bennett et al	0	1990 and <TREF>Moens and Steedman 1988</TREF>, with lexicalsemantic information based on Jackendoff 1983, 1990	0	We have examined the question of cross-linguistic applicability showing that the integration of aspect with lexical-semantics is especially critical in machine translation when there are a large number of temporal connectives and verbal selection/realization possibilities that may be generated from a lexical semantic representation	0	Furthermore, we have illustrated that the selection/realization processes may be parameterized, by means of selection charts and coercion functions, so that the processes may operate uniformly across more than one language	0	6	1
P92-1033	J88-2003	1992	S: Juan le dio una puflaJada a Marls John gave a knife-wound to Mary S: Juan le dio pufialadas a Marls John gave knife-wounds to Mary b Duratlve Divergence, E: John met/knew Mary 4 S: Juan coaoci6 a Marls John met Mary S: Juan conoci a Mrfa John knew Merit Figure 1: Three Levels of MT Divergences et el	0	1990 have examined aspect and verb semantics within the context of machine translation in the spirit of <TREF>Moens and Steedman 1988</TREF>	1	This paper borrows from, and extends, these ideas by demonstrating how this theoretical framework might be adapted for crosslinguistic applicability	0	The framework has been tested within the context of an interlingual machine translation system and is currently being used as the basis for extraction of aspectual information from corpora	0	3	2
W98-0304	J88-2003	1998	Although there have been quite a few studies on individual aspects of sentence planning, little attention has been paid to the interaction between the various tasks--exceptions are <REF>Rambow and Korelsky 1992</REF> and <REF>Wanner and Hovy 1996</REF>--and in particular to the role of marker choice in the overall sentence planning process	0	There exists a large body of research in NLU on analysing the temporal structure of texts, including the role of temporal markers, though again restricted to English <TREF>Moens and Steedman 1988</TREF>; <REF>Lascarides and Oberlander 1993</REF>; <REF>Hitzeman et al 1995</REF>	1	We turn to these studies when it comes to identifying the information that needs to be assembled for representing temporal markers	0	3 Linguistic perspective: Describing temporal markers Selecting an appropriate German temporal marker given two events in a temporal relationship requires detailed knowledge of the semantic, pragmatic and syntactic properties that characterize temporal markers	0	1	3
P97-1020	J88-2003	1997	edu Abstract Verbal and compositional lexical aspect provide the underlying temporal structure of events	0	Knowledge of lexical aspect, eg, atelicity, is therefore required for interpreting event sequences in discourse <REF>Dowty, 1986</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Passoneau, 1988</REF>, interfacing to temporal databases <REF>Androutsopoulos, 1996</REF>, processing temporal modifiers <REF>Antonisse, 1994</REF>, describing allowable alternations and their semantic effects <REF>Resnik, 1996</REF>; <REF>Tenny, 1994</REF>, and selecting tense and lexical items for natural language generation <REF>Dorr and Olsen, 1996</REF>; <REF>Klavans and Chodorow, 1992</REF>, cf	1	<REF>Slobin and Bocaz, 1988</REF>	0	We show that it is possible to represent lexical aspect--both verbal and compositional--on a large scale, using Lexical Conceptual Structure LCS representations of verbs in the classes cataloged by <REF>Levin 1993</REF>	0	3	2
P97-1020	J88-2003	1997	Finally, we illustrate how knowledge of lexical aspect facilitates the interpretation of events in NLP applications	0	Knowledge of lexical aspect--how verbs denote situations as developing or holding in time--is required for interpreting event sequences in discourse <REF>Dowty, 1986</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Passoneau, 1988</REF>, interfacing to temporal databases <REF>Androutsopoulos, 1996</REF>, processing temporal modifiers <REF>Antonisse, 1994</REF>, describing allowable alternations and their semantic effects <REF>Resnik, 1996</REF>; <REF>Tenny, 1994</REF>, and for selecting tense and lexical items for natural language generation Dorr and Olsen	1	1996: <REF>Klavans and Chodorow, 1992</REF>, cf	0	<REF>Slobin and Bocaz, 1988</REF>	0	3	2
J03-4002	J88-2003	2003	How does 37b get its interpretation	0	As with 36d, the relevant elements of 37b can be represented as   then R   after S  turn right on County Line   e 3 :turn-rightyou, county line and the unresolved interpretation of 37b is thus  xafterx, EVe 3  aftere 3, EV 560 Computational Linguistics Volume 29, Number 4 As for resolving EV, in a well-known article, <TREF>Moens and Steedman 1988</TREF> discuss several ways in which an eventuality of one type eg , a process can be coerced into an eventuality of another type eg , an accomplishment, which Moens and Steedman call a culminated process	1	In this case, the matrix argument of then the eventuality of turning right on County Line can be used to coerce the process eventuality in 37b into a culminated process of going west on Lancaster Avenue until County Line	0	We treat this coercion as a type of associative or bridging inference, as in the examples discussed in section 31	0	5	2
E91-1022	J88-2003	1991	The alternatives arise when more than one event can be used	0	The temporal ontology is based on a recent theory of temporal semantics developed by <TREF>Moens and Steedman 1988</TREF>	1	This allows a modular representation of the semantics of temporal adverbials like until and by, and also aids in the generation of tense and aspect	0	This system looks at the mechanics of how the alternatives can be generated from the initial data, but we will have less to say about choosing between them	0	5	2
P97-1045	J88-2003	1997	21 Aspectual Categories of Verbs A number of aspectually oriented lexical-semantic representations have been proposed	0	Ve adopt and extend the feature-based framework proposed by <REF>Bennett et al , 1990</REF> in the spirit of <TREF>Moens and Steedman, 1988</TREF>	1	They uses three features: dynamic, telic, and atomic	0	We add two more features: process and gradual	0	3	2
J00-4004	J88-2003	2000	In principle, it is possible for this second module to detect aspectual transformations that apply to any input clause, independent of the manner in which the core constituents interact to produce its fundamental aspectual class	0	600 Siegel and McKeown Improving Aspectual Classification 26 Applications of Aspectual Classification Aspectual classification is a required component of applications that perform natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks <TREF>Moens and Steedman 1988</TREF>; <REF>Klavans and Chodorow 1992</REF>; <REF>Klavans 1994</REF>; <REF>Dorr 1992</REF>; <REF>Wiebe et al 1997</REF>	1	These applications require the ability to reason about time, ie, temporal reasoning	0	Assessing temporal relationships is a prerequisite for inferring sequences of medical procedures in medical domains	0	3	2
J00-4004	J88-2003	2000	598 Siegel and McKeown Improving Aspectual Classification Table 3 Several aspectual entailments	0	If a clause occurring: necessarily entails: then it must be: in past progressive tense as argument of stopped in simple present tense past tense reading past tense reading the habitual reading Nonculminated Event Nonculminated Event or State Event 23 Interpreting Temporal Connectives and Modifiers Several researchers have developed models that incorporate aspectual class to assess temporal constraints between connected clauses <REF>Hwang and Schubert 1991</REF>; <REF>Schubert and Hwang 1990</REF>; <REF>Dorr 1992</REF>; <REF>Passonneau 1988</REF>; <TREF>Moens and Steedman 1988</TREF>; <REF>Hitzeman, Moens, and Grover 1994</REF>	1	For example, stativity must be identified to detect temporal constraints between clauses connected with when	0	For example, in interpreting, 7 She had good strength when objectively tested	0	3	2
J00-4004	J88-2003	2000	An understanding system can recognize the aspectual transformations that have affected a clause only after establishing the clauses fundamental aspectual category	0	Linguistic models motivate the division between a module that first detects fundamental aspect and a second that detects aspectual transformations <REF>Hwang and Schubert 1991</REF>; <REF>Schubert and Hwang 1990</REF>; <REF>Dorr 1992</REF>; <REF>Passonneau 1988</REF>; <TREF>Moens and Steedman 1988</TREF>; <REF>Hitzeman, Moens, and Grover 1994</REF>	1	In principle, it is possible for this second module to detect aspectual transformations that apply to any input clause, independent of the manner in which the core constituents interact to produce its fundamental aspectual class	1	600 Siegel and McKeown Improving Aspectual Classification 26 Applications of Aspectual Classification Aspectual classification is a required component of applications that perform natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks <TREF>Moens and Steedman 1988</TREF>; <REF>Klavans and Chodorow 1992</REF>; <REF>Klavans 1994</REF>; <REF>Dorr 1992</REF>; <REF>Wiebe et al 1997</REF>	0	4	2
J00-4004	J88-2003	2000	Some aspectual markers such as the pseudocleft and many manner adverbs test for intentional events in particular not all events in general, and therefore are not compatible with all events, eg, I died diligently	0	Aspectual coercion such as iteration can allow a punctual event to appear in the progressive, eg She was sneezing for a week point  process  culminated process 4 <TREF>Moens and Steedman 1988</TREF>	1	The predictive power of some indicators is uncertain, since several measure phenomena that are not linguistically constrained by any aspectual category, eg, the present tense, durative for-PPs, frequency and notnever indicators	0	Therefore, the predictive power of individual linguistic indicators is incomplete; only the subset of verbs that adhere to the respective constraints or trends can be correctly classified	0	6	1
J00-4004	J88-2003	2000	the second sentence describes a state, which begins before the event described by the first sentence	0	Aspectual classification is also a necessary prerequisite for interpreting certain adverbial adjuncts, as well as identifying temporal constraints between sentences in a discourse <TREF>Moens and Steedman 1988</TREF>; <REF>Dorr 1992</REF>; <REF>Klavans 1994</REF>	1	In addition, it is crucial for lexical choice and tense selection in machine translation <TREF>Moens and Steedman 1988</TREF>; <REF>Klavans and Chodorow 1992</REF>; <REF>Klavans 1994</REF>; <REF>Dorr 1992</REF>	0	Table 1 sunnarizes the three aspectual distinctions, which compose five aspectual categories	0	4	1
J00-4004	J88-2003	2000	Some aspectual auxiliaries also perform an aspectual transformation of the clause they modify, eg, 11 I finished staring at it culminated process	0	Aspectual coercion, a second type of aspectual transformation, can take place when a clause is modified by an aspectual marker that violates an aspectual constraint <TREF>Moens and Steedman 1988</TREF>; <REF>Pustejovsky 1991</REF>	1	In this case, an alternative interpretation of the clause is inferred which satisfies the aspectual constraint	0	For example, the progressive marker is constrained to appear with an extended event	0	4	2
J00-4004	J88-2003	2000	E-mail: evscscolumbiaedu t Computer Science Dept , 1214 Amsterdam Ave , New York, NY 10027	0	E-mail: kathycscolumbiaedu  2001 Association for Computational Linguistics Computational Linguistics Volume 26, Number 4 Aspectual classification is necessary for interpreting temporal modifiers and assessing temporal entailments <TREF>Moens and Steedman 1988</TREF>; <REF>Dorr 1992</REF>; <REF>Klavans 1994</REF> and is therefore a required component for applications that perform certain natural language interpretation, generation, summarization, information retrieval, and machine translation tasks	1	Each of these applications requires the ability to reason about time	0	A verbs aspectual category can be predicted by co-occurrence frequencies between the verb and linguistic phenomena such as the progressive tense and certain temporal modifiers <REF>Klavans and Chodorow 1992</REF>	0	3	2
J00-4004	J88-2003	2000	Aspectual classification is also a necessary prerequisite for interpreting certain adverbial adjuncts, as well as identifying temporal constraints between sentences in a discourse <TREF>Moens and Steedman 1988</TREF>; <REF>Dorr 1992</REF>; <REF>Klavans 1994</REF>	0	In addition, it is crucial for lexical choice and tense selection in machine translation <TREF>Moens and Steedman 1988</TREF>; <REF>Klavans and Chodorow 1992</REF>; <REF>Klavans 1994</REF>; <REF>Dorr 1992</REF>	1	Table 1 sunnarizes the three aspectual distinctions, which compose five aspectual categories	0	In addition to the two distinctions described in the previous section, atomicity distinguishes punctual events eg , She noticed the picture on the wall from extended events, which have a time duration eg , She ran to the store	0	4	2
J00-4004	J88-2003	2000	Therefore, if it appears with an atomic event, eg, 12 He hiccupped point, the event is transformed to an extended event, eg, 13 He was hiccupping process	0	in this case with the iterated reading of the clause <TREF>Moens and Steedman 1988</TREF>	1	25 The First Problem: Fundamental Aspect We define fundamental aspectual class as the aspectual class of a clause before any aspectual transformations or coercions	1	That is, the fundamental aspectual category is the category the clause would have if it were stripped of any and all aspectual markers that induce an aspectual transformation, as well as all components of the clauses pragmatic context that induce a transformation	0	4	2
J00-4004	J88-2003	2000	Aspect in Natural Language Because, in general, the sequential order of clauses is not enough to determine the underlying chronological order, aspectual classification is required for interpreting 596 Siegel and McKeown Improving Aspectual Classification Table 1 Aspectual classes	0	This table is adapted from Moens and Steedman 1988, p 17	1	Culminated Nonculminated EVENTS punctual extended CULMINATION CULMINATED PROCESS recognize build a house POINT PROCESS hiccup run, swim, walk STATES understand even the simplest narratives in natural language	0	For example, consider: 1 Sue mentioned Miami event	0	4	2
P93-1040	J88-2003	1993	THE IMPERFECTIVE PARADOX AND TRAJECTORY-OF-MOTION EVENTS  Michael White Department of Computer and Information Science University of Pennsylvania Philadelphia, PA, USA mwhit el inc c is upenn, edu Abstract In the first part of the paper, I present a new treatment of THE IMPERFICTIVE PARADOX <REF>Dowty 1979</REF> for the restricted case of trajectoryof-motion events	0	This treatment extends and refines those of <TREF>Moens and Steedman 1988</TREF> and <REF>Jackendoff 1991</REF>	1	In the second part, I describe an implemented algorithm based on this treatment which determines whether a specified sequence of such events is or is not possible under certain situationally supplied constraints and restrictive assumptions	0	Bach 1986:12 summarizes THE IMPERFECTIVE PARADOX <REF>Dowty 1979</REF> as follows: how can we characterize the meaning of a progressive sentence like la 17 on the basis of the meaning of a simple sentence like lb 18 when la can be true of a history without lb ever being true	0	3	2
P93-1040	J88-2003	1993	<REF>White 1993</REF>	0	5Much as in <TREF>Moens and Steedman 1988</TREF> and <REF>Jackendoff 1991</REF>, the introduction of gr is necessary to avoid having an ill-sorted formula	1	284 the manner of motion supplied by a verb, it does nevertheless permit one to consider factors such as the normal speed as well as the meanings of the prepositions 10, lowards, etc By making two additional restrictive assumptions, namely that these events be of constant velocity and in one dimension, I have been able to construct and implement an algorithm which determines whether a specified sequence of such events is or is not possible under certain situationally supplied constraints	0	These constraints include the locations of various landmarks assumed to remain stationary and the minimum, maximum, and normal rates associated with various manners of motion eg running, jogging for a given individual	0	5	2
P93-1040	J88-2003	1993	Capitalizing on Bachs insight, I present in the first part of the paper a new treatment of the imperfective paradox which relies on the possibility of having actual events standing in the part-of relation to hypothetical super-events	0	This treatment extends and refines those of <TREF>Moens and Steedman 1988</TREF> and <REF>Jackendoff 1991</REF>, at least for the restricted case of trajectory-of-motion events	1	1 In particular, the present treatment correctly accounts not only for what 2a fails to entail -namely, that John eventually reaches the museum -but also for what 2a does in fact entail -namely, that John follows by jogging at least an initial part of a path that leads to the museum	0	In the second part of the paper, I briefly describe an implemented algorithm based on this theoretical treatment which determines whether a specified sequence of trajectory-of-motion is or is not possible under certain situationally supplied constraints and restrictive assumptions	0	3	2
P07-1113	J88-2003	2007	1 SonyCorp	0	hasheavilypromotedtheVideoWalkman since the products introduction last summer, 2 but Bob Gerson, video editor of This Week in Consumer Electronics, says 3 Sony conceives of 8mm as a family of products, camcorders and VCR decks,  SE classification is a fundamental component in determining the discourse mode of texts <REF>Smith, 2003</REF> and, along with aspectual classification, for temporal interpretation <TREF>Moens and Steedman, 1988</TREF>	1	It may be useful for discourse relation projection and discourse parsing	0	Though situation entities are well-studied in linguistics, they have received very little computational treatment	0	6	1
C98-1007	J88-2003	1998	The imperfective point of view brought by IMP imposes a change of point of view on the term of the eventuality	0	As for accomplishments, we can assume that they can be decomposed into several stages, according to <TREF>Moens and Steedman, 1988</TREF>: first  preparatory phase, second a cuhnination or achievement we are not concerned here with the result state	1	We can then say that IMP refers only to the preparatory phase, so that the term of the eventuality loses all relevance	0	This explains the so-called imperfective paradox: it is possible to use IMP even though the eventnality never reaches its term: 6 a I1 traversait la rue quand la voiture la ras6 He was crossing the street when the car hit him b  I1 traversa la rue quand la voiture la 6cras6 Ile crossed the street when the car hit him As for achievements, we can assume that they are reduced to a culmination	0	3	2
W97-0318	J88-2003	1997	Three machine learning methods are compared for this task: decision tree induction, a genetic algorithm, and log-linear regression	0	The ability to distinguish states, eg, Mark seems happy, from events, eg, Rende ran down the street, is a necessary prerequisite for interpreting certain adverbial adjuncts, as well as identifying temporal constraints between sentences in a discourse <TREF>Moens and Steedman, 1988</TREF>; <REF>Doff, 1992</REF>; <REF>Klavans, 1994</REF>	1	Furthermore, stativity is the first of three fundamental temporal distinctions that compose the aspectual class of a clause	0	Aspectual classification is a necessary component for a system that analyzes temporal constraints, or performs lexical choice and tense selection in machine translation <TREF>Moens and Steedman, 1988</TREF>; <REF>Passonneau, 1988</REF>; <REF>Doff, 1992</REF>; <REF>Klavans, 1994</REF>	0	6	1
W97-0318	J88-2003	1997	Furthermore, stativity is the first of three fundamental temporal distinctions that compose the aspectual class of a clause	0	Aspectual classification is a necessary component for a system that analyzes temporal constraints, or performs lexical choice and tense selection in machine translation <TREF>Moens and Steedman, 1988</TREF>; <REF>Passonneau, 1988</REF>; <REF>Doff, 1992</REF>; <REF>Klavans, 1994</REF>	1	Researchers have used empirical analysis of corpora to develop linguistically-based numerical indicators that aid in aspectual classification <REF>Klavans and Chodorow, 1992</REF>; <REF>Siegel and McKeown, 1996</REF>	0	Specifically, this technique takes advantage of linguistic constraints that pertain to aspect, eg, only clauses that describe an event can appear in the progressive	1	3	2
C08-1037	J88-2003	2008	And that they should be seen as the result of an attempt to take a good metaphor too literally	0	<TREF>Moens and Steedman 1988</TREF> conceived temporal adverbials as functions which coerce their inputs to the appropriate type, by a loose sic	1	analogy with type-coercion in programming languages	0	Under this perspective, aspectual shift is triggered by a conflict between the aspectual type of the situation to be modified and the aspectual constraint set by the temporal preposition heading the modifier1 Coercion operators, then, are thought to adapt the verbal input on the level of model-theoretical interpretation by mapping one sort of situation onto another	0	6	1
C00-2148	J88-2003	2000	By using TAGs we get the additional benefit of an existing parser that yields derivations and derived trees fiom which we can construct the compositional semantics of a given sentence	0	We decompose each event E into a tripartite structure in a manner similar to <TREF>Moens and Steedman 1988</TREF>, introducing a time function for each predicate to specify whether the predicate is true in the preparatory dringE, cuhnination erdE, or consequent resll:E stage of an event	1	hfitial trees capture tile semantics of the basic senses of verbs in each class	0	For example, many IThese restrictions are more like preferences that generate a preferred reading of a sentence	0	4	2
P99-1015	J88-2003	1999	However, this incompleteness is also a consequence of the linguistic characteristics of various indicators	0	For example:  Aspectual coercion such as iteration compromises indicator measurements <TREF>Moens and Steedman, 1988</TREF>	1	For example, a punctual event appears with the progressive in, She was sneezing for a week	0	point --, process --	0	6	1
P99-1015	J88-2003	1999	For example, I made a fire is culminated, since a new state is introduced something is made, whereas, I gazed at the sunset is non-culminated	0	Aspectual classification is necessary for interpreting temporal modifiers and assessing temporal entailments <REF>Vendler, 1967</REF>; <REF>Dowty, 1979</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Dorr, 1992</REF>, and is therefore a necessary component for applications that perform certain natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks	1	Aspect introduces a large-scale, domaindependent lexical classification problem	1	Although an aspectual lexicon of verbs would suffice to classify many clauses by their main verb only, a verbs primary class is often domaindependent <REF>Siegel, 1998b</REF>	0	3	2
P99-1015	J88-2003	1999	112 Table 1: Aspectual classes	0	This table comes from Moens and Steedman <TREF>Moens and Steedman, 1988</TREF>	1	Culm EVENTS STATES punctual extended CULM CULM PROCESS recognize build a house NonPOINT PROCESS Culm hiccup run, swim understand 2 Aspect in Natural Language Table 1 summarizes the three aspectual distinctions, which compose five aspectual categories	1	In addition to the two distinctions described in the previous section, atomicity distinguishes events according to whether they have a time duration punctual versus extended	0	3	2
C92-4177	J88-2003	1992	This can effect not only the semantic interpretation of the text itself, but also translation and the choice of adverb	0	3 3Many of these issues are discussed in the CL Special Issue on Tense and Aspect <REF>June, 1988</REF> in articles by Hinniche, Moens and Steedman, Nakhimovsky, Passoneau, and Webber	1	For example, Passoneau demonstrates how, without an ccurate specification of the pectual tendencies of the verb coupled with the effect of temporal and aspectual adjuncts, messages, which tend to be in the present tense, ttre not correctly understood nor generated in the PUNDIT system	0	For instance, the pressure is low must be interpreted at statlve, whereas the pump operates must be interpreted as a process	0	4	2
W94-0312	J88-2003	1994	It is also clear that events are not undifferentiated masses, but rather have subparts that can be picked out by the choice of phrase type or the addition of adverbial phrases	0	<TREF>Moens  Steedman 1988</TREF> identify three constituents to an event nucleus, a preparatory process, culmination, and consequent state, whereas <REF>Nakhimovsky 1988</REF> identifies five: preparatory, initial, body, final, result, exemplified by the following: 1 15	1	When the children crossed the road, a they waited for the teacher to give a signal b they stepped onto its concrete surface as if it were about to swallow them up	0	c they were nearly hit by a car d they reached the other side stricken with fear	0	5	2
J91-4003	J88-2003	1991	I will call this level the event structure of a word cf	0	<REF>Pustejovsky 1991</REF>; <TREF>Moens and Steedman 1988</TREF>	1	The event structure of a word is one level of the semantic specification 419 Computational Linguistics Volume 17, Number 4 for a lexical item, along with its argument structure, qualia structure, and inheritance structure	0	Because it is recursively defined on the syntax, it is also a property of phrases and sentences	0	6	1
C08-1092	J88-2003	2008	Weather would seem selfcontained, but change, creation and stative are not semantic fields at all	0	Stative belongs to the Aktionsart categorisation of verbs distinguishing it from verbs of activity, achievement and accomplishment, which is orthogonal to the categorisation of verbs into semantic fields <REF>Vendler, 1967</REF>, <TREF>Moens  Steedman 1988</TREF>, <REF>Amaro, 2006</REF>	1	Moreover, a verb can belong to more than one Aktionsart category, as these apply to verbs in contexts	0	33 Suggested Revision of Categories Among verbs, the level of arbitrariness and incorrectness of the WordNet categories seems greater than that of the relations	0	4	2
W06-0906	J88-2003	2006	Differences in annotation could be due to the differences in interpretations of the event; however, we found that the vast majority of radically different judgments can be categorized into a relatively small number of classes	1	Some of these correspond to aspectual features of events, which have been intensively investigated eg , <REF>Vendler, 1967</REF>; <REF>Dowty, 1979</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Passonneau, 1988</REF>	1	We then developed guidelines to cover those cases see the next section	0	22 Event Classes Action vs State: Actions involve change, such as those described by words like speaking, gave, and skyrocketed	0	4	2
W98-0602	J88-2003	1998	Events of type eat differ from those of type run in the way the result d is brought about	0	This can be illustrated by means of the notion of a nucleus-structure Moens/<REF>Steedman 1988</REF>	1	A nucleus-structure consists of three parts: the inception-point IP, the development-portion DP and the culmination-point CP	1	Nucleus-Structure e S S  IP DP CP Figure 1 The result  is evaluated at each part of the nucleus-structure	0	4	2
P90-1016	J88-2003	1990	Further, we do not have a theory of the interaction of temporal interpretation with aspect	0	<REF>See Dowty, 1979</REF>; <REF>Dowty, 1986</REF>; <REF>Moens, 1987</REF>; <TREF>Moens and Steedman, 1988</TREF>; <REF>Nakhimovsky, 1988</REF>; and <REF>Passoneau, 1988</REF>	0	found in these works	0	Section 5 provides a more detailed comparison with <REF>Yip 1986</REF> and <REF>Hornstein 1990</REF>	0	6	1
W04-0912	J88-2003	2004	The decisive units for this selection are phases and boundaries <REF>Bickel, 1996</REF>	0	Presuming a tripartite event structure <TREF>Moens and Steedman, 1988</TREF> consisting of a preparation phase dynamic phase  dyn , a culmination point boundary  and a consequent state static phase  stat , there are three possibilities for aspect to select	1	English and Turkish both have  dyn -selecting aspectual markers, Turkish also a marker for explicit  stat selection; Russian pf aspect explicitly selects 	0	The unmarked members of the aspectual oppositions may assert anything else  Russian ipf aspect may assert anything but the explicit selection of a boundary	0	6	1
P04-1017	P83-1007	2004	The knowledge about the context of anaphor and antecedent is nevertheless ignored	0	However, research in centering theory <REF>Sidner, 1981</REF>; <TREF>Grosz et al , 1983</TREF>; <REF>Grosz et al , 1995</REF>; <REF>Tetreault, 2001</REF> has revealed that the local focusing or centering also has a great efiect on the processing of pronominal expressions	0	The choices of the antecedents of pronouns usually depend on the center of attention throughout the local discourse segment <REF>Mitkov, 1999</REF>	0	To determine the salience of a candidate in the local context, we may need to check the coreferential information of the candidate, such as the existence and properties of its antecedents	0	0	0
P07-2040	P83-1007	2007	We report the results of our experiments in Section 3 and conclude the paper in Section 4	0	2 Relation Detection The proposed method employs contextual features based on centering theory <TREF>Grosz et al , 1983</TREF> as well as conventional syntactic and word-based features	0	These features are organized as a tree structure and are fed into a boosting-based classification algorithm	0	The method consists of three parts: preprocessing POS tagging, NE tagging, and parsing, 1The numbers show correspondences of words between Japanese and English	0	0	0
P98-2204	P83-1007	1998	I propose a model for determining the heaters attentional state in understanding discourse	0	My proposal is inspired by the centering model <TREF>Grosz et al , 1983</TREF>; 1995 and draws on the conclusions of Strube  Hahns 1996 approach for the ranking of the forward-looking center list for German	0	Their approach has been proven as the point of departure for a new model which is valid for English as well	0	The use of the centering transitions in Brennan et als 1987 algorithm prevents it from being applied incrementally cf	0	0	0
P98-2204	P83-1007	1998	2 A Look Back: Centering The centering model describes the relation between the focus of attention, the choices of referring expressions, and the perceived coherence of discourse	0	The model has been motivated with evidence from preferences for the antecedents of pronouns <TREF>Grosz et al , 1983</TREF>; 1995 and has been applied to pronoun resolution Brennan et al	0	1987, inter alia, whose interpretation differs from the original model	0	The centering model itself consists of two constructs, the backward-looking center and the list of forward-looking centers, and a few rules and constraints	0	0	0
E95-1035	P83-1007	1995	2 For the problem with multi-sentence discourses, and the threads that sentences continue, we use an implementation of temporM centering <REF>Kameyama et al , 1993</REF>; <REF>Poesio, 1994</REF>	0	This is a technique similar to the type of centering used for nominal anaphora <REF>Sidner, 1983</REF>; <TREF>Grosz et al , 1983</TREF>	1	Centering assumes that discourse understanding requires some notion of aboutness	0	While nominal centering assumes there is one object that the current discourse is about, temporal centering assumes that there is one thread that the discourse is currently following, and that, in addition to tense and aspect constraints, there is a preference for a new utterance to continue a thread which has a parallel tense or which is semantically related to it and a preference to continue the current thread rather than switching to another thread	0	2	1
P95-1015	P83-1007	1995	Passonneau to appear examined some of the few claims relating discourse anaphoric noun phrases to global discourse structure in the Pear corpus	0	Resuits included an absence of correlation of segmental structure with centering <TREF>Grosz et al , 1983</TREF>; <REF>Kameyama, 1986</REF>, and poor correlation with the contrast between full noun phrases and pronouns	1	As noted in <REF>Passonneau and Litman, 1993</REF>, the NP features largely reflect Passonneaus hypotheses that adjacent utterances are more likely to contain expressions that corefer, or that are inferentially linked, if they occur within the same segment; and that a definite pronoun is more likely than a full NP to refer to an entity that was mentioned in the current segment, if not in the previous utterance	0	33 Evaluation The segmentation algorithms presented in the next two sections were developed by examining only a training set of narratives	0	6	1
C98-2199	P83-1007	1998	I propose a model for determining the hearers attentional state in understanding discourse	0	My proposal is inspired by the centering model <TREF>Grosz et al, 1983</TREF>; 1995 and draws on the conclusions of Strube  Hahns 1996 approach for the ranking of the forward-looking center list for German	0	Their approach has been proven as the point of departure for a new model which is valid for English as well	0	The use of the centering transitions in Brennan et als 1987 algorithm prevents it from being applied incrementally cf	0	0	0
C98-2199	P83-1007	1998	2 A Look Back: Centering The centering model describes the relation between the focus of attention, the choices of referring expressions, and the perceived coherence of discourse	0	The model has been motivated with evidence from preferences for the antecedents of pronouns <TREF>Grosz et al, 1983</TREF>; 1995 and has been applied to pronoun resolution Brennan et al	0	1987, inter alia, whose interpretation differs from the original model	0	The centering model itself consists of two constructs, the backward-looking center and the list of forward-looking centers, and a few rules and constraints	0	0	0
P89-1030	P83-1007	1989	Any communicative act, be it spoken, written, gestured, or system-initiated, can give rise to DEs	0	As a discourse progresses, an adequate discourse model must represent the relevant entities, and the relationships between them <REF>Grosz and Sidner, 1986</REF>, A speaker may then felicitously refer anaphorically to an object subject to focusing or centering constraints <TREF>Grosz et al , 1983</TREF>, <REF>Sidner 1981, 1983</REF>, <REF>Brennan et al 1987</REF>  if there is an existing DE representing it, or if a corresponding DE may be directly inferred from an existing DE	1	For example, the utterance Every senior in Milford High School has a car gives rise to at least 3 entities, describable in English as the seniors in Milford High School, Milford High School, and the set of cars each of which is owned by some senior in Milford High School	0	These entities may then be accessed by the following next utterances, respectively: They graduate in June	0	6	1
P89-1030	P83-1007	1989	This is, to our knowledge, the first implementation of Webbers DE generation ideas	0	We designed the 243 algorithms and structures necessary to generate discourse entities from our logical representation of the meaning of utterances, and from pointing gestures, and currently use them in Januss <REF>Weischedel et al , 1987</REF>, BSN, 1988 pronoun resolution component, which applies centering techniques <TREF>Grosz et al , 1983</TREF>, <REF>Sidner 1981, 1983</REF>, <REF>Brennan et al 1987</REF> to track and constrain references	1	Janus has been demonstrated in the Navy domain for DARPAs Fleet Command Center Battle Management Program FCCBMP, and in the Army domain for the Air Land Battle Management Program ALBM	0	2 Meaninq Representation for DE Generation Webber found that appropriate discourse entities could be generated from the meaning representation of a sentence by applying rules to the representation that are strictly structural in nature, as long as the representation reflects certain crucial aspects of the sentence	0	3	2
P95-1040	P83-1007	1995	This distinction underlies my proposals about the attentional consequences of pitch accents when applied to pronominals, in particular, that while most pitch accents may weaken or reinforce a cospecifiers status as the center of attention, a contrastively stressed pronominal may force a shift, even when contraindicated by textual features	0	To predict and track the center of attention in discourse, theories of centering <TREF>Grosz et al , 1983</TREF>; <REF>Brennan et al , 1987</REF>; <REF>Grosz et al , 1989</REF> and immediate focus <REF>Sidner, 1986</REF> rely on syntactic and grammatical features of the text such as pronominalization and surface sentence position	0	This may be sufficient for written discourse	0	For oral discourse, however, we must also consider the way intonation affects the interpretation of a sentence, especially the cases in which it alters the predictions of centering theories	0	0	0
J99-2001	P83-1007	1999	3	0	Processing Complex Sentences: A Reason for Extending Focusing Algorithms Although complex sentences are prevalent in written English, most other local focusing research focusing: Sidner 1979 and Carter 1987; centering: Grosz, Joshi, and Weinstein 1983, 1995, Brennan, Friedman, and Pollard 1987, Walker 1989, 1993, Kameyama 1986 2, Walker, Iida, and Cote 1994, Brennan 1998, Kameyama, Passonneau, and Poesio 1993, Linson 1993 and Hoffman 1998; and PUNDIT: Dahl 1986, Palmer et al 1986, and Dahl and Ball 1990 did not explicitly and/or adequately address how to process complex sentences	0	Thus, there is a need to extend focusing algorithms	0	An exception to this rule is the work of <REF>Strube 1996</REF> which applies functionalinformation-structure-based criteria on a per-clause basis, <REF>Kameyama 1998</REF>, and <REF>Strube 1998</REF>	0	0	0
P96-1036	P83-1007	1996	This claim is backed up by an empirical evaluation of functional centering	0	The centering model has evolved as a methodology for the description and explanation of the local coherence of discourse <TREF>Grosz et al , 1983</TREF>; 1995, with focus on pronominal and nominal anaphora	0	Though several cross-linguistic studies have been carded out cf	0	the enumeration in Grosz et al	0	0	0
P96-1036	P83-1007	1996	This claim, however, has to be further substantiated by additional cross-linguistic empirical studies	0	5 Comparison with Related Approaches The centering model <TREF>Grosz et al , 1983</TREF>; 1995 is concerned with the interactions between the local coherence of discourse and the choices of referring expressions	0	Crucial for the centering model is the way the forward-looking centers are organized	0	Despite several cross-linguistic studies a kind of standard has emerged based on the study of English cf	0	0	0
C88-2159	P83-1007	1988	Its identification needs peech act cal;egorization of sentences	0	This topic-based approach is in contrast to Kameyamas,Japanese version <REF>Kameyama 1985</REF>, <REF>Kameyama 1986</REF> of tbcus-based spproach to anaphora by <TREF>Grosz et al 1983</TREF>	1	In her framewock, subjecthood and predicate deixis play the principal role, and the fact that topic provides the most important clue to anaphora identification in actual spoken Japanese discourse is not utilized eexplicitly	0	,-L3 Extension of topic introduction One of the pobems with the topicobased approach is that topics reerred to by zero pronouns are not always e:pliitiy marked by the topic postposition wa	0	2	1
P00-1052	P83-1007	2000	In this study,we employ the e-rater essay scoring system to test a hy1 http:2F2Flsacoloradoedu	0	2 http:2F2Fwwwetsorg2Fresearch2Feraterhtml pothesis related to Centering Theory 28<REF>Joshi and Weinstein, 1981</REF>; <TREF>Grosz et al , 1983</TREF>, inter alia29	0	We focus on Centering Theorys Rough-Shift transition which is the least well studied among the four transition types	0	In particular, we examine whether the discourse coherence found in an essay, as de0Cned bya measure of relative proportion of Rough-Shift transitions, might be a signi0Ccant contributor to the accuracy of computer-generated essay scores	0	0	0
P91-1014	P85-1018	1991	The parser can be modified to simulate other types of machines such LRk-like or SLR-like automata	0	It can also be extended to handle unification based grammars using a similar method as that employed by <TREF>Shieber 1985</TREF> for extending Earleys algorithm	1	Furthermore, the algorithm can be tuned to a particular grammar and therefore be made more efficient by carefully determinizing portions of the nondeterministic machine while making sure that the number of states in not increased	0	These variants lead to more efficient parsers than the one based on the basic non-deterministic push-down machine	0	6	1
W91-0108	P85-1018	1991	Finally note that in cases where substantial material has to be supplied, as it were, by the target grammar eg if a transitive verb is supplied but no object, then Definition 3 would allow arbitrary lexicalisations, giving rise to a very large number of permissible outputs	0	If this is felt to be problem, then estricting in the sense of <TREF>Shieber 1985</TREF> the subsumption test in the second half of Definition 3 to ignore the values of certain features, ie pred, would bepstraight-forward	1	This would have the effect of producing a single, exemplary lexicalisation for each significantly different ie different ignoring differences under pred structure which satisfies the minimaximal requirements	0	II4 A Problem with the Mini-maximal Approach One potential problem clearly arises with this approach	0	6	1
P96-1058	P85-1018	1996	So, top-down constraints must be weakened in order for parsing to be guaranteed to terminate	0	In order to solve the nontermination problem, <TREF>Shieber 1985</TREF> proposes restrictor, a statically predefined set of features to consider in propagation, and restriction, a filtering function which removes the features not in restrictor from top-down expectation	1	However, not only does this approach fail to provide a method to automatically generate the restrictor set, it may weaken the predicative power of top-down expectation more than necessary: a globally defined restrictor can only specify the least common features for all propagation paths	1	In this paper, a general method of maximizing top-down constraints is proposed	0	1	3
J01-2005	P85-1018	2001	Manual detection is also problematic: when a grammar is large, particularly if semantic features are included, complete detection is nearly impossible	0	As for the techniques developed so far which partially solve prediction nontermination eg , <TREF>Shieber 1985</TREF>; <REF>Haas 1989</REF>; <REF>Samuelsson 1993</REF>, they do not apply to nonminimal derivations because nonminimal derivations may arise without left recursion or recursion in general s One way is to define p to filter out all features except the context-free backbone of predictions	1	However, this severely restricts the range of possible instantiations of Shiebers algorithm	0	9 A third possibility is to manually fix the grammar so that nonminimal derivations do not occur, as we noted in Section 4	0	1	3
J01-2005	P85-1018	2001	However, simple subsumption may filter out valid parses for some grammars, thus sacrificing completeness	0	7 Another possibility is to filter out problematic features in the Prediction step by using the function p However, automatic detection of such features ie , automatic derivation of p is undecidable for the same reason as the prediction nontermination problem caused by left recursion for unification grammars <TREF>Shieber 1985</TREF>	1	Manual detection is also problematic: when a grammar is large, particularly if semantic features are included, complete detection is nearly impossible	0	As for the techniques developed so far which partially solve prediction nontermination eg , <TREF>Shieber 1985</TREF>; <REF>Haas 1989</REF>; <REF>Samuelsson 1993</REF>, they do not apply to nonminimal derivations because nonminimal derivations may arise without left recursion or recursion in general s One way is to define p to filter out all features except the context-free backbone of predictions	1	1	3
J01-2005	P85-1018	2001	1	0	Unification grammar is a term often used to describe a family of feature-based grammar formalisms, including GPSG <REF>Gazdar et al 1985</REF>, PATR-II <REF>Shieber 1986</REF>, DCG <REF>Pereira and Warren 1980</REF>, and HPSG <REF>Pollard and Sag 1994</REF>	1	In an effort to formalize the common elements of unification-style grammars, <REF>Shieber 1992</REF> developed a logic for describing them, and used this logic to define an abstract parsing algorithm	0	The algorithm uses the same set of operations as Earleys 1970 algorithm for context-free grammars, but modified for unification grammars	0	6	1
P90-1024	P85-1018	1990	It is more so because 1 there is no restriction such as that there should be only one zero morpheme within an S clause, and 2 the stack is useless because zero morphemes are independent morphemes and are not bound to other morphemes comparable to wh-words	0	<TREF>Shieber 1985</TREF> proposes a more efficient approach to gaps in the PATR-II formalism, extending Earleys algorithm by using restriction to do top-down filtering	1	While an approach to zero morphemes similar to Shiebers gap treatment is possible, we can see one advantage of ours	1	That is, our approach does not depend on what kind of parsing algorithm we choose	1	1	3
J93-4001	P85-1018	1993	However, if features are carefully selected so as to increase the amount of pruning done by the chart, the net effect may 583 Computational Linguistics Volume 19, Number 4 be that even though the grammar allows more types of constituents, the chart may end up with fewer instances	0	It is interesting to compare this technique to the restriction proposal in <TREF>Shieber 1985</TREF>	1	Both approaches select functional features to be moved forward in processing order in the hope that some processing will be pruned	1	Shiebers approach changes the processing order of functional constraints so that some of them are processed top-down instead of bottom-up	0	2	1
J97-3004	P85-1018	1997	For the experiments discussed in the final section all goal-weakening operators were chosen by hand, based on small experiments and inspection of the goal table and item table	0	Even if goal weakening is reminiscent of Shiebers 1985 restriction operator, the rules of the game are quite different: in the case of goal weakening, as much information as possible is removed without risking nontermination of the parser, whereas in the case of Shiebers restriction operator, information is removed until the resulting parser terminates	1	For the current version of the grammar of OVIS, weakening the goal category in such a way that all information below a depth of 6 is replaced by fresh variables eliminates the problem caused by the absence of the occur check; moreover, this goal-weakening operator reduces parsing times substantially	1	In the latest version, we use different goal-weakening operators for each different functor	0	2	3
J97-3004	P85-1018	1997	Depending on the properties of a particular grammar, it may, for example, be worthwhile to restrict a given category to its syntactic features before attempting to solve the parse-goal of that category	0	Shiebers 1985 restriction operator can be used here	1	Thus we essentially throw some information away before an attempt is made to solve a memorized goal	0	For example, the category xA, B, f A, B, gA,hB, i C   may be weakened into: xA,B,f ,,g, If we assume that the predicate weaken/2 relates a term t to a weakened version tw, such that tw subsumes t, then 15 is the improved version of the parse predicate: parsewithweakening Cat, P0, P, E0, E  15 weakenCat,WeakenedCat, parseWeakenedCat,P0,P,E0,E, CatWeakenedCat	0	3	2
J97-3004	P85-1018	1997	Therefore, we generally cannot use all information available in the grammar but rather we should compute a weakened version of the linking table	0	This can be accomplished, for example, by replacing all terms beyond a certain depth by anonymous variables, or by other restrictors <TREF>Shieber 1985</TREF>	1	Secondly, the use of a linking table may give rise to spurious ambiguities	0	Consider the case in which the category we are trying to parse can be matched against two different items in the linking table, but in which case the predicted head-category may turn out to be the same	0	6	1
J89-4001	P85-1018	1989	One can obtain similar results for the class of grammars whose context-free backbone is finitely ambiguous--what <REF>Pereira and Warren 1983</REF> called the offline-parsable grammars	0	However, as <TREF>Shieber 1985b</TREF> observed, this class of grammars excludes many linguistically interesting grammars that do not use atomic category symbols	1	230 The present parser as opposed to the table-building algorithm is much like those in the literature	0	Like nearty all parsers using term unification, it is a special case of Earley deduction <REF>Pereira and Warren 1985</REF>	0	6	1
J89-4001	P85-1018	1989	<REF>Sato and Tamaki 1984</REF> proposed to analyze the behavior of Prolog programs, including parsers, by using something much like a weak prediction table	0	To guarantee that the table was finite, they restricted the depth of terms occurring in the table <TREF>Shieber 1985b</TREF> offered a more selective approach--his program predicts only those features chosen by the user as most useful for prediction	1	<REF>Pereira and Shieber 1987</REF> discuss both approaches	0	We will present a variation of Shiebers ideas that depends on using a sorted language	0	2	1
J89-4001	P85-1018	1989	Any general parsing method for definite clause grammar will enter an infinite loop in some cases, and it is the task of the grammar writer to avoid this	0	Generalized phrase structure grammar avoids the problem because it has only the formal power of context-free grammar <REF>Gazdar et al 1985</REF>, but according to <TREF>Shieber 1985a</TREF> this is not adequate for describing human language	1	Lexical functional grammar employs a better solution	0	A lexical functional grammar must include a finitely ambiguous context-free grammar, which we will call the context-free backbone <REF>Barton 1987</REF>	0	6	1
J89-4001	P85-1018	1989	We then define the set of terms in a standard way	0	All unification in this paper is unification of terms, as in <REF>Robinson 1965</REF>--not graphs or other structures, as in much recent work <TREF>Shieber 1985b</TREF>	1	A unification grammar is a five-tuple G  S, ,r T, P, Z where S is a set of sorts, ,r an S-ranked alphabet, T a finite set of terminal symbols, and Z a function letter of arity e in ,r	0	Z is called the start symbol of the grammar the standard notation is S not Z, but by bad luck that conflicts with standard notation for the set of sorts	0	2	1
J89-4001	P85-1018	1989	One could devise more elaborate examples, but this one suffices to make the point: not every natural unification grammar has an obvious context-free backbone	0	Therefore it is useful to have a parser that does not require us to find a context-free backbone, but works directly on a unification grammar <TREF>Shieber 1985b</TREF>	1	We propose to guarantee that the parsing problem is solvable by restricting ourselves to depth-bounded grammars	0	A unification grammar is depth-bounded if for every L > 0 there is a D > 0 such that every parse tree for a sentential form of L symbols has depth less than D In other words, the depth of a tree is bounded by the length of the string it derives	0	6	1
J89-4001	P85-1018	1989	The grammar is depth-bounded because the depth of a tree is a linear function of the length of the string it derives	0	A similar grammar can derive the crossed serial dependencies of Swiss German, which according to <TREF>Shieber 1985a</TREF> no context-free grammar can derive	1	It is clear where the extra formal power comes from: a contextfree grammar has a finite set of nonterminals, but a unification grammar can build arbitrarily large nonterminal symbols	0	It remains to show that there is a parsing algorithm for depth-bounded unification grammars	0	6	1
P94-1016	P85-1018	1994	Some additional penalty may also have been incurred by not using dotted grammar rules to generate reductions, as in standard leftcorner parsing algorithms	0	2 There are important differences between the technique for limited prediction in this parser, and other techniques for limited prediction such as Shiebers notion of restriction <TREF>Shieber, 1985</TREF> which we also use	1	In methods such as Shiebers, predictions are weakened in ways that can result in an overall gain in efficiency, but predictions nevertheless must be dynamically generated for every phrase that is built bottom-up	1	In our log version 314	0	3	2
P94-1016	P85-1018	1994	In addition, the parser maintains a skeletal copy of the chart in which edges are labeled only by the nonterminal symbols contained in their context-free backbone, which gives us more efficient indexing of the full grammar rules	0	Other optimizations include using one-word look-ahead before adding new predictions, and using restrictors <TREF>Shieber, 1985</TREF> to increase the generality of the predictions	1	Comparison with Other Parsers Table 1 compares the average number of edges, average number of predictions, and average parse times 1 in seconds per utterance for the limited 1All parse times given in this paper were produced on a Sun SPARCstation 10/51, running Quintus Pro111 For grammar with start symbol , phrase structure rules P, lexicon L, context-independent categories CI, and context-dependent categories CD; and for word string w  wlwn: Variant Edges Preds Secs Bottom-Up 1191 0 146 Limited Left-Context 203 25 10 Left-Corner 112 78 40 Table h Comparison of Syntax-Only Parsers if  E CD, predictT, 0; addemptycategories 0 ; for i from I to n do foreach C such that C--wi EL do addedgetochartC, i-i, i ; makenewpredictionsC, ii, i ; findnew-reductionsC, il,i end addemptycategories i ; end sub findmew-reductionsB, j, k  foreach A and a such that A- B 6 P do foreach i such that i  match, j do if A 6 CD and predictedA,i or A 6 CI addedgetochartA, i, k; makenewpredictionsA, i, k ; findnewreductionsA, i, k ; end end  sub addemptycategoriesi  foreach A such that A - e E P do if A 6 CD and predictedA,/ or A 6 CI addedgetochartA, i, i ; makenewpredictionsA, i, i ; findnewreductionsA, i, i ; end  sub makenewpredictionsA, i, j  foreach Aft E Predictionsi do predict fl, j end foreach H - ABfl 6 P such that H 6 CI and B E CD and fl 6 CI do predict B, j end foreach H -- AB 6 P such that H E CD and B E CD and fl E CI and predictedH, i or H left-corner-of C and predictedC, i do predict B, j end Figure 1: Limited Left-Context Algorithm left-context parser with those for a variant equivalent to a bottom-up parser when all categories are context independent and for a variant equivalent to a left-corner parser when all categories are context dependent	0	The tests were performed on a set of 194 utterances chosen at random from the ARPA ATIS corpus MADCOW, 1992, using a broad-coverage syntactic grammar of English having 84 coverage of the test set	0	3	2
P98-1101	P85-1018	1998	The situation becomes more complicated when we move to unification-based grammars, since there may be an unbounded number of different categories appearing in the accessible stack states	0	In the system implemented here we used restriction <TREF>Shieber, 1985</TREF> on the stack states to restrict attention to a finite number of distinct stack states for any given stack depth	1	Since the restriction operation maps a stack state to a more general one, it produces a finite-state approximation which accepts a superset of the language generated by the original unification grammar	0	Thus for general constraint-based grammars the language accepted by our finite-state approximation is not guaranteed to be either a superset or a subset of the language generated by the input grammar	0	3	2
E91-1052	P85-1018	1991	Since the size of the state sets possible with finite partitioning is now finite, the algorithm always terminates	0	After establishing a correspondence between attribute and unification grammar UG, we may see that the technique of restriction used by <TREF>Shieber 1985</TREF> in his extended algorithm is related to finite partitioning on attribute domains, in fact a particular case which takes advantage of the more structured attribute domains of UG	1	For attribute grammar, given that the domains involved are more general eg , the integers, finite partitioning is the required device	0	5	0	6	1
E91-1052	P85-1018	1991	1	0	Earleys 1970 algorithm is a general algorithm for context-free languages, widely used in natural language processing <REF>King, 1983</REF>; <TREF>Shieber, 1985</TREF> and syntactic pattern recognition <REF>Fu, 1982</REF>, where the full generative power of context-free grammar is required	1	The original algorithm and its common implementations, however, assume the atomic symbols of context-free grammars, thus limiting its applicability to systems with attributed symbols, or attribute grammars <REF>Knuth, 1968</REF>	0	Attribute grammar is an elegant formalization of the augmented context-free grammars characteristic of most current NLP systems	0	6	1
E91-1052	P85-1018	1991	However, their particular realization of the technique is severely restricted for NLP applications, since it uses a deterministic one-path LR algorithm, applicable only to semantically unambiguous grammars	0	<REF>Pereira and Warren 1983</REF> and <TREF>Shieber 1985</TREF> present v6rsions of Earleys algorithm for unification grammars, in which unification is the sole operation responsible for attribute evaluation	1	However, given the high computational cost of unification, important differences between attribute and unification grammars in their respective attribution domains and functions Correa, forthcoming, and the more general nature of attribute grammars in this regard, it is of interest to investigate the extension of Earleys algorithm directly to the main subclasses of attribute grammar	1	The paper is organized as follows: Section 2 presents pieliminary elements, including a definition of attribute grammar and Earleys algorithm	0	1	3
E91-1052	P85-1018	1991	Attribute grammar is an elegant formalization of the augmented context-free grammars characteristic of most current NLP systems	0	It is more general than members of the family of unification-based grammar formalisms <REF>Kay, 1985</REF>; <REF>Shieber, 1986</REF>, mainly in that it allows and encourages the use of simpler attribution functions than unification for the definition of attribute values, and hence can lead to computationally efficient grammatical definitions, while maintaining the advantages of a well-understood declarative formalism	1	Attribute grammar has been used in the past by the author to define computational models of Chomskys Government-binding theory, from which practical parsing programs were developed <REF>Correa, 1987a</REF>	0	Many systems based on Earleys algorithm have a clear division between the phases of syntactic and semantic analysis	0	2	1
P89-1029	P85-1018	1989	The parsing problem for offline parsable grammars ts solvable	0	Yet these grammars apparently have enough formal power to describe natural language at least, they can describe the crossed-serial dependencies of Dutch and Swiss German, which are presently the most widely accepted example of a construction that goes beyond context-free grammar <TREF>Shieber 1985a</TREF>	1	Suppose that the variable M ranges over integers, and the function letter s denotes the successor function	0	Consider the rule 1 pM --- psM A grammar containing this rule cannot be offline parsable, because erasing the arguments of the top-level terms in the rule gives 2 p --- p which immediately leads to infinite ambiguity	0	1	2
P89-1029	P85-1018	1989	These ideas can be generalized to other forms of unification	0	Consider dag unification as in <TREF>Shieber 1985b</TREF>	1	Given a set S of sorts, assign a sort to each label and to each atomic dag	1	The arity of a label is a set of sorts not a sequence of sorts as in term unification	0	6	1
J90-1004	P85-1018	1990	This does not deny that compilation methods may be able to convert a grammar into a program that generates without termination problems	0	In fact, the partial execution techniques described by two of us <REF>Pereira and Shieber 1985</REF> could form the basis of a compiler built by partial execution of the new algorithm we propose below relative to a grammar	1	However, the compiler will not generate a program that generates top-down, as Strzalkowskis does	1	v c,k,mj V mj I zag V k,m V e,k saw  helpen voeren help feed Figure 2 Schematic of Verb Subeategorization Lists for Dutch Example	0	1	3
J90-1004	P85-1018	1990	But even this ad hoc solution is problematic, as there may be no principled bound on the size of the subcategorization list	0	For instance, in analyses of Dutch cross-serial verb constructions <REF>Evers 1975</REF>; <REF>Huybrechts 1984</REF>, subcategorization lists may be concatenated by syntactic rules Moort32 Computational Linguistics Volume 16, Number 1, <REF>March 1990</REF> Shieber et al Semantic Head-Driven Grammar gat 1984; <REF>Fodor et al 1985</REF>; <REF>Pollard 1988</REF>, resulting in arbitrarily long lists	1	Consider the Dutch sentence dat Jan Marie de oppasser de olifanten zag helpen that John Mary the keeper the elephants saw help voeren feed that John saw Mary help the keeper feed the elephants The string of verbs is analyzed by appending their subcategorization lists as in Figure 2	0	Subcategorization lists under this analysis can have any length, and it is impossible to predict from a semantic structure the size of its corresponding subcategorization list merely by examining the lexicon	1	1	3
J90-1004	P85-1018	1990	The symptom is an ordering paradox in the sorting	0	For example, the complements rule given by <TREF>Shieber 1985a</TREF> in the PATR-II formalism VP 1 -- VP 2 X VPl head  VP2 head VP2 syncat first  X <VP2 syncat rest  VPI syncat can be encoded as the DCG rule: vpHead, Syncat/VP ->,Head, Compl/LFlSyncat/VP, Compl/LF	1	Top-down generation using this rule will be forced to expand the lower VP before its complement, since LF is uninstantiated initially	0	Any of the reordering methods must choose to expand the child VP node first	0	6	1
J90-1004	P85-1018	1990	where the cat i are terms representing the grammatical category of an expression and its subconstituents	0	Terminal symbols are introduced into rules by enclosing them in list brackets, for example sbar/S --> that, s/S Such rules can be translated into Prolog directly using a difference list encoding of string positions; we assume readers are familiar with this technique <REF>Pereira and Shieber, 1985</REF>	1	Because we concentrate on the relationship between expressions in a language and their logical forms, we will assume that the category terms have both a syntactic and a semantic component	0	In particular, the infix function symbol / will be used to form categories of the form Syn/Sem where Syn is the syntactic category of the expression and Sere is an encoding of its semantics as a logical form; the previous rule uses this notation, for example	0	6	1
J90-1004	P85-1018	1990	This is the correlate of the link relation used in left-corner parsers with top-down filtering; we direct the reader to the discussion by Matsumoto et al	1	1983 or <REF>Pereira and Shieber 1985</REF> for further information	1	applicable  non  chain  ruleRoot, Pivot, RHS : semantics ofroot andpivot ere serae node semanticsRoot, Sem, node semanticsPivot, Sere,  choose a nonchain rue non  chain  ruloLHS, RHS,   whose lhs matches the pivot unifyPivot, LHS,  make sttre tile categories can connect chained nodesPivot, Root	0	A chain rule is applicable to connect a pivot to a root if the pivot can serve as the semantic head of the rule and the left-hand side of the rule is appropriate for linking to the root	0	6	1
J90-1004	P85-1018	1990	The reason is simple	0	Consider, for example, a grammar with a gap-threading treatment of wh-movement <REF>Pereira 1981</REF>; <REF>Pereira and Shieber 1985</REF>, which might include the rule npAffr, npAgr/SemJX-X/Sem -->  	1	stating that an NP with agreement Agr and semantics Sere can be empty provided that the list of gaps in the NP can be represented as the difference list npAgr/SemlX-X, that is, the list containing an NP gap with the same agreement features Agr	1	Because the above rule is a nonchain rule, it will be considered when trying to generate any nongap NP, such as the proper noun np3-sing, G-G/john	0	6	1
J90-1004	P85-1018	1990	Tile algorithm described in this paper is an attempt to resolve these problems in a satisfactory manner	0	Although we believe that this algorithm could be seen as an instance of a uniform architecture for parsing and generation--just as tile extended Earley parser <TREF>Shieber, 1985b</TREF> and the bottom-up generator were instances of the generalized Earley deduction architecture--our efforts to date have been aimed foremost toward the development of the algorithm for generation alone	1	We will mention efforts toward this end in Section 5	0	11 APPLICABILITY OF THE ALGORITHM As does the Earley-based generator, the new algorithm assumes that the grammar is a unification-based or logic grammar with a phrase structure backbone and complex nonterminals	0	2	1
C96-2106	P85-1018	1996	441 Identifying Functional Strata Manually Normally, the grammarian knows which information needs to be made explicit	0	Hence, instead of differentiating between the linguistic strata sYN and SEM, we let the linguist identify which constraints filter and which only serve as a means for representation; see also <TREF>Shieber, 1985</TREF>	1	In contrast to the separation along linguistic levels, this approach adopts a functional view, cutting across linguistic strata	0	On this view, the syntactic constraints together with, eg, semantic selection constraints would constitute a subgrammar	0	6	1
C96-2106	P85-1018	1996	Though theoretically very attractive, codescription has its price: i the grammar is difficult to modularize due to the fact that the levels constrain each other mutually and ii there is a computational overhead when parsers use the complete descriptions	0	Problems of these kinds which were already noted by <TREF>Shieber, 1985</TREF> motivated tile research described here	1	The goal was to develop more flexible ways of using codescriptive grammars than having them applied by a parser with full informational power	0	The underlying observation is that constraints in such grammars can play different roles:  Genuine constraints which relate directly to tile grammaticality wellformedness of the input	0	5	2
E95-1011	P85-1018	1995	Furthermore, the need to perform nondestructive unification means that a large proportion of the processing time is spent copying feature structures	0	One approach to this problem is to refine parsing algorithms by developing techniques such as restrictions, structure-sharing, and lazy unification that reduce the amount of structure that is stored and hence the need for copying of features structures <TREF>Shieber, 1985</TREF>; <REF>Pereira, 1985</REF>; <REF>Karttunen and Kay, 1985</REF>; <REF>Wroblewski, 1987</REF>; <REF>Gerdemann, 1989</REF>; <REF>Godden, 1990</REF>; <REF>Kogure, 1990</REF>; <REF>Emele, 1991</REF>; <REF>Tomabechi, 1991</REF>; <REF>Harrison and Ellison, 1992</REF>	1	While these techniques can yield significant improvements in performance, the generality of unification-based grammar formalisms means that there are still cases where expensive processing is unavoidable	1	This approach does not address the fundamental issue of the tradeoff between the descriptive capacity of a formalism and its computational power	0	1	2
C86-1045	P85-1018	1986	Original Earley prediction works on category symbols	0	An answer to these problems was presented by <TREF>Shieber 1985</TREF> who proposed to do Earley prediction on the basis of some finite quotient of all constituent DAGs which can be specified by the grammar writer	1	Another example for the influence of the CUG efforts on the development of PATR is a new template notation introduced by Lauri Karttunen in his Interlisp-D version of PATR	0	Since categorial grammars exhibit an extensive embedding of categories within other categories, it is useful to unify templates not only with the whole lexical DAG but also with its categorial subgraphs	0	4	2
C94-2141	P85-1018	1994	The sohltion to this problem is to define a finite number of equivalence classes into which the infinite uumber of nnnterminals inay be sorted	0	Fhese ,lasses may be established in a number of ways; the one we have adopted in that presented by Harrison and Ellison,  992 which builds on l;he work of <TREF>Shieber, 1985</TREF>: it introduces the nol;ion of a negative restrictor to define equivalence classes	1	In this solution a predefined portion of a category a specific set of paths is discarded when determining whether a category belongs to an equivalence :lass or not	0	For instance, in the above example we could define the negative restrictor to be orth	0	5	2
E91-1031	P85-1018	1991	It turns out to be the case that only in this way the effect of top-down filtering will pay-off against the increased overhead of having to check the left-corner table	0	6 Some Results The performance of the parsing algorithms discussed in the preceding sections a bottom-up parser for UG BU, a top-down parser for UG of <TREF>Shieber, 1985</TREF> TD, a top-down parser operating on an instantiated grammar TD/1, and a bottom-up parser with topdown filtering operating on an instantiated grammar BU/LC were tested on two experimental CUGs, one implementing the morphosyntactic features of German N Ps, and one implementing the syntax of WH-questions in Dutch by means of a gap-threading mechanism	1	Some illustrative results are listed in Tables 1 and 2	0	Sentencel Sentence2 items sees items sees TD: 93 59 160 105 TD/I: 45 20 68 25 BU: 68 20 120 30 Bu/ c: 12 o6 53 o9 Table1: German For German, an ideal restrictor R was < l > II  cat,val, arg, or dir	0	6	1
E91-1031	P85-1018	1991	In terms of parse times the two algorithms are almost equivalent	0	Comparing our results with those of <TREF>Shieber 1985</TREF> and <REF>Haas 1989</REF>, we see that in all cases top-down filtering may reduce the size of the chart significantly	1	<REF>Whereas Haas 1989</REF> found that top-down filtering never helps to actually decrease parse times in a bottom-up parser, we have found at least one example German where top-down filtering is useful	0	183 7 Conclusions There is a trend in modern linguistics to replace grammars that are completely language specific by grammars which combine universal rules and principles with language specific parameter settings, lexicons, etc This trend can be observed in such diverse frameworks as Lexical Functional Grammar, Government-Binding Theory, Head-driven Phrase Structure Grammar and Categorial Grammar	0	2	3
E91-1031	P85-1018	1991	CHART PARSING OF UNIFICATION GRAMMAR UG	0	Parsing methods for context-free grammar can be extended to unification-based grammar formalisms see <TREF>Shieber, 1985</TREF> or <REF>Haas, 1989</REF>, and therefore they can in principle be used to parse CUG	1	A chart-parser scans a sentence from left to right, while entering items, representing partial derivations, in a chart	0	Assume that items are represented as Prolog terms of the form itemBegin, End, LH S, Parsed, ToParse, where LHS is a feature-structure and Parsed and ToParse contain lists of feature-structures	0	6	1
E91-1031	P85-1018	1991	Contrary to bottomup parsing, however, the adaptation of a top-down algorithm for UG requires some special care	0	For UGs which lack a so-called context-free back-bone, such as CUG, the top-down prediction step can only be guaranteed to terminate if we make use of restriction, as defined in <TREF>Shieber 1985</TREF>	1	Top-down prediction with a restrictor R where R is a finite set of paths through a feature-structure amounts to the following: Restriction The restriction of a feature-structure F relative to a restrictor R is the most specific feature-structure F  E F, such that every path in F j has either an atomic value or is an element of R Predictor Step For each item, End, LHS, Parsed, Next I ToParse such that Rjve, is the restriction of Next relative to R, and each rule RNe:t  RHS, add itemi,i, Rge:t, , RHS	0	Restriction can be used to develop a top-down chart parser for CUG in which the top-down prediction step terminates	1	4	2
P89-1002	P85-1018	1989	The algorithm described in this paper is an attempt to resolve these problems in a satisfactory manner	0	Although we believe that this algorithm could be seen as an instance of a uniform architecture for parsing and generation--just as the extended Earley parser <TREF>Shieber, 1985b</TREF> and the bottom-up generator were instances of the generalized Earley deduction architecture our efforts to date have been aimed foremost toward the development of the algorithm for generation alone	1	We will have little to say about its relation to parsing, leaving such questions for later research1 2 Applicability of the Algorithm As does the Earley-based generator, the new algorithm assumes that the grammar is a unificationbased or logic grammar with a phrase-structure backbone and complex nonterminMs	0	Furthermore, and again consistent with previous work, we assume that the nonterminals associate to the phrases they describe logical expressions encoding their possible meanings	0	2	1
P89-1002	P85-1018	1989	This is the correlate of the link relation used in left-corner parsers with topdown filtering; we direct the reader to the discussion by Matsumoto et al	1	1983 or Pereira and Shieber 1985, p 182 for further information	1	applicablenonchainrule Root, Pivot, RHS :7o semantics of root and pivot are same nodesemantics Root, Sem, nodesemanticsPivot, Sem, o choose a nonchain rule nonehainrulerHS, RttS, whose lhs matches the pivot unifyPivot, LHS, make sure the categories can connect chainednodesPivot, Root	0	A chain rule is applicable to connect a pivot to a root if the pivot can serve as the semantic head of the rule and the left-hand-side of the rule is appropriate for linking to the root	0	6	1
P01-1022	P85-1018	2001	In particular, in order to derive a finite CF grammar, we will need to consider only those features that have a finite number of possible values, or at least consider only finitely many of the possible values for infinitely valued features	0	We can use the technique of restriction <TREF>Shieber 1985</TREF> to remove these features from our feature structures	1	Removing these features may give us a more permissive language model, but it will still be a sound approximation	1	The experimental results reported in this paper are based on a grammar under development at RIACS for a spoken dialogue interface to a semi-autonomous robot, the Personal Satellite Assistant PSA	0	1	2
C98-1098	P85-1018	1998	The situation becomes more complicated when we move to unification-based grammars, since there may be an unbounded number of different categories appearing in the accessible stack states	0	In the system implemented here we used restriction <TREF>Shieber, 1985</TREF> on the stack states to restrict attention to a finite number of distinct stack states for any given stack depth	1	Since the restriction operation maps a stack state to a more general one, it produces a finite-state approximation which accepts a superset of the language generated by the original unification grammar	0	Thus for general constraint-based grammars the language accepted by our finite-state aptroximation is not guaranteed to be either a superset or a subset of the language generated by the input grammar	0	3	2
P96-1033	P85-1018	1996	The rule builds up infinitely large subcategorization lists of which eventually only one is to be matched against the subcategorization list of, eg, the lexical entry for buys	0	Though this rule is not cyclic, it becomes cyclic upon off-line abstraction: magicvp VForm, CSem I3, SSem : magicvp VForm, CSem2l, SSem  Through trimming this magic rule, eg, given a bounded term depth <REF>Sato and Tamaki, 1984</REF> or a restrictor <TREF>Shieber, 1985</TREF>, constructing an abstract unfolding tree reveals the fact that a cycle results from the magic rule	1	This information can then be used to discard the culprit	0	312 Indexing Removing the direct or indirect cycles from the magic part of the compiled grammar does eliminate the necessity of subsumption checking in many cases	0	6	1
P96-1033	P85-1018	1996	As a result of the explicit representation of filtering we do not need to postpone abstraction until run-time, but can trim the magic predicates off-line	0	One can consider this as bringing abstraction into the logic as the definite clause representation of filtering is weakened such that only a mild form of connectedness results which does not affect completeness <TREF>Shieber, 1985</TREF>	1	Consider the following magic rule: magicvpVForm, CgemlArgs, SSem :magicvp VForm, Args, SSem  This is the rule that is derived from the headrecursive vp rule when the partially specified subcategorization list is considered as filtering information cf	0	, fn	0	6	1
P96-1033	P85-1018	1996	More specifically, magic generation falls prey to non-termination in the face of head recursion, ie, the generation analog of left recursion in parsing	0	This necessitates a dynamic processing strategy, ie, memoization, extended with an abstraction function like, eg, restriction <TREF>Shieber, 1985</TREF>, to weaken filtering and a subsumption check to discard redundant results	0	It is shown that for a large class of grammars the subsumption check which often influences processing efficiency rather dramatically can be eliminated through fine-tuning of the magic predicates derived for a particular grammar after applying an abstraction function in an off-line fashion	0	Unfolding can be used to eliminate superfluous filtering steps	0	1	2
P95-1014	P85-1018	1995	In the categorial grammar example only x/3 goals are memoized and thus only these goals incur the cost of table management	0	The abstraction step, which is used in most memoizing systems including complex feature grammar chart parsers where it is somewhat confusingly called restriction, as in <TREF>Shieber 1985</TREF>, receives an elegant treatment in a CLP approach; an abstracted goal is merely one in which not all of the equality constraints associated with the variables appearing in the goal are selected with that goal	1	2 For example, because of the backward application rule and the left-to-right evaluation our parser uses, eventually it will search at every left string position for an uninstantiated category the variable Y in the clause, we might as well abstract all memoized goals of the form xC, L, R to x, L, , ie, goals in which the category and right string position are uninstantinted	0	Making the equality constraints explicit, we see that the abstracted goal is obtained by merely selecting the underlined subset of these below: xXl,X2, X3,Xl  C, X2  L, Xa  R While our formal presentation does not discuss abstraction since it can be implemented in terms of constraint selection as just described, because our implementation uses the underlying Prologs unification mechanism to solve equality constraints over terms, it provides an explicit abstraction operation	0	6	1
C96-2111	P85-1018	1996	24 Top-Down Predictive Linking The aim of our proposal is to define equivalence relations that keep the linking relation finite while also preventing it from being too restrictive; this turns the linking relation into a weakpredietion table in the sense of Haas 1989: 227ff	0	Like Shieber 1985, 1992 with the notion of restriction, we confine our attention to a subset of specifications; in particular, we can define a feature structure that subsumes all VP-type feature structures of Shiebers recursive subcategorization rules	1	But unlike Shieber, our restrictors are computed automatically by building the generalization of the occurrences ofleftrecursive categories in a grammar	1	The intuitive idea is that we consider categories to be left recursive if their tokens can be unified rather than being identical, as in the case of atoms; we then use their generalization, or greatest lower bound, as a common denominator defining an equivalence relation	0	2	3
C96-2111	P85-1018	1996	A better solution, which we have adopted from <REF>Kilbury 1990</REF>, is to introduce rule numbers, which are then used to define a purely filtering linking relation	0	This amounts to the simplest case of the restriction technique of <TREF>Shieber 1985</TREF>	1	Only when a link between numerical pointers is first found is the linking relation between feature structures used to instantiate information	0	3 Consequences of Predictive Linking What is the advantage of predictive linking as discussed above in 2	0	6	1
C96-2111	P85-1018	1996	Such formalisms typically include a contextfree CF base, which allows the use of parsing algorithms designed for CF languages despite the fact that complex-feature-based formalisms are essentially more powerful than CF grammars	0	However, such an adaptation of CF algorithms involves their extension to possibly infinite nonterminal domains, which, as <TREF>Shieber 1985</TREF> and <REF>Haas 1989</REF> have shown, is nontrivial	1	Various CF algorithms make use of a binary relation between a goal category and the category of a constituent phrase or word which either has just been parsed or is to be parsed next	0	Different terms have been used to designate this relation; <REF>Kay 1980</REF> speaks of reachability, while Pereira/<REF>Shieber 1987</REF> and others before them use the term linking for the relation	0	6	1
C96-2111	P85-1018	1996	1990 have discussed similar techniques in the context of semantichead-driven generation, we are concerned here with parsing	0	We view the linking relation not simply as a filter to increase efficiency within the domain of syntactic analysis--this aspect is stressed by <TREF>Shieber 1985</TREF> and other investigators such as <REF>Bouma 1991</REF>--but rather as a device for the top-down predictive instantiation of information, as Shieber et al	1	1990 have shown for semantic-head-driven generation	1	In this paper we are concerned especially with morphosyntactic information and illustrate the relevance of predictive linking for morphological analysis and for the analysis of unknown or new lexical items	0	4	2
C96-2111	P85-1018	1996	Whatever term one takes, an important aspect of the relation is that it can be used to reduce the search space of possible syntactic analyses at an earlier point in parsing and thus serves to improve the efficiency of a parser	0	Shieber 1985, 1992 follows established terminology in speaking of top-down filtering in connection with the prediction step of the Earley algorithm	0	His central notion of restriction, whereby a restrictor is a finite subset of the paths specified in a feature structure, is related to the technique we introduce here, since both guarantee the finiteness of an otherwise possibly infinite domain of complex categories, but Shiebers restrictors are specified manually	1	We propose a general algorithmic method of compilation that avoids manual specification	0	1	3
J93-1002	P85-1018	1993	In particular, declaring certain category-valued features so that they cannot take variable values may lead to nontermination in the backbone construction for some grammars	0	However, it should be possible to restrict the set of features that are considered in category-valued features in an analogous way to Shiebers 1985 restrictors for Earleys 1970 algorithm, so that a parse table can still be constructed	1	36 Ted Briscoe and John Carroll Generalized Probabilistic LR Parsing 4	0	Building LR Parse Tables for Large NL Grammars The backbone grammar generated from the ANLT grammar is large: it contains almost 500 distinct categories and more than 1600 productions	0	1	2
J93-1002	P85-1018	1993	This requirement places a greater load on the grammar writer and is inconsistent with most recent unification-based grammar formalisms, which represent grammatical categories entirely as feature bundles eg <REF>Gazdar et al 1985</REF>; <REF>Pollard and Sag 1987</REF>; <REF>Zeevat, Calder, and Klein 1987</REF>	0	In addition, it violates the principle that grammatical formalisms should be declarative and defined independently of parsing procedure, since different definitions of the CF portion of the grammar will, at least, effect the efficiency of the resulting parser and might, in principle, lead to nontermination on certain inputs in a manner similar to that described by <TREF>Shieber 1985</TREF>	1	In what follows, we will assume that the unification-based grammars we are considering are represented in the ANLT object grammar formalism <REF>Briscoe et al 1987</REF>	0	This formalism is a notational variant of Definite Clause Grammar eg <REF>Pereira and Warren 1980</REF>, in which rules consist of a mother category and one or more daughter categories, defining possible phrase structure configurations	0	1	3
W07-1219	P85-1018	2007	In contrast to the symbols in context-free grammars, feature structures in unification-based grammars often include information encoding part of the derivation history, most notably semantics	0	In order to achieve successful packing rates, feature restriction <TREF>Shieber, 1985</TREF> is used to remove this information during creation of the packed parse forest	1	During the unpacking phase, which operates only on successful parse trees, these features are unified back in again	0	For their experiments with efficient subsumptionbased packing, <REF>Oepen and Carroll, 2000</REF> experimented with different settings of the packing restrictor for the English Resource Grammar ERG <REF>Copestake and Flickinger, 2000</REF>: they found that good packing rates, and overall good performance during forest creation and unpacking were achieved, for the ERG, with partial restriction of the semantics, eg keeping index features unrestricted, since they have an impact on external combinatorial potential, but restricting most of the internal MRS representation, including the list of elementary predications and scope constraints	0	3	2
A00-2022	P85-1018	2000	5 Choosing the Grammar Restrictor and Parsing Strategy In order for the subsumption relation to apply meaningfully to HPSG signs, two conditions must be met	0	Firstly, parse tree construction must not be duplicated in the feature structures by means of the HPSG DTRS feature but be left to the parser ie recorded in the chart; this is achieved in a standard way by feature structure restriction <TREF>Shieber, 1985</TREF> applied to all passive edges	1	Secondly, the processing of constraints that do not restrict the search space but build up new often semantic structure should be postponed, since they are likely to interfere with subsumption	0	For example, analyses that differ only with respect to PP attachment would have the same syntax, but differences in semantics may prevent them being packed	0	6	1
P97-1058	P85-1018	1997	Attention is restricted here to approximations of context-free grammars because context-free languages are the smallest class of formal language that can realistically be applied to the analysis of natural language	0	Techniques such as restriction <TREF>Shieber, 1985</TREF> can be used to construct context-free approximations of many unification-based formalisms, so techniques for constructing finite-state approximations of context-free grammars can then be applied to these formalisms too	0	2 Finite-state calculus A finite-state calculus or finite automata toolkit is a set of programs for manipulating finite-state automata and the regular languages and transducers that they describe	0	Standard operations include intersection, union, difference, determinisation and minimisation	0	6	2
C90-2019	P85-1018	1990	The ELU tormalism provides a generalization of the template facility of PATR-II, the relational abstractions, which are statements abstracting over sets of constraint equations	1	These statements 5 Restrictors are also used to restrict the search space in parsing see <TREF>Shieber 1985</TREF>	1	fbe use of linking information in generation was first proposed by van <REF>Noord 1988</REF>	0	may receive multiple and mcursive definitions	0	6	1
C88-2121	P85-1018	1988	Problems in the prediction step of the Earley parser used for unification-based formalisms no longer exist	0	The use of restrictors as proposed by <TREF>Shieber 1985</TREF> is no longer necessary and the difficulties caused by treating subcategorization as a feature is no longer a problem	1	By assuming that the number of structures associated with a lexical item is finite, since each structure has a lexical item attached to it, we implicitly make the assumption that an input string of finite length cannot be syntactically infinitely ambiguous	0	Since the trees are produced by the input string, the parser can use information that might be non-local to guide the search	0	1	3
C02-1075	P85-1018	2002	The resulting structures form equivalence classes, since they abstract from word-specific information, such as FORM or STEM	0	The abstraction is specified by means of a restrictor <TREF>Shieber, 1985</TREF>, the so-called lexicon restrictor	1	After that, the grammar rules are instantiated by unification, using the abstracted lexicon entries and resulting in derivation trees of depth 1	0	The rule restrictor is applied to each resulting feature structure FS, removing all information contained only in the daughters of a rule	0	3	2
C96-2160	P85-1018	1996	head-dtr syn  counter 1   Then, this can generate an infinite sequence of signs, each of which contains a part,  counter <bar, ba, r,,bar l and is not equivalent to any previously generated sign	0	In order to resolve this difficulty, we apply tim restriction <TREF>Shieber, 1985</TREF> to a rule schemata and a lexical entry, and split the feature structure F  fsR of a rule schema R or a lexical entry F  l, into two, namely, coreF and subF such that F  coreF U subF	1	The definition of the restriction here is given as follows	0	Definition 5 paths For arty node n in a feature structure F, pathsn,F is a set of all the paths that reaches n from the root of F Definition 6 Restriction Schema A restriction schema rs is a set of paths	0	3	1
P91-1032	P85-1018	1991	However, these models are inadequate for language interpretation, since they cannot express the relevant syntactic and semantic regularities	0	Augmented phrase structure grammar APSG formalisms, such as unification-based grammars <TREF>Shieber, 1985a</TREF>, can express many of those regularities, but they are computationally less suitable for language modeling, because of the inherent cost of computing state transitions in APSG parsers	1	The above problems might be circumvented by using separate grammars for language modeling and language interpretation	0	Ideally, the recognition grammar should not reject sentences acceptable by the interpretation grammar and it should contain as much as reasonable of the constraints built into the interpretation grammar	0	1	3
E91-1013	P85-1018	1991	procedure CLOSUREI; begin repeat for each item <AwBx> in I, and each production C-y such that C is unifiable with B and <CBy> is not in I do add <CB--,y> to I; until no more items can be added to I; return I end; procedure NEXT-SI,C for each category C that appears to the right ; of the dot in items begin let J be the set of items <A-wBx> such that <AwBx> is in I and B is unifiable with C; return CLOSUREJ end; Figure 6	0	Preliminary CLOSURE/NEXT-S Procedures The preliminary CLOSURE procedure Unifies the lhs of a predicted production, ie -71 Cy, and the category the prediction is made flom, ieB This approach is essentially top-down lrOlagation of instantiated features and well documented by <TREF>Shieber 1985</TREF> in the context of Earleys algorithm	1	A new item added to the state, <CB--,	0	y>, is not the production C--,y, but its partial instantiation, y is also instantiated to be y as a result of the unification CB if C and some members of y share tags	0	6	1
E91-1013	P85-1018	1991	That is, instantiation of productions introduces the nontermination problem of left-recursive productions to the procedure, as well as to the Predictor Step of Earleys algorithm	0	To overcome this problem, <TREF>Shieber 1985</TREF> proposes restrictor, which specifies a maximum depth of feature-based categories	1	When the depth of a category in a predicted item exceeds the limit imposed by a restrictor, further instantiation of the category in new items is prohibited	0	The Predictor Step eventually halts when it starts creating a new item whose feature specification within the depth allowed by the resuictor is identical to, or subsumed by, a previous one	0	1	2
P99-1061	P85-1018	1999	The situation is different for active chart items since daughters can affect their siblings	0	To be independent from a-certain grammatical theory or implementation, we use restrictors similar to <TREF>Shieber, 1985</TREF> as a flexible and easyto-use specification to perform this deletion	1	A positive restrictor is an automaton describing the paths in a feature structure that will remain after restriction the deletion operation, 3There are refinements of the technique which we have implemented and which in practice produce additional benefits; we will report these in a subsequent paper	0	Briefly, they involve an improvement to th e path collection method, and the storage of other information besides types in the vectors	0	3	2
J85-4001	P85-1018	1985	Estimates of the object-grammar size for typical systems vary from hundreds or thousands 3 up to trillions of rules <REF>Shieber 1983</REF>:4	0	With some formalisms, the context-free object-grammar approach is not even possible because the object grammar would be infinite <TREF>Shieber 1985</TREF>:145	1	Grammar size matters beyond questions of elegance and clumsiness, for it typically affects processing complexity	0	<REF>Berwick and Weinberg 1982</REF> argue that the effects of grammar size can actually dominate complexity for a relevant range of input lengths	0	6	1
P04-1017	P87-1022	2004	That is, for the reference determination, the subject roles of the candidates referent within a discourse segment will be checked intheflrstplace	0	Thisflndingsupportswell the suggestion in centering theory that the grammaticalrelationsshouldbeusedasthe key criteria to rank forward-looking centers in the process of focus tracking <TREF>Brennan et al , 1987</TREF>; <REF>Grosz et al , 1995</REF>	1	3	0	candi Pron and candi NoAntecedent are to be examined in the cases when the subject-role checking fails, which conflrms the hypothesis in the S-List model by <REF>Strube 1998</REF> that co-refereing candidates would have higher preference than other candidates in the pronoun resolution	0	4	2
P04-1017	P87-1022	2004	The S-List model <REF>Strube, 1998</REF>, for example, assumes that a co-referring candidate is a hearer-old discourse entity and is preferred to other hearer-new candidates	0	In the algorithms based on the centering theory <TREF>Brennan et al , 1987</TREF>; <REF>Grosz et al , 1995</REF>, if acandidateanditsantecedentarethebackwardlooking centers of two subsequent utterances respectively, the candidate would be the most preferred since the CONTINUE transition is always ranked higher than SHIFT or RETAIN	1	In this paper, we present a supervised learning-based pronoun resolution system which incorporates coreferential information of candidates in a trainable model	0	For each candidate, we take into consideration the properties of its antecedents in terms of features henceforth backward features, and use the supervised learning method to explore their in uences on pronoun resolution	0	6	1
W99-0104	P87-1022	1999	The first class is characterized by adaptations of previously known reference algonthms eg	0	<REF>Lappin and Leass, 1994</REF>, <TREF>Brennan et al , 1987</TREF> the scarce syntactic and semantic knowledge available m an w system eg	1	<REF>Kameyama, 1997</REF>	0	The second class is based on statistical and machine learning techniques that rely on the tagged corpora to extract features of the coreferential relations eg	0	6	1
P00-1051	P87-1022	2000	One of the most unusual features of centering theory is that the notions of utterance, previous utterance, ranking, and realization used in the definitions above are left unspecified, to be appropriately defined on the basis of empirical evidence, and possibly in a different way for each language	0	As a result, centering theory is best viewed as a cluster of theories, each of which specifies the parameters in a different ways: eg, ranking has been claimed to depend on grammatical function <REF>Kameyama, 1985</REF>; <TREF>Brennan et al , 1987</TREF>, on thematic roles <REF>Cote, 1998</REF>, and on the discourse status of the CFs <REF>Strube and Hahn, 1999</REF>; there are at least two definitions of what counts as previous utterance <REF>Kameyama, 1998</REF>; <REF>Suri and McCoy, 1994</REF>; and realization can be interpreted either in a strict sense, ie, by taking a CF to be realized in an utterance only if an NP in that utterance denotes that CF, or in a looser sense, by also counting a CF as realized if it is referred to indirectly by means of a bridging reference <REF>Clark, 1977</REF>, ie, an anaphoric expression that refers to an object which wasnt mentioned before but is somehow related to an object that already has, as in the vase the handle see, eg, the discussion in <REF>Grosz et al , 1995</REF>; <REF>Walker et al , 1998b</REF>	1	3 METHODS The fact that so many basic notions of centering theory do not have a completely specified definition makes empirical verification of the theory rather difficult	1	Because any attempt at directly annotating a corpus for utterances and their CBs is bound to force the annotators to adopt some specification of the basic notions of the theory, previous studies have tended to study a particular variant of the theory <REF>Di Eugenio, 1998</REF>; <REF>Kameyama, 1998</REF>; <REF>Passonneau, 1993</REF>; <REF>Strube and Hahn, 1999</REF>; <REF>Walker, 1989</REF>	0	1	3
C04-1074	P87-1022	2004	Another important factor in pronoun resolution is the grammatical role of the antecedent	0	The role hierarchy used in centering <TREF>Brennan et al , 1987</TREF>; <REF>Grosz et al , 1995</REF> ranks subjects over direct objects over indirect objects over others	1	<REF>Lappin and Leass 1994</REF> provide a more elaborate model which ranks NP complements and NP adjuncts lowest	0	Two other distinctions in their model express a preference of rhematic2 over thematic arguments: Existential subjects, which follow the verb, rank very high, between subjects and direct objects	0	6	1
C04-1074	P87-1022	2004	Similarly, we can assess other strategies of sentence ordering that have been proposed in the literature	0	Hard-core centering approaches only deal with the last sentence <TREF>Brennan et al , 1987</TREF>	1	In Negra, these approaches can consequently have at most a success rate of 442	1	Performance is particularly low with possessive pronouns which often only have antecedents in the current sentence	1	1	3
W96-0211	P87-1022	1996	While it appears that our existing linguistic bias set will be of use, we believe that the CBL system will benefit from additional linguistic biases	0	Centering constraints see <TREF>Brennan et al , 1987</TREF>, for example, can be encoded as linguistic biases and applied to the pronoun resolution task to increase system performance	1	Furthermore, we have focused on applying the linguistic bias approach to feature set selection for case-based learning algorithms only	0	In future work, we plan to investigate the use of the approach for feature selection in conjunction with other standard machine learning algorithms	0	6	1
P98-2241	P87-1022	1998	A number of studies have developed refinements and extensions of the theory eg	0	<TREF>Brennan et al , 1987</TREF>; <REF>Kameyama, 1986</REF>; <REF>Strube and Hahn, 1996</REF>; <REF>Walker et al , 1998</REF>, but few have attempted to extend the model to multi-party discourse cf	1	<REF>Brennan, 1998</REF>; <REF>Walker, 1998</REF>	0	For dialog systems, the benefits of using centering theory include improved reference resolution and generation of more coherent referring expressions	0	6	1
P04-1011	P87-1022	2004	Separately, the SPG also handles referring expression generation by converting proper names to pronouns when they appear in the previous utterance	0	The rules are applied locally, across adjacent sequences of utterances <TREF>Brennan et al , 1987</TREF>	1	Referring expressions are manipulated in the d-trees, either intrasententially during the creation of the sp-tree, or intersententially, if the full sp-tree contains any period operations	0	The third and fourth sentences for Alt 13 in Figure 4 show the conversion of a named restaurant Carmines to a pronoun	0	6	1
C98-2161	P87-1022	1998	Pragmatic level Working together, surface patterns and possessive relationships can deal with many PPAs found in our corpus, but we still have two problems to be solved: semantic ambiguity among two or more acceptable candidates and abstract anaphors/antecedents, which cannot be solved by simply applying possessive relationship rules	0	For these cases, and possibly for some other cases not included in previous rules, we suggest a pragmatic factor, adapted from S Brennans et al 1987 centering algorithm	1	Although sentence center plays a crucial role in many works in anaphor resolution, usually limiting the number of candidates to be considered, we notice that, because PPAs can refer to almost any NP in the sentence rather than, for example, personal pronouns, which are often related to the sentence center, pragmatic knowledge plays only a secondary but still important role in our approach	0	We have adapted basic aspects of center algorithm, considering subject/object preference, and domain concepts preference, 1012 suggested by R <REF>Mitkov 1996</REF>, aiming to estimate the most probable center for intrasentential PPAs	0	5	2
P98-2204	P87-1022	1998	In Section 3, I introduce my model, its only data structure, the S-list, and the accompanying algorithm	0	In Section 4, I compare the results of my algorithm with the results of the centering algorithm <TREF>Brennan et al , 1987</TREF> with and without specifications for complex sentences <REF>Kameyama, 1998</REF>	1	2 A Look Back: Centering The centering model describes the relation between the focus of attention, the choices of referring expressions, and the perceived coherence of discourse	0	The model has been motivated with evidence from preferences for the antecedents of pronouns <REF>Grosz et al , 1983</REF>; 1995 and has been applied to pronoun resolution Brennan et al	0	6	1
P98-2204	P87-1022	1998	Their approach has been proven as the point of departure for a new model which is valid for English as well	0	The use of the centering transitions in Brennan et als 1987 algorithm prevents it from being applied incrementally cf	1	<REF>Kehler 1997</REF>	0	In my approach, I propose to replace the functions of the backward-looking center and the centering transitions by the order among the elements of the list of salient discourse entities S-list	0	1	3
P98-2204	P87-1022	1998	RANK by transition orderings	0	To illustrate this algorithm, we consider example 1 <TREF>Brennan et al , 1987</TREF> which has two different final utterances ld and ld	1	Utterance ld contains one pronoun, utterance ld t two pronouns	0	We look at the interpretation of ld and ldt	0	6	1
C96-1060	P87-1022	1996	Table 1 illustrates the Pour transitions that are detined according to diese constraints	0	<TREF>Brennan et al , 1987</TREF></TREF> proposes a default ordering on transitions which correlates with discourse coherence: CONTINUE is preferred to RETAIN is prelbrred to SMOOTH-SHIFT is pre2The version of centering I presem; here is tiom <TREF>Brennan et al , 1987</TREF></TREF>	1	352 H CbUu  CbWn, Ct,Un 7 CtW,,	0	1 n CbU,  CtU, XNTINUI,; SMOOTII-SItlH CbU,,  CpU, IETAIN IIUIlI-SIIIFT Tatle 1: Ceutering Transitions ferred to IIIII-SIIllT	0	6	1
W97-1302	P87-1022	1997	Although they report that their method estimates over 90 of zero subjects correctly, there are several difficulties including the fact that the test corpus is identical with the corpus from which the pragmatic constraints are extracted, and the fact that there are so many rules46 rules to estimate 175 sentences	0	As for the identifying method available in general discourses, the centering theory<TREF>Brennan et al , 1987</TREF>; <REF>Walker et al , 1990</REF> and the property sharing theory<REF>Kameyama, 1988</REF> are proposed	1	The important feature of these theories is the fact that it is independent of the type of discourse	0	However, according to our experimental result, it seems that these kinds of theory do not estimate zero subjects in high precision for manual sentences 3	1	1	3
C98-2138	P87-1022	1998	This preference can be explained in terms of salience from the point of view of the centering theory	0	The latter proposes the ranking subject, direct object, indirect object <TREF>Brennan et al 1987</TREF> and noun phrases which are parts of prepositional phrases are usually indirect objects	1	Collocation pattern preference This preference is given to candidates which have an identical collocation pattern with a pronoun 2,0	0	The collocation preference here is restricted to the patterns noun phrase pronoun, verb and verb, noun phrase pronoun	0	6	1
J04-3003	P87-1022	2004	Grosz et al list seven such costraints, three of which can be directly evaluated	0	Even though we are not following here the distinction between constraints and rules introduced in <REF>Brennan, Friedman, and Pollard 1987</REF>, we will use for these three claims the names Brennan et al gave them, by which they are now best known: Constraint 1 Strong: All utterances of a segment except for the first have exactly one CB	1	Rule 1 GJW95: If any CF is pronominalized, the CB is Rule 2 GJW95: Sequences of continuations are preferred over sequences of retains, which are preferred over sequences of shifts	0	231 Constraint 1, Topic Uniqueness, and Entity Coherence	0	3	2
W98-1119	P87-1022	1998	162 In effect, we use this probability information to identify the topic of the segment with the belief that the topic is more likely to be referred to by a pronoun	1	The idea is similar to that used in the centering approach <TREF>Brennan et al , 1987</TREF> where a continued topic is the highest-ranked candidate for pronominalization	1	Given the above possible sources of informar tion, we arrive at the following equation, where Fp denotes a function from pronouns to their antecedents: Fp  argmaxP Ap  alp, h, l, t, l, so, d A where Ap is a random variable denoting the referent of the pronoun p and a is a proposed antecedent	0	In the conditioning events, h is the head constituent above p, l r is the list of candidate antecedents to be considered, t is the type of phrase of the proposed antecedent always a noun-phrase in this study, I is the type of the head constituent, sp describes the syntactic structure in which p appears, dspecifies the distance of each antecedent from p and M is the number of times the referent is mentioned	0	5	2
C98-2236	P87-1022	1998	A number of studies have developed refinements and extensions of the theory eg	0	Brennan et at, 1987; <REF>Kameyama, 1986</REF>; <REF>Strube and Hahn, 1996</REF>; <REF>Walker et al, 1998</REF>, but few have attempted to extend the model to mul party discourse cf	1	<REF>Brennan, 1998</REF>; <REF>Walker, 1998</REF>	0	For dialog systems, the benefits of using centering theory include improved reference resolution and generation of more coherent referring expressions	0	6	1
C98-2199	P87-1022	1998	CbU  CpUd cbu  cpud Cb U   CbU   OR no CbUi-l CONTINUE RETAIN CbUi  CbUi-1 SMOOTH-SHIFT ROUGH-SHIFT Table 1: Transition Types Brennan et al	0	1987 modify the second of two rules on center movement and realization which were defined by Grosz et al	0	1983; 1995: Rule 1: If some element of CfUi-1 is realized as a pronoun in Ui, then so is CbUi	0	Rule 2: Transition states are ordered	0	0	0
C98-2199	P87-1022	1998	In Section 3, I introduce my model, its only data structure, the S-list, and the accompanying algorithm	0	In Section 4, I compare the results of my algorithm with the results of the centering algorithm <TREF>Brennan et al, 1987</TREF> with and without specifications for complex sentences <REF>Kamcyama, 1998</REF>	1	2 A Look Back: Centering The centering model describes the relation between the focus of attention, the choices of referring expressions, and the perceived coherence of discourse	0	The model has been motivated with evidence from preferences for the antecedents of pronouns <REF>Grosz et al, 1983</REF>; 1995 and has been applied to pronoun resolution Brennan et al	0	6	1
C98-2199	P87-1022	1998	Their approach has been proven as the point of departure for a new model which is valid for English as well	0	The use of the centering transitions in Brennan et als 1987 algorithm prevents it from being applied incrementally cf	1	<REF>Kehler 1997</REF>	0	In my approach, I propose to replace the functions of the backward-looking center and the centering transitions by the order among the elements of the list of salient discourse entities S-list	0	1	3
C98-2199	P87-1022	1998	RANK by transition orderings	0	To illustrate this algorithm, we consider example 1 <TREF>Brennan et al, 1987</TREF> which has two different final utterances ld and ld	1	Utterance ld contains one pronoun, utterance ld t two pronouns	0	We look at the interpretation of ld and ld	0	6	1
P03-1023	P87-1022	2003	Mitkovs knowledge-poor pronoun resolution method <REF>Mitkov, 1998</REF>, for example, uses the scores from a set of antecedent indicators to rank the candidates	0	And centering algorithms <TREF>Brennan et al , 1987</TREF>; <REF>Strube, 1998</REF>; <REF>Tetreault, 2001</REF>, sort the antecedent candidates based on the ranking of the forward-looking or backwardlooking centers	1	In recent years, supervised machine learning approaches have been widely used in coreference resolution <REF>Aone and Bennett, 1995</REF>; <REF>McCarthy, 1996</REF>; <REF>Soon et al , 2001</REF>; <REF>Ng and Cardie, 2002a</REF>, and have achieved significant success	0	Normally, these approaches adopt a single-candidate model in which the classifier judges whether an antecedent candidate is coreferential to an anaphor with a confidence value	0	6	1
P89-1030	P87-1022	1989	Any communicative act, be it spoken, written, gestured, or system-initiated, can give rise to DEs	0	As a discourse progresses, an adequate discourse model must represent the relevant entities, and the relationships between them <REF>Grosz and Sidner, 1986</REF>, A speaker may then felicitously refer anaphorically to an object subject to focusing or centering constraints <REF>Grosz et al , 1983</REF>, <REF>Sidner 1981, 1983</REF>, <TREF>Brennan et al 1987</TREF>  if there is an existing DE representing it, or if a corresponding DE may be directly inferred from an existing DE	1	For example, the utterance Every senior in Milford High School has a car gives rise to at least 3 entities, describable in English as the seniors in Milford High School, Milford High School, and the set of cars each of which is owned by some senior in Milford High School	0	These entities may then be accessed by the following next utterances, respectively: They graduate in June	0	6	1
P89-1030	P87-1022	1989	This is, to our knowledge, the first implementation of Webbers DE generation ideas	0	We designed the 243 algorithms and structures necessary to generate discourse entities from our logical representation of the meaning of utterances, and from pointing gestures, and currently use them in Januss <REF>Weischedel et al , 1987</REF>, BSN, 1988 pronoun resolution component, which applies centering techniques <REF>Grosz et al , 1983</REF>, <REF>Sidner 1981, 1983</REF>, <TREF>Brennan et al 1987</TREF> to track and constrain references	1	Janus has been demonstrated in the Navy domain for DARPAs Fleet Command Center Battle Management Program FCCBMP, and in the Army domain for the Air Land Battle Management Program ALBM	0	2 Meaninq Representation for DE Generation Webber found that appropriate discourse entities could be generated from the meaning representation of a sentence by applying rules to the representation that are strictly structural in nature, as long as the representation reflects certain crucial aspects of the sentence	0	6	1
P98-2166	P87-1022	1998	Pragmatic level Working together, surface patterns and possessive relationships can deal with many PPAs found in our corpus, but we still have two problems to be solved: semantic ambiguity among two or more acceptable candidates and abstract anaphors/antecedents, which cannot be solved by simply applying possessive relationship rules	0	For these cases, and possibly for some other cases not included in previous rules, we suggest a pragmatic factor, adapted from S Brennans et al 1987 centering algorithm	1	Although sentence center plays a crucial role in many works in anaphor resolution, usually limiting the number of candidates to be considered, we notice that, because PPAs can refer to almost any NP in the sentence rather than, for example, personal pronouns, which are often related to the sentence center, pragmatic knowledge plays only a secondary but still important role in our approach	0	We have adapted basic aspects of center algorithm, considering subject/object preference, and domain concepts preference, 1012 suggested by R <REF>Mitkov 1996</REF>, aiming to estimate the most probable center for intrasentential PPAs	0	5	2
W99-0109	P87-1022	1999	The result is as follows: UI : Cb f a, Cp  a U2:Cba, Cpb U3 : Cb f b, Cp  b U4 : Cb  b, Cp  b In terms of the conventional transitions this works out as U/U2: RETIN U2/U3: SMOOTH SHIFT us/u: COnTINUa This is consistent with Strube and Hahns 1996 observation that a IIrAIN transition ideally predicts a SMOOTH sswr in the following utterance	0	<REF>Brenuan et al 1987</REF> make a very similar claim: A computational system for 9e-emtion would try to plan a retention as a signal of an impending shift, so that after a retention, a shift would be preferred rather than a continuation	1	<REF>Grosz et al 1995</REF> give the following example of the Am SHIFT pattern: 5 a John has had trouble arranging his vacation	0	b He Cb; John cannot find anyone to take over his responsibilities	0	2	1
W99-0109	P87-1022	1999	I suggmtthat these results should be treated with some caution since it is not dear that the authors have the same assumptions about the claims of CT or that what they are testing directly reflects formulations of CT in the more theoretical literature	0	For instance <REF>Passoneau 1998</REF> refers to two variantS of CT: Version A based on <TREF>Brennan et al 1987</TREF> and Version B taken from <REF>Kameyama et al 1993</REF>	1	Passoneau does nt address the issue of direct vs indirect realisation and it appears from the examples given that she only takes account of entities realised by a full NP or possibly null pronoun	0	The analysis according to Version B results in a count of 52 NULL transitions, ie no Cb, which gives the impression that CT is in fact a rather poor measure of coherence, It is probable that a higher measure might have been obtained if Passoneau had allowed entities to be added to the U/s by inference, as discussed in Brennan et al, op cit	0	6	1
W99-0109	P87-1022	1999	Centering theory C is a theory of discourse structure which models the interaction of cohesion and salience in the internal organlsation of a text	0	The main assumptions of the theory as presented by Gross et a11995 GJW, <TREF>Brennan et al 1987</TREF> rare: 1	1	For each utterance in a discourse there is precisely one entity which is the centre of attention or center	0	2	0	6	1
W99-0109	P87-1022	1999	Take the Cb as given and plan the realisation of Ui- to make this entity the highestranked	0	The first strategy is clearly appropriate for interpretation cf <TREF>Brennan et al 1987</TREF> but for generation the issue is less clear-cut	1	Either the generator interprets its own output to designate Cb in terms of the grammatical structure of the previous utterance, in which case there have to be separate principles for deciding on the grammatical structure, or Cb is independently defined in the text plan and this information is used to plan the sentence structure	0	According to the pipelining principle information cannot flow backwards between tasks	0	6	1
W04-0713	P87-1022	2004	The function for resolving IPAs ResolveIpa has similarly been tested on texts, where APAs were excluded	0	We have compared the obtained results with those obtained by testing bfp <TREF>Brennan et al , 1987</TREF> and str98 <REF>Strube, 1998</REF>	1	In all tests the intrasentential anaphors have been manually resolved	0	Expletive and cataphoric uses of pronouns have been marked and excluded from the tests	0	6	1
P95-1017	P87-1022	1995	Thus, even if there exists a perfect theory, it might not work well with noisy input, or it would not cover all the anaphoric phenomena	0	1Walker <REF>Walker, 1989</REF> compares Brennan, Friedman aad Pollards centering approach <TREF>Brennan et al , 1987</TREF> with Hobbs algorithm <REF>Hohbs, 1976</REF> on a theoretical basis	1	These requirements have motivated us to develop robust, extensible, and trainable anaphora resolution systems	0	Previously <REF>Aone and McKee, 1993</REF>, we reported our data-driven multilingual anaphora resolution system, which is robust, exteusible, and manually trainable	0	6	1
W99-0108	P87-1022	1999	But, more generally, we must have a theory that is able to handle all cases of pronoun use	0	A pronoun interpretation algorithm based on centering which relied on centering transition preferences was developed in Brennan et aL 1987 Using transition preferences in a pronoun generation rule would cover more cases of pronoun use than is covered by Rule 1, but the application of such transition preferences also proved unhelpful in explaining pronoun patterns in our corpus	1	<REF>Reichman 1985</REF> and <REF>Grosz  Sidner 1986</REF> indicate that discourse segmentation has an effect on the linguistic realization of referring expressions	0	While this is intuitively appealing, it is unclear how to apply this to the generation problem in part because it is unclear how to define discourse segments to a generation system	0	6	1
P95-1040	P87-1022	1995	This distinction underlies my proposals about the attentional consequences of pitch accents when applied to pronominals, in particular, that while most pitch accents may weaken or reinforce a cospecifiers status as the center of attention, a contrastively stressed pronominal may force a shift, even when contraindicated by textual features	0	To predict and track the center of attention in discourse, theories of centering <REF>Grosz et al , 1983</REF>; <TREF>Brennan et al , 1987</TREF>; <REF>Grosz et al , 1989</REF> and immediate focus <REF>Sidner, 1986</REF> rely on syntactic and grammatical features of the text such as pronominalization and surface sentence position	1	This may be sufficient for written discourse	1	For oral discourse, however, we must also consider the way intonation affects the interpretation of a sentence, especially the cases in which it alters the predictions of centering theories	1	1	3
J99-2001	P87-1022	1999	3	0	Processing Complex Sentences: A Reason for Extending Focusing Algorithms Although complex sentences are prevalent in written English, most other local focusing research focusing: Sidner 1979 and Carter 1987; centering: Grosz, Joshi, and Weinstein 1983, 1995, Brennan, Friedman, and Pollard 1987, Walker 1989, 1993, Kameyama 1986 2, Walker, Iida, and Cote 1994, Brennan 1998, Kameyama, Passonneau, and Poesio 1993, Linson 1993 and Hoffman 1998; and PUNDIT: Dahl 1986, Palmer et al 1986, and Dahl and Ball 1990 did not explicitly and/or adequately address how to process complex sentences	1	Thus, there is a need to extend focusing algorithms	1	An exception to this rule is the work of <REF>Strube 1996</REF> which applies functionalinformation-structure-based criteria on a per-clause basis, <REF>Kameyama 1998</REF>, and <REF>Strube 1998</REF>	0	1	3
E06-3001	P87-1022	2006	Overview of the data used	0	5 Preliminary Model Overviews The models evaluated in this paper are based on Centering Theory <REF>Grosz et al , 1995</REF>; <REF>Grosz  Sidner, 1986</REF> and the algorithms devised by Brennan and colleagues 1987 and adapted by <REF>Tetreault 2001</REF>	1	We examine a language-only model based on Tetreaults Left-Right Centering LRC model, a visual-only model that uses a measure of visual salience to rank the objects in the visual field as possible referential anchors, and an integrated model that balances the visual information along with the linguistic information to generate a ranked list of possible anchors	0	51 The Language-Only Model We chose the LRC algorithm <REF>Tetreault, 2001</REF> to serve as the basis for our language-only model	0	6	1
E06-3001	P87-1022	2006	Together this work suggests that the interlocutors shared visual context has a major impact on their patterns of referring behavior	1	Yet, a number of discourse-based models of reference primarily rely on linguistic information without regard to the surrounding visual environment eg , see <TREF>Brennan et al , 1987</TREF>; <REF>Hobbs, 1978</REF>; <REF>Poesio et al , 2004</REF>; <REF>Strube, 1998</REF>; <REF>Tetreault, 2005</REF>	1	Recently, multi-modal models have emerged that integrate visual information into the resolution process	0	However, many of these models are restricted by their simplifying assumption of communication via a command language	0	1	3
P98-2143	P87-1022	1998	This preference can be explained in terms of salience from the point of view of the centering theory	0	The latter proposes the ranking subject, direct object, indirect object <TREF>Brennan et al 1987</TREF> and noun phrases which are parts of prepositional phrases are usually indirect objects	1	Collocation pattern preference This preference is given to candidates which have an identical collocation pattern with a pronoun 2,0	0	The collocation preference here is restricted to the patterns noun phrase pronoun, verb and verb, noun phrase pronoun	0	6	1
C96-2132	P87-1022	1996	Since the constraints are eflective in the lifferent target from ours, the accuracy of identifying the referents of zero pronouns would be improved much more by using both of his constraints and the constraint we proposed	0	As for the identifying method available in general discourses, the centering theory<TREF>Brennan et al , 1987</TREF>; <REF>Walker et al , 1990</REF> and the property sharing theory<REF>Kameyama, 1988</REF> are proposed	1	Although this kind of theory has a good point that it is independent of the type o17 discourse, the linguistic constraints specitic to expressions like the pragmatic constraints l/roposed by Dohsaka or us are more accurate than theirs when the speeitlc constraints are applicable	1	3 General ontology in manuals and prinmry constraints In this section, we consider the general ontology which can be used in,dl types of manuals	0	1	3
N06-2017	P87-1022	2006	S, O and X Table 1B	0	The members of the CF list are ranked according to their grammatical role <TREF>Brennan et al , 1987</TREF> and their position in the grid3 The derived sequence of CF lists can then be used to compute other important Centering concepts:  The CB, ie the referent that links the current CF list with the previous one such as microsoft in b	1	Transitions <TREF>Brennan et al , 1987</TREF> and NOCBs, that is, cases in which two subsequent CF lists do not have any referent in common	0	Violations of CHEAPNESS <REF>Strube and Hahn, 1999</REF>, COHERENCE and SALIENCE <REF>Kibble and Power, 2000</REF>	0	6	1
N06-2017	P87-1022	2006	The members of the CF list are ranked according to their grammatical role <TREF>Brennan et al , 1987</TREF> and their position in the grid3 The derived sequence of CF lists can then be used to compute other important Centering concepts:  The CB, ie the referent that links the current CF list with the previous one such as microsoft in b	0	Transitions <TREF>Brennan et al , 1987</TREF> and NOCBs, that is, cases in which two subsequent CF lists do not have any referent in common	1	Violations of CHEAPNESS <REF>Strube and Hahn, 1999</REF>, COHERENCE and SALIENCE <REF>Kibble and Power, 2000</REF>	0	22 Metrics of coherence <REF>Karamanis 2003</REF> assumes a system which receives an unordered set of CF lists as its input and uses a metric to output the highest scoring ordering	0	6	1
P04-1050	P87-1022	2004	2 <unit finitefinite-yes idu210> <ne idne410 gfsubj>144</ne> is <ne idne411 gfpredicate> a torc</ne> </unit>	0	The ranking of the CFs other than the CP is defined according to the following preference on their gf <TREF>Brennan et al , 1987</TREF>: obj>iobj>other	1	CFs with the same gf are ranked according to the linear order of the corresponding NPs in the utterance	0	The second column of Table 1 shows how the utterances in example 1 are automatically translated by the scripts developed by Poesio et al	0	6	1
P04-1050	P87-1022	2004	It is often claimed in current work on in natural language generation that the constraints on felicitous text proposed by the theory are useful to guide text structuring, in combination with other factors see <REF>Karamanis, 2003</REF> for an overview	0	However, how successful Centerings constraints are on their own in generating a felicitous text structure is an open question, already raised by the seminal papers of the theory <TREF>Brennan et al , 1987</TREF>; <REF>Grosz et al , 1995</REF>	1	In this work, we explored this question by developing an approach to text structuring purely based on Centering, in which the role of other factors is deliberately ignored	0	In accordance with recent work in the emerging field of text-to-text generation <REF>Barzilay et al , 2002</REF>; <REF>Lapata, 2003</REF>, we assume that the input to text structuring is a set of clauses	0	1	2
P04-1050	P87-1022	2004	However, in this work we are treating CF lists as an abstract representation Following again the terminology in <REF>Kibble and Power 2000</REF>, we call the requirement that CBn be the same as CBn1 the principle of coherence and the requirement that CBn be the same as CPn the principle of salience	0	Each of these principles can be satisfied or violated while their various combinations give rise to the standard transitions of Centering shown in Table 2; Poesio et als scripts compute these violations6 We also make note of the preference between these transitions, known as Centerings Rule 2 <TREF>Brennan et al , 1987</TREF>: continue is preferred to retain, which is preferred to smoothshift, which is preferred to rough-shift	1	Finally, the scripts determine whether CBn is the same as CPn1, known as the principle of cheapness <REF>Strube and Hahn, 1999</REF>	0	The last column of Table 1 shows the violations of cheapness denoted with an asterisk in 17 23 Evaluating the coherence of a text and text structuring The statistics about transitions computed as just discussed can be used to determine the degree to which a text conforms with, or violates, Centerings principles	0	6	1
P99-1079	P87-1022	1999	P99-1079:56	0	Analysis of Syntax-Based Pronoun Resolution Methods Joel R Tetreault University of Rochester Department of Computer Science Rochester, NY, 14627 tetreaulcs, rochester, edu Abstract This paper presents a pronoun resolution algorithm that adheres to the constraints and rules of Centering Theory <REF>Grosz et al , 1995</REF> and is an alternative to Brennan et als 1987 algorithm	1	The advantages of this new model, the Left-Right Centering Algorithm LRC, lie in its incremental processing of utterances and in its low computational overhead	1	The algorithm is compared with three other pronoun resolution methods: Hobbs syntax-based algorithm, Strubes S-list approach, and the BFP Centering algorithm	0	1	3
P99-1079	P87-1022	1999	The noteworthy results were that Hobbs and LRC performed the best	0	The aim of this project is to develop a pronoun resolution algorithm which performs better than the <TREF>Brennan et al 1987</TREF> algorithm 1 as a cognitive model while also performing well empirically	1	A revised algorithm Left-Right Centering was motivated by the fact that the BFP algorithm did not allow for incremental processing of an utterance and hence of its pronouns, and also by the fact that it occasionally imposes a high computational load, detracting from its psycholinguistic plausibility	1	A second motivation for the project is to remedy the dearth of empirical results on pronoun resolution methods	0	1	3
P99-1079	P87-1022	1999	5	0	Identify Transition with the Cb and Cf resolved, use the criteria from <TREF>Brennan et al , 1987</TREF> to assign the transition	1	It should be noted that BFP makes use of Centering Rule 2 <REF>Grosz et al , 1995</REF>, LRC does not use the transition generated or Rule 2 in steps 4 and 5 since Rule 2s role in pronoun resolution is not yet known see <REF>Kehler 1997</REF> for a critique of its use by BFP	0	Computational overhead is avoided since no anchors or auxiliary data structures need to be produced and filtered	0	3	2
W00-1411	P87-1022	2000	The RETAIN is motivated as it enables a cheap SMOOTH SHIFT, and so we need a way of evaluating the whole sequence CONTINUE-RETAIN-SHIFT verSUS CONTINUE-CONTINUE-SHIFT	0	: :24,:Ceaateringin :NLG CT has developed primarily in the context of natural language interpretation, focussing on anaphora resolution see eg, <TREF>Brennan et al 1987</TREF>	0	Curiously, NLG researchers have tended to overlook GJWs proposal that Rule 2 provides a constraint on speakers, and on natural-language generation systems To empirically test the claim made by Rule 2 requires examination of differences in inference load of alternative multi-utterance sequences that differentially realize the same content	0	GJW, p 215	0	6	1
W00-1411	P87-1022	2000	This is also referred to as the backward-looking center or Cb	0	The notion of salience for the purposes of centering theory is most commonly defined according to a hierarchy of grammatical roles: SUBJECT > DIRECT OBJECT > INDIRECT OBJECT > OTHERS see eg, <TREF>Brennan et al 1987</TREF> For alternative approaches see eg, <REF>Strube and Hahn 1999</REF>, <REF>Walker et al 1994</REF>	1	2	0	There is a preference for consecutive utterances within a discourse segment to keep the same entity as the center, and for the center to be realised as Subject or preferred center Cp	0	6	1
W00-1411	P87-1022	2000	Cheapness is satisfied by a transition pair Un-1, Un, Un, Unl if the preferred center of Un is the Cb of Unl For example, this test is satisfied by a RETAIN-SHIFT sequence but not by CONTINUE-SHIFT, so it is predicted that the former pattern will be used to introduce a new center	0	This claim is consistent with the findings of <REF>Brennan 1998</REF>, <TREF>Brennan et al 1987</TREF>	1	If we consider examples la-e below, the sequence cd-e , including a RETAIN-SHIFT sequence, reads more fluently than c-d-e even though the latter scores better according to the canonical ranking	0	a John has had trouble arranging his vacation	0	4	2
W04-0210	P87-1022	2004	We found that it is much easier to annotate the building blocks of a theory of the local focus, and then use scripts to automatically compute the CB	0	There are two advantages to this approach: first of all, agreement on the building blocks is much easier to reach than agreement on the CBin our preliminary experiments we didnt go beyond   6 when trying to directly identify the CB using the definitions from <TREF>Brennan et al , 1987</TREF>	1	And secondly, this approach makes it possible to compute the CB according to different ways of instantiating what we call the parameters of Centering eg , ranking	0	We developed such scripts for the work discussed in <REF>Poesio et al , 2004b</REF>; they can be tested on the web site associated with that paper, http://cswwwessexacuk/staff/poesio/ cbc/	0	6	1
J94-4002	P87-1022	1994	It uses a hierarchy of grammatical roles quite similar to that of RAP, but this role hierarchy does not directly influence antecedent selection	0	Whereas th e hierarchy in RAP contributes to a multi-dimensional measure of the relative salience of all antecedent candidates, in <TREF>Brennan et al 1987</TREF>, it is used only to constrain the choice of the backward-looking center, Cb, of an utterance	1	It does not serve as a general preference measure for antecedence	0	The items in the forward center list, Cf, are ranked according to the hierarchy of grammatical roles	0	6	1
P00-1052	P87-1022	2000	The ranking of the Cf members is determined by the salience status of the entities in the utterance and mayvary crosslinguistically	0	Kameyama 28198529 and Brennan et al 28198729 proposed that the Cf ranking for English is determined by grammatical function as follows: 28229 Rule for ranking of forward-looking centers: SUBJ3EIND	1	OBJ3EOBJ3EOTHERS Later crosslinguistic studies based on empirical work 28<REF>Di Eugenio, 1998</REF>; <REF>Turan, 1995</REF>; <REF>Kameyama, 1985</REF>29 determined the following detailed ranking, with QIS standing for quanti0Ced inde0Cnite subjects 28people, everyone etc29 and PRO-ARB 28we, you29 for arbitrary plural pronominals	0	28329Revised rule for the ranking of forward-looking centers: SUBJ3EIND	0	6	1
J90-3005	P87-1022	1990	For example, as pointed out in Bonnie Webbers Penn presentation, there is a distinction between Tree Adjunction Grammar TAG as a linguistic theory and the several algorithms that have been used to implement TAG parsers: Extended CKY parser, Extended Earley parser, Two-pass extended Earley parser based on lexicalized TAGs, and a DCG parser using lexicalized TAGs	0	There is also a distinction between Centering as a theory for resolving anaphoric pronouns <REF>Joshi and Weinstein 1981</REF>; <REF>Gross et al 1983</REF>, and the attempts to use a centering approach to resolving pronouns in an implementation <TREF>Brennan et al 1987</TREF>	1	In addition, one way of looking inside a system is to look at the performance of one or more modules or components	0	Which components are obtained depends on the nature of the decomposition of the system	0	6	1
W05-1621	P87-1022	2005	PFNOCB, a second baseline, which enhances MNOCB with a global constraint on coherence that <REF>Karamanis, 2003</REF> calls the PageFocus PF	0	PFBFP which is based on PF as well as the original formulation of CT in <TREF>Brennan et al , 1987</TREF>	1	PFKP which makes use of PF as well as the recent reformulation of CT in <REF>Kibble and Power, 2000</REF>	0	<REF>Karamanis et al , 2004</REF> report that PFNOCB outperformed MNOCB but was overtaken by PFBFP and PFKP	1	1	2
C04-1034	P87-1022	2004	The function for resolving IPAsResolveIpa has similarly been tested on texts, where APAswereexcluded	0	We have compared the obtained results with those obtained by testing bfp <TREF>Brennan et al , 1987</TREF> and str98 <REF>Strube, 1998</REF>	1	In all tests the intrasentential anaphors have been manually resolved and expletive and cataphoric uses of pronouns have been marked and excluded from the test	0	Dialogue act units were marked and classified by three annotators following <REF>Eckert and Strube, 2000</REF>	0	6	1
P04-1051	P87-1022	2004	three arguments	0	Finally, the measure MBFP <TREF>Brennan et al , 1987</TREF> uses a lexicographic ordering on 4-tuples which indicate whether the transition is a CONTINUE, RETAIN, SMOOTH-SHIFT, or ROUGHSHIFT	1	cT and all four functions it is computed from take three arguments because the classification depends on COHERENCE	0	As the first transition in the discourse is coherent by default it has no Cb, we can compute cI by distinguishing RETAIN and CONTINUE via SALIENCE	0	6	1
P04-1051	P87-1022	2004	This is in contrast to theories of global coherence, which can consider relations between larger chunks of the discourse and eg structures them into a tree <REF>Mann and Thompson, 1988</REF>; <REF>Marcu, 1997</REF>; <REF>Webber et al , 1999</REF>	0	Measures of local coherence specify which ordering of the sentences makes for the most coherent discourse, and can be based eg on Centering Theory <REF>Walker et al , 1998</REF>; <TREF>Brennan et al , 1987</TREF>; <REF>Kibble and Power, 2000</REF>; <REF>Karamanis and Manurung, 2002</REF> or on statistical models <REF>Lapata, 2003</REF>	1	But while formal models of local coherence have made substantial progress over the past few years, the question of how to efficiently compute an ordering of the sentences in a discourse that maximises local coherence is still largely unsolved	1	The fundamental problem is that any of the factorial number of permutations of the sentences could be the optimal discourse, which makes for a formidable search space for nontrivial discourses	1	1	3
P04-1051	P87-1022	2004	Based on these concepts, CT classifies the transitions between subsequent utterances into different types	0	Table 1 shows the most common classification into the four types CONTINUE, RETAIN, SMOOTH-SHIFT, and ROUGH-SHIFT, which are predicted to be less and less coherent in this order <TREF>Brennan et al , 1987</TREF>	1	<REF>Kibble and Power 2000</REF> define three further classes of transitions: COHERENCE and SALIENCE, which are both defined in Table 1 as well, and NOCB, the class of transitions for which Cbui is undefined	0	Finally, a transition is considered to satisfy the CHEAPNESS constraint <REF>Strube and Hahn, 1999</REF> if Cbui  Cpui1	0	6	1
W06-1665	P89-1010	2006	One more filtering criterion is mutual information MI, which reflects the relatedness of two terms in their combination , kj ww  To keep a relation  kji wwwP, we require , kj ww be a meaningful combination	0	We use the following pointwise MI <TREF>Church and Hanks 1989</TREF>:  ,log, kj kj kj wPwP wwPwwMI  We only keep meaningful combinations such that 0, >kj wwMI  By these filtering criteria, we are able to reduce considerably the number of biterms and triterms	1	For example, on a collection of about 200MB, with a vocabulary size of about 148K, we selected only about 27M useful biterms and about 137M triterms, which remain tractable	0	33 Probability of Biterms In LM used in IR, each query term is attributed the same weight	0	3	2
W02-0606	P89-1010	2002	33 Scoring the semantic similarity of word pairs Measuring the semantic similarity of words on the basis of raw corpus data is obviously a much harder task than measuring the orthographic similarity of words	0	Mutual information first introduced to computational linguistics by <TREF>Church and Hanks 1989</TREF> is one of many measures that seems to be roughly correlated to the degree of semantic relatedness between words	1	The mutual information between two words A and B is given by: IA;B  log PrA;BPrAPrB 1 Intuitively, the larger the deviation between the empirical frequency of co-occurrence of two words and the expected frequency of co-occurrence if they were independent, the more likely it is that the occurrence of one of the two words is not independent from the occurrence of the other	0	Brown et alii 1990 observed that when mutual information is computed in a bi-directional fashion, and by counting co-occurrences of words within a 4Most of the pairs in this block  78  are actually morphologically related	0	6	1
W99-0610	P89-1010	1999	2In the case of an interrupted collocation, words can be separated by an arbitrary number of words, whereas 71 sin:e,:hey assumed that a collocation is a se-,lun:e of adjacent words that frequently apl:,ar tgether	0	<TREF>Church and Hanks, 1989</TREF> delhw:I ;t collocation as a pair of correlated words :mi,,set mutual information to evaluate such ,xi:a,1 :orrelations of word pairs of length two	1	They retrieved interrupted word pairs, as well as,minterrupted word pairs	0	<REF>Haruno et al , 1996</REF>,:onstructed collocations by combining adjacent n-grams with high value of mutual information	0	6	1
J04-2002	P89-1010	2004	Because of their low ambiguity and high specificity, these words are also particularly useful for conceptualizing a knowledge domain or for supporting the creation of a domain ontology	0	Candidate terminological expressions are usually captured with more or less shallow techniques, ranging from stochastic methods <TREF>Church and Hanks 1989</TREF>; <REF>Yamamoto and Church 2001</REF> to more sophisticated syntactic approaches <REF>Jacquemin 1997</REF>	1	155 Navigli and Velardi Learning Domain Ontologies WordNet domain corpus contrastive corpora terminology extraction candidate extraction terminology filtering semantic interpretation semantic disambiguation identification of taxonomic relations identification of conceptual relations Inductive learner Natural Language Processor ontology integration and updating 3 2 1 Lexical Resources Domain Concept Forest Figure 3 The architecture of OntoLearn	0	Obviously, richer syntactic information positively influences the quality of the result to be input to the statistical filtering	0	6	1
J95-1001	P89-1010	1995	Afterward, if a target adjective sense was not resolved, semantic indicator attributes were applied; no individual indicator nouns were used	0	The semantic attributes that were applied were animate, body part, color, concrete, human, and text type; <TREF>Church and Hanks 1989</TREF> had pointed to two of these attributes, person and body part also time, previously mentioned above in a seemingly casual listing of just five attributes potentially useful for describing the lexico-syntactic regularities of noun-verb relations	1	Table 1 shows that these few, general attributes cover almost three-quarters of all instances of the target adjectives	0	Disambiguation by these syntactic and semantic attributes is effectively as reliable as disambiguation using significant indicator nouns: having three apparent errors in disambiguation is not significantly worse than the errorless performance of the significant indicator nouns in the 100-sentence samples	0	4	2
J95-1001	P89-1010	1995	Content words that have a close syntactic relation to one another are useful candidates for examination and are intuitively more likely to bear a close semantic relation than words that are near one another but are not related syntactically	0	One much-studied example is the semantic relation between a verb and its arguments eg , <REF>Boguraev et al 1989</REF>; <TREF>Church and Hanks 1989</TREF>; Braden-<REF>Harder 1991</REF>; <REF>Hindle and Rooth 1991</REF>	0	Discrimination among senses of adjectives based on the nouns they modify or of which they are predicated has been the subject of less intensive and systematic study	0	Determining the potential of this line of evidence is the focus of this paper	1	5	2
P06-1005	P89-1010	2006	Like path coreference, semantic compatibility can be considered a form of world knowledge needed for more challenging pronoun resolution instances	0	We encode the semantic compatibility between a noun and its parse tree parent and grammatical relationship with the parent using mutual information MI <TREF>Church and Hanks, 1989</TREF>	1	Suppose we are determining whether ham is a suitable antecedent for the pronoun it in eat it	0	We calculate the MI as: MIeat:obj, ham  log Preat:obj:hamPreat:objPrham Although semantic compatibility is usually only computed for possessive-noun, subject-verb, and verb-object relationships, we include 121 different kinds of syntactic relationships as parsed in our news corpus3 We collected 488 billion parent:rel:node triples, including over 327 million possessive-noun values, 129 billion subject-verb and 877 million verb-direct object	0	3	2
H90-1055	P89-1010	1990	This line of research was motivated by a series of successful applications of mutual information statistics to other problems in natural language processing	0	In the last decade, research in speech recognition <REF>Jelinek 1985</REF>, noun classification <REF>Hindle 1988</REF>, predicate argument relations <TREF>Church  Hanks 1989</TREF>, and other areas have shown that mutual information statistics provide a wealth of information for solving these problems	1	22 Mutual Information Statistics The mutual information statistic <REF>Fano 1961</REF> is a measure of the interdependence of two signals in a message	0	It is a function of the probabilities of the two events: Mz, u  log u xzPvy In this paper, the events x and y will be part-of-speech n-grams instead of single parts-of-speech, as in some earlier work	0	6	2
C08-1051	P89-1010	2008	The idea behind it is that similar words tend to co-occur in certain patterns	0	Considerable efforts have been devoted to measure word similarity based on cooccurrence frequency of two words in a window <TREF>Church and Hanks, 1989</TREF>; <REF>Turney, 2001</REF>; <REF>Terra and Clarke, 2003</REF>; <REF>Matsuo et al, 2006</REF>	1	In addition to the classical window-based technique, some studies investigated the use of lexico-syntactic patterns eg, X or Y to get more accurate co-occurrence statistics <REF>Chilovski and Pantel, 2004</REF>; <REF>Bollegala et al, 2007</REF>	0	These two approaches are complementary with each other, because they are founded on different hypotheses and utilize different corpus statistics	0	6	1
J91-1001	P89-1010	1991	For example, Wilks et al	0	1989 use this ratio as a criterion for establishing links between words in a semantic network; <TREF>Church and Hanks 1989</TREF> use the logarithm of this ratio as a measure for word association	1	14 Justeson and Katz Co-occurrences of Antonymous Adjectives Under this formulation of the co-occurrence theory, acquiring the lexical relation of antonymy requires a certain amount of training for the association, and as the frequency of adjectives declines, so must the frequency of training for its associations	0	On the whole, then, very infrequent training should result in weaker associations; more generally, adjective frequency should correlate with the strength of lexical associations	0	6	1
P99-1067	P89-1010	1999	In the past, for this purpose a number of measures have been proposed	0	They were based on mutual information <TREF>Church  Hanks, 1989</TREF>, conditional probabilities <REF>Rapp, 1996</REF>, or on some standard statistical tests, such as the chi-square test or the loglikelihood ratio <REF>Dunning, 1993</REF>	0	For the purpose of this paper, we decided to use the loglikelihood ratio, which is theoretically well justified and more appropriate for sparse data than chi-square	1	In preliminary experiments it also led to slightly better results than the conditional probability measure	0	1	3
P01-1025	P89-1010	2001	Finally, methods and strategies for handling low-frequency data are suggested	0	The measures2  Mutual Information a0a2a1  <TREF>Church and Hanks, 1989</TREF>, the log-likelihood ratio test <REF>Dunning, 1993</REF>, two statistical tests: t-test and a3a5a4 -test, and co-occurrence frequency  are applied to two sets of data: adjective-noun AdjN pairs and preposition-noun-verb PNV triples, where the AMs are applied to PN,V pairs	1	See section 3 for a description of the base data	0	For evaluation of the association measures, a6 -best strategies section 41 are supplemented with precision and recall graphs section 42 over the complete data sets	0	3	2
W95-0105	P89-1010	1995	6 Probabifities were estimated using the Penn Treebank version of the Brown corpus	0	The pairs come from an example given by <TREF>Church and Hanks 1989</TREF>, illustrating the words that human subjects most frequently judged as being associated with the word doctor	1	The word sick also appeared on the list, but is excluded here because it is not a noun	0	Word 1 Word 2 doctor nurse doctor lawyer doctor man doctor medicine doctor hospital doctor health doctor sickness Similarity Most Informative Subsumer 94823 health professional 72240 professional person 29683 person, individual 10105 <entity 10105 <entity 00 virtual root 00 virtual root Doctors are minimally similar to medicine and hospitals, since these things are all instances of something having concrete existence, riving or nonliving WordNet class ent ty, but they are much more similar to lawyers, since both are kinds of professional people, and even more similar to nurses, since both are professional people working specifically within the health professions	0	6	1
C08-1086	P89-1010	2008	By no means an exhaustive list, the most commonly cited ranking and scoring algorithms are HITS <REF>Kleinberg 1998</REF> and PageRank <REF>Page et al 1998</REF>, which rank hyperlinked documents using the concepts of hubs and authorities	0	The most well-known keyword scoring methods within the IR community are the tf-idf <REF>Salton and McGill 1983</REF> and pointwise mutual information <TREF>Church and Hanks 1989</TREF> measures, which put more importance on matching keywords that occur frequently in a document relative to the total number of documents that contain the keyword by normalizing term frequencies with inverse document frequencies	1	Various methods including tf-idf have been comparatively evaluated by <REF>Salton and Buckley 1987</REF>	0	Creating nbest lists using the above algorithms produce result sets where each result is considered independently	0	6	1
C08-1086	P89-1010	2008	41 EIIR: Expected Independent Information Ranking Model Baseline Model Recall the task definition from Section 3	0	Finding a property r that most reduces the uncertainty in a query set Q can be modeled by measuring the strength of association between r and Q <REF>Following Pantel and Lin 2002</REF>, we use pointwise mutual information pmi to measure the association strength between two events q and r, where q is a term in Q and r is syntactic dependency, as follows <TREF>Church and Hanks 1989</TREF>:      N fqc N rwc N rqc Ff Ww rqpmi       , , , log,  41 where cq,r is the frequency of r in the feature vector of q as defined in Section 32, W is the set of all words in our corpus, F is the set of all syntactic dependencies in our corpus, and N   WwFf fwc , is the total frequency count of all features of all words	0	We estimate the association strength between a property r and a set of terms Q by taking the expected pmi between r and each term in Q as:       Qq rqpmiqPrQpmi ,,  42 where Pq is the probability of q in the corpus	1	Finally, the EIIR model chooses an n-best list by selecting the n properties from R that have highest pmiQ, r	0	3	2
E06-1050	P89-1010	2006	32 Contexts The context in which a word appears often imposesconstraintsonthesemantictypeoftheword	0	This basic idea has been exploited by many proposals for distributional similarity and clustering, eg, <TREF>Church and Hanks, 1989</TREF>; <REF>Lin, 1998</REF>; <REF>Pereira et al , 1993</REF>	1	Similar to <REF>Lin and Pantel 2001</REF>, we define the contexts of a word to be the undirected paths in dependency trees involving that word at either the beginning or the end	0	The following diagram shows an example dependency tree: Which city hosted the 1988 Winter Olympics	0	6	1
P02-1053	P89-1010	2002	RB, RBR, or RBS VB, VBD, VBN, or VBG anything The second step is to estimate the semantic orientation of the extracted phrases, using the PMI-IR algorithm	0	This algorithm uses mutual information as a measure of the strength of semantic association between two words <TREF>Church  Hanks, 1989</TREF>	1	PMI-IR has been empirically evaluated using 80 synonym test questions from the Test of English as a Foreign Language TOEFL, obtaining a score of 74 <REF>Turney, 2001</REF>	0	For comparison, Latent Semantic Analysis LSA, another statistical measure of word association, attains a score of 64 on the 3 http://wwwcsjhuedu/brill/RBT114tarZ 4 <REF>See Santorini 1995</REF> for a complete description of the tags	0	3	2
P02-1053	P89-1010	2002	same 80 TOEFL questions <REF>Landauer  Dumais, 1997</REF>	0	The Pointwise Mutual Information PMI between two words, word1 and word2, is defined as follows <TREF>Church  Hanks, 1989</TREF>: pword1  word2 PMIword1, word2  log2 pword1 pword2 1 Here, pword1  word2 is the probability that word1 and word2 co-occur	1	If the words are statistically independent, then the probability that they co-occur is given by the product pword1 pword2	0	The ratio between pword1  word2 and pword1 pword2 is thus a measure of the degree of statistical dependence between the words	0	6	1
C00-1084	P89-1010	2000	Thus we introduce d-bigram which is a bigram cooccurrence information concerning the distance<REF>Tsutsumi et al , 1993</REF>	0	Expression 1 calculates the score between two neighboring letters; UKi  E E Mwj,wid;d  x,qd 1 dl j-i--d--1 where wl as an eveN;, d as the distance between two eveN;s, dmax as the maximum distance used in the processing we set drnax - 5, and gd as the weight fimction on distance for this system gd  d-2<REF>Sano et al , 1996</REF>, to decrease tile influence of tile d-bigrams when the distance get longer <TREF>Church and Hanks, 1989</TREF>	1	When calculating the linking score between the letters wi and Wil, tile d-bigram information of the letter pairs around tim target two such as wi-l, wi2; 3 are added	0	Expression 2 calculates the mutual information between two events with d-bigram data; v; d d -2 where x, y as events, d for the distance between two events, and Px as the probability	0	3	2
C96-2099	P89-1010	1996	Linking Score Expression 2 is tbr calculating the linking score between two letters in a sentence 	0	Z 2 d:-:l ji-d-1 dmax : max distance used wl : the i-th letter in the sentence w gd : a certain weight for iV// concerning distance between letters The information between two remote words has less nmaning in a sentence when it comes to the semantic analysis<TREF>Church and Hanks, 1989</TREF>	1	According to the idea we put gd in the expression so that nearer pair can be more effective in calculating the score of the sentence	0	 hi,, I I I--1 B C  F G H Figure 3: Calculation of Linking Score A pair of far-away letters do not have strong relation between each other, neither syntactically nor semantically	0	6	1
P06-2111	P89-1010	2006	Word alignments that are shared by many different words are most probably mismatches	0	For this experiment we used Pointwise Mutual Information I <TREF>Church and Hanks, 1989</TREF>	1	IW, f  log PW, fPWPf,where W is the target word PW is the probability of seeing the word Pf is the probability of seeing the feature PW,f is the probability of seeing the word and the feature together	0	33 Word Alignment The multilingual approach we are proposing relies on automatic word alignment of parallel corpora from Dutch to one or more target languages	0	3	2
D07-1086	P89-1010	2007	For statistical features, previous work Section 2 suggests that the mutual information between the decision tokens xL0 and xR0 may be appropriate	0	The log of the pointwise mutual information <TREF>Church and Hanks, 1989</TREF> between the decision-boundary tokens xL0, xR0 is: MIxL0, xR0  log PrxL0xR0Prx L0PrxR0 This is equivalent to the sum: log CxL0xR0  log K log CxL0 log CxR0	1	For web-based features, the counts C	0	can be taken as a search engines count of the number of pages containing the term	0	6	1
C00-2104	P89-1010	2000	Tile focus of much of this work was to develop the methods themselves	0	<TREF>Church and Hanks 1989</TREF> explored tile use of mutual information statistics in ranking co-occurrences within five-word windows	1	<REF>Smadja 1992</REF> gathered co-occurrences within fiveword windows to find collocations, particularly in specific domains	0	<REF>Hindle 1990</REF> classified nouns on the basis of co-occurring patterns of subjectverb and verb-object pairs	0	6	1
C94-2202	P89-1010	1994	Collocations have been studied by computational linguists in different contexts	0	For instance, there is a substantial body of papers on the extraction of frequently co-occurring words from corpora using statistical methods eg , <REF>Choueka et al , 1983</REF>, <TREF>Church and Hanks, 1989</TREF>, <REF>Smadja, 1993</REF> to list only a few	1	These authors focus on techniques for providing material that can be used in other processing tasks such as x The research rcpmlcd in this paper was undmtaken as the project Collocations and the Lexicalisation of Semantic Operations ET10/75	0	Financial contributions weir by the Commission of the European Community, Association Suissetra Geneva and Oxford University Press	0	6	1
H05-1113	P89-1010	2005	Hence, greater the frequency, the more is the likelihood of the expression to be a MWE	0	612 Point-wise Mutual Information a16  Point-wise Mutual information of a collocation <TREF>Church and Hanks, 1989</TREF> is defined as, a16a18a17a19a11a21a20a23a22a25a24a27a26 a15a28a17a19a11a2a20a23a22a25a24a30a29a31a15a28a17a33a32a34a20a35a32a36a24 a15a28a17a19a11a2a20a35a32a36a24a30a29a37a15a28a17a33a32a34a20a23a22a25a24 where, a11 is the verb and a22 is the object of the collocation	1	The higher the Mutual information of a collocation, the more is the likelihood of the expression to be a MWE	0	613 Least mutual information difference with similar collocations a38  This feature is based on Lins work <REF>Lin, 1999</REF>	0	3	2
H05-1113	P89-1010	2005	Various statistical measures have been suggested for ranking expressions based on their compositionality	0	Some of these are Frequency, Mutual Information <TREF>Church and Hanks, 1989</TREF>, distributed frequency of object <REF>Tapanainen et al , 1998</REF> and LSA model <REF>Baldwin et al , 2003</REF> <REF>Schutze, 1998</REF>	0	In this paper, we define novel measures both collocation based and context based measures to measure the relative compositionality of MWEs of V-N type see section 6 for details	1	Integrating these statistical measures should provide better evidence for ranking the expressions	0	5	2
H05-1113	P89-1010	2005	These ranks are then compared with the human ranking	0	<REF>Breidt, 1995</REF> has evaluated the usefulness of the Point-wise Mutual Information measure as suggested by <TREF>Church and Hanks, 1989</TREF> for the extraction of V-N collocations from German text corpora	1	Several other measures like Log-Likelihood <REF>Dunning, 1993</REF>, Pearsons a2a4a3 <REF>Church et al , 1991</REF></REF>, Z-Score <REF>Church et al , 1991</REF></REF>, Cubic Association Ratio MI3, etc , have been also proposed	0	These measures try to quantify the association of two words but do not talk about quantifying the non-compositionality of MWEs	0	6	1
N07-1028	P89-1010	2007	However, the focus was more on balancing the effect of query expansion techniques such that different concepts in the query were equally benefited	0	Mutual information has been used previously in <TREF>Church and Hanks, 1989</TREF> to identify collocations of terms for identifying semantic relationships in text	1	Experiments were confined to bigrams	0	The use of MaST over a graph of mutual information values to incorporate the most significant dependencies between terms was first noted in <REF>Rijsbergen, 1979</REF>	0	6	1
N07-1028	P89-1010	2007	Mutual Information is attractive because it is not only easy to compute, but also takes into consideration corpus statistics and semantics	0	The mutual information between two terms <TREF>Church and Hanks, 1989</TREF> can be calculated using Equation 2	0	Ix,y  log nx,y N nx N ny N 2 nx,y is the number of times terms x and y occurred within a term window of 100 terms across the corpus, while nx and ny are the frequencies of x and y in the collection of size N terms	0	To tackle the situation where we have an arbitrary number of variables terms we extend the twovariable case to the multivariate case	1	3	2
H89-2012	P89-1010	1989	1	0	Mutual <REF>Information Church and Hanks 1989</REF> discussed the use of the mutual information statistic in order to identify a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type content word/content word to lexico-syntacfic co-occurrence constraints between verbs and prepositions content word/function word	1	Mutual information, lx;y, compares the probability of observing word x and word y together the joint probability with the probabilities of observing x and y independently chance	0	lx;y - log 2 Px,y ex ey If there is a genuine association between x and y, then the joint probability Px,y will he much larger than chance Px Py, and consequently lx;y >> 0, as illustrated in the table below	0	6	1
H89-2012	P89-1010	1989	75 Some Interesting Associations with Doctor in the 1987 AP Corpus N  15 million; w  6 Ix; y fx y fx x fly Y 2	0	Phrasal Verbs 80 24 111 honorary 621 doctor 80 16 1105 doctors 44 dentists 84 60 1105 doctors 241 nurses 71 16 1105 doctors 154 treating 67 12 275 examined 621 doctor 66 12 1105 doctors 317 treat 64 50 621 doctor 1407 bills 64 12 621 doctor 350 visits 63 38 1105 doctors 676 hospitals 61 12 241 nurses 1105 doctors Associations with Doctor Some Less Interesting -13 12 621 doctor 73785 with -14 82 284690 a 1105 doctors 14 24 84716 is 1105 doctors <TREF>Church and Hanks 1989</TREF> also used the mutual information statistic in order to identify phrasal verbs, following up a remark by Sinclair: How common are the phrasal verbs with set	1	Set is particularly rich in making combinations with words like about, in, up, out, on, off, and these words are themselves very common	0	How likely is set off to occur	0	6	1
W93-0309	P89-1010	1993	Extraction of V-N-Collocations from Text Corpora: A Feasibility Study for German Elisabeth Breidt Seminar fiir Sprachwissenschaft University of Tiibingen Kleine Wilhelmstr	0	113, D-72074 Tiibingen breidtarbucklesnsneuphilologieuni-tuebingende Abstract The usefulness of a statistical approach suggested by <TREF>Church and Hanks 1989</TREF> is evaluated for the extraction of verb-noun V-N collocations from German text corpora	1	Some motivations for the extraction of V-N collocations from corpora are given and a couple of differences concerning the German language are mentioned that have implications on the applicability of extraction methods developed for English	0	We present precision and recall results for V-N collocations with support verbs and discuss the consequences for further work on the extraction of collocations from German corpora	0	3	1
W93-0309	P89-1010	1993	Collocations present an area that is important both for lexicography to improve their coverage in modern dictionaries as well as for lexical acquisition in computational linguistics, where the goal is to build either large reusable lexical databases LDBs or specific lexica for specialized NLP-applications	0	We have tested the statistical approach Mutual Information MI, brought up by <TREF>Church and Hanks 1989</TREF> for linguistics, for a semiautomatic extraction of verb-noun V-N collocations from untagged German text corpora	1	We try to answer the question how much can be done with an untagged corpus and what might be gained by lemmatizing, POS-tagging or even superficial parsing	0	<REF>Choueka 1988</REF> describes how to automatically extract word combinations from English corpora as a preselection of collocation candidates to ease a lexicographers search for collocations	0	3	1
W06-1204	P89-1010	2006	AER  MergePos 054 045 049 05101  MergeMI 055 045 050 05045 Table 6: Results using the compositionality based features pressions of various types	1	Some of them are Frequency, Point-wise mutual information <TREF>Church and Hanks, 1989</TREF>, Distributed frequency of object <REF>Tapanainen et al , 1998</REF>, Distributed frequency of object using verb information <REF>Venkatapathy and Joshi, 2005</REF></REF>, Similarity of object in verbobject pair using the LSA model <REF>Baldwin et al , 2003</REF>, <REF>Venkatapathy and Joshi, 2005</REF></REF> and Lexical and Syntactic fixedness <REF>Fazly and Stevenson, 2006</REF>	0	These features have largely been evaluated by the correlation of the compositionality value predicted by these measures with the gold standard value suggested by human judges	0	It has been shown that the correlation of these measures is higher than simple baseline measures suggesting that these measures represent compositionality quite well	0	3	2
W06-1204	P89-1010	2006	In the past, various measures have been suggested for measuring the compositionality of multi-word expressions	0	Some of these are mutual information <TREF>Church and Hanks, 1989</TREF>, distributed frequency <REF>Tapanainen et al , 1998</REF> and Latent Semantic Analysis LSA model <REF>Baldwin et al , 2003</REF>	0	Even though, these measures have been shown to represent compositionality quite well, compositionality itself has not been shown to be useful in any application yet	1	In this paper, we explore this possibility of using the information about compositionality of MWEs verb based for the word alignment task	0	1	2
D07-1053	P89-1010	2007	Our main aim is here to investigate the use of long-distance semantic dependencies to dynamically adapt the prediction to the current semantic context of communication	0	Similar work has been done by <REF>Li and Hirst 2005</REF> and <REF>Matiasek and Baroni 2003</REF>, who exploit Pointwise Mutual Information PMI; <TREF>Church and Hanks, 1989</TREF>	1	Trnka et al	0	2005 dynamically interpolate a high number of topic-oriented models in order to adapt their predictions to the current topic of the text or conversation	0	6	1
P90-1034	P89-1010	1990	More is to be learned from the fact that you can drink wine than from the fact that you can drink it even though there are more clauses in our sample with  as an object of drink than with wine	0	To capture this intuition, we turn, following <TREF>Church and Hanks 1989</TREF>, to mutual information see <REF>Fano 1961</REF>	1	The mutual information of two events lx y is defined as follows: Px y lxy  log2 Px Py where Px y is the joint probability of events x and y, and Px and Py axe the respective independent probabilities	0	When the joint probability Px y is high relative to the product of the independent probabilities, I is positive; when the joint probability is relatively low, I is negative	0	3	2
W05-1207	P89-1010	2005	The aim of this measure is to indicate the relatedness between two elements composing a pair	0	Mutual information has been positively used in many NLP tasks such as collocation analysis <TREF>Church and Hanks, 1989</TREF>, terminology extraction <REF>Damerau, 1993</REF>, and word sense disambiguation <REF>Brown et al , 1991</REF>	1	3 Experimental Evaluation As many other corpus linguistic approaches, our entailment detection model relies partially on some linguistic prior knowledge the expected structure of the searched collocations, ie, the textual entailment patterns and partially on some probability distribution estimation	0	Only a positive combination of both these two ingredients can give good results when applying and evaluating the model	0	1	2
J93-1007	P89-1010	1993	In the first stage, pairwise lexical relations are retrieved using only statistical information	0	This stage is comparable to <TREF>Church and Hanks 1989</TREF> in that it evaluates a certain word association between pairs of words	1	As in <TREF>Church and Hanks 1989</TREF>, the words can appear in any order and they can be separated by an arbitrary number of other words	0	However, the statistics we use provide more information and allow us to have more precision in our output	0	2	2
J93-1007	P89-1010	1993	Example sentences containing the two words in the two possible positions are:  The provision is aimed at making a hostile takeover prohibitively expensive by enabling Borg Warners stockholders to buy the The pill would make a takeover attempt more expensive by allowing the retailers shareholders to buy more company stock Let us note that this filtering method is an original contribution of our work	0	Other works such as <TREF>Church and Hanks 1989</TREF> simply focus on an evaluation of the correlation of appearance of a pair of words, which is roughly equivalent to condition C1	1	See next section	0	However, taking note of their pattern of appearance allows us to filter out more irrelevant collocations with C2 and C3	0	2	1
J93-1007	P89-1010	1993	Finally, at a more general level, although disambiguation was originally considered as a performance task, the collocations retrieved have not been used for any specific computational task	0	<TREF>Church and Hanks 1989</TREF> describe a different set of techniques to retrieve collocations	1	A collocation as defined in their work is a pair of correlated words	0	That is, a collocation is a pair of words that appear together more often than expected	0	6	1
J93-1007	P89-1010	1993	Collocations in the lexicographic meaning are only dealt with in the lexical approach	0	Aside from the work we present in this paper, most of the work carried out within the lexical approach has been done in computer-assisted lexicography by <REF>Choueka, Klein, and Neuwitz 1983</REF> and Church and his colleagues <TREF>Church and Hanks 1989</TREF>	0	Both works attempted to automatically acquire true collocations from corpora	1	Our work builds on Chouekas, and has been developed contemporarily to Churchs	0	2	1
J93-1007	P89-1010	1993	This stage is comparable to <TREF>Church and Hanks 1989</TREF> in that it evaluates a certain word association between pairs of words	1	As in <TREF>Church and Hanks 1989</TREF>, the words can appear in any order and they can be separated by an arbitrary number of other words	0	However, the statistics we use provide more information and allow us to have more precision in our output	0	The output of this first stage is then passed in parallel to the next two stages	0	2	3
J93-1007	P89-1010	1993	This limitation is intrinsic to the technique used since mutual information scores are defined for two items	0	The second limitation is that many collocations identified in <TREF>Church and Hanks 1989</TREF> do not really identify true collocations, but simply pairs of words that frequently appear together such as the pairs doctor-nurse, doctor-bill, doctor-honorary, doctors-dentists, doctors-hospitals, etc These co-occurrences are mostly due to semantic reasons	1	The two words are used in the same context because they are of related meanings; they are not part of a single collocational construct	0	The work we describe in the rest of this paper is along the same lines of research	0	1	3
J93-1007	P89-1010	1993	The two words are often used together because they are associated with the same context rather than for pure structural reasons	0	Many collocations retrieved in <TREF>Church and Hanks 1989</TREF> were of this type, as they retrieved doctors-dentists, doctors-nurses, doctorbills, doctors-hospitals, nurses-doctor, etc , which are not collocations in the sense defined above	1	Such collocations are not of interest for our purpose, although they could be useful for disambiguation or other semantic purposes	0	Condition C2 filters out exactly this type of collocations	0	1	3
J93-1002	P89-1010	1993	In this case, we are interested in collocations between the head of a PP complement, a preposition and the head of the phrase being postmodified	0	In general, these words will not be adjacent in the text, so it will not be possible to use existing approaches unmodified eg <TREF>Church and Hanks 1989</TREF>, because these apply to adjacent words in unanalyzed text	1	<REF>Hindle and Rooth 1991</REF> report good results using a mutual information measure of collocation applied within such a structurally defined context, and their approach should carry over to our framework straightforwardly	0	One way of integrating structural collocational information into the system presented above would be to make use of the semantic component of the ANLT grammar This component pairs logical forms with each distinct syntactic analysis that represent, among other things, the predicate-argument structure of the input	0	1	3
H05-1058	P89-1010	2005	Finally, we write the conditional probability as a function of : Pci  1jsi1,si  11  n1    n where   PH1P H0  Psi1,siPs i1Psi  Psijsi1Ps i The conditional probability, Pci  1jsi1,si is a mapping g from  2 0,1 to p 2 0, 1	0	Beginning with <TREF>Church and Hanks, 1989</TREF>, numerous authors have used the pointwise mutual information between pairs of words to analyze word co-locations and associations	1	This ratio tells us whether si1 and si co-occur more or less often than would be expected by chance alone	0	Consider, for example, the tags DT determiner and NN noun, and the four possible ordered tagpairs	0	6	1
P05-1077	P89-1010	2005	Since we use grammatical context, the feature set is considerably larger than the simple word based proximity feature set for the newspaper corpus	0	43 Calculating Feature Vectors Having collected all nouns and their features, we now proceed to construct feature vectors and values for nouns from both corpora using mutual information <TREF>Church and Hanks, 1989</TREF>	1	We first construct a frequency count vector Ce  ce1,ce2,,cek, where k is the total number of features and cef is the frequency count of feature f occurring in word e Here, cef is the number of times word e occurred in context f We then construct a mutual information vector MIe  mie1,mie2,,miek for each word e, where mief is the pointwise mutual information between word e and feature f, which is defined as: mief  log cef Nsummationtext n i1 cif N  summationtextk j1 cej N 6 where n is the number of words and N  5We perform this operation so that we can compare the performance of our system to that of <REF>Pantel and Lin 2002</REF>	0	summationtextn i1 summationtextm j1 cij is the total frequency count of all features of all words	0	3	2
P04-3025	P89-1010	2004	The SO of a phrase is determined based upon the phrases pointwise mutual information PMI with the words excellent and poor	0	PMI is defined by <TREF>Church and Hanks 1989</TREF> as follows: a0a2a1a4a3a6a5a8a7a10a9a12a11a13a7a15a14a17a16a19a18a21a20a23a22a25a24 a14a27a26a29a28 a5a8a7a10a9a19a30a31a7a15a14a17a16 a28 a5a8a7 a9 a16 a28 a5a8a7 a14 a16a33a32 1 where a28 a5a8a7a10a9a19a30a31a7a15a14a12a16 is the probability that a7a34a9 and a7a35a14 co-occur	0	The SO for a a28a37a36a39a38a41a40a29a42a44a43 is the difference between its PMI with the word excellent and its PMI with the word poor The method used to derive these values takes advantage of the possibility of using the World Wide Web as a corpus, similarly to work such as <REF>Keller and Lapata, 2003</REF>	0	The probabilities are estimated by querying the AltaVista Advanced Search engine1 for counts	1	3	2
W97-1004	P89-1010	1997	To solve the problem, we make use of a kind of cooperative evolution strategy to design an evolutionary algorithm	0	Word compositions have long been a concern in lexicography<REF>Benson et al 1986</REF></REF>; <REF>Miller et al 1995</REF>, and now as a specific kind of lexical knowledge, it has been shown that they have an important role in many areas in natural language processing, eg, parsing, generation, lexicon building, word sense disambiguation, and information retrieving, etceg , <REF>Abney 1989, 1990</REF>; <REF>Benson et al 1986</REF></REF>; <REF>Yarowsky 1995</REF>; <TREF>Church and Hanks 1989</TREF>; Church, <REF>Gale, Hans, and Hindle 1989</REF>	1	But due to the huge number of words, it is impossible to list all compositions between words by hand in dictionaries	0	So an urgent problem occurs: how to automatically acquire word compositions	0	5	2
W97-1004	P89-1010	1997	While bound compositions are not predictable, ie, their reasonableness cannot be derived from the syntactic and semantic properties of the words in them<REF>Smadja 1993</REF>	0	Now with the availability of large-scale corpus, automatic acquisition of word compositions, especially word collocations from them have been extensively studiedeg , <REF>Choueka et al 1988</REF>; <TREF>Church and Hanks 1989</TREF>; <REF>Smadja 1993</REF>	0	The key of their methods is to make use of some statistical means, eg, frequencies or mutual information, to quantify the compositional strength between words	0	These methods are more appropriate for retrieving bound compositions, while less appropriate for retrieving free ones	1	1	3
I05-1049	P89-1010	2005	The classifier can also be used to rank these vectors according to their relative compositionality	0	3 Related <REF>Work Church and Hanks 1989</REF> proposed a measure of association called Mutual Information 9	1	Mutual Information MI is the logarithm of the ratio between the probability of the two words occurring together and the product of the probability of each word occurring individually	0	The higher the MI, the more likely are the words to be associated with each other	0	6	1
P93-1032	P89-1010	1993	Dictionaries produced by hand always substantially lag real language use	0	The last two points do not argue against the use of existing dictionaries, but show that the incomplete information that they provide needs to be supplemented with further knowledge that is best collected automatically The desire to combine hand-coded and automatically learned knowledge 1A point made by <TREF>Church and Hanks 1989</TREF>	1	Arbitrary gaps in listing can be smoothed with a program such as the work presented here	0	For example, among the 27 verbs that most commonly cooccurred with from, Church and Hanks found 7 for which this 235 suggests that we should aim for a high precision learner even at some cost in coverage, and that is the approach adopted here	0	4	2
D07-1115	P89-1010	2007	They are estimated by using Table 2	0	C8B4CRCYD4D3D7B5 BP CUB4CRBND4D3D7B5 CUB4CRBND4D3D7B5B7CUB4BMCRBND4D3D7B5 C8B4CRCYD2CTCVB5 BP CUB4CRBND2CTCVB5 CUB4CRBND2CTCVB5B7CUB4BMCRBND2CTCVB5 PMI based polarity value Using PMI, the strength of association between CR and positive sentences and negative sentences is defined as follows <TREF>Church and Hanks, 1989</TREF>	1	C8C5C1B4CRBND4D3D7B5 BP D0D3CV BE C8B4CRBND4D3D7B5 C8B4CRB5C8B4D4D3D7B5 C8C5C1B4CRBND2CTCVB5 BP D0D3CV BE C8B4CRBND2CTCVB5 C8B4CRB5C8B4D2CTCVB5 PMI based polarity value is defined as their difference	0	This idea is the same as <REF>Turney, 2002</REF>	0	3	2
W05-1202	P89-1010	2005	The reason for choosing this measure is that it can be used to compute the distance between any two co-occurrence vectors independent of any information about other words	0	This is in contrast to many other measures, eg, <REF>Lin 1998</REF>, which use the co-occurrences of features with other words to compute a weighting function such as mutual information MI <TREF>Church and Hanks, 1989</TREF>	1	Since we only have corpus data for the target phrases, it is not possible for us to use such a measure	0	However, the -skew divergence measure has been shown <REF>Weeds, 2003</REF> to perform comparably with measures which use MI, particularly for lower frequency target words	0	6	1
I08-1038	P89-1010	2008	If the absolute value of the relative distance in a sentence for a feature and an opinion word is less than Minimum-Offset, they are considered contextdependent	0	Many methods have been proposed to measure the co-occurrence relation between two words such as  2 Church and Mercer,1993 , mutual information <TREF>Church and Hanks, 1989</TREF></TREF>; <REF>Pantel and Lin, 2002</REF>, t-test <TREF>Church and Hanks, 1989</TREF></TREF>, and loglikelihood Dunning,1993	0	In this paper a revised formula of mutual information is used to measure the association since mutual information of a lowfrequency word pair tends to be very high	1	Table 1 gives the contingency table for two words or phrases w 1  and  w 2 , where A is the number of reviews where w 1  and w 2  co-occur; B indicates the number of reviews where w 1  occurs but does not co-occur with w 2 ; C denotes the number of reviews where w 2  occurs but does not co-occur with w 1 ; D is number of reviews where neither w 1  nor w 2  occurs; N  A  B  C  D With the table, the revised formula of mutual information is designed to calculate the association of w 1 with w 2  as formula 1	0	5	2
W04-0412	P89-1010	2004	Other types of phrases	0	Many efficient techniques exist to extract multiword expressions, collocations, lexical units and idioms <TREF>Church and Hanks, 1989</TREF>; <REF>Smadja, 1993</REF>; <REF>Dias et al , 2000</REF>; <REF>Dias, 2003</REF>	1	Unfortunately, very few have been applied to information retrieval with a deep evaluation of the results	0	Maximal Frequent Sequences	0	1	2
I05-3009	P89-1010	2005	An inter-domain entropy IDE measure will be proposed for this purpose	0	2 Conventional Clustering View for Constructing Lexicon Trees One conventional way to construct the lexicon hierarchy from web corpora is to collect the terms in all web documents and measure the degree of word association between word pairs using some well-known association metrics <TREF>Church and Hanks, 1989</TREF>; <REF>Smadja et al , 1996</REF> as the distance measure	1	Terms of high association are then clustered bottom-up using some clustering techniques to build the hierarchy	0	The clustered hierarchy is then submitted to lexicographers to assign a semantic label to each sub-cluster	0	6	1
P06-1107	P89-1010	2006	The definition can be easily extended to a set of expressions T Given a pair vt and vh we define the following entailment strength indicator Svt,vh	0	Specifically, the measure Snomvt,vh is derived from point-wise mutual information <TREF>Church and Hanks, 1989</TREF>: Snomvt,vh  log pvt,vhnompv tpvhpers 3 where nom is the event of having a nominalized textual entailment pattern and pers is the event of having an agentive nominalization of verbs	1	Probabilities are estimated using maximum-likelihood: pvt,vhnom  fCPnomvt,vhf C uniontextP nomvprimet,vprimeh, 852 pvt  fCFvt/fCuniontextFv, and pvhpers  fCFagentvh/fCuniontextFagentv	0	Counts are considered useful when they are greater or equal to 3	0	3	2
N04-1041	P89-1010	2004	We then construct a mutual information vector MIe  mi e1, mi e2, , mi em  for each word e, where mi ef is the pointwise mutual information between word e and feature f, which is defined as: N c N c N c ef m j ej n i if ef mi       1 1 log 1 where n is the number of words and N    n i m j ij c 11 is the total frequency count of all features of all words	1	Mutual information is commonly used to measure the association strength between two words <TREF>Church and Hanks 1989</TREF>	0	A well-known problem is that mutual information is biased towards infrequent elements/features	0	We therefore multiply mi ef with the following discounting factor: 1,min,min 1 11 11                        m j jf n i ei m j jf n i ei ef ef cc cc c c 2 32 Phase II Following <REF>Pantel and Lin 2002</REF>, we construct a committee for each semantic class	0	3	2
J94-4003	P90-1034	1994	This is the basis for Sadlers Analogical Semantics <REF>Sadler 1989</REF>, which according to his report has not proved effective	0	His results may be improved if more sophisticated methods and larger corpora are used to establish similarity between words such as in <TREF>Hindle 1990</TREF>	1	In particular, an enhancement of our disambiguation method, using similarity-based estimation <REF>Dagan, Marcus, and Markovitch 1993</REF>, was evaluated recently	0	In this evaluation the applicability of the disambiguation method was increased by 15, with only a slight decrease in the precision	0	6	1
J94-4003	P90-1034	1994	 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 4 knowledge can be found in the use of statistical data on the occurrence of lexical relations in large corpora eg , <REF>Grishman, Hirschman, and Nhan 1986</REF>	0	The use of such relations mainly relations between verbs or nouns and their arguments and modifiers for various purposes has received growing attention in recent research <REF>Church and Hanks 1990</REF>; <REF>Zernik and Jacobs 1990</REF>; <TREF>Hindle 1990</TREF>; <REF>Smadja 1993</REF>	1	More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment <REF>Hindle and Rooth 1991</REF> and pronoun references <REF>Dagan and Itai 1990, 1991</REF>	0	Clearly, statistics on lexical relations can also be useful for target word selection	0	6	1
J94-4003	P90-1034	1994	The use of such relations mainly relations between verbs or nouns and their arguments and modifiers for various purposes has received growing attention in recent research <REF>Church and Hanks 1990</REF>; <REF>Zernik and Jacobs 1990</REF>; <TREF>Hindle 1990</TREF>; <REF>Smadja 1993</REF>	0	More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment <REF>Hindle and Rooth 1991</REF> and pronoun references <REF>Dagan and Itai 1990, 1991</REF>	1	Clearly, statistics on lexical relations can also be useful for target word selection	0	Consider, for example, the Hebrew sentence extracted from the foreign news section of the daily Ha-<REF>Aretz, September 1990</REF> transcripted to Latin letters: 1 Nose ze mana mi-shtei ha-mdinot mi-lahtom al hoze shalom	0	6	1
P06-1100	P90-1034	2006	We present an empirical evaluation on the task of attaching partof and causation relations, showing an improvement on F-score over a baseline model	0	NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts <REF>Etzioni et al 2005</REF>, semantic lexicons <REF>Riloff and Shepherd 1997</REF>, concept lists <REF>Lin and Pantel 2002</REF>, and word similarity lists <TREF>Hindle 1990</TREF>	1	Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments <REF>Szpektor et al 2004</REF>, is-a <REF>Ravichandran and Hovy 2002</REF>, part-of <REF>Girju et al 2003</REF>, and other relations	0	The output of most of these systems is flat lists of lexical semantic knowledge such as Italy is-a country and orange similar-to blue	0	6	1
C04-1116	P90-1034	2004	There have been many approachs to automatic detection of similar words from text	0	Our method is similar to <TREF>Hindle, 1990</TREF>, <REF>Lin, 1998</REF>, and <REF>Gasperin, 2001</REF> in the use of dependency relationships as the word features	1	Another approach used the words distribution to cluster the words <REF>Pereira, 1993</REF>, and Inoue <REF>Inoue, 1991</REF> also used the word distributional information in the Japanese-English word pairs to resolve the polysemous word problem	0	Wu <REF>Wu, 2003</REF> shows one approach to collect synonymous collocation by using translation information	0	5	1
C04-1116	P90-1034	2004	3 http:// wwwcisupennedu/ treebank/ rank candidate 1 batt 2 batterie 3 bat 4 BTBTBTBT cover 5 BTY 6 batterry 7 BT BT BT BT BT BT BT BT BT BT adapter 8 bezel 9 BT BT BT BT BT BT BT BT BT BT cheque 10 BTBTBTBT screw Table 3: batterys Synonymous Expression Candidates from the Entire Corpus Author A rank candidate 1 battery 2 controller 3 BT BT BT BT BT BT BT BT Cover 4 APM 5 BTBTBTBT screw 6 mark 7 BT BT BT BT BT BT BT BT BT BT cheque 8 diskette 9 checkmark 10 boot Author B rank candidate 1 batt 2 form 3 protector 4 DISKETTE 5 Mwave 6 BT BT BT BT BT BT BT BT BT BT adapter 7 mouse 8 BT BT BT BT BT BT BT BT BT BT cheque 9 checkmark 10 process Table 4: Noise Candidates from Each Authors Corpus word	0	The words we want to aggregate for text analysis are not rigorous synonyms, but the role is the same, so we have to consider the syntactic relation based on the assumptions that words with the same role tend to modify or be modified by similar words <TREF>Hindle, 1990</TREF>; <REF>Strzalkowski, 1992</REF>	1	On the other hand, window-based techniques are not suitable for our data, because the documents are written by several authors who have a variety of different writing styles eg selecting different prepositions and articles	0	Therefore we consider only syntactic features: dependency pairs, which consist of nouns, verbs, and their relationships	0	6	1
P06-1102	P90-1034	2006	All digits in both patterns and sentences are replaced with a common marker, such 810 that any two numerical values with the same number of digits will overlap during matching	0	Many methods have been proposed to compute distributional similarity between words, eg, <TREF>Hindle, 1990</TREF>, <REF>Pereira et al , 1993</REF>, <REF>Grefenstette, 1994</REF> and <REF>Lin, 1998</REF>	1	Almost all of the methods represent a word by a feature vector, where each feature corresponds to a type of context in which the word appeared	0	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed	0	6	1
C08-1051	P90-1034	2008	et al, 1999; <REF>Torisawa, 2002</REF>	0	Others proposed distributional similarity measures between words <TREF>Hindle, 1990</TREF>; <REF>Lin, 1998</REF>; <REF>Lee, 1999</REF>; <REF>Weeds et al, 2004</REF>	1	Once such similarity is defined, it is trivial to perform clustering	0	On the other hand, some researchers utilized co-occurrence for word clustering	0	6	1
C94-1074	P90-1034	1994	In fact, corpus linguistics became a popular research field because of the claim that shallow techniques could overcome the lexical coverage bottleneck of traditional NLP techniques	0	Among the applications of collocational analysis for lexical acquisition are: the derivation of syntactic disambiguation cues <REF>Basili et al 1991, 1993a</REF>; <REF>Hindle and Rooths 1991</REF>,1993; <REF>Sekine 1992</REF> <REF>Bogges et al 1992</REF>, sense preference <REF>Yarowski 1992</REF>, acquisition of selectional restrictions <REF>Basili et al 1992b, 1993b</REF>; <REF>Utsuro et al 1993</REF>, lexical preference in generation <REF>Smadjia 1991</REF>, word clustering <REF>Pereira 1993</REF>; <TREF>Hindle 1990</TREF>; <REF>Basili et al 1993c</REF>, etc In the majority of these papers, even though the precedent or subsequent statistical processing reduces the number of accidental associations, very large corpora 10,000,000 words are necessary to obtain reliable data on a large enough number of words	1	In addition, most papers produce a performance evaluation of their methods but do not provide a measure of the coverage, ie the percentage of cases for which their method actually provides a right or wrong solution	0	It is quite common that results are discussed only for 10-20 cases	0	1	3
W05-1516	P90-1034	2005	This is known as the Distributional Hypothesis in linguistics <REF>Harris, 1968</REF>	0	For example, the words test and exam are similar because both of them follow verbs such as administer, cancel, cheat on, conduct,  and both of them can be preceded by adjectives such as academic, comprehensive, diagnostic, difficult,  Many methods have been proposed to compute distributional similarity between words <TREF>Hindle, 1990</TREF>; <REF>Pereira et al , 1993</REF>; <REF>Grefenstette, 1994</REF>; <REF>Lin, 1998</REF>	1	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared	0	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed	0	6	1
W06-2904	P90-1034	2006	This is known as the Distributional Hypothesis in linguistics <REF>Harris, 1968</REF>	0	For example, the words test and exam are similar because both of them can follow verbs such as administer, cancel, cheat on, conduct, etc Many methods have been proposed to compute distributional similarity between words, eg, <TREF>Hindle, 1990</TREF>; <REF>Pereira et al , 1993</REF>; <REF>Grefenstette, 1994</REF>; <REF>Lin, 1998</REF>	1	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared	0	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed	0	6	1
P08-2008	P90-1034	2008	<REF>Schutze 1998</REF> used bag-of-words contexts for sense discrimination	0	<TREF>Hindle 1990</TREF> grouped nouns into thesaurus-like lists based on the similarity of their syntactic contexts	0	Our approach is similar with the difference that we do not group noun arguments into finite categories, but instead leave the category boundaries blurry and allow overlaps	1	The DDNs are essentially a form of world knowledge which we extract automatically and apply to VSD	0	5	1
P93-1022	P90-1034	1993	or the cooccurrence of two words within a limited distance in the context	0	Statistical data about these various cooccurrence relations is employed for a variety of applications, such as speech recognition <REF>Jelinek, 1990</REF>, language generation <REF>Smadja and McKeown, 1990</REF>, lexicography <REF>Church and Hanks, 1990</REF>, machine translation Brown et al , ; <REF>Sadler, 1989</REF>, information retrieval <REF>Maarek and Smadja, 1989</REF> and various disambiguation tasks <REF>Dagan et al , 1991</REF>; <REF>Hindle and Rooth, 1991</REF>; <REF>Grishman et al , 1986</REF>; <REF>Dagan and Itai, 1990</REF>	0	A major problem for the above applications is how to estimate the probability of cooccurrences that were not observed in the training corpus	1	Due to data sparseness in unrestricted language, the aggregate probability of such cooccurrences is large and can easily get to 25 or more, even for a very large training corpus <REF>Church and Mercer, 1992</REF>	0	1	3
P93-1022	P90-1034	1993	To account for this problem we developed a simple heuristic that searches for words that are potentially similar to w, using thresholds on mutual information values and frequencies of cooccurrence pairs	0	The search is based on the property that when computing simwl, w2, words that have high mutual information values 5The nominator in our metric resembles the similarity metric in <TREF>Hindle, 1990</TREF>	1	We found, however, that the difference between the two metrics is important, because the denominator serves as a normalization factor	0	with both wl and w2 make the largest contributions to the value of the similarity measure	0	2	1
P98-1082	P90-1034	1998	Semantic variation is rarely studied in specialized domains	0	Works on word similarity and word sense disambiguation are generally based on statistical methods designed for large or even very large corpora <TREF>Hindle, 1990</TREF>; <REF>Agirre and Rigau, 1996</REF>	0	Therefore, they cannot be applied for technical documents which usually are medium size corpora	1	However, dealing with already linguistic filtered data, <REF>Assadi, 1997</REF> aims at statistically build rough clusters supposing that similar candidate terms have similar expansions	0	1	3
W02-1107	P90-1034	2002	We applied both a neural network model and a linguistic method, that is syntactic information, to a large corpora and extracted necessary information	0	To extract semantic information of words such as synonyms and antonyms from corpora, previous research used syntactic structures <TREF>Hindle 1990</TREF>, <REF>Hatzivassiloglou 1993</REF> and <REF>Tokunaga 1995</REF>, response time to associate synonyms and antonyms in psychological experiments <REF>Gross 1989</REF>, or extracting related words automatically from corpora <REF>Grefensette 1994</REF>	1	Most lexical classification is based on parts of speech, as they have very important semantic information	0	For examples, typically, an adjective refers to an attribute, a verb refers to a motion or an event, and a noun refers to an object	0	6	1
P91-1027	P90-1034	1991	3 RELATED WORK Interest in extracting lexical and especially collocational information from text has risen dramatically in the last two years, as sufficiently large corpora and sufficiently cheap computation have become available	0	Three recent papers in this area are <REF>Church and Hanks 1990</REF>, <TREF>Hindle 1990</TREF>, and <REF>Smadja and McKeown 1990</REF>	1	The latter two are concerned exclusively with collocation relations between open-class words and not with grammatical properties	0	Church is also interested primarily in open-class collocations, but he does discuss verbs that tend to be followed by infinitives within his mutual information framework	0	6	1
P07-1057	P90-1034	2007	Following the idea proposed in Harris Distributional Hypothesis <REF>Harris, 1985</REF>, that words occurring in similar contexts are semantically similar, many works have used different definitions of context to identify various types of semantic similarity	0	<TREF>Hindle 1990</TREF> uses a mutual-information based metric derived from the distribution of subject, verb and object in a large corpus to classify nouns	1	Pereira et al	0	1993 cluster nouns according to their distribution as direct objects of verbs, using information-theoretic tools the predecessors of the tools we use in this work	0	6	1
P08-3001	P90-1034	2008	Distributional similarity represents the relatedness of two words by the commonality of contexts the words share, based on the distributional hypothesis <REF>Harris, 1985</REF>, which states that semantically similar words share similar contexts	0	A number of researches which utilized distributional similarity have been conducted, including <TREF>Hindle, 1990</TREF>; <REF>Lin, 1998</REF>; <REF>Geffet and Dagan, 2004</REF> and many others	0	Although they have been successful in acquiring related words, various parameters such as similarity measures and weighting are involved	1	As Weeds et al	0	1	3
P06-1101	P90-1034	2006	In our experiments we set   095	0	32 m,n-cousin Classification The classifier for learning coordinate terms relies on the notion of distributional similarity, ie, the idea that two words with similar meanings will be used in similar contexts <TREF>Hindle, 1990</TREF>	0	We extend this notion to suggest that words with similar meanings should be near each other in a semantic taxonomy, and in particular will likely share a hypernym as a near parent	1	Our classifier for m,n-cousins is derived from the algorithm and corpus given in <REF>Ravichandran et al , 2005</REF>	0	5	1
P97-1066	P90-1034	1997	We agree with the differential definition of semantics : the meaning of the morpho-lexical units is not defined by reference to a concept, but rather by contrast with other units <REF>Rastier et al , 1994</REF>	0	In fact, we are considering word usage rather than word meanin <REF>Zernik, 1990</REF> following in this the distributional point of view, see <REF>Harris, 1968</REF>, <TREF>Hindle, 1990</TREF>	1	Statistical or probabilistic methods are often used to extract semantic clusters from corpora in order to build lexical resources for ANLP tools <TREF>Hindle, 1990</TREF>, <REF>Zernik, 1990</REF>, <REF>Resnik, 1993</REF>, or for automatic thesaurus generation <REF>Grefenstette, 1994</REF>	0	We use similar techniques, enriched by a preliminaxy morpho-syntaztic analysis, in order to perform knowledge acquisition and modeling for a specific task eg : electrical network planning	0	6	1
P97-1066	P90-1034	1997	In fact, we are considering word usage rather than word meanin <REF>Zernik, 1990</REF> following in this the distributional point of view, see <REF>Harris, 1968</REF>, <TREF>Hindle, 1990</TREF>	0	Statistical or probabilistic methods are often used to extract semantic clusters from corpora in order to build lexical resources for ANLP tools <TREF>Hindle, 1990</TREF>, <REF>Zernik, 1990</REF>, <REF>Resnik, 1993</REF>, or for automatic thesaurus generation <REF>Grefenstette, 1994</REF>	1	We use similar techniques, enriched by a preliminaxy morpho-syntaztic analysis, in order to perform knowledge acquisition and modeling for a specific task eg : electrical network planning	0	Moreover, we are dealing with language for specific purpose texts and not with general texts	0	3	1
P08-1002	P90-1034	2008	Our approach avoids hand-crafting a set of spe11 ci c indicator features; we simply use the distribution of the pronouns context	0	Our method is thus related to previous work based on <REF>Harris 1985</REF>s distributional hypothesis2 It has been used to determine both word and syntactic path similarity <TREF>Hindle, 1990</TREF>; <REF>Lin, 1998a</REF>; <REF>Lin and Pantel, 2001</REF>	1	Our work is part of a trend of extracting other important information from statistical distributions	0	<REF>Dagan and Itai 1990</REF> use the distribution of a pronouns context to determine which candidate antecedents can  t the context	0	5	1
P05-1016	P90-1034	2005	The hypothesis states that words that occur in the same contexts tend to have similar meaning	0	Researchers have mostly looked at representing words by their surrounding words <REF>Lund and Burgess 1996</REF> and by their syntactical contexts <TREF>Hindle 1990</TREF>; <REF>Lin 1998</REF>	0	However, these representations do not distinguish between the different senses of words	1	Our framework utilizes these principles and representations to induce disambiguated feature vectors	0	1	3
W05-1504	P90-1034	2005	2a	0	If the bound is too tight to allow the correct parse of some sentence, we would still like to allow an accurate partial parse: a sequence of accurate parse fragments <TREF>Hindle, 1990</TREF>; <REF>Abney, 1991</REF>; <REF>Appelt et al , 1993</REF>; <REF>Chen, 1995</REF>; <REF>Grefenstette, 1996</REF>	1	Furthermore, we would like to use the fact that some fragment sequences are presumably more likely than others	0	Our partial parses will look like the one in Fig	0	6	1
C00-2104	P90-1034	2000	<REF>Smadja 1992</REF> gathered co-occurrences within fiveword windows to find collocations, particularly in specific domains	0	<TREF>Hindle 1990</TREF> classified nouns on the basis of co-occurring patterns of subjectverb and verb-object pairs	1	<REF>Hatzivassiloglou and MeKeown 1993</REF> clustered adjectives into semantic classes, and Pereira et al	0	1993 clustered nouns on their appearance ill verb-object pairs	0	6	1
C04-1111	P90-1034	2004	Also, the patterns are learned with the specific goal of scaling to the terascale see Table 2	0	22 Co-occurrence-based approaches The second class of algorithms uses cooccurrence statistics <TREF>Hindle 1990</TREF>, <REF>Lin 1998</REF>	1	These systems mostly employ clustering algorithms to group words according to their meanings in text	0	Assuming the distributional hypothesis <REF>Harris 1985</REF>, words that occur in similar grammatical contexts are similar in meaning	0	6	1
C96-1083	P90-1034	1996	4 Towards an adequate similarity esfimatation for the building of ontologies The comparison with the similarity score of <TREF>Hindle, 1990</TREF> shows that SYCLADE similarity indicator is specifically relevant for ontology bootstrap and tuning	0	Hindle uses the observed frequencies within a specific syntactic pattern subject/verb, and verb/object to derive a cooccu,> rence score which is an estimate of mutual information <REF>Church and Hanks, 1990</REF>	0	We adapted this score to noun phrase patterns However the similarity measures based on cooccurrence scores and nominal phrase patterns are less relevant for an ontological analysis	1	The subgraph of the chirurgical acts words, which is easy to identify from the SYCLADE graph fig	0	5	1
C96-1083	P90-1034	1996	Automatic exploration of a sublanguage corpus constitutes a first step towards identifying the semantic classes and relationships which are relevant for this sublanguage	0	In the past five years, important research on the automatic acquisition of word classes based on lexical distribution has been published <REF>Church and Hanks, 1990</REF>; <TREF>Hindle, 1990</TREF>; <REF>Smadja, 1993</REF>; Greinstette, 1994; <REF>Grishman and Sterling, 1994</REF>	0	Most of these approaches, however, need large or even very large corpora in order for word classes to be discovered 1 whereas it is often the case that the data to be processed are insufficient to provide reliable lexical intbrmation	1	In other words, it is not always possible to resort to statistical methods	0	1	3
C96-1083	P90-1034	1996	2 Simplifying parse trees to classify words 21 The need for normalized syntactic contexts As Hindles work proves it, among others <REF>Grishman and Sterling, 1994</REF>; <REF>Grefenstette, 1994</REF>:, the mere existence of robust syntactic parsers makes it possible to parse large corpora in order to automate the discovery of syntactic patterns in the spirit of Harriss distributional hypothesis	0	Itowever, Harris methodology implies also to simplify and transform each parse tree 2, so as to obtain so-called elementary sentences exhibiting the main conceptual classes for the domain Sager lIaor instance, Hindle <TREF>Hindle, 1990</TREF> needs a six million word corpus in order to extract noun similarities from predicate-argunlent structures	1	2Changing passive into active sentences, using a verb instead of a nominalization, and so on	0	490 NP NPa AP4 I I Nr As I I stenose serre NPo PP2 Pa NP6 I de D9 NPlo le NPll AP12 t NPla AP14 A15 I I I N Ar gauche I I tronc eorninun Iigure 1: Parse tree for stenose serre de le hone commun gauche et al , 1987	0	6	1
W98-0704	P90-1034	1998	Although Stairmand <REF>Stairmand, 1997</REF> and Richardson <REF>Richardson and Smeaton, 1995</REF> have proposed the use of WordNet in information retrieval, they did not used WordNet in the query expansion framework	0	Our predicate-argument structure-based thesatmis is based on the method proposed by Hindie <TREF>Hindle, 1990</TREF>, although Hindle did not apply it to information retrieval	1	Instead, he used mutual information statistics as a Similarity coefficient, wheras we used the Dice coefficient for normalization purposes	0	Hindle only extracted the subject-verb and the object-verb predicatearguments, while we also extract adjective-noun predicate-arguments	1	2	1
P06-1045	P90-1034	2006	Among many kinds of lexical relations, synonyms are especially useful ones, having broad range of applications such as query expansion technique in information retrieval and automatic thesaurus construction	0	Various methods <TREF>Hindle, 1990</TREF>; <REF>Lin, 1998</REF>; <REF>Hagiwara et al , 2005</REF> have been proposed for synonym acquisition	0	Most of the acquisition methods are based on distributional hypothesis <REF>Harris, 1985</REF>, which states that semantically similar words share similar contexts, and it has been experimentally shown considerably plausible	0	However, whereas many methods which adopt the hypothesis are based on contextual clues concerning words, and there has been much consideration on the language models such as Latent Semantic Indexing <REF>Deerwester et al , 1990</REF> and Probabilistic LSI <REF>Hofmann, 1999</REF> and synonym acquisition method, almost no attention has been paid to what kind of categories of contextual information, or their combinations, are useful for word featuring in terms of synonym acquisition	1	1	3
P06-1045	P90-1034	2006	However, whereas many methods which adopt the hypothesis are based on contextual clues concerning words, and there has been much consideration on the language models such as Latent Semantic Indexing <REF>Deerwester et al , 1990</REF> and Probabilistic LSI <REF>Hofmann, 1999</REF> and synonym acquisition method, almost no attention has been paid to what kind of categories of contextual information, or their combinations, are useful for word featuring in terms of synonym acquisition	0	For example, <TREF>Hindle 1990</TREF> used cooccurrences between verbs and their subjects and objects, and proposed a similarity metric based on mutual information, but no exploration concerning the effectiveness of other kinds of word relationship is provided, although it is extendable to any kinds of contextual information	1	<REF>Lin 1998</REF> also proposed an information theorybased similarity metric, using a broad-coverage parser and extracting wider range of grammatical relationship including modifications, but he didnt further investigate what kind of relationships actually had important contributions to acquisition, either	0	The selection of useful contextual information is considered to have a critical impact on the performance of synonym acquisition	0	6	1
J93-2005	P90-1034	1993	Some of our initial data suggest that the hypothesis of deep semantic selection may in fact be correct, as well as indicating what the nature of the coercion rules may be	0	Using techniques described in <REF>Church and Hindle 1990</REF>, <REF>Church and Hanks 1990</REF>, and <REF>Hindle and Rooth 1991</REF>, Figure 4 shows some examples of the most frequent V-O pairs from the AP corpus	1	Corpus studies confirm similar results for weakly intensional contexts such as the complement of coercive verbs such as veto	0	These are interesting because regardless of the noun type appearing as complement, it is embedded within a semantic interpretation of the proposal to, thereby clothing the complement within an intensional context	0	6	1
J93-2005	P90-1034	1993	Unfortunately, noun compounds are also employed to express numerous other relationships, as in Unix kernel and C debugger	0	We have found, however, that collocational evidence can be employed to suggest which noun compounds reflect taxonomic relationships, using a strategy similar to that employed by <TREF>Hindle 1990</TREF> for detecting synonyms	0	Given a term T, we extract from the phrase database those nouns Ni that appear as the head of any phrase in which T is the immediately preceding term	0	These nouns represent candidate classes of which T may be a member	0	0	0
J93-2005	P90-1034	1993	While full automatic extraction of semantic collocations is not yet feasible, some recent research in related areas is promising	0	<TREF>Hindle 1990</TREF> reports interesting results of this kind based on literal collocations, where he parses the corpus <REF>Hindle 1983</REF> into predicate-argument structures and applies a mutual information measure <REF>Fano 1961</REF>; <REF>Magerman and Marcus 1990</REF> to weigh the association between the predicate and each of its arguments	1	For example, as a list of the most frequent objects for the verb drink in his corpus, Hindle found beer, tea, Pepsi, and champagne	0	Based on the distributional hypothesis that the degree of shared contexts is a similarity measure for words, he develops a similarity metric for nouns based on their substitutability in certain verb contexts	0	6	1
E99-1013	P90-1034	1999	<REF>Although Stairmand 1997</REF> and <REF>Richardson 1995</REF> proposed the use of WordNet in information retrieval, they did not use WordNet in the query expansion framework	0	Our syntactic-relation-based thesaurus is based on the method proposed by <TREF>Hindle 1990</TREF>, although Hindle did not apply it to information retrieval	1	Hindle only extracted subject-verb and object-verb relations, while we also extract adjective-noun and noun-noun relations, in the manner of <REF>Grefenstette 1994</REF>, who applied his 99 Proceedings of EACL 99 Table 3: Average non-interpolated precision for expansion using single or combined thesauri	0	Topic Type Base Title 01175 Description 01428 All 01976 Expanded with WordNet Roget Syntac Cooccur Combined only only only only method 01276 01236 01386 01457 02314 86 52  179 240 969 01509 0,1477 01648 01693 02645 57 34 154 185 852 02010 01999 02131 02191 02724 17 12 78 108 378 syntactically-based thesaurus to information retrieval with mixed results	0	5	1
E99-1013	P90-1034	1999	232 Syntactically-based Thesaurus In contrast to the previous section, this method attempts to gather term relations on the basis of linguistic relations and not document cooccurrence statistics	0	Words appearing in similax grammatical contexts are assumed to be similar, and therefore classified into the same class <REF>Lin, 1998</REF>; <REF>Grefenstette, 1994</REF>; <REF>Grefenstette, 1992</REF>; <REF>Ruge, 1992</REF>; <TREF>Hindle, 1990</TREF>	1	First, all the documents are parsed using the Apple Pie Parser	0	The Apple Pie Parser is a natural language syntactic analyzer developed by Satoshi Sekine at New York University <REF>Sekine and Grishman, 1995</REF>	0	6	1
P93-1024	P90-1034	1993	The problemis that for large enough corpora the number of possible joint events is much larger than the number of event occurrences in the corpus, so many events are seen rarely or never, making their frequency counts unreliable estimates of their probabilities	0	<TREF>Hindle 1990</TREF> proposed dealing with the sparseness problem by estimating the likelihood of unseen events from that of similar events that have been seen	1	For instance, one may estimate the likelihood of a particular direct object for a verb from the likelihoods of that direct object for similar verbs	0	This requires a reasonable definition of verb similarity and a similarity estimation method	0	6	1
P06-1015	P90-1034	2006	With seemingly endless amounts of textual data at our disposal, we have a tremendous opportunity to automatically grow semantic term banks and ontological resources	0	To date, researchers have harvested, with varying success, several resources, including concept lists <REF>Lin and Pantel 2002</REF>, topic signatures <REF>Lin and Hovy 2000</REF>, facts <REF>Etzioni et al 2005</REF>, and word similarity lists <TREF>Hindle 1990</TREF>	1	Many recent efforts have also focused on extracting semantic relations between entities, such as entailments <REF>Szpektor et al 2004</REF>, is-a <REF>Ravichandran and Hovy 2002</REF>, part-of <REF>Girju et al 2006</REF>, and other relations	0	The following desiderata outline the properties of an ideal relation harvesting algorithm:  Performance: it must generate both high precision and high recall relation instances;  Minimal supervision: it must require little or no human annotation;  Breadth: it must be applicable to varying corpus sizes and domains; and  Generality: it must be applicable to a wide variety of relations ie , not just is-a or part-of	0	6	1
J04-3002	P90-1034	2004	We are not aware of other work that uses such collocations as we do	0	Features identified using distributional similarity have previously been used for syntactic and semantic disambiguation <TREF>Hindle 1990</TREF>; <REF>Dagan, Pereira, and Lee 1994</REF> and to develop lexical resources from corpora <REF>Lin 1998</REF>; <REF>Riloff and Jones 1999</REF>	1	We are not aware of other work identifying and using density parameters as described in this article	0	Since our experiments, other related work in NLP has been performed	0	6	1
C04-1036	P90-1034	2004	Typical feature weighting functions include the logarithm of the frequency of word-feature cooccurrence <REF>Ruge, 1992</REF>, and the conditional probability of the feature given the word within probabilistic-based measures <REF>Pereira et al , 1993</REF>, <REF>Lee, 1997</REF>, <REF>Dagan et al , 1999</REF>	0	Probably the most widely used association weight function is point-wise Mutual Information MI <REF>Church et al , 1990</REF>, <TREF>Hindle, 1990</TREF>, <REF>Lin, 1998</REF>, <REF>Dagan, 2000</REF>, defined by:  ,log, 2 fPwP fwPfwMI  A known weakness of MI is its tendency to assign high weights for rare features	1	Yet, similarity measures that utilize MI showed good performance	0	In particular, a common practice is to filter out features by minimal frequency and weight thresholds	0	1	3
C04-1036	P90-1034	2004	Finally, a novel feature weighting and selection function is presented, which yields superior feature vectors and better word similarity performance	0	Distributional Similarity has been an active research area for more than a decade <TREF>Hindle, 1990</TREF>, <REF>Ruge, 1992</REF>, <REF>Grefenstette, 1994</REF>, <REF>Lee, 1997</REF>, <REF>Lin, 1998</REF>, <REF>Dagan et al , 1999</REF>, <REF>Weeds and Weir, 2003</REF>	1	Inspired by Harris distributional hypothesis <REF>Harris, 1968</REF>, similarity measures compare a pair of weighted feature vectors that characterize two words	0	Features typically correspond to other words that co-occur with the characterized word in the same context	0	6	1
P07-1028	P90-1034	2007	Let Seenrp be the set of seen headwords for an argument rp of a predicate p Then we model the selectional preference S of rp for a possible headword w0 as a weighted sum of the similarities between w0 and the seen headwords: Srpw0  summationdisplay wSeenrp simw0,wwtrpw simw0,w is the similarity between the seen and the potential headword, and wtrpw is the weight of seen headword w Similarity simw0,w will be computed on the generalization corpus, again on the basis of extracted tuples p,rp,w	0	We will be using the similarity metrics shown in Table 1: Cosine, the Dice and Jaccard coefficients, and <TREF>Hindles 1990</TREF> and <REF>Lins 1998</REF> mutual information-based metrics	1	We write f for frequency, I for mutual information, and Rw for the set of arguments rp for which w occurs as a headword	0	In this paper we only study corpus-based metrics	0	3	1
W97-0205	P90-1034	1997	Computing MI scores is by now a standard procedure for measuring the co-occurrence between objects relative to their overall occurrence	0	MI is defined in general as follows: y I ix y  log2 Px Py We can use this definition to derive an estimate of the connectedness between words, in terms of collocations <REF>Smadja, 1993</REF>, but also in terms of phrases and grammatical relations <TREF>Hindle, 1990</TREF>	1	For instance the co-occurrence of verbs and the heads of their NP objects iN: size of the corpus, ie the number of stems: N Cobj v n  log2 /v /n N N All nouns are now classified by running a similaxity measure over their MI scores and the MI scores of each CoRELEx class	0	For this we use the Jaccard measure that compares objects relative to the attributes they share <REF>Grefenstette, 1994</REF>	0	6	1
C98-2122	P90-1034	1998	Evaluation of automatically generated lexical resources is a difficult problem	0	In <TREF>Hindle, 1990</TREF>, a small set of sample results are presented	1	In <REF>Smadja, 1993</REF>, automatically extracted collocations are judged by a lexicographer	0	In <REF>Dagan et al, 1993</REF> and <REF>Pereira et al, 1993</REF>, clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time	0	6	1
C98-2122	P90-1034	1998	We also constructed several other thesauri using the same corpus, but with the similarity measures in Figure 1	0	The measure simHindle is the same as the similarity measure proposed in <REF>Hindie, 1990</REF>, except that it does not use dependency triples with negative mutual information	1	The measure simHindle r is the same as simHindle except that all types of dependency relationships are used, instead of just subject and object relationships	0	The measures simcosine, simdice and simJacard are versions of similarity measures commonly used in information retrieval Frakes and Baeza-<REF>Yates, 1992</REF>	0	3	1
C98-2122	P90-1034	1998	and Conclusion There have been many approaches to automatic detection of similar words from text corpora	0	Ours is 772 similar to <REF>Grefenstette, 1994</REF>; <TREF>Hindle, 1990</TREF>; <REF>Ruge, 1992</REF> in the use of dependency relationship as the word features, based on which word similarities are computed	1	Evaluation of automatically generated lexical resources is a difficult problem	0	In <TREF>Hindle, 1990</TREF>, a small set of sample results are presented	0	2	1
C96-2205	P90-1034	1996	The similarity is usually calculated from a thesaurus	0	Since a handmade thesaurus is not slfitahle for machine use, and expensive to compile, automatical construction ofa thesaurus has been attempted using corpora <TREF>Hindle, 1990</TREF>	0	llowever, the thesaurus constructed by such ways does not contain so many nouns, and these nouns are specified by the used corpus	1	In other words, we cannot construct the general thesaurus from only a corpus	0	1	3
C96-2205	P90-1034	1996	In all, we obtained 2,708,135 bits of generalized cooccurrence data, which consisted of 115,330 types	0	23 Measuring the similarity between classes step 3 In step 3, we measure the similarity between two primitive classes by using the method given by Hindle <TREF>Hindle, 1990</TREF>	1	First, we define the nmtual information MI of a verb v and a primitive class C as follows	0	ZmY2 M ,Clogs N eq1 N N In the above equation, N is the total number of cooccurrence data bits, and fv and fC are the frequency of v and C in the whole cooccurrence data set respectively, and fv, C is the frequency of the cooccurrence data C, wo, v	0	3	1
P05-1077	P90-1034	2005	In the next section, we proceed to apply this technique for generating noun similarity lists	0	4 Building Noun Similarity Lists A lot of work has been done in the NLP community on clustering words according to their meaning in text <TREF>Hindle, 1990</TREF>; <REF>Lin, 1998</REF>	1	The basic intuition is that words that are similar to each other tend to occur in similar contexts, thus linking the semantics of words with their lexical usage in text	0	One may ask why is clustering of words necessary in the first place	0	6	1
P92-1028	P90-1034	1992	The UMass/MUC-3 parser would clearly need additional mechanisms to handle the ensuing part of speech and 7Other parsing errors occurred throughout the training set, but only those instances where the antecedent was not recognized as a constituent and the wh-word had an anteceden0 were discarded	0	8Interestingly, in work on the automated classification of nouns, <TREF>Hindle, 1990</TREF> also noted problems with empty words that depend on their complements for meaning	1	221 word sense disambiguation problems	0	However, recent research in these areas indicates that automated approaches for these tasks may be feasible see, for example, Brown, Della Pietra, <REF>Della Pietra,  Mercer, 1991</REF> and l-<REF>Iindle, 1983</REF>	0	6	1
P92-1028	P90-1034	1992	The corpus is relatively small it contains approximately 450,000 words and 18,750 sentences	0	In comparison, most corpus-based algorithms employ substantially larger corpora eg , 1 million words de <REF>Marcken, 1990</REF>, 25 million words <REF>Brent, 1991</REF>, 6 million words <TREF>Hindle, 1990</TREF>, 13 million words <REF>Hindle,  Rooth, 1991</REF>	1	Relative pronoun processing is especially important for the MUC-3 corpus because approximately 25 of the sentences contain at least one relative pronoun	0	3 In fact, the relative pronoun who occurs in approximately 1 out of every 10 sentences	0	6	1
C04-1165	P90-1034	2004	In previous research, word meanings have been statistically modeled based on syntactic information derived from a corpus	0	<TREF>Hindle 1990</TREF> used noun-verb syntactic relations, and <REF>Hatzivassiloglou and McKeown 1993</REF> used coordinated adjective-adjective modifier pairs	0	These methods are useful for the organization of words deep within a hierarchy, but do not seem to provide a solution for the top levels of the hierarchy	1	To find an objective hierarchical word structure, we utilize the complementary similarity measure CSM, which estimates a one-to-many relation, such as superordinatesubordinate relations <REF>Hagita and Sawaki 1995</REF>, <REF>Yamamoto and Umemura 2002</REF>	0	1	3
P94-1032	P90-1034	1994	Do we really need to fully parse the texts in every application	0	Some researchers apply shallow or partial parsers <REF>Smadja, 1991</REF>; <TREF>Hindle, 1990</TREF> to acquiring specific patterns from texts	1	These tell us that it is not necessary to completely parse the texts for some applications	0	This paper will propose a probabilistic partial parser and incorporate linguistic knowledge to extract noun phrases	0	5	1
P98-2127	P90-1034	1998	We also constructed several other thesauri using the same corpus, but with the similarity measures in Figure 1	0	The measure simHinate is the same as the similarity measure proposed in <TREF>Hindle, 1990</TREF>, except that it does not use dependency triples with negative mutual information	1	The measure simHindle,, is the same as simHindle except that all types of dependency relationships are used, instead of just subject and object relationships	0	The measures simcosine, simdice and simdacard are versions of similarity measures commonly used in information retrieval Frakes and Baeza-<REF>Yates, 1992</REF>	0	3	1
P98-2127	P90-1034	1998	and Conclusion There have been many approaches to automatic detection of similar words from text corpora	0	Ours is 772 similar to <REF>Grefenstette, 1994</REF>; <TREF>Hindle, 1990</TREF>; <REF>Ruge, 1992</REF> in the use of dependency relationship as the word features, based on which word similarities are computed	1	Evaluation of automatically generated lexical resources is a difficult problem	0	In <TREF>Hindle, 1990</TREF>, a small set of sample results are presented	0	2	1
P98-2127	P90-1034	1998	Evaluation of automatically generated lexical resources is a difficult problem	0	In <TREF>Hindle, 1990</TREF>, a small set of sample results are presented	1	In <REF>Smadja, 1993</REF>, automatically extracted collocations are judged by a lexicographer	0	In <REF>Dagan et al , 1993</REF> and Pereira et al ,  993, clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time	0	6	1
A92-1013	P90-1034	1992	2 Acquiring syntactic associations Clustered association data are collected by first extracting from the corpus all the syntactically related word pairs	0	Combining statistical and parsing methods has been done by <TREF>Hindle, 1990</TREF>; Hindle and Rooths,1991 and <REF>Smadja and McKewon, 1990</REF>; Smadja,1991	0	The novel aspect of our study is that we collect not only operational pairs, but triples, such as Nprep N, VprepN etc In fact, the preposition convey important information on the nature of the semantic link between syntactically related content words	1	By looking at the preposition, it is possible to restrict the set of semantic relations underlying a syntactic relation eg forpurpose,beneficiary	0	5	1
A92-1013	P90-1034	1992	The results of these studies have important applications in lexicography, to detect lexicosyntactic regularities <REF>Church and Hanks, 1990</REF>1 Calzolari and Bindi,1990, such as, for example support verbs eg make-decision prepositional verbs eg rely-upon idioms, semantic relations eg partof and fixed expressions eg kick the bucket	0	In Hindle,1990; <REF>Zernik, 1989</REF>; Webster el <REF>Marcus, 1989</REF> cooccurrence analyses augmented with syntactic parsing is used for the purpose of word classification	1	All these studies are based on th strong assumption that syntactic similarity in wor patterns implies semantic similarity	0	In Guthrie el al , 1991, sets of consistently contiguous word, neighbourhood are extracted from machinereadable dictionaries, to help semantic disambiguation in information retrieval	0	6	1
A92-1013	P90-1034	1992	In <REF>Smadja, 1989</REF>, <REF>Zernik and Jacobs, 1990</REF>, the associations are filtered by selecting the word pairs x,y whose frequency of occurrence is above fks, where f is the average appearance, s is the standard deviation, and k is an empirically determined factor	0	<TREF>Hindle, 1990</TREF>; Hindle and Rooths,1991 and <REF>Smadja, 1991</REF> use syntactic markers to increase the significance of the data	1	<REF>Guthrie et al , 1991</REF> uses the subject classification given in machine-readable dictionaries eg economics, engineering, etc	0	to reinforce cooccurence links	0	6	1
A94-1011	P90-1034	1994	More sophisticated linguistic information comes in several forms, all of which may need to be represented if performance in an automatic categorisation experiment is to be improved	0	Typical examples of linguistically sophisticated annotation include tagging words with their syntactic category although this has not been found to be effective for 1R, lemma of the word eg corpus for corpora, phrasal information eg identifying noun groups and phrases <REF>Lewis 1992c</REF>, <REF>Church 1988</REF>, and subject-predicate identification eg <TREF>Hindle 1990</TREF>	1	For the RAPRA corpus, we currently identify noun groups and adjective groups	0	This is achieved in a manner similar to Churchs 1988 PARTS algorithm used by Lewis 1992bc, in the sense that its main properties are robustness and corpus sensitivity	0	6	1
W93-0107	P90-1034	1993	In NLP, representing verb semantics with their thematic roles is a consolidated practice, even though theoretical researches <REF>Pustejovski 1991</REF> propose more rich and formal representation frameworks	0	More recent papers <TREF>Hindle 1990</TREF>, <REF>Pereira and Tishby 1992</REF> proposed to cluster nouns on the basis of a metric derived from the distribution of subject, verb and object in the texts	0	Both papers use as a source of information large corpora, but differ in the type of statistical approach used to determine word similarity	0	These studies, though valuable, leave several open problems: 70 1 A metric of conceptual closeness based on mere syntactic similarity is questionable, particularly if applied to verbs	1	1	3
P06-1116	P90-1034	2006	1993 and <REF>Lee 1999</REF>, among others	0	We use the cosine similarity measure for windowbased contexts and the following commonly used similarity measures for the syntactic vector space: <TREF>Hindles 1990</TREF> measure, the weighted Lin measure <REF>Wu and Zhou, 2003</REF>, the -Skew divergence measure <REF>Lee, 1999</REF>, the Jensen-Shannon JS divergence measure <REF>Lin, 1991</REF>, Jaccards coef cient van <REF>Rijsbergen, 1979</REF> and the Confusion probability <REF>Essen and Steinbiss, 1992</REF>	1	The Jensen-Shannon measure JS x1, x2  summationtext yY summationtext xx1,x2 parenleftbigg P yx log parenleftbigg Pyx 1 2 Pyx1Pyx2 parenrightbiggparenrightbigg subsequently performed best for our task	0	We compare the different ranking methodologies and data sets with respect to a manually-de ned gold standard list of 20 goal-type verbs and 20 nouns	0	3	1
J93-2002	P90-1034	1993	First, this approach leverages a little a priori grammatical knowledge using statistical inference	0	Most work on corpora of naturally occurring language 244 Michael R Brent From Grammar to Lexicon either uses no a priori grammatical knowledge <REF>Brill and Marcus 1992</REF>; <REF>Ellison 1991</REF>; <REF>Finch and Chater 1992</REF>; <REF>Pereira and Schabes 1992</REF>, or else it relies on a large and complex grammar <REF>Hindle 1990, 1991</REF>	1	One exception is <REF>Magerman and Marcus 1991</REF>, in which a small grammar is used to aid learning	0	1 A second difference is that the work reported here uses inferential rather than descriptive statistics	0	6	1
J93-2002	P90-1034	1993	In other words, it uses statistical methods to infer facts about the language as it exists in the minds of those who produced the corpus	0	Many other projects have used statistics in a way that summarizes facts about the text but does not draw any explicit conclusions from them <REF>Finch and Chater 1992</REF>; <TREF>Hindle 1990</TREF>	1	On the other hand, <REF>Hindle 1991</REF> does use inferential statistics, and <REF>Brill 1992</REF> recognizes the value of inference, although he does not use inferential statistics per se	0	Finally, many other projects in machine learning of natural language use input that is annotated in some way, either with part-of-speech tags <REF>Brill 1992</REF>; <REF>Brill and Marcus 1992</REF>; <REF>Magerman and Marcus 1990</REF> or with syntactic brackets <REF>Pereira and Schabes 1992</REF>	0	6	1
P91-1017	P90-1034	1991	This is the basis for Sadlers <REF>Analogical Semantics 1989</REF> which has not yet proved effective	0	His results may be improved if more sophisticated techniques and larger corpora are used to establish similarity between words such as in <TREF>Hindle, 1990</TREF>	1	Conflicting data	0	In very few cases two alternatives were supported equally by the statistical data, thus preventing a selection	0	6	1
P91-1017	P90-1034	1991	Consequently, a possible though partial alternative to using manually constructed knowledge can be found in the use of statistical data on the occurrence of lexical relations in large corpora	0	The use of such relations mainly relations between verbs or nouns and their arguments and modifiers for various purposes has received growing attention in recent research <REF>Church and Hanks, 1990</REF>; <REF>Zernik and Jacobs, 1990</REF>; <TREF>Hindle, 1990</TREF>	1	More specifically, two recent works have suggested to use statistical data on lexical relations for resolving ambiguity cases of PP-attachment <REF>Hindle and Rooth, 1990</REF> and pronoun references <REF>Dagan and Itai, 1990a</REF>; <REF>Dagan and Itai, 1990b</REF>	0	Clearly, statistical methods can be useful also for target word selection	0	6	1
P91-1017	P90-1034	1991	The use of such relations mainly relations between verbs or nouns and their arguments and modifiers for various purposes has received growing attention in recent research <REF>Church and Hanks, 1990</REF>; <REF>Zernik and Jacobs, 1990</REF>; <TREF>Hindle, 1990</TREF>	0	More specifically, two recent works have suggested to use statistical data on lexical relations for resolving ambiguity cases of PP-attachment <REF>Hindle and Rooth, 1990</REF> and pronoun references <REF>Dagan and Itai, 1990a</REF>; <REF>Dagan and Itai, 1990b</REF>	1	Clearly, statistical methods can be useful also for target word selection	0	Consider, for example, the Hebrew sentence extracted from the foreign news section of the daily <REF>Haaretz, September 1990</REF> transcripted to Latin letters	0	6	1
I08-1060	P90-1034	2008	Many studies extract synonyms from large monolingual corpora by using context information around targetterms<REF>CroachandYang, 1992</REF>; <REF>ParkandChoi, 1996</REF>; <REF>Waterman, 1996</REF>; <REF>Curran, 2004</REF>	0	Some researchers <TREF>Hindle, 1990</TREF>; <REF>Grefenstette, 1994</REF>; <REF>Lin, 1998</REF> classify terms by similarities based on their distributional syntactic patterns	1	These methods often extract not only synonyms, but also semantically related terms, such as antonyms, hyponyms and coordinate terms such as cat and dog Some studies make use of bilingual corpora or dictionaries to nd synonyms in a target language <REF>Barzilay and McKeown, 2001</REF>; <REF>Shimohata and Sumita, 2002</REF>; <REF>Wu and Zhou, 2003</REF>; <REF>Lin et al, 2003</REF>	0	Lin et al	0	6	1
C92-2082	P90-1034	1992	Semantic Relatedness Information	0	There bas recently been work in the detection of semantically related nouns via, for example, shared argument structures <TREF>Hindle 1990</TREF>, and shared dictionary definition context Wilks e al 1990	0	These approaches attempt to infer relationships among exical terms by looking at very large text samples and determining which ones are related in a statistically significant way	0	The technique introduced in this paper can be seen as having a similar goal but an entirely different approach, since only one sample need be found in order to determine a salient relationship and that sample may be infrequently occurring or nonexistent	1	2	1
W03-1610	P90-1034	2003	However, many studies investigate synonym extraction from only one resource	0	The most frequently used resource for synonym extraction is large monolingual corpora <TREF>Hindle, 1990</TREF>; <REF>Crouch and Yang, 1992</REF>; <REF>Grefenstatte, 1994</REF>; <REF>Park and Choi, 1997</REF>; <REF>Gasperin et al , 2001</REF> and <REF>Lin, 1998</REF>	0	The methods used the contexts around the investigated words to discover synonyms	0	The problem of the methods is that the precision of the extracted synonymous words is low because it extracts many word pairs such as cat and dog, which are similar but not synonymous	1	1	3
N07-1016	P90-1034	2007	It has two sources of evidence: the similarity of the strings themselves ie , edit distance and the similarity of the assertions they appear in	0	This second source of evidence is sometimes referred to as distributional similarity <TREF>Hindle, 1990</TREF>	1	Section 32 presents a simple model for predicting whether a pair of strings co-refer based on string similarity	0	Section 33 then presents a model called the Extracted Shared Property ESP Model for predicting whether a pair of strings co-refer based on their distributional similarity	0	6	1
P99-1004	P90-1034	1999	3 It is worth noting at this point that there are several well-known measures from the NLP literature that we have omitted from our experiments	0	Arguably the most widely used is the mutual information <TREF>Hindle, 1990</TREF>; <REF>Church and Hanks, 1990</REF>; <REF>Dagan et al , 1995</REF>; <REF>Luk, 1995</REF>; D <REF>Lin, 1998a</REF>	1	It does not apply in the present setting because it does not measure the similarity between two arbitrary probability distributions in our case, PVIn  and PVIm, but rather the similarity between a joint distribution PX1,X2 and the corresponding product distribution PX1PX2	0	Hamming-type metrics <REF>Cardie, 1993</REF>; <REF>Zavrel and Daelemans, 1997</REF> are intended for data with symbolic features, since they count feature label mismatches, whereas we are dealing feature Values that are probabilities	0	6	1
W97-0803	P90-1034	1997	Furthermore, this effort is repeated when a system is ported to another domain	0	This criticism leads us to automatic approaches for building thesauri from large corpora <REF>Hirschman et al , 1975</REF>; <TREF>Hindle, 1990</TREF>; <REF>Hatzivassiloglou and McKeown, 1993</REF>; <REF>Pereira et al , 1993</REF>; Tokunaga et aL, 1995; <REF>Ushioda, 1996</REF>	0	Past attempts have basically taken the following steps <REF>Charniak, 1993</REF>	0	1 extract word co-occurrences 2 define similarities distances between words on the basis of co-occurrences 3 cluster words on the basis of similarities The most crucial part of this approach is gathering word co-occurrence data	0	6	1
N03-4011	P90-1034	2003	The Distributional Hypothesis <REF>Harris 1985</REF> states that words that occur in the same contexts tend to be similar	0	There have been many approaches to compute the similarity between words based on their distribution in a corpus <TREF>Hindle 1990</TREF>; <REF>Landauer and Dumais 1997</REF>; <REF>Lin 1998</REF>	1	The output of these programs is a ranked list of similar words to each word	0	For example, Lins approach outputs the following similar words for wine and suit: wine: beer, white wine, red wine, Chardonnay, champagne, fruit, food, coffee, juice, Cabernet, cognac, vinegar, Pinot noir, milk, vodka, suit: lawsuit, jacket, shirt, pant, dress, case, sweater, coat, trouser, claim, business suit, blouse, skirt, litigation,  The similar words of wine represent the meaning of wine	0	6	1
W93-0113	P90-1034	1993	A proper filter must be able to access information in the text using any word of a set of similar words	0	A number of knowledge-rich <REF>Jacobs and Rau, 1990</REF>, <REF>Calzolari and Bindi, 1990</REF>, <REF>Mauldin, 1991</REF> and knowledge-poor <REF>Brown et al , 1992</REF>, <TREF>Hindle, 1990</TREF>, <REF>Ruge, 1991</REF>, <REF>Grefenstette, 1992</REF> methods have been proposed for recognizing when words are similar	1	The knowledge-rich approaches require either a conceptual dependency representation, or semantic tagging of the words, while the knowledge-poor approaches require no previously encoded semantic information, and depend on frequency of co-occurrence of word contexts to determine similarity	0	Evaluations of results produced by the above systems are often been limited to visual verification by a human subject or left to the human reader	0	6	1
W04-1216	P90-1034	2004	3 Distributional Word Similarity Words that tend to appear in the same contexts tend to have similar meanings <REF>Harris 1968</REF>	0	For example, the words corruption and abuse are similar because both of them can be subjects of verbs like arouse, become, betray, cause, continue, cost, exist, force, go on, grow, have, increase, lead to, and persist, etc, and both of them can modify nouns like accusation, act, allegation, appearance, and case, etc Many methods have been proposed to compute distributional similarity between words, eg, <TREF>Hindle, 1990</TREF>, <REF>Pereira et al 1993</REF>, <REF>Grefenstette 1994</REF> and <REF>Lin 1998</REF>	1	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared	0	84 31 Proximity-based Similarity It is natural to use dependency relationship Meluk, 1987 as features, but a parser has to be available	0	6	1
J05-4002	P90-1034	2005	The underlying idea is based largely on the central claim of the distributional hypothesis <REF>Harris 1968</REF>, that is: The meaning of entities, and the meaning of grammatical relations among them, is related to the restriction of combinations of these entities relative to other entities	0	This hypothesized relationship between distributional similarity and semantic similarity has given rise to a large body of work on automatic thesaurus generation <TREF>Hindle 1990</TREF>; <REF>Grefenstette 1994</REF>; <REF>Lin 1998a</REF>; <REF>Curran and Moens 2002</REF>; <REF>Kilgarriff 2003</REF>	0	There are inherent problems in evaluating automatic thesaurus extraction techniques, and much research assumes a gold standard that does not exist see Kilgarriff 2003 and Weeds 2003 for more discussion of this	0	A further problem for distributional similarity methods for automatic thesaurus generation is that they do not offer any obvious way to distinguish between linguistic relations such as synonymy, antonymy, and hyponymy see Caraballo 1999 and Lin et al 2003 for work on this	1	1	3
J05-4002	P90-1034	2005	As can be seen, similarity between neighbor sets is significantly higher at high recall settings low  within the model than at highprecision settings high , which suggests that dist  has high-recall CR characteristics	0	45 Hindles <REF>Measure Hindle 1990</REF> proposed an MI-based measure, which he used to show that nouns could be reliably clustered based on their verb co-occurrences	1	We consider the variant of 458 Weeds and Weir Co-occurrence Retrieval Figure 1 Variation with parameters  and  in development set mean similarity between neighbor sets of the additive t-test based CRM and of dist   Hindles Measure proposed by <REF>Lin 1998a</REF>, which overcomes the problem associated with calculating MI for word-feature combinations that do not occur: sim hind w 1, w 2   summationdisplay Tw 1 Tw 2  minIc, w 1 , Ic, w 2  38 where Tw 1  c : Ic, n > 0	0	This expression is the same as the numerator in the expressions for precision and recall in the difference-weighted MI-based CRM: P dw mi w 1, w 2   summationtext TP Iw 1, c  minIw 1, c,Iw 2, c Iw 1, c summationtext Fw 1  Iw 1, c  summationtext TP minIw 1, c, Iw 2, c summationtext Fw 1  Iw 1, c 39 R dw mi w 1, w 2   summationtext TP Iw 2, c  minIw 2, c,Iw 1, c Iw 2, c summationtext Fw 2  Iw 2, c  summationtext TP minIw 2, c, Iw 1, c summationtext Fw 2  Iw 2, c 40 since TP  Tw 1   Tw 2 	0	6	1
J05-4002	P90-1034	2005	A statistical technique using a language model that assigns a zero probability to these previously unseen events will rule the correct parse or interpretation of the utterance impossible	0	Similarity-based smoothing <TREF>Hindle 1990</TREF>; <REF>Brown et al 1992</REF>; <REF>Dagan, Marcus, and Markovitch 1993</REF>; <REF>Pereira, Tishby, and Lee 1993</REF>; <REF>Dagan, Lee, and Pereira 1999</REF> provides an intuitively appealing approach to language modeling	1	In order to estimate the probability of an unseen co-occurrence of events, estimates based on seen occurrences of similar events can be combined	0	For example, in a speech recognition task, we might predict that cat is a more likely subject of growl than the word cap, even though neither co-occurrence has been seen before, based on the fact that cat is similar to words that do occur as the subject of growl eg , dog and tiger, whereas cap is not	0	6	1
J98-4002	P90-1034	1998	statistical factors, although statistical factors are calculated in terms of the predicate argument structure in which each noun appears	0	Predicate argument structures, which consist of complements case filler nouns and case markers and verbs, have also been used in the task of noun classification <TREF>Hindle 1990</TREF>	1	This can be expressed by Equation 3, where ff is the vector for the noun in question, and items ti represent the statistics for predicate argument structures including n ff  h, t2,, ti  3 In regard to ti, we used the notion of TF	0	IDF <REF>Salton and McGill 1983</REF>	0	6	1
N04-1041	P90-1034	2004	2 Previous Work There have been several approaches to automatically discovering lexico-semantic information from text <REF>Hearst 1992</REF>; <REF>Riloff and Shepherd 1997</REF>; <REF>Riloff and Jones 1999</REF>; <REF>Berland and Charniak 1999</REF>; <REF>Pantel and Lin 2002</REF>; <REF>Fleischman et al 2003</REF>; <REF>Girju et al 2003</REF>	0	One approach constructs automatic thesauri by computing the similarity between words based on their distribution in a corpus <TREF>Hindle 1990</TREF>; <REF>Lin 1998</REF>	1	The output of these programs is a ranked list of similar words to each word	0	For example, Lins approach outputs the following top-20 similar words of orange: D peach, grapefruit, yellow, lemon, pink, avocado, tangerine, banana, purple, Santa Ana, strawberry, tomato, red, pineapple, pear, Apricot, apple, green, citrus, mango A common problem of such lists is that they do not discriminate between the senses of polysemous words	0	6	1
C96-1006	P91-1022	1996	First, most of theln assume that the input corpora me aligned sentence by sentence, which reduces their applicability remarkably	0	Although a number of automatic sentence alignment methods have been proposed <TREF>Brown et al 1991</TREF> ; <REF>Gale  Church 1991</REF> b; <REF>Kay  Roscheisen 1993</REF>; <REF>Chen 1993</REF>, they are not very reliable for real noisy bilingual texts	1	Second, the statistical methods usually require a very large corpus as their input	0	However, it is not easy to obtain a very large corpus	0	1	3
P98-1117	P91-1022	1998	In fact, it could be argued that, ultimately, text alignment is no easier than the more general problem of natural language understanding	0	In addition, most research efforts were directed towards the easiest problem, that of sentence-to-sentence alignment <TREF>Brown et al , 1991</TREF>; <REF>Gale and Church, 1991</REF>; <REF>Debili, 1992</REF>; Kay and lscheisen, 1993; <REF>Simard et al , 1992</REF>; <REF>Simard and Plamondon, 1996</REF>	1	Alignment at the word and term level, which is extremely useful for applications such as lexieal resource extraction, is still a largely unexplored research area<REF>Melamed, 1997</REF>	0	In order to live up to the expectations of the 711 various application fields, alignment technology will therefore have to improve substantially	0	6	1
W96-0201	P91-1022	1996	Several automatic methods have been proposed for this task in recent years	0	However, most of these methods address only the sub-problem of alignment <REF>Catizone et al 1989</REF>, <TREF>Brown et al 1991</TREF>, <REF>Gale  Church 1991</REF>, <REF>Debili  Sammouda 1992</REF>, <REF>Simard et al 1992</REF>, Kay  R<REF>Sscheisen 1993</REF>, <REF>Wu 1994</REF>	1	Alignment algorithms assume the availability of text unit boundary information and their output has less expressive power than a general bitext map	0	The only published solution to the more difficult general bitext mapping problem <REF>Church 1993</REF> can err by several typeset pages	0	1	3
C08-1051	P99-1004	2008	et al, 1999; <REF>Torisawa, 2002</REF>	0	Others proposed distributional similarity measures between words <REF>Hindle, 1990</REF>; <REF>Lin, 1998</REF>; <TREF>Lee, 1999</TREF>; <REF>Weeds et al, 2004</REF>	1	Once such similarity is defined, it is trivial to perform clustering	0	On the other hand, some researchers utilized co-occurrence for word clustering	0	6	1
C08-1029	P99-1004	2008	Moreover, it may not work well for dealing with general predicate phrases because it is hard to enumerate all phrases to determine the weights of features w,fWe thus simply adopted the co-occurrence frequency of the phrase and the feature as in <REF>Fujita and Sato, 2008</REF>	0	Skew divergence The skew divergence, a variant of KL divergence, was proposed in <TREF>Lee, 1999</TREF> based on an insight: the substitutability of one word for another need not be symmetrical	1	The divergence is given by the following formula: d skew t,sD P s bardblP t 1 P s , where P s and P t are the probability distributions of features for the given original and substituted words s and t, respectively	0	0    1 is a parameter for approximating KL divergence DThe score can be recast into a similarity score via, for example, the following function <REF>Fujita and Sato, 2008</REF>: Par skew stexpd skew t,s	0	6	1
J02-3004	P99-1004	2002	We preferred taxonomic class-based methods over distributional clustering mainly because we wanted to compare directly methods that use distributional information inherent in the corpus without making external assumptions with regard to how concepts and their similarity are represented with methods that quantify similarity relationships based on information present in a hand-crafted taxonomy	0	Furthermore, as <REF>Lee and Pereiras 1999</REF> results indicate that distributional clustering 365 Lapata The Disambiguation of Nominalizations and distance-weighted averaging obtain similar levels of performance, we restricted ourselves to the latter	1	We evaluated the contribution of the different smoothing methods on the nominalization task by exploring how each method and their combination influences disambiguation performance	0	Sections 3133 review discounting, class-based smoothing, and distance-weighted averaging	0	2	1
J02-3004	P99-1004	2002	The problem arises when the probability of word combinations that do not occur in the training data needs to be estimated	0	The smoothing methods proposed in the literature overviews are provided by <REF>Dagan, Lee, and Pereira 1999</REF> and <TREF>Lee 1999</TREF> can be generally divided into three types: discounting <REF>Katz 1987</REF>, class-based smoothing <REF>Resnik 1993</REF>; <REF>Brown et al 1992</REF>; 364 Computational Linguistics Volume 28, Number 3 <REF>Pereira, Tishby, and Lee 1993</REF>, and distance-weighted averaging <REF>Grishman and Sterling 1994</REF>; <REF>Dagan, Lee, and Pereira 1999</REF>	1	Discounting methods decrease the probability of previously seen events so that the total probability of observed word co-occurrences is less than one, leaving some probability mass to be redistributed among unseen co-occurrences	0	Class-based smoothing and distance-weighted averaging both rely on an intuitively simple idea: interword dependencies are modeled by relying on the corpus evidence available for words that are similar to the words of interest	0	6	1
J02-3004	P99-1004	2002	Furthermore, some nominalizations are conventionalized eg , business administration, health organization and are therefore attested more frequently than their verb-subject or verb-object counterparts	0	We re-created the frequencies of unseen verb-argument pairs by experimenting with three types of smoothing techniques proposed in the literature: back-off smoothing <REF>Katz 1987</REF>, class-based smoothing <REF>Resnik 1993</REF>; <REF>Lauer 1995</REF>, and distanceweighted averaging <REF>Grishman and Sterling 1994</REF>; <REF>Dagan, Lee, and Pereira 1999</REF>	1	We present these three smoothing variants and their underlying assumptions in the following section	0	3	0	3	1
J02-3004	P99-1004	2002	A key feature of this type of smoothing is the function that measures distributional similarity from co-occurrence frequencies	0	Several measures of distributional similarity have been proposed in the literature <REF>Dagan, Lee, and Pereira 1999</REF>; <TREF>Lee 1999</TREF>	1	We used two measures, the Jensen-Shannon divergence and the confusion probability	0	The choice of these two measures was motivated by work described in <REF>Dagan, Lee, and Pereira 1999</REF>, in which the JensenShannon divergence outperforms related similarity measures such as the confusion probability or the L 1 norm on a pseudodisambiguation task that uses verb-object pairs	0	6	1
J02-3004	P99-1004	2002	<REF>Grishman and Sterling 1994</REF> in particular employ the confusion probability to re-create the frequencies of verb-noun co-occurrences in which the noun is the object or the subject of the verb in question	0	In the following we describe these two similarity measures and show how they can be used to re-create the frequencies for unseen verb-argument tuples for a more detailed description see <REF>Dagan, Lee, and Pereira 1999</REF>	1	331 Confusion Probability	0	The confusion probability P C is an estimate of the probability that a word w 1 can be substituted for a word w prime 1, in the sense of being found in the same contexts	0	6	1
J02-3004	P99-1004	2002	In class-based smoothing, classes are used as the basis according to which the co-occurrence probability of unseen word combinations is estimated	0	Classes can be induced directly from the corpus using distributional clustering <REF>Pereira, Tishby, and Lee 1993</REF>; <REF>Brown et al 1992</REF>; <REF>Lee and Pereira 1999</REF> or taken from a manually crafted taxonomy <REF>Resnik 1993</REF>	1	In the latter case the taxonomy is used to provide a mapping from words to conceptual classes	0	Distance-weighted averaging differs from distributional clustering in that it does not explicitly cluster words	0	3	2
J02-3004	P99-1004	2002	33 Distance-Weighted Averaging Distance-weighted averaging induces classes of similar words from word co-occurrences without making reference to a taxonomy	0	Instead, it is based on the assumption that if a word w prime 1 is similar to word w 1, then w prime 1 can provide information about the frequency of unseen word pairs involving w 1 <REF>Dagan, Lee, and Pereira 1999</REF>	0	A key feature of this type of smoothing is the function that measures distributional similarity from co-occurrence frequencies	0	Several measures of distributional similarity have been proposed in the literature <REF>Dagan, Lee, and Pereira 1999</REF>; <TREF>Lee 1999</TREF>	1	6	1
J02-3004	P99-1004	2002	In language modeling, smoothing techniques are typically evaluated by showing that a language model that uses smoothed estimates incurs a reduction in perplexity on test data over a model that does not employ smoothed estimates <REF>Katz 1987</REF>	0	<REF>Dagan, Lee, and Pereira 1999</REF> use perplexity to compare back-off smoothing against distance-weighted averaging methods within the context of language modeling for speech recognition and show that the latter outperform the former	1	They also compare different distance-weighted averaging methods on a pseudoword disambiguation task in which the language model decides which of two verbs v 1 and v 2 is more likely to take a noun n as its object	0	The method being tested must reconstruct which of the unseen v 1, n and v 2, n is a valid verb-object combination	0	6	1
J02-3004	P99-1004	2002	The method being tested must reconstruct which of the unseen v 1, n and v 2, n is a valid verb-object combination	0	The same task is used by <REF>Lee and Pereira 1999</REF> in a detailed comparison between distributional clustering and distance-weighted averaging that demonstrates that the two methods yield comparable results	1	In our experiments we re-created co-occurrence frequencies for unseen verb-subject and verb-object pairs using three maximally different approaches: back-off smoothing, class-based smoothing using a predefined taxonomy, and distance-weighted averaging	0	We preferred taxonomic class-based methods over distributional clustering mainly because we wanted to compare directly methods that use distributional information inherent in the corpus without making external assumptions with regard to how concepts and their similarity are represented with methods that quantify similarity relationships based on information present in a hand-crafted taxonomy	0	6	1
J02-3004	P99-1004	2002	We used two measures, the Jensen-Shannon divergence and the confusion probability	0	The choice of these two measures was motivated by work described in <REF>Dagan, Lee, and Pereira 1999</REF>, in which the JensenShannon divergence outperforms related similarity measures such as the confusion probability or the L 1 norm on a pseudodisambiguation task that uses verb-object pairs	1	The confusion probability has been used by several authors to smooth word co367 Lapata The Disambiguation of Nominalizations occurrence probabilities <REF>Essen and Steinbiss 1992</REF>; <REF>Grishman and Sterling 1994</REF> and shown to give promising performance	0	<REF>Grishman and Sterling 1994</REF> in particular employ the confusion probability to re-create the frequencies of verb-noun co-occurrences in which the noun is the object or the subject of the verb in question	0	5	2
W04-2411	P99-1004	2004	McCarthy determines the sense profile of a verb/slot pair using a minimum description length tree cut model over the frequency-populated hierarchy <REF>Li and Abe, 1998</REF>	0	The two profiles for a verb are aligned to permit comparison using skew divergence as a probability distance measure <TREF>Lee 1999</TREF>	1	This step is explained in more detail in the next section, with an example	0	The value of the distance measure is compared to a threshold, which determines classification of a verb as causative the two profiles are similar or non-causative the two profiles are dissimilar, leading to best performance of 73 accuracy, on a set of hand-selected verbs	0	6	1
W04-2411	P99-1004	2004	<REF>Briefly, Clark and Weir 2002</REF> populate the WordNet hierarchy based on corpus frequencies of all nouns for a verb/slot pair, and then determine the appropriate probability estimate at each node in the hierarchy by using a24 a102 to determine whether to generalize an estimate to a parent node in the hierarchy	0	We compare SPD to other measures applied directly to the unpropagated probability profiles given by the Clark-Weir method: the probability distribution distance given by skew divergence skew <TREF>Lee, 1999</TREF>, as well as the general vector distance given by cosine cos	1	These are the measures aside from SPD that performed best in our pilot experiments	1	It is worth noting that the method of <REF>Clark and Weir 2002</REF> does not yield a tree cut, but instead generally populates the WordNet hierarchy with non-zero probabilities	0	2	2
W04-2411	P99-1004	2004	A drawback of this approach for generalizing to other sense profile comparisons is the assumption in relative entropy of an asymmetry between the two probability distributions	0	<REF>Similarly, McCarthy 2000</REF> uses skew divergence a variant of KL divergence proposed by <TREF>Lee, 1999</TREF> to compare the sense profile of one argument of a verb eg , the subject position of the intransitive to another argument of the same verb eg , the object position of the transitive, to determine if the verb participates in an argument alternation involving the two positions	1	For example, the causative alternation in sentences 1 and 2 illustrates how the subject of the intransitive is the same underlying semantic argument ie , the Themethe argument undergoing the action as the object of the transitive: 1 The snow melted	0	2 The sun melted the snow	0	6	1
W06-0101	P99-1004	2006	Due to the original KL distance is asymmetric and is not defined when zero frequency occurs	0	Some enhanced KL models were developed to prevent these problems such as Jensen-Shannon <REF>Jianhua, 1991</REF>, which introducing a probabilistic variable m, or  -Skew Divergence <TREF>Lee, 1999</TREF>, by adopting adjustable variable 	1	Research shows that Skew Divergence achieves better performance than other measures	1	<REF>Lee, 2001</REF> 1yxS rgenceDSkewDive yxxKL aaa  2/,2/yx,JS Shannon-DJensen yxm myKLmxKL   To convert distance to similarity value, we adopt the formula inspired by <REF>Mochihashi, and Matsumoto 2002</REF>	0	4	2
A00-2034	P99-1004	2000	Figure 2 exemplifies this process for two TOMs TCM1 and TCM2 in an imaginary hierarchy	0	The UBC is at the classes B, c and D To quantify the similarity between the probability distributions for the target slots we use the a-skew divergence aSD proposed by <TREF>Lee 1999</TREF>	1	1 This measure, defined in equation 2, is a smoothed version of the Kulback-Liebler divergence, plx and p2x are the two probability distributions which are being compared	0	The  constant is a value between 0 and 1 We also experimented with euclidian distance, the L1 norm, and cosine measures	0	3	2
W07-2009	P99-1004	2007	synonyms from the hypernyms verbs and nouns or closely related classes adjectives of all synsets of the target, ranked with the BNC frequency data	0	We also produced best and oot baselines using the distributional similarity measures l1, jaccard, cosine, lin <REF>Lin, 1998</REF> and SD <TREF>Lee, 1999</TREF> 4	1	We took the word with the largest similarity or smallest distance for SD and l1 for best and the top 10 for oot	0	For mw detection and identification we used WordNet to detect if a multiword in WordNet which includes the target word occurs within a window of 2 words before and 2 words after the target word	0	3	1
D07-1042	P99-1004	2007	All counts are log-likelihood transformed	0	We experiment with two distance measures to compute vector similarity, namely the Jaccard Coefficient and Cosine Distance, both of which have been shown to yield good performance in NLP tasks <TREF>Lee, 1999</TREF>; <REF>McDonald and Lowe, 1998</REF>	1	Evaluation Procedure	0	We evaluate our models by correlating the predicted plausibility values with the human judgements, which range between 1 and 7	0	6	1
C02-1090	P99-1004	2002	The distributional similarity was measured by means of three different similarity measures: the Jaccards coefficient, L1 distance, and the skew divergence	0	This choice of similarity measures was motivated by results of studies by <REF>Levy et al 1998</REF> and <TREF>Lee 1999</TREF> which compared several well known measures on similar tasks and found these three to be superior to many others	1	Another reason for this choice is that there are different ideas underlying these measures: while the Jaccards coefficient is a binary measure, L1 and the skew divergence are probabilistic, the former being geometrically motivated and the latter being a version of the information theoretic Kullback Leibler divergence cf	0	, <TREF>Lee 1999</TREF>	0	5	2
W06-1105	P99-1004	2006	The same procedure is applied for symmetric KL divergence and JS divergence	0	The second approach is from <TREF>Lee 1999</TREF>	1	Here similarity for KL is defined as Simp,q  C KLpq, where C is a free parameter to be tuned	0	4 Experimental Setup 41 Materials Following Chen et al	0	6	1
W06-1105	P99-1004	2006	Comparing the different divergence measures for LDA, we found that KL and JS perform significantly better than symmetrised KL divergence	0	Interestingly, the performance of the asymmetric KL divergence and the symmetric JS divergence is very close, which makes it difficult to conclude whether the relation discovery domain is a symmetric domain or an asymmetric domain like <TREF>Lees 1999</TREF> task of improving probability estimates for unseen word co-occurrences	1	A shortcoming of all the models we will describe here is that they are derived from the basic bag-of-words models and as such do not account for word order or other notions of syntax	1	Related work on relation discovery by Zhang et al	0	1	3
W06-1105	P99-1004	2006	The optimal configuration varies by the divergence measure with D  50 and C  14 for KL divergence, D  200 and C  4 for symmetrised KL, and D  150 and C  2 for JS divergence	0	For all divergence measures, <TREF>Lees 1999</TREF> method outperformed Dagan et als 1997 method	1	Also for all divergence measures, the model hyper-parameter  was found to be optimal at 00001	0	The  hyper-parameter was always set to 50/T following <REF>Griffiths and Steyvers 2004</REF>	0	4	2
I08-1070	P99-1004	2008	wx,f stands for the weight frequency in our experiment of f in F x  While Par Lin is symmetric, it has been argued that itisimportant todetermine thedirection ofparaphrase	0	As an asymmetric measure, we examine skew divergence defined by the following equation <TREF>Lee, 1999</TREF>: d skew t,sD P s bardblP t 1 P s , where P x denotes a probability distribution estimated 6 from a feature set F x HowwellP t approximates P s is calculated based on the KL divergence, D The parameter  is set to 099, following tradition, because the optimization of  is difficult	1	To take consistent measurements, we define the paraphrasability score Par skew as follows: Par skew stexpd skew t,s	0	6 We estimate them simply using maximum likelihood estimation, ie, P x fwx,f/ P f prime F x wx,f prime 	0	6	1
W05-0604	P99-1004	2005	Note that if any a56 a8 a64a80a50, then a57 a11a81a1a59a55a60a52a61a56a4a5 is infinite; in general, the KLdivergence is very sensitive to small probabilities, and careful attention must be paid to smoothing if it is to be used with text co-occurrence data	0	The Jensen-Shannon divergencean average of the divergences of a55 and a56 from their mean distribution does not share this sensitivity and has previously been used in tests of lexical similarity <TREF>Lee, 1999</TREF>	1	Furthermore, unlike the KL-divergence, it is symmetric, presumably a desirable property in this setting, since synonymy is a symmetric relation, and our test design exploits this symmetry	0	However, a57 a11a83a82a45a17 a1a59a55a60a52a61a56a4a5, the Hellinger distance 3, is also symmetric and robust to small or zero estimates	0	6	1
W05-0604	P99-1004	2005	For a48 a49 a1a51a50a23a52a54a53a19a5 and word-conditional context distributions a55 and a56, we have the so-called a48 -divergences <REF>Zhu and Rohwer, 1998</REF>: a57 a58 a1a59a55a60a52a61a56a4a5a63a62a59a64 a53a65a14 a7 a55 a58 a56 a11a38a66 a58 a48a67a1a45a53a18a14a16a48a42a5 1 Divergences a57 a68 and a57 a11 are defined as limits as a48a6a69 a50 and a48a6a69a70a53 :a57 a11 a1a59a55a60a52a61a56a4a5a71a64 a57 a68 a1a51a56a67a52a51a55a72a5a71a64a74a73 a55a76a75a78a77a47a79 a55 a56 In other words, a57 a11a19a1a59a55a60a52a61a56a4a5 is the KL-divergence of a55 from a56  Members of this divergence family are in some sense preferred by theory to alternative measures	0	It can be shown that the a48 -divergences or divergences defined by combinations of them, such as the Jensen-Shannon or skew divergences <TREF>Lee, 1999</TREF> are the only ones that are robust to redundant contexts ie , only divergences in this family are invariant <REF>Csiszar, 1975</REF>	1	Several notions of lexical similarity have been based on the KL-divergence	0	Note that if any a56 a8 a64a80a50, then a57 a11a81a1a59a55a60a52a61a56a4a5 is infinite; in general, the KLdivergence is very sensitive to small probabilities, and careful attention must be paid to smoothing if it is to be used with text co-occurrence data	0	1	2
W05-0604	P99-1004	2005	By default, we bracket a token sequence with pseudo-tokens <bos> and <eos>2 Contextual tokens in the window may be either observed or disregarded, and the policy governing which to admit is one of the dimensions we explore here	0	The decision whether or not to observe a particular contextual token is made before counting commences, and is not sensitive to the circumstances of a particular occurrence eg , its participation in some syntactic relation <REF>Lin, 1997</REF>; <TREF>Lee, 1999</TREF>	1	When a contextual token is observed, it is always counted as a single occurrence	0	Thus, in contrast with earlier approaches <REF>Sahlgren, 2001</REF>; <REF>Ehlert, 2003</REF>, we do not use a weighting scheme that is a function of distance from the reference token	0	6	1
W05-0604	P99-1004	2005	We do not know whether or to what extent this particular parameter setting is universally best, best only for English, best for newswire English, or best only for the specific test we have devised	0	We have restricted our attention to a relatively small space of similarity measures, excluding many previously proposed measures of lexical affinity but see Weeds, et al 2004, and <TREF>Lee 1999</TREF> for some empirical comparisons	1	Lee observed that measures from the space of invariant divergences particularly the JS and skew divergences perform at least as well as any of a wide variety of alternatives	1	As noted, we experimented with the JS divergence and observed accuracies that tracked those of the Hellinger closely	0	3	2
H05-1053	P99-1004	2005	One could look at differences in the ranking over all words, using a meaTraining Testing FINANCE SPORTS Finance 355 Sports 409 SemCor 142 153 100 Table 4: WSD accuracy for words with a different first sense to the BNC	0	sure such as pairwise agreement of rankings or a ranking correlation coefficient, such as Spearmans One could also use the rankings to estimate probability distributions and compare the distributions with measures such as alpha-skew divergence <TREF>Lee, 1999</TREF>	1	A simple definition would be where the rankings assign different predominant senses to a word	0	Taking this simple definition of deviation, we demonstrate how this might be done for our corpora	0	2	1
W06-1406	P99-1004	2006	The distributional hypothesis <REF>Harris, 1968</REF> says the following: The meaning of entities, and the meaning of grammatical relations among them, is related to the restriction of combinations of these entities relative to other entities	0	Over recent years, many applications <REF>Lin, 1998</REF>, <TREF>Lee, 1999</TREF>, <REF>Lee, 2001</REF>, <REF>Weeds et al , 2004</REF>, and <REF>Weeds and Weir, 2006</REF> have been investigating the distributional similarity of words	1	Similarity means that words with similar meaning tend to appear in similar contexts	0	In NLG, the considerationofsemanticsimilarityisusuallypreferred to just distributional similarity	0	6	1
P06-2007	P99-1004	2006	The pairs are generally either related in one type of relationship, or completely unrelated	0	In general we may be able to identify related phrases for example with distributional similarity <TREF>Lee, 1999</TREF>, but would like to be able to automatically classify the related phrases by the type of the relationship	1	For this task we identify a larger set of candidate-related phrases	0	32 Query Log Data To find phrases that are similar or substitutable for web searchers, we turn to logs of user search sessions	0	6	1
P06-2007	P99-1004	2006	We draw a distinction between the task of identifying terms which are topically related and identifying the specific semantic class	0	For example, the terms dog, puppy, canine, schnauzer, cat and pet are highly related terms, which can be identified using techniques that include distributional similarity <TREF>Lee, 1999</TREF> and withindocument cooccurrence measures such as pointwise mutual information <REF>Turney et al , 2003</REF>	1	These techniques, however, do not allow us to distinguish the more specific relationships:  hypernymdog,puppy This work was carried out while these authors were at Yahoo	1	Research	0	1	3
W01-0502	P99-1004	2001	In all studies done so far, however, the first classifier  the confusion sets  were constructed manually by the researchers	0	Other word predictions tasks have also constructed manually the list of confusion sets <REF>Lee and Pereira, 1999</REF>; <REF>Dagan et al , 1999</REF>; <TREF>Lee, 1999</TREF> and justifications where given as to why this is a reasonable way to construct it	1	Even-<REF>Zohar and Roth, 2000</REF> present a similar task in which the confusion sets generation was automated	0	Their study also quantified experimentally the advantage in using early classifiers to restrict the size of the confusion set	0	6	1
D07-1061	P99-1004	2007	Therefore, the  term in skew divergence implicitly defines a parameter stating how many orders of magnitude smaller than pj to count qj if qj  0	0	We define the Zero-KL divergence with respect to 2<REF>In Lees 1999</REF> original presentation, skew divergence is defined not as sp,q but rather as sq,p	1	We reverse the argument order for consistency with the other measures discussed here	0	586 gamma: ZKLp,q  summationdisplay i pi braceleftbigg logpi qi qi negationslash 0  qi  0 Note that this is exactly KL-divergence when KLdivergence is defined and, like skew divergence, approximates KL divergence in the limit as   	0	3	1
D07-1061	P99-1004	2007	One is Jensen-Shannon divergence <REF>Lin, 1991</REF>, a symmetric measure based on KL-divergence defined as the average of the KL divergences of each distribution to their average distribution	0	Jensen-Shannon is well defined for all distributions becausetheaverageofpi andqi isnon-zerowhenevereither number is These measures and others are surveyed in <REF>Lee, 2001</REF>, who finds that Jensen-Shannon is outperformed by the Skew divergence measure introduced by Lee in 1999	1	The skew divergence2 accounts for zeros in q by mixing in a small amount of p sp,q  Dp bardbl q  1p  summationtexti pi log piqi1pi Lee found that as   1, the performance of skew divergence on natural language tasks improves	0	In particular, it outperforms most other models and even beats pure KL divergence modified to avoid zeros with sophisticated smoothing models	0	2	2
P99-1005	P99-1004	1999	22 Nearest-neighbors averaging As noted earlier, the nearest-neighbors averaging method is an alternative to clustering for estimating the probabilities of unseen cooccurfences	0	Given an unseen pair n, v, we calculate an estimate 15vln  as an appropriate average of pvln I where n I is distributionally similar to n Many distributional similarity measures can be considered <TREF>Lee, 1999</TREF>	1	In this paper, we focus on the one that gave the best results in our earlier work <REF>Dagan et al , 1999</REF>, the Jensen-Shannon divergence <REF>Rao, 1982</REF>; <REF>Lin, 1991</REF>	0	The Jensen-Shannon divergence of two discrete distributions p and q over the same domain is defined as 1 gSp, q   It is easy to see that JSp, q is always defined	0	6	1
J04-3002	P99-1004	2004	Opinion-piece data are used for training, and a different set of opinion-piece data and the subjective-element data are used for testing	0	With distributional similarity, words are judged to be more or less similar based on their distributional patterning in text <TREF>Lee 1999</TREF>; <REF>Lee and Pereira 1999</REF>	1	Our Table 5 Random sample of fixed-3-gram collocations in OP1	0	one-noun of-prep his-det worst-adj of-prep all-det quality-noun of-prep the-det to-prep do-verb so-adverb in-prep the-det company-noun you-pronoun and-conj your-pronoun have-verb taken-verb the-det rest-noun of-prep us-pronoun are-verb at-prep least-adj but-conj if-prep you-pronoun as-prep a-det weapon-noun continue-verb to-to do-verb purpose-noun of-prep the-det could-modal have-verb be-verb it-pronoun seem-verb to-prep to-pronoun continue-verb to-prep have-verb be-verb the-det do-verb something-noun about-prep cause-verb you-pronoun to-to evidence-noun to-to back-adverb that-prep you-pronoun are-verb i-pronoun be-verb not-adverb of-prep the-det century-noun of-prep money-noun be-prep 291 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language Table 6 Random sample of unique generalized collocations in OP1	0	3	2
J04-3002	P99-1004	2004	Thus, to decide whether to retain a word as a PSE, we consider the precision not of the individual word, but of the word together with a cluster of words similar to it	0	Many variants of distributional similarity have been used in NLP <TREF>Lee 1999</TREF>; <REF>Lee and Pereira 1999</REF>	1	<REF>Dekang Lins 1998</REF> method is used here	0	In contrast to many implementations, which focus exclusively on verb-noun relationships, Lins method incorporates a variety of syntactic relations	0	6	1
A00-2017	P99-1004	2000	To evaluate word prediction as a simple language model	0	We chose the verb prediction task which is similar to other word prediction tasks eg ,<REF>Golding and Roth, 1999</REF> and, in particular, follows the paradigm in <REF>Lee and Pereira, 1999</REF>; <REF>Dagan et al , 1999</REF>; <TREF>Lee, 1999</TREF>	1	There, a list of the confusion sets is constructed first, each consists of two different verbs	0	The verb vl is coupled with v2 provided that they occur equally likely in the corpus	0	5	1
A00-2017	P99-1004	2000	Results are shown in percentage of improvement in accuracy over the baseline	0	Table 2 compares our method to methods that use similarity measures <REF>Dagan et al , 1999</REF>; <TREF>Lee, 1999</TREF>	1	Since we could not use the same corpus as in those experiments, we compare the ratio of improvement and not the WER	0	The baseline in this studies is different, but other than that the experiments are identical	0	2	1
C04-1146	P99-1004	2004	The cosine measure <REF>Salton and McGill, 1983</REF> returns the cosine of the angle between two vectors	0	The Jensen-Shannon JS divergence measure <REF>Rao, 1983</REF> and the -skew divergence measure <TREF>Lee, 1999</TREF> are based on the Kullback-Leibler KL divergence measure	1	The KL divergence, or relative entropy, Dpjjq, between two probability distribution functions p and q is de ned <REF>Cover and Thomas, 1991</REF> as the ine ciency of assuming that the distribution is q when the true distribution is p: Dpjjq  Pcplog pq	0	However, Dpjjq  1 if there are any contexts c for which pc > 0 and qc  0	0	6	1
C04-1146	P99-1004	2004	However, due to the lack of a tight de nition for the concept of distributional similarity and the broad range of potential applications, a large number of measures of distributional similarity have been proposed or adopted see Section 2	0	Previous work on the evaluation of distributional similarity methods tends to either compare sets of distributionally similar words to a manually created semantic resource <REF>Lin, 1998</REF>; <REF>Curran and Moens, 2002</REF> or be oriented towards a particular task such as language modelling <REF>Dagan et al , 1999</REF>; <TREF>Lee, 1999</TREF>	1	The rst approach is not ideal since it assumes that the goal of distributional similarity methods is to predict semantic similarity and that the semantic resource used is a valid gold standard	0	Further, the second approach is clearly advantageous when one wishes to apply distributional similarity methods in a particular application area	1	1	2
C08-1082	P99-1004	2008	As the vector for each target word must sum to 1, the marginal distributions of target words have little effect on the resulting similarity estimates	0	Many 649 similarity measures and weighting functions have been proposed for distributional vectors; comparative studies include <TREF>Lee 1999</TREF>, <REF>Curran 2003</REF> and <REF>Weeds and Weir 2005</REF>	1	22 Kernel Methods for Computing Similarity and Distance In this section we describe two classes of functions, positive semi-definite and negative semidefinite kernels, and state some relationships between these classes	0	The mathematical treatment follows Berg et al	0	6	1
C08-1082	P99-1004	2008	It seems likely that distance measures that are known to work well for comparing co-occurrence distributions will also give us suitable psd similarity measures	0	Negative semi-definite kernels are bydefinitionsymmetric, whichrulestheKullbackLeibler divergence and <TREF>Lees 1999</TREF>-skew divergence out of consideration	1	The nsd condition 2 ismetifthedistancefunctionisasquaredmetricin a Hilbert space	0	In this paper we use a parametric familyofsquaredHilbertianmetricsonprobability distributions that has been discussed by <REF>Hein and Bousquet 2005</REF>	0	1	3
C08-1082	P99-1004	2008	23 Distributional Kernels Given the effectiveness of distributional similarity measures for numerous tasks in NLP and the interpretation of kernels as similarity functions, it seems natural to consider the use of kernels tailored for co-occurrence distributions when performing semantic classification	0	As shown in Section 22 the standardly used linear and Gaussian kernelsderivefromtheL2 distance, yet<TREF>Lee1999</TREF> has shown that this distance measure is relatively poor at comparing co-occurrence distributions	1	Information theory provides a number of alternative distance functions on probability measures, of which the L1 distance also called variational distance, Kullback-Leibler divergence and JensenShannon divergence are well-known in NLP and 1Negated nsd functions are sometimes called conditionally psd; they constitute a superset of the psd functions	0	650 Distance Definition Derived linear kernel L2 distance2 summationtextcPcw1Pcw22 summationtextc Pcw1Pcw2 L1 distance summationtextcPcw1Pcw2 summationtextc minPcw1,Pcw2 Jensen-Shannon summationtextc Pcw1log2 2Pcw1Pcw1Pcw2  summationtextc Pcw1log2 Pcw1Pcw1Pcw2  divergence Pcw2log2 2Pcw2Pcw1Pcw2 Pcw2log2 Pcw2Pcw1Pcw2 Hellinger distance summationtextcradicalbigPcw1radicalbigPcw22 summationtextcradicalbigPcw1Pcw2 Table 1: Squared metric distances on co-occurrence distributions and corresponding linear kernels were shown by Lee to give better similarity estimates than the L2 distance	0	1	2
P01-1046	P99-1004	2001	A key feature of this type of smoothing is the function which measures distributional similarity from cooccurrence frequencies	0	Several measures of distributional similarity have been proposed in the literature <REF>Dagan et al , 1999</REF>; <TREF>Lee, 1999</TREF>	1	We used two measures, the Jensen-Shannon divergence and the confusion probability	0	Those two measures have been previously shown to give promising performance for the task of estimating the frequencies of unseen verb-argument pairs <REF>Dagan et al , 1999</REF>; <REF>Grishman and Sterling, 1994</REF>; <REF>Lapata, 2000</REF>; <TREF>Lee, 1999</TREF>	1	2	2
P01-1046	P99-1004	2001	We used two measures, the Jensen-Shannon divergence and the confusion probability	0	Those two measures have been previously shown to give promising performance for the task of estimating the frequencies of unseen verb-argument pairs <REF>Dagan et al , 1999</REF>; <REF>Grishman and Sterling, 1994</REF>; <REF>Lapata, 2000</REF>; <TREF>Lee, 1999</TREF>	1	In the following we describe these two similarity measures and show how they can be used to recreate the frequencies for unseen adjective-noun pairs	0	Jensen-Shannon Divergence	0	2	2
W02-1030	P99-1004	2002	If a bigram is unseen in a given corpus, conventional approaches recreate its frequency using techniques such as back-off, linear interpolation, class-based smoothing or distance-weighted averaging see Dagan et al	1	1999 and <TREF>Lee 1999</TREF> for overviews	1	The approach proposed here does not recreate the missing counts, but instead retrieves them from a corpus that is much larger but also much more noisy than any existing corpus: it launches queries to a search engine in order to determine how often a bigram occurs on the web	0	We systematically investigated the validity of this approach by using it to obtain frequencies for predicate-argument bigrams adjective-noun, nounnoun, and verb-object bigrams	0	6	1
P03-1017	P99-1004	2003	The two measures are shown in Figure 2	0	The Skew divergence represents a generalisation of the Kullback-Leibler divergence and was proposed by <TREF>Lee 1999</TREF> as a linguistically motivated distance measure	1	We use a value of   :99	0	We explored in detail the influence of different types and sizes of context by varying the context specification and path value functions	0	6	2
P03-1017	P99-1004	2003	This makes semantic spaces more flexible, different types of contexts can be selected and words do not have to physically co-occur to be considered contextually relevant	0	However, existing models either concentrate on specific relations for constructing the semantic space such as objects eg , <TREF>Lee, 1999</TREF> or collapse all types of syntactic relations available for a given target word <REF>Grefenstette, 1994</REF>; <REF>Lin, 1998</REF>	1	Although syntactic information is now used to select a words appropriate contexts, this information is not explicitly captured in the contexts themselves which are still represented by words and is therefore not amenable to further processing	0	A commonly raised criticism for both types of semantic space models ie , word-based and syntaxbased concerns the notion of semantic similarity	0	2	1
P03-1017	P99-1004	2003	Contexts are defined as a small number of words surrounding the target word <REF>Lund and Burgess, 1996</REF>; <REF>Lowe and McDonald, 2000</REF> or as entire paragraphs, even documents <REF>Landauer and Dumais, 1997</REF>	0	Context is typically treated as a set of unordered words, although in some cases syntactic information is taken into account <REF>Lin, 1998</REF>; <REF>Grefenstette, 1994</REF>; <TREF>Lee, 1999</TREF>	1	A word can be thus viewed as a point in an n-dimensional semantic space	0	The semantic similarity between words can be then mathematically computed by measuring the distance between points in the semantic space using a metric such as cosine or Euclidean distance	0	6	1
W04-1507	P99-1004	2004	There are a number of studies that, starting from this hypothesis, have built automatic or semi-automatic procedures for clustering words <REF>Brill and Marcus, 1992</REF>; <REF>Pereira et al , 1993</REF>; <REF>Martin et al , 1998</REF>, especially in the field of cognitive sciences <REF>Redington et al , 1998</REF>; <REF>Gobet and Pine, 1997</REF>; <REF>Clark, 2000</REF>	0	They examine the distributional behaviour of some target words, comparing the lexical distribution of their respective collocates using quantitative measures of distributional similarity <TREF>Lee, 1999</TREF>	1	In <REF>Brill and Marcus, 1992</REF> it is given a semiautomatic procedure that, starting from lexical statistical data collected from a large corpus, aims to arrange target words in a tree more precisely a dendrogram, instead of clustering them automatically	0	This procedure requires a linguistic examination of the resulting tree, in order to identify the word classes that are most appropriate to describe the phenomenon under investigation	0	3	2
W04-1808	P99-1004	2004	The formula is symmetric but does not satisfy the triangle inequality	0	For speed the estimate may be calculated from the shared features alone <TREF>Lee, 1999</TREF>	1	After calculating all the pairwise estimates, we retained lists of the 100 most similar nouns for each of the nouns in the corpus data	0	No other data is used in the similarity calculations	0	1	2
W04-1808	P99-1004	2004	There are many approaches to computing semantic similarity between words based on their distribution in a corpus	0	For a general overview of similarity measures, see <REF>Manning and Schutze, 1999</REF>, and for some recent and extensive overviews and evaluations of similarity measures for ia automatic thesaurus construction, see <REF>Weeds, 2003</REF>; <REF>Curran, 2003</REF>; <REF>Lee, 2001</REF>; <REF>Dagan et al , 1999</REF>	1	They show that the information radius and the skew distance are among the best for finding distributional proxies for words	0	If we assume that a word w is represented as a sum of its contexts and that we can calculate the similarities between such word representations, we get a list Lw of words with quantifications of how similar they are to w Each similarity <REF>CompuTerm 2004</REF> 3rd International Workshop on Computational Terminology 63 list Lw contains a mix of words related to the senses of the word w If we wish to identify groups of synonyms and other related words in a list of similarityrated words, we need to find clusters of similar words that are more similar to one another than they are to other words	0	6	1
P08-3011	P99-1004	2008	The intuition behind the cosine measure is that the similarity between two distributions of words should be independent of the length of either document	0	However, researchers have demonstrated that cosine is not the best relevance metric for other applications, so we evaluated two other topical similarity scores: Jacquards coefficient, which performed better than most other similarity measures in a different task for <TREF>Lee 1999</TREF> and Nave Bayes, which gave better results than cosine in topic-adapted language models for <REF>Seymore and Rosenfeld 1997</REF>	1	We evaluated all three similarity metrics using Switchboard topics as the training data and each of our corpora for testing using cross-validation	0	We found that cosine is consistently better than both Jacquards coefficient and Nave Bayes, across all corpora tested	0	6	1
P06-1116	P99-1004	2006	1993 and <TREF>Lee 1999</TREF>, among others	0	We use the cosine similarity measure for windowbased contexts and the following commonly used similarity measures for the syntactic vector space: <REF>Hindles 1990</REF> measure, the weighted Lin measure <REF>Wu and Zhou, 2003</REF>, the -Skew divergence measure <TREF>Lee, 1999</TREF>, the Jensen-Shannon JS divergence measure <REF>Lin, 1991</REF>, Jaccards coef cient van <REF>Rijsbergen, 1979</REF> and the Confusion probability <REF>Essen and Steinbiss, 1992</REF>	1	The Jensen-Shannon measure JS x1, x2  summationtext yY summationtext xx1,x2 parenleftbigg P yx log parenleftbigg Pyx 1 2 Pyx1Pyx2 parenrightbiggparenrightbigg subsequently performed best for our task	1	We compare the different ranking methodologies and data sets with respect to a manually-de ned gold standard list of 20 goal-type verbs and 20 nouns	0	1	3
P06-1116	P99-1004	2006	We use verb-object relations in both active and passive voice constructions as did Pereira et al	0	1993 and <TREF>Lee 1999</TREF>, among others	0	We use the cosine similarity measure for windowbased contexts and the following commonly used similarity measures for the syntactic vector space: <REF>Hindles 1990</REF> measure, the weighted Lin measure <REF>Wu and Zhou, 2003</REF>, the -Skew divergence measure <TREF>Lee, 1999</TREF>, the Jensen-Shannon JS divergence measure <REF>Lin, 1991</REF>, Jaccards coef cient van <REF>Rijsbergen, 1979</REF> and the Confusion probability <REF>Essen and Steinbiss, 1992</REF>	1	The Jensen-Shannon measure JS x1, x2  summationtext yY summationtext xx1,x2 parenleftbigg P yx log parenleftbigg Pyx 1 2 Pyx1Pyx2 parenrightbiggparenrightbigg subsequently performed best for our task	1	3	3
P06-1116	P99-1004	2006	Although -Skew outperforms the simpler measures in ranking nouns, its performance on verbs is worse than the performance of Weighted Lin	0	<REF>While Lee 1999</REF> argues that -Skews asymmetry can be advantageous for nouns, this probably does not hold for verbs: verb hierarchies have much shallower structure than noun hierarchies with most verbs concentrated on one level <REF>Miller et al , 1990</REF>	1	This would explain why JS, which is symmetric compared to the -Skew metric, performed better in our experiments	1	In the evaluation presented here we therefore use Google Scholar data and the JS measure	0	1	3
P05-1019	P99-1004	2005	Table 1 summarises our expectations of the values of KL divergence and V, for the various substitutability relationships	0	KL divergence, unlike most similarity functions, is sensitive to the order of arguments related by hyponymy <TREF>Lee, 1999</TREF>	1	The 152 Something happened and something else happened	0	Something happened or something else happened	0	6	1
P05-1019	P99-1004	2005	149 This paper proposes that substitutability can be predicted through statistical analysis of the contexts in which connectives appear	0	Similar methods have been developed for predicting the similarity of nouns and verbs on the basis of their distributional similarity, and many distributional similarity functions have been proposed for these tasks <TREF>Lee, 1999</TREF>	1	However substitutability is a more complex notion than similarity, and we propose a novel variance-based function for assisting in this task	0	This paper constitutes a first step towards predicting substitutability of cnonectives automatically	0	6	1
C08-1053	P99-1004	2008	Here, xi and yj denote two words and c stands for a context	0	Similarly to <TREF>Lee, 1999</TREF>, we use unsmoothed relative frequencies to derive probability estimates P In the de nition of the dice coef cient, Fxi  c : Pcxi > 0	1	We are mainly interested in the symmetric measures dxi, yj  dyj, xi because of a symmetric positive semi-de nite matrix required by kernel methods	0	Consequently, such measures as the skew divergence were excluded from the consideration <TREF>Lee, 1999</TREF>	0	6	1
C08-1053	P99-1004	2008	There are a number of measures proposed over the years, including such metrics as cosine, dice coef cient, and Jaccard distance	0	Distributional similarity measures have been extensively studied in <TREF>Lee, 1999</TREF>; <REF>Weeds et al, 2004</REF>	1	We have chosen the following metrics: dice, cosine and l2 euclidean whose de nitions are given in Table 1	0	Here, xi and yj denote two words and c stands for a context	0	6	1
C08-1053	P99-1004	2008	We are mainly interested in the symmetric measures dxi, yj  dyj, xi because of a symmetric positive semi-de nite matrix required by kernel methods	0	Consequently, such measures as the skew divergence were excluded from the consideration <TREF>Lee, 1999</TREF>	1	The Euclidean measure as de ned in Table 1 does not necessarily vary from 0 to 1	0	It was therefore normalized by dividing an l2 score in Table 1 by a maximum score and retracting it from 1	0	1	3
C08-1053	P99-1004	2008	42 Experiment I: Distributional measures and their impact on the final performance Distributional similarity measures have been used for various tasks in the past	0	For instance, <TREF>Lee, 1999</TREF> employs them to detect similar nouns based on the verb-object cooccurrence pairs	1	The results suggest the Jaccards coef cient to be one of the best performing measures followed by some others including cosine	0	Euclidean distance fell into the group with the largest error rates	0	6	1
W05-1202	P99-1004	2005	This shows that we have extracted a reasonable number of features for each phrase, since distributional similarity techniques have been shown to work well for words which occur more than 100 times in a given corpus <REF>Lin, 1998</REF>; <REF>Weeds and Weir, 2003</REF>	0	We then computed the distributional similarity between each co-occurrence vector using the -skew divergence measure <TREF>Lee, 1999</TREF>	1	The -skew divergence measure is an approximation to the KullbackLeibler KL divergence meassure between two distributions p and q: Dpq  summationdisplay x pxlogpxqx 5We currently retain all of the distinctions between grammatical relations output by RASP	0	10 The -skew divergence measure is designed to be used when unreliable maximum likelihood estimates MLE of probabilities would result in the KL divergence being equal to 	0	3	2
J06-1003	P99-1004	2006	Given this framework, many different methods of measuring distributional similarity have been proposed; see <REF>Dagan 2000</REF>, <REF>Weeds 2003</REF>, or <REF>Mohammad and Hirst 2005</REF> for a review	0	For example, the set of words that co-occur with w 1 and those that co-occur with w 2 may be regarded as a feature vector of each and their similarity measured as the cosine between the vectors; or a measure may be based on the KullbackLeibler divergence between the probability distributions Pww 1 andPww 2 , as, for example, <TREF>Lees 1999</TREF> -skew divergence	1	<REF>Lin 1998b</REF> uses his similarity theorem equation 19 above to derive a measure based on the degree of overlap of the sets of words with which w 1 and w 2 , respectively, have positive mutual information	0	22 Words that are distributionally similar do indeed often represent semantically related concepts, and vice versa, as the following examples demonstrate	0	6	1
J06-1003	P99-1004	2006	Second, whereas semantic relatedness is symmetric, distributional similarity is a potentially asymmetrical relationship	0	If distributional similarity is conceived of as substitutability, as <REF>Weeds and Weir 2005</REF> and <TREF>Lee 1999</TREF> emphasize, then asymmetries arise when one word appears in a subset of the contexts in which the other appears; for example, the adjectives that typically modify apple are a subset of those that modify fruit,sofruit substitutes for apple better than apple substitutes for fruit	1	While some distributional similarity measures, such as cosine, are symmetric, many, such as -skew divergence and the co-occurrence retrieval models developed by Weeds and Weir, are not	0	But this is simply not an adequate model of semantic relatedness, for which substitutability is far too strict a requirement: window and house are semantically related, but they are not plausibly substitutable in most contexts	1	1	3
J06-1003	P99-1004	2006	As a means of acknowledging the polysemy of language, in this paper the term concept will refer to a particular sense of a given word	0	We want to be very clear that, throughout this paper, when we say that two words are similar, this is a short way of saying that they denote similar concepts; we are not talking about similarity of distributional or co-occurrence behavior of the words, for which the term word similarity has also been used <REF>Dagan 2000</REF>; <REF>Dagan, Lee, and Pereira 1999</REF>	1	While similarity of denotation might be inferred from similarity of distributional or co-occurrence behavior <REF>Dagan 2000</REF>; <REF>Weeds 2003</REF>, the two are distinct ideas	0	We return to the relationship between them in Section 62	0	6	1
W04-1216	P99-1004	2004	Baseline1 and Baseline2 in our system use different back-off schema	0	The following formula is introduced in <TREF>Lee 1999</TREF> for word similarity-based smoothing: 4 , ,    1         tt tt wSw tt wSw tttt tt wwsim wtagPwwsim wtagP where Sw is a set of candidate similar words and simw,w is the similarity between word w and w	1	Word similarity-based smoothing approach is used in our system to make advantage of the huge unlabeled corpus	0	In order to plug the word similarity-based smoothing into our HMM model, we made several extensions to formula 4	1	5	2
J05-4002	P99-1004	2005	The constant and multiplying factors are required, since the CRM defines a similarity in the range 0,1, whereas the L 1 Norm defines a distance in the range 0,2 where 0 distance is equivalent to 1 on the similarity scale	0	44 The -skew Divergence Measure The -skew divergence measure <REF>Lee 1999, 2001</REF> is a popular approximation to the Kullback-Leibler divergence measure 8 <REF>Kullback and Leibler 1951</REF>; <REF>Cover and Thomas 1991</REF>	0	It is an approximation developed to be used when unreliable MLE probabilities 7 Distance measures, also referred to as divergence and dissimilarity measures, can be viewed as the inverse of similarity measures; that is, an increase in distance correlates with a decrease in similarity	0	8 The Kullback-Leibler divergence measure is also often referred to as relative entropy 456 Weeds and Weir Co-occurrence Retrieval would result in the actual Kullback-Leibler divergence measure being equal to Itis defined <TREF>Lee 1999</TREF> as: dist  q, r  Drq  1 r 35 for 0    1, and where: Dpq  summationdisplay x pxlog px qx 36 In effect, the q distribution is smoothed with the r distribution, which results in it always being non-zero when the r distribution is non-zero	1	6	1
J05-4002	P99-1004	2005	In our experiments, the development-set similarity using the harmonic mean in the additive MI-based CRM was 0312 for high-frequency nouns and 0153 for low-frequency nouns, and the development-set similarity using the harmonic mean in the additive t-test based CRM was 0294 for high-frequency nouns and 0129 for low-frequency nouns	0	52 Pseudo-Disambiguation Task Pseudo-disambiguation tasks have become a standard evaluation technique <REF>Gale, Church, and Yarowsky 1992</REF>; Sch utze 1992; <REF>Pereira, Tishby, and Lee 1993</REF>; Sch utze 1998; <TREF>Lee 1999</TREF>; <REF>Dagan, Lee, and Pereira 1999</REF>; <REF>Golding and Roth 1999</REF>; <REF>Rooth et al 1999</REF>; <REF>EvenZohar and Roth 2000</REF>; <REF>Lee 2001</REF>; <REF>Clark and Weir 2002</REF> and, in the current setting, we may use a nouns neighbors to decide which of two co-occurrences is the most likely	1	Although pseudo-disambiguation is an artificial task, it has relevance in at least two application areas	0	First, by replacing occurrences of a particular word in a test suite with 465 Computational Linguistics Volume 31, Number 4 a pair of words from which a technique must choose, we recreate a simplified version of the word sense disambiguation task; that is, we choose between a fixed number of homonyms based on local context	0	6	1
J05-4002	P99-1004	2005	In order to study the relationship between parameter settings and error rate, we combine three of the sets to form a development set and two of the sets to form a test set	0	The development set is used to optimize parameters and the test set 10 <REF>Unlike Lee 1999</REF>, we do not delete instances from the test data that occur in the training data	1	This is discussed in detail in <REF>Weeds 2003</REF>, but our main justification for this approach is that a single co-occurrence of n, v 1  compared to zero co-occurrences of n, v 2  is not necessarily sufficient evidence to conclude that the population probability of n, v 1  is greater than that of n, v 2 	1	11 Ten being less than the minimum number 14 of possibly indistinct co-occurrences for any target noun in the original test data	0	2	1
J05-4002	P99-1004	2005	This is advantageous in the computation of similarity, since computing the sums over all co-occurrence types rather than just those co-occurring with at least one of the words is 1 very computationally expensive and 2 due to their vast number, the effect of these zero frequency co-occurrence types tends to outweigh the effect of those co-occurrence types that have actually occurred	0	Giving such weight to these shared non-occurrences seems unintuitive and has been shown by <TREF>Lee 1999</TREF> to be undesirable in the calculation of distributional similarity	1	Hence, when using the 448 Weeds and Weir Co-occurrence Retrieval ALLR as the weight function, we use the additional restriction that Pc, w > 0 when selecting features	1	24 Difference-Weighted Models In additive models, no distinction is made between features that have occurred to the same extent with each word and features that have occurred to different extents with each word	0	3	2
J05-4002	P99-1004	2005	It is an approximation developed to be used when unreliable MLE probabilities 7 Distance measures, also referred to as divergence and dissimilarity measures, can be viewed as the inverse of similarity measures; that is, an increase in distance correlates with a decrease in similarity	0	8 The Kullback-Leibler divergence measure is also often referred to as relative entropy 456 Weeds and Weir Co-occurrence Retrieval would result in the actual Kullback-Leibler divergence measure being equal to Itis defined <TREF>Lee 1999</TREF> as: dist  q, r  Drq  1 r 35 for 0    1, and where: Dpq  summationdisplay x pxlog px qx 36 In effect, the q distribution is smoothed with the r distribution, which results in it always being non-zero when the r distribution is non-zero	1	The parameter  controls the extent to which the measure approximates the Kullback-Leibler divergence measure	0	When  is close to 1, the approximation is close while avoiding the problem with zero probabilities associated with using the Kullback-Leibler divergence measure	0	6	1
J05-4002	P99-1004	2005	Further, the noun hyponymy hierarchy in WordNet, which will be used as a pseudo-gold standard for comparison, is widely recognized in this area of research	0	Some previous work on distributional similarity between nouns has used only a single grammatical relation eg , <TREF>Lee 1999</TREF>, whereas other work has considered multiple grammatical relations eg , <REF>Lin 1998a</REF>	1	We consider only a single grammatical relation because we believe that it is important to evaluate the usefulness of each grammatical relation in calculating similarity before deciding how to combine information from 5 This results in a single 80:20 split of the complete data set, in which we are guaranteed that the original relative frequencies of the target nouns are maintained	1	6 The use of grammatical relations to model context precludes finding similarities between words of different parts of speech	0	2	2
J05-4002	P99-1004	2005	A statistical technique using a language model that assigns a zero probability to these previously unseen events will rule the correct parse or interpretation of the utterance impossible	0	Similarity-based smoothing <REF>Hindle 1990</REF>; <REF>Brown et al 1992</REF>; <REF>Dagan, Marcus, and Markovitch 1993</REF>; <REF>Pereira, Tishby, and Lee 1993</REF>; <REF>Dagan, Lee, and Pereira 1999</REF> provides an intuitively appealing approach to language modeling	1	In order to estimate the probability of an unseen co-occurrence of events, estimates based on seen occurrences of similar events can be combined	1	For example, in a speech recognition task, we might predict that cat is a more likely subject of growl than the word cap, even though neither co-occurrence has been seen before, based on the fact that cat is similar to words that do occur as the subject of growl eg , dog and tiger, whereas cap is not	0	1	2
J03-3005	P99-1004	2003	However, the next section will present a small-scale study that compares the performance of several smoothing techniques with the performance of Web counts on a standard task from the literature	0	34 Pseudodisambiguation In the smoothing literature, re-created frequencies are typically evaluated using pseudodisambiguation <REF>Clark and Weir 2001</REF>; <REF>Dagan, Lee, and Pereira 1999</REF>; <TREF>Lee 1999</TREF>; <REF>Pereira, Tishby, and Lee 1993</REF>; <REF>Prescher, Riezler, and Rooth 2000</REF>; <REF>Rooth et al 1999</REF>	1	477 Keller and Lapata Web Frequencies for Unseen Bigrams The aim of the pseudodisambiguation task is to decide whether a given algorithm re-creates frequencies that make it possible to distinguish between seen and unseen bigrams in a given corpus	0	A set of pseudobigrams is constructed according to a set of criteria detailed below that ensure that they are unattested in the training corpus	0	6	1
J03-3005	P99-1004	2003	Conclusions This article explored a novel approach to overcoming data sparseness	0	If a bigram is unseen in a given corpus, conventional approaches re-create its frequency using techniques such as back-off, linear interpolation, class-based smoothing or distanceweighted averaging see Dagan, Lee, and Pereira 1999 and Lee 1999 for overviews	1	The approach proposed here does not re-create the missing counts but instead retrieves them from a corpus that is much larger but also much more noisy than any existing corpus: it launches queries to a search engine in order to determine how often the bigram occurs on the Web	0	We systematically investigated the validity of this approach by using it to obtain frequencies for predicate-argument bigrams adjective-noun, noun-noun, and verbobject bigrams	0	6	1
J03-3005	P99-1004	2003	Other, more sophisticated class-based methods do away with the simplifying assumption that the argument co-occurring with a given predicate adjective, noun, verb is distributed evenly across its conceptual classes and attempt to find the right level of generalization in a concept hierarchy, by discounting, for example, the contribution of very general classes <REF>Clark and Weir 2001</REF>; <REF>McCarthy 2000</REF>; <REF>Li and Abe 1998</REF>	0	Other smoothing approaches such as discounting <REF>Katz 1987</REF> and distance-weighted averaging <REF>Grishman and Sterling 1994</REF>; <REF>Dagan, Lee, and Pereira 1999</REF> re-create counts of unseen word combinations by exploiting only corpus-internal evidence, without relying on taxonomic information	1	Our goal was to demonstrate that frequencies retrieved from the Web are a viable alternative to conventional smoothing methods when data are sparse; we do not claim that our Web-based method is necessarily superior to smoothing or that it should be generally preferred over smoothing methods	1	However, the next section will present a small-scale study that compares the performance of several smoothing techniques with the performance of Web counts on a standard task from the literature	0	2	1
J03-3005	P99-1004	2003	They demonstrate that the counts re-created using this smoothing technique correlate significantly with plausibility judgments for adjective-noun bigrams	0	They also show that this class-based approach outperforms distance-weighted averaging <REF>Dagan, Lee, and Pereira 1999</REF>, a smoothing method that re-creates unseen word co-occurrences on the basis of distributional similarity without relying on a predefined taxonomy, in predicting plausibility	1	In the current study, we used the smoothing technique of <REF>Lapata, Keller, and McDonald 2001</REF> to re-create not only adjective-noun bigrams, but also noun-noun 475 Keller and Lapata Web Frequencies for Unseen Bigrams Table 12 Correlation of counts re-created using class-based smoothing with Web counts	0	Adjective-Noun Noun-Noun Verb-Object Seen Bigrams AltaVista 344 362 361 Google 330 343 349 Unseen Bigrams AltaVista 439 386 412 Google 444 421 397 p <05 one-tailed	0	1	3
J03-3005	P99-1004	2003	Despite their imperfect output, heuristic methods for the extraction of syntactic relations are relatively common in statistical NLP	0	Several statistical models employ frequencies obtained from the output of partial parsers and other heuristic methods; these include models for disambiguating the attachment site of prepositional phrases <REF>Hindle and Rooth 1993</REF>; <REF>Ratnaparkhi 1998</REF>, models for interpreting compound nouns <REF>Lauer 1995</REF>; <REF>Lapata 2002</REF> and polysemous adjectives <REF>Lapata 2001</REF>, models for the induction of selectional preferences <REF>Abney and Light 1999</REF>, methods for automatically clustering words according to their distribution in particular syntactic contexts <REF>Pereira, Tishby, and Lee 1993</REF>, automatic thesaurus extraction <REF>Grefenstette 1994</REF>; <REF>Curran 2002</REF>, and similarity-based models of word co-occurrence probabilities <TREF>Lee 1999</TREF>; <REF>Dagan, Lee, and Pereira 1999</REF>	1	In this article we investigate alternative ways for obtaining bigram frequencies that are potentially useful for such models despite the fact that some of these bigrams are identified in a heuristic manner and may be noisy	0	22 Sampling Bigrams from the NANTC We also obtained corpus counts from a second corpus, the North American News Text Corpus NANTC	0	6	1
C04-1135	P99-1016	2004	By using Japanese HTML documents, we empirically show that our proposed method can obtain a significant number of hyponymy relations which would otherwise be missed by alternative methods	1	Hyponymy relations can play a crucial role in various NLP systems, and there have been many attempts to develop automatic methods to acquire hyponymy relations from text corpora <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>; <REF>Imasumi, 2001</REF>; <REF>Fleischman et al , 2003</REF>; <REF>Morin and Jacquemin, 2003</REF>; <REF>Ando et al , 2003</REF>	1	Most of these techniques have relied on particular linguistic patterns, such as NP such as NP The frequencies of use for such linguistic patterns are relatively low, though, and there can be many expressions that do not appear in such patterns even if we look at large corpora	0	The effort of searching for other clues indicating hyponymy relations is thus significant	0	4	2
P06-1038	P99-1016	2006	<REF>Pantel and Lin, 2002</REF> improves on the latter by clustering by committee	0	<TREF>Caraballo 1999</TREF> uses conjunction and appositive annotations in the vector representation	1	2We did not compare against methods that use richer syntactic information, both because they are supervised and because they are much more computationally demanding	1	3We are not aware of any multilingual evaluation previously reported on the task	0	6	1
D07-1034	P99-1016	2007	For instance, <REF>Lin 1998</REF> used dependency relation as word features to compute word similarities from large corpora, and compared the thesaurus created in such a way with WordNet and Roget classes	0	<TREF>Caraballo 1999</TREF> selected head nouns from conjunctions and appositives in noun phrases, and used the cosine similarity measure with a bottomup clustering technique to construct a noun hierarchy from text	1	<REF>Curran and Moens 2002</REF> explored a new similarity measure for automatic thesaurus extraction which better compromises with the speed/performance tradeoff	0	<REF>You and Chen 2006</REF> used a feature clustering method to create a thesaurus from a Chinese newspaper corpus	0	6	1
C08-1058	P99-1016	2008	Previous work on automatic methods for building semantic lexicons could be divided into two main groups	1	One is automatic thesaurus acquisition, that is, to identify synonyms or topically related words from corpora based on various measures of similarity eg <REF>Riloff and Shepherd, 1997</REF>; <REF>Lin, 1998</REF>; <TREF>Caraballo, 1999</TREF>; <REF>Thelen and Riloff, 2002</REF>; <REF>You and Chen, 2006</REF>	1	Another line of research, which is more closely related to the current study, is to extend existing thesauri by classifying new words with respect to their given structures eg <REF>Tokunaga et al, 1997</REF>; <REF>Pekar, 2004</REF>	0	An early effort along this line is <REF>Hearst 1992</REF>, who attempted to identify hyponyms from large text corpora, based on a set of lexico-syntactic patterns, to augment and critique the content of WordNet	0	4	2
N07-1031	P99-1016	2007	In contrast, in this paper we focus on the problem of determining the categories of interest	0	Another thread of work is on finding synonymous terms and word associations, as well as automatic acquisition of IS-A or genus-head relations from dictionary definitions and free text <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>	1	That work focuses on finding the right position for a word within a lexicon, rather than building up comprehensible and coherent faceted hierarchies	1	A major class of solutions for creating subject hierarchies uses data clustering	0	4	2
W02-0904	P99-1016	2002	One way to overcome this problem might be to give judges information about a sequence of higher ancestors, in order to make the judgement easier	0	It is difficult to compare these results with results from other studies such as that of <TREF>Caraballo 1999</TREF>, as the data used is not the same	1	However, it seems that our figures are in the same range as those reported in previous studies	1	<REF>Charniak  Roark 1998</REF>, evaluating the semantic lexicon against gold standard resources the MUC-4 and the WSJ corpus, reports that the ratio of valid to total entries for their system lies between 20 and 40	0	4	2
W02-0904	P99-1016	2002	For example, while the plural form of the word boy ie boys is a valid hyponym of the hypernym group, the singular form would not be	1	As was also reported by <TREF>Caraballo 1999</TREF>, the judges sometimes found proper nouns as hyponyms hard to evaluate	1	Eg it might be hard to tell if Simon Le Bon is a valid hyponym to the hypernym rock star if his identity is unknown to the judge	0	One way to overcome this problem might be to give judges information about a sequence of higher ancestors, in order to make the judgement easier	1	6	1
W02-0904	P99-1016	2002	Generally, principle 1-2 above are meant to prevent the hierarchies from containing ambiguity	0	The built-in ambiguity in the hyponymy hierarchy presented in <TREF>Caraballo, 1999</TREF> is primarily an effect of the fact that all information is composed into one tree	1	Part of the ambiguity could have been solved if the requirement of building one tree had been relaxed	0	Principle 2, regarding keeping the hierarchy ambiguity-free, is especially important, as we are working with acquisition from a corpus that is not domain restricted	0	6	1
W02-0904	P99-1016	2002	<REF>Charniak  Roark 1998</REF>, evaluating the semantic lexicon against gold standard resources the MUC-4 and the WSJ corpus, reports that the ratio of valid to total entries for their system lies between 20 and 40	0	<TREF>Caraballo 1999</TREF> let three judges evaluate ten internal nodes in the hyponymy hierarchy, that had at least twenty descendants	1	Cases where judges had problems with proper nouns as hyponyms, corresponding to these mentioned above, were corrected	0	When the best hypernym was evaluated, the result reported for a majority of the judges was 33	0	6	1
W02-0904	P99-1016	2002	Continue at 1	0	<TREF>Caraballo 1999</TREF> uses a hierarchical clustering technique to build a hyponymy hierarchy of nouns	1	The internal nodes are labeled by the syntactic constructions from <REF>Hearst 1992</REF>	0	Each internal node in the hierarchy can be represented by up to three nouns	0	6	1
J06-2003	P99-1016	2006	Automatically extracting world knowledge from MRDs was attempted by projects such as MindNet at Microsoft Research <REF>Richardson, Dolan, and Vanderwende 1998</REF>, and Barrierre and <REF>Popowichs 1996</REF> project, which learns from childrens dictionaries	0	IS-A hierarchies have been learned automatically from MRDs <REF>Hearst 1992</REF> and from corpora Caraballo 1999 among others	1	14 http://wwwclcamacuk/Research/NL/acquilex/acqhomehtml 240 Inkpen and Hirst A Lexical Knowledge Base of Near-Synonym Differences Research on merging information from various lexical resources is related to the present work in the sense that the consistency issues to be resolved are similar	0	One example is the construction of Unified Medical Language System UMLS 15 <REF>Lindberg, Humphreys, and McCray 1993</REF>, in the medical domain	0	6	1
W08-2113	P99-1016	2008	Based on these seeds, she proposes a bootstrapping algorithm to semi-automatically acquire new more specific patterns	1	Similarly, <TREF>Caraballo, 1999</TREF> uses predefined patterns such as X is a kind of Y or X, Y, and other Zs to identify hypernym/hyponym relationships	1	This approach to information extraction is based on a technique called selective concept extraction as defined by <REF>Riloff, 1993</REF>	0	Selective concept extraction is a form of text skimming that selectively processes relevant text while effectively ignoring surrounding text that is thought to be irrelevant to the domain	0	2	1
W08-2113	P99-1016	2008	However, it is well known that any knowledge-based system suffers from the so-called knowledge acquisition bottleneck, ie the difficulty to actually model the domain in question	0	As stated in <TREF>Caraballo, 1999</TREF>, WordNet has been an important lexical knowledge base, but it is insufficient for domain specific texts	1	So, many attempts have been made to automatically produce taxonomies <REF>Grefenstette, 1994</REF>, but <TREF>Caraballo, 1999</TREF> is certainly the first work which proposes a complete overview of the problem by 1 automatically building a hierarchical structure of nouns based on bottom-up clustering methods and 2 labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as B is a kind of A	0	2008	0	1	3
W08-2113	P99-1016	2008	As stated in <TREF>Caraballo, 1999</TREF>, WordNet has been an important lexical knowledge base, but it is insufficient for domain specific texts	1	So, many attempts have been made to automatically produce taxonomies <REF>Grefenstette, 1994</REF>, but <TREF>Caraballo, 1999</TREF> is certainly the first work which proposes a complete overview of the problem by 1 automatically building a hierarchical structure of nouns based on bottom-up clustering methods and 2 labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as B is a kind of A	1	2008	0	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 30 Unported license http://creativecommonsorg/licenses/by-ncsa/30/	0	1	3
W05-1006	P99-1016	2005	For example, the phrase France, Germany, Italy, and other European countries suggests that France, Germany and Italy are part of the class of European countries	0	Such hierarchical examples are quite sparse, and greater coverage was later attained by <REF>Riloff and Shepherd 1997</REF> and <REF>Roark and Charniak 1998</REF> in extracting relations not of hierarchy but of similarity, by finding conjunctions or co-ordinations such as cloves, cinammon, and nutmeg and cars and trucks This work was extended by <TREF>Caraballo 1999</TREF>, who built classes of related words in this fashion and then reasoned that if a hierarchical relationship could be extracted for any member of this class, it could be applied to all members of the class	1	This technique can often mistakenly reason across an ambiguous middle-term, a situation that was improved upon by <REF>Cederberg and Widdows 2003</REF>, by combining pattern-based extraction with contextual filtering using latent semantic analysis	0	Prior work in discovering non-compositional phrases has been carried out by <REF>Lin 1999</REF> and Baldwin et al	0	6	2
W03-0404	P99-1016	2003	The extraction patterns used in our research are linguistically richer patterns, requiring shallow parsing and syntactic role assignment	1	In recent years several techniques have been developed for semantic lexicon creation eg , <REF>Hearst, 1992</REF>; <REF>Riloff and Shepherd, 1997</REF>; <REF>Roark and Charniak, 1998</REF>; <TREF>Caraballo, 1999</TREF>	1	Semantic word learning is different from subjective word learning, but we have shown that MetaBootstrapping and Basilisk could be successfully applied to subjectivity learning	1	Perhaps some of these other methods could also be used to learn subjective words	1	3	2
C02-1090	P99-1016	2002	For this reason, knowledge-poor approaches such as the distributional approach are particularly suited for this task	0	Its previous applications eg , <REF>Grefenstette 1993</REF>, <REF>Hearst and Schuetze 1993</REF>, <REF>Takunaga et al 1997</REF>, <REF>Lin 1998</REF>, <TREF>Caraballo 1999</TREF> demonstrated that cooccurrence statistics on a target word is often sufficient for its automatical classification into one of numerous classes such as synsets of WordNet	1	Distributional techniques, however, are poorly applicable to rare words, ie, those words for which a corpus does not contain enough cooccurrence data to judge about their meaning	0	Such words are the primary concern of many practical NLP applications: as a rule, they are semantically focused words and carry a lot of important information	0	6	1
W02-1111	P99-1016	2002	<REF>Hearst 1992</REF> used textual patterns eg such as to identify common class members	0	<REF>Caraballo and Charniak 1999</REF> and <TREF>Caraballo 1999</TREF> augmented these lexical patterns with more general lexical co-occurrence statistics such as relative entropy	1	<REF>Berland and Charniak 1999</REF> use Hearst style techniques to learn meronym relationships part-whole from corpora	0	There has also been work in building ontologies from structured Correct Answer Question Debbie Reynolds What actress once held the title of Miss Burbank	0	6	1
C00-2104	P99-1016	2000	In addition, <REF>Strzalkowski and Wang 1996</REF> used a bootstrapping technique to identify types of references, and <REF>Riloff and Jones 1999</REF> adapted bootstrapping techniques to lexicon building targeted to information extraction	1	In the same vein, researchers at Brown University <REF>Caraballo and Charniak, 1999</REF> <REF>Berland and Charniak, 1999</REF>, <TREF>Caraballo, 1999</TREF> and <REF>Roark and Charniak, 1998</REF> focused on target constructions, in particular complex noun thrases, and searched for information not only on identifying classes of nouns, lint also hypernyms, noun specificity and meronymy	1	We have a diflbrent perspective than these lines of inquiry	1	They were specifying various semantic relationships and seeking ways to collect similar pairs	0	2	1
W04-2103	P99-1016	2004	To do this, many approaches to lexical acquisition employ the distributional model of word meaning induced from the distribution of the word across various lexical contexts of its occurrence found in the corpus	1	The approach is now being actively explored for a wide range of semantics-related tasks including automatic construction of thesauri <REF>Lin, 1998</REF>; <TREF>Caraballo, 1999</TREF>, their enrichment <REF>Alfonseca and Manandhar, 2002</REF>; <REF>Pekar and Staab, 2002</REF>, acquisition of bilingual lexica from nonaligned <REF>Kay and Rscheisen, 1993</REF> and nonparallel corpora <REF>Fung and Yee, 1998</REF>, learning of information extraction patterns from un-annotated text <REF>Riloff and Schmelzenbach, 1998</REF>	1	However, because of irregularities in corpus data, corpus statistics cannot guarantee optimal performance, notably for rare lexical items	0	In order to improve robustness, recent research has attempted a variety of ways to incorporate external knowledge into the distributional model	0	6	1
C04-1111	P99-1016	2004	However, such clustering algorithms fail to name their classes	1	<TREF>Caraballo 1999</TREF> was the first to use clustering for labeling is-a relations using conjunction and apposition features to build noun clusters	1	<REF>Recently, Pantel and Ravichandran 2004</REF> extended this approach by making use of all syntactic dependency features for each noun	0	3 Syntactical co-occurrence approach Much of the research discussed above takes a similar approach of searching text for simple surface or lexico-syntactic patterns in a bottom-up approach	0	1	3
P07-2038	P99-1016	2007	larity measure could be defined so that, for example: simexecutives, spouses > simbusloads, spouses then it is potentially useful for coordination disambiguation	0	The idea that nouns co-occurring in conjunctions tend to be semantically related has been noted in <REF>Riloff and Shepherd, 1997</REF> and used effectively to automatically cluster semantically similar words <REF>Roark and Charniak, 1998</REF>; <TREF>Caraballo, 1999</TREF>; <REF>Widdows and Dorow, 2002</REF>	1	The tendency for conjoined nouns to be semantically similar has also been exploited for coordinate noun phrase disambiguation by <REF>Resnik 1999</REF> who employed a measure of similarity based on WordNet to measure which were the head nouns being conjoined in certain types of coordinate noun phrase	0	In this paper we look at different measures of word similarity in order to discover whether they can detect empirically a tendency for conjoined nouns to be more similar than nouns which co-occur but are not conjoined	1	2	1
J05-3004	P99-1016	2005	This includes the extraction of hyponymy and synonymy relations <REF>Hearst 1992</REF>; <TREF>Caraballo 1999</TREF>, among others as well as meronymy <REF>Berland and Charniak 1999</REF>; <REF>Meyer 2001</REF>	0	10 One approach to the extraction of instances of a particular lexical relation is the use of patterns that express lexical relations structurally explicitly in a corpus <REF>Hearst 1992</REF>; <REF>Berland and Charniak 1999</REF>; <TREF>Caraballo 1999</TREF>; <REF>Meyer 2001</REF>, and this is the approach we focus on here	1	As an example, the pattern NP 1 and other NP 2 usually expresses a hyponymy/similarity relation between the hyponym NP 1 and its hypernym NP 2 <REF>Hearst 1992</REF>, and it can therefore be postulated that two noun phrases that occur in such a pattern in a corpus should be linked in an ontology via a hyponymy link	0	Applications of the extracted relations to anaphora resolution are less frequent	0	3	2
J05-3004	P99-1016	2005	372 Markert and Nissim Knowledge Sources for Anaphora Resolution consuming hand-modeling	0	This includes the extraction of hyponymy and synonymy relations <REF>Hearst 1992</REF>; <TREF>Caraballo 1999</TREF>, among others as well as meronymy <REF>Berland and Charniak 1999</REF>; <REF>Meyer 2001</REF>	1	10 One approach to the extraction of instances of a particular lexical relation is the use of patterns that express lexical relations structurally explicitly in a corpus <REF>Hearst 1992</REF>; <REF>Berland and Charniak 1999</REF>; <TREF>Caraballo 1999</TREF>; <REF>Meyer 2001</REF>, and this is the approach we focus on here	1	As an example, the pattern NP 1 and other NP 2 usually expresses a hyponymy/similarity relation between the hyponym NP 1 and its hypernym NP 2 <REF>Hearst 1992</REF>, and it can therefore be postulated that two noun phrases that occur in such a pattern in a corpus should be linked in an ontology via a hyponymy link	0	3	2
N04-4030	P99-1016	2004	The literature on automated text categorization is enormous, but assumes that a set of categories has already been created, whereas the problem here is to determine the categories of interest	0	There has also been extensive work on finding synonymous terms and word associations, as well as automatic acquisition of IS-A or genus-head relations from dictionary definitions and glosses <REF>Klavans and Whitman, 2001</REF> and from free text <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>	1	<REF>Sanderson and Croft 1999</REF> propose a method called subsumption for building a hierarchy for a set of documents retrieved for a query	0	For two terms x and y, x is said to subsume y if the following conditions hold: a2a4a3a6a5a8a7a9a11a10a13a12a15a14a17a16a18a20a19a21a2a4a3a6a9a22a7a5a23a10a25a24a27a26	0	6	2
W02-0903	P99-1016	2002	Other kinds of models that have been studied in the context of lexical acquisition are those based on lexico-syntactic patterns of the kind X, Y and other Zs, as in the phrase bluejays, robins and other birds	0	These types of models have been used for hyponym discovery <REF>Hearst, 1992</REF>; <REF>Roark and Charniak, 1998</REF>, meronym discovery <REF>Berland and Charniak, 1999</REF>, and hierarchy building <TREF>Caraballo, 1999</TREF>	1	These methods are very interesting but of limited applicability, because nouns that do not appear in known lexico-syntactic patterns cannot be learned	1	7 Conclusion All the approaches cited above focus on some aspect of the problem of lexical acquisition	0	1	3
W02-1028	P99-1016	2002	Hale, Ge, and Charniak <REF>Ge et al , 1998</REF> devised a technique to learn the gender of words	0	Caraballo <TREF>Caraballo, 1999</TREF> and Hearst <REF>Hearst, 1992</REF> created techniques to learn hypernym/hyponym relationships	1	None of these previous algorithms used extraction patterns or similar contexts to infer semantic class associations	1	Several learning algorithms have also been developed for named entity recognition eg , <REF>Collins and Singer, 1999</REF>; <REF>Cucerzan and Yarowsky, 1999</REF>	0	6	1
W02-0908	P99-1016	2002	Alternatively, some systems are based on the observation that related terms appear together in particular contexts	0	These systems extract related terms directly by recognising linguistic patterns eg X, Y and other Zs which link synonyms and hyponyms <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>	1	Our previous work <REF>Curran and Moens, 2002</REF> has evaluated thesaurus extraction performance and ef ciency using several different context models	1	In this paper, we evaluate some existing similarity metrics and propose and motivate a new metric which outperforms the existing metrics	0	3	2
P06-1015	P99-1016	2006	These methods use clustering algorithms to group words according to their meanings in text, label the clusters using its members lexical or syntactic dependencies, and then extract an is-a relation between each cluster member and the cluster label	1	<TREF>Caraballo 1999</TREF> proposed the first attempt, which used conjunction and apposition features to build noun clusters	1	<REF>Recently, Pantel and Ravichandran 2004</REF> extended this approach by making use of all syntactic dependency features for each noun	1	The advantage of clustering approaches is that they permit algorithms to identify is-a relations that do not explicitly appear in text, however they generally fail to produce coherent clusters from fewer than 100 million words; hence they are unreliable for small corpora	0	4	2
W03-0415	P99-1016	2003	In Section 3, we show how latent semantic analysis can be used to filter potential relationships according to their semantic plausibility	0	In Section 4, we show how correctly extracted relationships can be used as seed-cases to extract several more relationships, thus improving recall; this work shares some similarities with that of <TREF>Caraballo 1999</TREF>	1	In Section 5 we show that combining the techniques of Section 3 and Section 4 improves both precision and recall	0	Section 6 demonstrates that 1Another possible view is that hyponymy should only refer to core relationships, not contingent ones so pheasant a60 bird might be accepted but pheasant a60 food might not be, because it depends on context and culture	0	2	2
W03-0415	P99-1016	2003	We use the broader subset definition because contingent relationships are an important part of world-knowledge and are therefore worth learning, and because in practice we found the distinction difficult to enforce	1	Another definition is given by <TREF>Caraballo 1999</TREF>: 	1	a word A is said to be a hypernym of a word B if native speakers of English accept the sentence B is a kind of A  linguistic tools such as lemmatization can be used to reliably put the extracted relationships into a normalized or canonical form for addition to a semantic resource	1	2 Pattern-Based Hyponymy Extraction The first major attempt to extract hyponyms from text was that of <REF>Hearst 1992</REF>, described in more detail in <REF>Hearst, 1998</REF>, who extracted relationships from the text of Groliers Encyclopedia	0	2	1
W03-0415	P99-1016	2003	4 Improving Recall Using Coordination Information One of the main challenges facing hyponymy extraction is that comparatively few of the correct relations that might be found in text are expressed overtly by the simple lexicosyntactic patterns used in Section 2, as was apparent in the results presented in that section	1	This problem has been addressed by <TREF>Caraballo 1999</TREF>, who describes a system that first builds an unlabelled hierarchy of noun clusters using agglomerative bottom-up clustering of vectors of noun coordination information	1	The leaves of this hierarchy corresponding to nouns are assigned hypernyms using Hearst-style lexicosyntactic patterns	0	Internal nodes in the hierarchy are then labelled with hypernyms of the leaves they subsume according to a vote of these subsumed leaves	0	4	2
W03-0415	P99-1016	2003	This paper suggests many possibilities for future work	1	First of all, it would be interesting to apply LSA to a system for building an entire hypernym-labelled ontology in roughly the way described in <TREF>Caraballo, 1999</TREF>, perhaps by using an LSA-weighted voting method to determine which hypernym would be used to label each node	1	We are considering how to extend our techniques to such a task	1	Also, systematic comparison of the lexicosyntactic patterns used for extraction to determine the relative productiveness and accuracy of each pattern might prove illuminating, as would comparison across different corpora to determine the impact of the topic area and medium/format of documents on the effectiveness of hyponymy extraction	0	5	2
C04-1146	P99-1016	2004	Further, we explore a problem faced by the automatic thesaurus generation community, which is that distributional similarity methods do not seem to o er any obvious way to distinguish between the semantic relations of synonymy, antonymy and hyponymy	1	Previous work on this problem <TREF>Caraballo, 1999</TREF>; <REF>Lin et al , 2003</REF> involves identifying speci c phrasal patterns within text eg, Xs and other Ys is used as evidence that X is a hyponym of Y Our work explores the connection between relative frequency, distributional generality and semantic generality with promising results	1	The rest of this paper is organised as follows	0	In Section 2, we present ten distributional similarity measures that have been proposed for use in NLP	0	2	1
W99-0609	P99-1016	1999	The sparseness of these patterns prevents this from being an effective approach to the problem we address here	1	<REF>In Caraballo 1999</REF>, we construct a hierarchy of nouns, including hypernym relations	1	However, there are several areas where that work could benefit from the research presented here	0	The hypernyms used to label the internal nodes of that hierarchy are chosen in a simple fashion; pattern-matching as in <REF>Hearst 1992</REF> is used to identify candidate hypernyms of the words dominated by a particular node, and a simple voting scheme selects the hypernyms to be used	0	1	3
W99-0609	P99-1016	1999	This project is meant to provide a tool to support other methods	1	<REF>See Caraballo 1999</REF> for a detailed description of a method to construct such a hierarchy	1	2 Previous work To the best of our knowledge, this is the first attempt to automatically rank nouns based on specificity	0	<REF>Hearst 1992</REF> found individual pairs of hypernyms and hyponyms from text using pattern-matching techniques	0	4	2
W05-1003	P99-1016	2005	our disposal, WordNet <REF>Fellbaum, 1998</REF> contains very little information that would be considered as being about attributesonly information about parts, not about qualities such as height, or even to the values of such attributes in the adjective networkand this information is still very sparse	0	On the other hand, the only work on the extraction of lexical semantic relations we are aware of has concentrated on the type of relations found in WordNet: hyponymy <REF>Hearst, 1998</REF>; <TREF>Caraballo, 1999</TREF> and meronymy <REF>Berland and Charniak, 1999</REF>; <REF>Poesio et al, 2002</REF>	1	2 The work discussed here could be perhaps best described as an example of empirical ontology: using linguistics and philosophical ideas to improve the results of empirical work on lexical / ontology acquisition, and vice versa, using findings from empirical analysis to question some of the assumptions of theoretical work on ontology and the lexicon	0	Specifically, we discuss work on the acquisition of nominal concept attributes whose goal is twofold: on the one hand, to clarify the notion of attribute and its role in lexical semantics, if any; on the other, to develop methods to acquire such information automatically eg , to supplement WordNet	0	4	2
P02-1030	P99-1016	2002	Finally, some systems extract synonyms directly without extracting and comparing contextual representations for each term	1	Instead, these systems recognise terms within certain linguistic patterns eg X, Y and other Zs which associate synonyms and hyponyms <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>	1	Thesaurus extraction is a good task to use to experiment with scaling context spaces	0	The vectorspace model with nearest neighbour searching is simple, so we neednt worry about interactions between the contexts we select and a learning algorithm such as independence of the features	0	2	1
P04-2001	P99-1016	2004	Node numbers represent hierarchical structure of terms Contextual information has been mainly used to represent the characteristics of terms	0	<TREF>Caraballo, 1999</TREF>A <REF>Grefenstette, 1994</REF> <REF>Hearst, 1992</REF> <REF>Pereira, 1993</REF> and <REF>Sanderson, 1999</REF> used contextual information to find hyponymy relation between terms	1	<TREF>Caraballo, 1999</TREF>B also used contextual information to determine the specificity of nouns	1	Contrary, compositional information of terms has not been commonly discussed	0	6	1
P03-2011	P99-1016	2003	This paper describes a classifier that assigns semantic thesaurus categories to unknown Chinese words	0	<REF>The Caraballo 1999</REF>s system adopted the contextual information to assign nouns to their hyponyms	1	<REF>Roark and Charniak 1998</REF> used the co-occurrence of words as features to classify nouns	0	While context is clearly an important feature, this paper focuses on non-contextual features, which may play a key role for unknown words that occur only once 1 The Sinica Corpus is a balanced corpus contained five million part-of-speech words in Mandarin Chinese	1	2	1
P03-2011	P99-1016	2003	My analysis of the Sinica Corpus shows that contrary to expectation, most of unknown words in Chinese are common nouns, adjectives, and verbs rather than proper nouns	1	Other previous research has focused on features related to unknown word contexts <TREF>Caraballo 1999</TREF>; <REF>Roark and Charniak 1998</REF>	1	While context is clearly an important feature, this paper focuses on non-contextual features, which may play a key role for unknown words that occur only once and hence have limited context	0	The feature I focus on, following <REF>Ciaramita 2002</REF>, is morphological similarity to words whose semantic category is known	0	4	2
W04-1806	P99-1016	2004	The existing approaches to ontology induction include those that start from structured data, merging ontologies or database schemas <REF>Doan et al 2002</REF>	1	Other approaches use natural language data, sometimes just by analyzing the corpus <REF>Sanderson and Croft 1999</REF>, <TREF>Caraballo 1999</TREF> or by learning to expand WordNet with clusters of terms from a corpus, eg, <REF>Girju et al 2003</REF>	1	Information extraction approaches that infer labeled relations either require substantial handcreated linguistic or domain knowledge, eg, <REF>Craven and Kumlien 1999</REF> <REF>Hull and Gomez 1993</REF>, or require human-annotated training data with relation information for each domain <REF>Craven et al 1998</REF>	0	The number of relations in H that our system missed relations that were more than distance 1 away in the system ontology, is 3493	0	2	1
W04-1806	P99-1016	2004	<REF>CompuTerm 2004</REF> 3rd International Workshop on Computational Terminology 49 234 Explicit Patterns Relations This knowledge source infers specific relations between terms based on characteristic cue-phrases which relate them	1	For example, the cue-phrase such as <REF>Hearst 1992</REF> <TREF>Caraballo 1999</TREF> suggest a kind-of relation, eg, a ligand such as triethylphosphine tells us that triethylphosphene is a kind of ligand	1	Likewise, in the TREC domain, air toxics such as benzene can suggest that benzene is a kind of air toxic	0	However, since such cue-phrase patterns tend to be sparse in occurrence, we do not use them in the evaluations described below	1	1	3
W04-1806	P99-1016	2004	Corpus statistics can be used to weight the links	1	For example, based on <TREF>Caraballo 1999</TREF>, each parent of a leaf node could be viewed as a cluster label for its children, with the weight of a parent-child link being determined based on how strongly the child is associated with the cluster	1	10 The mean distance in H between terms that are distance 1 apart in M is 517, with a standard deviation of 212	0	The mean distance in M between terms which are distance 1 apart in H is 385, with a standard deviation of 169	0	6	1
N04-1010	P99-1016	2004	The goal of this work is to become able to automatically acquire hyponymy relations for a wide range of words or phrases from HTML documents on the WWW	0	We do not use particular lexicosyntactic patterns, as previous attempts have <REF>Hearst, 1992</REF>; <TREF>Caraballo, 1999</TREF>; <REF>Imasumi, 2001</REF>; <REF>Fleischman et al , 2003</REF>; <REF>Morin and Jacquemin, 2003</REF>; <REF>Ando et al , 2003</REF>	1	The frequencies of use for such lexicosyntactic patterns are relatively low, and there can be many words or phrases that do not appear in such patterns even if we look at a large number of texts	0	The effort of searching for other clues indicating hyponymy relations is thus significant	0	2	1
P08-1119	P99-1016	2008	Fully unsupervised semantic clustering eg, <REF>Lin, 1998</REF>; <REF>Lin and Pantel, 2002</REF>; <REF>Davidov and Rappoport, 2006</REF> has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user	0	Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes eg, <TREF>Caraballo, 1999</TREF>; <REF>Cimiano and Volker, 2005</REF>; <REF>Mann, 2002</REF>, and learning semantic relations such as meronymy <REF>Berland and Charniak, 1999</REF>; <REF>Girju et al, 2003</REF>	1	Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class eg, lists of FISH or VEHICLE words	1	Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics <REF>Riloff and Shepherd, 1997</REF>; <REF>Roark and Charniak, 1998</REF>, syntactic information <REF>Tanev and Magnini, 2006</REF>; <REF>Pantel and Ravichandran, 2004</REF>; <REF>Phillips and Riloff, 2002</REF>, lexico-syntactic contextual patterns eg, resides in <location> or moved to <location> <REF>Riloff and Jones, 1999</REF>; <REF>Thelen and Riloff, 2002</REF>, and local and global contexts <REF>Fleischman and Hovy, 2002</REF>	0	4	2
P04-3015	P99-1016	2004	Accordingly, we try to extract a hierarchical relation of words automatically and statistically	1	In previous research, ways of extracting from definition sentences in dictionaries <REF>Tsurumaru et al , 1986</REF>; <REF>Shoutsu et al , 2003</REF> or from a corpus by using patterns such as a part of, is-a, or and <REF>Berland and Charniak, 1999</REF>; <TREF>Caraballo, 1999</TREF> have been proposed	1	Also, there is a method that uses the dependence relation between words taken from a corpus <REF>Matsumoto et al , 1996</REF>	0	In contrast, we propose a method based on the inclusion relation of appearance patterns from corpora	1	2	1
W02-1017	P99-1016	2002	Roark and Charniak <REF>Roark and Charniak, 1998</REF> followed up on this work by using a parser to explicitly capture these structures	0	Caraballo <TREF>Caraballo, 1999</TREF> also exploited these syntactic structures and applied a cosine vector model to produce semantic groupings	1	In our view, these previous systems used weak syntactic models because the syntactic structures sometimes identified desirable semantic associations and sometimes did not	1	To compensate, statistical models were used to separate the meaningful semantic associations from the spurious ones	1	1	3
J05-4002	P99-1016	2005	There are inherent problems in evaluating automatic thesaurus extraction techniques, and much research assumes a gold standard that does not exist see Kilgarriff 2003 and Weeds 2003 for more discussion of this	1	A further problem for distributional similarity methods for automatic thesaurus generation is that they do not offer any obvious way to distinguish between linguistic relations such as synonymy, antonymy, and hyponymy see Caraballo 1999 and Lin et al 2003 for work on this	1	Thus, one may question 1 You shall know a word by the company it keeps<REF>Firth 1957</REF> 440 Weeds and Weir Co-occurrence Retrieval the benefit of automatically generating a thesaurus if one has access to large-scale manually constructed thesauri eg , WordNet <REF>Fellbaum 1998</REF>, Rogets <REF>Roget 1911</REF>, the Macquarie <REF>Bernard 1990</REF> and Moby 2 	0	Automatic techniques give us the opportunity to model language change over time or across domains and genres	0	1	3
P02-1042	P99-1069	2002	The number of dependency types may be reduced in future work	0	3 The Probability Model The DAG-like nature of the dependency structures makes it difficult to apply generative modelling techniques <REF>Abney, 1997</REF>; <TREF>Johnson et al , 1999</TREF>, so we have defined a conditional model, similar to the model of <REF>Collins 1996</REF> see also the conditional model in <REF>Eisner 1996b</REF>	1	While the model of <REF>Collins 1996</REF> is technically unsound <REF>Collins, 1999</REF>, our aim at this stage is to demonstrate that accurate, efficient wide-coverage parsing is possible with CCG, even with an over-simplified statistical model	0	Future work will look at alternative models4 4The reentrancies creating the DAG-like structures are fairly limited, and moreover determined by the lexical categories	0	1	3
H05-1064	P99-1069	2005	The features are shown with hidden variables corresponding to wordspecific hidden values, such as shares1 or bought3	0	In our experiments, we made use of features such as those in Figure 2 in combination with the following four definitions of the hiddenvalue 3We also performed some experiments using the conjugate gradient descent algorithm <TREF>Johnson et al , 1999</TREF>	1	However, we did not find a significant difference between the performance of either method	0	Since stochastic gradient descent was faster and required less memory, our final experiments used the stochastic gradient method	0	3	2
P06-2041	P99-1069	2006	Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser <REF>Collins, 1997</REF>; <REF>Collins, 1999</REF>; <REF>Charniak, 2000</REF>	0	These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser <TREF>Johnson et al , 1999</TREF>; <REF>Collins and Duffy, 2005</REF>; <REF>Charniak and Johnson, 2005</REF>	1	Alternatively, discriminative models can be used to search the complete space of possible parses <REF>Taskar et al , 2004</REF>; <REF>McDonald et al , 2005</REF>	0	A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank	0	4	2
W07-1202	P99-1069	2007	A recent development in data-driven parsing is the use of discriminative training methods <REF>Riezler et al , 2002</REF>; <REF>Taskar et al , 2004</REF>; <REF>Collins and Roark, 2004</REF>; <REF>Turian and Melamed, 2006</REF>	0	One popular approach is to use a log-linear parsing model and maximise the conditional likelihood function <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2002</REF>; <REF>Clark and Curran, 2004b</REF>; Malouf and van <REF>Noord, 2004</REF>; <REF>Miyao and Tsujii, 2005</REF>	1	Maximising the likelihood involves calculating feature expectations, which is computationally expensive	0	Dynamic programming DP in the form of the inside-outside algorithm can be used to calculate the expectations, if the features are sufficiently local <REF>Miyao and Tsujii, 2002</REF>; however, the memory requirements can be prohibitive, especially for automatically extracted, wide-coverage grammars	0	6	1
W03-0401	P99-1069	2003	If a complete structure is represented with a feature forest of a tractable size, the parameters can be efficiently estimated by dynamic programming	0	A series of studies on parsing with wide-coverage LFG <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2000</REF>; <REF>Riezler et al , 2002</REF> have had a similar motivation to ours	0	Their models have also been based on a discriminative model to select a parsing result from all candidates given by the grammar	0	A significant difference is that we apply maximum entropy estimation for feature forests to avoid the inherent problem with estimation: the exponential explosion of parsing results given by the grammar	1	2	3
P01-1042	P99-1069	2001	Wellknown computational linguistic models such as MLE MCLE Y  yi; X  xi X  xi Y  yi; X  xi Figure 1: The MLE makes the training data yi; xi as likely as possible relative to , while the MCLE makes yi; xi as likely as possible relative to other pairs y0; xi	0	Maximum-Entropy Markov Models <REF>McCallum et al , 2000</REF> and Stochastic Unification-based Grammars <TREF>Johnson et al , 1999</TREF> are standardly estimated with conditional estimators, and it would be interesting to know whether conditional estimation affects the quality of the estimated model	0	It should be noted that in practice, the MCLE of a model with a large number of features with complex dependencies may yield far better performance than the MLE of the much smaller model that could be estimated with the same computational effort	0	Nevertheless, as this paper shows, conditional estimators can be used with other kinds of models besides MaxEnt models, and in any event it is interesting to ask whether the MLE differs from the MCLE in actual applications, and if so, how	1	3	2
A00-2021	P99-1069	2000	However, because these constraints can be non-local or context-sensitive, developing stochastic versions of UBGs and associated estimation procedures is not as straight-forward as it is for, eg, PCFGs	0	Recent work has shown how to define probability distributions over the parses of UBGs <REF>Abney, 1997</REF> and efficiently estimate and use conditional probabilities for parsing <TREF>Johnson et al , 1999</TREF>	0	Like most other practical stochastic grammar estimation procedures, this latter estimation procedure requires a parsed training corpus	1	Unfortunately, large parsed UBG corpora are not yet available	1	1	3
W02-2018	P99-1069	2002	Maximum entropy ME models, variously known as log-linear, Gibbs, exponential, and multinomial logit models, provide a general purpose machine learning technique for classification and prediction which has been successfully applied to fields as diverse as computer vision and econometrics	0	In natural language processing, recent years have seen ME techniques used for sentence boundary detection, part of speech tagging, parse selection and ambiguity resolution, and stochastic attribute-value grammars, to name just a few applications <REF>Abney, 1997</REF>; <REF>Berger et al , 1996</REF>; <REF>Ratnaparkhi, 1998</REF>; <TREF>Johnson et al , 1999</TREF>	1	A leading advantage of ME models is their flexibility: they allow stochastic rule systems to be augmented with additional syntactic, semantic, and pragmatic features	0	However, the richness of the representations is not without cost	0	6	1
W02-2018	P99-1069	2002	2 Maximum likelihood estimation Suppose we are given a probability distribution p over a set of events X which are characterized by a d dimensional feature vector function f : X Rd In addition, we have also a set of contexts W and a function Y which partitions the members of X In the case of a stochastic context-free grammar, for example, X might be the set of possible trees, the feature vectors might represent the number of times each rule applied in the derivation of each tree, W might be the set of possible strings of words, and Yw the set of trees whose yield is w2W	0	A conditional maximum entropy model qxjw for p has the parametric form <REF>Berger et al , 1996</REF>; <REF>Chi, 1998</REF>; <TREF>Johnson et al , 1999</TREF>: qxjw  exp T f x y2Yw expT f y 1 where  is a d-dimensional parameter vector and T f x is the inner product of the parameter vector and a feature vector	1	Given the parametric form of an ME model in 1, fitting an ME model to a collection of training data entails finding values for the parameter vector  which minimize the Kullback-Leibler divergence between the model q and the empirical distribution p: Dpjjq   w;x px;wlog pxjwq xjw or, equivalently, which maximize the log likelihood: L   w;x pw;xlogqxjw 2 The gradient of the log likelihood function, or the vector of its first derivatives with respect to the parameter  is: G  Ep f  Eq f  3 Since the likelihood function 2 is concave over the parameter space, it has a global maximum where the gradient is zero	0	Unfortunately, simply setting G  0 and solving for  does not yield a closed form solution, so we proceed iteratively	0	6	1
D07-1071	P99-1069	2007	23 Log-Linear CCGs We can generalize CCGs to weighted, or probabilistic, models as follows	0	Our models are similar to several other approaches <REF>Ratnaparkhi et al , 1994</REF>; <TREF>Johnson et al , 1999</TREF>; <REF>Lafferty et al , 2001</REF>; <REF>Collins, 2004</REF>; <REF>Taskar et al , 2004</REF>	1	We will write x to denote a sentence, and y to denote a CCG parse for a sentence	0	We use GENx; to refer to all possible CCG parses for x under some CCG lexicon 	0	6	1
W02-2030	P99-1069	2002	Therefore there are a large number of features available that could be used by stochastic models for disambiguation	0	Other researchers have worked on extracting features useful for disambiguation from unification grammar analyses and have built log linear models aka Stochastic Unification Based Grammars <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2000</REF>	0	Here we also use log linear models to estimate conditional probabilities of sentence analyses	1	Since feature selection is almost prohibitive for these models, because of high computational costs, we use PCFG models to select features for log linear models	0	3	2
N03-1033	P99-1069	2003	One is for a simple model with a relatively small number of features, and the other is for a model with a large number of features	0	The usefulness of priors in maximum entropy models is not new to this work: Gaussian prior smoothing is advocated in <REF>Chen and Rosenfeld 2000</REF>, and used in all the stochastic LFG work <TREF>Johnson et al , 1999</TREF>	0	However, until recently, its role and importance have not been widely understood	1	For example, <REF>Zhang and Oles 2001</REF> attribute the perceived limited success of logistic regression for text categorization to a lack of use of regularization	0	4	2
N03-1026	P99-1069	2003	After filtering by the generator, the remaining fstructures were weighted by the stochastic disambiguation component	0	Similar to stochastic disambiguation for constraint-based parsing <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2002</REF>, an exponential aka log-linear or maximumentropy probability model on transferred structures is estimated from a set of training data	1	The data for estimation consists of pairs of original sentences y and goldstandard summarized f-structures s which were manually selected from the transfer output for each sentence	0	For training data sj,yjmj1 and a set of possible summarized structures Sy for each sentence y, the objective was to maximize a discriminative criterion, namely the conditional likelihood L of a summarized f-structure given the sentence	0	2	2
P07-1104	P99-1069	2007	If on the other hand most features are noisy but at least weakly correlated with the target, it may be reasonable to attempt to reduce noise by averaging over all of the features	0	ME estimators with L2 regularization, which have been widely used in NLP tasks eg , <REF>Chen and Rosenfeld 2000</REF>; <REF>Charniak and Johnson 2005</REF>; <TREF>Johnson et al 1999</TREF>, tend to produce models that have this property	1	In addition, the perceptron algorithm and its variants, eg, the voted or averaged perceptron, is becoming increasingly popular due to their competitive performance, simplicity in implementation and low computational cost in training eg , <REF>Collins 2002</REF>	0	While recent studies claim advantages for L1 regularization, this study is the first of which we are aware to systematically compare it to a range of estimators on a diverse set of NLP tasks	0	6	1
J05-1003	P99-1069	2005	The problems with history-based models and the desire to be able to specify features as arbitrary predicates of the entire tree have been noted before	0	In particular, previous work <REF>Ratnaparkhi, Roukos, and Ward 1994</REF>; <REF>Abney 1997</REF>; Della Pietra, <REF>Della Pietra, and Lafferty 1997</REF>; <TREF>Johnson et al 1999</TREF>; <REF>Riezler et al 2002</REF> has investigated the use of Markov random fields MRFs or log-linear models as probabilistic models with global features for parsing and other NLP tasks	1	Log-linear models are often referred to as maximum-entropy models in the NLP literature	0	Similar methods have also been proposed for machine translation <REF>Och and Ney 2002</REF> and language understanding in dialogue systems <REF>Papineni, Roukos, and Ward 1997, 1998</REF>	0	6	1
W08-2102	P99-1069	2008	Experiments on the Penn WSJ treebank show that the model achieves state-of-the-art performance, for both constituent and dependency accuracy	0	In global linear models GLMs for structured prediction, eg, <TREF>Johnson et al, 1999</TREF>; <REF>Lafferty et al, 2001</REF>; <REF>Collins, 2002</REF>; <REF>Altun et al, 2003</REF>; <REF>Taskar et al, 2004</REF>, the optimal label y for an input x is y  arg max yYx w fx,y 1 where Yx is the set of possible labels for the input x; fx,y  Rd is a feature vector that represents the pair x,y; and w is a parameter vector	0	This paper describes a GLM for natural language parsing, trained using the averaged perceptron	1	The parser we describe recovers full syntactic representations, similar to those derived by a probabilistic context-free grammar PCFG	0	5	2
W08-2102	P99-1069	2008	This section describes the relationship between our work and this previous work	0	In reranking approaches, a first-pass parser is used to enumerate a small set of candidate parses for an input sentence; the reranking model, which is a GLM, is used to select between these parses eg, <REF>Ratnaparkhi et al, 1994</REF>; <TREF>Johnson et al, 1999</TREF>; <REF>Collins, 2000</REF>; <REF>Charniak and Johnson, 2005</REF>	0	A crucial advantage of our approach is that it considers a very large set of alternatives in Yx, and can thereby avoid search errors that may be made in the first-pass parser1 Another approach that allows efficient training of GLMs is to use simpler syntactic representations, in particular dependency structures McDon1Some features used within reranking approaches may be difficult to incorporate within dynamic programming, but it is nevertheless useful to make use of GLMs in the dynamicprogramming stage of parsing	1	Our parser could, of course, be used as the first-stage parser in a reranking approach	0	5	2
W07-1203	P99-1069	2007	Moreover, property design can be carried out in a targeted way, ie properties can be designed in order to improve the disambiguation of grammatical relations that, so far, are disambiguated particularly poorly or that are of special interest for the task that the systems output is used for	0	By demonstrating that property design is the key to good log-linear models for deepsyntactic disambiguation, our work confirms that specifying the features of a SUBG stochastic unification-based grammar is as much an empirical matter as specifying the grammar itself<TREF>Johnson et al , 1999</TREF>	1	Acknowledgements The work described in this paper has been carried out in the DLFG project, which was funded by the German Research Foundation DFG	0	Furthermore, I thank the audiences at several ParGram meetings, at the Research Workshop of the Israel Science Foundation on Large-scale Grammar Development and Grammar Engineering at the University of Haifa and at the SFB 732 Opening Colloquium in Stuttgart for their important feedback on earlier versions of this work	0	4	2
W07-2208	P99-1069	2007	Note that HPSG is one of the lexicalized grammar formalisms, in which lexical entries determine the dominant syntactic structures	0	Previous studies <REF>Abney, 1997</REF>; <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2000</REF>; Malouf and van <REF>Noord, 2004</REF>; <REF>Kaplan et al , 2004</REF>; <REF>Miyao and Tsujii, 2005</REF> defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model <REF>Berger et al , 1996</REF>	1	The probability that a parse result T is assigned to a given sentence w  w1,,wn is Probabilistic HPSG phpsgTw  1Z w exp parenleftBiggsummationdisplay u ufuT parenrightBigg Zw  summationdisplay Tprime exp parenleftBiggsummationdisplay u ufuTprime parenrightBigg, where u is a model parameter, fu is a feature function that represents a characteristic of parse tree T, and Zw is the sum over the set of all possible parse trees for the sentence	0	Intuitively, the probability is defined as the normalized product of the weights expu when a characteristic corresponding to fu appears in parse result T The model parameters, u, are estimated using numerical optimization methods <REF>Malouf, 2002</REF> to maximize the log-likelihood of the training data	0	6	1
W07-2208	P99-1069	2007	The main difficulty of developing parsers in these formalisms was how to model a well-defined probabilistic model for graph structures such as feature structures	0	This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model <REF>Berger et al , 1996</REF> with many features for parse trees <REF>Abney, 1997</REF>; <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2000</REF>; Malouf and van <REF>Noord, 2004</REF>; <REF>Kaplan et al , 2004</REF>; <REF>Miyao and Tsujii, 2005</REF>	1	Following this discriminative approach, techniques for efficiency were investigated for estimation <REF>Geman and Johnson, 2002</REF>; <REF>Miyao and Tsujii, 2002</REF>; Malouf and van <REF>Noord, 2004</REF> and parsing <REF>Clark and Curran, 2004b</REF>; <REF>Clark and Curran, 2004a</REF>; <REF>Ninomiya et al , 2005</REF>	0	An interesting approach to the problem of parsing efficiency was using supertagging Clark and Cur60 ran, 2004b; <REF>Clark and Curran, 2004a</REF>; <REF>Wang, 2003</REF>; <REF>Wang and Harper, 2004</REF>; <REF>Nasr and Rambow, 2004</REF>; <REF>Ninomiya et al , 2006</REF>; <REF>Foth et al , 2006</REF>; <REF>Foth and Menzel, 2006</REF>, which was originally developed for lexicalized tree adjoining grammars LTAG <REF>Bangalore and Joshi, 1999</REF>	0	6	1
P02-1035	P99-1069	2002	Firstly, the rudimentary character of functional annotations in standard treebanks has hindered the direct use of such data for statistical estimation of linguistically fine-grained statistical parsing systems	0	Rather, parameter estimation for such models had to resort to unsupervised techniques <REF>Bouma et al , 2000</REF>; <REF>Riezler et al , 2000</REF>, or training corpora tailored to the specific grammars had to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences <TREF>Johnson et al , 1999</TREF>	0	Furthermore, the effort involved in coding broadcoverage grammars by hand has often led to the specialization of grammars to relatively small domains, thus sacrificing grammar coverage ie the percentage of sentences for which at least one analysis is found on free text	0	The approach presented in this paper is a first attempt to scale up stochastic parsing systems based on linguistically fine-grained handcoded grammars to the UPenn Wall Street Journal henceforth WSJ treebank <REF>Marcus et al , 1994</REF>	1	5	2
P02-1035	P99-1069	2002	The clustering model itself is then used to yield smoothed probabilities as values for property functions on head-argument-relation tuples of LFG parses	0	32 Discriminative Estimation Discriminative estimation techniques have recently received great attention in the statistical machine learning community and have already been applied to statistical parsing <TREF>Johnson et al , 1999</TREF>; <REF>Collins, 2000</REF>; <REF>Collins and Duffy, 2001</REF>	1	In discriminative estimation, only the conditional relation of an analysis given an example is considered relevant, whereas in maximum likelihood estimation the joint probability of the training data to best describe observations is maximized	0	Since the discriminative task is kept in mind during estimation, discriminative methods can yield improved performance	0	6	1
P02-1062	P99-1069	2002	Recent work in statistical approaches to parsing and tagging has begun to consider methods which incorporate global features of candidate structures	0	Examples of such techniques are Markov Random Fields <REF>Abney 1997</REF>; Della <REF>Pietra et al 1997</REF>; <TREF>Johnson et al 1999</TREF>, and boosting algorithms <REF>Freund et al 1998</REF>; <REF>Collins 2000</REF>; <REF>Walker et al 2001</REF>	0	One appeal of these methods is their flexibility in incorporating features into a model: essentially any features which might be useful in discriminating good from bad structures can be included	1	A second appeal of these methods is that their training criterion is often discriminative, attempting to explicitly push the score or probability of the correct structure for each training sentence above the score of competing structures	0	1	2
P02-1062	P99-1069	2002	A second appeal of these methods is that their training criterion is often discriminative, attempting to explicitly push the score or probability of the correct structure for each training sentence above the score of competing structures	0	This discriminative property is shared by the methods of <TREF>Johnson et al 1999</TREF>; <REF>Collins 2000</REF>, and also the Conditional Random Field methods of <REF>Lafferty et al 2001</REF>	1	In a previous paper <REF>Collins 2000</REF>, a boosting algorithm was used to rerank the output from an existing statistical parser, giving significant improvements in parsing accuracy on Wall Street Journal data	0	Similar boosting algorithms have been applied to natural language generation, with good results, in <REF>Walker et al 2001</REF>	0	6	1
P02-1062	P99-1069	2002	The framework is derived by the transformation from ranking problems to a margin-based classification problem in <REF>Freund et al 1998</REF>	0	It is also related to the Markov Random Field methods for parsing suggested in <TREF>Johnson et al 1999</TREF>, and the boosting methods for parsing in <REF>Collins 2000</REF>	1	We consider the following set-up: a15 Training data is a set of example input/output pairs	0	In tagging we would have training examples a147 a71 a28 a30a37a17 a28a19a148 where each a71 a28 is a sentence and each a17 a28 is the correct sequence of tags for that sentence	0	6	1
P05-1011	P99-1069	2005	Experiments of the parsing of realworld sentences can properly evaluate the effectiveness and possibility of parsing models for HPSG	0	2 Disambiguation models for HPSG Discriminative log-linear models are now becoming a de facto standard for probabilistic disambiguation models for deep parsing <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2002</REF>; <REF>Geman and Johnson, 2002</REF>; <REF>Miyao and Tsujii, 2002</REF>; <REF>Clark and Curran, 2004b</REF>; <REF>Kaplan et al , 2004</REF>	1	Previous studies on probabilistic models for HPSG <REF>Toutanova and Manning, 2002</REF>; <REF>Baldridge and Osborne, 2003</REF>; Malouf and van <REF>Noord, 2004</REF> also adopted log-linear models	0	HPSG exploits feature structures to represent linguistic constraints	0	6	1
W03-1013	P99-1069	2003	Following Abney, we propose a loglinear framework which incorporates long-range dependencies as features without loss of consistency	0	Log-linear models have previously been applied to statistical parsing <TREF>Johnson et al , 1999</TREF>; <REF>Toutanova et al , 2002</REF>; <REF>Riezler et al , 2002</REF>; <REF>Osborne, 2000</REF>	0	Typically, these approaches have enumerated all possible parses for model estimation and finding the most probable parse	1	For grammars extracted from the Penn Treebank in our case CCGbank <REF>Hockenmaier, 2003</REF>, enumerating all parses is infeasible	0	4	2
W03-1019	P99-1069	2003	As expected, we observed that the regularization term increases the accuracy, especially when the training data is small; but we did not observe much difference when we used different regularization terms	0	The results we report are with the Gaussian prior regularization term described in <TREF>Johnson et al , 1999</TREF>	1	Our goal in this paper is not to build the best tagger or recognizer, but to compare different loss functions and optimization methods	0	Since we did not spend much effort on designing the most useful features, our results are slightly worse than, but comparable to the best performing models	0	3	2
P05-1022	P99-1069	2005	This method generates 50-best lists that are of substantially higher quality than previously obtainable	0	We used these parses as the input to a MaxEnt reranker <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2002</REF> that selects the best parse from the set of parses for each sentence, obtaining an f-score of 910 on sentences of length 100 or less	1	We describe a reranking parser which uses a regularized MaxEnt reranker to select the best parse from the 50-best parses returned by a generative parsing model	0	The 50-best parser is a probabilistic parser that on its own produces high quality parses; the maximum probability parse trees according to the parsers model have an f-score of 0897 on section 23 of the Penn Treebank <REF>Charniak, 2000</REF>, which is still state-of-the-art	0	3	2
W05-1511	P99-1069	2005	Given set W of words and set F of feature structures, an HPSG is formulated as a tuple, G  L,R, where L  l  w,Fw  W,F  F is a set of lexical entries, and R is a set of schemata, ie, r  R is a partial function: F F  F Given a sentence, an HPSG computes a set of phrasal signs, ie, feature structures, as a result of parsing	0	Previous studies <REF>Abney, 1997</REF>; <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2000</REF>; <REF>Miyao et al , 2003</REF>; Malouf and van <REF>Noord, 2004</REF>; <REF>Kaplan et al , 2004</REF>; <REF>Miyao and Tsujii, 2005</REF> defined a probabilistic model of unification-based grammars as a log-linear model or maximum entropy model <REF>Berger et al , 1996</REF>	1	The probability of parse result T assigned to given sentence w  w1,,,wn is pTw  1Z w exp parenleftBiggsummationdisplay i ifiT parenrightBigg Zw  summationdisplay T prime exp parenleftBiggsummationdisplay i ifiTprime parenrightBigg, where i is a model parameter, and fi is a feature function that represents a characteristic of parse tree T Intuitively, the probability is defined as the normalized product of the weights expi when a characteristic corresponding to fi appears in parse result T Model parameters i are estimated using numer104 ical optimization methods <REF>Malouf, 2002</REF> so as to maximize the log-likelihood of the training data	0	However, the above model cannot be easily estimated because the estimation requires the computation of pTw for all parse candidates assigned to sentence w Because the number of parse candidates is exponentially related to the length of the sentence, the estimation is intractable for long sentences	0	6	1
