The second instantiation finds the borders of phrases beginning and end and then pairs them in an optimal way into different phrases~~~These problems formulations are similar to those studied in <REF>Ramshaw and Marcus, 1995</REF> and <TREF>Church, 1988</TREF>; <REF>Argamon et al , 1998</REF>, respectively~~~The experimental results presented using the SNoW based approach compare favorably with previously published results, both for NPs and SV phrases~~~A s important, we present a few experiments that shed light on some of the issues involved in using learned predictors that interact to produce the desired inference.
Our earlier example would be marked for base NPs as: I wont to California last May~~~This approach has been studied in <TREF>Church, 1988</TREF>; <REF>Argamon et al , 1998</REF>~~~331 Architecture The architecture used for the Open/Close predictors is shown in Figure 2~~~Two SNoW predictors are used, one to predict if the word currently in consideration is the first in the phrase an open bracket, and the other to predict if it is the last a close bracket.
A lot of the work on shallow parsing over the past years has concentrated on manual construction of rules~~~The observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local part-of-speech information has motivated the use of learning methods to recognize these patterns <TREF>Church, 1988</TREF>; <REF>Ramshaw and Marcus, 1995</REF>; <REF>Argamon et al , 1998</REF>; <REF>Cardie and Pierce, 1998</REF>~~~ Research supported by NSF grants IIS-9801638 and SBR-9873450~~~t Research supported by NSF grant CCR-9502540.
HMMs have long been central in speech recognition <REF>Rabiner, 1989</REF>~~~Their application to partof-speech tagging <TREF>Church, 1988</TREF>; <REF>DeRose, 1988</REF> kicked off the era of statistical NLP, and they have found additional NLP applications to phrase chunking, text segmentation, word-sense disambiguation, and information extraction~~~The algorithm is also important to teach for pedagogical reasons, as the entry point to a family of EM algorithms for unsupervised parameter estimation~~~Indeed, it is an instructive special case of 1 the inside-outside algorithm for estimation of probabilistic context-free grammars; 2 belief propagation for training singly-connected Bayesian networks and junction trees <REF>Pearl, 1988</REF>; <REF>Lauritzen, 1995</REF>; 3 algorithms for learning alignment models such as weighted edit distance; 4 general finitestate parameter estimation <REF>Eisner, 2002</REF>.
Subsequent analysis suggested that half the errors could be removed with only a little additional work, suggesting that over 90 performance is achievable~~~In a related test, we explored the bracketings produced by Churchs PARTS program <TREF>Church, 1988</TREF>~~~We extracted 200 sentences of WSJ text by taking every tenth sentence from a collection of manually corrected parse trees data from the TREEBANK Project at the University of Pennsylvania~~~We evaluated the NP bracketings in these 200 sentences by hand, and tried to classify the errors.
Given that each token has on the average more than 2 possible tags, the procedural description above is very inefficient for all but very short sentences~~~However, the observation that our constraints are localized to a window of a small number of tokens say at most 5 tokens in a sequence, suggests a more efficient scheme originally used by <TREF>Church 1988</TREF>~~~Assume our constraint windows are allowed to look at a window of at most size k sequential parses~~~Let us take the first k tokens of a sentence and generate all possible paths of k arcs spanning k  1 nodes, and apply all constraints to these short paths.
Part-of-speech tagging is one of the preliminary steps in many natural language processing systems in which the proper part-of-speech tag of the tokens comprising the sentences are disambiguated using either statistical or symbolic local contextual information~~~Tagging systems have used either a statistical approach where a large corpora is employed to train a probabilistic model which then is used to tag unseen text, eg , <TREF>Church 1988</TREF>, Cutting et al~~~1992, <REF>DeRose 1988</REF>, or a constraint-based approach which employs a large number of hand-crafted linguistic constraints that are used to eliminate impossible sequences or morphological parses for a given word in a given context, recently most prominently exemplified by the Constraint Grammar work <REF>Karlsson et al , 1995</REF>; <REF>Voutilainen, 1995b</REF>; <REF>Voutilainen et al , 1992</REF>; <REF>Voutilainen and Tapanainen, 1993</REF>~~~BriU 1992; 1994; 1995 has presented a transformationbased learning approach.
 Right close double quote 231 Automated Stage~~~During the early stages of the Penn Treebank project, the initial automatic POS assignment was provided by PARTS <TREF>Church 1988</TREF>, a stochastic algorithm developed at ATT Bell Labs~~~PARTS uses a modified version of the Brown Corpus tagset close to our own and assigns POS tags with an error rate of 3-5~~~The output of PARTS was automatically tokenized 8 and the tags assigned by PARTS were automatically mapped onto the Penn Treebank tagset.
Various methods for POS tagging have been proposed in recent years~~~For simplicity, we adapted the method proposed by <REF>Churchl1988</REF> to tag the definition sentence~~~In the second stage, we select the label which is associated with word lists most similar to the definition as the result~~~We sum up the above descriptions and outline the procedure for labeling a dictionary sense.
The experimental results show the proposed method significantly outperforms both hand-crafted and conventional statistical methods~~~The last few years have seen the great success of stochastic part-of-speech POS taggers <TREF>Church, 1988</TREF>: <REF>Kupiec, 1992</REF>; Charniak et M , 1993; <REF>Brill, 1992</REF>; <REF>Nagata, 1994</REF>~~~The stochastic approach generally attains 94 to 96 accuracy and replaces the labor-intensive compilation of linguistics rules by using an automated learning algorithm~~~However, 1NTT is an abbreviation of Nippon Telegraph and Telephone Corporation.
1~~~A recent trend in natural language processing has been toward a greater emphasis on statistical approaches, beginning with the success of statistical part-of-speech tagging programs <TREF>Church 1988</TREF>, and continuing with other work using statistical part-of-speech tagging programs, such as BBN PLUM <REF>Weischedel et al 1993</REF> and NYU Proteus <REF>Grishman and Sterling 1993</REF>~~~More recently, statistical methods have been applied to domain-specific semantic parsing <REF>Miller et al 1994</REF>, and to the more difficult problem of wide-coverage syntactic parsing <REF>Magerman 1995</REF>~~~Nevertheless, most natural language systems remain primarily rule based, and even systems that do use statistical techniques, such as ATT Chronus <REF>Levin and Pieraccini 1995</REF>, continue to require a significant rule based component.
The training is performed on ambiguity classes and not on individual word tokens~~~<REF>Kallgren 1996</REF> gives a more covering description of how XPOST is used on the Swedish material and also sketches the major differences between this algorithm and some others used for tagging, such as PARTS <TREF>Church 1988</TREF> and VOLSUNGA <REF>DeRose 1988</REF>~~~A characteristic tbature of the SUC is its high number of different tags~~~The number of part-ofspeech tags used in the SUC is 21.
Disambiguation of capitalized words is usually handled by POS taggers, which treat capitalized words in the same way as other categories, that is, by accounting for the immediate syntactic context and using estimates collected from a training corpus~~~<REF>As Church 1988</REF> rightly pointed out, however, Proper nouns and capitalized words are particularly problematic: some capitalized words are proper nouns and some are not~~~Estimates from the Brown Corpus can be misleading~~~For example, the capitalized word Acts is found twice in the Brown Corpus, both times as a proper noun in a title.
The morphological ambiguity will differ depending on the level of tagging used in each case, as shown in table 2~~~There are two kinds of methods for morphological disambiguation: on one hand, statistical methods need little effort and obtain very good results <TREF>Church, 1988</TREF>; Cutting el al, 1992, at least when applied to English, but when we try to apply them to Basque we encounter additional problems; on the other hand, some rule-based systems <REF>Brill, 1992</REF>; <REF>Voutilainen et al, 1992</REF> are at least as good as statistical systems and are better adapted to free-order languages and agglutinative languages~~~So, we 381 have selected one of each group: Constraint Grammar formalism <REF>Karlsson et al, 1995</REF> and the HMM based TATOO tagger <REF>Armstrong et al, 1995</REF>, which has been designed to be applied it to the output of a morphological analyser and the tagset can be switched easily without changing the input text~~~second  third 70 ks I M M MCG MCG Figure 1-Initial ambiguity3.
We are tagging this material with a much simpler tagset than used by previous projects, as discussed at the Oct 1989 DARPA Workshop~~~The material is first processed using Ken Churchs tagger <TREF>Church 1988</TREF>, which labels it as if it were Brown Corpus material, and then is mapped to our tagset by a SEDscript~~~Because of fundamental differences in tagging strategy between the Penn Treebank Project and the Brown project, the resulting mapping is about 9 inaccurate, given the tagging guidelines of the Penn Treebank project as given in 40 pages of explicit tagging guidelines~~~This material is then hand-corrected by our annotators; the result is consistent within annotators to about 3 cf.
H90-1055:17~~~Deducing Linguistic Structure from the Statistics of Large Corpora Eric Brill David Magerman Mitchell Marcus Beatrice Santorini Department of Computer and Information Science University of Pennsylvania Philadelphia, PA 19104 1 Introduction Within the last two years, approaches using both stochastic and symbolic techniques have proved adequate to deduce lexical ambiguity resolution rules with less than 3-4 error rate, when trained on moderate sized 500K word corpora of English text eg <TREF>Church, 1988</TREF>; <REF>Hindle, 1989</REF>~~~The success of these techniques suggests that much of the grammatical structure of language may be derived automatically through distributional analysis, an approach attempted and abandoned in the 1950s~~~We describe here two experiments to see how far purely distributional techniques can be pushed to automatically provide both a set of part of speech tags for English, and a grammatical analysis of free English text.
This line of research was motivated by a series of successful applications of mutual information statistics to other problems in natural language processing~~~In the last decade, research in speech recognition <REF>Jelinek 1985</REF>, noun classification <REF>Hindle 1988</REF>, predicate argument relations <REF>Church  Hanks 1989</REF>, and other areas have shown that mutual information statistics provide a wealth of information for solving these problems~~~22 Mutual Information Statistics The mutual information statistic <REF>Fano 1961</REF> is a measure of the interdependence of two signals in a message~~~It is a function of the probabilities of the two events: Mz, u  log u xzPvy In this paper, the events x and y will be part-of-speech n-grams instead of single parts-of-speech, as in some earlier work.
Each of these three steps will be described below~~~3 The preprocessing stage The noun phrase parser identifies simple non-recursive noun phrases such as DetAdjN or NN The method used for this process involves an algorithm of the type described in <TREF>Church 1988</TREF> which was trained on a manually marked part of our corpus~~~The module is thus geared to the particular type of second language text the checker needs to deal with~~~The resulting information is passed on to a preprocessing module consisting of a number of automata groups.
Measures/NNS of/IN manufacturing/VBG activity/NN fell/VBD more/RBR than/IN the/DT overall/JJ measures/NNS/~~~Figure 1: An example sentence with baseNP brackets A number of researchers have dealt with the problem of baseNP identification <TREF>Church 1988</TREF>; <REF>Bourigault 1992</REF>; <REF>Voutilainen 1993</REF>; <REF>Justeson  Katz 1995</REF>~~~Recently some researchers have made experiments with the same test corpus extracted from the 20 th section of the Penn Treebank Wall Street Journal Penn Treebank~~~<REF>Ramshaw  Markus 1998</REF> applied transformbased error-driven algorithm <REF>Brill 1995</REF> to learn a set of transformation rules, and using those rules to locally updates the bracket positions.
4 Concluding remarks Though there can be little doubt that the ruling system of bakeoffs actively encourages a degree of oneupmanship, our paper and our software are not offered in a competitive spirit~~~As we said at the out211 set, we dont necessarily believe HunPos to be in any way better than TnT, and certainly the main ideas have been pioneered by <REF>DeRose 1988</REF>, <TREF>Church 1988</TREF>, and others long before this generation of HMM work~~~But to improve the results beyond what a basic HMM can achieve one needs to tune the system, and progress can only be made if the experiments are end to end replicable~~~There is no doubt many other systems could be tweaked further and improve on our results what matters is that anybody could now also tweak HunPos without any restriction to improve the state of the art.
In this paper we describe experiments we performed to ascertain how well humans, given an annotated training set, can generate rules for base noun phrase chunking~~~Much previous work has been done on this problem and many different methods have been used: Churchs PARTS 1988 program uses a Markov model; <REF>Bourigault 1992</REF> uses heuristics along with a grammar; Voutilainens NP<REF>Tool 1993</REF> uses a lexicon combined with a constraint grammar; <REF>Juteson and Katz 1995</REF> use repeated phrases; <REF>Veenstra 1998</REF>, Argamon, Dagan  <REF>Krymolowski1998</REF> and Daelemaus, van den <REF>Bosch  Zavrel 1999</REF> use memory-based systems; Ramshaw  Marcus In Press and <REF>Cardie  Pierce 1998</REF> use rule-based systems~~~2 Learning Base Noun Phrases by Machine We used the base noun phrase system of Ramshaw and Marcus RM as the machine learning system with which to compare the human learners~~~It is difficult to compare different machine learning approaches to base NP annotation, since different definitions of base NP are used in many of the papers, but the RM system is the best of those that have been tested on the Penn Treebank.
The suggestion which we want to explore is that the association revealed by textual distribution whether its source is a complementation relation, a modification relation, or something else gives us information needed to resolve the prepositional attachment~~~Discovering Lexical Association in Text A 13 million word sample of Associated Press new stories from 1989 were automatically parsed by the Fidditch parser <REF>Hindle 1983</REF>, using Churchs part of speech analyzer as a preprocessor <TREF>Church 1988</TREF>~~~From the syntactic analysis provided by the parser for each sentence, we extracted a table containing all the heads of all noun phrases~~~For each noun phrase head, we recorded the following preposition if any occurred ignoring whether or not the parser attached the preposition to the noun phrase, and the preceding verb if the noun phrase was the object of that verb.
We also looked at whether the token constituted an entire intermediate or intonational phrase--possibly with other cue phrases--or not, and what each tokens position within its intermediate phrase and larger intonational phrase was--first-inphrase again, including tokens preceded only by other cue phrases as well as tokens that were absolutely first in intermediate phrase, last, or other~~~We also examined each items part of speech, using Churchs 1988 part-of-speech tagger~~~Finally, we investigated orthographic features of the transcript that might be associated with a discourse/sentential distinction, such as immediately preceding and succeeding punctuation and paragraph boundaries~~~In both the syntactic and orthographic analyses we were particularly interested in discovering how successful nonprosodic features that might be obtained automatically from a text would be in differentiating discourse from sentential uses.
While the use of orthographic and part-of-speech data represents only a fractional improvement over orthographic information alone, it is possible that, since the latter is not subject to transcriber idiosyncracy, such an approach may prove more reliable than orthography alone in the general case~~~And, for text-to-speech applications, it 7 The parbof-speech tagger employed in this analysis <TREF>Church 1988</TREF> uses a subset of the part-of-speech tags used in Francis and Kuera 1982~~~We have translated these for Table 12~~~Note that intensifier corresponds to QU in Francis and Kuera 1982.
Research on corpus-based natural language learning and processing is rapidly accelerating following the introduction of large on-line corpora, faster computers, and cheap storage devices~~~Recent work involves novel ways to employ annotated corpus in part of speech tagging <TREF>Church 1988</TREF> <REF>Derose 1988</REF> and the application of mutual information statistics on the corpora to uncover lexical information <REF>Church 1989</REF>~~~The goal of the research is the construction of robust and portable natural language processing systems~~~The wide range of topics available on the Internet calls for an easily adaptable information extraction system for different domains.
Part-of-speech tagging is to assign the correct tag to each word in the context of the sentence~~~here are three main approaches in tagging problem: rule-based approach Klein and Simmons 13; <REF>Brodda 1982</REF>; <REF>Paulussen and Martin 1992</REF>; <REF>Brill et al 1990</REF>, statistical approach Church :1988; <REF>Merialdo 1994</REF>; <REF>Foster 1991</REF>; <REF>Weischedel et al 1993</REF>; <REF>Kupiec 1992</REF> and connectionist approach <REF>Benello et al 1989</REF>; <REF>Nakanmra et al 1989</REF>~~~In these approaches, statistical approach has the following advantages :  a theoretical framework is provided  automatic learning facility is provided  the probabilities provide a straightforward way to disambiguate Many information sources must be combined to solve tagging problem with statistical approach~~~It is a significant assumption that tire correct tag can generally be chosen from Ihe local context.
In this study, we measure performance solely through the cross-entropy of test data; it would be interesting to see how these cross-entropy differences correlate with performance in end applications such as speech recognition~~~In addition, it would be interesting to see whether these results extend to fields other than language modeling where smoothing is used, such as prepositional phrase attachment <REF>Collins and Brooks, 1995</REF>, part-of-speech tagging <TREF>Church, 1988</TREF>, and stochastic parsing <REF>Magerman, 1994</REF>~~~317 Acknowledgements The authors would like to thank Stuart Shieber and the anonymous reviewers for their comments on previous versions of this paper~~~We would also like to thank William Gale and Geoffrey Sampson for supplying us with code for Good-Turing frequency estimation without tears.
In addition, we introduce two novel smoothing techniques, one a variation of Jelinek-Mercer smoothing and one a very simple linear interpolation technique, both of which outperform existing methods~~~Smoothing is a technique essential in the construction of n-gram language models, a staple in speech recognition <REF>Bahl, Jelinek, and Mercer, 1983</REF> as well as many other domains <TREF>Church, 1988</TREF>; <REF>Brown et al , 1990</REF>; <REF>Kernighan, Church, and Gale, 1990</REF>~~~A language model is a probability distribution over strings Ps that attempts to reflect the frequency with which each string s occurs as a sentence in natural text~~~Language models are used in speech recognition to resolve acoustically ambiguous utterances.
In practice, computational limitations do not allow the enumeration of all possible assignments for long sentences, and smoothing is required for infrequent events~~~This is described in more detail in the original publication <TREF>Church, 1988</TREF>~~~Although more sophisticated algorithms for unsupervised learning which can be trained on plain text instead on manually tagged corpora are well established see eg <REF>Merialdo, 1994</REF>, we decided not to use them~~~The main reason is that with large tag sets, the sparse-data-problem can become so severe that unsupervised training easily ends up in local minima, which can lead to poor results without any indication to the user.
<REF>Lezius, Rapp  Wettler 1996</REF> give an overview on some German tagging projects~~~Although we considered a number of algorithms, we decided to use the trigram algorithm described by <TREF>Church 1988</TREF> for tagging~~~It is simple, fast, robust, and among the statistical taggers still more or less unsurpassed in terms of accuracy~~~Conceptually, the Church-algorithm works as follows: For each sentence of a text, it generates all possible assignments of part-of-speech tags to words.