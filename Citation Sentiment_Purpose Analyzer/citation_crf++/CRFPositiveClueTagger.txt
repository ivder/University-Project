given VBN
that IN
each DT
token NN
has VBZ
on IN
the DT
average NN
more JJR
than IN
2 CD
possible JJ
tags NNS
, ,
the DT
procedural JJ
description NN
above IN
is VBZ
very RB
inefficient JJ
for IN
all DT
but CC
very RB
short JJ
sentences NNS
. .

however RB
, ,
the DT
observation NN
that IN
our PRP$
constraints NNS
are VBP
localized VBN
to TO
a DT
window NN
of IN
a DT
small JJ
number NN
of IN
tokens NNS
say VBP
at IN
most JJS
5 CD
tokens NNS
in IN
a DT
sequence NN
, ,
suggests VBZ
a DT
more RBR
efficient JJ
scheme NN
originally RB
used VBN
by IN
< JJ
tref NN
> NNP
church NN
1988 CD
< NNP
/tref NNP
> NNP
. .

the DT
last JJ
few JJ
years NNS
have VBP
seen VBN
the DT
great JJ
success NN
of IN
stochastic JJ
part-of-speech JJ
pos NN
taggers NNS
< VBP
tref JJ
> NNP
church NN
, ,
1988 CD
< NN
/tref CC
> NN
: :
< JJ
ref NN
> NNP
kupiec NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
charniak NN
et FW
m NN
, ,
1993 CD
; :
< CC
ref VB
> NNP
brill NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
nagata NN
, ,
1994 CD
< NN
/ref NNP
> NNP
. .

the DT
stochastic JJ
approach NN
generally RB
attains VBZ
94 CD
to TO
96 CD
accuracy NN
and CC
replaces VBZ
the DT
labor-intensive JJ
compilation NN
of IN
linguistics NNS
rules NNS
by IN
using VBG
an DT
automated VBN
learning NN
algorithm NN
. .

a DT
recent JJ
trend NN
in IN
natural JJ
language NN
processing NN
has VBZ
been VBN
toward IN
a DT
greater JJR
emphasis NN
on IN
statistical JJ
approaches NNS
, ,
beginning VBG
with IN
the DT
success NN
of IN
statistical JJ
part-of-speech JJ
tagging NN
programs NNS
< VBP
tref JJ
> NNP
church NN
1988 CD
< NNP
/tref NNP
> NNP
, ,
and CC
continuing VBG
with IN
other JJ
work NN
using VBG
statistical JJ
part-of-speech JJ
tagging NN
programs NNS
, ,
such JJ
as IN
bbn NN
plum NN
< NNP
ref NN
> NNP
weischedel NN
et NN
al NN
1993 CD
< NNP
/ref NNP
> NNP
and CC
nyu JJ
proteus NN
< NNP
ref NN
> NNP
grishman NN
and CC
sterling NN
1993 CD
< NNP
/ref NNP
> NNP
. .

nevertheless RB
, ,
most JJS
natural JJ
language NN
systems NNS
remain VBP
primarily RB
rule NN
based VBN
, ,
and CC
even RB
systems NNS
that WDT
do VBP
use VB
statistical JJ
techniques NNS
, ,
such JJ
as IN
att JJ
chronus NN
< NNP
ref NN
> NNP
levin NN
and CC
pieraccini NN
1995 CD
< NNP
/ref NNP
> NNP
, ,
continue VBP
to TO
require VB
a DT
significant JJ
rule NN
based VBN
component NN
. .

disambiguation NN
of IN
capitalized JJ
words NNS
is VBZ
usually RB
handled VBN
by IN
pos NN
taggers NNS
, ,
which WDT
treat VBP
capitalized VBN
words NNS
in IN
the DT
same JJ
way NN
as IN
other JJ
categories NNS
, ,
that DT
is VBZ
, ,
by IN
accounting VBG
for IN
the DT
immediate JJ
syntactic JJ
context NN
and CC
using VBG
estimates NNS
collected VBN
from IN
a DT
training NN
corpus NN
. .

< JJ
ref NN
> NN
as IN
church NN
1988 CD
< NNP
/ref NNP
> NNP
rightly RB
pointed VBD
out RP
, ,
however RB
, ,
proper JJ
nouns NNS
and CC
capitalized VBN
words NNS
are VBP
particularly RB
problematic JJ
: :
some DT
capitalized JJ
words NNS
are VBP
proper JJ
nouns NNS
and CC
some DT
are VBP
not RB
. .

for IN
example NN
, ,
the DT
capitalized JJ
word NN
acts VBZ
is VBZ
found VBN
twice RB
in IN
the DT
brown JJ
corpus NN
, ,
both DT
times NNS
as IN
a DT
proper JJ
noun NN
in IN
a DT
title NN
. .

the DT
morphological JJ
ambiguity NN
will MD
differ VB
depending VBG
on IN
the DT
level NN
of IN
tagging VBG
used VBN
in IN
each DT
case NN
, ,
as IN
shown VBN
in IN
table JJ
2 CD
. .

there EX
are VBP
two CD
kinds NNS
of IN
methods NNS
for IN
morphological JJ
disambiguation NN
: :
on IN
one CD
hand NN
, ,
statistical JJ
methods NNS
need VBP
little JJ
effort NN
and CC
obtain VB
very RB
good JJ
results NNS
< VBP
tref JJ
> NNP
church NN
, ,
1988 CD
< NN
/tref NNP
> NNP
; :
cutting VBG
el NN
al NN
, ,
1992 CD
, ,
at IN
least JJS
when WRB
applied VBN
to TO
english VB
, ,
but CC
when WRB
we PRP
try VBP
to TO
apply VB
them PRP
to TO
basque VB
we PRP
encounter VBP
additional JJ
problems NNS
; :
on IN
the DT
other JJ
hand NN
, ,
some DT
rule-based JJ
systems NNS
< MD
ref VB
> NNP
brill NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
voutilainen NN
et NN
al NN
, ,
1992 CD
< NN
/ref NNP
> NN
are VBP
at IN
least JJS
as RB
good JJ
as IN
statistical JJ
systems NNS
and CC
are VBP
better RB
adapted VBN
to TO
free-order JJ
languages NNS
and CC
agglutinative JJ
languages NNS
. .

so RB
, ,
we PRP
381 CD
have VBP
selected VBN
one CD
of IN
each DT
group NN
: :
constraint NN
grammar NN
formalism NN
< NNP
ref NN
> NNP
karlsson NNP
et FW
al NN
, ,
1995 CD
< NN
/ref NNP
> NNP
and CC
the DT
hmm NN
based VBN
tatoo RB
tagger JJ
< NNP
ref NN
> NNP
armstrong RB
et RB
al NN
, ,
1995 CD
< NN
/ref NNP
> NNP
, ,
which WDT
has VBZ
been VBN
designed VBN
to TO
be VB
applied VBN
it PRP
to TO
the DT
output NN
of IN
a DT
morphological JJ
analyser NN
and CC
the DT
tagset NN
can MD
be VB
switched VBN
easily RB
without IN
changing VBG
the DT
input NN
text NN
. .

because IN
of IN
fundamental JJ
differences NNS
in IN
tagging VBG
strategy NN
between IN
the DT
penn NN
treebank NN
project NN
and CC
the DT
brown NN
project NN
, ,
the DT
resulting VBG
mapping NN
is VBZ
about IN
9 CD
inaccurate NN
, ,
given VBN
the DT
tagging VBG
guidelines NNS
of IN
the DT
penn NN
treebank NN
project NN
as IN
given VBN
in IN
40 CD
pages NNS
of IN
explicit JJ
tagging VBG
guidelines NNS
. .

this DT
material NN
is VBZ
then RB
hand-corrected VBN
by IN
our PRP$
annotators NNS
; :
the DT
result NN
is VBZ
consistent JJ
within IN
annotators NNS
to TO
about IN
3 CD
cf NN
. .

deducing VBG
linguistic JJ
structure NN
from IN
the DT
statistics NNS
of IN
large JJ
corpora NNS
eric VBP
brill NN
david JJ
magerman NN
mitchell NN
marcus VB
beatrice NN
santorini JJ
department NN
of IN
computer NN
and CC
information NN
science NN
university NN
of IN
pennsylvania NN
philadelphia NN
, ,
pa VBD
19104 CD
1 CD
introduction NN
within IN
the DT
last JJ
two CD
years NNS
, ,
approaches VBZ
using VBG
both DT
stochastic JJ
and CC
symbolic JJ
techniques NNS
have VBP
proved VBN
adequate JJ
to TO
deduce VB
lexical JJ
ambiguity NN
resolution NN
rules NNS
with IN
less JJR
than IN
3-4 JJ
error NN
rate NN
, ,
when WRB
trained VBN
on IN
moderate JJ
sized VBN
500k CD
word NN
corpora NN
of IN
english JJ
text NN
eg NN
< NNP
tref NN
> NNP
church NN
, ,
1988 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
hindle NN
, ,
1989 CD
< NN
/ref NNP
> NNP
. .

the DT
success NN
of IN
these DT
techniques NNS
suggests VBZ
that IN
much JJ
of IN
the DT
grammatical JJ
structure NN
of IN
language NN
may MD
be VB
derived VBN
automatically RB
through IN
distributional JJ
analysis NN
, ,
an DT
approach NN
attempted VBD
and CC
abandoned VBD
in IN
the DT
1950s CD
. .

we PRP
describe VBP
here RB
two CD
experiments NNS
to TO
see VB
how WRB
far RB
purely RB
distributional JJ
techniques NNS
can MD
be VB
pushed VBN
to TO
automatically RB
provide VB
both DT
a DT
set NN
of IN
part NN
of IN
speech NN
tags NNS
for IN
english JJ
, ,
and CC
a DT
grammatical JJ
analysis NN
of IN
free JJ
english JJ
text NN
. .

this DT
line NN
of IN
research NN
was VBD
motivated VBN
by IN
a DT
series NN
of IN
successful JJ
applications NNS
of IN
mutual JJ
information NN
statistics NNS
to TO
other JJ
problems NNS
in IN
natural JJ
language NN
processing NN
. .

in IN
the DT
last JJ
decade NN
, ,
research NN
in IN
speech NN
recognition NN
< NNP
ref NN
> NNP
jelinek NN
1985 CD
< NNP
/ref NNP
> NNP
, ,
noun JJ
classification NN
< NNP
ref NN
> NNP
hindle NN
1988 CD
< NNP
/ref NNP
> NNP
, ,
predicate NN
argument NN
relations NNS
< VBP
ref NN
> NNP
church NN
hanks NNS
1989 CD
< NNP
/ref NNP
> NNP
, ,
and CC
other JJ
areas NNS
have VBP
shown VBN
that IN
mutual JJ
information NN
statistics NNS
provide VBP
a DT
wealth NN
of IN
information NN
for IN
solving VBG
these DT
problems NNS
. .

it PRP
is VBZ
a DT
function NN
of IN
the DT
probabilities NNS
of IN
the DT
two CD
events NNS
: :
mz NN
, ,
u JJ
log NN
u JJ
xzpvy NN
in IN
this DT
paper NN
, ,
the DT
events NNS
x NN
and CC
y NN
will MD
be VB
part-of-speech JJ
n-grams JJ
instead RB
of IN
single JJ
parts-of-speech NN
, ,
as IN
in IN
some DT
earlier JJR
work NN
. .

4 CD
concluding VBG
remarks NNS
though IN
there EX
can MD
be VB
little JJ
doubt NN
that IN
the DT
ruling NN
system NN
of IN
bakeoffs NNS
actively RB
encourages VBZ
a DT
degree NN
of IN
oneupmanship NN
, ,
our PRP$
paper NN
and CC
our PRP$
software NN
are VBP
not RB
offered VBN
in IN
a DT
competitive JJ
spirit NN
. .

as IN
we PRP
said VBD
at IN
the DT
out211 NN
set VBN
, ,
we PRP
dont VBP
necessarily RB
believe VB
hunpos NN
to TO
be VB
in IN
any DT
way NN
better JJR
than IN
tnt NN
, ,
and CC
certainly RB
the DT
main JJ
ideas NNS
have VBP
been VBN
pioneered VBN
by IN
< NNP
ref NN
> NNP
derose NN
1988 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
tref NN
> NNP
church NN
1988 CD
< NNP
/tref NNP
> NNP
, ,
and CC
others NNS
long RB
before IN
this DT
generation NN
of IN
hmm JJ
work NN
. .

but CC
to TO
improve VB
the DT
results NNS
beyond IN
what WP
a DT
basic JJ
hmm NN
can MD
achieve VB
one CD
needs VBZ
to TO
tune VB
the DT
system NN
, ,
and CC
progress NN
can MD
only RB
be VB
made VBN
if IN
the DT
experiments NNS
are VBP
end NN
to TO
end VB
replicable NN
. .

there EX
is VBZ
no DT
doubt NN
many JJ
other JJ
systems NNS
could MD
be VB
tweaked VBN
further JJ
and CC
improve VB
on IN
our PRP$
results NNS
what WP
matters VBZ
is VBZ
that IN
anybody NN
could MD
now RB
also RB
tweak VBP
hunpos NNS
without IN
any DT
restriction NN
to TO
improve VB
the DT
state NN
of IN
the DT
art NN
. .

thus RB
, ,
examples VBZ
3-5 JJ
illustrate NN
how WRB
the DT
syntactic JJ
context NN
of IN
a DT
word NN
can MD
help VB
determine VB
its PRP$
meaning NN
. .

22 CD
motivation NN
from IN
previous JJ
work NN
221 CD
parsing NN
in IN
recent JJ
years NNS
, ,
the DT
success NN
of IN
statistical JJ
parsing VBG
techniques NNS
can MD
be VB
attributed VBN
to TO
several JJ
factors NNS
, ,
such JJ
as IN
the DT
increasing VBG
size NN
of IN
computing VBG
machinery NN
to TO
accommodate VB
larger JJR
models NNS
, ,
the DT
availability NN
of IN
resources NNS
such JJ
as IN
the DT
penn NN
treebank NN
< NNP
ref NN
> NNP
marcus NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
and CC
the DT
success NN
of IN
machine NN
learning VBG
techniques NNS
for IN
lowerlevel JJ
nlp NN
problems NNS
, ,
such JJ
as IN
part-of-speech JJ
tagging VBG
< JJ
tref NN
> NNP
church NN
, ,
1988 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
brill NN
, ,
1995 CD
< NN
/ref NNP
> NNP
, ,
and CC
ppattachment JJ
< NNP
ref NN
> NNP
brill NN
and CC
resnik NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
collins NNS
and CC
brooks NNS
, ,
1995 CD
< NN
/ref NNP
> NNP
. .

however RB
, ,
perhaps RB
even RB
more RBR
significant JJ
has VBZ
been VBN
the DT
lexicalization NN
of IN
the DT
grammar NN
formalisms NN
being VBG
probabilistically RB
modeled VBN
: :
crucially RB
, ,
all PDT
the DT
recent JJ
, ,
successful JJ
statistical JJ
parsers NNS
have VBP
in IN
some DT
way NN
made VBN
use NN
of IN
bilexical JJ
dependencies NNS
. .

recent JJ
research NN
advances NNS
may MD
lead VB
to TO
the DT
development NN
of IN
viable JJ
book NN
indexing VBG
methods NNS
for IN
chinese JJ
books NNS
. .

these DT
include VBP
the DT
availability NN
of IN
efficient JJ
and CC
high JJ
precision NN
word NN
segmentation NN
methods NNS
for IN
chinese JJ
text NN
< NNP
ref NN
> NNP
chang NN
et NN
al NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
sproat NN
and CC
shih NN
, ,
1990 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
wang NN
et NN
al NN
, ,
1990 CD
< NN
/ref NNP
> NNP
, ,
the DT
availability NN
of IN
statistical JJ
analysis NN
of IN
a DT
chinese JJ
corpus NN
< NNP
ref NN
> NNP
liu VBZ
et FW
al NN
, ,
1975 CD
< NN
/ref NNP
> NNP
and CC
large-scale JJ
electronic JJ
chinese JJ
dictionaries NNS
with IN
partof-speech JJ
information NN
< NNP
ref NN
> NNP
chang NN
et NN
al NN
, ,
1988 CD
< NN
/ref NNP
> NNP
; :
bdc NN
, ,
1992 CD
, ,
the DT
corpus-based JJ
statistical JJ
part-of-speech JJ
tagger NN
< NNP
tref NN
> NNP
church NN
, ,
1988 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
derose NN
, ,
1988 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
beale NN
, ,
1988 CD
< NN
/ref NNP
> NNP
, ,
as RB
well RB
as IN
phrasal NN
and CC
clausal NN
analyzers NNS
< VBP
tref JJ
> NNP
church NN
1988 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> RB
ejerhed JJ
1990 CD
< NNP
/ref NNP
> VBD
2 CD
. .

given VBN
the DT
text NN
of IN
a DT
book NN
, ,
an DT
indexing NN
system NN
, ,
must MD
perform VB
some DT
kind NN
of IN
phrasal NN
and CC
statistical JJ
analysis NN
in IN
order NN
to TO
produce VB
a DT
list NN
of IN
candidate NN
indexes NNS
and CC
their PRP$
occurrence NN
statistics NNS
in IN
order NN
to TO
generate VB
indexes NNS
as IN
shown VBN
in IN
figure NN
1 CD
which WDT
is VBZ
an DT
excerpt NN
from IN
the DT
reconstruction NN
of IN
indexes NNS
of IN
a DT
book NN
on IN
transformational JJ
grammar NN
for IN
mandarin NN
chinese JJ
< NNP
ref NN
> NNP
tang NN
, ,
1977 CD
< NN
/ref NNP
> NNP
. .

much JJ
recent JJ
research NN
in IN
the DT
field NN
of IN
natural JJ
language NN
processing NN
nlp NN
has VBZ
focused VBN
on IN
an DT
empirical JJ
, ,
corpus-based JJ
approach NN
< NN
ref NN
> NNP
church NN
and CC
mercer NN
, ,
1993 CD
< NN
/ref NNP
> NNP
. .

the DT
high JJ
accuracy NN
achieved VBN
by IN
a DT
corpus-based JJ
approach NN
to TO
part-of-speech JJ
tagging NN
and CC
noun JJ
phrase NN
parsing NN
, ,
as IN
demonstrated VBN
by IN
< NNP
tref NN
> NNP
church NN
, ,
1988 CD
< NN
/tref NNP
> NNP
, ,
has VBZ
inspired VBN
similar JJ
approaches NNS
to TO
other JJ
problems NNS
in IN
natural JJ
language NN
processing NN
, ,
including VBG
syntactic JJ
parsing NN
and CC
word NN
sense NN
disambiguation NN
wsd NN
. .

the DT
availability NN
of IN
large JJ
quantities NNS
of IN
part-ofspeech JJ
tagged NN
and CC
syntactically RB
parsed JJ
sentences NNS
like IN
the DT
penn NN
treebank NN
corpus NN
< NNP
ref NN
> NNP
marcus NN
, ,
santorini NN
, ,
and CC
marcinkiewicz NN
, ,
1993 CD
< NN
/ref NNP
> NNP
has VBZ
contributed VBN
greatly RB
to TO
the DT
development NN
of IN
robust NN
, ,
broad JJ
coverage NN
partof-speech JJ
taggers NNS
and CC
syntactic JJ
parsers NNS
. .

the DT
penn NN
treebank NN
corpus NN
contains VBZ
a DT
sufficient JJ
number NN
of IN
partof-speech JJ
tagged NN
and CC
syntactically RB
parsed JJ
sentences NNS
to TO
serve VB
as IN
adequate JJ
training NN
material NN
for IN
building VBG
broad JJ
coverage NN
part-of-speech JJ
taggers NNS
and CC
parsers NNS
. .

this DT
is VBZ
quite RB
feasible JJ
using VBG
statistical JJ
taggers NNS
like IN
those DT
of IN
< JJ
ref NN
> NNP
garside NN
1987 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
tref NN
> NNP
church NN
1988 CD
< NNP
/tref NNP
> NNP
or CC
< NNP
ref VBP
> NNP
foster NN
1991 CD
< NNP
/ref NNP
> NNP
which WDT
achieve VBP
performance NN
upwards NNS
of IN
97 CD
on IN
unrestricted JJ
text NN
. .

they PRP
are VBP
well RB
enough RB
concemcd NN
to TO
allude VB
at IN
times NNS
even RB
the DT
human JJ
reader NN
and CC
no DT
automatic JJ
term-recognition NN
system NN
has VBZ
attempted VBN
to TO
distinguish VB
such JJ
terms NNS
, ,
despite IN
the DT
prevalence NN
ofpolysemy NN
in IN
such JJ
fields NNS
as IN
the DT
social JJ
sciences NNS
riggs NNS
, ,
1993 CD
and CC
the DT
importance NN
for IN
purposes NNS
of IN
terminological JJ
standardization NN
that WDT
deviant JJ
usage NN
be VB
tracked VBN
. .

on IN
sentences NNS
with IN
< JJ
40 CD
words NNS
, ,
the DT
former JJ
model NN
performs NNS
at IN
69 CD
precision NN
, ,
75 CD
recall NN
, ,
and CC
the DT
latter NN
at IN
77 CD
precision NN
and CC
78 CD
recall NN
. .

ever RB
since IN
the DT
success NN
of IN
hmms JJ
application NN
to TO
part-of-speech JJ
tagging NN
in IN
< NNP
tref NN
> NNP
church NN
, ,
1988 CD
< NN
/tref NNP
> NNP
, ,
machine NN
learning NN
approaches NNS
to TO
natural JJ
language NN
processing NN
have VBP
steadily RB
become VBN
more RBR
widespread JJ
. .

many JJ
machine NN
learning VBG
approaches NNS
let VBP
the DT
data NNS
speak NN
for IN
itself PRP
data NNS
ipsa RB
loquuntur RB
, ,
as IN
it PRP
were VBD
, ,
allowing VBG
the DT
modeler NN
to TO
focus VB
on IN
what WDT
features NNS
of IN
the DT
data NNS
are VBP
important JJ
, ,
rather RB
than IN
on IN
the DT
complicated JJ
interaction NN
of IN
such JJ
features NNS
, ,
as IN
had VBD
often RB
been VBN
the DT
case NN
with IN
hand-crafted JJ
nlp JJ
systems NNS
. .

to TO
see VB
whether IN
our PRP$
four CD
hypotheses NNS
in IN
italics NNS
above IN
effectively RB
addressed VBD
the DT
four CD
concerns NNS
above IN
, ,
we PRP
chose VBD
to TO
test VB
the DT
hypotheses NNS
on IN
two CD
well-known JJ
problems NNS
: :
ambiguity NN
both DT
at IN
the DT
structural JJ
level NN
and CC
at IN
the DT
part-of-speech JJ
level NN
and CC
inferring VBG
syntactic JJ
and CC
semantic JJ
information NN
about IN
unknown JJ
words NNS
. .

guided VBN
by IN
the DT
past JJ
success NN
of IN
probabilistic JJ
models NNS
in IN
speech NN
processing NN
, ,
we PRP
have VBP
integrated VBN
probabilistic JJ
models NNS
into IN
our PRP$
language NN
processing NN
systems NNS
. .

the DT
effectiveness NN
of IN
such JJ
models NNS
is VBZ
well RB
known VBN
< NNP
ref NN
> NNP
derose NN
1988 CD
< NNP
/ref NNP
> NNP
; :
< NNP
tref VBZ
> CD
church NN
1988 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> CD
kupiec NN
1989 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
jelinek NN
1985 CD
< NNP
/ref NNP
> NNP
, ,
and CC
they PRP
are VBP
currently RB
in IN
use NN
in IN
parsers NNS
eg VBP
de IN
< NNP
ref NN
> NNP
marcken NN
1990 CD
< NNP
/ref NNP
> NNP
. .

our PRP$
work NN
is VBZ
an DT
incremental JJ
improvement NN
on IN
these DT
models NNS
in IN
three CD
ways NNS
: :
1 CD
much RB
less JJR
training VBG
data NNS
than IN
theoretically RB
required VBN
proved JJ
adequate JJ
; :
2 CD
we PRP
integrated VBD
a DT
probabilistic JJ
model NN
of IN
word NN
features NNS
to TO
handle VB
unknown JJ
words NNS
uniformly RB
within IN
the DT
probabilistic JJ
model NN
and CC
measured VBD
its PRP$
contribution NN
; :
and CC
3 CD
we PRP
have VBP
applied VBN
the DT
forward-backward JJ
algorithm NN
to TO
accurately RB
compute VB
the DT
most RBS
likely JJ
tag NN
set VBN
. .

in IN
section NN
3 CD
, ,
we PRP
demonstrate VBP
that DT
probability NN
models NNS
can MD
improve VB
the DT
performance NN
of IN
knowledge-based JJ
syntactic JJ
and CC
semantic JJ
processing NN
in IN
dealing VBG
with IN
structural JJ
ambiguity NN
and CC
with IN
unknown JJ
words NNS
. .

< JJ
ref NN
> NNP
hearst NN
1991 CD
< NNP
/ref NNP
> NNP
presented VBD
an DT
effective JJ
approach NN
to TO
modeling VBG
local JJ
contextual JJ
evidence NN
, ,
while IN
< JJ
ref NN
> NNP
resnik NN
1993 CD
< NNP
/ref NNP
> NNP
gave VBD
a DT
classic JJ
treatment NN
of IN
the DT
use NN
of IN
word NN
classes NNS
in IN
selectional JJ
constraints NNS
. .

preprocessing VBG
the DT
corpus NN
with IN
a DT
part NN
of IN
speech NN
tagger NN
phrasal NN
verbs IN
involving VBG
the DT
preposition NN
to TO
raise VB
an DT
interesting JJ
problem NN
because IN
of IN
the DT
possible JJ
confusion NN
with IN
the DT
infinitive JJ
marker NN
to TO
. .

we PRP
have VBP
found VBN
that IN
if IN
we PRP
first VBP
tag JJ
every DT
word NN
in IN
the DT
corpus NN
with IN
a DT
part NN
of IN
speech NN
using VBG
a DT
method NN
such JJ
as IN
< JJ
tref NN
> NNP
church NN
1988 CD
< NNP
/tref NNP
> NNP
or CC
< NNP
ref VBP
> NNP
derose JJ
1988 CD
< NNP
/ref NNP
> NNP
, ,
and CC
then RB
measure NN
associations NNS
between IN
tagged VBN
words NNS
, ,
we PRP
can MD
identify VB
interesting JJ
contrasts NNS
between IN
verbs NNS
associated VBN
with IN
a DT
following JJ
preposition NN
toin NN
and CC
verbs NN
associated VBN
with IN
a DT
following JJ
infinitive JJ
marker NN
toto NN
. .

the DT
score NN
identifies VBZ
quite RB
a DT
number NN
of IN
verbs NNS
associated VBN
in IN
an DT
interesting JJ
way NN
with IN
to TO
; :
restricting VBG
our PRP$
attention NN
to TO
pairs VB
with IN
a DT
score NN
of IN
30 CD
or CC
more JJR
, ,
there EX
are VBP
768 CD
verbs NNS
associated VBN
with IN
the DT
preposition NN
toin NN
and CC
551 CD
verbs NNS
with IN
the DT
infinitive JJ
marker NN
toto NN
. .

however RB
, ,
as IN
< JJ
tref NN
> NNP
church NN
1988 CD
< NNP
/tref NNP
> NNP
rightly RB
pointed VBD
out RP
proper JJ
nouns NNS
and CC
capitalized VBN
words NNS
are VBP
particularly RB
problematic JJ
: :
some DT
capitalized JJ
words NNS
are VBP
proper JJ
nouns NNS
and CC
some DT
are VBP
not RB
. .

for IN
example NN
, ,
the DT
capitalized JJ
word NN
acts VBZ
is VBZ
found VBN
twice RB
in IN
brown JJ
corpus NN
, ,
both DT
times NNS
as IN
a DT
proper JJ
noun NN
in IN
a DT
title NN
. .

given VBN
that IN
each DT
token NN
has VBZ
on IN
the DT
average NN
more JJR
than IN
2 CD
possible JJ
tags NNS
, ,
the DT
procedural JJ
description NN
above IN
is VBZ
very RB
inefficient JJ
for IN
m1 NN
but CC
very RB
short JJ
sentences NNS
. .

however RB
, ,
the DT
observation NN
that IN
our PRP$
constraints NNS
are VBP
localized VBN
to TO
a DT
window NN
of IN
a DT
small JJ
number NN
of IN
tokens NNS
say VBP
at IN
most JJS
5 CD
tokens NNS
in IN
a DT
sequence NN
, ,
suggests VBZ
a DT
more RBR
efficient JJ
scheme NN
originally RB
used VBN
by IN
< JJ
tref NN
> NNP
church NN
1988 CD
< NNP
/tref NNP
> NNP
. .

they PRP
report VBP
rates NNS
of IN
correctly RB
tagged VBN
words NNS
which WDT
are VBP
comparable JJ
to TO
that DT
presented VBN
by IN
< NNP
tref NN
> NNP
church NN
1988 CD
< NNP
/tref NNP
> NNP
and CC
< NNP
ref VBP
> NNP
kempe NN
1993 CD
< NNP
/ref NNP
> NNP
. .

in IN
the DT
area NN
of IN
speech NN
recognition NN
neural JJ
networks NNS
have VBP
been VBN
used VBN
for IN
a DT
decade NN
r NN
, ,
ow NN
. .

indeed RB
, ,
recent JJ
increased VBN
interest NN
in IN
the DT
problem NN
of IN
disambiguating VBG
lexical JJ
category NN
in IN
english NN
has VBZ
led VBN
to TO
significant JJ
progress NN
in IN
developing VBG
effective JJ
programs NNS
for IN
assigning VBG
lexical JJ
category NN
in IN
unrestricted JJ
text NN
. .

the DT
most RBS
successful JJ
and CC
comprehensive JJ
of IN
these DT
are VBP
based VBN
on IN
probabilistic JJ
modeling NN
of IN
category NN
sequence NN
and CC
word NN
category NN
< NNP
ref NN
> NNP
church NN
1987 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
garside NN
, ,
leech NN
and CC
sampson NN
1987 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
derose JJ
1988 CD
< NNP
/ref NNP
> NNP
. .

these DT
stochastic JJ
methods NNS
show VBP
impressive JJ
performance NN
: :
church NN
reports VBZ
a DT
success NN
rate NN
of IN
95 CD
to TO
99 CD
, ,
and CC
shows VBZ
a DT
sample JJ
text NN
with IN
an DT
error NN
rate NN
of IN
less JJR
than IN
one CD
percent NN
. .

what WP
may MD
seem VB
particularly RB
surprising JJ
is VBZ
that IN
these DT
methods NNS
succeed VB
essentially RB
without IN
reference NN
to TO
syntactic JJ
structure NN
; :
purely RB
surface VBP
lexical JJ
patterns NNS
are VBP
involved VBN
. .

excellent JJ
methods NNS
have VBP
been VBN
developed VBN
for IN
part-of-speech JJ
pos NN
tagging VBG
using VBG
stochastic JJ
models NNS
trained VBN
on IN
partially RB
tagged VBN
corpora NN
< NNP
tref NN
> NNP
church NN
, ,
1988 CD
< NN
/tref NNP
> NNP
; :
cutting VBG
, ,
< JJ
ref NN
> NNP
kupiec NN
, ,
pedersen NN
sibun NN
, ,
1992 CD
< NN
/ref NNP
> NNP
. .

semantic JJ
issues NNS
have VBP
been VBN
addressed VBN
, ,
particularly RB
for IN
sense NN
disambiguation NN
, ,
by IN
using VBG
large JJ
contexts NN
, ,
eg NN
, ,
50 CD
nearby JJ
words NNS
< VBP
ref JJ
> NNP
gale NN
, ,
church NN
yarowsky NN
, ,
1992 CD
< NN
/ref NNP
> NNP
or CC
by IN
reference NN
to TO
on-line JJ
dictionaries NNS
< VBP
ref JJ
> NNP
krovetz NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
lesk NN
, ,
1986 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
liddy NN
paik NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
zernik NN
, ,
1991 CD
< NN
/ref NNP
> NNP
. .

more RBR
recently RB
, ,
methods NNS
to TO
work VB
with IN
entirely RB
untagged JJ
corpora NNS
have VBP
been VBN
developed VBN
which WDT
show VBP
great JJ
promise NN
< NNP
ref NN
> NNP
brill NN
marcus NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
finch NN
chater NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
myaeng NN
li NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
schutze NN
, ,
1992 CD
< NN
/ref NNP
> NNP
. .

much RB
of IN
this DT
work NN
offers VBZ
the DT
prospect NN
that IN
a DT
disambiguation NN
system NN
might MD
be VB
able JJ
to TO
input VB
unrestricted JJ
text NN
and CC
tag VB
each DT
word NN
with IN
the DT
most RBS
likely JJ
sense NN
with IN
fairly RB
reasonable JJ
accuracy NN
and CC
efficiency NN
, ,
just RB
as IN
part NN
of IN
speech NN
taggers NNS
eg VBP
, ,
< JJ
tref NN
> NNP
church NN
1988 CD
< NNP
/tref NNP
> NNP
can MD
now RB
input VB
unrestricted JJ
text NN
and CC
assign VB
each DT
word NN
with IN
the DT
most RBS
likely JJ
part NN
of IN
speech NN
with IN
fairly RB
reasonable JJ
accuracy NN
and CC
efficiency NN
. .

the DT
availability NN
of IN
massive JJ
lexicographic JJ
databases VBZ
offers VBZ
a DT
promising VBG
route NN
to TO
overcoming VBG
the DT
knowledge NN
acquisition NN
bottleneck NN
. .

more RBR
than IN
thirty CD
years NNS
ago RB
, ,
bari- JJ
< NNP
ref NN
> NNP
iillel NN
1960 CD
< NNP
/ref NNP
> NNP
predicted VBD
that IN
it PRP
would MD
be VB
futile JJ
to TO
write VB
expert-system-like JJ
rules NNS
by-hand VBP
as IN
they PRP
had VBD
been VBN
doing VBG
at IN
georgetown VBN
at IN
the DT
time NN
because IN
there EX
would MD
be VB
no DT
way NN
to TO
scale VB
up RP
such JJ
rules NNS
to TO
cope VB
with IN
unrestricted JJ
input NN
. .

the DT
most RBS
successful JJ
achievements NNS
so RB
far RB
in IN
the DT
domain NN
of IN
large-scale JJ
morphological JJ
disambiguation NN
of IN
running VBG
text NN
have VBP
been VBN
those DT
for IN
english JJ
reported VBN
by IN
< NNP
ref NN
> NNP
garside NN
, ,
leech NN
, ,
and CC
sampson NN
1987 CD
< NNP
/ref NNP
> NNP
, ,
on IN
tagging VBG
the DT
lob NN
corpus NN
, ,
and CC
< NNP
tref VBP
> NNP
church NN
1988 CD
< NNP
/tref NNP
> NNP
, ,
on IN
assigning VBG
part-of-speech JJ
labels NNS
and CC
parsing VBG
noun JJ
phrases NNS
. .

success NN
rates NNS
ranging VBG
between IN
95-99 CD
are VBP
reported VBN
, ,
depending VBG
on IN
how WRB
success NN
is VBZ
defined VBN
. .

additionally RB
, ,
there EX
is VBZ
a DT
slight JJ
but CC
not RB
significant JJ
improvement NN
of IN
tagging VBG
accuracy NN
. .

in IN
the DT
past JJ
decade NN
, ,
the DT
speech NN
recognition NN
community NN
has VBZ
had VBN
huge JJ
successes NNS
in IN
applying VBG
hidden JJ
markov NN
models NNS
, ,
or CC
hmms NN
to TO
their PRP$
problems NNS
. .

more RBR
recently RB
, ,
the DT
natural JJ
language NN
processing NN
community NN
has VBZ
effectively RB
employed VBN
these DT
models NNS
for IN
part-ofspeech JJ
tagging NN
, ,
as IN
in IN
the DT
seminal JJ
< NNP
tref NN
> NNP
church NN
, ,
1988 CD
< NN
/tref NNP
> NNP
and CC
other JJ
, ,
more RBR
recent JJ
efforts NNS
< VBP
ref VB
> NNP
weischedel NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
. .

we PRP
would MD
now RB
propose VB
that IN
hmms NN
have VBP
successfully RB
been VBN
applied VBN
to TO
the DT
problem NN
of IN
name-finding NN
. .

we PRP
have VBP
built VBN
a DT
named-entity JJ
ne NN
recognition NN
system NN
using VBG
a DT
slightly-modified JJ
version NN
of IN
an DT
hmm NN
; :
we PRP
call VBP
our PRP$
system NN
nymble JJ
. .

once RB
the DT
base NN
formalism NN
has VBZ
been VBN
decided VBN
upon IN
we PRP
currently RB
are VBP
using VBG
lexicalized VBN
multi-component JJ
tags NNS
with IN
substitution NN
and CC
adjunction NN
, ,
a DT
simple JJ
translation NN
strategy NN
from IN
a DT
source NN
string NN
to TO
a DT
target NN
is VBZ
to TO
parse VB
the DT
string NN
using VBG
an DT
appropriate JJ
tag NN
parser NN
for IN
the DT
base NN
formalism NN
. .

pd NN
productdisplay NN
i NN
p VBP
i NN
j NN
, ,
r NN
i JJ
note VBP
that IN
each DT
probability NN
on IN
the DT
right JJ
represents VBZ
the DT
syntactic/semantic JJ
preference NN
of IN
a DT
dependency NN
of IN
two CD
lexical JJ
items NNS
. .

we PRP
can MD
readily VB
see VB
that IN
the DT
model NN
is VBZ
very RB
similar JJ
to TO
lpcfg VB
models NNS
. .

a DT
more RBR
linguistically RB
motivated JJ
approach NN
is VBZ
to TO
expand VB
the DT
domain NN
of IN
productions NNS
downward VBP
to TO
incorporate VB
more JJR
tree JJ
structures NNS
. .

in IN
particular JJ
, ,
we PRP
show VBP
how WRB
a DT
fixed JJ
constituency NN
can MD
be VB
maintained VBN
at IN
the DT
level NN
of IN
the DT
elementary JJ
trees NNS
of IN
lexicalized JJ
tags NNS
and CC
yet RB
be VB
able JJ
to TO
achieve VB
the DT
kind NN
of IN
flexibility NN
needed VBN
for IN
dealing VBG
with IN
the DT
so-called JJ
non-constituents NNS
. .

recently RB
there EX
has VBZ
been VBN
a DT
gain NN
in IN
interest NN
in IN
the DT
so-called JJ
mildly RB
context-sensitive JJ
formalisms NNS
vijay- JJ
< NNP
ref NN
> NNP
shanker NN
, ,
1987 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
weir NN
, ,
1988 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
joshi NN
, ,
vijayshanker NN
, ,
and CC
weir NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
vijay- JJ
< NNP
ref NN
> NNP
shanker NN
and CC
weir NN
, ,
1993a CD
< NN
/ref NNP
> VBZ
that IN
generate NN
only RB
a DT
small JJ
superset NN
of IN
context-free JJ
languages NNS
. .

one CD
such JJ
formalism NN
is VBZ
lexicalized VBN
tree-adjoining JJ
grammar NN
ltag NN
schabes NN
, ,
abeill NN
, ,
and CC
< NNP
ref VBP
> NNP
joshi NN
, ,
1988 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
abeillfi NN
et NN
al NN
, ,
1990 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
joshi NN
and CC
schabes NNS
, ,
1992 CD
< NN
/ref NNP
> NNP
, ,
which WDT
provides VBZ
a DT
number NN
of IN
attractive JJ
properties NNS
at IN
the DT
cost NN
of IN
decreased JJ
efficiency NN
, ,
on6-time JJ
in IN
the DT
worst JJS
case NN
< NNP
ref NN
> NNP
vijayshanker NN
, ,
1987 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
schabes NNS
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
lang NN
, ,
1990 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
vijayshanker NN
and CC
weir NN
, ,
1993b CD
< NN
/ref NNP
> NNP
. .

much RB
of IN
the DT
appeal NN
of IN
these DT
approaches NNS
is VBZ
tied VBN
to TO
the DT
use NN
of IN
a DT
simple JJ
formalism NN
, ,
which WDT
allows VBZ
for IN
the DT
use NN
of IN
efficient JJ
parsing VBG
algorithms NN
, ,
as RB
well RB
as IN
straightforward NN
ways NNS
to TO
train VB
discriminative JJ
models NNS
to TO
perform VB
disambiguation NN
. .

at IN
the DT
same JJ
time NN
, ,
there EX
is VBZ
growing VBG
interest NN
in IN
parsing VBG
with IN
more RBR
sophisticated JJ
lexicalized JJ
grammar NN
formalisms NNS
, ,
such JJ
as IN
lexical JJ
functional JJ
grammar NN
lfg NN
< NNP
ref NN
> NNP
bresnan NN
, ,
1982 CD
< NN
/ref NNP
> NNP
, ,
lexicalized VBD
tree JJ
adjoining VBG
grammar NN
ltag NN
< NNP
tref NN
> NNP
schabes VBZ
et FW
al NN
, ,
1988 CD
< NN
/tref NNP
> NNP
, ,
headdriven JJ
phrase NN
structure NN
grammar NN
hpsg NN
< NNP
ref NN
> NNP
pollard NN
and CC
sag NN
, ,
1994 CD
< NN
/ref NNP
> NNP
and CC
combinatory JJ
categorial JJ
grammar NN
ccg NN
< NNP
ref NN
> NNP
steedman NN
, ,
2000 CD
< NN
/ref NNP
> NNP
, ,
which WDT
represent VBP
deep JJ
syntactic JJ
structures NNS
that WDT
can MD
not RB
be VB
expressed VBN
in IN
a DT
shallower JJR
formalism NN
designed VBN
to TO
represent VB
only RB
aspects NNS
of IN
surface NN
syntax NN
, ,
such JJ
as IN
the DT
dependency NN
formalism NN
used VBN
in IN
current JJ
mainstream NN
dependency NN
parsing NN
. .

we PRP
present VBP
a DT
novel JJ
framework NN
that WDT
combines VBZ
strengths NNS
from IN
surface NN
syntactic JJ
parsing NN
and CC
deep JJ
syntactic JJ
parsing NN
, ,
specifically RB
by IN
combining VBG
dependency NN
and CC
hpsg NN
parsing NN
. .

we PRP
show VBP
that IN
, ,
by IN
using VBG
surface NN
dependencies NNS
to TO
constrain VB
the DT
application NN
of IN
wide-coverage JJ
hpsg NN
rules NNS
, ,
we PRP
can MD
benefit VB
from IN
a DT
number NN
of IN
parsing VBG
techniques NNS
designed VBN
for IN
high-accuracy NN
dependency NN
parsing NN
, ,
while IN
actually RB
performing VBG
deep JJ
syntactic JJ
analysis NN
. .

this DT
paper NN
will MD
concentrate VB
on IN
context-free JJ
grammars NNS
cfg NNS
and CC
their PRP$
associated JJ
parsers NNS
. .

hence NN
, ,
the DT
parsing NN
techniques NNS
and CC
tools NNS
described VBD
here RB
can MD
be VB
applied VBN
to TO
most RBS
tags NNS
used VBN
for IN
nlp NN
, ,
with IN
, ,
in IN
the DT
worst JJS
case NN
, ,
a DT
light JJ
over-generation NN
which WDT
can MD
be VB
easily RB
and CC
efficiently RB
eliminated VBN
in IN
a DT
complementary JJ
pass NN
. .

this DT
is VBZ
indeed RB
what WP
we PRP
have VBP
achieved VBN
with IN
a DT
tag NN
automatically RB
extracted VBN
from IN
villemonte NN
de FW
< FW
ref FW
> FW
la FW
clergerie NN
, ,
2005 CD
< NN
/ref NNP
> NNP
s VBD
large-coverage JJ
factorized JJ
french JJ
tag NN
, ,
as IN
we PRP
will MD
see VB
in IN
section NN
4 CD
. .

we PRP
can MD
thus RB
define VB
lexical JJ
transfer NN
rules NNS
that WDT
avoid VBP
the DT
defects NNS
of IN
a DT
mere JJ
word-to-word JJ
approach NN
but CC
still RB
benefit VB
from IN
the DT
simplicity NN
and CC
elegance NN
of IN
a DT
lexical JJ
approach NN
. .

we PRP
are VBP
indebted VBN
to TO
stuart VB
shieber NN
for IN
his PRP$
valuable JJ
comments NNS
. .

3 CD
a DT
tag NN
analysis NN
the DT
tag NN
formalism NN
for IN
a DT
recent JJ
introduction NN
, ,
see VBP
< JJ
ref NN
> NNP
joshi NN
1987a CD
< NN
/ref NNP
> NNP
is VBZ
well RB
suited VBN
for IN
linguistic JJ
description NN
because IN
1 CD
it PRP
provides VBZ
a DT
larger JJR
domain NN
of IN
locality NN
than IN
a DT
cfg NN
or CC
other JJ
augmented JJ
cfg-based JJ
formalisms NNS
such JJ
as IN
tlpsg NN
or CC
lfg NN
, ,
and CC
2 CD
it PRP
allows VBZ
factoring NN
of IN
recursion NN
from IN
the DT
domain NN
of IN
dependencies NNS
. .

the DT
tree NN
will MD
contain VB
the DT
lexical JJ
item NN
, ,
and CC
all DT
of IN
its PRP$
syntac3some JJ
verbs NNS
allow VBP
scrambling VBG
out IN
of IN
their PRP$
complements NNS
more RBR
freely RB
than IN
others NNS
. .

it PRP
appears VBZ
that IN
all DT
subject-control JJ
verbs NNS
and CC
most JJS
object-control JJ
verbs NN
governing VBG
the DT
dative JJ
allow NN
scrambling VBG
fairly RB
fely RB
, ,
while IN
scrambling VBG
with IN
objectcontrol NN
verbs NNS
governing VBG
the DT
accusative NN
is VBZ
more RBR
restricted JJ
cir NN
. .

along IN
with IN
the DT
independent JJ
development NN
of IN
parsing VBG
techniques NNS
for IN
individual JJ
grammar NN
formalisms NN
, ,
some DT
of IN
them PRP
have VBP
been VBN
adapted VBN
to TO
other JJ
formalisms JJ
< NNP
tref NN
> NNP
schabes VBZ
et FW
al NN
, ,
1988 CD
< NN
/tref NNP
> NNP
; :
van FW
< FW
ref FW
> FW
noord NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yoshida NNP
et FW
al NN
, ,
1999 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
torisawa NN
et NN
al NN
, ,
2000 CD
< NN
/ref NNP
> NNP
. .

if IN
we PRP
could MD
identify VB
an DT
algorithmic JJ
difference NN
that WDT
causes VBZ
performance NN
difference NN
, ,
it PRP
would MD
reveal VB
advantages NNS
and CC
disadvantages NNS
of IN
the DT
different JJ
realizations NNS
. .

the DT
parser NN
achieves VBZ
an DT
ogn6-time JJ
worst JJ
case NN
behavior NN
, ,
og2n4-time JJ
for IN
unambiguous JJ
grammars NNS
and CC
linear JJ
time NN
for IN
a DT
large JJ
class NN
of IN
grammars NNS
. .

the DT
parser NN
uses VBZ
the DT
following JJ
two-pass NN
parsing VBG
strategy NN
originally RB
defined VBN
for IN
lexicalized JJ
grammars NNS
< VBP
tref JJ
> NNP
schabes NN
et NN
al NN
, ,
1988 CD
< NN
/tref NNP
> NNP
which WDT
improves VBZ
its PRP$
performance NN
in IN
practice NN
< NNP
ref NN
> NNP
schabes NN
and CC
joshi NN
, ,
1990 CD
< NN
/ref CC
> NN
: :
in IN
the DT
first JJ
step NN
the DT
parser NN
will MD
select VB
, ,
the DT
set NN
of IN
structures NNS
corresponding VBG
to TO
each DT
word NN
in IN
the DT
sentence NN
. .

this DT
information NN
is VBZ
particularly RB
useful JJ
for IN
a DT
top-down JJ
component NN
of IN
the DT
parser NN
< NNP
ref NN
> NNP
schabes NN
and CC
joshi NN
, ,
1990 CD
< NN
/ref NNP
> NNP
. .

all PDT
the DT
syntactic JJ
concepts NNS
of IN
lexicalized JJ
tag NN
such JJ
as IN
the DT
grouping NN
of IN
the DT
trees NNS
in IN
tree NN
families NNS
which WDT
represents VBZ
the DT
possible JJ
variants NNS
on IN
a DT
basic JJ
subcategorization NN
frame NN
are VBP
accessible JJ
through IN
mouse-sensitive JJ
items NNS
. .

that DT
is VBZ
, ,
they PRP
used VBD
deep JJ
analysis NN
as IN
a DT
preprocessor NN
to TO
obtain VB
useful JJ
features NNS
for IN
training VBG
a DT
probabilistic JJ
model NN
or CC
statistical JJ
classifier NN
of IN
a DT
semantic JJ
argument NN
identifier NN
. .

as IN
for IN
lexicalized JJ
tags NNS
, ,
in IN
< NNP
tref NN
> NNP
schabes VBZ
et FW
al NN
, ,
1988 CD
< NN
/tref NNP
> VBZ
a DT
two CD
step NN
algorithm NN
has VBZ
been VBN
presented VBN
: :
during IN
the DT
first JJ
step NN
the DT
trees NNS
corresponding VBG
to TO
the DT
input NN
string VBG
are VBP
selected VBN
and CC
in IN
the DT
second JJ
step NN
the DT
input NN
string NN
is VBZ
parsed VBN
with IN
respect NN
to TO
this DT
set NN
of IN
trees NNS
. .

another DT
paper NN
by IN
< NNP
ref NN
> NNP
schabes NN
and CC
joshi NN
1989 CD
< NNP
/ref NNP
> NN
shows VBZ
how WRB
parsing JJ
strategies NNS
can MD
take VB
advantage NN
of IN
lexicalization NN
in IN
order NN
to TO
improve VB
parsers NNS
performance NN
. .

two CD
major JJ
advantages NNS
have VBP
been VBN
discussed VBN
in IN
the DT
cited JJ
work NN
: :
grammar NN
filtering VBG
the DT
parser NN
can MD
use VB
only RB
a DT
subset NN
of IN
the DT
entire JJ
grammar NN
and CC
bottom-up JJ
information NN
further RBR
constraints NNS
are VBP
imposed VBN
on IN
the DT
way NN
trees NNS
can MD
be VB
combined VBN
. .

in IN
< NNP
ref NN
> NNP
kroch NN
and CC
joshi NN
, ,
1985 CD
< NN
/ref NNP
> VBZ
a DT
detailed JJ
discussion NN
of IN
the DT
linguistic JJ
relevance NN
of IN
tags NNS
can MD
be VB
found VBN
. .

lexicalized VBN
tree JJ
adjoining VBG
grammars NNS
< JJ
tref JJ
> NNP
schabes NN
et NN
al NN
, ,
1988 CD
< NN
/tref NNP
> NNP
are VBP
a DT
refinement NN
of IN
tags NNS
such JJ
that IN
each DT
elementary JJ
tree NN
is VBZ
associated VBN
with IN
a DT
lexieal JJ
item NN
, ,
called VBD
the DT
anchor NN
of IN
the DT
tree NN
. .

notably RB
, ,
the DT
association NN
between IN
elementary JJ
trees NNS
and CC
anchors NNS
improves NNS
also RB
parsing VBG
performance NN
, ,
as IN
will MD
be VB
discussed VBN
below IN
. .

a DT
more RBR
linguistically RB
motivated JJ
approach NN
is VBZ
to TO
expand VB
the DT
domain NN
of IN
productions NNS
downward VBP
to TO
incorporate VB
more JJR
tree JJ
structures NNS
. .

indeed RB
, ,
recent JJ
increased VBN
interest NN
in IN
the DT
problem NN
of IN
disambiguating VBG
lexical JJ
category NN
in IN
english NN
has VBZ
led VBN
to TO
significant JJ
progress NN
in IN
developing VBG
effective JJ
programs NNS
for IN
assigning VBG
lexical JJ
category NN
in IN
unrestricted JJ
text NN
. .

the DT
most RBS
successful JJ
and CC
comprehensive JJ
of IN
these DT
are VBP
based VBN
on IN
probabilistic JJ
modeling NN
of IN
category NN
sequence NN
and CC
word NN
category NN
< NNP
ref NN
> NNP
church NN
1987 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
garside NN
, ,
leech NN
and CC
sampson NN
1987 CD
< NNP
/ref NNP
> NNP
; :
< NNP
tref VBZ
> CD
derose JJ
1988 CD
< NNP
/tref NNP
> NNP
. .

these DT
stochastic JJ
methods NNS
show VBP
impressive JJ
performance NN
: :
church NN
reports VBZ
a DT
success NN
rate NN
of IN
95 CD
to TO
99 CD
, ,
and CC
shows VBZ
a DT
sample JJ
text NN
with IN
an DT
error NN
rate NN
of IN
less JJR
than IN
one CD
percent NN
. .

what WP
may MD
seem VB
particularly RB
surprising JJ
is VBZ
that IN
these DT
methods NNS
succeed VB
essentially RB
without IN
reference NN
to TO
syntactic JJ
structure NN
; :
purely RB
surface VBP
lexical JJ
patterns NNS
are VBP
involved VBN
. .

4 CD
concluding VBG
remarks NNS
though IN
there EX
can MD
be VB
little JJ
doubt NN
that IN
the DT
ruling NN
system NN
of IN
bakeoffs NNS
actively RB
encourages VBZ
a DT
degree NN
of IN
oneupmanship NN
, ,
our PRP$
paper NN
and CC
our PRP$
software NN
are VBP
not RB
offered VBN
in IN
a DT
competitive JJ
spirit NN
. .

as IN
we PRP
said VBD
at IN
the DT
out211 NN
set VBN
, ,
we PRP
dont VBP
necessarily RB
believe VB
hunpos NN
to TO
be VB
in IN
any DT
way NN
better JJR
than IN
tnt NN
, ,
and CC
certainly RB
the DT
main JJ
ideas NNS
have VBP
been VBN
pioneered VBN
by IN
< NNP
tref NN
> NNP
derose NN
1988 CD
< NNP
/tref NNP
> NNP
, ,
< NNP
ref VBZ
> CD
church NN
1988 CD
< NNP
/ref NNP
> NNP
, ,
and CC
others NNS
long RB
before IN
this DT
generation NN
of IN
hmm JJ
work NN
. .

but CC
to TO
improve VB
the DT
results NNS
beyond IN
what WP
a DT
basic JJ
hmm NN
can MD
achieve VB
one CD
needs VBZ
to TO
tune VB
the DT
system NN
, ,
and CC
progress NN
can MD
only RB
be VB
made VBN
if IN
the DT
experiments NNS
are VBP
end NN
to TO
end VB
replicable NN
. .

there EX
is VBZ
no DT
doubt NN
many JJ
other JJ
systems NNS
could MD
be VB
tweaked VBN
further JJ
and CC
improve VB
on IN
our PRP$
results NNS
what WP
matters VBZ
is VBZ
that IN
anybody NN
could MD
now RB
also RB
tweak VBP
hunpos NNS
without IN
any DT
restriction NN
to TO
improve VB
the DT
state NN
of IN
the DT
art NN
. .

< JJ
ref NN
> NNP
recently RB
, ,
brill NN
1992 CD
< NNP
/ref NNP
> NNP
described VBD
a DT
rule-based JJ
tagger NN
that WDT
performs VBZ
as RB
well RB
as IN
taggers NNS
based VBN
upon IN
probabilistic JJ
models NNS
and CC
overcomes VBZ
the DT
limitations NNS
common JJ
in IN
rule-based JJ
approaches NNS
to TO
language NN
processing NN
: :
it PRP
is VBZ
robust JJ
and CC
the DT
rules NNS
are VBP
automatically RB
ac JJ
mitsubishi NN
electric JJ
research NN
laboratories NNS
, ,
201 CD
broadway NN
, ,
cambridge NN
, ,
ma RB
02139 CD
. .

unknown JJ
words NNS
unknown JJ
common JJ
words NNS
unknown JJ
proper JJ
nouns NNS
tagger IN
guesser NN
metrics NNS
error VBP
error NN
coverage NN
error NN
coverage NN
hmm NN
xerox NNP
mean VBZ
17851643 CD
30022169 CD
37567270 CD
10785563 CD
63797113 CD
s-error JJ
0484710 CD
0469922 CD
1687396 CD
0613745 CD
1714969 CD
hmm NN
cascade VBD
mean JJ
12378716 CD
21266264 CD
36507909 CD
7776456 CD
64795969 CD
s-error JJ
0917656 CD
0403957 CD
2336381 CD
0853958 CD
2206457 CD
brill NN
brill NN
mean VBP
14688501 CD
27411736 CD
38998687 CD
6439525 CD
62160917 CD
s-error JJ
0908172 CD
0539634 CD
2627234 CD
0501082 CD
4010992 CD
brill NN
cascade VBD
mean JJ
11327863 CD
20986240 CD
37933048 CD
5548990 CD
63816586 CD
s-error JJ
0761576 CD
0480798 CD
2353510 CD
0561009 CD
3775991 CD
the DT
brown NN
corpus NN
, ,
we PRP
obtained VBD
the DT
error NN
rate NN
mean VBP
0 CD
4003093 CD
with IN
the DT
standard JJ
error NN
deb0155599 NN
. .

the DT
brill NN
tagger NN
showed VBD
some DT
better JJR
results NNS
: :
error NN
rate NN
mean VBP
0 CD
3327366 CD
with IN
the DT
standard JJ
error NN
debo NN
123903 CD
. .

it PRP
is VBZ
interesting VBG
to TO
note VB
that IN
the DT
most RBS
commonly RB
used JJ
method NN
is VBZ
viterbi JJ
tagging VBG
see NN
< JJ
tref NN
> NNP
derose NN
1988 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> CD
church NN
1989 CD
< NNP
/ref NNP
> NNP
although IN
it PRP
is VBZ
not RB
the DT
optimal JJ
method NN
for IN
evaluation NN
at IN
word NN
level NN
. .

the DT
reasons NNS
for IN
this DT
preference NN
are VBP
presumably RB
that IN
: :
viterbi NN
tagging NN
is VBZ
simpler VBN
to TO
implement VB
than IN
ml NN
tagging NN
and CC
requires VBZ
less JJR
computation NN
although IN
they PRP
both DT
have VBP
the DT
same JJ
asymptotic JJ
complexity NN
viterbi NN
tagging VBG
provides VBZ
the DT
best JJS
interpretation NN
for IN
the DT
sentence NN
, ,
which WDT
is VBZ
linguistically RB
appealing VBG
ml NNS
tagging VBG
may MD
produce VB
sequences NNS
of IN
tags NNS
that WDT
are VBP
linguistically RB
impossible JJ
because IN
the DT
choice NN
of IN
a DT
tag NN
depends VBZ
on IN
all DT
contexts NN
taken VBN
together RB
. .

however RB
, ,
in IN
our PRP$
experiments NNS
, ,
we PRP
will MD
show VB
that IN
viterbi NN
and CC
ml NN
tagging VBG
result NN
in IN
very RB
similar JJ
performance NN
. .

although IN
methods NNS
for IN
unsupervised JJ
training NN
of IN
hmms NN
do VBP
exist VB
, ,
training NN
is VBZ
usually RB
done VBN
in IN
a DT
supervised JJ
way NN
by IN
estimation NN
of IN
the DT
above JJ
probabilities NNS
from IN
relative JJ
frequencies NNS
in IN
the DT
training NN
data NNS
. .

in IN
van NN
< NNP
ref NN
> NNP
halteren NN
, ,
zavrel NN
, ,
and CC
daelemans NNS
1998 CD
< NNP
/ref NNP
> NNP
we PRP
used VBD
a DT
straightforward JJ
implementation NN
of IN
hmms NN
, ,
which WDT
turned VBD
out RP
to TO
have VB
the DT
worst JJS
accuracy NN
of IN
the DT
four CD
competing VBG
methods NNS
. .

in IN
the DT
present JJ
work NN
, ,
we PRP
have VBP
replaced VBN
this DT
by IN
the DT
tnt NN
system NN
we PRP
will MD
refer VB
to TO
this DT
tagger NN
as IN
hmm NN
below IN
. .

a DT
special JJ
lexicon NN
had VBD
to TO
be VB
developed VBN
to TO
map VB
spoken JJ
langnage NN
variants NNS
onto IN
their PRP$
canonical JJ
written VBN
language NN
forms NNS
. .

to TO
see VB
whether IN
our PRP$
four CD
hypotheses NNS
in IN
italics NNS
above IN
effectively RB
addressed VBD
the DT
four CD
concerns NNS
above IN
, ,
we PRP
chose VBD
to TO
test VB
the DT
hypotheses NNS
on IN
two CD
well-known JJ
problems NNS
: :
ambiguity NN
both DT
at IN
the DT
structural JJ
level NN
and CC
at IN
the DT
part-of-speech JJ
level NN
and CC
inferring VBG
syntactic JJ
and CC
semantic JJ
information NN
about IN
unknown JJ
words NNS
. .

guided VBN
by IN
the DT
past JJ
success NN
of IN
probabilistic JJ
models NNS
in IN
speech NN
processing NN
, ,
we PRP
have VBP
integrated VBN
probabilistic JJ
models NNS
into IN
our PRP$
language NN
processing NN
systems NNS
. .

the DT
effectiveness NN
of IN
such JJ
models NNS
is VBZ
well RB
known VBN
< NNP
tref NN
> NNP
derose NN
1988 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> CD
church NN
1988 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
kupiec NN
1989 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
jelinek NN
1985 CD
< NNP
/ref NNP
> NNP
, ,
and CC
they PRP
are VBP
currently RB
in IN
use NN
in IN
parsers NNS
eg VBP
de IN
< NNP
ref NN
> NNP
marcken NN
1990 CD
< NNP
/ref NNP
> NNP
. .

our PRP$
work NN
is VBZ
an DT
incremental JJ
improvement NN
on IN
these DT
models NNS
in IN
three CD
ways NNS
: :
1 CD
much RB
less JJR
training VBG
data NNS
than IN
theoretically RB
required VBN
proved JJ
adequate JJ
; :
2 CD
we PRP
integrated VBD
a DT
probabilistic JJ
model NN
of IN
word NN
features NNS
to TO
handle VB
unknown JJ
words NNS
uniformly RB
within IN
the DT
probabilistic JJ
model NN
and CC
measured VBD
its PRP$
contribution NN
; :
and CC
3 CD
we PRP
have VBP
applied VBN
the DT
forward-backward JJ
algorithm NN
to TO
accurately RB
compute VB
the DT
most RBS
likely JJ
tag NN
set VBN
. .

in IN
section NN
3 CD
, ,
we PRP
demonstrate VBP
that DT
probability NN
models NNS
can MD
improve VB
the DT
performance NN
of IN
knowledge-based JJ
syntactic JJ
and CC
semantic JJ
processing NN
in IN
dealing VBG
with IN
structural JJ
ambiguity NN
and CC
with IN
unknown JJ
words NNS
. .

finally RB
, ,
there EX
is VBZ
a DT
large JJ
body NN
of IN
work NN
, ,
eg RB
, ,
< NNP
tref VBZ
> JJ
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
passoneau NN
1988 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> CD
webber NN
1988 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
hwang NN
1992 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> NN
song NN
and CC
cohen NN
1991 CD
< NNP
/ref NNP
> NNP
, ,
that WDT
has VBZ
focused VBN
on IN
a DT
computational JJ
analysis NN
of IN
tense NN
and CC
aspect NN
. .

while IN
the DT
work NN
on IN
event NN
chronologies NNS
is VBZ
based VBN
on IN
some DT
of IN
the DT
notions NNS
developed VBD
in IN
that DT
body NN
of IN
work NN
, ,
we PRP
hope VBP
to TO
further JJ
exploit JJ
insights NNS
from IN
previous JJ
work NN
. .

in IN
the DT
work NN
described VBD
here RB
, ,
we PRP
investigate VBP
how WRB
far RB
we PRP
can MD
get VB
by IN
focusing VBG
our PRP$
attention NN
only RB
on IN
discourse NN
markers NNS
and CC
lexicogrammatical JJ
constructs NNS
that WDT
can MD
be VB
detected VBN
by IN
a DT
shallow JJ
analysis NN
of IN
natural JJ
language NN
texts NN
. .

the DT
intuition NN
behind IN
our PRP$
choice NN
relies NNS
on IN
the DT
following JJ
facts NNS
: :
psycholinguistic JJ
and CC
other JJ
empirical JJ
research NN
< NNP
ref VBZ
> NNP
kintsch NN
, ,
1977 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
schiffrin NN
, ,
1987 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
segal NN
, ,
duchan NN
, ,
and CC
scott NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
cahn NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
sanders NNS
, ,
spooren NNS
, ,
and CC
noordman RB
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
hirschberg NN
and CC
litman NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
knott NN
, ,
1995 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
costermans NNS
and CC
fayol NN
, ,
1997 CD
< NN
/ref NNP
> NNP
has VBZ
shown VBN
that IN
discourse NN
markers NNS
are VBP
consistently RB
used VBN
by IN
human JJ
subjects NNS
both DT
as IN
cohesive JJ
ties NNS
between IN
adjacent JJ
clauses NNS
and CC
as IN
macroconnectors NNS
between IN
larger JJR
textual JJ
units NNS
. .

the DT
feature NN
specification NN
of IN
this DT
ompositionally RB
derived VBN
accomplishment NN
is VBZ
therefore RB
identical JJ
to TO
that DT
of IN
a DT
sentence NN
containing VBG
a DT
telic JJ
accomplishment NN
verb NN
, ,
such JJ
as IN
destroy NN
. .

so RB
our PRP$
semantics NNS
of IN
the DT
perfect NN
is VBZ
like IN
that DT
in IN
< NNP
tref NN
> NN
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NN
: :
a DT
perfect JJ
transforms VBZ
an DT
event NN
into IN
a DT
consequent JJ
state NN
, ,
and CC
asserts VBZ
that IN
the DT
consequent JJ
state NN
holds VBZ
. .

as IN
for IN
accomplishments NNS
, ,
we PRP
can MD
assume VB
that IN
they PRP
can MD
be VB
decomposed VBN
into IN
several JJ
stages NNS
, ,
according VBG
to TO
< NNP
tref NN
> NN
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref CC
> NN
: :
first RB
a DT
preparatory NN
phase NN
, ,
second VB
a DT
culmination NN
or CC
achievement NN
we PRP
are VBP
not RB
concerned VBN
here RB
with IN
the DT
result NN
state NN
. .

we PRP
can MD
then RB
say VB
that IN
imp NN
refers NNS
only RB
to TO
the DT
preparatory NN
phase NN
, ,
so IN
that IN
the DT
term NN
of IN
the DT
eventuality NN
loses VBZ
all DT
relevance NN
. .

this DT
explains VBZ
the DT
so-called JJ
imperfective JJ
paradox NN
: :
it PRP
is VBZ
possible JJ
to TO
use VB
imp JJ
even RB
though IN
the DT
eventuality NN
never RB
reaches VBZ
its PRP$
term NN
: :
6 CD
a DT
i1 NN
traversait NN
la NN
rue FW
quand NN
la FW
voiture NN
la VBZ
6cras6 CD
he PRP
was VBD
crossing VBG
the DT
street NN
when WRB
the DT
car NN
hit VBD
him PRP
b VB
i1 NN
traversa NN
la NN
rue FW
quand NN
la FW
voiture NN
la VBZ
6cras6 CD
he PRP
crossed VBD
the DT
street NN
when WRB
the DT
car NN
hit VBD
him PRP
as IN
for IN
achievements NNS
, ,
we PRP
can MD
assume VB
that IN
they PRP
are VBP
reduced VBN
to TO
a DT
culmination NN
. .

an DT
obvious JJ
first JJ
step NN
, ,
which WDT
we PRP
are VBP
currently RB
working VBG
on IN
, ,
is VBZ
to TO
include VB
a DT
linguisticallymotivatedtemporalontology NN
< NNP
ref NN
> NNP
moensandsteedman NN
, ,
1988 CD
< NN
/ref NNP
> NNP
, ,
which WDT
will MD
be VB
separate JJ
from IN
the DT
existing VBG
domain NN
ontology NN
. .

we PRP
also RB
need VBP
better JJR
techniques NNS
for IN
communicating VBG
the DT
temporal JJ
relationships NNS
between IN
events NNS
in IN
cases NNS
where WRB
they PRP
are VBP
not RB
listed VBN
in IN
chronological JJ
order NN
< NNP
ref NN
> NNP
oberlander NN
and CC
lascarides NNS
, ,
1992 CD
< NN
/ref NNP
> NNP
. .

6 CD
discussion NN
two CD
discourse NN
analysts NNS
from IN
edinburgh JJ
university NN
, ,
dr JJ
andy JJ
mckinlay NN
and CC
dr NN
chris NN
mcvittie NN
, ,
kindly RB
examined VBD
and CC
compared VBN
some DT
of IN
the DT
human JJ
and CC
bt45 JJ
texts NN
. .

the DT
domain NN
is VBZ
limited VBN
to TO
trajectoryof-motion JJ
events NNS
specified VBN
by IN
the DT
verbs NNS
run VBP
, ,
jog NN
, ,
sit NN
is VBZ
worth JJ
noting VBG
that IN
as IN
an DT
alternative NN
to TO
positing VBG
a DT
lexical JJ
ambiguity NN
, ,
one CD
could MD
just RB
as IN
easily RB
invoke VBZ
a DT
coercion NN
operator NN
on IN
an DT
event NN
predicate NN
pz NN
mapping VBG
it PRP
to TO
the DT
process NN
predicate NN
he PRP
. .

plod NN
, ,
and CC
walk NN
; :
the DT
locative JJ
prepositions NNS
to TO
, ,
towards NNS
, ,
from IN
, ,
away RB
from IN
, ,
along IN
, ,
eastwards NNS
, ,
westwards NNS
, ,
and CC
to TO
and CC
back RB
; :
various JJ
landmarks NNS
; :
the DT
distance NN
adverbials NNS
n JJ
miles NNS
; :
the DT
frequency NN
adverbials NNS
twice RB
and CC
n JJ
times NNS
; :
and CC
finally RB
the DT
temporal JJ
adverbials NNS
for IN
and CC
in IN
. .

2 CD
3 CD
theory NN
31 CD
ontology NN
various JJ
authors NNS
including VBG
< JJ
ref NN
> NNP
link NN
, ,
1983 CD
< NN
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
bach NN
, ,
1986 CD
< NN
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
krifka NN
, ,
1989 CD
< NN
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
eberle NN
, ,
1990 CD
< NN
/ref NNP
> NNP
have VBP
proposed VBN
modeltheoretic JJ
treatments NNS
in IN
which WDT
a DT
parallel JJ
ontological JJ
distinction NN
is VBZ
made VBN
between IN
substances NNS
and CC
things NNS
, ,
processes NNS
and CC
events NNS
, ,
etc FW
a DT
similarly RB
parallel JJ
distinction NN
is VBZ
employed VBN
here RB
, ,
but CC
in IN
a DT
rather RB
different JJ
way NN
: :
unlike IN
the DT
above NN
treatments NNS
, ,
the DT
present JJ
account NN
models NNS
substances NNS
, ,
processes NNS
, ,
and CC
other JJ
such JJ
entities NNS
as IN
abstract JJ
kinds NNS
whose WP$
realizations NNS
vary VBP
in IN
amount NN
. .

extending VBG
their PRP$
ontology NN
, ,
the DT
same JJ
distinction NN
is VBZ
assumed VBN
to TO
hold VB
not RB
only RB
in IN
the DT
domain NN
of IN
materials NNS
but CC
also RB
in IN
the DT
domain NN
of IN
eventualities NNS
, ,
and CC
derivatively RB
in IN
the DT
domains NNS
of IN
space NN
and CC
time NN
as RB
well RB
. .

note NN
that IN
in IN
a DT
terminal JJ
drs NN
ready NN
for IN
an DT
embedding JJ
test NN
, ,
all PDT
the DT
auxiliary JJ
rpts NNS
disappear VBP
do VBP
not RB
participate VB
in IN
the DT
embedding NN
. .

the DT
perfect NN
is VBZ
analyzed VBN
by IN
using VBG
the DT
notion NN
of IN
a DT
nucleus JJ
< NN
tref NN
> NN
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref NNP
> NNP
to TO
account VB
for IN
the DT
inner JJ
structure NN
of IN
an DT
eventuality NN
. .

aspectual JJ
classification NN
is VBZ
necessary JJ
for IN
interpreting VBG
temporal JJ
modifiers NNS
and CC
assessing VBG
temporal JJ
entailments NNS
< VBP
tref JJ
> NN
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dorr NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
klavans NNS
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
and CC
is VBZ
therefore RB
a DT
necessary JJ
component NN
for IN
applications NNS
that WDT
perform VBP
certain JJ
language NN
interpretation NN
, ,
summarization NN
, ,
information NN
retrieval NN
, ,
and CC
machine NN
translation NN
tasks NNS
. .

aspectual JJ
classification NN
is VBZ
a DT
diflqcult NN
problem NN
because IN
many JJ
verbs NNS
, ,
like IN
have VBP
, ,
are VBP
aspectually RB
ambiguous JJ
. .

according VBG
to TO
< NNP
ref NN
> NNP
bennett NN
et NN
al NN
, ,
1990 CD
< NN
/ref NNP
> NNP
in IN
the DT
spirit NN
of IN
< NNP
tref NN
> NN
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref NNP
> NNP
, ,
predicates NNS
are VBP
allowed VBN
to TO
undergo VB
an DT
atomicity NN
coercion NN
in IN
which WDT
an DT
inherently RB
non-atomic JJ
predicate NN
such JJ
as IN
dio NN
may MD
become VB
atomic JJ
under IN
certain JJ
conditions NNS
. .

given VBN
the DT
featural JJ
scheme NN
that WDT
is VBZ
imposed VBN
on IN
top NN
of IN
the DT
lexical-semantic JJ
framework NN
, ,
it PRP
is VBZ
easy JJ
to TO
specify VB
coercion NN
functions NNS
for IN
each DT
language NN
. .

in IN
light NN
of IN
these DT
observations NNS
, ,
the DT
lexicm-semantic JJ
structure NN
adopted VBN
for IN
unitran NN
is VBZ
an DT
augmented JJ
form NN
of IN
jackendoffs NNS
representation NN
in IN
which WDT
events NNS
are VBP
distinguished VBN
from IN
states NNS
as IN
before RB
, ,
but CC
they PRP
are VBP
further JJ
subdivided VBN
into IN
activities NNS
, ,
achievements NNS
, ,
and CC
accomplishments NNS
. .

the DT
subdivision NN
is VBZ
achieved VBN
by IN
means NNS
of IN
three CD
features NNS
proposed VBN
by IN
< NNP
ref NN
> NNP
bennett NN
et NN
al NN
, ,
1990 CD
< NN
/ref NNP
> NNP
following VBG
the DT
framework NN
of IN
< NNP
tref NN
> NN
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref NNP
> NNP
in IN
the DT
spirit NN
of IN
< NNP
ref NN
> NNP
dowty NN
, ,
1979 CD
< NN
/ref NNP
> NNP
and CC
< NNP
ref VBP
> NNP
vendler NN
, ,
1967 CD
< NN
/ref CC
> NN
: :
dynamic JJ
ie NN
, ,
events NNS
vs VBP
states NNS
, ,
as IN
in IN
the DT
jackendoff NN
framework NN
, ,
: :
t NN
: :
telic JJ
i NN
e NN
, ,
culminative JJ
events NNS
transitions NNS
vs VBP
nonculminative JJ
events NNS
activities NNS
, ,
and CC
atomic JJ
ie NN
, ,
point NN
events NNS
vs VBP
extended JJ
events NNS
. .

this DT
featural JJ
system NN
is VBZ
imposed VBN
on IN
top NN
of IN
the DT
lexical-semantic JJ
framework NN
proposed VBN
by IN
jackendoff NN
. .

for IN
example NN
, ,
the DT
primitive JJ
go NN
would MD
be VB
annotated VBN
with IN
the DT
features NNS
d VBP
, ,
t NN
, ,
-a NN
for IN
the DT
verb NN
destroy NN
, ,
but CC
d NN
, ,
t NN
, ,
a DT
for IN
the DT
verb NN
obliterate NN
, ,
thus RB
providing VBG
the DT
appropriate JJ
distinction NN
for IN
cases NNS
such JJ
as IN
12 CD
. .

figure NN
2 CD
relates VBZ
the DT
four CD
types NNS
of IN
lexical-semantic JJ
frameworks NNS
outlined VBN
above IN
. .

note NN
that IN
the DT
system NN
of IN
features NNS
proposed VBN
by IN
< NNP
ref NN
> NNP
bennett NN
et NN
al NN
, ,
1990 CD
< NN
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NNP
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref NNP
> NNP
provide VBP
the DT
finest JJS
tuning NN
given VBN
that IN
five CD
distinct JJ
categories NNS
of IN
predicates NNS
are VBP
identified VBN
by IN
the DT
feature NN
settings NNS
. .

this DT
system NN
is VBZ
essentially RB
equivalent JJ
to TO
the DT
dowty/vendler NN
proposal NN
, ,
but CC
features NNS
are VBP
used VBN
to TO
distinguish VB
the DT
categories NNS
more RBR
precisely RB
. .

in IN
the DT
next JJ
section NN
, ,
we PRP
will MD
see VB
how WRB
the DT
tense NN
and CC
aspect JJ
structure NN
described VBN
in IN
section NN
21 CD
and CC
the DT
lexicm-semantic JJ
representation NN
described VBN
in IN
this DT
section NN
are VBP
combined VBN
to TO
provide VB
the DT
framework NN
for IN
generating VBG
a DT
target-language JJ
surface NN
form NN
. .

< JJ
ref NN
> NNP
dowty NN
1986 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NNP
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
decisively RB
questioned VBD
the DT
coherence NN
of IN
the DT
class NN
of IN
achievement NN
verbs NN
, ,
arguing VBG
that IN
not RB
all DT
of IN
them PRP
are VBP
non-durative JJ
. .

as IN
noted VBN
above IN
, ,
vendler NN
identifies NNS
punctual JJ
events NNS
through IN
the DT
conjunction NN
of IN
the DT
positive JJ
at IN
and CC
negative JJ
finish NN
tests NNS
. .

we PRP
impose VBP
this DT
system NN
of IN
features NNS
on IN
top NN
of IN
the DT
current JJ
lexical-semantic JJ
framework NN
. .

for IN
example NN
, ,
the DT
lexical JJ
entry NN
for IN
all DT
three CD
verbs NNS
, ,
ransack NN
, ,
obliterate NN
, ,
and CC
destroy NN
, ,
would MD
contain VB
the DT
following JJ
lexical-semantic JJ
representation NN
: :
6 CD
event NN
cause NN
thing NN
x NN
, ,
event NN
goloc NN
thing NN
x NN
, ,
position NN
toloc NN
x NNP
john NN
, ,
property NN
destroyed VBD
the DT
three CD
verbs NNS
would MD
then RB
be VB
distinguished VBN
by IN
annotating VBG
this DT
representation NN
with IN
the DT
aspectual JJ
features NNS
d VBP
, ,
t NN
, ,
-a NN
for IN
the DT
verb NN
ransack NN
, ,
d NN
, ,
t NN
, ,
-a NN
for IN
the DT
verb NN
destroy NN
, ,
and CC
d NN
, ,
t NN
, ,
a DT
for IN
the DT
verb NN
obliterate NN
, ,
thus RB
providing VBG
the DT
appropriate JJ
distinction NN
for IN
cases NNS
such JJ
as IN
4 CD
. .

s NN
: :
juan NN
le NN
dio NN
una JJ
puflajada NN
a DT
marls NN
john NN
gave VBD
a DT
knife-wound NN
to TO
mary JJ
s NN
: :
juan NN
le NN
dio NN
pufialadas VBZ
a DT
marls JJ
john NN
gave VBD
knife-wounds NNS
to TO
mary VB
b NN
duratlve NN
divergence NN
, ,
e NN
: :
john NN
met/knew VBD
mary JJ
4 CD
s NN
: :
juan NN
coaoci6 VBZ
a DT
marls NN
john NN
met VBD
mary JJ
s NN
: :
juan NN
conoci VBZ
a DT
mrfa NN
john NN
knew VBD
merit JJ
figure NN
1 CD
: :
three CD
levels NNS
of IN
mt NN
divergences NNS
et VBP
el NN
. .

1990 CD
have VBP
examined VBN
aspect NN
and CC
verb NN
semantics NNS
within IN
the DT
context NN
of IN
machine NN
translation NN
in IN
the DT
spirit NN
of IN
< NNP
tref NN
> NN
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
. .

knowledge NN
of IN
lexical JJ
aspect NN
, ,
eg NN
, ,
atelicity NN
, ,
is VBZ
therefore RB
required VBN
for IN
interpreting VBG
event NN
sequences NNS
in IN
discourse NN
< NN
ref NN
> NNP
dowty NN
, ,
1986 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> JJ
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
passoneau NN
, ,
1988 CD
< NN
/ref NNP
> NNP
, ,
interfacing VBG
to TO
temporal JJ
databases NNS
< VBP
ref JJ
> NNP
androutsopoulos NN
, ,
1996 CD
< NN
/ref NNP
> NNP
, ,
processing VBG
temporal JJ
modifiers NNS
< VBP
ref JJ
> NNP
antonisse NN
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
describing VBG
allowable JJ
alternations NNS
and CC
their PRP$
semantic JJ
effects NNS
< VBP
ref JJ
> NNP
resnik NN
, ,
1996 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
tenny NN
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
and CC
selecting VBG
tense NN
and CC
lexical JJ
items NNS
for IN
natural JJ
language NN
generation NN
< NNP
ref NN
> NNP
dorr NN
and CC
olsen NN
, ,
1996 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
klavans NNS
and CC
chodorow NN
, ,
1992 CD
< NN
/ref NNP
> NNP
, ,
cf NN
. .

we PRP
show VBP
that IN
it PRP
is VBZ
possible JJ
to TO
represent VB
lexical JJ
aspect NN
-- :
both DT
verbal JJ
and CC
compositional JJ
-- :
on IN
a DT
large JJ
scale NN
, ,
using VBG
lexical JJ
conceptual JJ
structure NN
lcs JJ
representations NNS
of IN
verbs NN
in IN
the DT
classes NNS
cataloged VBN
by IN
< NNP
ref NN
> NNP
levin NN
1993 CD
< NNP
/ref NNP
> NNP
. .

knowledge NN
of IN
lexical JJ
aspect NN
-- :
how WRB
verbs JJ
denote NN
situations NNS
as IN
developing VBG
or CC
holding VBG
in IN
time NN
-- :
is VBZ
required VBN
for IN
interpreting VBG
event NN
sequences NNS
in IN
discourse NN
< NN
ref NN
> NNP
dowty NN
, ,
1986 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> JJ
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
passoneau NN
, ,
1988 CD
< NN
/ref NNP
> NNP
, ,
interfacing VBG
to TO
temporal JJ
databases NNS
< VBP
ref JJ
> NNP
androutsopoulos NN
, ,
1996 CD
< NN
/ref NNP
> NNP
, ,
processing VBG
temporal JJ
modifiers NNS
< VBP
ref JJ
> NNP
antonisse NN
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
describing VBG
allowable JJ
alternations NNS
and CC
their PRP$
semantic JJ
effects NNS
< VBP
ref JJ
> NNP
resnik NN
, ,
1996 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
tenny NN
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
and CC
for IN
selecting VBG
tense NN
and CC
lexical JJ
items NNS
for IN
natural JJ
language NN
generation NN
dorr NN
and CC
olsen NN
. .

as IN
with IN
36d CD
, ,
the DT
relevant JJ
elements NNS
of IN
37b CD
can MD
be VB
represented VBN
as IN
then RB
r NN
after IN
s JJ
turn NN
right NN
on IN
county NN
line NN
e VBD
3 CD
: :
turn-rightyou NN
, ,
county NN
line NN
and CC
the DT
unresolved JJ
interpretation NN
of IN
37b CD
is VBZ
thus RB
xafterx JJ
, ,
eve VBP
3 CD
aftere RB
3 CD
, ,
ev RB
560 CD
computational JJ
linguistics NNS
volume NN
29 CD
, ,
number NN
4 CD
as IN
for IN
resolving VBG
ev NN
, ,
in IN
a DT
well-known JJ
article NN
, ,
< NNP
tref VBZ
> JJ
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
discuss VBZ
several JJ
ways NNS
in IN
which WDT
an DT
eventuality NN
of IN
one CD
type NN
eg NN
, ,
a DT
process NN
can MD
be VB
coerced VBN
into IN
an DT
eventuality NN
of IN
another DT
type NN
eg NN
, ,
an DT
accomplishment NN
, ,
which WDT
moens VBZ
and CC
steedman JJ
call VB
a DT
culminated JJ
process NN
. .

in IN
this DT
case NN
, ,
the DT
matrix NN
argument NN
of IN
then RB
the DT
eventuality NN
of IN
turning VBG
right NN
on IN
county NN
line NN
can MD
be VB
used VBN
to TO
coerce VB
the DT
process NN
eventuality NN
in IN
37b CD
into IN
a DT
culminated JJ
process NN
of IN
going VBG
west JJS
on IN
lancaster JJ
avenue NN
until IN
county JJ
line NN
. .

we PRP
treat VBP
this DT
coercion NN
as IN
a DT
type NN
of IN
associative JJ
or CC
bridging VBG
inference NN
, ,
as IN
in IN
the DT
examples NNS
discussed VBN
in IN
section NN
31 CD
. .

this DT
allows VBZ
a DT
modular JJ
representation NN
of IN
the DT
semantics NNS
of IN
temporal JJ
adverbials NNS
like IN
until IN
and CC
by IN
, ,
and CC
also RB
aids NNS
in IN
the DT
generation NN
of IN
tense NN
and CC
aspect NN
. .

this DT
system NN
looks VBZ
at IN
the DT
mechanics NNS
of IN
how WRB
the DT
alternatives NNS
can MD
be VB
generated VBN
from IN
the DT
initial JJ
data NNS
, ,
but CC
we PRP
will MD
have VB
less JJR
to TO
say VB
about IN
choosing VBG
between IN
them PRP
. .

ve NN
adopt NN
and CC
extend VB
the DT
feature-based JJ
framework NN
proposed VBN
by IN
< NNP
ref NN
> NNP
bennett NN
et NN
al NN
, ,
1990 CD
< NN
/ref NNP
> NNP
in IN
the DT
spirit NN
of IN
< NNP
tref NN
> NN
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref NNP
> NNP
. .

they PRP
uses VBP
three CD
features NNS
: :
dynamic JJ
, ,
telic JJ
, ,
and CC
atomic JJ
. .

in IN
principle NN
, ,
it PRP
is VBZ
possible JJ
for IN
this DT
second JJ
module NN
to TO
detect VB
aspectual JJ
transformations NNS
that WDT
apply VBP
to TO
any DT
input NN
clause NN
, ,
independent JJ
of IN
the DT
manner NN
in IN
which WDT
the DT
core NN
constituents NNS
interact VBP
to TO
produce VB
its PRP$
fundamental JJ
aspectual JJ
class NN
. .

600 CD
siegel NN
and CC
mckeown JJ
improving VBG
aspectual JJ
classification NN
26 CD
applications NNS
of IN
aspectual JJ
classification NN
aspectual JJ
classification NN
is VBZ
a DT
required JJ
component NN
of IN
applications NNS
that WDT
perform VBP
natural JJ
language NN
interpretation NN
, ,
natural JJ
language NN
generation NN
, ,
summarization NN
, ,
information NN
retrieval NN
, ,
and CC
machine NN
translation NN
tasks NNS
< VBP
tref JJ
> NN
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
klavans NNS
and CC
chodorow NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
klavans NNS
1994 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
dorr NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
wiebe NN
et NN
al NN
1997 CD
< NNP
/ref NNP
> NNP
. .

these DT
applications NNS
require VBP
the DT
ability NN
to TO
reason NN
about IN
time NN
, ,
ie NN
, ,
temporal JJ
reasoning NN
. .

598 CD
siegel NN
and CC
mckeown JJ
improving VBG
aspectual JJ
classification NN
table NN
3 CD
several JJ
aspectual JJ
entailments NNS
. .

if IN
a DT
clause NN
occurring NN
: :
necessarily RB
entails VBZ
: :
then RB
it PRP
must MD
be VB
: :
in IN
past JJ
progressive JJ
tense NN
as IN
argument NN
of IN
stopped VBN
in IN
simple JJ
present JJ
tense NN
past IN
tense NN
reading NN
past IN
tense NN
reading VBG
the DT
habitual JJ
reading NN
nonculminated JJ
event NN
nonculminated VBN
event NN
or CC
state NN
event NN
23 CD
interpreting VBG
temporal JJ
connectives NNS
and CC
modifiers NNS
several JJ
researchers NNS
have VBP
developed VBN
models NNS
that IN
incorporate VBP
aspectual JJ
class NN
to TO
assess VB
temporal JJ
constraints NNS
between IN
connected VBN
clauses NNS
< VBP
ref JJ
> NNP
hwang NN
and CC
schubert JJ
1991 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
schubert NN
and CC
hwang NN
1990 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
dorr NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
passonneau NN
1988 CD
< NNP
/ref NNP
> NNP
; :
< NNP
tref VBZ
> JJ
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
hitzeman NN
, ,
moens NNS
, ,
and CC
grover NN
1994 CD
< NNP
/ref NNP
> NNP
. .

for IN
example NN
, ,
in IN
interpreting NN
, ,
7 CD
she PRP
had VBD
good JJ
strength NN
when WRB
objectively RB
tested VBN
. .

an DT
understanding JJ
system NN
can MD
recognize VB
the DT
aspectual JJ
transformations NNS
that WDT
have VBP
affected VBN
a DT
clause NN
only RB
after IN
establishing VBG
the DT
clauses NNS
fundamental JJ
aspectual JJ
category NN
. .

linguistic JJ
models NNS
motivate VBP
the DT
division NN
between IN
a DT
module NN
that IN
first JJ
detects NNS
fundamental JJ
aspect NN
and CC
a DT
second JJ
that WDT
detects VBZ
aspectual JJ
transformations NNS
< VBP
ref JJ
> NNP
hwang NN
and CC
schubert JJ
1991 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
schubert NN
and CC
hwang NN
1990 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
dorr NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
passonneau NN
1988 CD
< NNP
/ref NNP
> NNP
; :
< NNP
tref VBZ
> JJ
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
hitzeman NN
, ,
moens NNS
, ,
and CC
grover NN
1994 CD
< NNP
/ref NNP
> NNP
. .

in IN
principle NN
, ,
it PRP
is VBZ
possible JJ
for IN
this DT
second JJ
module NN
to TO
detect VB
aspectual JJ
transformations NNS
that WDT
apply VBP
to TO
any DT
input NN
clause NN
, ,
independent JJ
of IN
the DT
manner NN
in IN
which WDT
the DT
core NN
constituents NNS
interact VBP
to TO
produce VB
its PRP$
fundamental JJ
aspectual JJ
class NN
. .

600 CD
siegel NN
and CC
mckeown JJ
improving VBG
aspectual JJ
classification NN
26 CD
applications NNS
of IN
aspectual JJ
classification NN
aspectual JJ
classification NN
is VBZ
a DT
required JJ
component NN
of IN
applications NNS
that WDT
perform VBP
natural JJ
language NN
interpretation NN
, ,
natural JJ
language NN
generation NN
, ,
summarization NN
, ,
information NN
retrieval NN
, ,
and CC
machine NN
translation NN
tasks NNS
< VBP
tref JJ
> NN
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
klavans NNS
and CC
chodorow NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
klavans NNS
1994 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
dorr NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
wiebe NN
et NN
al NN
1997 CD
< NNP
/ref NNP
> NNP
. .

for IN
example NN
, ,
the DT
progressive JJ
marker NN
is VBZ
constrained VBN
to TO
appear VB
with IN
an DT
extended JJ
event NN
. .

e-mail NN
: :
kathycscolumbiaedu NN
2001 CD
association NN
for IN
computational JJ
linguistics NNS
computational JJ
linguistics NNS
volume NN
26 CD
, ,
number NN
4 CD
aspectual JJ
classification NN
is VBZ
necessary JJ
for IN
interpreting VBG
temporal JJ
modifiers NNS
and CC
assessing VBG
temporal JJ
entailments NNS
< VBP
tref JJ
> NN
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> CD
dorr NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
klavans NNS
1994 CD
< NNP
/ref NNP
> NNP
and CC
is VBZ
therefore RB
a DT
required JJ
component NN
for IN
applications NNS
that WDT
perform VBP
certain JJ
natural JJ
language NN
interpretation NN
, ,
generation NN
, ,
summarization NN
, ,
information NN
retrieval NN
, ,
and CC
machine NN
translation NN
tasks NNS
. .

each DT
of IN
these DT
applications NNS
requires VBZ
the DT
ability NN
to TO
reason NN
about IN
time NN
. .

a DT
verbs JJ
aspectual JJ
category NN
can MD
be VB
predicted VBN
by IN
co-occurrence NN
frequencies NNS
between IN
the DT
verb NN
and CC
linguistic JJ
phenomena NNS
such JJ
as IN
the DT
progressive JJ
tense NN
and CC
certain JJ
temporal JJ
modifiers NNS
< VBP
ref JJ
> NN
klavans NNS
and CC
chodorow NN
1992 CD
< NNP
/ref NNP
> NNP
. .

aspectual JJ
classification NN
is VBZ
also RB
a DT
necessary JJ
prerequisite NN
for IN
interpreting VBG
certain JJ
adverbial JJ
adjuncts NNS
, ,
as RB
well RB
as IN
identifying VBG
temporal JJ
constraints NNS
between IN
sentences NNS
in IN
a DT
discourse NN
< NN
tref NN
> NN
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> CD
dorr NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
klavans NNS
1994 CD
< NNP
/ref NNP
> NNP
. .

in IN
addition NN
to TO
the DT
two CD
distinctions NNS
described VBN
in IN
the DT
previous JJ
section NN
, ,
atomicity NN
distinguishes NNS
punctual JJ
events NNS
eg NN
, ,
she PRP
noticed VBD
the DT
picture NN
on IN
the DT
wall NN
from IN
extended JJ
events NNS
, ,
which WDT
have VBP
a DT
time NN
duration NN
eg NN
, ,
she PRP
ran VBD
to TO
the DT
store NN
. .

that DT
is VBZ
, ,
the DT
fundamental JJ
aspectual JJ
category NN
is VBZ
the DT
category NN
the DT
clause NN
would MD
have VB
if IN
it PRP
were VBD
stripped VBN
of IN
any DT
and CC
all DT
aspectual JJ
markers NNS
that WDT
induce VBP
an DT
aspectual JJ
transformation NN
, ,
as RB
well RB
as IN
all DT
components NNS
of IN
the DT
clauses NNS
pragmatic JJ
context NN
that WDT
induce VBZ
a DT
transformation NN
. .

aspect NN
in IN
natural JJ
language NN
because IN
, ,
in IN
general JJ
, ,
the DT
sequential JJ
order NN
of IN
clauses NNS
is VBZ
not RB
enough RB
to TO
determine VB
the DT
underlying JJ
chronological JJ
order NN
, ,
aspectual JJ
classification NN
is VBZ
required VBN
for IN
interpreting VBG
596 CD
siegel NN
and CC
mckeown JJ
improving VBG
aspectual JJ
classification NN
table NN
1 CD
aspectual JJ
classes NNS
. .

culminated VBN
nonculminated JJ
events NNS
punctual JJ
extended VBD
culmination NN
culminated VBD
process NN
recognize NN
build VB
a DT
house NN
point NN
process NN
hiccup NN
run NN
, ,
swim NN
, ,
walk VB
states NNS
understand RB
even RB
the DT
simplest JJS
narratives NNS
in IN
natural JJ
language NN
. .

the DT
imperfective JJ
paradox NN
and CC
trajectory-of-motion NN
events NNS
michael JJ
white JJ
department NN
of IN
computer NN
and CC
information NN
science NN
university NN
of IN
pennsylvania NN
philadelphia NN
, ,
pa NN
, ,
usa JJ
mwhit NN
el NN
inc NN
c NN
is VBZ
upenn JJ
, ,
edu JJ
abstract NN
in IN
the DT
first JJ
part NN
of IN
the DT
paper NN
, ,
i JJ
present VBP
a DT
new JJ
treatment NN
of IN
the DT
imperfictive JJ
paradox NN
< NNP
ref NN
> NNP
dowty NN
1979 CD
< NNP
/ref NNP
> NNP
for IN
the DT
restricted JJ
case NN
of IN
trajectoryof-motion NN
events NNS
. .

bach NN
1986:12 CD
summarizes VBZ
the DT
imperfective JJ
paradox NN
< NNP
ref NN
> NNP
dowty NN
1979 CD
< NNP
/ref NNP
> NNP
as IN
follows VBZ
: :
how WRB
can MD
we PRP
characterize VB
the DT
meaning NN
of IN
a DT
progressive JJ
sentence NN
like IN
la $
17 CD
on IN
the DT
basis NN
of IN
the DT
meaning NN
of IN
a DT
simple JJ
sentence NN
like IN
lb NN
18 CD
when WRB
la NN
can MD
be VB
true JJ
of IN
a DT
history NN
without IN
lb NN
ever RB
being VBG
true JJ
. .

< JJ
ref NN
> NNP
white JJ
1993 CD
< NN
/ref NNP
> NNP
. .

5much CD
as IN
in IN
< NNP
tref NN
> NN
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
and CC
< NNP
ref VBP
> NNP
jackendoff NN
1991 CD
< NNP
/ref NNP
> NNP
, ,
the DT
introduction NN
of IN
gr NN
is VBZ
necessary JJ
to TO
avoid VB
having VBG
an DT
ill-sorted JJ
formula NN
. .

284 CD
the DT
manner NN
of IN
motion NN
supplied VBN
by IN
a DT
verb NN
, ,
it PRP
does VBZ
nevertheless RB
permit VB
one CD
to TO
consider VB
factors NNS
such JJ
as IN
the DT
normal JJ
speed NN
as RB
well RB
as IN
the DT
meanings NNS
of IN
the DT
prepositions NNS
10 CD
, ,
lowards NNS
, ,
etc FW
by IN
making VBG
two CD
additional JJ
restrictive JJ
assumptions NNS
, ,
namely RB
that IN
these DT
events NNS
be VB
of IN
constant JJ
velocity NN
and CC
in IN
one CD
dimension NN
, ,
i NN
have VBP
been VBN
able JJ
to TO
construct VB
and CC
implement VB
an DT
algorithm NN
which WDT
determines VBZ
whether IN
a DT
specified JJ
sequence NN
of IN
such JJ
events NNS
is VBZ
or CC
is VBZ
not RB
possible JJ
under IN
certain JJ
situationally RB
supplied JJ
constraints NNS
. .

these DT
constraints NNS
include VBP
the DT
locations NNS
of IN
various JJ
landmarks NNS
assumed VBD
to TO
remain VB
stationary JJ
and CC
the DT
minimum NN
, ,
maximum NN
, ,
and CC
normal JJ
rates NNS
associated VBN
with IN
various JJ
manners NNS
of IN
motion NN
eg NN
running VBG
, ,
jogging VBG
for IN
a DT
given VBN
individual NN
. .

capitalizing VBG
on IN
bachs NN
insight NN
, ,
i JJ
present NN
in IN
the DT
first JJ
part NN
of IN
the DT
paper NN
a DT
new JJ
treatment NN
of IN
the DT
imperfective JJ
paradox NN
which WDT
relies VBZ
on IN
the DT
possibility NN
of IN
having VBG
actual JJ
events NNS
standing VBG
in IN
the DT
part-of JJ
relation NN
to TO
hypothetical JJ
super-events NNS
. .

1 CD
in IN
particular JJ
, ,
the DT
present JJ
treatment NN
correctly RB
accounts VBZ
not RB
only RB
for IN
what WP
2a CD
fails NNS
to TO
entail VB
-namely RB
, ,
that IN
john NN
eventually RB
reaches VBZ
the DT
museum NN
-but NN
also RB
for IN
what WP
2a CD
does VBZ
in IN
fact NN
entail NN
-namely RB
, ,
that IN
john NN
follows VBZ
by IN
jogging VBG
at IN
least JJS
an DT
initial JJ
part NN
of IN
a DT
path NN
that WDT
leads VBZ
to TO
the DT
museum NN
. .

as IN
for IN
accomplishments NNS
, ,
we PRP
can MD
assume VB
that IN
they PRP
can MD
be VB
decomposed VBN
into IN
several JJ
stages NNS
, ,
according VBG
to TO
< NNP
tref NN
> NN
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref CC
> NN
: :
first JJ
preparatory NN
phase NN
, ,
second VB
a DT
cuhnination NN
or CC
achievement NN
we PRP
are VBP
not RB
concerned VBN
here RB
with IN
the DT
result NN
state NN
. .

we PRP
can MD
then RB
say VB
that IN
imp NN
refers NNS
only RB
to TO
the DT
preparatory NN
phase NN
, ,
so IN
that IN
the DT
term NN
of IN
the DT
eventuality NN
loses VBZ
all DT
relevance NN
. .

this DT
explains VBZ
the DT
so-called JJ
imperfective JJ
paradox NN
: :
it PRP
is VBZ
possible JJ
to TO
use VB
imp JJ
even RB
though IN
the DT
eventnality NN
never RB
reaches VBZ
its PRP$
term NN
: :
6 CD
a DT
i1 NN
traversait NN
la NN
rue FW
quand NN
la FW
voiture NN
la NN
ras6 NN
he PRP
was VBD
crossing VBG
the DT
street NN
when WRB
the DT
car NN
hit VBD
him PRP
b VB
i1 NN
traversa NN
la NN
rue FW
quand NN
la FW
voiture NN
la FW
6cras6 CD
ile NN
crossed VBD
the DT
street NN
when WRB
the DT
car NN
hit VBD
him PRP
as IN
for IN
achievements NNS
, ,
we PRP
can MD
assume VB
that IN
they PRP
are VBP
reduced VBN
to TO
a DT
culmination NN
. .

aspectual JJ
classification NN
is VBZ
a DT
necessary JJ
component NN
for IN
a DT
system NN
that WDT
analyzes VBZ
temporal JJ
constraints NNS
, ,
or CC
performs NNS
lexical JJ
choice NN
and CC
tense NN
selection NN
in IN
machine NN
translation NN
< NNP
tref NN
> NN
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
passonneau NN
, ,
1988 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
doff NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
klavans NNS
, ,
1994 CD
< NN
/ref NNP
> NNP
. .

specifically RB
, ,
this DT
technique NN
takes VBZ
advantage NN
of IN
linguistic JJ
constraints NNS
that WDT
pertain VBP
to TO
aspect VB
, ,
eg VB
, ,
only RB
clauses VBZ
that IN
describe VBG
an DT
event NN
can MD
appear VB
in IN
the DT
progressive NN
. .

by IN
using VBG
tags NN
we PRP
get VBP
the DT
additional JJ
benefit NN
of IN
an DT
existing VBG
parser NN
that WDT
yields VBZ
derivations NNS
and CC
derived VBD
trees NNS
fiom VBP
which WDT
we PRP
can MD
construct VB
the DT
compositional JJ
semantics NNS
of IN
a DT
given VBN
sentence NN
. .

we PRP
decompose VBP
each DT
event NN
e NN
into IN
a DT
tripartite JJ
structure NN
in IN
a DT
manner NN
similar JJ
to TO
< VB
tref JJ
> NN
moens NNS
and CC
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
, ,
introducing VBG
a DT
time NN
function NN
for IN
each DT
predicate NN
to TO
specify VB
whether IN
the DT
predicate NN
is VBZ
true JJ
in IN
the DT
preparatory NN
dringe NN
, ,
cuhnination NN
erde NN
, ,
or CC
consequent JJ
resll NN
: :
e JJ
stage NN
of IN
an DT
event NN
. .

hfitial JJ
trees NNS
capture VBP
tile JJ
semantics NNS
of IN
the DT
basic JJ
senses NNS
of IN
verbs NNS
in IN
each DT
class NN
. .

for IN
example NN
, ,
many JJ
ithese JJ
restrictions NNS
are VBP
more RBR
like JJ
preferences NNS
that WDT
generate VBP
a DT
preferred JJ
reading NN
of IN
a DT
sentence NN
. .

aspectual JJ
classification NN
is VBZ
necessary JJ
for IN
interpreting VBG
temporal JJ
modifiers NNS
and CC
assessing VBG
temporal JJ
entailments NNS
< VBP
ref JJ
> NNP
vendler NN
, ,
1967 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dowty NN
, ,
1979 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> JJ
moens NNS
and CC
steedman NN
, ,
1988 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dorr NN
, ,
1992 CD
< NN
/ref NNP
> NNP
, ,
and CC
is VBZ
therefore RB
a DT
necessary JJ
component NN
for IN
applications NNS
that WDT
perform VBP
certain JJ
natural JJ
language NN
interpretation NN
, ,
natural JJ
language NN
generation NN
, ,
summarization NN
, ,
information NN
retrieval NN
, ,
and CC
machine NN
translation NN
tasks NNS
. .

although IN
an DT
aspectual JJ
lexicon NN
of IN
verbs NNS
would MD
suffice VB
to TO
classify VB
many JJ
clauses NNS
by IN
their PRP$
main JJ
verb NN
only RB
, ,
a DT
verbs JJ
primary JJ
class NN
is VBZ
often RB
domaindependent JJ
< NNP
ref NN
> NNP
siegel NN
, ,
1998b CD
< NN
/ref NNP
> NNP
. .

culm JJ
events NNS
states VBZ
punctual JJ
extended VBD
culm JJ
culm NN
process NN
recognize VBP
build VB
a DT
house NN
nonpoint NN
process NN
culm NN
hiccup NN
run NN
, ,
swim JJ
understand VBP
2 CD
aspect NN
in IN
natural JJ
language NN
table JJ
1 CD
summarizes VBZ
the DT
three CD
aspectual JJ
distinctions NNS
, ,
which WDT
compose VBP
five CD
aspectual JJ
categories NNS
. .

in IN
addition NN
to TO
the DT
two CD
distinctions NNS
described VBN
in IN
the DT
previous JJ
section NN
, ,
atomicity NN
distinguishes NNS
events NNS
according VBG
to TO
whether IN
they PRP
have VBP
a DT
time NN
duration NN
punctual JJ
versus NN
extended VBD
. .

3 CD
3many CD
of IN
these DT
issues NNS
are VBP
discussed VBN
in IN
the DT
cl NN
special JJ
issue NN
on IN
tense NN
and CC
aspect JJ
< NNP
ref NN
> NNP
june NN
, ,
1988 CD
< NN
/ref NNP
> NNP
in IN
articles NNS
by IN
hinniche NN
, ,
moens NNS
and CC
steedman NN
, ,
nakhimovsky JJ
, ,
passoneau NN
, ,
and CC
webber NN
. .

for IN
example NN
, ,
passoneau NN
demonstrates VBZ
how WRB
, ,
without IN
an DT
ccurate JJ
specification NN
of IN
the DT
pectual JJ
tendencies NNS
of IN
the DT
verb NN
coupled VBN
with IN
the DT
effect NN
of IN
temporal JJ
and CC
aspectual JJ
adjuncts NNS
, ,
messages NNS
, ,
which WDT
tend VBP
to TO
be VB
in IN
the DT
present JJ
tense NN
, ,
ttre VBZ
not RB
correctly RB
understood JJ
nor CC
generated VBN
in IN
the DT
pundit NN
system NN
. .

it PRP
is VBZ
also RB
clear JJ
that IN
events NNS
are VBP
not RB
undifferentiated JJ
masses NNS
, ,
but CC
rather RB
have VB
subparts NNS
that WDT
can MD
be VB
picked VBN
out RP
by IN
the DT
choice NN
of IN
phrase NN
type NN
or CC
the DT
addition NN
of IN
adverbial JJ
phrases NNS
. .

when WRB
the DT
children NNS
crossed VBD
the DT
road NN
, ,
a DT
they PRP
waited VBD
for IN
the DT
teacher NN
to TO
give VB
a DT
signal NN
b NN
they PRP
stepped VBD
onto IN
its PRP$
concrete JJ
surface NN
as IN
if IN
it PRP
were VBD
about RB
to TO
swallow VB
them PRP
up RP
. .

stative JJ
belongs NNS
to TO
the DT
aktionsart JJ
categorisation NN
of IN
verbs NN
distinguishing VBG
it PRP
from IN
verbs NN
of IN
activity NN
, ,
achievement NN
and CC
accomplishment NN
, ,
which WDT
is VBZ
orthogonal JJ
to TO
the DT
categorisation NN
of IN
verbs NN
into IN
semantic JJ
fields NNS
< VBP
ref JJ
> NNP
vendler NN
, ,
1967 CD
< NN
/ref NNP
> NNP
, ,
< NNP
tref VBZ
> JJ
moens NNS
steedman JJ
1988 CD
< NNP
/tref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
amaro NN
, ,
2006 CD
< NN
/ref NNP
> NNP
. .

differences NNS
in IN
annotation NN
could MD
be VB
due JJ
to TO
the DT
differences NNS
in IN
interpretations NNS
of IN
the DT
event NN
; :
however RB
, ,
we PRP
found VBD
that IN
the DT
vast JJ
majority NN
of IN
radically RB
different JJ
judgments NNS
can MD
be VB
categorized VBN
into IN
a DT
relatively RB
small JJ
number NN
of IN
classes NNS
. .

22 CD
event NN
classes NNS
action NN
vs NN
state NN
: :
actions NNS
involve VBP
change NN
, ,
such JJ
as IN
those DT
described VBN
by IN
words NNS
like IN
speaking NN
, ,
gave VBD
, ,
and CC
skyrocketed VBD
. .

we PRP
designed VBD
the DT
243 CD
algorithms NN
and CC
structures NNS
necessary JJ
to TO
generate VB
discourse JJ
entities NNS
from IN
our PRP$
logical JJ
representation NN
of IN
the DT
meaning NN
of IN
utterances NNS
, ,
and CC
from IN
pointing VBG
gestures NNS
, ,
and CC
currently RB
use VBP
them PRP
in IN
januss NN
< NNP
ref NN
> NNP
weischedel NN
et NN
al NN
, ,
1987 CD
< NN
/ref NNP
> NNP
, ,
bsn NN
, ,
1988 CD
pronoun NN
resolution NN
component NN
, ,
which WDT
applies VBZ
centering VBG
techniques NNS
< NNP
tref NN
> NNP
grosz NN
et NN
al NN
, ,
1983 CD
< NN
/tref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
sidner NN
1981 CD
, ,
1983 CD
< NN
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
brennan NN
et NN
al NN
1987 CD
< NNP
/ref NNP
> NNP
to TO
track VB
and CC
constrain VB
references NNS
. .

2 CD
meaninq JJ
representation NN
for IN
de FW
generation NN
webber NN
found VBD
that IN
appropriate JJ
discourse NN
entities NNS
could MD
be VB
generated VBN
from IN
the DT
meaning VBG
representation NN
of IN
a DT
sentence NN
by IN
applying VBG
rules NNS
to TO
the DT
representation NN
that WDT
are VBP
strictly RB
structural JJ
in IN
nature NN
, ,
as RB
long RB
as IN
the DT
representation NN
reflects VBZ
certain JJ
crucial JJ
aspects NNS
of IN
the DT
sentence NN
. .

depending VBG
on IN
the DT
properties NNS
of IN
a DT
particular JJ
grammar NN
, ,
it PRP
may MD
, ,
for IN
example NN
, ,
be VB
worthwhile JJ
to TO
restrict VB
a DT
given VBN
category NN
to TO
its PRP$
syntactic JJ
features NNS
before IN
attempting VBG
to TO
solve VB
the DT
parse-goal NN
of IN
that DT
category NN
. .

for IN
example NN
, ,
the DT
category NN
xa NNP
, ,
b NN
, ,
f VB
a DT
, ,
b NN
, ,
ga NN
, ,
hb NN
, ,
i JJ
c VBP
may MD
be VB
weakened VBN
into IN
: :
xa NN
, ,
b NN
, ,
f NN
, ,
,g NNP
, ,
if IN
we PRP
assume VBP
that IN
the DT
predicate NN
weaken/2 NN
relates VBZ
a DT
term NN
t NN
to TO
a DT
weakened VBN
version NN
tw NN
, ,
such JJ
that IN
tw JJ
subsumes NNS
t RB
, ,
then RB
15 CD
is VBZ
the DT
improved JJ
version NN
of IN
the DT
parse JJ
predicate NN
: :
parsewithweakening NN
cat NN
, ,
p0 NN
, ,
p NN
, ,
e0 NN
, ,
e VBZ
15 CD
weakencat NN
, ,
weakenedcat NN
, ,
parseweakenedcat NN
, ,
p0 NN
, ,
p NN
, ,
e0 NN
, ,
e NN
, ,
catweakenedcat NN
. .

2 CD
there EX
are VBP
important JJ
differences NNS
between IN
the DT
technique NN
for IN
limited JJ
prediction NN
in IN
this DT
parser NN
, ,
and CC
other JJ
techniques NNS
for IN
limited JJ
prediction NN
such JJ
as IN
shiebers NNS
notion NN
of IN
restriction NN
< NNP
tref NN
> NNP
shieber NN
, ,
1985 CD
< NN
/tref NNP
> NNP
which WDT
we PRP
also RB
use VBP
. .

in IN
methods NNS
such JJ
as IN
shiebers NNS
, ,
predictions NNS
are VBP
weakened VBN
in IN
ways NNS
that WDT
can MD
result VB
in IN
an DT
overall JJ
gain NN
in IN
efficiency NN
, ,
but CC
predictions NNS
nevertheless RB
must MD
be VB
dynamically RB
generated VBN
for IN
every DT
phrase NN
that WDT
is VBZ
built VBN
bottom-up NN
. .

in IN
addition NN
, ,
the DT
parser NN
maintains VBZ
a DT
skeletal JJ
copy NN
of IN
the DT
chart NN
in IN
which WDT
edges NNS
are VBP
labeled VBN
only RB
by IN
the DT
nonterminal JJ
symbols NNS
contained VBN
in IN
their PRP$
context-free JJ
backbone NN
, ,
which WDT
gives VBZ
us PRP
more RBR
efficient JJ
indexing NN
of IN
the DT
full JJ
grammar NN
rules NNS
. .

comparison NN
with IN
other JJ
parsers NNS
table JJ
1 CD
compares VBZ
the DT
average JJ
number NN
of IN
edges NNS
, ,
average JJ
number NN
of IN
predictions NNS
, ,
and CC
average JJ
parse JJ
times NNS
1 CD
in IN
seconds NNS
per IN
utterance NN
for IN
the DT
limited JJ
1all CD
parse NN
times NNS
given VBN
in IN
this DT
paper NN
were VBD
produced VBN
on IN
a DT
sun JJ
sparcstation NN
10/51 CD
, ,
running VBG
quintus NN
pro111 NN
for IN
grammar NN
with IN
start JJ
symbol NN
, ,
phrase NN
structure NN
rules NNS
p VBP
, ,
lexicon JJ
l NN
, ,
context-independent JJ
categories NNS
ci NN
, ,
and CC
context-dependent JJ
categories NNS
cd NN
; :
and CC
for IN
word NN
string NN
w NN
wlwn NN
: :
variant JJ
edges NNS
preds NNS
secs VBP
bottom-up JJ
1191 CD
0 CD
146 CD
limited JJ
left-context JJ
203 CD
25 CD
10 CD
left-corner JJ
112 CD
78 CD
40 CD
table JJ
h NN
comparison NN
of IN
syntax-only JJ
parsers NNS
if IN
e JJ
cd NN
, ,
predictt NN
, ,
0 CD
; :
addemptycategories NNS
0 CD
; :
for IN
i NN
from IN
i NN
to TO
n VB
do VB
foreach VB
c VB
such JJ
that IN
c VBP
-- :
wi JJ
el NN
do VBP
addedgetochartc RB
, ,
i-i JJ
, ,
i NN
; :
makenewpredictionsc CC
, ,
ii JJ
, ,
i JJ
; :
findnew-reductionsc JJ
, ,
il JJ
, ,
i JJ
end VBP
addemptycategories NNS
i VBP
; :
end VB
sub JJ
findmew-reductionsb JJ
, ,
j NN
, ,
k VB
foreach VBP
a DT
and CC
a DT
such JJ
that IN
a- JJ
b NN
6 CD
p NN
do VBP
foreach VB
i VB
such JJ
that IN
i JJ
match NN
, ,
j NN
do VBP
if IN
a DT
6 CD
cd NN
and CC
predicteda NN
, ,
i NN
or CC
a DT
6 CD
ci NN
addedgetocharta NN
, ,
i NN
, ,
k NN
; :
makenewpredictionsa CC
, ,
i NN
, ,
k NN
; :
findnewreductionsa NN
, ,
i NN
, ,
k NN
; :
end JJ
end NN
sub NN
addemptycategoriesi VBZ
foreach VBP
a DT
such JJ
that IN
a DT
- :
e NN
e NN
p NN
do VBP
if IN
a DT
6 CD
cd NN
and CC
predicteda NN
, ,
/ ''
or CC
a DT
6 CD
ci NN
addedgetocharta NN
, ,
i NN
, ,
i NN
; :
makenewpredictionsa CC
, ,
i JJ
, ,
i NN
; :
findnewreductionsa NN
, ,
i NN
, ,
i NN
; :
end CC
sub NN
makenewpredictionsa NN
, ,
i NN
, ,
j NN
foreach NN
aft NN
e NN
predictionsi NN
do VBP
predict NN
fl NN
, ,
j JJ
end NN
foreach NN
h SYM
- :
abfl NN
6 CD
p NN
such JJ
that IN
h VBZ
6 CD
ci NN
and CC
b NN
e VBP
cd NN
and CC
fl $
6 CD
ci NN
do VBP
predict NN
b NN
, ,
j JJ
end NN
foreach NN
h NN
-- :
ab JJ
6 CD
p NN
such JJ
that IN
h VBP
e JJ
cd NN
and CC
b NN
e VBP
cd NN
and CC
fl NN
e NN
ci NN
and CC
predictedh NN
, ,
i NN
or CC
h VB
left-corner-of JJ
c NNS
and CC
predictedc NN
, ,
i NN
do VBP
predict NN
b NN
, ,
j JJ
end NN
figure NN
1 CD
: :
limited JJ
left-context JJ
algorithm NN
left-context JJ
parser NN
with IN
those DT
for IN
a DT
variant JJ
equivalent NN
to TO
a DT
bottom-up JJ
parser NN
when WRB
all DT
categories NNS
are VBP
context JJ
independent JJ
and CC
for IN
a DT
variant JJ
equivalent NN
to TO
a DT
left-corner JJ
parser NN
when WRB
all DT
categories NNS
are VBP
context JJ
dependent NN
. .

the DT
situation NN
becomes VBZ
more RBR
complicated JJ
when WRB
we PRP
move VBP
to TO
unification-based JJ
grammars NNS
, ,
since IN
there EX
may MD
be VB
an DT
unbounded JJ
number NN
of IN
different JJ
categories NNS
appearing VBG
in IN
the DT
accessible JJ
stack NN
states NNS
. .

in IN
the DT
system NN
implemented VBN
here RB
we PRP
used VBD
restriction NN
< NNP
tref NN
> NNP
shieber NN
, ,
1985 CD
< NN
/tref NNP
> NN
on IN
the DT
stack NN
states VBZ
to TO
restrict VB
attention NN
to TO
a DT
finite JJ
number NN
of IN
distinct JJ
stack NN
states NNS
for IN
any DT
given VBN
stack NN
depth NN
. .

since IN
the DT
restriction NN
operation NN
maps VBZ
a DT
stack NN
state NN
to TO
a DT
more RBR
general JJ
one CD
, ,
it PRP
produces VBZ
a DT
finite-state JJ
approximation NN
which WDT
accepts VBZ
a DT
superset NN
of IN
the DT
language NN
generated VBN
by IN
the DT
original JJ
unification NN
grammar NN
. .

yet RB
these DT
grammars NNS
apparently RB
have VBP
enough RB
formal JJ
power NN
to TO
describe VB
natural JJ
language NN
at IN
least JJS
, ,
they PRP
can MD
describe VB
the DT
crossed-serial JJ
dependencies NNS
of IN
dutch NN
and CC
swiss JJ
german NN
, ,
which WDT
are VBP
presently RB
the DT
most RBS
widely RB
accepted JJ
example NN
of IN
a DT
construction NN
that WDT
goes VBZ
beyond IN
context-free JJ
grammar NN
< NNP
tref NN
> NNP
shieber VBD
1985a CD
< NNP
/tref NNP
> NNP
. .

though IN
theoretically RB
very RB
attractive JJ
, ,
codescription NN
has VBZ
its PRP$
price NN
: :
i VB
the DT
grammar NN
is VBZ
difficult JJ
to TO
modularize VB
due JJ
to TO
the DT
fact NN
that IN
the DT
levels NNS
constrain VBP
each DT
other JJ
mutually RB
and CC
ii VB
there EX
is VBZ
a DT
computational JJ
overhead NN
when WRB
parsers NNS
use VBP
the DT
complete JJ
descriptions NNS
. .

problems NNS
of IN
these DT
kinds NNS
which WDT
were VBD
already RB
noted VBN
by IN
< NNP
tref NN
> NNP
shieber NN
, ,
1985 CD
< NN
/tref NNP
> NNP
motivated VBD
tile JJ
research NN
described VBN
here RB
. .

the DT
goal NN
was VBD
to TO
develop VB
more RBR
flexible JJ
ways NNS
of IN
using VBG
codescriptive JJ
grammars NNS
than IN
having VBG
them PRP
applied VBN
by IN
a DT
parser NN
with IN
full JJ
informational JJ
power NN
. .

the DT
underlying JJ
observation NN
is VBZ
that IN
constraints NNS
in IN
such JJ
grammars NNS
can MD
play VB
different JJ
roles NNS
: :
genuine NN
constraints NNS
which WDT
relate VBP
directly RB
to TO
tile VB
grammaticality NN
wellformedness NN
of IN
the DT
input NN
. .

furthermore RB
, ,
the DT
need NN
to TO
perform VB
nondestructive JJ
unification NN
means VBZ
that IN
a DT
large JJ
proportion NN
of IN
the DT
processing NN
time NN
is VBZ
spent VBN
copying VBG
feature NN
structures NNS
. .

one CD
approach NN
to TO
this DT
problem NN
is VBZ
to TO
refine VB
parsing VBG
algorithms NNS
by IN
developing VBG
techniques NNS
such JJ
as IN
restrictions NNS
, ,
structure-sharing JJ
, ,
and CC
lazy JJ
unification NN
that WDT
reduce VB
the DT
amount NN
of IN
structure NN
that WDT
is VBZ
stored VBN
and CC
hence RB
the DT
need NN
for IN
copying NN
of IN
features NNS
structures NNS
< VBP
tref JJ
> NNP
shieber NN
, ,
1985 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
pereira NN
, ,
1985 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
karttunen NN
and CC
kay NN
, ,
1985 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
wroblewski NN
, ,
1987 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gerdemann NN
, ,
1989 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
godden NN
, ,
1990 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
kogure NN
, ,
1990 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
emele NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
tomabechi NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
harrison NN
and CC
ellison NN
, ,
1992 CD
< NN
/ref NNP
> NNP
. .

while IN
these DT
techniques NNS
can MD
yield VB
significant JJ
improvements NNS
in IN
performance NN
, ,
the DT
generality NN
of IN
unification-based JJ
grammar NN
formalisms NNS
means VBZ
that IN
there EX
are VBP
still RB
cases NNS
where WRB
expensive JJ
processing NN
is VBZ
unavoidable JJ
. .

original JJ
earley NN
prediction NN
works VBZ
on IN
category NN
symbols NNS
. .

since IN
categorial JJ
grammars NNS
exhibit VBP
an DT
extensive JJ
embedding NN
of IN
categories NNS
within IN
other JJ
categories NNS
, ,
it PRP
is VBZ
useful JJ
to TO
unify VB
templates NNS
not RB
only RB
with IN
the DT
whole JJ
lexical JJ
dag NN
but CC
also RB
with IN
its PRP$
categorial JJ
subgraphs NN
. .

fhese JJ
, ,
lasses NNS
may MD
be VB
established VBN
in IN
a DT
number NN
of IN
ways NNS
; :
the DT
one CD
we PRP
have VBP
adopted VBN
in IN
that DT
presented VBN
by IN
harrison NN
and CC
ellison NN
, ,
992 CD
which WDT
builds NNS
on IN
l NN
; :
he PRP
work NN
of IN
< JJ
tref NN
> NNP
shieber NN
, ,
1985 CD
< NN
/tref CC
> NN
: :
it PRP
introduces VBZ
the DT
nol NN
; :
ion NN
of IN
a DT
negative JJ
restrictor NN
to TO
define VB
equivalence NN
classes NNS
. .

for IN
instance NN
, ,
in IN
the DT
above JJ
example NN
we PRP
could MD
define VB
the DT
negative JJ
restrictor NN
to TO
be VB
orth JJ
. .

contrary JJ
to TO
bottomup VB
parsing NN
, ,
however RB
, ,
the DT
adaptation NN
of IN
a DT
top-down JJ
algorithm NN
for IN
ug JJ
requires VBZ
some DT
special JJ
care NN
. .

top-down JJ
prediction NN
with IN
a DT
restrictor NN
r NN
where WRB
r NN
is VBZ
a DT
finite JJ
set NN
of IN
paths NNS
through IN
a DT
feature-structure JJ
amounts NNS
to TO
the DT
following NN
: :
restriction NN
the DT
restriction NN
of IN
a DT
feature-structure JJ
f NN
relative NN
to TO
a DT
restrictor NN
r NN
is VBZ
the DT
most RBS
specific JJ
feature-structure JJ
f NN
e NN
f NN
, ,
such JJ
that IN
every DT
path NN
in IN
f JJ
j NN
has VBZ
either CC
an DT
atomic JJ
value NN
or CC
is VBZ
an DT
element NN
of IN
r NN
predictor NN
step NN
for IN
each DT
item NN
, ,
end NN
, ,
lhs NN
, ,
parsed VBN
, ,
next JJ
i NN
toparse NN
such JJ
that IN
rjve NN
, ,
is VBZ
the DT
restriction NN
of IN
next JJ
relative NN
to TO
r VB
, ,
and CC
each DT
rule NN
rne NN
: :
t NN
rhs NN
, ,
add VB
itemi NN
, ,
i NN
, ,
rge NN
: :
t NN
, ,
, ,
rhs NN
. .

in IN
particular JJ
, ,
in IN
order NN
to TO
derive VB
a DT
finite JJ
cf NN
grammar NN
, ,
we PRP
will MD
need VB
to TO
consider VB
only RB
those DT
features NNS
that WDT
have VBP
a DT
finite JJ
number NN
of IN
possible JJ
values NNS
, ,
or CC
at IN
least JJS
consider VB
only RB
finitely RB
many JJ
of IN
the DT
possible JJ
values NNS
for IN
infinitely RB
valued VBN
features NNS
. .

removing VBG
these DT
features NNS
may MD
give VB
us PRP
a DT
more RBR
permissive JJ
language NN
model NN
, ,
but CC
it PRP
will MD
still RB
be VB
a DT
sound JJ
approximation NN
. .

the DT
situation NN
becomes VBZ
more RBR
complicated JJ
when WRB
we PRP
move VBP
to TO
unification-based JJ
grammars NNS
, ,
since IN
there EX
may MD
be VB
an DT
unbounded JJ
number NN
of IN
different JJ
categories NNS
appearing VBG
in IN
the DT
accessible JJ
stack NN
states NNS
. .

in IN
the DT
system NN
implemented VBN
here RB
we PRP
used VBD
restriction NN
< NNP
tref NN
> NNP
shieber NN
, ,
1985 CD
< NN
/tref NNP
> NN
on IN
the DT
stack NN
states VBZ
to TO
restrict VB
attention NN
to TO
a DT
finite JJ
number NN
of IN
distinct JJ
stack NN
states NNS
for IN
any DT
given VBN
stack NN
depth NN
. .

since IN
the DT
restriction NN
operation NN
maps VBZ
a DT
stack NN
state NN
to TO
a DT
more RBR
general JJ
one CD
, ,
it PRP
produces VBZ
a DT
finite-state JJ
approximation NN
which WDT
accepts VBZ
a DT
superset NN
of IN
the DT
language NN
generated VBN
by IN
the DT
original JJ
unification NN
grammar NN
. .

more RBR
specifically RB
, ,
magic JJ
generation NN
falls VBZ
prey JJ
to TO
non-termination NN
in IN
the DT
face NN
of IN
head NN
recursion NN
, ,
ie NN
, ,
the DT
generation NN
analog NN
of IN
left JJ
recursion NN
in IN
parsing NN
. .

this DT
necessitates VBZ
a DT
dynamic JJ
processing NN
strategy NN
, ,
ie NN
, ,
memoization NN
, ,
extended VBN
with IN
an DT
abstraction NN
function NN
like IN
, ,
eg FW
, ,
restriction NN
< NNP
tref NN
> NNP
shieber NN
, ,
1985 CD
< NN
/tref NNP
> NNP
, ,
to TO
weaken VB
filtering NN
and CC
a DT
subsumption NN
check NN
to TO
discard VB
redundant JJ
results NNS
. .

it PRP
is VBZ
shown VBN
that IN
for IN
a DT
large JJ
class NN
of IN
grammars NNS
the DT
subsumption NN
check NN
which WDT
often RB
influences VBZ
processing VBG
efficiency NN
rather RB
dramatically RB
can MD
be VB
eliminated VBN
through IN
fine-tuning NN
of IN
the DT
magic JJ
predicates NNS
derived VBN
for IN
a DT
particular JJ
grammar NN
after IN
applying VBG
an DT
abstraction NN
function NN
in IN
an DT
off-line JJ
fashion NN
. .

we PRP
view VBP
the DT
linking VBG
relation NN
not RB
simply RB
as IN
a DT
filter NN
to TO
increase VB
efficiency NN
within IN
the DT
domain NN
of IN
syntactic JJ
analysis NN
-- :
this DT
aspect NN
is VBZ
stressed VBN
by IN
< NNP
tref NN
> NNP
shieber NN
1985 CD
< NNP
/tref NNP
> NNP
and CC
other JJ
investigators NNS
such JJ
as IN
< JJ
ref NN
> NNP
bouma NN
1991 CD
< NNP
/ref NNP
> NNP
-- :
but CC
rather RB
as IN
a DT
device NN
for IN
the DT
top-down JJ
predictive JJ
instantiation NN
of IN
information NN
, ,
as IN
shieber JJ
et NN
al NN
. .

in IN
this DT
paper NN
we PRP
are VBP
concerned VBN
especially RB
with IN
morphosyntactic JJ
information NN
and CC
illustrate VB
the DT
relevance NN
of IN
predictive JJ
linking VBG
for IN
morphological JJ
analysis NN
and CC
for IN
the DT
analysis NN
of IN
unknown JJ
or CC
new JJ
lexical JJ
items NNS
. .

in IN
particular JJ
, ,
declaring VBG
certain JJ
category-valued JJ
features NNS
so IN
that IN
they PRP
can MD
not RB
take VB
variable JJ
values NNS
may MD
lead VB
to TO
nontermination NN
in IN
the DT
backbone NN
construction NN
for IN
some DT
grammars NNS
. .

building NN
lr NN
parse NN
tables NNS
for IN
large JJ
nl JJ
grammars VBZ
the DT
backbone NN
grammar NN
generated VBN
from IN
the DT
anlt NN
grammar NN
is VBZ
large JJ
: :
it PRP
contains VBZ
almost RB
500 CD
distinct JJ
categories NNS
and CC
more JJR
than IN
1600 CD
productions NNS
. .

in IN
contrast NN
to TO
the DT
symbols NNS
in IN
context-free JJ
grammars NNS
, ,
feature NN
structures NNS
in IN
unification-based JJ
grammars NNS
often RB
include VBP
information NN
encoding VBG
part NN
of IN
the DT
derivation NN
history NN
, ,
most RBS
notably RB
semantics NNS
. .

in IN
order NN
to TO
achieve VB
successful JJ
packing NN
rates NNS
, ,
feature JJ
restriction NN
< NNP
tref NN
> NNP
shieber NN
, ,
1985 CD
< NN
/tref NNP
> NNP
is VBZ
used VBN
to TO
remove VB
this DT
information NN
during IN
creation NN
of IN
the DT
packed JJ
parse NN
forest NN
. .

during IN
the DT
unpacking JJ
phase NN
, ,
which WDT
operates VBZ
only RB
on IN
successful JJ
parse NN
trees NNS
, ,
these DT
features NNS
are VBP
unified VBN
back RB
in IN
again RB
. .

for IN
their PRP$
experiments NNS
with IN
efficient JJ
subsumptionbased JJ
packing NN
, ,
< NNP
ref VBZ
> NNP
oepen NN
and CC
carroll NN
, ,
2000 CD
< NN
/ref NNP
> NNP
experimented VBD
with IN
different JJ
settings NNS
of IN
the DT
packing NN
restrictor NN
for IN
the DT
english JJ
resource NN
grammar NN
erg NN
< NNP
ref NN
> NNP
copestake NN
and CC
flickinger NN
, ,
2000 CD
< NN
/ref CC
> NN
: :
they PRP
found VBD
that IN
good JJ
packing NN
rates NNS
, ,
and CC
overall JJ
good JJ
performance NN
during IN
forest JJ
creation NN
and CC
unpacking NN
were VBD
achieved VBN
, ,
for IN
the DT
erg NN
, ,
with IN
partial JJ
restriction NN
of IN
the DT
semantics NNS
, ,
eg VBP
keeping VBG
index NN
features NNS
unrestricted VBN
, ,
since IN
they PRP
have VBP
an DT
impact NN
on IN
external JJ
combinatorial JJ
potential NN
, ,
but CC
restricting VBG
most JJS
of IN
the DT
internal JJ
mrs NN
representation NN
, ,
including VBG
the DT
list NN
of IN
elementary JJ
predications NNS
and CC
scope NN
constraints NNS
. .

attention NN
is VBZ
restricted VBN
here RB
to TO
approximations NNS
of IN
context-free JJ
grammars NNS
because IN
context-free JJ
languages NNS
are VBP
the DT
smallest JJS
class NN
of IN
formal JJ
language NN
that WDT
can MD
realistically RB
be VB
applied VBN
to TO
the DT
analysis NN
of IN
natural JJ
language NN
. .

that DT
is VBZ
, ,
instantiation NN
of IN
productions NNS
introduces NNS
the DT
nontermination NN
problem NN
of IN
left-recursive JJ
productions NNS
to TO
the DT
procedure NN
, ,
as RB
well RB
as IN
to TO
the DT
predictor JJ
step NN
of IN
earleys NNS
algorithm VBP
. .

the DT
situation NN
is VBZ
different JJ
for IN
active JJ
chart NN
items NNS
since IN
daughters NNS
can MD
affect VB
their PRP$
siblings NNS
. .

to TO
be VB
independent JJ
from IN
a-certain JJ
grammatical JJ
theory NN
or CC
implementation NN
, ,
we PRP
use VBP
restrictors NNS
similar JJ
to TO
< VB
tref JJ
> NNP
shieber NN
, ,
1985 CD
< NN
/tref NNP
> NNP
as IN
a DT
flexible JJ
and CC
easyto-use JJ
specification NN
to TO
perform VB
this DT
deletion NN
. .

a DT
positive JJ
restrictor NN
is VBZ
an DT
automaton NN
describing VBG
the DT
paths NNS
in IN
a DT
feature NN
structure NN
that WDT
will MD
remain VB
after IN
restriction NN
the DT
deletion NN
operation NN
, ,
3there CD
are VBP
refinements NNS
of IN
the DT
technique NN
which WDT
we PRP
have VBP
implemented VBN
and CC
which WDT
in IN
practice NN
produce VBP
additional JJ
benefits NNS
; :
we PRP
will MD
report VB
these DT
in IN
a DT
subsequent JJ
paper NN
. .

briefly NN
, ,
they PRP
involve VBP
an DT
improvement NN
to TO
th VB
e JJ
path NN
collection NN
method NN
, ,
and CC
the DT
storage NN
of IN
other JJ
information NN
besides IN
types NNS
in IN
the DT
vectors NNS
. .

that DT
is VBZ
, ,
for IN
the DT
reference NN
determination NN
, ,
the DT
subject JJ
roles NNS
of IN
the DT
candidates NNS
referent VBP
within IN
a DT
discourse NN
segment NN
will MD
be VB
checked VBN
intheflrstplace NN
. .

candi NN
pron NN
and CC
candi NN
noantecedent NN
are VBP
to TO
be VB
examined VBN
in IN
the DT
cases NNS
when WRB
the DT
subject-role JJ
checking NN
fails NNS
, ,
which WDT
conflrms VBZ
the DT
hypothesis NN
in IN
the DT
s-list JJ
model NN
by IN
< NNP
ref NN
> NNP
strube NN
1998 CD
< NNP
/ref NNP
> VBD
that IN
co-refereing JJ
candidates NNS
would MD
have VB
higher JJR
preference NN
than IN
other JJ
candidates NNS
in IN
the DT
pronoun JJ
resolution NN
. .

pragmatic JJ
level NN
working VBG
together RB
, ,
surface NN
patterns NNS
and CC
possessive JJ
relationships NNS
can MD
deal VB
with IN
many JJ
ppas NN
found VBD
in IN
our PRP$
corpus NN
, ,
but CC
we PRP
still RB
have VBP
two CD
problems NNS
to TO
be VB
solved VBN
: :
semantic JJ
ambiguity NN
among IN
two CD
or CC
more JJR
acceptable JJ
candidates NNS
and CC
abstract JJ
anaphors/antecedents NNS
, ,
which WDT
can MD
not RB
be VB
solved VBN
by IN
simply RB
applying VBG
possessive JJ
relationship NN
rules NNS
. .

for IN
these DT
cases NNS
, ,
and CC
possibly RB
for IN
some DT
other JJ
cases NNS
not RB
included VBN
in IN
previous JJ
rules NNS
, ,
we PRP
suggest VBP
a DT
pragmatic JJ
factor NN
, ,
adapted VBN
from IN
s JJ
brennans NNS
et VBP
al JJ
1987 CD
centering VBG
algorithm NN
. .

although IN
sentence NN
center NN
plays VBZ
a DT
crucial JJ
role NN
in IN
many JJ
works NNS
in IN
anaphor NN
resolution NN
, ,
usually RB
limiting VBG
the DT
number NN
of IN
candidates NNS
to TO
be VB
considered VBN
, ,
we PRP
notice VBP
that DT
, ,
because IN
ppas NN
can MD
refer VB
to TO
almost RB
any DT
np NN
in IN
the DT
sentence NN
rather RB
than IN
, ,
for IN
example NN
, ,
personal JJ
pronouns NNS
, ,
which WDT
are VBP
often RB
related VBN
to TO
the DT
sentence NN
center NN
, ,
pragmatic JJ
knowledge NN
plays VBZ
only RB
a DT
secondary JJ
but CC
still RB
important JJ
role NN
in IN
our PRP$
approach NN
. .

we PRP
have VBP
adapted VBN
basic JJ
aspects NNS
of IN
center NN
algorithm NN
, ,
considering VBG
subject/object JJ
preference NN
, ,
and CC
domain NN
concepts NNS
preference NN
, ,
1012 CD
suggested VBN
by IN
r NN
< NNP
ref NN
> NNP
mitkov NN
1996 CD
< NNP
/ref NNP
> NNP
, ,
aiming VBG
to TO
estimate VB
the DT
most RBS
probable JJ
center NN
for IN
intrasentential JJ
ppas NN
. .

even RB
though IN
we PRP
are VBP
not RB
following VBG
here RB
the DT
distinction NN
between IN
constraints NNS
and CC
rules NNS
introduced VBN
in IN
< NNP
ref NN
> NNP
brennan NN
, ,
friedman NN
, ,
and CC
pollard RB
1987 CD
< NNP
/ref NNP
> NNP
, ,
we PRP
will MD
use VB
for IN
these DT
three CD
claims NNS
the DT
names NNS
brennan VBP
et JJ
al NNS
gave VBD
them PRP
, ,
by IN
which WDT
they PRP
are VBP
now RB
best RB
known VBN
: :
constraint NN
1 CD
strong JJ
: :
all DT
utterances NNS
of IN
a DT
segment NN
except IN
for IN
the DT
first JJ
have VBP
exactly RB
one CD
cb NN
. .

231 CD
constraint NN
1 CD
, ,
topic NN
uniqueness NN
, ,
and CC
entity NN
coherence NN
. .

given VBN
the DT
above IN
possible JJ
sources NNS
of IN
informar NN
tion NN
, ,
we PRP
arrive VBP
at IN
the DT
following JJ
equation NN
, ,
where WRB
fp NN
denotes VBZ
a DT
function NN
from IN
pronouns NNS
to TO
their PRP$
antecedents NNS
: :
fp NN
argmaxp NN
ap NN
alp NN
, ,
h NN
, ,
l NN
, ,
t NN
, ,
l NN
, ,
so RB
, ,
d VB
a DT
where WRB
ap NN
is VBZ
a DT
random NN
variable JJ
denoting VBG
the DT
referent NN
of IN
the DT
pronoun NN
p NN
and CC
a DT
is VBZ
a DT
proposed JJ
antecedent NN
. .

in IN
the DT
conditioning NN
events NNS
, ,
h NN
is VBZ
the DT
head JJ
constituent NN
above IN
p NN
, ,
l NN
r NN
is VBZ
the DT
list NN
of IN
candidate NN
antecedents NNS
to TO
be VB
considered VBN
, ,
t EX
is VBZ
the DT
type NN
of IN
phrase NN
of IN
the DT
proposed VBN
antecedent NN
always RB
a DT
noun-phrase JJ
in IN
this DT
study NN
, ,
i NN
is VBZ
the DT
type NN
of IN
the DT
head NN
constituent NN
, ,
sp NN
describes VBZ
the DT
syntactic JJ
structure NN
in IN
which WDT
p NN
appears VBZ
, ,
dspecifies VBZ
the DT
distance NN
of IN
each DT
antecedent NN
from IN
p NN
and CC
m NN
is VBZ
the DT
number NN
of IN
times NNS
the DT
referent NN
is VBZ
mentioned VBN
. .

it PRP
is VBZ
often RB
claimed VBN
in IN
current JJ
work NN
on IN
in IN
natural JJ
language NN
generation NN
that IN
the DT
constraints NNS
on IN
felicitous JJ
text NN
proposed VBN
by IN
the DT
theory NN
are VBP
useful JJ
to TO
guide VB
text NN
structuring NN
, ,
in IN
combination NN
with IN
other JJ
factors NNS
see VBP
< JJ
ref NN
> NNP
karamanis NN
, ,
2003 CD
< NN
/ref NNP
> NNP
for IN
an DT
overview NN
. .

however RB
, ,
how WRB
successful JJ
centerings NNS
constraints NNS
are VBP
on IN
their PRP$
own JJ
in IN
generating VBG
a DT
felicitous JJ
text NN
structure NN
is VBZ
an DT
open JJ
question NN
, ,
already RB
raised VBN
by IN
the DT
seminal JJ
papers NNS
of IN
the DT
theory NN
< NNP
tref NN
> NNP
brennan NN
et NN
al NN
, ,
1987 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
grosz NN
et NN
al NN
, ,
1995 CD
< NN
/ref NNP
> NNP
. .

in IN
accordance NN
with IN
recent JJ
work NN
in IN
the DT
emerging VBG
field NN
of IN
text-to-text JJ
generation NN
< NNP
ref NN
> NNP
barzilay NN
et NN
al NN
, ,
2002 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
lapata NN
, ,
2003 CD
< NN
/ref NNP
> NNP
, ,
we PRP
assume VBP
that IN
the DT
input NN
to TO
text VB
structuring NN
is VBZ
a DT
set NN
of IN
clauses NNS
. .

identify VB
transition NN
with IN
the DT
cb NN
and CC
cf NN
resolved VBD
, ,
use VB
the DT
criteria NNS
from IN
< NNP
tref NN
> NNP
brennan NN
et NN
al NN
, ,
1987 CD
< NN
/tref NNP
> NNP
to TO
assign VB
the DT
transition NN
. .

cheapness NN
is VBZ
satisfied VBN
by IN
a DT
transition NN
pair NN
un-1 JJ
, ,
un JJ
, ,
un JJ
, ,
unl JJ
if IN
the DT
preferred JJ
center NN
of IN
un NN
is VBZ
the DT
cb NN
of IN
unl NN
for IN
example NN
, ,
this DT
test NN
is VBZ
satisfied VBN
by IN
a DT
retain-shift JJ
sequence NN
but CC
not RB
by IN
continue-shift NN
, ,
so IN
it PRP
is VBZ
predicted VBN
that IN
the DT
former JJ
pattern NN
will MD
be VB
used VBN
to TO
introduce VB
a DT
new JJ
center NN
. .

this DT
claim NN
is VBZ
consistent JJ
with IN
the DT
findings NNS
of IN
< NNP
ref NN
> NNP
brennan NN
1998 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
tref VBZ
> NNP
brennan NN
et NN
al NN
1987 CD
< NNP
/tref NNP
> NNP
. .

if IN
we PRP
consider VBP
examples NNS
la-e RB
below IN
, ,
the DT
sequence NN
cd-e NN
, ,
including VBG
a DT
retain-shift JJ
sequence NN
, ,
reads VBZ
more RBR
fluently RB
than IN
c-d-e JJ
even RB
though IN
the DT
latter JJ
scores NNS
better RBR
according VBG
to TO
the DT
canonical JJ
ranking NN
. .

pfnocb NN
, ,
a DT
second JJ
baseline NN
, ,
which WDT
enhances VBZ
mnocb NN
with IN
a DT
global JJ
constraint NN
on IN
coherence NN
that IN
< NNP
ref VBD
> NNP
karamanis NN
, ,
2003 CD
< NN
/ref NNP
> NNP
calls VBZ
the DT
pagefocus NN
pf NN
. .

pfbfp NN
which WDT
is VBZ
based VBN
on IN
pf NN
as RB
well RB
as IN
the DT
original JJ
formulation NN
of IN
ct NN
in IN
< NNP
tref NN
> NNP
brennan NN
et NN
al NN
, ,
1987 CD
< NN
/tref NNP
> NNP
. .

pfkp NN
which WDT
makes VBZ
use NN
of IN
pf NN
as RB
well RB
as IN
the DT
recent JJ
reformulation NN
of IN
ct NN
in IN
< NNP
ref NN
> NNP
kibble NN
and CC
power NN
, ,
2000 CD
< NN
/ref NNP
> NNP
. .

one CD
more JJR
filtering JJ
criterion NN
is VBZ
mutual JJ
information NN
mi NN
, ,
which WDT
reflects VBZ
the DT
relatedness NN
of IN
two CD
terms NNS
in IN
their PRP$
combination NN
, ,
kj VB
ww NN
to TO
keep VB
a DT
relation NN
kji NN
wwwp NN
, ,
we PRP
require VBP
, ,
kj FW
ww NN
be VB
a DT
meaningful JJ
combination NN
. .

we PRP
use VBP
the DT
following JJ
pointwise NN
mi NN
< NNP
tref NN
> NNP
church NN
and CC
hanks NNS
1989 CD
< NNP
/tref NNP
> NN
: :
, ,
log NN
, ,
kj VB
kj FW
kj FW
wpwp FW
wwpwwmi NN
we PRP
only RB
keep VB
meaningful JJ
combinations NNS
such JJ
that IN
0 CD
, ,
> NNP
kj NNP
wwmi NN
by IN
these DT
filtering VBG
criteria NNS
, ,
we PRP
are VBP
able JJ
to TO
reduce VB
considerably RB
the DT
number NN
of IN
biterms NNS
and CC
triterms NNS
. .

for IN
example NN
, ,
on IN
a DT
collection NN
of IN
about IN
200mb CD
, ,
with IN
a DT
vocabulary JJ
size NN
of IN
about IN
148k CD
, ,
we PRP
selected VBD
only RB
about RB
27m CD
useful JJ
biterms NNS
and CC
about IN
137m CD
triterms NNS
, ,
which WDT
remain VBP
tractable JJ
. .

afterward RB
, ,
if IN
a DT
target NN
adjective JJ
sense NN
was VBD
not RB
resolved VBN
, ,
semantic JJ
indicator NN
attributes NNS
were VBD
applied VBN
; :
no DT
individual JJ
indicator NN
nouns NNS
were VBD
used VBN
. .

the DT
semantic JJ
attributes NNS
that WDT
were VBD
applied VBN
were VBD
animate JJ
, ,
body JJ
part NN
, ,
color NN
, ,
concrete NN
, ,
human JJ
, ,
and CC
text JJ
type NN
; :
< CC
tref VB
> JJ
church NN
and CC
hanks NNS
1989 CD
< NNP
/tref NNP
> NNP
had VBD
pointed VBN
to TO
two CD
of IN
these DT
attributes NNS
, ,
person NN
and CC
body NN
part NN
also RB
time NN
, ,
previously RB
mentioned VBN
above IN
in IN
a DT
seemingly RB
casual JJ
listing NN
of IN
just RB
five CD
attributes NNS
potentially RB
useful JJ
for IN
describing VBG
the DT
lexico-syntactic JJ
regularities NNS
of IN
noun-verb JJ
relations NNS
. .

disambiguation NN
by IN
these DT
syntactic JJ
and CC
semantic JJ
attributes NNS
is VBZ
effectively RB
as RB
reliable JJ
as IN
disambiguation NN
using VBG
significant JJ
indicator NN
nouns NNS
: :
having VBG
three CD
apparent JJ
errors NNS
in IN
disambiguation NN
is VBZ
not RB
significantly RB
worse JJR
than IN
the DT
errorless JJ
performance NN
of IN
the DT
significant JJ
indicator NN
nouns NNS
in IN
the DT
100-sentence JJ
samples NNS
. .

content NN
words NNS
that WDT
have VBP
a DT
close JJ
syntactic JJ
relation NN
to TO
one CD
another DT
are VBP
useful JJ
candidates NNS
for IN
examination NN
and CC
are VBP
intuitively RB
more RBR
likely JJ
to TO
bear VB
a DT
close JJ
semantic JJ
relation NN
than IN
words NNS
that WDT
are VBP
near IN
one CD
another DT
but CC
are VBP
not RB
related VBN
syntactically RB
. .

determining VBG
the DT
potential NN
of IN
this DT
line NN
of IN
evidence NN
is VBZ
the DT
focus NN
of IN
this DT
paper NN
. .

like IN
path NN
coreference NN
, ,
semantic JJ
compatibility NN
can MD
be VB
considered VBN
a DT
form NN
of IN
world NN
knowledge NN
needed VBN
for IN
more RBR
challenging JJ
pronoun JJ
resolution NN
instances NNS
. .

suppose NN
we PRP
are VBP
determining VBG
whether IN
ham NN
is VBZ
a DT
suitable JJ
antecedent NN
for IN
the DT
pronoun NN
it PRP
in IN
eat NN
it PRP
. .

we PRP
calculate VBP
the DT
mi NN
as IN
: :
mieat NN
: :
obj NN
, ,
ham NN
log NN
preat NN
: :
obj NN
: :
hampreat NN
: :
objprham CC
although IN
semantic JJ
compatibility NN
is VBZ
usually RB
only RB
computed VBD
for IN
possessive-noun JJ
, ,
subject-verb JJ
, ,
and CC
verb-object JJ
relationships NNS
, ,
we PRP
include VBP
121 CD
different JJ
kinds NNS
of IN
syntactic JJ
relationships NNS
as IN
parsed VBN
in IN
our PRP$
news NN
corpus3 NN
we PRP
collected VBD
488 CD
billion CD
parent NN
: :
rel NN
: :
node NN
triples NNS
, ,
including VBG
over IN
327 CD
million CD
possessive-noun JJ
values NNS
, ,
129 CD
billion CD
subject-verb NN
and CC
877 CD
million CD
verb-direct JJ
object NN
. .

this DT
line NN
of IN
research NN
was VBD
motivated VBN
by IN
a DT
series NN
of IN
successful JJ
applications NNS
of IN
mutual JJ
information NN
statistics NNS
to TO
other JJ
problems NNS
in IN
natural JJ
language NN
processing NN
. .

in IN
the DT
last JJ
decade NN
, ,
research NN
in IN
speech NN
recognition NN
< NNP
ref NN
> NNP
jelinek NN
1985 CD
< NNP
/ref NNP
> NNP
, ,
noun JJ
classification NN
< NNP
ref NN
> NNP
hindle NN
1988 CD
< NNP
/ref NNP
> NNP
, ,
predicate NN
argument NN
relations NNS
< VBP
tref JJ
> NNP
church NN
hanks NNS
1989 CD
< NNP
/tref NNP
> NNP
, ,
and CC
other JJ
areas NNS
have VBP
shown VBN
that IN
mutual JJ
information NN
statistics NNS
provide VBP
a DT
wealth NN
of IN
information NN
for IN
solving VBG
these DT
problems NNS
. .

it PRP
is VBZ
a DT
function NN
of IN
the DT
probabilities NNS
of IN
the DT
two CD
events NNS
: :
mz NN
, ,
u JJ
log NN
u JJ
xzpvy NN
in IN
this DT
paper NN
, ,
the DT
events NNS
x NN
and CC
y NN
will MD
be VB
part-of-speech JJ
n-grams JJ
instead RB
of IN
single JJ
parts-of-speech NN
, ,
as IN
in IN
some DT
earlier JJR
work NN
. .

for IN
evaluation NN
of IN
the DT
association NN
measures NNS
, ,
a6 JJ
-best JJS
strategies NNS
section NN
41 CD
are VBP
supplemented VBN
with IN
precision NN
and CC
recall VB
graphs JJ
section NN
42 CD
over IN
the DT
complete JJ
data NNS
sets NNS
. .

41 CD
eiir NN
: :
expected VBN
independent JJ
information NN
ranking VBG
model NN
baseline NN
model NN
recall VBP
the DT
task NN
definition NN
from IN
section NN
3 CD
. .

expression NN
1 CD
calculates VBZ
the DT
score NN
between IN
two CD
neighboring VBG
letters NNS
; :
uki JJ
e NN
e NN
mwj NN
, ,
wid NN
; :
d CC
x NNP
, ,
qd RB
1 CD
dl JJ
j-i NN
-- :
d NN
-- :
1 CD
where WRB
wl NN
as IN
an DT
even RB
; :
, ,
d VBZ
as IN
the DT
distance NN
between IN
two CD
even RB
; :
s PRP
, ,
dmax RB
as IN
the DT
maximum JJ
distance NN
used VBN
in IN
the DT
processing NN
we PRP
set VBP
drnax JJ
- :
5 CD
, ,
and CC
gd NN
as IN
the DT
weight NN
fimction NN
on IN
distance NN
for IN
this DT
system NN
gd VBZ
d-2 JJ
< NNP
ref NN
> NNP
sano NN
et NN
al NN
, ,
1996 CD
< NN
/ref NNP
> NNP
, ,
to TO
decrease VB
tile JJ
influence NN
of IN
tile NN
d-bigrams NNS
when WRB
the DT
distance NN
get NN
longer RBR
< JJ
tref NN
> NNP
church NN
and CC
hanks NNS
, ,
1989 CD
< NN
/tref NNP
> NNP
. .

in IN
this DT
paper NN
, ,
we PRP
define VBP
novel JJ
measures NNS
both DT
collocation NN
based VBN
and CC
context JJ
based VBN
measures NNS
to TO
measure VB
the DT
relative JJ
compositionality NN
of IN
mwes NN
of IN
v-n JJ
type NN
see NN
section NN
6 CD
for IN
details NNS
. .

integrating VBG
these DT
statistical JJ
measures NNS
should MD
provide VB
better JJR
evidence NN
for IN
ranking VBG
the DT
expressions NNS
. .

mutual JJ
information NN
is VBZ
attractive JJ
because IN
it PRP
is VBZ
not RB
only RB
easy JJ
to TO
compute VB
, ,
but CC
also RB
takes VBZ
into IN
consideration NN
corpus NN
statistics NNS
and CC
semantics NNS
. .

these DT
features NNS
have VBP
largely RB
been VBN
evaluated VBN
by IN
the DT
correlation NN
of IN
the DT
compositionality NN
value NN
predicted VBN
by IN
these DT
measures NNS
with IN
the DT
gold JJ
standard NN
value NN
suggested VBN
by IN
human JJ
judges NNS
. .

it PRP
has VBZ
been VBN
shown VBN
that IN
the DT
correlation NN
of IN
these DT
measures NNS
is VBZ
higher JJR
than IN
simple JJ
baseline JJ
measures NNS
suggesting VBG
that IN
these DT
measures NNS
represent VBP
compositionality NN
quite RB
well RB
. .

even RB
though IN
, ,
these DT
measures NNS
have VBP
been VBN
shown VBN
to TO
represent VB
compositionality NN
quite RB
well RB
, ,
compositionality NN
itself PRP
has VBZ
not RB
been VBN
shown VBN
to TO
be VB
useful JJ
in IN
any DT
application NN
yet RB
. .

more RBR
is VBZ
to TO
be VB
learned VBN
from IN
the DT
fact NN
that IN
you PRP
can MD
drink VB
wine JJR
than IN
from IN
the DT
fact NN
that IN
you PRP
can MD
drink VB
it PRP
even RB
though IN
there EX
are VBP
more JJR
clauses NNS
in IN
our PRP$
sample NN
with IN
as IN
an DT
object NN
of IN
drink NN
than IN
with IN
wine NN
. .

the DT
mutual JJ
information NN
of IN
two CD
events NNS
lx JJ
y NN
is VBZ
defined VBN
as IN
follows VBZ
: :
px NN
y NN
lxy NN
log2 NN
px NN
py NN
where WRB
px NN
y NN
is VBZ
the DT
joint JJ
probability NN
of IN
events NNS
x JJ
and CC
y JJ
, ,
and CC
px NN
and CC
py NN
axe VBP
the DT
respective JJ
independent JJ
probabilities NNS
. .

when WRB
the DT
joint JJ
probability NN
px NN
y NN
is VBZ
high JJ
relative NN
to TO
the DT
product NN
of IN
the DT
independent JJ
probabilities NNS
, ,
i NN
is VBZ
positive JJ
; :
when WRB
the DT
joint JJ
probability NN
is VBZ
relatively RB
low JJ
, ,
i NN
is VBZ
negative JJ
. .

mutual JJ
information NN
has VBZ
been VBN
positively RB
used VBN
in IN
many JJ
nlp JJ
tasks NNS
such JJ
as IN
collocation NN
analysis NN
< NNP
tref NN
> NNP
church NN
and CC
hanks NNS
, ,
1989 CD
< NN
/tref NNP
> NNP
, ,
terminology NN
extraction NN
< NNP
ref NN
> NNP
damerau NN
, ,
1993 CD
< NN
/ref NNP
> NNP
, ,
and CC
word NN
sense NN
disambiguation NN
< NNP
ref NN
> NNP
brown IN
et FW
al NN
, ,
1991 CD
< NN
/ref NNP
> NNP
. .

only RB
a DT
positive JJ
combination NN
of IN
both DT
these DT
two CD
ingredients NNS
can MD
give VB
good JJ
results NNS
when WRB
applying VBG
and CC
evaluating VBG
the DT
model NN
. .

however RB
, ,
the DT
statistics NNS
we PRP
use VBP
provide RB
more JJR
information NN
and CC
allow VB
us PRP
to TO
have VB
more JJR
precision NN
in IN
our PRP$
output NN
. .

since IN
we PRP
use VBP
grammatical JJ
context NN
, ,
the DT
feature NN
set VBN
is VBZ
considerably RB
larger JJR
than IN
the DT
simple JJ
word NN
based VBN
proximity NN
feature NN
set VBN
for IN
the DT
newspaper NN
corpus NN
. .

43 CD
calculating VBG
feature NN
vectors NNS
having VBG
collected VBN
all DT
nouns NNS
and CC
their PRP$
features NNS
, ,
we PRP
now RB
proceed VBP
to TO
construct VB
feature NN
vectors NNS
and CC
values NNS
for IN
nouns NNS
from IN
both DT
corpora NNS
using VBG
mutual JJ
information NN
< NNP
tref NN
> NNP
church NN
and CC
hanks NNS
, ,
1989 CD
< NN
/tref NNP
> NNP
. .

the DT
so NN
of IN
a DT
phrase NN
is VBZ
determined VBN
based VBN
upon IN
the DT
phrases NNS
pointwise VBP
mutual JJ
information NN
pmi NN
with IN
the DT
words NNS
excellent NN
and CC
poor JJ
. .

the DT
so RB
for IN
a DT
a28a37a36a39a38a41a40a29a42a44a43 NN
is VBZ
the DT
difference NN
between IN
its PRP$
pmi NN
with IN
the DT
word NN
excellent NN
and CC
its PRP$
pmi NN
with IN
the DT
word NN
poor JJ
the DT
method NN
used VBN
to TO
derive VB
these DT
values NNS
takes VBZ
advantage NN
of IN
the DT
possibility NN
of IN
using VBG
the DT
world NN
wide JJ
web NN
as IN
a DT
corpus NN
, ,
similarly RB
to TO
work VB
such JJ
as IN
< JJ
ref NN
> NNP
keller NN
and CC
lapata NN
, ,
2003 CD
< NN
/ref NNP
> NNP
. .

the DT
probabilities NNS
are VBP
estimated VBN
by IN
querying VBG
the DT
altavista NN
advanced VBD
search NN
engine1 NN
for IN
counts NNS
. .

to TO
solve VB
the DT
problem NN
, ,
we PRP
make VBP
use NN
of IN
a DT
kind NN
of IN
cooperative JJ
evolution NN
strategy NN
to TO
design VB
an DT
evolutionary JJ
algorithm NN
. .

word NN
compositions NNS
have VBP
long RB
been VBN
a DT
concern NN
in IN
lexicography NN
< NNP
ref NN
> NNP
benson NN
et NN
al NN
1986 CD
< NNP
/ref NNP
> NNP
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
miller NN
et NN
al NN
1995 CD
< NNP
/ref NNP
> NNP
, ,
and CC
now RB
as IN
a DT
specific JJ
kind NN
of IN
lexical JJ
knowledge NN
, ,
it PRP
has VBZ
been VBN
shown VBN
that IN
they PRP
have VBP
an DT
important JJ
role NN
in IN
many JJ
areas NNS
in IN
natural JJ
language NN
processing NN
, ,
eg NN
, ,
parsing NN
, ,
generation NN
, ,
lexicon NN
building NN
, ,
word NN
sense NN
disambiguation NN
, ,
and CC
information NN
retrieving NN
, ,
etceg NN
, ,
< NNP
ref VBZ
> NNP
abney NN
1989 CD
, ,
1990 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
benson NN
et NN
al NN
1986 CD
< NNP
/ref NNP
> NNP
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
1995 CD
< NNP
/ref NNP
> NNP
; :
< NNP
tref VBZ
> JJ
church NN
and CC
hanks NNS
1989 CD
< NNP
/tref NNP
> NNP
; :
church NN
, ,
< NNP
ref VBZ
> NNP
gale NN
, ,
hans NNS
, ,
and CC
hindle JJ
1989 CD
< NNP
/ref NNP
> NNP
. .

dictionaries NNS
produced VBN
by IN
hand NN
always RB
substantially RB
lag JJ
real JJ
language NN
use NN
. .

the DT
last JJ
two CD
points NNS
do VBP
not RB
argue VB
against IN
the DT
use NN
of IN
existing VBG
dictionaries NNS
, ,
but CC
show VBP
that IN
the DT
incomplete JJ
information NN
that IN
they PRP
provide VBP
needs NNS
to TO
be VB
supplemented VBN
with IN
further JJ
knowledge NN
that WDT
is VBZ
best RBS
collected VBN
automatically RB
the DT
desire NN
to TO
combine VB
hand-coded JJ
and CC
automatically RB
learned VBD
knowledge NN
1a CD
point NN
made VBN
by IN
< NNP
tref NN
> NNP
church NN
and CC
hanks NNS
1989 CD
< NNP
/tref NNP
> NNP
. .

for IN
example NN
, ,
among IN
the DT
27 CD
verbs NNS
that IN
most JJS
commonly RB
cooccurred VBN
with IN
from IN
, ,
church NN
and CC
hanks NNS
found VBD
7 CD
for IN
which WDT
this DT
235 CD
suggests VBZ
that IN
we PRP
should MD
aim VB
for IN
a DT
high JJ
precision NN
learner VBD
even RB
at IN
some DT
cost NN
in IN
coverage NN
, ,
and CC
that DT
is VBZ
the DT
approach NN
adopted VBD
here RB
. .

c8b4crcyd4d3d7b5 NN
bp NN
cub4crbnd4d3d7b5 NN
cub4crbnd4d3d7b5b7cub4bmcrbnd4d3d7b5 NN
c8b4crcyd2ctcvb5 NN
bp NN
cub4crbnd2ctcvb5 NN
cub4crbnd2ctcvb5b7cub4bmcrbnd2ctcvb5 NN
pmi NN
based VBN
polarity NN
value NN
using VBG
pmi NN
, ,
the DT
strength NN
of IN
association NN
between IN
cr NN
and CC
positive JJ
sentences NNS
and CC
negative JJ
sentences NNS
is VBZ
defined VBN
as IN
follows VBZ
< NNP
tref NN
> NNP
church NN
and CC
hanks NNS
, ,
1989 CD
< NN
/tref NNP
> NNP
. .

c8c5c1b4crbnd4d3d7b5 NN
bp NN
d0d3cv NN
be VB
c8b4crbnd4d3d7b5 VBN
c8b4crb5c8b4d4d3d7b5 JJ
c8c5c1b4crbnd2ctcvb5 NN
bp NN
d0d3cv NN
be VB
c8b4crbnd2ctcvb5 VBN
c8b4crb5c8b4d2ctcvb5 JJ
pmi NNS
based VBN
polarity NN
value NN
is VBZ
defined VBN
as IN
their PRP$
difference NN
. .

if IN
the DT
absolute JJ
value NN
of IN
the DT
relative JJ
distance NN
in IN
a DT
sentence NN
for IN
a DT
feature NN
and CC
an DT
opinion NN
word NN
is VBZ
less JJR
than IN
minimum-offset NN
, ,
they PRP
are VBP
considered VBN
contextdependent NN
. .

many JJ
efficient JJ
techniques NNS
exist VBP
to TO
extract VB
multiword JJ
expressions NNS
, ,
collocations NNS
, ,
lexical JJ
units NNS
and CC
idioms NNS
< VBP
tref JJ
> NNP
church NN
and CC
hanks NNS
, ,
1989 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
smadja NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
dias NNS
et FW
al RB
, ,
2000 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
dias NNS
, ,
2003 CD
< NN
/ref NNP
> NNP
. .

the DT
definition NN
can MD
be VB
easily RB
extended VBN
to TO
a DT
set NN
of IN
expressions NNS
t VBP
given VBN
a DT
pair NN
vt NN
and CC
vh NN
we PRP
define VBP
the DT
following JJ
entailment JJ
strength NN
indicator NN
svt NN
, ,
vh NN
. .

counts NNS
are VBP
considered VBN
useful JJ
when WRB
they PRP
are VBP
greater JJR
or CC
equal JJ
to TO
3 CD
. .

we PRP
have VBP
already RB
used VBN
this DT
algorithm JJ
successfully RB
as IN
a DT
part NN
of IN
a DT
system NN
to TO
assign VB
senses NNS
to TO
english VB
and CC
french JJ
words NNS
on IN
the DT
basis NN
of IN
the DT
context NN
in IN
which WDT
they PRP
appear VBP
< JJ
ref NN
> NNP
brown IN
et RB
al JJ
1991a CD
, ,
1991b CD
< NN
/ref NNP
> NNP
. .

it PRP
can MD
resolve VB
the DT
alignment NN
problem NN
on IN
real JJ
bilingual JJ
text NN
. .

on IN
clean JJ
inputs NNS
, ,
such JJ
as IN
the DT
canadian JJ
hansards NNS
and CC
the DT
hong JJ
kang NN
hansards NNS
, ,
these DT
methods NNS
have VBP
been VBN
very RB
successful JJ
. .

church NN
, ,
kenneth FW
w NN
, ,
1993 CD
; :
< CC
ref VB
> NN
chen NN
, ,
stanley NN
, ,
1993 CD
< NN
/ref NNP
> NNP
proposed VBD
some DT
methods NNS
to TO
resolve VB
the DT
problem NN
in IN
noisy JJ
bilingual JJ
texts NN
. .

the DT
result NN
shows VBZ
that IN
the DT
use NN
of IN
dependency NN
relation NN
helps VBZ
to TO
acquire VB
interesting JJ
translation NN
patterns NNS
. .

since IN
the DT
advent NN
of IN
statistical JJ
methods NNS
in IN
machine NN
qhanslation NN
, ,
the DT
bilingual JJ
sentence NN
alignmerit NN
< NNP
tref NN
> NNP
brown IN
et FW
al NN
, ,
1991 CD
< NN
/tref NNP
> NNP
or CC
word NN
alignment NN
< NNP
ref NN
> NNP
dagan VBZ
et FW
al NN
, ,
1992 CD
< NN
/ref NNP
> NNP
have VBP
been VBN
explored VBN
and CC
achieved VBN
numerous JJ
success NN
over IN
the DT
last JJ
decade NN
. .

as IN
word NN
sequences NNS
are VBP
not RB
translated VBN
literally RB
a DT
word NN
for IN
a DT
word NN
, ,
acquiring VBG
phraseqevel NN
correspondence NN
still RB
remains VBZ
an DT
important JJ
problem NN
to TO
be VB
exploited VBN
. .

4 CD
conclusions NNS
compared VBN
with IN
other JJ
word NN
alignment NN
algorithms NN
< NNP
ref NN
> NNP
brown IN
et FW
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gale NN
and CC
church NN
, ,
1991a CD
< NN
/ref NNP
> NNP
, ,
wordalign NN
does VBZ
not RB
require VB
sentence NN
alignment NN
as IN
input NN
, ,
and CC
was VBD
shown VBN
to TO
produce VB
useful JJ
alignments NNS
for IN
small JJ
and CC
noisy JJ
corpora NN
. .

taking VBG
the DT
output NN
of IN
charalign NN
as IN
input NN
, ,
wordalign NN
produces VBZ
significantly RB
better RBR
, ,
word7 JJ
offset NN
from IN
correct JJ
alignment JJ
0 CD
1 CD
2 CD
3 CD
4 CD
percentage NN
605 CD
108 CD
75 CD
52 CD
16 CD
accumulative JJ
percentage NN
605 CD
713 CD
788 CD
84 CD
856 CD
table JJ
2 CD
: :
wordaligns NNS
precision NN
on IN
noisy NN
input NN
, ,
scanned VBN
by IN
an DT
ocr JJ
device NN
. .

588 CD
ido NN
dagan NN
and CC
alon NN
itai NN
word NN
sense NN
disambiguation NN
vides VBZ
a DT
useful JJ
source NN
of IN
a DT
sense NN
tagged VBN
corpus NN
. .

< JJ
ref NN
> NNP
gale NN
, ,
church NN
, ,
and CC
yarowsky $
1992a CD
< NNP
/ref NNP
> NNP
have VBP
also RB
exploited VBN
this DT
resource NN
for IN
achieving VBG
large JJ
amounts NNS
of IN
testing VBG
and CC
training VBG
materials NNS
. .

clearly RB
, ,
statistics NNS
on IN
lexical JJ
relations NNS
can MD
also RB
be VB
useful JJ
for IN
target NN
word NN
selection NN
. .

some DT
of IN
our PRP$
initial JJ
data NNS
suggest VBP
that IN
the DT
hypothesis NN
of IN
deep JJ
semantic JJ
selection NN
may MD
in IN
fact NN
be VB
correct JJ
, ,
as RB
well RB
as IN
indicating VBG
what WP
the DT
nature NN
of IN
the DT
coercion NN
rules NNS
may MD
be VB
. .

counts NNS
for IN
objects NNS
of IN
begin/v NN
: :
205 CD
begin/v NN
career/o NN
176 CD
begin/v NN
day/o NN
159 CD
begin/v NN
work/o NN
140 CD
begin/v NN
talk/o NN
120 CD
begin/v NN
campaign/o NN
113 CD
begin/v NN
investigation/o NN
106 CD
begin/v NN
process/o NN
92 CD
begin/v NN
program/o NN
8s CD
begin/v NN
operation/o NN
86 CD
begin/v NN
negotiation/o RB
66 CD
begin/v NN
strike/o NN
64 CD
begin/v NN
production/o NN
59 CD
begin/v NN
meeting/o NN
89 CD
begin/v NN
term/o NN
50 CD
begin/v NN
visit/o NN
45 CD
begin/v NN
test/o NN
39 CD
begin/v NN
construction/o NN
31 CD
begin/v NN
debate/o NN
29 CD
begin/v NN
trial/o NN
corpus NN
studies NNS
confirm VBP
similar JJ
results NNS
for IN
weakly JJ
intensional JJ
contexts NN
< NNP
ref NN
> NNP
pustejovsky NN
1991 CD
< NNP
/ref NNP
> NNP
such JJ
as IN
the DT
complement NN
of IN
coercive JJ
verbs NNS
such JJ
as IN
veto NN
. .

these DT
are VBP
interesting VBG
because IN
regardless NN
of IN
the DT
noun JJ
type NN
appearing VBG
as IN
complement NN
, ,
it PRP
is VBZ
embedded VBN
within IN
a DT
semantic JJ
interpretation NN
of IN
the DT
proposal NN
to TO
, ,
thereby RB
clothing VBG
the DT
complement NN
within IN
an DT
intensional JJ
context NN
. .

some DT
of IN
our PRP$
initial JJ
data NNS
suggest VBP
that IN
the DT
hypothesis NN
of IN
deep JJ
semantic JJ
selection NN
may MD
in IN
fact NN
be VB
correct JJ
, ,
as RB
well RB
as IN
indicating VBG
what WP
the DT
nature NN
of IN
the DT
coercion NN
rules NNS
may MD
be VB
. .

corpus NN
studies NNS
confirm VBP
similar JJ
results NNS
for IN
weakly JJ
intensional JJ
contexts NN
such JJ
as IN
the DT
complement NN
of IN
coercive JJ
verbs NNS
such JJ
as IN
veto NN
. .

these DT
are VBP
interesting VBG
because IN
regardless NN
of IN
the DT
noun JJ
type NN
appearing VBG
as IN
complement NN
, ,
it PRP
is VBZ
embedded VBN
within IN
a DT
semantic JJ
interpretation NN
of IN
the DT
proposal NN
to TO
, ,
thereby RB
clothing VBG
the DT
complement NN
within IN
an DT
intensional JJ
context NN
. .

methods NNS
of IN
resolving VBG
ambiguities NNS
have VBP
been VBN
based VBN
, ,
for IN
example NN
, ,
on IN
the DT
assumption NN
that IN
case NN
slots NNS
are VBP
mutually RB
independent JJ
< NNP
tref NN
> NNP
hindle NN
and CC
rooth NN
1991 CD
< NNP
/tref NNP
> NNP
, ,
or CC
at IN
most JJS
two CD
case NN
slots NNS
are VBP
dependent JJ
< NNP
ref NN
> NN
collins NNS
and CC
brooks NNS
1995 CD
< NNP
/ref NNP
> NNP
. .

in IN
this DT
article NN
, ,
we PRP
propose VBP
an DT
efficient NN
and CC
general JJ
method NN
of IN
learning VBG
dependencies NNS
between IN
case NN
frame NN
slots NNS
. .

in IN
general JJ
, ,
these DT
words NNS
will MD
not RB
be VB
adjacent JJ
in IN
the DT
text NN
, ,
so IN
it PRP
will MD
not RB
be VB
possible JJ
to TO
use VB
existing VBG
approaches NNS
unmodified JJ
eg JJ
< NN
ref NN
> NNP
church NN
and CC
hanks NNS
1989 CD
< NNP
/ref NNP
> NNP
, ,
because IN
these DT
apply NNS
to TO
adjacent JJ
words NNS
in IN
unanalyzed JJ
text NN
. .

< JJ
tref NN
> NNP
hindle NN
and CC
rooth NN
1991 CD
< NNP
/tref NNP
> NNP
report NN
good JJ
results NNS
using VBG
a DT
mutual JJ
information NN
measure NN
of IN
collocation NN
applied VBN
within IN
such JJ
a DT
structurally RB
defined VBN
context NN
, ,
and CC
their PRP$
approach NN
should MD
carry VB
over IN
to TO
our PRP$
framework NN
straightforwardly RB
. .

one CD
way NN
of IN
integrating VBG
structural JJ
collocational JJ
information NN
into IN
the DT
system NN
presented VBN
above RB
would MD
be VB
to TO
make VB
use NN
of IN
the DT
semantic JJ
component NN
of IN
the DT
anlt JJ
grammar NN
this DT
component NN
pairs VBZ
logical JJ
forms NNS
with IN
each DT
distinct JJ
syntactic JJ
analysis NN
that WDT
represent NN
, ,
among IN
other JJ
things NNS
, ,
the DT
predicate-argument JJ
structure NN
of IN
the DT
input NN
. .

in IN
the DT
resolution NN
of IN
pp JJ
attachment NN
and CC
similar JJ
ambiguities NNS
, ,
it PRP
is VBZ
collocation NN
at IN
this DT
level NN
of IN
representation NN
that WDT
appears VBZ
to TO
be VB
most RBS
relevant JJ
. .

the DT
novel JJ
aspect NN
of IN
our PRP$
study NN
is VBZ
that IN
we PRP
collect VBP
not RB
only RB
operational JJ
pairs NNS
, ,
but CC
triples NNS
, ,
such JJ
as IN
nprep JJ
n NN
, ,
vprepn NN
etc NN
in IN
fact NN
, ,
the DT
preposition NN
convey NN
important JJ
information NN
on IN
the DT
nature NN
of IN
the DT
semantic JJ
link NN
between IN
syntactically RB
related VBN
content JJ
words NNS
. .

by IN
looking VBG
at IN
the DT
preposition NN
, ,
it PRP
is VBZ
possible JJ
to TO
restrict VB
the DT
set NN
of IN
semantic JJ
relations NNS
underlying VBG
a DT
syntactic JJ
relation NN
eg NN
forpurpose NN
, ,
beneficiary NN
. .

partial JJ
parsing VBG
techniques NNS
have VBP
been VBN
used VBN
with IN
a DT
considerable JJ
success NN
in IN
processing VBG
large JJ
volumes NNS
of IN
text NN
, ,
for IN
example NN
atts NNS
fidditch VBP
< NNP
tref NN
> NNP
hindle NN
and CC
rooth NN
, ,
1991 CD
< NN
/tref NNP
> NNP
parsed VBD
13 CD
million CD
words NNS
of IN
associated JJ
press NN
news NN
messages NNS
, ,
while IN
mits NNS
parser VBP
de IN
< NNP
ref NN
> NNP
marcken NN
, ,
1990 CD
< NN
/ref NNP
> NNP
was VBD
used VBN
to TO
process VB
the DT
1 CD
million CD
word NN
lancaster/oslo/bergen NN
lob NN
corpus NN
. .

this DT
kind NN
of IN
partial JJ
analysis NN
may MD
be VB
sufficient JJ
in IN
some DT
applications NNS
because IN
of IN
a DT
relatively RB
high JJ
precision NN
of IN
identifying VBG
correct JJ
syntactic JJ
dependencies NNS
. .

future JJ
directions NNS
this DT
paper NN
presented VBD
one CD
method NN
of IN
learning VBG
subcategorizations NNS
, ,
but CC
there EX
are VBP
other JJ
approaches NNS
one CD
might MD
try VB
. .

this DT
method NN
could MD
be VB
usefully RB
incorporated VBN
into IN
my PRP$
parser NN
, ,
but CC
it PRP
remains VBZ
a DT
special-purpose JJ
technique NN
for IN
one CD
particular JJ
ease NN
. .

another DT
research NN
direction NN
would MD
be VB
making VBG
the DT
parser NN
stochastic NN
as RB
well RB
, ,
rather RB
than IN
it PRP
being VBG
a DT
categorical JJ
finite NN
state NN
device NN
that WDT
runs VBZ
on IN
the DT
output NN
of IN
a DT
stochastic JJ
tagger NN
. .

the DT
generalization NN
step NN
is VBZ
needed VBN
in IN
order NN
to TO
represent VB
the DT
input NN
case NN
frame NN
instances NNS
more RBR
compactly RB
as RB
well RB
as IN
to TO
judge VB
the DT
degree NN
of IN
acceptability NN
of IN
unseen JJ
case NN
frame NN
instances NNS
. .

for IN
the DT
extraction NN
problem NN
, ,
there EX
have VBP
been VBN
various JJ
methods NNS
proposed VBN
to TO
date NN
, ,
which WDT
are VBP
quite RB
adequate JJ
< NNP
tref NN
> NNP
hindle NN
and CC
rooth NN
1991 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
grishman NN
and CC
sterling NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
manning NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
utsuro NN
, ,
matsumoto NN
, ,
and CC
nagao JJ
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
brent NN
1993 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
smadja NN
1993 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
grefenstette NN
1994 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
briscoe NN
and CC
carroll NN
1997 CD
< NNP
/ref NNP
> NNP
. .

a DT
number NN
of IN
methods NNS
for IN
generalizing VBG
values NNS
of IN
a DT
case NN
frame NN
slot NN
for IN
a DT
verb NN
have VBP
been VBN
cc JJ
media NNS
res NNS
. .

figure NN
10 CD
shows VBZ
the DT
result NN
as IN
lat NN
, ,
where WRB
the DT
threshold NN
for IN
t-score NN
is VBZ
set VBN
to TO
128 CD
significance NN
level NN
of IN
90 CD
percent NN
. .

from IN
figure NN
10 CD
we PRP
see VBP
that IN
with IN
respect NN
to TO
accuracy-coverage JJ
curves NNS
, ,
mdl NN
outperforms NNS
both DT
sa NNS
and CC
la NN
throughout IN
, ,
while IN
sa NN
is VBZ
better JJR
than IN
la JJR
next JJ
, ,
we PRP
tested VBD
the DT
method NN
of IN
applying VBG
a DT
default NN
rule NN
after IN
applying VBG
each DT
method NN
. .

sense NN
disambiguation NN
thus RB
resembles VBZ
many JJ
other JJ
decision NN
tasks NNS
, ,
and CC
not RB
surprisingly RB
, ,
several JJ
common JJ
decision NN
algorithms NNS
were VBD
employed VBN
in IN
different JJ
works NNS
. .

these DT
include VBP
a DT
bayesian JJ
classifier NN
< NNP
ref NN
> NNP
gale NN
, ,
church NN
, ,
and CC
yarowsky JJ
1993 CD
< NNP
/ref NNP
> NNP
and CC
a DT
distance NN
589 CD
computational JJ
linguistics NNS
volume NN
20 CD
, ,
number NN
4 CD
metric JJ
between IN
vectors NNS
< NNP
ref NN
> NNP
schiitze NN
1993 CD
< NNP
/ref NNP
> NNP
, ,
both DT
inspired VBN
from IN
methods NNS
in IN
information NN
retrieval NN
; :
the DT
use NN
of IN
the DT
flip-flop JJ
algorithm NN
for IN
ordering VBG
possible JJ
informants NNS
about IN
the DT
preferred JJ
sense NN
, ,
trying VBG
to TO
maximize VB
the DT
mutual JJ
information NN
between IN
the DT
informant NN
and CC
the DT
ambiguous JJ
word NN
< NNP
tref NN
> NNP
brown IN
et RB
al JJ
1991 CD
< NNP
/tref NNP
> NNP
; :
and CC
the DT
use NN
of IN
confidence NN
intervals NNS
to TO
establish VB
the DT
degree NN
of IN
confidence NN
in IN
a DT
certain JJ
preference NN
, ,
combined VBN
with IN
a DT
constraint NN
propagation NN
algorithm IN
the DT
current JJ
paper NN
. .

at IN
the DT
present JJ
stage NN
of IN
research NN
on IN
sense NN
disambiguation NN
, ,
it PRP
is VBZ
difficult JJ
to TO
judge VB
whether IN
a DT
certain JJ
decision NN
algorithm NN
is VBZ
significantly RB
superior JJ
to TO
others NNS
. .

a DT
third JJ
difference NN
concerns NNS
the DT
granularity NN
of IN
wsd NN
attempted VBN
, ,
which WDT
one CD
can MD
illustrate VB
in IN
terms NNS
of IN
the DT
two CD
levels NNS
of IN
semantic JJ
distinctions NNS
found VBD
in IN
many JJ
dictionaries NNS
: :
homograph NN
and CC
sense NN
see VBP
section NN
31 CD
. .

like IN
< NNP
ref VBP
> NNP
cowie NN
, ,
guthrie NN
, ,
and CC
guthrie NN
1992 CD
< NNP
/ref NNP
> NNP
, ,
we PRP
shall MD
give VB
results NNS
at IN
both DT
levels NNS
, ,
but CC
it PRP
is VBZ
worth JJ
pointing VBG
out RP
that IN
the DT
targets NNS
of IN
, ,
say UH
, ,
work NN
using VBG
translation NN
equivalents NNS
eg VBP
, ,
< JJ
tref NN
> NNP
brown IN
et RB
al JJ
1991 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gale NN
, ,
church NN
, ,
and CC
< NNP
ref VBP
> NNP
yarowsky NN
1992 CD
< NNP
/ref NNP
> NNP
c VBZ
< NNP
/ref NNP
> NNP
; :
and CC
see VB
section NN
23 CD
and CC
roget VB
categories NNS
< NNP
ref NN
> NNP
yarowsky NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
masterman NN
1957 CD
< NNP
/ref NNP
> NNP
correspond NN
broadly RB
to TO
the DT
wider NN
, ,
homograph NN
, ,
distinctions NNS
. .

in IN
this DT
paper NN
we PRP
attempt VBP
to TO
show VB
that IN
the DT
high JJ
level NN
of IN
results NNS
more RBR
typical JJ
of IN
systems NNS
trained VBN
on IN
many JJ
instances NNS
of IN
a DT
restricted JJ
vocabulary NN
can MD
also RB
be VB
obtained VBN
by IN
large JJ
vocabulary JJ
systems NNS
, ,
and CC
that IN
the DT
best JJS
results NNS
are VBP
to TO
be VB
obtained VBN
from IN
an DT
optimization NN
of IN
a DT
combination NN
of IN
types NNS
of IN
lexical JJ
knowledge NN
see VBP
section NN
2 CD
. .

11 CD
lexical JJ
knowledge NN
and CC
wsd NN
syntactic JJ
, ,
semantic JJ
, ,
and CC
pragmatic JJ
information NN
are VBP
all DT
potentially RB
useful JJ
for IN
wsd NN
, ,
as IN
can MD
be VB
demonstrated VBN
by IN
considering VBG
the DT
following JJ
sentences NNS
: :
1 CD
2 CD
3 CD
4 CD
john NN
did VBD
not RB
feel VB
well RB
. .

semi-supervised JJ
methods NNS
for IN
wsd NN
are VBP
characterized VBN
in IN
terms NNS
of IN
exploiting VBG
unlabeled JJ
data NNS
in IN
learning JJ
procedure NN
with IN
the DT
requirement NN
of IN
predefined JJ
sense NN
inventory NN
for IN
target NN
words NNS
. .

they PRP
roughly RB
fall VBP
into IN
three CD
categories NNS
according VBG
to TO
what WP
is VBZ
used VBN
for IN
supervision NN
in IN
learning VBG
process NN
: :
1 CD
using VBG
external JJ
resources NNS
, ,
eg NN
, ,
thesaurus NN
or CC
lexicons NNS
, ,
to TO
disambiguate VB
word NN
senses VBZ
or CC
automatically RB
generate JJ
sense-tagged JJ
corpus NN
, ,
< NNP
ref VBZ
> NNP
lesk NN
, ,
1986 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
lin NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
mccarthy JJ
et NN
al NN
, ,
2004 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
seo NN
et NN
al NN
, ,
2004 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
, ,
1992 CD
< NN
/ref NNP
> NNP
, ,
2 CD
exploiting VBG
the DT
differences NNS
between IN
mapping NN
of IN
words NNS
to TO
senses NNS
in IN
different JJ
languages NNS
by IN
the DT
use NN
of IN
bilingual JJ
corpora NN
eg NN
parallel JJ
corpora NN
or CC
untagged JJ
monolingual JJ
corpora NN
in IN
two CD
languages NNS
< VBP
tref JJ
> NNP
brown NN
et NN
al NN
, ,
1991 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan NN
and CC
itai NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
diab NN
and CC
resnik NN
, ,
2002 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
li NN
and CC
li NN
, ,
2004 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
ng JJ
et NN
al NN
, ,
2003 CD
< NN
/ref NNP
> NNP
, ,
3 CD
bootstrapping VBG
sensetagged VBD
seed NN
examples NNS
to TO
overcome VB
the DT
bottleneck NN
of IN
acquisition NN
of IN
large JJ
sense-tagged JJ
data NNS
< NNS
ref VBP
> NNP
hearst RB
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
karov NN
and CC
edelman NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
mihalcea NN
, ,
2004 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
park NN
et NN
al NN
, ,
2000 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
, ,
1995 CD
< NN
/ref NNP
> NNP
. .

as IN
a DT
commonly RB
used VBN
semi-supervised JJ
learning NN
method NN
for IN
wsd NN
, ,
bootstrapping VBG
algorithm NN
works NNS
by IN
iteratively RB
classifying VBG
unlabeled JJ
examples NNS
and CC
adding VBG
confidently RB
classified VBN
examples NNS
into IN
labeled VBN
dataset NN
using VBG
a DT
model NN
learned VBN
from IN
augmented VBN
labeled JJ
dataset NN
in IN
previous JJ
iteration NN
. .

it PRP
can MD
be VB
found VBN
that IN
the DT
affinity NN
information NN
among IN
unlabeled JJ
examples NNS
is VBZ
not RB
fully RB
explored VBN
in IN
this DT
bootstrapping NN
process NN
. .

for IN
example NN
, ,
the DT
correct JJ
alignment NN
of IN
the DT
bilingual JJ
corpus NN
in IN
figure NN
2 CD
consists NNS
of IN
the DT
sentence NN
bead NN
el NN
; :
f1 NN
followed VBN
by IN
the DT
sentence NN
bead NN
e2 NN
; :
; :
2 CD
, ,
f3 NN
. .

this DT
approach NN
is VBZ
quite RB
different JJ
from IN
those DT
adopted VBN
for IN
the DT
translation NN
of IN
single JJ
words NNS
< VBP
ref JJ
> NN
klavans NNS
and CC
tzoukermann JJ
1990 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
dorr NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
klavans NNS
and CC
tzoukermann JJ
1996 CD
< NNP
/ref NNP
> NNP
, ,
since IN
for IN
single JJ
words NNS
polysemy NN
can MD
not RB
be VB
ignored VBN
; :
indeed RB
, ,
the DT
problem NN
of IN
sense NN
disambiguation NN
has VBZ
been VBN
linked VBN
to TO
the DT
problem NN
of IN
translating VBG
ambiguous JJ
words NNS
< VBP
tref JJ
> NNP
brown NN
et NN
al NN
1991 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan NN
, ,
itai NN
, ,
and CC
schwall NN
1991 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan NN
and CC
itai NN
1994 CD
< NNP
/ref NNP
> NNP
. .

the DT
assumption NN
of IN
a DT
single JJ
meaning NN
per IN
collocation NN
was VBD
based VBN
on IN
our PRP$
previous JJ
experience NN
with IN
english JJ
collocations NNS
< VBP
ref JJ
> NNP
smadja NN
1993 CD
< NNP
/ref NNP
> NNP
, ,
is VBZ
supported VBN
for IN
less JJR
opaque JJ
collocations NNS
by IN
the DT
fact NN
that IN
their PRP$
constituent NN
words NNS
tend VBP
to TO
have VB
a DT
single JJ
sense NN
when WRB
they PRP
appear VBP
in IN
the DT
collocation NN
< NNP
ref NN
> NNP
yarowsky NN
1993 CD
< NNP
/ref NNP
> NNP
, ,
and CC
was VBD
verified VBN
during IN
our PRP$
evaluation NN
of IN
champollion NN
section NN
7 CD
. .

we PRP
construct VBP
a DT
mathematical JJ
model NN
of IN
the DT
events NNS
we PRP
want VBP
to TO
correlate VB
, ,
namely RB
, ,
the DT
appearance NN
of IN
any DT
word NN
or CC
group NN
of IN
words NNS
in IN
the DT
sentences NNS
of IN
our PRP$
corpus NN
, ,
as IN
follows VBZ
: :
to TO
each DT
group NN
of IN
words NNS
g NNS
, ,
in IN
either CC
the DT
source NN
or CC
the DT
target NN
language NN
, ,
we PRP
map VBP
a DT
binary JJ
random NN
variable JJ
xc NN
that WDT
takes VBZ
the DT
value NN
1 CD
if IN
g JJ
appears VBZ
in IN
a DT
particular JJ
sentence NN
and CC
0 CD
if IN
not RB
. .

semi-supervised JJ
methods NNS
for IN
wsd NN
are VBP
characterized VBN
in IN
terms NNS
of IN
exploiting VBG
unlabeled JJ
data NNS
in IN
the DT
learning JJ
procedure NN
with IN
the DT
need NN
of IN
predened JJ
sense NN
inventories NNS
for IN
target NN
words NNS
. .

the DT
information NN
for IN
semi-supervised JJ
sense NN
disambiguation NN
is VBZ
usually RB
obtained VBN
from IN
bilingual JJ
corpora NN
eg NN
parallel JJ
corpora NN
or CC
untagged JJ
monolingual JJ
corpora NN
in IN
two CD
languages NNS
< VBP
tref JJ
> NNP
brown NN
et NN
al NN
, ,
1991 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan NN
and CC
itai NN
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
or CC
sense-tagged JJ
seed NN
examples NNS
< VBP
ref JJ
> NNP
yarowsky NN
, ,
1995 CD
< NN
/ref NNP
> NNP
. .

they PRP
always RB
rely VBP
on IN
hand-crafted JJ
lexicons NNS
eg VBP
, ,
wordnet NN
as IN
sense NN
inventories NNS
. .

by IN
repeating VBG
the DT
above NN
processes VBZ
, ,
it PRP
can MD
create VB
an DT
accurate NN
classifier NN
for IN
word NN
translation NN
disambiguation NN
. .

to TO
deal VB
with IN
these DT
robustness NN
issues NNS
, ,
< NNP
ref VBZ
> CD
church NN
1993 CD
< NNP
/ref NNP
> NNP
developed VBD
a DT
character-based JJ
alignment NN
method NN
called VBN
charalign NN
. .

the DT
method NN
was VBD
intended VBN
as IN
a DT
replacement NN
for IN
sentence-based JJ
methods NNS
eg NN
, ,
< NNP
tref VBZ
> NNP
brown JJ
et NN
al NN
, ,
1991a CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gale NN
and CC
church NN
, ,
1991b CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
kay NN
and CC
rosenschein NN
, ,
1993 CD
< NN
/ref NNP
> NNP
, ,
which WDT
are VBP
very RB
sensitive JJ
to TO
noise VB
. .

this DT
paper NN
describes VBZ
a DT
new JJ
program NN
, ,
called VBD
wordalign NN
, ,
that WDT
starts VBZ
with IN
an DT
initial JJ
rough JJ
alignment NN
eg NN
, ,
the DT
output NN
of IN
charalign NN
or CC
a DT
sentence-based JJ
alignment NN
method NN
, ,
and CC
produces VBZ
improved JJ
alignments NNS
by IN
exploiting VBG
constraints NNS
at IN
the DT
word-level NN
. .

more RBR
importantly RB
, ,
because IN
wordalign NN
and CC
charalign NN
were VBD
designed VBN
to TO
work VB
robustly RB
on IN
texts NNS
that WDT
are VBP
smaller JJR
and CC
more RBR
noisy JJ
than IN
the DT
hansards NNS
, ,
it PRP
has VBZ
been VBN
possible JJ
to TO
successfully RB
deploy VB
the DT
programs NNS
at IN
att JJ
language NN
line NN
services NNS
, ,
a DT
commercial JJ
translation NN
service NN
, ,
to TO
help VB
them PRP
with IN
difficult JJ
terminology NN
. .

the DT
information NN
retrieval NN
application NN
may MD
be VB
of IN
particular JJ
relevance NN
to TO
this DT
audience NN
. .

the DT
information NN
retrieval NN
application NN
may MD
be VB
of IN
particular JJ
relevance NN
to TO
this DT
audience NN
. .

it PRP
would MD
be VB
highly RB
desirable JJ
for IN
users NNS
to TO
be VB
able JJ
to TO
express VB
queries NNS
in IN
whatever WDT
language NN
they PRP
chose VBD
and CC
retrieve VB
documents NNS
that WDT
may MD
or CC
may MD
not RB
have VB
been VBN
written VBN
in IN
the DT
same JJ
language NN
as IN
the DT
query NN
. .

similar JJ
results NNS
are VBP
reported VBN
in IN
< NNP
ref NN
> NNP
nakatani NN
, ,
hirschberg NN
, ,
and CC
grosz NN
1995 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
ref VBP
> NNP
hirschberg NN
and CC
nakatani JJ
1996 CD
< NNP
/ref NNP
> NNP
for IN
spontaneous JJ
speech NN
as RB
well RB
. .

< JJ
ref NN
> NNP
grosz NN
and CC
hirschberg NN
1992 CD
< NNP
/ref NNP
> NNP
also RB
use VBP
the DT
classification NN
and CC
regression NN
tree NN
system NN
cart JJ
< NNP
ref NN
> NNP
brieman NN
et VBZ
al JJ
1984 CD
< NNP
/ref NNP
> NNP
to TO
automatically RB
construct VB
and CC
evaluate VB
decision NN
trees NNS
for IN
classifying VBG
aspects NNS
of IN
discourse NN
structure NN
from IN
intonational JJ
feature NN
values NNS
. .

< JJ
ref NN
> NN
in IN
swerts NNS
1995 CD
< NNP
/ref NNP
> NNP
, ,
paragraph NN
boundaries NNS
are VBP
empirically RB
obtained VBN
as IN
described VBN
above IN
. .

semcor NN
contains VBZ
91,808 CD
words NNS
tagged VBN
with IN
wordnet JJ
synsets NNS
, ,
6,071 CD
of IN
which WDT
are VBP
proper JJ
names NNS
, ,
which WDT
we PRP
ignored VBD
, ,
leaving VBG
85,737 CD
words NNS
which WDT
could MD
potentially RB
be VB
translated VBN
. .

the DT
translation NN
contains VBZ
only RB
36,869 CD
words NNS
tagged VBN
with IN
ldoce JJ
senses NNS
; :
however RB
, ,
this DT
is VBZ
a DT
reasonable JJ
size NN
for IN
an DT
evaluation NN
corpus NN
for IN
the DT
task NN
, ,
and CC
it PRP
is VBZ
several JJ
orders NNS
of IN
magnitude NN
larger JJR
than IN
those DT
used VBN
by IN
other JJ
researchers NNS
working VBG
in IN
large JJ
vocabulary JJ
wsd NN
, ,
for IN
example NN
< NNP
ref VBZ
> NNP
cowie NN
, ,
guthrie NN
, ,
and CC
guthrie NN
1992 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
harley NN
and CC
glennon NN
1997 CD
< NNP
/ref NNP
> NNP
, ,
and CC
mahesh JJ
et NN
al NN
. .

co-occurrence NN
information NN
between IN
neighboring VBG
words NNS
and CC
words NNS
in IN
the DT
same JJ
sentence NN
has VBZ
been VBN
used VBN
in IN
phrase JJ
extraction NN
< NNP
ref NN
> NNP
smadja NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
fung NN
and CC
wu NN
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
phrasal NN
translation NN
< NNP
ref NN
> NNP
smadja NN
et NN
al NN
, ,
1996 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
kupiec NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
wu NN
, ,
1995 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan NN
and CC
church NN
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
target NN
word NN
selection NN
< NNP
ref NN
> NNP
liu NN
and CC
li NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
tanaka NN
and CC
iwasaki NN
, ,
1996 CD
< NN
/ref NNP
> NNP
, ,
domain NN
word NN
translation NN
< NNP
ref NN
> NNP
fung NN
and CC
lo NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
fung NN
, ,
1998 CD
< NN
/ref NNP
> NNP
, ,
sense NN
disambiguation NN
< NNP
ref NN
> NNP
brown IN
et FW
al NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan JJ
et FW
al NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan NN
and CC
itai NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
gale NN
et NN
al NN
, ,
1992a CD
< NN
/tref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
gale NN
et NN
al NN
, ,
1992b CD
< NN
/tref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
gale NN
et NN
al NN
, ,
1992c CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
shiitze NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gale NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
, ,
1995 CD
< NN
/ref NNP
> NNP
, ,
and CC
even RB
recently RB
for IN
query NN
translation NN
in IN
cross-language JJ
ir NN
as IN
well RB
< NNP
ref NN
> NNP
ballesteros NN
and CC
croft NN
, ,
1998 CD
< NN
/ref NNP
> NNP
. .

we PRP
want VBP
to TO
devise VB
a DT
method NN
that WDT
uses VBZ
only RB
monolingual JJ
data NNS
in IN
the DT
primary JJ
language NN
to TO
train VB
co-occurrence JJ
information NN
. .

co-occurrence NN
information NN
between IN
neighboring VBG
words NNS
and CC
words NNS
in IN
the DT
same JJ
sentence NN
has VBZ
been VBN
used VBN
in IN
phrase JJ
extraction NN
< NNP
ref NN
> NNP
smadja NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
fung NN
and CC
wu NN
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
phrasal NN
translation NN
< NNP
ref NN
> NNP
smadja NN
et NN
al NN
, ,
1996 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
kupiec NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
wu NN
, ,
1995 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan NN
and CC
church NN
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
target NN
word NN
selection NN
< NNP
ref NN
> NNP
liu NN
and CC
li NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
tanaka NN
and CC
iwasaki NN
, ,
1996 CD
< NN
/ref NNP
> NNP
, ,
domain NN
word NN
translation NN
< NNP
ref NN
> NNP
fung NN
and CC
lo NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
fung NN
, ,
1998 CD
< NN
/ref NNP
> NNP
, ,
sense NN
disambiguation NN
< NNP
ref NN
> NNP
brown IN
et FW
al NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan JJ
et FW
al NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan NN
and CC
itai NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
gale NN
et NN
al NN
, ,
1992a CD
< NN
/tref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
gale NN
et NN
al NN
, ,
1992b CD
< NN
/tref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
gale NN
et NN
al NN
, ,
1992c CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
shiitze NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gale NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
, ,
1995 CD
< NN
/ref NNP
> NNP
, ,
and CC
even RB
recently RB
for IN
query NN
translation NN
in IN
cross-language JJ
ir NN
as IN
well RB
< NNP
ref NN
> NNP
ballesteros NN
and CC
croft NN
, ,
1998 CD
< NN
/ref NNP
> NNP
. .

7 CD
subjects VBZ
a DT
, ,
b NN
, ,
c NN
, ,
d NN
, ,
e NN
, ,
f NN
, ,
g VBZ
161 CD
i0 NN
hei NN
falls VBZ
over RP
, ,
figure JJ
2 CD
: :
portion NN
of IN
segntentation NN
from IN
narrative JJ
6 CD
subject JJ
annotation NN
of IN
narratrs JJ
httention NN
digression NN
to TO
describe VB
suml JJ
track NN
no DT
verbal JJ
communication NN
ie NN
, ,
speaker NN
describes NNS
lack VBP
thereof JJ
describes NNS
that IN
it PRP
is VBZ
a DT
silent JJ
movie NN
with IN
only JJ
nature NN
sounds VBZ
speaker NN
describes NNS
sound NN
techniques NNS
used VBN
in IN
tnovie NN
explain VBP
that IN
there EX
is VBZ
no DT
speaking NN
ill VB
nlovie JJ
figure NN
3 CD
: :
segment NN
spanning VBG
1,12 CD
through IN
154 CD
3 CD
discourse NN
segment NN
boundaries NNS
in IN
< NNP
ref NN
> NNP
passonneau NN
and CC
litman NN
, ,
1993 CD
< NN
/ref NNP
> NNP
, ,
we PRP
show VBP
that IN
our PRP$
subjects NNS
agree VBP
with IN
one CD
another DT
at IN
levels NNS
that WDT
are VBP
statistically RB
significant JJ
, ,
thus RB
demonstrating VBG
the DT
reliability NN
of IN
intention NN
as IN
a DT
segmentation NN
criterion NN
. .

percent NN
agreement NN
is VBZ
defined VBN
in IN
< NNP
tref NN
> NNP
gale NN
et NN
al NN
, ,
1992 CD
< NN
/tref NNP
> NNP
as IN
the DT
ratio NN
of IN
observed JJ
agreements NNS
with IN
the DT
majority NN
opinion NN
to TO
possible JJ
agreements NNS
with IN
the DT
majority NN
opinion NN
. .

we PRP
use VBP
percent JJ
agreement NN
to TO
measure VB
the DT
ability NN
of IN
subjects NNS
to TO
agree VB
with IN
one CD
anotlter NN
on IN
whether IN
there EX
is VBZ
segment NN
boundary JJ
between IN
two CD
adjacent JJ
prosodic JJ
phrases NNS
. .

we PRP
find VBP
that IN
the DT
average JJ
agreement NN
across IN
the DT
20 CD
narratives NNS
on IN
the DT
status NN
of IN
all DT
potential JJ
boundary JJ
locations NNS
is VBZ
89 CD
with IN
a DT
range NN
from IN
82-92 JJ
. .

this DT
process NN
is VBZ
similar JJ
to TO
the DT
use NN
of IN
general JJ
pseudowords NNS
< VBP
tref JJ
> NNP
gale NN
et NN
al NN
, ,
1992b CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gaustad NN
, ,
2001 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
nakov NN
and CC
hearst NN
, ,
2003 CD
< NN
/ref NNP
> NNP
, ,
but CC
has VBZ
some DT
essential JJ
differences NNS
. .

this DT
artificial JJ
ambiguous JJ
word NN
need NN
to TO
simulate VB
the DT
function NN
of IN
the DT
real JJ
ambiguous JJ
word NN
, ,
and CC
to TO
acquire VB
semantic JJ
knowledge NN
as IN
the DT
real JJ
ambiguous JJ
word NN
does VBZ
. .

thus RB
, ,
we PRP
call VBP
it PRP
an DT
equivalent JJ
pseudoword NN
ep NN
for IN
its PRP$
equivalence NN
with IN
the DT
real JJ
ambiguous JJ
word NN
. .

making VBG
such JJ
an DT
assumption NN
is VBZ
reasonable JJ
since IN
pos NN
taggers NNS
that WDT
can MD
achieve VB
accuracy NN
of IN
96 CD
are VBP
readily RB
available JJ
to TO
assign VB
pos NN
to TO
unrestricted JJ
english JJ
sentences NNS
< VBP
ref JJ
> NNP
brill NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBP
> NNP
cutting VBG
et NN
al NN
, ,
1992 CD
< NN
/ref NNP
> NNP
. .

in IN
addition NN
, ,
sense NN
definitions NNS
are VBP
only RB
available JJ
for IN
root NN
words NNS
in IN
a DT
dictionary NN
. .

these DT
are VBP
words NNS
that WDT
are VBP
not RB
morphologically RB
inflected VBN
, ,
such JJ
as IN
interest NN
as IN
opposed VBN
to TO
the DT
plural JJ
form NN
interests NNS
, ,
fall NN
as IN
opposed VBN
to TO
the DT
other JJ
inflected JJ
forms NNS
like IN
fell VBD
, ,
fallen VBN
, ,
falling VBG
, ,
falls NNS
, ,
etc FW
the DT
sense NN
of IN
a DT
morphologically RB
inflected JJ
content NN
word NN
is VBZ
the DT
sense NN
of IN
its PRP$
uninflected JJ
form NN
. .

table JJ
5 CD
: :
tion NN
out IN
score RB
0008421 CD
0007895 CD
0007669 CD
0007588 CD
0007283 CD
0006812 CD
0006430 CD
0006218 CD
0005921 CD
0005527 CD
0005335 CD
0005335 CD
0005221 CD
0004731 CD
0004470 CD
0004275 CD
0003878 CD
0003859 CD
0003859 CD
0003784 CD
0003686 CD
0003550 CD
0003519 CD
0003481 CD
0003407 CD
0003407 CD
0003338 CD
0003324 CD
some DT
chinese JJ
ut JJ
english JJ
teng-hui JJ
sar NN
flu NN
lei JJ
poultry NN
sar VBD
hijack JJ
poultry NN
tung NN
diaoyu VBP
primeminister NN
president NN
china VBD
lien JJ
poultry NN
china NN
flu JJ
primeminister NN
president NN
poultry NN
kalkanov VBD
poultry NN
sar NN
zhuhai NN
primeminister NN
president NN
flu NN
apologise NN
unknown JJ
word NN
translachinese JJ
weng-hui JJ
u JJ
lei NN
j NN
poultry NN
chee-hwa JJ
teng-hui JJ
sar JJ
chee-hwa NN
: :
teng-hui JJ
weng-hui JJ
w NN
weng-hui JJ
clam NN
teng-hui JJ
- :
chee-hwa JJ
teng-hui JJ
lei JJ
chee-hwa JJ
chee-hwa NN
leung NN
zhuhai NN
i NN
lei VBP
j NN
yeltsin SYM
- :
chee-hwa JJ
lam NN
lam NN
j NN
poultry NN
w VBD
teng-hui JJ
0003250 CD
dpp NN
0003206 CD
tang NN
0003202 CD
tung NN
0003040 CD
leung NN
0003033 CD
china NN
0002888 CD
zhuhai NN
0002886 CD
tung NN
teng-hui NN
tang NN
leung NN
leung NN
sar NN
lunar NN
tung NN
1994 CD
for IN
sense NN
disambiguation NN
between IN
multiple JJ
usages NNS
of IN
the DT
same JJ
word NN
. .

in IN
the DT
years NNS
since IN
the DT
appearance NN
of IN
the DT
first JJ
papers NNS
on IN
using VBG
statistical JJ
models NNS
for IN
bilingual JJ
lexicon NN
compilation NN
and CC
machine NN
translation NN
< NNP
ref NN
> NNP
brown IN
et FW
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
brown JJ
et NN
al NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gale NN
and CC
< NNP
ref VBP
> NNP
church NN
, ,
1993 CD
< NN
/ref NNP
> NNP
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
church NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
simard NN
et NN
al NN
, ,
1992 CD
< NN
/ref NNP
> NNP
, ,
large JJ
amount NN
of IN
human JJ
effort NN
and CC
time NN
has VBZ
been VBN
invested VBN
in IN
collecting VBG
parallel JJ
corpora NNS
of IN
translated JJ
texts NN
. .

our PRP$
goal NN
is VBZ
to TO
alleviate VB
this DT
effort NN
and CC
enlarge VB
the DT
scope NN
of IN
corpus JJ
resources NNS
by IN
looking VBG
into IN
monolingual JJ
, ,
comparable JJ
texts NN
. .

word NN
sense NN
disambiguation NN
wsd NN
is VBZ
wellknown VBN
as IN
one CD
of IN
the DT
more RBR
difficult JJ
problems NNS
in IN
the DT
field NN
of IN
natural JJ
language NN
processing NN
, ,
as IN
noted VBN
in IN
< NNP
tref NN
> NNP
gale NN
et NN
al NN
, ,
1992 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
kilgarriff NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
ide NN
and CC
vronis NN
, ,
1998 CD
< NN
/ref NNP
> NNP
, ,
and CC
others NNS
. .

the DT
difficulties NNS
stem VBP
from IN
several JJ
sources NNS
, ,
including VBG
the DT
lack NN
of IN
means NNS
to TO
formalize VB
the DT
properties NNS
of IN
context NN
that WDT
characterize VBP
the DT
use NN
of IN
an DT
ambiguous JJ
word NN
in IN
a DT
given VBN
sense NN
, ,
lack NN
of IN
a DT
standard NN
and CC
possibly RB
exhaustive JJ
sense NN
inventory NN
, ,
and CC
the DT
subjectivity NN
of IN
the DT
human JJ
evaluation NN
of IN
such JJ
algorithms NNS
. .

to TO
address VB
the DT
last JJ
problem NN
, ,
< NNP
tref VBZ
> NNP
gale NN
et NN
al NN
, ,
1992 CD
< NN
/tref NNP
> NNP
argue NN
for IN
upper JJ
and CC
lower JJR
bounds NNS
of IN
precision NN
when WRB
comparing VBG
automatically RB
assigned VBN
sense NN
labels NNS
with IN
those DT
assigned VBN
by IN
human JJ
judges NNS
. .

the DT
difficulties NNS
stem VBP
from IN
several JJ
sources NNS
, ,
including VBG
the DT
lack NN
of IN
means NNS
to TO
formalize VB
the DT
properties NNS
of IN
context NN
that WDT
characterize VBP
the DT
use NN
of IN
an DT
ambiguous JJ
word NN
in IN
a DT
given VBN
sense NN
, ,
lack NN
of IN
a DT
standard NN
and CC
possibly RB
exhaustive JJ
sense NN
inventory NN
, ,
and CC
the DT
subjectivity NN
of IN
the DT
human JJ
evaluation NN
of IN
such JJ
algorithms NNS
. .

to TO
address VB
the DT
last JJ
problem NN
, ,
< NNP
tref VBZ
> NNP
gale NN
et NN
al NN
, ,
1992 CD
< NN
/tref NNP
> NNP
argue NN
for IN
upper JJ
and CC
lower JJR
bounds NNS
of IN
precision NN
when WRB
comparing VBG
automatically RB
assigned VBN
sense NN
labels NNS
with IN
those DT
assigned VBN
by IN
human JJ
judges NNS
. .

the DT
lower JJR
bound NN
should MD
not RB
drop VB
below IN
the DT
baseline NN
usage NN
of IN
the DT
algorithm NN
in IN
which WDT
every DT
word NN
that WDT
is VBZ
disambiguated VBN
is VBZ
assigned VBN
the DT
most RBS
frequent JJ
sense NN
whereas IN
the DT
upper JJ
bound NN
should MD
not RB
be VB
too RB
restrictive JJ
when WRB
the DT
word NN
in IN
question NN
is VBZ
hard JJ
to TO
disambiguate VB
even RB
for IN
human JJ
judges NNS
a DT
measure NN
of IN
this DT
difficulty NN
is VBZ
the DT
computation NN
of IN
the DT
agreement NN
rates NNS
between IN
human JJ
annotators NNS
. .

identification NN
and CC
formalization NN
of IN
the DT
determining VBG
contextual JJ
parameters NNS
for IN
a DT
word NN
used VBN
in IN
a DT
given VBN
sense NN
is VBZ
the DT
focus NN
of IN
wsd JJ
work NN
that WDT
treats VBZ
texts VBP
in IN
a DT
monolingual JJ
settingthat NN
is VBZ
, ,
a DT
setting NN
where WRB
translations NNS
of IN
the DT
texts NN
in IN
other JJ
languages NNS
either CC
do VBP
not RB
exist VB
or CC
are VBP
not RB
considered VBN
. .

the DT
summed JJ
deviation NN
for IN
perfect JJ
performance NN
is VBZ
thus RB
0 CD
. .

researchers NNS
have VBP
begun VBN
to TO
investigate VB
the DT
ability NN
of IN
humans NNS
to TO
agree VB
with IN
one CD
another DT
on IN
segmen108 NN
tation NN
, ,
and CC
to TO
propose VB
methodologies NNS
for IN
quantifying VBG
their PRP$
findings NNS
. .

several JJ
studies NNS
have VBP
used VBN
expert JJ
coders NNS
to TO
locally RB
and CC
globally RB
structure NN
spoken JJ
discourse NN
according VBG
to TO
the DT
model NN
of IN
< NNP
ref NN
> NNP
grosz NN
and CC
sidnet NN
1986 CD
< NNP
/ref NNP
> NNP
, ,
including VBG
< JJ
ref NN
> NNP
grosz NN
and CC
hirschberg NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
hirschberg NN
and CC
grosz NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
nakatani JJ
et NN
al NN
, ,
1995 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
stifleman NN
, ,
1995 CD
< NN
/ref NNP
> NNP
. .

< JJ
ref NN
> NNP
moser NN
and CC
moore NN
1995 CD
< NNP
/ref NNP
> NNP
had VBD
an DT
expert JJ
coder NN
assign NN
segments NNS
and CC
various JJ
segment NN
features NNS
and CC
relations NNS
based VBN
on IN
rst NN
. .

to TO
quantify VB
their PRP$
findings NNS
, ,
these DT
studies NNS
use VBP
notions NNS
of IN
agreement NN
< NNP
tref NN
> NNP
gale NN
et NN
al NN
, ,
1992 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
moset NN
and CC
moore NN
, ,
1995 CD
< NN
/ref NNP
> NNP
and/or VBP
reliability NN
< NNP
ref NN
> NNP
passonneau NN
and CC
litman NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
passonneau NN
and CC
litman NN
, ,
to TO
appear VB
; :
< NNP
ref VBZ
> NNP
isard NN
and CC
carletta NN
, ,
1995 CD
< NN
/ref NNP
> NNP
. .

by IN
using VBG
10-fold JJ
cross NN
validation NN
< NNP
ref NN
> NNP
kohavi NN
and CC
john NN
, ,
1995 CD
< NN
/ref NNP
> NNP
to TO
automatically RB
pick VB
the DT
best JJS
number NN
of IN
nearest JJ
neighbors NNS
to TO
use VB
, ,
the DT
performance NN
of IN
lsxas NN
has VBZ
improved VBN
. .

4 CD
word NN
sense NN
disambiguation NN
in IN
the DT
large JJ
in IN
< JJ
tref NN
> NNP
gale NN
et NN
al NN
, ,
1992 CD
< NN
/tref NNP
> NNP
, ,
it PRP
was VBD
argued VBN
that IN
any DT
wide JJ
coverage NN
wsd JJ
program NN
must MD
be VB
able JJ
to TO
perform VB
significantly RB
better JJR
than IN
the DT
most-frequent-sense JJ
classifier NN
to TO
be VB
worthy JJ
of IN
serious JJ
consideration NN
. .

the DT
performance NN
of IN
lexas NN
as IN
indicated VBN
in IN
table JJ
1 CD
is VBZ
significantly RB
better JJR
than IN
the DT
most-frequent-sense JJ
classifier NN
for IN
the DT
set NN
of IN
191 CD
words NNS
collected VBN
in IN
our PRP$
corpus NN
. .

figure NN
1 CD
and CC
2 CD
also RB
confirm VBP
that IN
all PDT
the DT
training NN
examples NNS
collected VBN
in IN
our PRP$
corpus NN
are VBP
effectively RB
utilized VBN
by IN
lexas NN
to TO
improve VB
its PRP$
wsd NN
performance NN
. .

word NN
sense NN
disambiguation NN
has VBZ
long RB
been VBN
one CD
of IN
the DT
major JJ
concerns NNS
in IN
natural JJ
language NN
processing VBG
area NN
eg NN
, ,
< NNP
ref VBZ
> JJ
bruce NN
et NN
al NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
choueka NN
et NN
al NN
, ,
1985 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gale NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
mcroy NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
1992 CD
, ,
1994 CD
, ,
1995 CD
< NN
/ref NNP
> NNP
, ,
whose WP$
aim NN
is VBZ
to TO
identify VB
the DT
correct JJ
sense NN
of IN
a DT
word NN
in IN
a DT
particular JJ
context NN
, ,
among IN
all DT
of IN
its PRP$
senses NNS
defined VBN
in IN
a DT
dictionary JJ
or CC
a DT
thesaurus NN
. .

undoubtedly RB
, ,
effective JJ
disambiguation NN
techniques NNS
are VBP
of IN
great JJ
use NN
in IN
many JJ
natural JJ
language NN
processing NN
tasks NNS
, ,
eg NN
, ,
machine NN
translation NN
and CC
information NN
retrieving VBG
< NNP
ref NN
> NNP
allen NN
, ,
1995 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
ng NN
and CC
lee NN
, ,
1996 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
resnik NN
, ,
1995 CD
< NN
/ref NNP
> NNP
, ,
etc FW
previous JJ
strategies NNS
for IN
word NN
sense NN
disambiguation NN
mainly RB
fall RB
into IN
two CD
categories NNS
: :
statistics-based JJ
method NN
and CC
exemplar-based JJ
method NN
. .

statistics-based JJ
method NN
often RB
requires VBZ
large-scale JJ
corpora NNS
eg NN
, ,
< NNP
ref VBZ
> NNP
hirst NN
, ,
1987 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
luk NN
, ,
1995 CD
< NN
/ref NNP
> NNP
, ,
sense-tagging NN
or CC
not RB
, ,
monolingual JJ
or CC
aligned VBN
bilingual JJ
, ,
as IN
training NN
data NNS
to TO
specify VB
significant JJ
clues NNS
for IN
each DT
word NN
sense NN
. .

23 CD
heuristic JJ
3 CD
: :
sense NN
ordering VBG
< NNP
tref NN
> NNP
gale NN
et NN
al NN
, ,
1992 CD
< NN
/tref NNP
> NNP
reports VBZ
that IN
word NN
sense NN
disambiguation NN
would MD
be VB
at IN
least JJS
75 CD
correct JJ
if IN
a DT
system NN
assigns VBZ
the DT
most RBS
frequently RB
occurring VBG
sense NN
. .

< JJ
ref NN
> NNP
miller NN
et NN
al NN
, ,
1994 CD
< NN
/ref NNP
> NNP
found VBD
that IN
automatic JJ
i NN
we PRP
use VBP
english JJ
wordnet NN
version NN
16 CD
l NN
143 CD
assignment NN
of IN
polysemous JJ
words NNS
in IN
brown JJ
corpus NN
to TO
senses NNS
in IN
wordnet NN
was VBD
58 CD
correct NN
with IN
a DT
heuristic NN
of IN
most JJS
frequently RB
occurring VBG
sense NN
. .

we PRP
adopt VBP
these DT
previous JJ
results NNS
to TO
develop VB
sense NN
ordering VBG
heuristic JJ
. .

in IN
the DT
area NN
of IN
word NN
sense NN
disambiguation NN
, ,
< NNP
ref VBZ
> NNP
black JJ
1988 CD
< NNP
/ref NNP
> NNP
developed VBD
a DT
model NN
based VBN
on IN
decision NN
trees NNS
using VBG
a DT
corpus NN
of IN
22 CD
million CD
tokens NNS
, ,
after IN
manually RB
sense-tagging JJ
approximately RB
2,000 CD
concordance NN
lines NNS
for IN
five CD
test NN
words NNS
. .

since IN
then RB
, ,
supervised VBD
learning VBG
from IN
sense-tagged JJ
corpora NN
has VBZ
since IN
been VBN
used VBN
by IN
several JJ
researchers NNS
: :
zernik NN
1990 CD
, ,
1991 CD
, ,
< NNP
ref VBZ
> CD
hearst JJ
1991 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
leacock NN
, ,
towell NN
, ,
and CC
voorhees NNS
1993 CD
< NNP
/ref NNP
> NNP
, ,
gale NN
, ,
church NN
, ,
and CC
yarowsky RB
1992d CD
, ,
1993 CD
, ,
< NNP
ref VBZ
> JJ
bruce NN
and CC
wiebe NN
1994 CD
< NNP
/ref NNP
> NNP
, ,
miller NN
et NN
al NN
. .

however RB
, ,
despite IN
the DT
availability NN
of IN
increasingly RB
large JJ
corpora NNS
, ,
two CD
major JJ
obstacles NNS
impede VBP
the DT
acquisition NN
of IN
lexical JJ
knowledge NN
from IN
corpora NN
: :
the DT
difficulties NNS
of IN
manually RB
sense-tagging VBG
a DT
training NN
corpus NN
, ,
and CC
data NNS
sparseness NN
. .

< JJ
ref NN
> NNP
sutcliffe NN
and CC
slater NN
1995 CD
< NNP
/ref NNP
> NNP
replicated VBD
this DT
method NN
on IN
full JJ
text NN
samples NNS
from IN
orwells NNS
animal JJ
farm NN
and CC
found VBD
similar JJ
results NNS
72 CD
correct JJ
sense NN
assignment NN
, ,
compared VBN
with IN
a DT
33 CD
chance NN
baseline NN
, ,
and CC
40 CD
using VBG
lesks NNS
method NN
. .

several JJ
authors NNS
for IN
example NN
, ,
krovetz NN
and CC
croft JJ
1989 CD
, ,
guthrie FW
et FW
al NN
1991 CD
, ,
slator NN
1992 CD
, ,
cowie NN
, ,
guthrie NN
, ,
and CC
guthrie NN
1992 CD
, ,
janssen NN
1992 CD
, ,
braden-harder NN
1993 CD
, ,
liddy NN
and CC
paik NN
1993 CD
have VBP
attempted VBN
to TO
improve VB
results NNS
by IN
using VBG
supplementary JJ
fields NNS
of IN
information NN
in IN
the DT
electronic JJ
version NN
of IN
the DT
longman JJ
dictionary NN
of IN
contemporary JJ
english JJ
ldoce NN
, ,
in IN
particular JJ
, ,
the DT
box NN
codes NNS
and CC
subject JJ
codes NNS
provided VBD
for IN
each DT
sense NN
. .

< JJ
ref NN
> NN
atkins VBZ
1987 CD
< NN
/ref NNP
> NNP
and CC
kilgarriff NN
forthcoming NN
also RB
implicitly RB
adopt VBZ
the DT
view NN
of IN
< NNP
ref NN
> NNP
harris NN
1954 CD
< NNP
/ref NNP
> NNP
, ,
according VBG
to TO
which WDT
each DT
sense NN
distinction NN
is VBZ
reflected VBN
in IN
a DT
distinct JJ
context NN
. .

in IN
this DT
volume NN
, ,
schiitze NN
continues VBZ
in IN
this DT
vein NN
and CC
proposes VBZ
a DT
technique NN
that WDT
avoids VBZ
the DT
problem NN
of IN
sense NN
distinction NN
altogether RB
: :
he PRP
creates VBZ
sense NN
clusters NNS
from IN
a DT
corpus NN
rather RB
than IN
relying VBG
on IN
a DT
pre-established JJ
sense NN
list NN
. .

furthermore RB
, ,
our PRP$
percent JJ
agreement NN
figures NNS
are VBP
comparable JJ
with IN
the DT
results NNS
of IN
other JJ
segmentation NN
studies NNS
discussed VBN
above IN
. .

while IN
studies NNS
of IN
other JJ
tasks NNS
have VBP
achieved VBN
stronger JJR
results NNS
eg VBP
, ,
968 CD
in IN
a DT
word-sense JJ
disambiguation NN
study NN
< NNP
tref NN
> NNP
gale NN
et NN
al NN
, ,
1992 CD
< NN
/tref NNP
> NNP
, ,
the DT
meaning NN
of IN
percent NN
agreement NN
in IN
isolation NN
is VBZ
unclear JJ
. .

for IN
example NN
, ,
a DT
percent NN
agreement NN
figure NN
of IN
less JJR
than IN
90 CD
could MD
still RB
be VB
very RB
meaningful JJ
if IN
the DT
probability NN
of IN
obtaining VBG
such JJ
a DT
figure NN
is VBZ
low JJ
. .

in IN
the DT
next JJ
section NN
we PRP
demonstrate VBP
the DT
significance NN
of IN
our PRP$
findings NNS
. .

agreement NN
among IN
subjects NNS
we PRP
measure VBP
the DT
ability NN
of IN
subjects NNS
to TO
agree VB
with IN
one CD
another DT
, ,
using VBG
a DT
figure NN
called VBN
percent NN
agreement NN
. .

percent NN
agreement NN
, ,
defined VBN
in IN
< NNP
tref NN
> NNP
gale NN
et NN
al NN
, ,
1992 CD
< NN
/tref NNP
> NNP
, ,
is VBZ
the DT
ratio NN
of IN
observed JJ
agreements NNS
with IN
the DT
majority NN
opinion NN
to TO
possible JJ
agreements NNS
with IN
the DT
majority NN
opinion NN
. .

here RB
, ,
agreement NN
among IN
four CD
, ,
five CD
, ,
six CD
, ,
or CC
seven CD
subjects NNS
on IN
whether IN
or CC
not RB
there EX
is VBZ
a DT
segment NN
boundary NN
between IN
two CD
adjacent JJ
prosodic JJ
phrases NNS
constitutes VBZ
a DT
majority NN
opinion NN
. .

reliability NN
the DT
correspondence NN
between IN
discourse NN
segments NNS
and CC
more JJR
abstract JJ
units NNS
of IN
meaning NN
is VBZ
poorly RB
understood JJ
see VB
< JJ
ref VB
> NNP
moore NN
and CC
pollack NN
, ,
1992 CD
< NN
/ref NNP
> NNP
. .

we PRP
present VBP
initial JJ
results NNS
of IN
an DT
investigation NN
of IN
whether IN
naive JJ
subjects NNS
can MD
reliably VB
segment NN
discourse NN
using VBG
speaker JJR
intention NN
as IN
a DT
criterion NN
. .

the DT
default NN
strategy NN
of IN
picking VBG
the DT
most RBS
frequent JJ
sense NN
has VBZ
been VBN
advocgted VBN
as IN
the DT
baseline NN
performance NN
for IN
evaluating VBG
wsd JJ
programs NNS
< VBP
tref JJ
> NNP
gale NN
et NN
al NN
, ,
1992b CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
miller NN
et NN
al NN
, ,
1994 CD
< NN
/ref NNP
> NNP
. .

since IN
wordnet NN
orders NNS
its PRP$
senses NNS
such JJ
that IN
sense NN
1 CD
is VBZ
the DT
most RBS
frequent JJ
sense NN
, ,
one CD
possibility NN
is VBZ
to TO
always RB
pick VB
sense NN
1 CD
as IN
the DT
best JJS
sense NN
assignment NN
. .

this DT
is VBZ
in IN
spite NN
of IN
the DT
conditional JJ
independence NN
assumption NN
made VBN
by IN
the DT
naive-bayes JJ
algorithm NN
, ,
which WDT
may MD
be VB
unjustified VBN
in IN
the DT
domains NNS
tested VBN
. .

gale NN
, ,
church NN
and CC
yarowsky JJ
< NNP
tref NN
> NNP
gale NN
et NN
al NN
, ,
1992a CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gale NN
et NN
al NN
, ,
1995 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
, ,
1992 CD
< NN
/ref NNP
> NNP
have VBP
also RB
successfully RB
used VBD
the DT
naive-bayes JJ
algorithm NN
and CC
several JJ
extensions NNS
and CC
variations NNS
for IN
word NN
sense NN
disambiguation NN
. .

on IN
the DT
other JJ
hand NN
, ,
our PRP$
past JJ
work NN
on IN
wsd JJ
< NNP
ref NN
> NNP
ng NN
and CC
lee NN
, ,
1996 CD
< NN
/ref NNP
> NNP
used VBD
an DT
exemplar-based JJ
or CC
nearest JJS
neighbor NN
learning VBG
approach NN
. .

much JJ
recent JJ
research NN
on IN
word NN
sense NN
disambiguation NN
wsd NN
has VBZ
adopted VBN
a DT
corpus-based JJ
, ,
learning JJ
approach NN
. .

many JJ
different JJ
learning VBG
approaches NNS
have VBP
been VBN
used VBN
, ,
including VBG
neural JJ
networks NNS
< VBP
ref JJ
> NNP
leacock NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
< NNP
/ref NNP
> NNP
, ,
probabilistic JJ
algorithms NN
< NNP
ref NN
> NN
bruce NN
and CC
wiebe NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
gale NN
et NN
al NN
, ,
1992a CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gale NN
et NN
al NN
, ,
1995 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
leacock NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
, ,
1992 CD
< NN
/ref NNP
> NNP
, ,
decision NN
lists NNS
< VBP
ref JJ
> NNP
yarowsky NN
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
exemplar-based JJ
learning NN
algorithms NN
< NNP
ref NN
> NNP
cardie NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
ng NN
and CC
lee NN
, ,
1996 CD
< NN
/ref NNP
> NNP
, ,
etc FW
in IN
particular JJ
, ,
< JJ
ref NN
> NNP
mooney NN
1996 CD
< NNP
/ref NNP
> NNP
evaluated VBD
seven CD
state-of-the-art JJ
machine NN
learning VBG
algorithms NNS
on IN
a DT
common JJ
data NN
set NN
for IN
disambiguating VBG
six CD
senses NNS
of IN
the DT
word NN
line NN
. .

his PRP$
results NNS
indicate VBP
that IN
the DT
simple JJ
naive-bayes JJ
algorithm NN
gives VBZ
the DT
highest JJS
accuracy NN
on IN
the DT
line NN
corpus NN
tested VBD
. .

table JJ
5 CD
: :
some DT
chinese JJ
unknown JJ
word NN
translation NN
output NN
score VBD
0008421 CD
0007895 CD
0007669 CD
0007588 CD
0007283 CD
0006812 CD
0006430 CD
0006218 CD
0005921 CD
0005527 CD
0005335 CD
0005335 CD
0005221 CD
0004731 CD
0004470 CD
0004275 CD
0003878 CD
0003859 CD
0003859 CD
0003784 CD
0003686 CD
0003550 CD
0003519 CD
0003481 CD
0003407 CD
0003407 CD
0oo3338 CD
0003324 CD
0003250 CD
0003206 CD
0003202 CD
0003040 CD
0003033 CD
0002888 CD
0002886 CD
english JJ
chinese JJ
teng-hui JJ
teng-hui JJ
sar NN
, ,
sar JJ
flu NN
n JJ
m NN
, ,
lei JJ
lei NN
poultry NN
j NN
poultry NN
sar VBD
chee-hwa JJ
hijack NN
teng-hui JJ
poultry NN
sar NN
, ,
ng JJ
chee-hw JJ
diaoyu NN
teng-hui JJ
primeminister NN
teng-hui JJ
president NN
teng-hui JJ
china NN
lava JJ
lien JJ
teng-hui JJ
poultry NN
chee-hwa JJ
china NN
teng-hui JJ
flu NN
lei NN
privaeminister NN
-i NNP
chee-hwa JJ
president NN
1 CD
; :
chee-hwa JJ
poultry NN
leung NN
kalkanov NN
i NN
zhuhai VBP
poultry NN
i NN
lei VBP
sar NN
1 CD
j NN
l NN
yeltsin NN
zhuhai NNP
-1 NNP
l VBD
chee-hwa JJ
primeminister NN
lain NN
president NN
lava VBZ
flu JJ
poultry NN
apologise VB
teng-hui JJ
dee NN
teng-hui JJ
tang NN
j NN
tang NN
islng NN
leung NN
leung NN
: :
leung JJ
china NN
tn NN
sar NN
zhuhai NN
lunar NN
ttulg NN
tung NN
1994 CD
for IN
sense NN
disambiguation NN
between IN
multiple JJ
usages NNS
of IN
the DT
same JJ
word NN
. .

in IN
the DT
years NNS
since IN
the DT
appearance NN
of IN
the DT
first JJ
papers NNS
on IN
using VBG
statistical JJ
models NNS
for IN
bilingual JJ
lexicon NN
compilation NN
and CC
machine NN
translation NN
< NNP
ref NN
> NNP
brown IN
et FW
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
brown JJ
et NN
al NN
, ,
1991 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gale NN
and CC
< NNP
ref VBP
> NNP
church NN
, ,
1993 CD
< NN
/ref NNP
> NNP
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
church NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
simard NN
et NN
al NN
, ,
1992 CD
< NN
/ref NNP
> NNP
, ,
large JJ
amount NN
of IN
human JJ
effort NN
and CC
time NN
has VBZ
been VBN
invested VBN
in IN
collecting VBG
parallel JJ
corpora NNS
of IN
translated JJ
texts NN
. .

our PRP$
goal NN
is VBZ
to TO
alleviate VB
this DT
effort NN
and CC
enlarge VB
the DT
scope NN
of IN
corpus JJ
resources NNS
by IN
looking VBG
into IN
monolingual JJ
, ,
comparable JJ
texts NN
. .

the DT
paradise NN
model NN
posits NNS
that IN
performance NN
can MD
be VB
correlated VBN
with IN
a DT
meaningful JJ
external JJ
criterion NN
such JJ
as IN
usability NN
, ,
and CC
thus RB
that IN
the DT
overall JJ
goal NN
of IN
a DT
spoken JJ
dialogue NN
agent NN
is VBZ
to TO
maximize VB
an DT
objective JJ
related VBN
to TO
usability NN
. .

user JJ
satisfaction NN
ratings NNS
< VBP
ref JJ
> NNP
kamm NN
, ,
1995 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
shriberg NN
, ,
wade NN
, ,
and CC
price NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
polifroni NN
et NN
al NN
, ,
1992 CD
< NN
/ref NNP
> NNP
have VBP
been VBN
frequently RB
used VBN
in IN
the DT
literature NN
as IN
an DT
external JJ
indicator NN
of IN
the DT
usability NN
of IN
a DT
dialogue NN
agent NN
. .

the DT
model NN
further JJ
posits NNS
that WDT
two CD
types NNS
of IN
factors NNS
are VBP
potential JJ
relevant JJ
contributors NNS
to TO
user VB
satisfaction NN
namely RB
task JJ
success NN
and CC
dialogue NN
costs NNS
, ,
and CC
that IN
two CD
types NNS
of IN
factors NNS
are VBP
potential JJ
relevant JJ
contributors NNS
to TO
costs NNS
< NNP
ref VBP
> NNP
walker NN
, ,
1996 CD
< NN
/ref NNP
> NNP
. .

in IN
addition NN
to TO
the DT
use NN
of IN
decision NN
theory NN
to TO
create VB
this DT
objective JJ
structure NN
, ,
other JJ
novel JJ
aspects NNS
of IN
paradise NN
include VBP
the DT
use NN
of IN
the DT
kappa NN
coefficient NN
< NNP
ref NN
> NNP
carletta NN
, ,
1996 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
siegel NN
and CC
castellan NN
, ,
1988 CD
< NN
/ref NNP
> NNP
to TO
operationalize VB
task NN
success NN
, ,
and CC
the DT
use NN
of IN
linear JJ
regression NN
to TO
quantify VB
the DT
relative JJ
contribution NN
of IN
the DT
success NN
and CC
cost NN
factors NNS
to TO
user VB
satisfaction NN
. .

this DT
approach NN
has VBZ
many JJ
widely RB
acknowledged VBD
limitations NNS
< NNP
ref NN
> NNP
hirschman NN
and CC
pao NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
danieli JJ
et NN
al NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
bates NNS
and CC
ayuso NN
, ,
1993 CD
< NN
/ref NNP
> NNP
, ,
eg RB
, ,
although IN
there EX
may MD
be VB
many JJ
potential JJ
dialogue NN
strategies NNS
for IN
carrying VBG
out RP
a DT
task NN
, ,
the DT
key NN
is VBZ
tied VBN
to TO
one CD
particular JJ
dialogue NN
strategy NN
. .

in IN
contrast NN
, ,
agents NNS
using VBG
different JJ
dialogue NN
strategies NNS
can MD
be VB
compared VBN
with IN
measures NNS
such JJ
as IN
inappropriate JJ
utterance NN
ratio NN
, ,
turn VBP
correction NN
ratio NN
, ,
concept NN
accuracy NN
, ,
implicit JJ
recovery NN
and CC
transaction NN
success NN
danieli NN
lwe NN
use IN
the DT
term NN
agent NN
to TO
emphasize VB
the DT
fact NN
that IN
we PRP
are VBP
evaluating VBG
a DT
speaking NN
entity NN
that WDT
may MD
have VB
a DT
personality NN
. .

readers NNS
who WP
wish VBP
to TO
may MD
substitute VB
the DT
word NN
system NN
wherever WRB
agent NN
is VBZ
used VBN
. .

the DT
problems NNS
arise VBP
because IN
most JJS
sense NN
distinctions NNS
are VBP
not RB
as RB
clear JJ
as IN
the DT
distinction NN
between IN
river NN
bank NN
and CC
money NN
bnk NN
, ,
so IN
it PRP
is VBZ
not RB
always RB
straightforward VB
for IN
a DT
person NN
to TO
say VB
what WP
the DT
correct JJ
answer NN
is VBZ
thus RB
we PRP
do VBP
not RB
always RB
know VBP
what WP
it PRP
would MD
mean VB
to TO
say VB
that IN
a DT
computer NN
program NN
got VBD
the DT
right JJ
answer NN
. .

if IN
people NNS
can MD
only RB
agree VB
on IN
the DT
correct JJ
answer NN
x NN
of IN
the DT
time NN
, ,
a DT
claim NN
that IN
a DT
program NN
achieves VBZ
more JJR
than IN
x JJR
accuracy NN
is VBZ
hard JJ
to TO
interpret VB
, ,
and CC
x NNP
is VBZ
the DT
upper JJ
bound NN
for IN
what WP
the DT
program NN
can MD
meaningfully RB
achieve VB
. .

although IN
this DT
methodology NN
could MD
be VB
valid JJ
for IN
certain JJ
nlp JJ
problems NNS
, ,
such JJ
as IN
english JJ
part-of-speech NN
tagging NN
, ,
we PRP
think VBP
that IN
there EX
exists VBZ
reasonable JJ
evidence NN
to TO
say VB
that IN
, ,
in IN
wsd NN
, ,
accuracy NN
results NNS
can MD
not RB
be VB
simply RB
extrapolated VBN
to TO
other JJ
domains NNS
contrary JJ
to TO
the DT
opinion NN
of IN
other JJ
authors NNS
< VBP
ref JJ
> NNP
ng NN
, ,
1997b CD
< NN
/ref NN
> NN
: :
on IN
the DT
asupervised JJ
approaches NNS
, ,
also RB
known VBN
as IN
data-driven JJ
or CC
corpus-dmven JJ
, ,
are VBP
those DT
that IN
learn VBP
from IN
a DT
previously RB
semantically RB
annotated VBN
corpus NN
. .

oi1 IN
the DT
other JJ
hand NN
, ,
it PRP
does VBZ
not RB
seem VB
reasonable JJ
to TO
think VB
that IN
the DT
training NN
material NN
is VBZ
large JJ
and CC
representative JJ
enough RB
to TO
cover VB
all DT
potential JJ
types NNS
of IN
examples NNS
. .

to TO
date NN
, ,
a DT
thorough JJ
study NN
of IN
the DT
domain NN
dependence NN
of IN
wsd NN
-- :
in IN
the DT
style NN
of IN
other JJ
studies NNS
devoted VBN
to TO
parsing VBG
< JJ
ref NN
> NNP
sekine NN
, ,
1997 CD
< NN
/ref NNP
> NNP
-has NNP
not RB
been VBN
carried VBN
out RP
. .

< JJ
ref NN
> NNP
ng NN
, ,
1997b CD
< NN
/ref NNP
> NNP
estimates VBZ
that IN
the DT
manual JJ
annotation NN
effort NN
necessary JJ
to TO
build VB
a DT
broad JJ
coverage NN
semantically RB
annotated VBD
english JJ
corpus NN
is VBZ
about IN
16 CD
personyears NNS
. .

word NN
sense NN
disambiguation NN
is VBZ
a DT
potentially RB
crucial JJ
task NN
in IN
many JJ
nlp JJ
applications NNS
, ,
such JJ
as IN
machine NN
translation NN
brown NN
, ,
della NN
pietra NN
, ,
and CC
< NNP
ref VBP
> NNP
della NN
pietra NN
1991 CD
< NNP
/ref NNP
> NNP
, ,
parsing VBG
< JJ
ref NN
> NNP
lytinen NN
1986 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
nagao JJ
1994 CD
< NNP
/ref NNP
> NNP
and CC
text JJ
retrieval NN
< NNP
ref NN
> NNP
krovets NNS
and CC
croft JJ
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
voorhees NNS
1993 CD
< NNP
/ref NNP
> NNP
. .

various JJ
corpus-based JJ
approaches NNS
to TO
word NN
sense NN
disambiguation NN
have VBP
been VBN
proposed VBN
< JJ
ref NN
> NN
bruce NN
and CC
wiebe NN
1994 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
charniak NN
1993 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan NN
and CC
itai NN
1994 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
fujii NN
et NN
al NN
1996 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
hearst JJ
1991 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
karov NN
and CC
edelman JJ
1996 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
kurohashi NN
and CC
nagao JJ
1994 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
li NN
, ,
szpakowicz NN
, ,
and CC
matwin VB
1995 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
ng NN
and CC
lee NN
1996 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
niwa NN
and CC
nitta JJ
1994 CD
< NNP
/ref NNP
> NNP
; :
schitze JJ
1992 CD
; :
< CC
ref VB
> NNP
uramoto JJ
1994b CD
< JJ
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
1995 CD
< NNP
/ref NNP
> NNP
. .

our PRP$
verb NN
sense NN
disambiguation NN
system NN
is VBZ
based VBN
on IN
such PDT
an DT
approach NN
, ,
that WDT
is VBZ
, ,
an DT
example-based JJ
approach NN
. .

alignment NN
at IN
other JJ
levels NNS
of IN
resolution NN
is VBZ
obviously RB
useful JJ
. .

other JJ
logical JJ
approaches NNS
involve VBP
aligning VBG
parse NN
trees NNS
of IN
a DT
sentence NN
and CC
its PRP$
translation NN
< NNP
ref NN
> NNP
matsumoto NN
, ,
ishimoto NN
, ,
and CC
utsuro JJ
1993 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
meyers NNS
, ,
yangarber NNP
, ,
and CC
grishman JJ
1996 CD
< NNP
/ref NNP
> NNP
, ,
or CC
simultaneously RB
generating VBG
parse NN
trees NNS
and CC
alignment JJ
arrangements NNS
< VBP
ref JJ
> NNP
wu NN
1995 CD
< NNP
/ref NNP
> NNP
. .

that DT
is VBZ
, ,
an DT
assumption NN
of IN
full JJ
statistical JJ
dependence NN
< NNP
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
, ,
rather RB
than IN
the DT
more RBR
common JJ
full JJ
independence NN
, ,
is VBZ
made3 JJ
when WRB
llf JJ
events NNS
el NN
, ,
e2 NN
, ,
, ,
e NN
, ,
are VBP
fully RB
independent JJ
, ,
then RB
the DT
joint JJ
probability NN
pe1 VBP
a DT
a DT
en NN
is VBZ
the DT
product NN
of IN
peipen JJ
, ,
but CC
if IN
they PRP
are VBP
maximally RB
dependent JJ
, ,
it PRP
is VBZ
the DT
minimum NN
of IN
these DT
values NNS
. .

of IN
course NN
, ,
neither DT
assumption NN
is VBZ
any DT
more JJR
than IN
an DT
approximation NN
to TO
the DT
truth NN
; :
but CC
assuming VBG
dependence NN
has VBZ
the DT
advantage NN
that IN
the DT
estimate NN
of IN
the DT
joint JJ
probability NN
depends VBZ
much RB
less JJR
strongly RB
on IN
n NN
, ,
and CC
so RB
estimates NNS
for IN
alternative JJ
joint JJ
events NNS
can MD
be VB
directly RB
compared VBN
, ,
without IN
any DT
possibly RB
tricky JJ
normalization NN
, ,
even RB
if IN
they PRP
are VBP
composed VBN
of IN
different JJ
numbers NNS
of IN
atomic JJ
events NNS
. .

this DT
property NN
is VBZ
desirable JJ
: :
different JJ
sub-paths NNS
through IN
a DT
chart NN
may MD
span VB
different JJ
numbers NNS
of IN
edges NNS
, ,
and CC
one CD
can MD
imagine VB
evaluation NN
criteria NNS
which WDT
are VBP
only RB
defined VBN
for IN
some DT
kinds NNS
of IN
edge NN
, ,
or CC
which WDT
often RB
duplicate VBP
information NN
supplied VBN
by IN
other JJ
criteria NNS
. .

we PRP
improve VBP
the DT
original JJ
decision NN
list NN
by IN
using VBG
written VBN
words NNS
in IN
the DT
default NN
evidence NN
. .

the DT
improved JJ
decision NN
list NN
can MD
raise VB
the DT
f-measure NN
of IN
error NN
detection NN
. .

we PRP
also RB
use VBP
the DT
special JJ
evidence NN
default NN
, ,
frqwl NN
, ,
default NN
is VBZ
defined VBN
as IN
the DT
frequency NN
of IN
wl NN
. .

step5 NN
pick VBZ
the DT
highest JJS
strength NN
estwh NN
, ,
ej VBP
among IN
5as CD
in IN
this DT
paper NN
, ,
the DT
addition NN
of IN
a DT
small JJ
value NN
is VBZ
an DT
easy JJ
and CC
effective JJ
way NN
to TO
avoid VB
the DT
unsatisfactory JJ
case NN
, ,
as IN
shown VBN
in IN
< NNP
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
. .

< JJ
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
, ,
and CC
using VBG
the DT
mxpost1 JJ
part NN
of IN
speech NN
tagger NN
and CC
wordnets NNS
lemmatization NN
, ,
the DT
following JJ
feature NN
set VBN
was VBD
used VBN
: :
bag NN
of IN
word NN
lemmas NN
for IN
the DT
context NN
words NNS
in IN
the DT
preceding NN
, ,
current JJ
and CC
following JJ
sentence NN
; :
unigrams NNS
of IN
lemmas NN
and CC
parts NNS
of IN
speech NN
in IN
a DT
window NN
of IN
/three JJ
words NNS
, ,
where WRB
each DT
position NN
provides VBZ
a DT
distinct JJ
feature NN
; :
and CC
bigrams NNS
of IN
lemmas NN
in IN
the DT
same JJ
window NN
. .

to TO
obtain VB
a DT
multi-class JJ
classifier NN
we PRP
used VBD
a DT
standard JJ
one-vs-all JJ
approach NN
of IN
training VBG
a DT
binary JJ
svm NN
for IN
each DT
possible JJ
sense NN
and CC
then RB
selecting VBG
the DT
highest JJS
scoring NN
sense NN
for IN
a DT
test NN
example NN
. .

it PRP
has VBZ
been VBN
amply RB
demonstrated VBN
that IN
a DT
wide JJ
assortment NN
of IN
machine NN
learning NN
algorithms NN
are VBP
quite RB
effective JJ
at IN
extracting VBG
linguistic JJ
information NN
from IN
manually RB
annotated VBN
corpora NN
. .

among IN
the DT
machine NN
learning VBG
algorithms JJ
studied VBN
, ,
rule NN
based VBN
systems NNS
have VBP
proven VBN
effective JJ
on IN
many JJ
natural JJ
language NN
processing NN
tasks NNS
, ,
including VBG
part-of-speech JJ
tagging NN
< NNP
ref NN
> NNP
brill NN
, ,
1995 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
ramshaw NN
and CC
marcus NN
, ,
1994 CD
< NN
/ref NNP
> NNP
, ,
spelling VBG
correction NN
< NNP
ref NN
> NNP
mangu NN
and CC
brill NN
, ,
1997 CD
< NN
/ref NNP
> NNP
, ,
word-sense JJ
disambiguation NN
< NNP
ref NN
> NNP
gale NN
et NN
al NN
, ,
1992 CD
< NN
/ref NNP
> NNP
, ,
message NN
understanding JJ
< JJ
ref NN
> NNP
day NN
et VBD
al RB
, ,
1997 CD
< NN
/ref NNP
> NNP
, ,
discourse NN
tagging VBG
< NNP
ref NN
> NNP
samuel NN
et NN
al NN
, ,
1998 CD
< NN
/ref NNP
> NNP
, ,
accent JJ
restoration NN
< NNP
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
, ,
prepositional-phrase JJ
attachment NN
< NNP
ref NN
> NNP
brill NN
and CC
resnik NN
, ,
1994 CD
< NN
/ref NNP
> NNP
and CC
base NN
noun JJ
phrase NN
identification NN
ramshaw NN
and CC
marcus NN
, ,
in IN
press NN
; :
< CC
ref VB
> NNP
cardie NN
and CC
pierce NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
veenstra NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
argamon JJ
et NN
al NN
, ,
1998 CD
< NN
/ref NNP
> NNP
. .

many JJ
of IN
these DT
rule NN
based VBN
systems NNS
learn VBP
a DT
short JJ
list NN
of IN
simple JJ
rules NNS
typically RB
on IN
the DT
order NN
of IN
50-300 JJ
which WDT
are VBP
easily RB
understood VBN
by IN
humans NNS
. .

since IN
these DT
rule-based JJ
systems NNS
achieve VBP
good JJ
performance NN
while IN
learning VBG
a DT
small JJ
list NN
of IN
simple JJ
rules NNS
, ,
it PRP
raises VBZ
the DT
question NN
of IN
whether IN
peoand NN
woman NN
. .

in IN
contrast NN
, ,
lexas JJ
uses NNS
supervised VBD
learning VBG
from IN
tagged VBN
sentences NNS
, ,
which WDT
is VBZ
also RB
the DT
approach NN
taken VBN
by IN
most JJS
recent JJ
work NN
on IN
wsd NNS
, ,
including VBG
< JJ
ref NN
> NN
bruce NN
and CC
wiebe NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
miller NN
et NN
al NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
leacock NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
, ,
1992 CD
< NN
/ref NNP
> NNP
. .

in IN
contrast NN
, ,
lexas JJ
uses NNS
supervised VBD
learning VBG
from IN
tagged VBN
sentences NNS
, ,
which WDT
is VBZ
also RB
the DT
approach NN
taken VBN
by IN
most JJS
recent JJ
work NN
on IN
wsd NNS
, ,
including VBG
< JJ
ref NN
> NN
bruce NN
and CC
wiebe NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
miller NN
et NN
al NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
leacock NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
yarowsky NN
, ,
1992 CD
< NN
/ref NNP
> NNP
. .

that DT
local JJ
collocation NN
knowledge NN
provides VBZ
important JJ
clues NNS
to TO
wsd VB
is VBZ
pointed VBN
out RP
in IN
< NNP
ref NN
> NNP
yarowsky NN
, ,
1993 CD
< NN
/ref NNP
> NNP
, ,
although IN
it PRP
was VBD
demonstrated VBN
only RB
on IN
performing VBG
binary JJ
or CC
very RB
coarse JJ
sense NN
disambiguation NN
. .

however RB
, ,
his PRP$
work NN
used VBN
decision NN
list NN
to TO
perform VB
classification NN
, ,
in IN
which WDT
only RB
the DT
single JJ
best RBS
disambiguating VBG
evidence NN
that IN
matched VBD
a DT
target NN
context NN
is VBZ
used VBN
. .

in IN
contrast NN
, ,
we PRP
used VBD
exemplar-based JJ
learning NN
, ,
where WRB
the DT
contributions NNS
of IN
all DT
features NNS
are VBP
summed VBN
up IN
and CC
taken VBN
into IN
account NN
in IN
coming VBG
up RP
with IN
a DT
classification NN
. .

1995 CD
, ,
we PRP
formalize VBP
the DT
problem NN
of IN
deciding VBG
dependency NN
preference NN
of IN
subordinate JJ
clauses NNS
by IN
utilizing VBG
the DT
correlation NN
of IN
scope NN
embedding VBG
preference NN
and CC
dependency NN
preference NN
of IN
japanese JJ
subordinate JJ
clauses NNS
. .

then RB
, ,
as IN
a DT
statistical JJ
learning NN
method NN
, ,
we PRP
employ VBP
the DT
decision NN
list NN
learning VBG
method NN
of IN
< NNP
tref NN
> NNP
yarowsky NN
1994 CD
< NNP
/tref NNP
> NNP
, ,
where WRB
optimal JJ
combination NN
of IN
those DT
features NNS
are VBP
selected VBN
and CC
sorted VBN
in IN
the DT
form NN
of IN
decision NN
rules NNS
, ,
according VBG
to TO
the DT
strength NN
of IN
correlation NN
between IN
those DT
features NNS
and CC
the DT
dependency NN
preference NN
of IN
the DT
two CD
subordinate NN
clauses NNS
. .

we PRP
evaluate VBP
the DT
proposed VBN
method NN
through IN
the DT
experiment NN
on IN
learning VBG
dependency NN
preference NN
of IN
japanese JJ
subordinate JJ
clauses NNS
from IN
the DT
edr NN
bracketed VBD
corpus JJ
section NN
4 CD
. .

roughly RB
speaking NN
, ,
the DT
first JJ
corresponds VBZ
to TO
the DT
case NN
where WRB
clause2 NN
inherently RB
has VBZ
a DT
scope NN
of IN
the DT
same JJ
or CC
a DT
broader JJR
breadth NN
compared VBN
with IN
that DT
of IN
clause1 NN
, ,
while IN
the DT
second JJ
corresponds NNS
to TO
the DT
case NN
where WRB
clause2 NN
inherently RB
has VBZ
a DT
narrower JJR
scope NN
compared VBN
with IN
that DT
of IN
clause17 NN
32 CD
decision NN
list NN
learning VBG
a DT
decision NN
list NN
< NNP
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
is VBZ
a DT
sorted JJ
list NN
of IN
the DT
decision NN
rules NNS
each DT
of IN
which WDT
decides VBZ
the DT
value NN
of IN
a DT
decision NN
d NN
given VBN
some DT
evidence NN
e VBD
each DT
decision NN
rule NN
in IN
a DT
decision NN
list NN
is VBZ
sorted VBN
tour JJ
modeling NN
is VBZ
slightly RB
different JJ
from IN
those DT
of IN
other JJ
standard JJ
approaches NNS
to TO
statistical JJ
dependency NN
analysis NN
< NNP
ref NN
> NN
collins NNS
, ,
1996 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
fujio NN
and CC
matsumoto NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
haruno NN
et NN
al NN
, ,
1998 CD
< NN
/ref NNP
> NNP
which WDT
simply RB
distinguish VB
the DT
two CD
cases NNS
: :
the DT
case NN
where WRB
dependency NN
relation NN
holds VBZ
between IN
the DT
given VBN
two CD
vp JJ
chunks NNS
or CC
clauses NNS
, ,
and CC
the DT
case NN
where WRB
dependency NN
relation NN
does VBZ
not RB
hold VB
. .

this DT
is VBZ
because IN
we PRP
assume VBP
that IN
this DT
case NN
is VBZ
more RBR
loosely RB
related VBN
to TO
the DT
scope NN
embedding VBG
preference NN
of IN
subordinate JJ
clauses NNS
. .

we PRP
formalize VBP
the DT
problem NN
of IN
deciding VBG
scope NN
embedding VBG
preference NN
as IN
a DT
classification NN
problem NN
, ,
in IN
which WDT
various JJ
types NNS
of IN
linguistic JJ
information NN
of IN
each DT
subordinate NN
clause NN
are VBP
encoded VBN
as IN
features NNS
and CC
used VBN
for IN
deciding VBG
which WDT
one CD
of IN
given VBN
two CD
subordinate JJ
clauses NNS
has VBZ
a DT
broader JJR
scope NN
than IN
the DT
other JJ
. .

as IN
a DT
statistical JJ
learning NN
method NN
, ,
we PRP
employ VBP
the DT
decision NN
list NN
learning VBG
method NN
of IN
< NNP
tref NN
> NNP
yarowsky NN
1994 CD
< NNP
/tref NNP
> NNP
. .

113 CD
table JJ
2 CD
: :
features NNS
of IN
japanese JJ
subordinate JJ
clauses NNS
feature VBP
type NN
of IN
feat NN
each DT
binary JJ
feature NN
punctuation NN
2 CD
with-comma NN
, ,
without-comma JJ
grammatical JJ
adverb NN
, ,
adverbial-noun JJ
, ,
formal-noun JJ
, ,
temporal-noun JJ
, ,
some DT
features NNS
have VBP
distinction NN
17 CD
quoting-particle NN
, ,
copula NN
, ,
predicate-conjunctive-particle NN
, ,
of IN
chunk-final/middle JJ
topic-marking-particle NN
, ,
sentence-final-particle JJ
12 CD
conjugation NN
form NN
of IN
chunk-final JJ
conjugative JJ
word NN
lexical JJ
lexicalized VBD
forms NNS
of IN
grammatical JJ
features NNS
, ,
with IN
more JJR
than IN
9 CD
occurrences NNS
in IN
edr JJ
corpus NN
235 CD
stem NN
, ,
base NN
, ,
mizen NN
, ,
renyou NN
, ,
rental JJ
, ,
conditional JJ
, ,
imperative JJ
, ,
ta NN
, ,
tari NN
, ,
re NN
, ,
conjecture NN
, ,
volitional JJ
adverb NN
eg NN
, ,
ippou-de JJ
, ,
irai JJ
, ,
adverbial-noun JJ
eg NN
, ,
tame NN
, ,
baai JJ
topic-marking-particle NN
eg NN
, ,
ha NN
, ,
mo NN
, ,
quoting-particle NN
to TO
, ,
predicate-conjunctive-particle JJ
eg NN
, ,
ga NN
, ,
kara NN
, ,
temporal-noun JJ
eg NN
, ,
ima NN
, ,
shunkan JJ
, ,
formal-noun JJ
eg NN
, ,
koto NN
, ,
copula NN
dearu NN
, ,
sentence-final-particle JJ
eg NN
, ,
ka NN
, ,
yo RB
31 CD
the DT
task NN
definition NN
considering VBG
the DT
dependency NN
preference NN
of IN
japanese JJ
subordinate JJ
clauses NNS
described VBN
in IN
section NN
24 CD
, ,
the DT
following VBG
gives VBZ
the DT
definition NN
of IN
our PRP$
task NN
of IN
deciding VBG
the DT
dependency NN
of IN
japanese JJ
subordinate JJ
clauses NNS
. .

for IN
each DT
piece NN
of IN
evidence NN
, ,
calculate VB
the DT
likelihood NN
ratio NN
of IN
the DT
conditional JJ
probability NN
of IN
a DT
decision NN
d NN
xl NNP
given VBN
the DT
presence NN
of IN
that DT
piece NN
of IN
evidence NN
to TO
the DT
conditional JJ
probability NN
of IN
the DT
rest NN
of IN
the DT
decisions NNS
d VBP
- :
, ,
xl NN
: :
pdxl NN
i NN
ei VBP
lg2 NN
pdxl NN
ei NN
then RB
, ,
a DT
decision NN
list NN
is VBZ
constructed VBN
with IN
pieces NNS
of IN
evidence NN
sorted VBN
in IN
descending VBG
order NN
with IN
respect NN
to TO
their PRP$
likelihood NN
ratios NNS
, ,
s VBD
2 CD
. .

the DT
provider NN
is VBZ
ixa JJ
and CC
they PRP
also RB
applied VBD
smoothing VBG
to TO
generate VB
more JJR
robust JJ
decision NN
lists NNS
. .

while IN
the DT
basic JJ
idea NN
of IN
our PRP$
model NN
is VBZ
similar JJ
to TO
trigger NN
models NNS
, ,
they PRP
handle VBP
co-occurrences NNS
of IN
word NN
pairs NNS
independently RB
and CC
do VB
not RB
use VB
a DT
representation NN
of IN
the DT
whole JJ
context NN
. .

this DT
omission NN
is VBZ
also RB
done VBN
in IN
applications NNS
such JJ
as IN
word NN
sense NN
dismnbiguation NN
yarowsky NN
: :
1994 CD
; :
fung CC
et VB
al NN
, ,
1999 CD
. .

the DT
decision-list JJ
algorithm NN
used VBN
here RB
< JJ
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
identifies VBZ
other JJ
collocations NNS
that WDT
reliably VBP
partition VBP
the DT
seed NN
training NN
data NNS
, ,
ranked VBN
by IN
the DT
purity NN
of IN
the DT
distribution NN
. .

9 CD
initial JJ
decision NN
list NN
for IN
plant NN
abbreviated VBN
logl RB
810 CD
758 CD
739 CD
720 CD
627 CD
470 CD
439 CD
430 CD
410 CD
352 CD
348 CD
345 CD
collocation NN
sense NN
plant NN
life NN
a DT
manufacturing NN
plant NN
b NN
life NN
within IN
4-2-10 JJ
words NNS
a DT
manufacturing NN
in IN
4-2-10 JJ
words NNS
b NN
animal NN
within IN
-i-2-10 JJ
words NNS
a DT
equipment NN
within IN
-1-2-10 NNP
words NNS
, ,
b NN
employee NN
within IN
4-2-10 JJ
words NNS
b NN
assembly NN
plant NN
b NN
plant NN
closure NN
b NN
plant NN
species VBZ
a DT
automate NN
within IN
4-2-10 JJ
words NNS
: :
: :
b NN
microscopic NN
plant NN
a DT
9note CD
that IN
a DT
given VBN
collocate NN
such JJ
as IN
life NN
may MD
appear VB
multiple JJ
times NNS
in IN
the DT
list NN
in IN
different JJ
collocations1 JJ
relationships NNS
, ,
including VBG
left-adjacent JJ
, ,
right-adjacent JJ
, ,
cooccurrence NN
at IN
other JJ
positions NNS
in IN
a DT
k-word NN
window NN
and CC
various JJ
other JJ
syntactic JJ
associations NNS
. .

our PRP$
probabilistic JJ
decision NN
lists NNS
can MD
thus RB
be VB
thought VBN
of IN
as IN
a DT
competitive JJ
way NN
to TO
probabilize VB
tbls NNS
, ,
with IN
the DT
advantage NN
of IN
preserving VBG
the DT
list-structure NN
and CC
simplicity NN
of IN
tbl NN
, ,
and CC
the DT
possible JJ
disadvantage NN
of IN
losing VBG
the DT
dependency NN
on IN
the DT
current JJ
state NN
. .

his PRP$
technique NN
involves VBZ
estimating VBG
both DT
a DT
probability NN
based VBN
on IN
the DT
global JJ
probability NN
distribution NN
for IN
a DT
question NN
, ,
and CC
a DT
local JJ
probability NN
, ,
given VBN
that IN
no DT
questions NNS
higher RBR
in IN
the DT
list NN
were VBD
true JJ
, ,
and CC
then RB
interpolating VBG
between IN
the DT
two CD
probabilities NNS
. .

lemmatization NN
allows VBZ
for IN
more JJR
compact JJ
and CC
generalizable JJ
data NNS
by IN
clustering VBG
all DT
inflected JJ
forms NNS
of IN
an DT
ambiguous JJ
word NN
together RB
, ,
an DT
effect NN
already RB
commented VBN
on IN
by IN
< NNP
tref NN
> NNP
yarowsky NN
1994 CD
< NNP
/tref NNP
> NNP
. .

the DT
more JJR
inflection NN
in IN
a DT
language NN
, ,
the DT
more JJR
lemmatization NN
will MD
help VB
to TO
compress VB
and CC
generalize VB
the DT
data NN
. .

we PRP
make VBP
use NN
of IN
the DT
advantage NN
of IN
clustering VBG
all DT
instances NNS
of IN
eg JJ
one CD
verb NN
in IN
a DT
single JJ
classifier NN
instead RB
of IN
several JJ
classifiers NNS
one CD
for IN
each DT
inflected JJ
form NN
found VBN
in IN
the DT
data NN
. .

4 CD
adaptation NN
of IN
decision NN
lists NNS
to TO
n-way JJ
ambiguities NNS
decision NN
lists NNS
as IN
defined VBN
in IN
< NNP
ref NN
> NNP
yarowsky NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
1994 CD
are VBP
simple JJ
means NNS
to TO
solve VB
ambiguity NN
problems NNS
. .

they PRP
have VBP
been VBN
successfully RB
applied VBN
to TO
accent JJ
restoration NN
, ,
word NN
sense NN
disambiguation NN
209 CD
and CC
homograph JJ
disambiguation NN
< NNP
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
; :
1995 CD
; :
1996 CD
. .

in IN
order NN
to TO
build VB
decision NN
lists VBZ
the DT
training NN
examples NNS
are VBP
processed VBN
to TO
extract VB
the DT
features NNS
each DT
feature NN
corresponds VBZ
to TO
a DT
kind NN
of IN
collocation NN
, ,
which WDT
are VBP
weighted VBN
with IN
a DT
log-likelihood JJ
measure NN
. .

4 CD
adaptation NN
of IN
decision NN
lists NNS
to TO
n-way JJ
ambiguities NNS
decision NN
lists NNS
as IN
defined VBN
in IN
< NNP
ref NN
> NNP
yarowsky NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
1994 CD
are VBP
simple JJ
means NNS
to TO
solve VB
ambiguity NN
problems NNS
. .

they PRP
have VBP
been VBN
successfully RB
applied VBN
to TO
accent JJ
restoration NN
, ,
word NN
sense NN
disambiguation NN
209 CD
and CC
homograph JJ
disambiguation NN
< NNP
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
; :
1995 CD
; :
1996 CD
. .

in IN
order NN
to TO
build VB
decision NN
lists VBZ
the DT
training NN
examples NNS
are VBP
processed VBN
to TO
extract VB
the DT
features NNS
each DT
feature NN
corresponds VBZ
to TO
a DT
kind NN
of IN
collocation NN
, ,
which WDT
are VBP
weighted VBN
with IN
a DT
log-likelihood JJ
measure NN
. .

the DT
list NN
of IN
all DT
features NNS
ordered VBN
by IN
log-likelihood NN
values NNS
constitutes VBZ
the DT
decision NN
list NN
. .

the DT
context NN
within IN
which WDT
the DT
ambiguous JJ
word NN
occurs VBZ
is VBZ
typically RB
represented VBN
by IN
a DT
set NN
of IN
linguistically RB
motivated VBN
features NNS
from IN
which WDT
a DT
learning NN
algorithm NN
induces VBZ
a DT
representative JJ
model NN
that WDT
performs VBZ
the DT
disambiguation NN
. .

a DT
variety NN
of IN
classifiers NNS
have VBP
been VBN
employed VBN
for IN
this DT
task NN
see VB
mooney JJ
1996 CD
and CC
ide VB
and CC
veronis VB
1998 CD
for IN
overviews NNS
, ,
the DT
most RBS
popular JJ
being VBG
decision NN
lists NNS
< VBP
ref JJ
> NNP
yarowsky NN
1994 CD
, ,
1995 CD
< NN
/ref NNP
> NNP
and CC
naive JJ
bayesian JJ
classifiers NNS
< VBP
ref JJ
> NNP
pedersen NN
2000 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> CD
ng JJ
1997 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
pedersen NN
and CC
bruce NN
1998 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
mooney NN
1996 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
cucerzan NN
and CC
yarowsky JJ
2002 CD
< NNP
/ref NNP
> NNP
. .

we PRP
employed VBD
a DT
naive JJ
bayesian NN
classifier NN
< NNP
ref NN
> NNP
duda NN
and CC
hart NN
1973 CD
< NNP
/ref NNP
> NNP
for IN
our PRP$
experiments NNS
, ,
as IN
it PRP
is VBZ
a DT
very RB
convenient JJ
framework NN
for IN
incorporating VBG
prior JJ
knowledge NN
and CC
studying VBG
its PRP$
influence NN
on IN
the DT
classification NN
task NN
. .

in IN
section NN
51 CD
we PRP
describe VBP
a DT
basic JJ
naive JJ
bayesian NN
classifier NN
and CC
show VB
how WRB
it PRP
can MD
be VB
extended VBN
with IN
informative JJ
priors NNS
. .

despite IN
their PRP$
simplicity NN
, ,
decision NN
lists NNS
dlist VBP
for IN
short JJ
as IN
defined VBN
in IN
< NNP
tref NN
> NNP
yarowsky NN
1994 CD
< NNP
/tref NNP
> NNP
have VBP
been VBN
shown VBN
to TO
be VB
very RB
effective JJ
for IN
wsd NN
< NNP
ref NN
> NNP
kilgarriff NN
palmer NN
, ,
2000 CD
< NN
/ref NNP
> NNP
. .

machine NN
learning VBG
methods NNS
have VBP
become VBN
the DT
most RBS
popular JJ
technique NN
in IN
a DT
variety NN
of IN
classification NN
problems NNS
of IN
these DT
sort NN
, ,
and CC
have VBP
shown VBN
significant JJ
success NN
. .

based VBN
methods NNS
< NNP
ref NN
> NNP
zavrel NNP
et FW
al NN
, ,
1997 CD
< NN
/ref NNP
> NNP
, ,
linear JJ
classifiers NNS
< VBP
ref JJ
> NNP
roth NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
roth NN
, ,
1999 CD
< NN
/ref NNP
> NNP
and CC
transformationbased VBD
learning VBG
< NNP
ref NN
> NNP
brill NN
, ,
1995 CD
< NN
/ref NNP
> NNP
. .

in IN
many JJ
of IN
these DT
classification NN
problems NNS
a DT
significant JJ
source NN
of IN
difficulty NN
is VBZ
the DT
fact NN
that IN
the DT
number NN
of IN
candidates NNS
is VBZ
very RB
large JJ
all DT
words NNS
in IN
words NNS
selection NN
problems NNS
, ,
all DT
possible JJ
tags NNS
in IN
tagging VBG
problems NNS
etc FW
since IN
general JJ
purpose NN
learning VBG
algorithms NNS
do VBP
not RB
handle VB
these DT
multi-class JJ
classification NN
problems NNS
well RB
see VB
below IN
, ,
most JJS
of IN
the DT
studies NNS
do VBP
not RB
address VB
the DT
whole JJ
problem NN
; :
rather RB
, ,
a DT
small JJ
set NN
of IN
candidates NNS
typically RB
two CD
is VBZ
first RB
selected VBN
, ,
and CC
the DT
classifier NN
is VBZ
trained VBN
to TO
choose VB
among IN
these DT
. .

obviously RB
, ,
how WRB
to TO
measure VB
the DT
confidence NN
of IN
features NNS
is VBZ
a DT
very RB
important JJ
issue NN
for IN
the DT
decision NN
list NN
. .

provided VBD
that IN
1 CD
0ps CD
f NN
> NN
for IN
all DT
i NN
: :
max NN
i NN
i VBP
confidence NN
f NN
p NN
s VBD
f RB
1 CD
this DT
value NN
measures VBZ
the DT
extent NN
to TO
which WDT
the DT
context NN
is VBZ
unambiguously RB
correlated VBN
with IN
one CD
particular JJ
slot NN
i NN
s VBD
24 CD
slot-value JJ
merging NN
and CC
semantic JJ
reclassification NN
the DT
slot-value JJ
merger NN
is VBZ
to TO
combine VB
the DT
slots NNS
assigned VBD
to TO
the DT
concepts NNS
in IN
an DT
input NN
sentence NN
. .

in IN
particular JJ
, ,
they PRP
may MD
involve VB
performing VBG
speech JJ
recognition NN
on IN
speech NN
data NNS
, ,
parsing VBG
on IN
text NN
data NNS
, ,
application NN
of IN
hand-coded JJ
rules NNS
to TO
the DT
results NNS
of IN
parsing NN
, ,
or CC
some DT
combination NN
of IN
these DT
. .

note NN
that IN
this DT
is VBZ
in IN
sharp JJ
contrast NN
with IN
the DT
naive JJ
bayes NNS
classifier VBP
< JJ
ref NN
> NNP
duda NN
et NN
al NN
, ,
2000 CD
< NN
/ref NNP
> NNP
, ,
which WDT
assumes VBZ
complete JJ
independence NN
. .

of IN
course NN
, ,
neither DT
assumption NN
can MD
be VB
true JJ
in IN
practice NN
; :
however RB
, ,
as IN
argued VBN
in IN
< NNP
ref NN
> NNP
carter NN
, ,
2000 CD
< NN
/ref NNP
> NNP
, ,
there EX
are VBP
good JJ
reasons NNS
for IN
preferring VBG
the DT
dependence NN
alternative NN
as IN
the DT
better JJR
option NN
in IN
a DT
situation NN
where WRB
there EX
are VBP
many JJ
features NNS
extracted VBN
in IN
ways NNS
that WDT
are VBP
likely JJ
to TO
overlap VB
. .

there EX
is VBZ
typically RB
no DT
corpus NN
data NNS
available JJ
at IN
the DT
start NN
of IN
a DT
project NN
, ,
but CC
considerable JJ
amounts NNS
at IN
the DT
end NN
: :
the DT
intention NN
behind IN
alterf NN
is VBZ
to TO
allow VB
us PRP
to TO
shift VB
smoothly RB
from IN
an DT
initial JJ
version NN
of IN
the DT
system NN
which WDT
is VBZ
entirely RB
rule-based JJ
, ,
to TO
a DT
final JJ
version NN
which WDT
is VBZ
largely RB
data-driven JJ
. .

for IN
example NN
, ,
in IN
the DT
procedure NN
assistant NN
domain NN
we PRP
represent VBP
the DT
utterances NNS
please NN
speak VB
up RP
show VB
me PRP
the DT
sample JJ
syringe NN
set VBD
an DT
alarm NN
for IN
five CD
minutes NNS
from IN
now RB
no DT
i NN
said VBD
go VBP
to TO
the DT
next JJ
step NN
respectively RB
as IN
fincrease NN
volumeg NN
fshow NN
, ,
sample JJ
syringeg NN
fset NN
alarm NN
, ,
5 CD
, ,
minutesg JJR
fcorrection NN
, ,
next JJ
stepg NN
where WRB
increase NN
volume NN
, ,
show NN
, ,
sample JJ
syringe NN
, ,
set VBN
alarm NN
, ,
5 CD
, ,
minutes NNS
, ,
correction NN
and CC
next JJ
step NN
are VBP
semantic JJ
atoms NNS
. .

left VBN
context JJ
ml2mii NN
ll NN
, ,
ight NN
named VBN
entity NN
context NN
m NN
mm NN
< VBD
3 CD
1 CD
2 CD
current JJ
position NN
4 CD
supervised VBD
learning NN
for IN
japanese JJ
named VBN
entity NN
recognition NN
this DT
section NN
describes VBZ
how WRB
to TO
apply VB
tile JJ
decision NN
list NN
learning VBG
method NN
to TO
chunking/tagging VBG
named VBN
entities NNS
. .

41 CD
decision NN
list NN
learning VBG
a DT
decision NN
list NN
< NNP
ref NN
> NNP
rivest NN
, ,
1987 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
is VBZ
a DT
sorted JJ
list NN
of IN
decision NN
rules NNS
, ,
each DT
of IN
which WDT
decides VBZ
the DT
wflue NN
of IN
a DT
decision NN
d NN
given VBN
some DT
evidence NN
e VBD
each DT
decision NN
rule NN
in IN
a DT
decision NN
list NN
is VBZ
sorted VBN
in IN
descending VBG
order NN
with IN
respect NN
to TO
some DT
preference NN
value NN
, ,
and CC
rules NNS
with IN
higher JJR
preference NN
values NNS
are VBP
applied VBN
first JJ
when WRB
applying VBG
the DT
decision NN
list NN
to TO
some DT
new JJ
test NN
; :
data NNS
. .

first RB
, ,
the DT
random NN
variable JJ
d NN
representing VBG
a DT
decision NN
w NN
, ,
ries VBZ
over IN
several JJ
possible JJ
values NNS
, ,
and CC
the DT
random NN
wriable JJ
e NN
representing VBG
some DT
evidence NN
varies NNS
over IN
1 CD
and CC
0 CD
where WRB
1 CD
denotes VBZ
the DT
presence NN
of IN
the DT
corresponding JJ
piece NN
of IN
evidence NN
, ,
0 CD
its PRP$
absence NN
. .

then RB
, ,
given VBN
some DT
training NN
data NNS
in IN
which WDT
the DT
correct NN
value NN
of IN
the DT
decision NN
d NN
is VBZ
annotated VBN
to TO
each DT
instance NN
, ,
the DT
conditional JJ
probabilities NNS
pd VBP
x NN
i NN
e VBP
1 CD
of IN
observing VBG
the DT
decision NN
d NN
x NNP
under IN
the DT
condition NN
of IN
the DT
presence NN
of IN
the DT
evidence NN
e NN
e NN
1 CD
are VBP
calculated VBN
and CC
the DT
decision NN
list NN
is VBZ
constructed VBN
by IN
the DT
tbllowing JJ
procedure NN
. .

in IN
general JJ
, ,
creating VBG
training VBG
data NNS
tbr NNS
supervised VBD
learning NN
is VBZ
somewhat RB
easier JJR
than IN
creating VBG
pattern JJ
matching NN
rules NNS
by IN
hand NN
. .

next JJ
, ,
we PRP
apply VBP
yarowskys JJ
method NN
tbr NN
supervised VBN
decision NN
list NN
learning VBG
i JJ
< VBP
tref JJ
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
to TO
1vve CD
choose NNS
tile JJ
decision NN
list NN
learning VBG
method CC
as IN
the DT
705 CD
table JJ
1 CD
: :
statistics NNS
of IN
ne JJ
types NNS
of IN
irex NN
ne NNS
type JJ
organization NN
person NN
location NN
artifact NN
date NN
time NN
money NN
percent NN
total JJ
frequency NN
training NN
3676 CD
197 CD
3840 CD
206 CD
5463 CD
292 CD
747 CD
40 CD
3567 CD
191 CD
502 CD
27 CD
390 CD
21 CD
492 CD
26 CD
18677 CD
test NN
361 CD
239 CD
338 CD
224 CD
413 CD
274 CD
48 CD
32 CD
260 CD
172 CD
54 CD
35 CD
15 CD
10 CD
21 CD
14 CD
1510 CD
japanese NN
named VBN
entity NN
recognition NN
, ,
into IN
which WDT
we PRP
incorporate VBP
several JJ
noun JJ
phrase NN
chunking VBG
techniques NNS
sections NNS
3 CD
and CC
4 CD
and CC
experimentally RB
evaluate VB
their PRP$
performance NN
on IN
the DT
irex NN
, ,
workshops VBZ
training NN
and CC
test NN
data NNS
section NN
5 CD
. .

as IN
one CD
of IN
those DT
noun JJ
phrase NN
chunking VBG
techniques NNS
, ,
we PRP
propose VBP
a DT
method NN
for IN
incorporating VBG
richer JJR
contextual JJ
information NN
as RB
well RB
as IN
patterns NNS
of IN
constituent NN
morphemes NNS
within IN
a DT
named VBN
entity NN
, ,
compared VBN
with IN
those DT
considered VBN
in IN
tire NN
previous JJ
research NN
< NNP
ref VBZ
> NNP
sekine NN
et NN
al NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
borthwick NN
, ,
1999 CD
< NN
/ref NNP
> NNP
, ,
and CC
show VBP
that IN
the DT
proposed VBN
method NN
outperlbrms VBZ
these DT
approaches NNS
. .

2 CD
japanese JJ
named VBN
entity NN
recognition NN
21 CD
task NN
of IN
the DT
irex NN
workshop VBD
the DT
task NN
of IN
named VBN
entity NN
recognition NN
of IN
the DT
irex NN
workshop NN
is VBZ
to TO
recognize VB
eight CD
named VBN
entity NN
types NNS
in IN
table JJ
1 CD
irex NN
< NNP
ref NN
> NNP
conmfittee NN
, ,
1999 CD
< NN
/ref NNP
> NNP
. .

this DT
small JJ
number NN
has VBZ
almost RB
no DT
effect NN
on IN
more RBR
frequent JJ
words NNS
, ,
but CC
boosts VBZ
the DT
score NN
of IN
less JJR
common JJ
, ,
yet RB
potentially RB
equally RB
informative JJ
, ,
words NNS
. .

222 CD
decision NN
list NN
the DT
decision NN
list NN
classifier NN
uses VBZ
the DT
log-likelihood NN
of IN
correspondence NN
between IN
each DT
context NN
feature NN
and CC
each DT
sense NN
, ,
using VBG
additive JJ
smoothing VBG
< JJ
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
. .

instances NNS
that WDT
did VBD
not RB
match VB
any DT
rule NN
in IN
the DT
decision NN
list NN
were VBD
assigned VBN
the DT
most RBS
frequent JJ
sense NN
, ,
as IN
calculated VBN
from IN
the DT
training NN
data NNS
. .

other JJ
research NN
, ,
such JJ
as IN
yarowskys NN
into IN
accent JJ
restoration NN
in IN
< NNP
ref NN
> NNP
spanish JJ
and CC
french JJ
1994 CD
< NNP
/ref NNP
> NNP
, ,
which WDT
reports VBZ
accuracy NN
levels NNS
of IN
9099 CD
, ,
is VBZ
again RB
at IN
a DT
more RBR
rough-grained JJ
level NN
, ,
in IN
this DT
case NN
that IN
of IN
distinguished VBN
unaccented JJ
and CC
accented JJ
word NN
forms NNS
. .

while IN
the DT
sense NN
tagging NN
results NNS
are VBP
fairly RB
encouraging JJ
, ,
the DT
part NN
of IN
speech NN
tagging VBG
results NNS
arc VBP
at IN
present JJ
relatively RB
poor JJ
. .

it PRP
thus RB
secrns VBZ
sensible JJ
, ,
especially RB
noting VBG
wilks NNS
and CC
stevensons NNS
analysis NN
mentioned VBN
above RB
, ,
to TO
first VB
run VB
a DT
sentence NN
through IN
a DT
traditional JJ
part NN
of IN
speech NN
tagger NN
before IN
trying VBG
to TO
disambiguate VB
the DT
senses NNS
. .

from IN
this DT
perspective NN
, ,
either CC
accent JJ
identification NN
can MD
be VB
extended VBN
to TO
truecasing VBG
or CC
truecasing VBG
can MD
be VB
extended VBN
to TO
incorporate VB
accent JJ
restoration NN
. .

< JJ
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
reports NNS
good JJ
results NNS
with IN
statistical JJ
methods NNS
for IN
spanish JJ
and CC
french JJ
accent NN
restoration NN
. .

there EX
is VBZ
a DT
vast JJ
literature NN
on IN
spelling VBG
correction NN
< NNP
ref NN
> NNP
jones NNS
and CC
martin NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
golding NN
and CC
roth NN
, ,
1996 CD
< NN
/ref NNP
> NNP
using VBG
both DT
linguistic JJ
and CC
statistical JJ
approaches NNS
. .

f VB
any DT
subset NN
of IN
braceleftbig NN
mlength NN
, ,
netag NN
, ,
pos NN
bracerightbig NN
braceleftbig NN
class NN
sys NN
no DT
outputs NNS
bracerightbig RB
in IN
the DT
training NN
and CC
testing NN
phases NNS
, ,
within IN
each DT
segment NN
segev VBZ
j NN
of IN
event NN
expression NN
, ,
a DT
class NN
is VBZ
assigned VBN
to TO
each DT
system NN
, ,
where WRB
each DT
class NN
class NN
i NN
sys VBP
for IN
the DT
i-th JJ
system NN
is VBZ
represented VBN
as IN
a DT
list NN
of IN
the DT
classes NNS
of IN
the DT
named VBN
entities NNS
output NN
by IN
the DT
system NN
: :
class NN
i NN
sys VBP
braceleftbigg NN
/ NN
, ,
, ,
/ VBZ
no DT
output NN
i RB
1 CD
, ,
,n VBD
34 CD
learning VBG
algorithm IN
we PRP
apply VBP
a DT
simple JJ
decision NN
list NN
learning VBG
method NN
to TO
the DT
task NN
of IN
learning VBG
a DT
classifier NN
for IN
combining VBG
outputs NNS
of IN
named VBN
entity NN
chunkers NNS
4 CD
a DT
decision NN
list NN
< NNP
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
is VBZ
a DT
sorted JJ
list NN
of IN
decision NN
rules NNS
, ,
each DT
of IN
which WDT
decides VBZ
the DT
value NN
of IN
class NN
given VBN
some DT
features NNS
f VBP
of IN
an DT
event NN
. .

each DT
decision NN
rule NN
in IN
a DT
decision NN
list NN
is VBZ
sorted VBN
in IN
descending VBG
order NN
with IN
respect NN
to TO
some DT
preference NN
value NN
, ,
and CC
rules NNS
with IN
higher JJR
preference NN
values NNS
are VBP
applied VBN
first JJ
when WRB
applying VBG
the DT
decision NN
list NN
to TO
some DT
new JJ
test NN
data NNS
. .

32 CD
nave JJ
bayes NNS
the DT
second JJ
system NN
used VBN
was VBD
a DT
nave JJ
bayes NN
classifier NN
where WRB
the DT
similarity NN
between IN
an DT
instance NN
, ,
i NN
, ,
and CC
a DT
sense NN
class NN
, ,
sj NN
, ,
is VBZ
defined VBN
as IN
: :
simi NN
, ,
sj NN
pi NN
, ,
sj JJ
psjpisj NN
we PRP
then RB
choose VBD
the DT
sense NN
class NN
, ,
sj NN
, ,
which WDT
maximized VBD
the DT
similarity NN
function NN
above IN
, ,
making VBG
standard JJ
independence NN
assumptions NNS
. .

the DT
ordering NN
of IN
rules NNS
employed VBN
in IN
a DT
decision NN
list NN
in IN
order NN
to TO
simplify VB
the DT
representation NN
and CC
perform VB
conflict NN
resolution NN
apparently RB
gives VBZ
it PRP
an DT
advantage NN
over IN
other JJ
symbolic JJ
methods NNS
on IN
this DT
task NN
. .

with IN
respect NN
to TO
training NN
time NN
, ,
the DT
symbolic JJ
methods NNS
are VBP
significantly RB
slower JJR
since IN
they PRP
are VBP
searching VBG
for IN
a DT
simple JJ
declarative JJ
representation NN
of IN
the DT
concept NN
. .

a DT
number NN
of IN
effective JJ
concept-learning JJ
systems NNS
have VBP
employed VBN
decision NN
lists NNS
clark VBP
84 CD
< JJ
ref NN
> NNP
niblett NN
, ,
1989 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
quinlan NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
mooney NN
califf NN
, ,
1995 CD
< NN
/ref NNP
> NNP
and CC
they PRP
have VBP
already RB
been VBN
successfully RB
applied VBN
to TO
lexical JJ
disambiguation NN
< NNP
tref NN
> NNP
yarowsky NN
, ,
1994 CD
< NN
/tref NNP
> NNP
. .

all DT
of IN
the DT
logic-based JJ
methods NNS
are VBP
variations NNS
of IN
the DT
foil NN
algorithm NN
for IN
induction NN
of IN
first-order JJ
function-free JJ
horn NN
clauses NNS
< VBP
ref JJ
> NNP
quinlan NN
, ,
1990 CD
< NN
/ref NNP
> NNP
, ,
appropriately RB
simplified VBN
for IN
the DT
propositional JJ
case NN
. .

suppose NN
, ,
for IN
example NN
, ,
that WDT
pattern VBZ
a DT
noun NN
: :
normal JJ
noun NN
; :
particle NN
: :
case-particle NN
: :
none NN
: :
wo MD
; :
verb NNS
: :
normal JJ
form NN
: :
217 CD
; :
symhol NN
: :
punctuatioif NN
occurs VBZ
13 CD
times NNS
in IN
a DT
learlfing NN
set NN
and CC
that DT
tell NN
of IN
the DT
occurrences NNS
include VBP
the DT
inserted JJ
partition NN
inal NN
: :
k NN
suppose NN
also RB
thai VBZ
; :
pattern NN
b IN
noun NN
; :
particle NN
; :
verb NN
; :
symbol NN
occurs VBZ
12a CD
times NNS
in IN
a DT
learning NN
set NN
and CC
that IN
90 CD
of IN
the DT
occurrences NNS
include VBP
the DT
mark NN
. .

over IN
the DT
past JJ
decade NN
, ,
there EX
has VBZ
been VBN
tremendous JJ
progress NN
on IN
learning VBG
parsing VBG
models NNS
from IN
treebank JJ
data NNS
< NNS
tref VBP
> JJ
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
collins NNS
, ,
1999 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
charniak NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
ratnaparkhi NN
, ,
1999 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
charniak NN
, ,
2000 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
wang NN
et NN
al NN
, ,
2005 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
mcdonald NNP
et VBZ
al RB
, ,
2005 CD
< NN
/ref NNP
> NNP
. .

learning VBG
in IN
this DT
context NN
consisted VBD
of IN
estimating VBG
the DT
parameters NNS
of IN
the DT
model NN
with IN
simple JJ
likelihood NN
based VBN
techniques NNS
, ,
but CC
incorporating VBG
various JJ
smoothing VBG
and CC
back-off JJ
estimation NN
tricks NNS
to TO
cope VB
with IN
the DT
sparse NN
data NNS
problems NNS
< VBP
ref VB
> JJ
collins NNS
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
bikel NN
, ,
2004 CD
< NN
/ref NNP
> NNP
. .

over IN
the DT
past JJ
decade NN
, ,
there EX
has VBZ
been VBN
tremendous JJ
progress NN
on IN
learning VBG
parsing VBG
models NNS
from IN
treebank JJ
data NNS
< NNS
tref VBP
> JJ
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
collins NNS
, ,
1999 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
charniak NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
ratnaparkhi NN
, ,
1999 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
charniak NN
, ,
2000 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
wang NN
et NN
al NN
, ,
2005 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
mcdonald NNP
et VBZ
al RB
, ,
2005 CD
< NN
/ref NNP
> NNP
. .

learning VBG
in IN
this DT
context NN
consisted VBD
of IN
estimating VBG
the DT
parameters NNS
of IN
the DT
model NN
with IN
simple JJ
likelihood NN
based VBN
techniques NNS
, ,
but CC
incorporating VBG
various JJ
smoothing VBG
and CC
back-off JJ
estimation NN
tricks NNS
to TO
cope VB
with IN
the DT
sparse NN
data NNS
problems NNS
< VBP
ref VB
> JJ
collins NNS
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
bikel NN
, ,
2004 CD
< NN
/ref NNP
> NNP
. .

a DT
recent JJ
trend NN
in IN
natural JJ
language NN
processing NN
has VBZ
been VBN
toward IN
a DT
greater JJR
emphasis NN
on IN
statistical JJ
approaches NNS
, ,
beginning VBG
with IN
the DT
success NN
of IN
statistical JJ
part-of-speech JJ
tagging NN
programs NNS
< VBP
ref JJ
> NNP
church NN
1988 CD
< NNP
/ref NNP
> NNP
, ,
and CC
continuing VBG
with IN
other JJ
work NN
using VBG
statistical JJ
part-of-speech JJ
tagging NN
programs NNS
, ,
such JJ
as IN
bbn NN
plum NN
< NNP
ref NN
> NNP
weischedel NN
et NN
al NN
1993 CD
< NNP
/ref NNP
> NNP
and CC
nyu JJ
proteus NN
< NNP
ref NN
> NNP
grishman NN
and CC
sterling NN
1993 CD
< NNP
/ref NNP
> NNP
. .

nevertheless RB
, ,
most JJS
natural JJ
language NN
systems NNS
remain VBP
primarily RB
rule NN
based VBN
, ,
and CC
even RB
systems NNS
that WDT
do VBP
use VB
statistical JJ
techniques NNS
, ,
such JJ
as IN
att JJ
chronus NN
< NNP
ref NN
> NNP
levin NN
and CC
pieraccini NN
1995 CD
< NNP
/ref NNP
> NNP
, ,
continue VBP
to TO
require VB
a DT
significant JJ
rule NN
based VBN
component NN
. .

development NN
of IN
a DT
complete JJ
end-to-end JJ
statistical JJ
understanding NN
system NN
has VBZ
been VBN
the DT
focus NN
of IN
several JJ
ongoing VBG
research NN
efforts NNS
, ,
including VBG
< JJ
ref NN
> NNP
miller NN
et NN
al NN
1995 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
ref VBP
> NNP
koppelman NNP
et VBZ
al JJ
1995 CD
< NNP
/ref NNP
> NNP
. .

in IN
empirical JJ
approaches NNS
to TO
parsing VBG
, ,
lexical/semantic JJ
collocation NN
extracted VBD
from IN
corpus NN
has VBZ
been VBN
proved VBN
to TO
be VB
quite RB
useful JJ
for IN
ranking VBG
parses NNS
in IN
syntactic JJ
analysis NN
. .

a DT
broader JJR
range NN
of IN
information NN
, ,
in IN
particular JJ
lexical JJ
information NN
, ,
was VBD
found VBN
to TO
be VB
essential JJ
in IN
disambiguating VBG
the DT
syntactic JJ
structures NNS
of IN
real-world JJ
sentences NNS
. .

spatter NN
< NNP
tref NN
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
augmented VBD
the DT
pure NN
pcfg NN
by IN
introducing VBG
a DT
number NN
of IN
lexical JJ
attributes NNS
. .

the DT
spatter NN
parser NN
attained VBD
87 CD
accuracy NN
and CC
first JJ
made VBN
stochastic JJ
parsers NNS
a DT
practical JJ
choice NN
. .

after IN
training NN
, ,
head NN
tagging NN
is VBZ
performed VBN
according VBG
to TO
equation NN
1 CD
, ,
where WRB
15 CD
is VBZ
the DT
estimated JJ
probability NN
and CC
hi NN
is VBZ
a DT
characteristic JJ
function NN
which WDT
is VBZ
true JJ
iff JJ
word NN
i NN
is VBZ
a DT
head NN
word NN
. .

n JJ
h NN
argmaxh JJ
hwilhihilhi-1hi-2 JJ
i1 NN
1 CD
the DT
second JJ
pass NN
then RB
takes VBZ
the DT
words NNS
with IN
this DT
head NN
information NN
and CC
supertags VB
them PRP
according VBG
to TO
equation NN
2 CD
, ,
where WRB
thio NN
is VBZ
the DT
supertag NN
of IN
the DT
epart NN
of IN
speech NN
tagging VBG
models NNS
have VBP
not RB
used VBN
heads NNS
in IN
this DT
manner NN
to TO
achieve VB
variable JJ
length NN
contexts NN
. .

there RB
have VBP
been VBN
two CD
main JJ
robust JJ
parsing VBG
paradigms NN
: :
finite JJ
state NN
grammar-based JJ
approaches NNS
such JJ
as IN
< JJ
ref NN
> NNP
abney NN
1990 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
grishman NN
1995 CD
< NNP
/ref NNP
> NNP
, ,
and CC
hobbs VBZ
et JJ
al NN
. .

< JJ
ref NN
> NNP
srinivas VBD
1997a CD
< NNP
/ref NNP
> NNP
has VBZ
presented VBN
a DT
different JJ
approach NN
called VBD
supertagging VBG
that IN
integrates VBZ
linguistically RB
motivated JJ
lexical JJ
descriptions NNS
with IN
the DT
robustness NN
of IN
statistical JJ
techniques NNS
. .

the DT
idea NN
underlying VBG
the DT
approach NN
is VBZ
that IN
the DT
computation NN
of IN
linguistic JJ
structure NN
can MD
be VB
localized VBN
if IN
lexical JJ
items NNS
are VBP
associated VBN
with IN
rich JJ
descriptions NNS
supertags VBP
that IN
impose NN
complex JJ
constraints NNS
in IN
a DT
local JJ
context NN
. .

second JJ
, ,
one CD
might MD
propagate VB
lexical JJ
information NN
upward RB
through IN
the DT
productions NNS
. .

a DT
more RBR
linguistically RB
motivated JJ
approach NN
is VBZ
to TO
expand VB
the DT
domain NN
of IN
productions NNS
downward VBP
to TO
incorporate VB
more JJR
tree JJ
structures NNS
. .

standard JJ
symbolic JJ
machine NN
learning VBG
techniques NNS
have VBP
been VBN
successfully RB
applied VBN
to TO
a DT
number NN
of IN
tasks NNS
in IN
natural JJ
language NN
processing NN
nlp NN
. .

examples NNS
include VBP
the DT
use NN
of IN
decision NN
trees NNS
for IN
syntactic JJ
analysis NN
< NNP
tref NN
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
, ,
coreference NN
< NNP
ref NN
> NNP
aone NN
and CC
bennett NN
, ,
1995 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
mccarthy NN
and CC
lehnert NN
, ,
1995 CD
< NN
/ref NNP
> NNP
, ,
and CC
cue NN
phrase NN
identification NN
< NNP
ref NN
> NNP
litman NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
the DT
use NN
of IN
inductive JJ
logic NN
programming VBG
for IN
learning VBG
semantic JJ
grammars NNS
and CC
building NN
prolog NN
parsers NNS
113 CD
< JJ
ref NN
> NNP
zelle NNP
and CC
mooney NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
zelle NNP
and CC
mooney NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
the DT
use NN
of IN
conceptual JJ
clustering NN
algorithms NN
for IN
relative JJ
pronoun NN
resolution NN
< NNP
ref NN
> NNP
cardie NN
, ,
1992a CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
cardie NN
1992b CD
< NN
/ref NNP
> NNP
, ,
and CC
the DT
use NN
of IN
case-based JJ
learning NN
techniques NNS
for IN
lexical JJ
tagging NN
tasks NNS
< VBP
ref JJ
> NNP
cardie NN
, ,
1993a CD
< NN
/ref NNP
> NNP
; :
daelemans NNS
et VBP
al RB
, ,
submitted VBD
. .

in IN
theory NN
, ,
both DT
statistical JJ
and CC
machine NN
learning VBG
techniques NNS
can MD
significantly RB
reduce VB
the DT
knowledge-engineering JJ
effort NN
for IN
building VBG
large-scale JJ
nlp JJ
systems NNS
: :
they PRP
offer VBP
an DT
automatic JJ
means NNS
for IN
acquiring VBG
robust JJ
heuristics NNS
for IN
a DT
host NN
of IN
lexical JJ
and CC
structural JJ
disambiguation NN
tasks NNS
. .

it PRP
is VBZ
well-known JJ
in IN
the DT
machine NN
learning VBG
community NN
, ,
however RB
, ,
that IN
the DT
success NN
of IN
a DT
learning NN
algorithm NN
depends VBZ
critically RB
on IN
the DT
representation NN
used VBN
to TO
describe VB
the DT
training NN
and CC
test NN
instances NNS
< VBP
ref JJ
> NNP
almuallim NN
and CC
dietterich NN
, ,
1991 CD
< NN
/ref NNP
> NNP
, ,
langley NN
and CC
sage NN
, ,
in IN
press NN
. .

a DT
strength NN
of IN
these DT
models NNS
is VBZ
undoubtedly RB
the DT
powerful JJ
estimation NN
techniques NNS
that IN
they PRP
use VBP
: :
maximum-entropy JJ
modeling NN
in IN
< NNP
ref NN
> NNP
ratnaparkhi NN
1997 CD
< NNP
/ref NNP
> NNP
or CC
decision NN
trees NNS
in IN
< NNP
ref NN
> NNP
jelinek NN
et NN
al NN
1994 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NNP
magerman NN
1995 CD
< NNP
/tref NNP
> NNP
. .

a DT
weakness NN
, ,
we PRP
will MD
argue VB
in IN
this DT
section NN
, ,
is VBZ
the DT
method NN
of IN
associating VBG
parameters NNS
with IN
transitions NNS
taken VBN
by IN
bottom-up JJ
, ,
shift-reduce-style JJ
parsers NNS
. .

we PRP
give VBP
examples NNS
in IN
which WDT
this DT
method NN
leads VBZ
to TO
the DT
parameters NNS
unnecessarily RB
fragmenting VBG
the DT
training NN
data NNS
in IN
some DT
cases NNS
or CC
ignoring VBG
important JJ
context NN
in IN
other JJ
cases NNS
. .

593 CD
collins NNS
head-driven JJ
statistical JJ
models NNS
for IN
nl JJ
parsing VBG
internal JJ
rules NNS
lexical JJ
rules NNS
top VBP
s NN
jj NN
last JJ
s JJ
np JJ
np NN
vp NN
nn JJ
week NN
np RB
jj JJ
nn JJ
nnp NN
ibm NN
np JJ
nnp NN
vbd NN
bought VBD
vp JJ
vbd NN
np NN
nnp JJ
lotus NN
np JJ
nnp JJ
figure NN
1 CD
a DT
nonlexicalized JJ
parse NN
tree NN
and CC
a DT
list NN
of IN
the DT
rules NNS
it PRP
contains VBZ
. .

the DT
precision NN
and CC
recall NN
of IN
the DT
traces NNS
found VBN
by IN
model NN
3 CD
were VBD
938 CD
and CC
901 CD
, ,
respectively RB
out IN
of IN
437 CD
cases NNS
in IN
section NN
23 CD
of IN
the DT
treebank NN
, ,
where WRB
three CD
criteria NNS
must MD
be VB
met VBN
for IN
a DT
trace NN
to TO
be VB
correct JJ
: :
1 CD
it PRP
must MD
be VB
an DT
argument NN
to TO
the DT
correct JJ
headword NN
; :
2 CD
it PRP
must MD
be VB
in IN
the DT
correct JJ
position NN
in IN
relation NN
to TO
that DT
headword NN
preceding VBG
or CC
following VBG
; :
15 CD
< NN
tref NN
> NNP
magerman NN
1995 CD
< NNP
/tref NNP
> NNP
collapses VBZ
advp NN
and CC
prt NN
into IN
the DT
same JJ
label NN
; :
for IN
comparison NN
, ,
we PRP
also RB
removed VBD
this DT
distinction NN
when WRB
calculating VBG
scores NNS
. .

22 CD
statistical JJ
parsers NNS
pioneered VBN
by IN
the DT
ibm JJ
natural JJ
language NN
group NN
< NNP
ref VBZ
> NNP
fujisaki NN
et NN
al NN
1989 CD
< NNP
/ref NNP
> NNP
and CC
later RB
pursued VBN
by IN
, ,
for IN
example NN
, ,
< NNP
ref VBZ
> NNP
schabes NNS
, ,
roth NN
, ,
and CC
osborne JJ
1993 CD
< NNP
/ref NNP
> NNP
, ,
jelinek NN
et NN
al NN
. .

the DT
rules NNS
to TO
assign VB
a DT
structure NN
to TO
an DT
input NN
are VBP
extracted VBN
automatically RB
from IN
hand-annotated JJ
parses NNS
of IN
large JJ
corpora NNS
, ,
which WDT
are VBP
then RB
subjected VBN
to TO
smoothing VBG
to TO
obtain VB
reasonable JJ
coverage NN
of IN
the DT
language NN
. .

during IN
the DT
last JJ
few JJ
years NNS
large JJ
treebanks NNS
have VBP
become VBN
available JJ
to TO
many JJ
researchers NNS
, ,
which WDT
has VBZ
resulted VBN
in IN
researches NNS
applying VBG
a DT
range NN
of IN
new JJ
techniques NNS
for IN
parsing VBG
systems NNS
. .

most JJS
of IN
the DT
methods NNS
that WDT
are VBP
being VBG
suggested VBN
include VBP
some DT
kind NN
of IN
machine NN
learning NN
, ,
such JJ
as IN
history NN
based VBN
grammars NNS
and CC
decision NN
tree NN
models NNS
< VBP
ref JJ
> NNP
black JJ
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
, ,
training NN
or CC
inducing VBG
statistical JJ
grammars NNS
< VBP
ref JJ
> NNP
black JJ
, ,
garside JJ
and CC
leech NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
pereira NN
and CC
schabes NNS
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
schabes NNS
et VBP
al RB
, ,
1993 CD
< NN
/ref NNP
> NNP
, ,
or CC
other JJ
techniques NNS
< VBP
ref JJ
> NNP
bod NN
, ,
1993 CD
< NN
/ref NNP
> NNP
. .

consequently RB
, ,
syntactical JJ
analysis NN
has VBZ
become VBN
an DT
area NN
with IN
a DT
wide JJ
variety NN
of IN
a DT
algorithms NN
and CC
methods NNS
for IN
learning VBG
and CC
parsing NN
, ,
and CC
b SYM
type NN
of IN
information NN
used VBN
for IN
learning VBG
and CC
parsing VBG
sometimes RB
referred VBN
to TO
as IN
feature NN
set VBN
. .

these DT
methods NNS
only RB
could MD
become VB
popular JJ
through IN
evaluation NN
methods NNS
for IN
parsing VBG
systems NNS
, ,
such JJ
as IN
bracket NN
accuracy NN
, ,
bracket NN
recall NN
, ,
sentence NN
accuracy NN
and CC
viterbi NN
score NN
. .

although IN
we PRP
report VBP
promising VBG
results NNS
, ,
parse JJ
selection NN
that WDT
is VBZ
sufficiently RB
accurate JJ
for IN
many JJ
practical JJ
applications NNS
will MD
require VB
a DT
more RBR
lexicalised JJ
system NN
. .

however RB
, ,
the DT
massively RB
increased JJ
coverage NN
obtained VBN
here RB
by IN
relaxing VBG
subcategorisation NN
constraints NNS
underlines VBP
the DT
need NN
to TO
acquire VB
accurate NN
and CC
complete JJ
subcategorisation NN
frames NNS
in IN
a DT
corpus-driven JJ
fashion NN
, ,
before IN
such JJ
constraints NNS
can MD
be VB
exploited VBN
robustly RB
and CC
effectively RB
with IN
free JJ
text NN
. .

in IN
our PRP$
experiments NNS
, ,
the DT
window NN
starts VBZ
at IN
the DT
sentence NN
prior RB
to TO
that DT
containing VBG
the DT
token NN
and CC
extends VBZ
back RB
w WP
the DT
window NN
size NN
sentences NNS
. .

the DT
choice NN
to TO
use VB
sentences NNS
as IN
the DT
unit NN
of IN
distance NN
is VBZ
motivated VBN
by IN
our PRP$
intention NN
to TO
incorporate VB
triggers NNS
of IN
this DT
form NN
into IN
a DT
probabilistie JJ
treebank-based JJ
parser NN
and CC
tagger NN
, ,
such JJ
as IN
< JJ
ref NN
> NNP
black JJ
et NN
al NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
black JJ
et NN
al NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
brill NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
collins NNS
, ,
1996 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
jelinek NN
et NN
al NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
ratnaparkhi NN
, ,
1997 CD
< NN
/ref NNP
> NNP
. .

all DT
such JJ
parsers NNS
and CC
taggers NNS
of IN
which WDT
we PRP
are VBP
aware JJ
use IN
only RB
intrasentential JJ
information NN
in IN
predicting VBG
parses NNS
or CC
tags NNS
, ,
and CC
we PRP
wish VBP
to TO
remove VB
this DT
information NN
, ,
as RB
far RB
as IN
possible JJ
, ,
from IN
our PRP$
results NNS
7 CD
the DT
window NN
was VBD
not RB
allowed VBN
to TO
cross VB
a DT
document NN
boundary NN
. .

this DT
approach NN
was VBD
congruent JJ
with IN
the DT
great JJ
success NN
of IN
word NN
n-gram JJ
models NNS
in IN
speech NN
recognition NN
, ,
and CC
drew VBD
strength NN
from IN
a DT
broader JJR
interest NN
in IN
lexicalized JJ
grammars NNS
, ,
as RB
well RB
as IN
demonstrations NNS
that WDT
lexical JJ
dependencies NNS
were VBD
a DT
key JJ
tool NN
for IN
resolving VBG
ambiguities NNS
such JJ
as IN
pp JJ
attachments NNS
< VBP
ref JJ
> NNP
ford NN
et NN
al NN
, ,
1982 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
hindle NN
and CC
rooth NN
, ,
1993 CD
< NN
/ref NNP
> NNP
. .

in IN
the DT
following JJ
decade NN
, ,
great JJ
success NN
in IN
terms NNS
of IN
parse NN
disambiguation NN
and CC
even RB
language NN
modeling NN
was VBD
achieved VBN
by IN
various JJ
lexicalized JJ
pcfg NN
models NNS
< VBP
tref JJ
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
charniak NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
collins NNS
, ,
1999 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
charniak NN
, ,
2000 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
charniak NN
, ,
2001 CD
< NN
/ref NNP
> NNP
. .

however RB
, ,
several JJ
results NNS
have VBP
brought VBN
into IN
question NN
how WRB
large JJ
a DT
role NN
lexicalization NN
plays NNS
in IN
such JJ
parsers NNS
. .

< JJ
ref NN
> NNP
johnson NN
1998 CD
< NNP
/ref NNP
> NNP
showed VBD
that IN
the DT
performance NN
of IN
an DT
unlexicalized JJ
pcfg NN
over IN
the DT
penn NN
treebank NN
could MD
be VB
improved VBN
enormously RB
simply RB
by IN
annotating VBG
each DT
node NN
by IN
its PRP$
parent NN
category NN
. .

however RB
, ,
perhaps RB
even RB
more RBR
significant JJ
has VBZ
been VBN
the DT
lexicalization NN
of IN
the DT
grammar NN
formalisms NN
being VBG
probabilistically RB
modeled VBN
: :
crucially RB
, ,
all PDT
the DT
recent JJ
, ,
successful JJ
statistical JJ
parsers NNS
have VBP
in IN
some DT
way NN
made VBN
use NN
of IN
bilexical JJ
dependencies NNS
. .

155 CD
even RB
more RBR
crucially RB
, ,
the DT
bilexical JJ
dependencies NNS
involve VBP
head-modifier JJ
relations NNS
hereafter NN
referred VBD
to TO
simply RB
as IN
head NN
relations NNS
. .

the DT
intuition NN
behind IN
the DT
lexicalization NN
of IN
a DT
grammar NN
formalism NN
is VBZ
to TO
capture VB
lexical JJ
items NNS
idiosyncratic JJ
parsing NN
preferences NNS
. .

in IN
those DT
research NN
, ,
extracted VBD
lexical/semantic JJ
collocation NN
is VBZ
especially RB
useful JJ
in IN
terms NNS
of IN
ranking VBG
parses NNS
in IN
syntactic JJ
analysis NN
as RB
well RB
as IN
automatic JJ
construction NN
of IN
lexicon NN
for IN
nlp NN
. .

for IN
example NN
, ,
in IN
the DT
context NN
of IN
syntactic JJ
disambiguation NN
, ,
< NNP
ref VBZ
> NNP
black JJ
1993 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NNP
magerman NN
1995 CD
< NNP
/tref NNP
> NNP
proposed VBD
statistical JJ
parsing NN
models NNS
based-on JJ
decisiontree JJ
learning VBG
techniques NNS
, ,
which WDT
incorporated VBD
not RB
only RB
syntactic JJ
but CC
also RB
lexical/semantic JJ
information NN
in IN
the DT
decision-trees NNS
. .

for IN
example NN
, ,
in IN
the DT
context NN
of IN
syntactic JJ
disambiguation NN
, ,
< NNP
ref VBZ
> NNP
black JJ
1993 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NNP
magerman NN
1995 CD
< NNP
/tref NNP
> NNP
proposed VBD
statistical JJ
parsing NN
models NNS
based-on JJ
decisiontree JJ
learning VBG
techniques NNS
, ,
which WDT
incorporated VBD
not RB
only RB
syntactic JJ
but CC
also RB
lexical/semantic JJ
information NN
in IN
the DT
decision-trees NNS
. .

other JJ
researchers NNS
have VBP
proposed VBN
automatically RB
selecting VBG
the DT
conditioning NN
information NN
for IN
various JJ
states NNS
of IN
the DT
model NN
, ,
thus RB
potentially RB
increasing VBG
greatly RB
the DT
space NN
of IN
possible JJ
features NNS
and CC
selectively RB
choosing VBG
the DT
best JJS
predictors NNS
for IN
each DT
situation NN
. .

another DT
example NN
of IN
automatic JJ
feature NN
selection NN
for IN
parsing NN
is VBZ
in IN
the DT
context NN
of IN
a DT
deterministic JJ
parsing NN
model NN
that WDT
chooses VBZ
parse JJ
actions NNS
based VBN
on IN
automatically RB
induced VBN
decision NN
structures VBZ
over RP
a DT
very RB
rich JJ
feature NN
set VBN
< NNP
ref NN
> NNP
hermjakob NN
and CC
mooney NN
, ,
1997 CD
< NN
/ref NNP
> NNP
. .

we PRP
grew VBD
the DT
trees NNS
fully RB
and CC
we PRP
calculated VBD
final JJ
expansion NN
probabilities NNS
at IN
the DT
leaves NNS
by IN
linear JJ
interpolation NN
with IN
estimates NNS
one CD
level NN
above IN
. .

the DT
node JJ
direction NN
features NNS
indicate VBP
whether IN
a DT
node NN
is VBZ
a DT
left JJ
child NN
, ,
a DT
right JJ
child NN
, ,
or CC
a DT
single JJ
child NN
. .

32 CD
word NN
alignment NN
because IN
most JJS
of IN
the DT
700 CD
languages NNS
in IN
odin NN
are VBP
low-density JJ
languages NNS
with IN
no DT
on-line JJ
bilingual JJ
dictionariesorlargeparallelcorpora NN
, ,
aligning VBG
the DT
source NN
sentence NN
and CC
its PRP$
english JJ
translation NN
directly RB
would MD
not RB
work VB
well RB
. .

the DT
final JJ
step NN
is VBZ
to TO
use VB
the DT
training NN
examples VBZ
to TO
learn VB
an DT
effective JJ
search NN
policy NN
so RB
that IN
our PRP$
run-time JJ
generation NN
component NN
can MD
find VB
good JJ
output NN
sentences NNS
in IN
a DT
reasonable JJ
time NN
frame NN
. .

in IN
particular JJ
, ,
we PRP
use VBP
variants NNS
of IN
existing VBG
search NN
optimization NN
< NNP
ref NN
> NNP
daum NN
and CC
marcu NN
, ,
2005 CD
< NN
/ref NNP
> NNP
and CC
ranking VBG
algorithms JJ
< NNP
ref NN
> NN
collins NNS
and CC
koo NN
, ,
2005 CD
< NN
/ref NNP
> NN
to TO
train VB
our PRP$
run-time JJ
component NN
to TO
find VB
good JJ
outputs NNS
within IN
a DT
specified JJ
time NN
window NN
; :
see VB
also RB
< NNP
ref NN
> NNP
stent NN
et NN
al NN
, ,
2004 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
walker NN
et NN
al NN
, ,
2001 CD
< NN
/ref NNP
> NNP
. .

in IN
addition NN
, ,
we PRP
deterministically RB
add VBP
features NNS
to TO
improve VB
several JJ
grammatical JJ
aspects NNS
, ,
including VBG
1 CD
enforcing VBG
verb JJ
inflectional JJ
agreement NN
in IN
derived JJ
trees NNS
, ,
2 CD
enforcing VBG
consistency NN
in IN
the DT
finiteness NN
of IN
vp NN
and CC
s JJ
complements NNS
, ,
and CC
3 CD
restricting VBG
subject/direct NN
object/indirect NN
object JJ
complements NNS
to TO
play VB
the DT
same JJ
grammatical JJ
role NN
in IN
derived JJ
trees NNS
. .

in IN
the DT
second JJ
stage NN
, ,
the DT
complements NNS
and CC
adjuncts NNS
in IN
the DT
decorated JJ
trees NNS
are VBP
incrementally RB
re80 JJ
syntax NN
: :
cat NN
: :
sa JJ
fin NN
: :
other JJ
, ,
cat NN
: :
s JJ
cat NN
: :
np NN
, ,
apr NN
: :
vbp NN
, ,
apn NN
: :
other JJ
pos NN
: :
prp NN
we PRP
fin VBP
: :
yes UH
, ,
cat NN
: :
vp NN
apn NN
: :
other JJ
, ,
pos JJ
: :
vbp NN
do VBP
pos NNS
: :
rb NN
nt JJ
fin NN
: :
yes UH
, ,
cat NN
: :
vp NN
, ,
gra NN
: :
obj1 JJ
fin NN
: :
yes UH
, ,
cat NN
: :
vp NN
, ,
gra NN
: :
obj1 JJ
pos NN
: :
vbp NN
have VBP
cat VBN
: :
np NN
, ,
gra NN
: :
obj1 JJ
operations NNS
: :
initial JJ
tree NN
comp NN
semantics NNS
: :
speech-actaction NN
assert JJ
speech-actcontentpolarity JJ
negative JJ
speech-actcontentattribute JJ
resourceattribute NN
syntax NN
: :
cat NN
: :
np NN
, ,
apr NN
: :
vbp NN
, ,
gra NN
: :
obj1 NN
, ,
apn NN
: :
other JJ
pos NN
: :
jj NN
medical JJ
pos NN
: :
nns JJ
supplies NNS
cat NN
: :
advp NN
, ,
gra NN
: :
adj JJ
pos NN
: :
rb NN
here RB
cat VBZ
: :
np NN
, ,
apr NN
: :
vbz NN
, ,
gra NN
: :
adj NN
, ,
apn NN
: :
3ps CD
pos NN
: :
nn NN
captain NN
operations NNS
: :
comp NN
left/right JJ
adjunction NN
left/right VBD
adjunction NN
semantics NNS
: :
speech-actcontentvalue JJ
medical-supplies NNS
speech-actcontentobject-id JJ
market NN
addressee VB
captain-kirk JJ
dialogue-actaddressee JJ
captain-kirk JJ
speech-actaddressee JJ
captain-kirk JJ
figure NN
2 CD
: :
the DT
linguistic JJ
resources NNS
inferred VBN
from IN
the DT
training NN
example NN
in IN
figure NN
1 CD
. .

whats NNS
more RBR
, ,
on IN
top NN
of IN
the DT
large JJ
undertaking NN
of IN
designing VBG
and CC
implementing VBG
a DT
statistical JJ
parsing NN
model NN
, ,
the DT
use NN
of IN
heuristics NNS
has VBZ
required VBN
a DT
further JJ
e NN
ort NN
, ,
forcing VBG
the DT
researcher NN
to TO
bring VB
both DT
linguistic JJ
intuition NN
and CC
, ,
more RBR
often RB
, ,
engineering NN
savvy NN
to TO
bear VB
whenever RB
moving VBG
to TO
a DT
new JJ
treebank NN
. .

the DT
apparently RB
haphazard JJ
placement NN
of IN
these DT
rules NNS
that WDT
pick VBP
out RP
fw NN
and CC
the DT
rarity NN
of IN
fw NN
nodes NNS
in IN
the DT
data NNS
strongly RB
suggest VBP
these DT
rules NNS
are VBP
the DT
result NN
of IN
engineering NN
e NN
ort NN
. .

furthermore RB
, ,
it PRP
is VBZ
not RB
at IN
all DT
apparent JJ
that IN
tree-transforming JJ
heuristics NNS
that WDT
are VBP
useful JJ
for IN
one CD
parsing VBG
model NN
will MD
be VB
useful JJ
for IN
another DT
. .

311 CD
enriching VBG
igt NN
in IN
a DT
previous JJ
study NN
< NNP
ref NN
> NNP
xia NNP
and CC
lewis NN
, ,
2007 CD
< NN
/ref NNP
> NNP
, ,
we PRP
proposed VBD
a DT
three-step JJ
process NN
to TO
enrich VB
igt JJ
data NNS
: :
1 CD
parse IN
the DT
english JJ
translation NN
with IN
an DT
english JJ
parser NN
and CC
convert JJ
english JJ
phrase NN
structures VBZ
ps VBP
into IN
dependency NN
structures NNS
ds VBP
with IN
a DT
head NN
percolation NN
table JJ
< NN
tref NN
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
, ,
2 CD
align IN
the DT
target NN
line NN
and CC
the DT
english JJ
translation NN
using VBG
the DT
gloss NN
line NN
, ,
and CC
3 CD
project NN
the DT
syntactic JJ
structures NNS
both DT
ps NNS
and CC
ds NN
from IN
english JJ
onto IN
the DT
target NN
line NN
. .

for IN
instance NN
, ,
given VBN
the DT
igt JJ
example NN
in IN
ex NN
1 CD
, ,
the DT
enrichment NN
algorithm NN
will MD
produce VB
the DT
word NN
alignment NN
in IN
figure NN
1 CD
and CC
the DT
syntactic JJ
structures NNS
in IN
figure NN
2 CD
. .

the DT
teacher NN
gave VBD
a DT
book NN
to TO
the DT
boy NN
yesterday NN
rhoddodd VBP
yr NN
athro NN
lyfr NN
ir NN
bachgen NN
ddoe NN
gloss NN
line NN
: :
translation NN
: :
target NN
line NN
: :
gave-3sg NN
the DT
teacher NN
book NN
to-the JJ
boy NN
yesterday NN
figure VBP
1 CD
: :
aligning VBG
the DT
target NN
line NN
and CC
the DT
english JJ
translation NN
with IN
the DT
help NN
of IN
the DT
gloss NN
line NN
533 CD
gave VBD
a DT
projecting JJ
ds NN
athro NN
bachgen NN
lyfr NN
yr VBP
ddoeir NN
rhoddodd NN
s NN
np1 JJ
vp NN
nn IN
teacher NN
vbd NN
gave VBD
np2 JJ
dt NN
a DT
np4pp JJ
nn NN
the DT
in IN
np3 NN
yesterday NN
nn IN
dt JJ
book NN
nn NN
boy NN
dt NN
to TO
s VB
np JJ
nn JJ
vbd NN
np NN
nppp JJ
nn JJ
indt NN
nn NN
nndt JJ
rhoddodd NN
gave VBD
yrthe CC
athro JJ
teacher NN
lyfr NN
book NN
ir JJ
to-the JJ
bachogen NN
boy NN
ddoe NN
yesterday NN
teacher IN
a DT
boy NN
the DT
book NN
the DT
yesterdayto NN
the DT
b NN
projecting VBG
ps JJ
figure NN
2 CD
: :
projecting NN
syntactic JJ
structure NN
from IN
english JJ
to TO
the DT
target NN
language NN
we PRP
evaluated VBD
the DT
algorithm NN
on IN
a DT
small JJ
set NN
of IN
538 CD
igt JJ
instances NNS
for IN
several JJ
languages NNS
. .

also RB
, ,
we PRP
treat VBP
a DT
propbank NN
argument NN
arg0 NN
: :
: :
: :
arg9 NN
as IN
a DT
complement NN
and CC
a DT
propbank NN
adjunct JJ
argms NN
as IN
an DT
adjunct NN
when WRB
such JJ
annotation NN
is VBZ
available1 JJ
otherwise RB
, ,
we PRP
basically RB
follow VBP
the DT
approach NN
of IN
< NNP
ref NN
> NNP
chen NN
, ,
2001 CD
< NN
/ref NNP
> VBZ
2 CD
besides IN
introducing VBG
one CD
kind NN
of IN
tag NN
extraction NN
1the CD
version NN
of IN
the DT
propbank NN
we PRP
are VBP
using VBG
is VBZ
not RB
fully RB
annotated VBN
with IN
semantic JJ
role NN
information NN
, ,
although IN
the DT
most RBS
common JJ
predicates NNS
are VBP
. .

thus RB
maxent NN
has VBZ
at IN
least JJS
one CD
advantage NN
over IN
each DT
of IN
the DT
reviewed VBN
pos NN
tagging VBG
techniques NNS
. .

it PRP
is VBZ
better RBR
able JJ
to TO
use VB
diverse JJ
information NN
than IN
markov NN
models NNS
, ,
requires VBZ
less JJR
supporting VBG
techniques NNS
than IN
sdt NN
, ,
and CC
unlike IN
tbl NN
, ,
can MD
be VB
used VBN
in IN
a DT
probabilistic JJ
framework NN
. .

since IN
most JJS
realistic JJ
natural JJ
language NN
applications NNS
must MD
process VB
words NNS
that WDT
were VBD
never RB
seen VBN
before IN
in IN
training NN
data NNS
, ,
all DT
experiments NNS
in IN
this DT
paper NN
are VBP
conducted VBN
on IN
test NN
data NNS
that WDT
include VBP
unknown JJ
words NNS
. .

the DT
experiments NNS
in IN
this DT
paper NN
test VBZ
the DT
hypothesis NN
that WDT
better JJR
use NN
of IN
context NN
will MD
improve VB
the DT
accuracy NN
. .

a DT
maximum JJ
entropy NN
model NN
is VBZ
well-suited JJ
for IN
such JJ
experiments NNS
since IN
it PRP
cornbines VBZ
diverse JJ
forms NNS
of IN
contextual JJ
information NN
in IN
a DT
principled JJ
manner NN
, ,
and CC
does VBZ
not RB
impose VB
any DT
distributional JJ
assumptions NNS
on IN
the DT
training NN
data NNS
. .

in IN
contrast NN
, ,
the DT
maxent NN
model NN
combines NNS
diverse JJ
and CC
non-local JJ
information NN
sources NNS
without IN
making VBG
any DT
independence NN
assumptions NNS
. .

however RB
, ,
the DT
aforementioned JJ
sdt NN
techniques NNS
require VBP
word NN
classes NNS
< VBP
ref JJ
> NNP
brown NN
et NN
al NN
, ,
1992 CD
< NN
/ref NNP
> NNP
to TO
help VB
prevent VB
data NNS
fragmentation NN
, ,
and CC
a DT
sophisticated JJ
smoothing NN
algorithm NN
to TO
mitigate VB
the DT
effects NNS
of IN
any DT
fragmentation NN
that IN
occurs VBZ
. .

6 CD
conclusion NN
it PRP
is VBZ
worth JJ
noting VBG
that IN
while IN
we PRP
have VBP
presented VBN
the DT
use NN
of IN
edge-based JJ
best-first JJ
chart NN
parsing NN
in IN
the DT
service NN
of IN
a DT
rather RB
pure JJ
form NN
of IN
pcfg NN
parsing NN
, ,
there EX
is VBZ
no DT
particular JJ
reason NN
to TO
assume VB
that IN
the DT
technique NN
is VBZ
so RB
limited JJ
in IN
its PRP$
domain NN
of IN
applicability NN
. .

one CD
can MD
imagine VB
the DT
same JJ
techniques NNS
coupled VBN
with IN
more RBR
informative JJ
probability NN
distributions NNS
, ,
such JJ
as IN
lexicalized JJ
pcfgs NN
< NNP
ref NN
> NNP
charniak NN
, ,
1997 CD
< NN
/ref NNP
> NNP
, ,
or CC
even RB
grammars NNS
not RB
based VBN
upon IN
literal JJ
rules NNS
, ,
but CC
probability NN
distributions NNS
that WDT
describe VBP
how WRB
rules NNS
are VBP
built VBN
up RP
from IN
smaller JJR
components NNS
< VBP
tref JJ
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
collins NNS
, ,
1997 CD
< NN
/ref NNP
> NNP
. .

clearly RB
further JJ
research NN
is VBZ
warranted VBN
. .

be VB
this DT
as IN
it PRP
may MD
, ,
the DT
take-home JJ
lesson NN
from IN
this DT
paper NN
is VBZ
simple JJ
: :
combining VBG
an DT
edge-based JJ
agenda NN
with IN
the DT
figure NN
of IN
merit NN
from IN
cc NN
is VBZ
easy JJ
to TO
do VB
by IN
simply RB
binarizing VBG
the DT
grammar NN
provides VBZ
a DT
factor NN
of IN
20 CD
or CC
so RB
reduction NN
in IN
the DT
number NN
of IN
edges NNS
required VBN
to TO
find VB
a DT
first JJ
parse NN
, ,
and CC
improves VBZ
parsing VBG
precision NN
and CC
recall NN
over IN
exhaustive JJ
parsing NN
. .

uk JJ
black JJ
, ,
eubank JJ
, ,
kashiokaatritlcojp VB
gleechocentllancsacuk NN
1 CD
introduction NN
a DT
treebank NN
is VBZ
a DT
body NN
of IN
natural JJ
language NN
text NN
which WDT
has VBZ
been VBN
grammatically RB
annotated VBN
by IN
hand NN
, ,
in IN
terms NNS
of IN
some DT
previously-established JJ
scheme NN
of IN
grammatical JJ
analysis NN
. .

treebanks NNS
have VBP
been VBN
used VBN
within IN
the DT
field NN
of IN
natural JJ
language NN
processing NN
as IN
a DT
source NN
of IN
training NN
data NNS
for IN
statistical JJ
part NN
og NN
speech NN
taggers NNS
< VBP
ref JJ
> NNP
black JJ
et NN
al NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
brill NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
merialdo NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
weischedel NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
and CC
for IN
statistical JJ
parsers NNS
< VBP
ref JJ
> NNP
black JJ
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
brill NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
aelinek JJ
et FW
al NN
, ,
1994 CD
; :
< CC
tref VB
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
magerman NN
and CC
marcus NN
, ,
1991 CD
< NN
/ref NNP
> NNP
. .

in IN
this DT
article NN
, ,
we PRP
present VBP
the DT
atr/lancaster NN
7reebauk CD
of IN
american JJ
english NN
, ,
a DT
new JJ
resource NN
tbr NN
natural-language- JJ
, ,
processing VBG
research NN
, ,
which WDT
has VBZ
been VBN
prepared VBN
by IN
lancaster JJR
university NN
uks JJ
unit NN
for IN
computer NN
research NN
on IN
the DT
english JJ
language NN
, ,
according VBG
to TO
specifications NNS
provided VBN
by IN
atr JJ
japans NNS
statistical JJ
parsing VBG
group NN
. .

moreover RB
, ,
the DT
results NNS
of IN
a DT
less-than-optimal JJ
version NN
of IN
dop NN
on IN
the DT
wall JJ
street NN
journal JJ
corpus NN
suggest VBP
that IN
the DT
approach NN
can MD
be VB
succesfully RB
extended VBN
to TO
larger JJR
domains NNS
. .

as IN
future JJ
research NN
, ,
we PRP
will MD
apply VB
the DT
full JJ
dop NN
model NN
on IN
wsj NN
word NN
strings NNS
in IN
order NN
to TO
compare VB
our PRP$
results NNS
with IN
the DT
best JJS
known JJ
parsers NNS
on IN
this DT
domain NN
< NNP
tref NN
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
collins NNS
, ,
1996 CD
< NN
/ref NNP
> NNP
. .

acknowledgements NNS
i VBP
am VBP
grateful JJ
to TO
remko VB
scha NN
for IN
many JJ
useful JJ
comments NNS
and CC
additions NNS
. .

i NN
also RB
thank VBD
three CD
anonymous JJ
reviewers NNS
for IN
their PRP$
comments NNS
. .

the DT
latter JJ
approach NN
has VBZ
become VBN
increasingly RB
popular JJ
eg NN
< NNP
ref NN
> NNP
schabes VBZ
et FW
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
weischedel NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
briscoe NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
collins NNS
, ,
1996 CD
< NN
/ref NNP
> NNP
. .

we PRP
calculate VBP
the DT
precision NN
, ,
recall NN
, ,
and CC
fscore RB
; :
however RB
for IN
brevitys NNS
sake VBP
we PRP
only RB
report VBD
the DT
f-score NN
for IN
most JJS
experiments NNS
in IN
this DT
section NN
. .

in IN
addition NN
to TO
antecedent VB
recovery NN
, ,
we PRP
also RB
report VBP
parsing VBG
accuracy NN
, ,
using VBG
the DT
bracketing VBG
f-score NN
, ,
the DT
combined JJ
measure NN
of IN
parseval-style NN
labeled VBN
bracketing NN
precision NN
and CC
recall VB
< NNP
tref JJ
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
. .

figure NN
9 CD
shows VBZ
that IN
the DT
perfect JJ
scheme NN
would MD
achieve VB
roughly RB
93 CD
precision NN
and CC
recall NN
, ,
which WDT
is VBZ
a DT
dramatic JJ
increase NN
over IN
the DT
top JJ
1 CD
accuracy NN
of IN
87 CD
precision NN
and CC
86 CD
recall NN
. .

figure NN
10 CD
shows VBZ
that IN
the DT
exact JJ
match NN
, ,
which WDT
counts VBZ
the DT
percentage NN
of IN
times NNS
2results CD
for IN
spatter NN
on IN
section NN
23 CD
are VBP
reported VBN
in IN
< NNP
ref NN
> NN
collins NNS
, ,
1996 CD
< NN
/ref NNP
> NNP
< NNP
/ref NNP
> NNP
parser NN
precision NN
maximum JJ
entropy JJ
868 CD
maximum JJ
entropy NN
875 CD
< NN
ref NN
> NN
collins NNS
, ,
1996 CD
< NN
/ref NNP
> NNP
< NNP
/ref NNP
> VBD
857 CD
< NNP
tref NN
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> VBZ
843 CD
recall NN
856 CD
863 CD
853 CD
840 CD
table JJ
5 CD
: :
results NNS
on IN
2416 CD
sentences NNS
of IN
section NN
23 CD
0 CD
to TO
100 CD
words NNS
in IN
length NN
of IN
the DT
wsj NN
treebank NN
. .

evaluations NNS
marked VBD
with IN
collapse NN
the DT
distinction NN
between IN
advp NN
and CC
prt NN
, ,
and CC
ignore RB
all DT
punctuation NN
. .

the DT
parseval JJ
black JJ
and CC
others NNS
, ,
1991 CD
measures NNS
compare VBP
a DT
proposed JJ
parse NN
p NN
with IN
the DT
corresponding VBG
correct JJ
treebank JJ
parse NN
t NN
as IN
follows VBZ
: :
correct JJ
constituents NNS
in IN
p NN
recall NN
constituents NNS
in IN
t NN
correct NN
constituents NNS
in IN
p JJ
precision NN
constituents NNS
in IN
p NN
a DT
constituent NN
in IN
p NN
is VBZ
correct JJ
if IN
there EX
exists VBZ
a DT
constituent NN
in IN
t NN
of IN
the DT
same JJ
label NN
that WDT
spans VBZ
the DT
same JJ
words NNS
. .

table JJ
5 CD
shows NNS
results NNS
using VBG
the DT
parseval NN
measures NNS
, ,
as RB
well RB
as IN
results NNS
using VBG
the DT
slightly RB
more RBR
forgiving JJ
measures NNS
of IN
< NNP
ref NN
> NN
collins NNS
, ,
1996 CD
< NN
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
. .

table JJ
5 CD
shows NNS
that IN
the DT
maximum JJ
entropy NN
parser NN
performs NNS
better RBR
than IN
the DT
parsers NNS
presented VBN
in IN
< NNP
ref NN
> NN
collins NNS
, ,
1996 CD
< NN
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
, ,
which WDT
have VBP
the DT
best JJS
previously RB
published VBN
parsing VBG
accuracies NNS
on IN
the DT
wall NN
st VBZ
journal JJ
domain NN
. .

it PRP
is VBZ
often RB
advantageous JJ
to TO
produce VB
the DT
top JJ
n NN
parses NNS
instead RB
of IN
just RB
the DT
top JJ
1 CD
, ,
since IN
additional JJ
information NN
can MD
be VB
used VBN
in IN
a DT
secondary JJ
model NN
that WDT
reorders VBZ
the DT
top JJ
n NN
and CC
hopefully RB
improves VBZ
the DT
quality NN
of IN
the DT
top JJ
ranked JJ
parse NN
. .

table JJ
5 CD
shows NNS
results NNS
using VBG
the DT
parseval NN
measures NNS
, ,
as RB
well RB
as IN
results NNS
using VBG
the DT
slightly RB
more RBR
forgiving JJ
measures NNS
of IN
< NNP
ref NN
> NN
collins NNS
, ,
1996 CD
< NN
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
. .

table JJ
5 CD
shows NNS
that IN
the DT
maximum JJ
entropy NN
parser NN
performs NNS
better RBR
than IN
the DT
parsers NNS
presented VBN
in IN
< NNP
ref NN
> NN
collins NNS
, ,
1996 CD
< NN
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
, ,
which WDT
have VBP
the DT
best JJS
previously RB
published VBN
parsing VBG
accuracies NNS
on IN
the DT
wall NN
st VBZ
journal JJ
domain NN
. .

it PRP
is VBZ
often RB
advantageous JJ
to TO
produce VB
the DT
top JJ
n NN
parses NNS
instead RB
of IN
just RB
the DT
top JJ
1 CD
, ,
since IN
additional JJ
information NN
can MD
be VB
used VBN
in IN
a DT
secondary JJ
model NN
that WDT
reorders VBZ
the DT
top JJ
n NN
and CC
hopefully RB
improves VBZ
the DT
quality NN
of IN
the DT
top JJ
ranked JJ
parse NN
. .

suppose RB
there EX
exists VBZ
a DT
perfect JJ
reranking NN
scheme NN
that IN
, ,
for IN
each DT
sentence NN
, ,
magically RB
picks VBZ
the DT
best JJS
parse NN
from IN
the DT
top JJ
n NN
parses NNS
produced VBN
by IN
the DT
maximum JJ
entropy NN
parser NN
, ,
where WRB
the DT
best JJS
parse NN
has VBZ
the DT
highest JJS
average JJ
precision NN
and CC
recall NN
when WRB
compared VBN
to TO
the DT
treebank NN
parse NN
. .

the DT
algorithm NN
exploits VBZ
robust JJ
lexical JJ
, ,
syntactic JJ
, ,
and CC
semantic JJ
knowledge NN
sources NNS
. .

i JJ
introduction VBP
the DT
application NN
of IN
decision-based JJ
learning VBG
techniques NNS
over IN
rich JJ
sets NNS
of IN
linguistic JJ
features NNS
has VBZ
improved VBN
significantly RB
the DT
coverage NN
and CC
performance NN
of IN
syntactic JJ
and CC
to TO
various JJ
degrees NNS
semantic JJ
parsers NNS
< VBP
ref JJ
> NNP
simmons NNS
and CC
yu NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
hermjakob NN
and CC
mooney NN
, ,
1997 CD
< NN
/ref NNP
> NNP
. .

in IN
this DT
paper NN
, ,
we PRP
apply VBP
a DT
similar JJ
paradigm NN
to TO
developing VBG
a DT
rhetorical JJ
parser NN
that WDT
derives VBZ
the DT
discourse JJ
structure NN
of IN
unrestricted JJ
texts NN
. .

crucial JJ
to TO
our PRP$
approach NN
is VBZ
the DT
reliance NN
on IN
a DT
corpus NN
of IN
90 CD
texts NNS
which WDT
were VBD
manually RB
annotated VBN
with IN
discourse NN
trees NNS
and CC
the DT
adoption NN
of IN
a DT
shift-reduce JJ
parsing NN
model NN
that WDT
is VBZ
well-suited JJ
for IN
learning VBG
. .

if IN
an DT
erroneous JJ
string NN
is VBZ
extracted VBN
, ,
its PRP$
errors NNS
will MD
propagate VB
through IN
the DT
rest NN
of IN
the DT
input NN
: :
trings NNS
. .

:3 VB
our PRP$
approach NN
31 CD
the DT
c45 NN
learning VBG
algorithm JJ
decision NN
tree NN
induction NN
algorithms NNS
have VBP
been VBN
successfully RB
applied VBN
for IN
nlp JJ
problems NNS
such JJ
as IN
sentence NN
boundary JJ
dismnbiguation NN
< NNP
ref NN
> NNP
pahner NN
et NN
al NN
1997 CD
< NNP
/ref NNP
> NNP
, ,
parsing VBG
< JJ
tref NN
> NNP
magerman NN
1995 CD
< NNP
/tref NNP
> NNP
and CC
word NN
segmentation NN
< NNP
ref NN
> NNP
mekuavin NN
et NN
al NN
1997 CD
< NNP
/ref NNP
> NNP
. .

we PRP
employ VBP
the DT
c45 NN
< NNP
ref NN
> NNP
quinhln NN
1993 CD
< NNP
/ref NNP
> NNP
decision NN
tree JJ
induction NN
program NN
as IN
the DT
learning NN
algorithm NN
for IN
word NN
extraction NN
. .

the DT
induction NN
algorithm NN
proceeds NNS
by IN
evaluating VBG
content NN
of IN
a DT
series NN
of IN
attributes NNS
and CC
iteratively RB
building VBG
a DT
tree NN
fiom VBZ
the DT
attribute NN
values NNS
with IN
the DT
leaves NNS
of IN
the DT
decision NN
tree NN
being VBG
the DT
value NN
of IN
the DT
goal NN
attribute NN
. .

by IN
implementing VBG
our PRP$
own JJ
version NN
of IN
the DT
publicly RB
available JJ
collins NNS
parser VBP
< JJ
ref NN
> NN
collins NNS
, ,
1996 CD
< NN
/ref NNP
> NNP
, ,
we PRP
also RB
learned VBD
a DT
dependency NN
model NN
that WDT
enables VBZ
the DT
mapping NN
of IN
parse NN
trees NNS
into IN
sets NNS
of IN
binary JJ
relations NNS
between IN
the DT
head-word NN
of IN
each DT
constituent NN
and CC
its PRP$
sibling-words NNS
. .

dogs NNS
iditarodcount VBP
pull NN
sled VBN
in IN
the DT
structure NN
above IN
, ,
count NN
represents VBZ
the DT
expected JJ
answer NN
type NN
, ,
replacing VBG
the DT
question NN
stem VBD
how WRB
many JJ
. .

one CD
is VBZ
a DT
full JJ
parser NN
of IN
english JJ
, ,
using VBG
a DT
statistically RB
learned VBN
decision NN
procedure NN
; :
spatter NN
has VBZ
achieved VBN
the DT
highest JJS
scores NNS
yet RB
reported VBN
on IN
parsing VBG
english JJ
text NN
< NNP
tref NN
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
. .

because IN
the DT
measurable JJ
improvement NN
in IN
parsing NN
is VBZ
so RB
great JJ
compared VBN
to TO
manually RB
constructed JJ
parsers NNS
, ,
it PRP
appears VBZ
to TO
offer VB
a DT
qualitatively RB
better RBR
parser NN
. .

we PRP
are VBP
looking VBG
ormat IN
de FW
scription NN
message NN
message NN
reader NN
i JJ
m VBP
orphologieal JJ
analyzer NN
lexieai NN
pattern NN
matcher PRP
fast VBP
partial JJ
parser NN
semantic JJ
interpreter NN
entene VBD
e-level JJ
pattern NN
matcher PRP$
discourse JJ
format NN
s NN
gml NN
handling VBG
initial JJ
iden JJ
tification NN
of IN
entities NNS
grouping VBG
words NNS
into IN
meaningful JJ
phrases NNS
establish VB
relationships NNS
within IN
sentences NNS
establish VB
relationships NNS
overall JJ
-- :
-- :
template/annotation NN
generator NN
i NN
output NN
entities NNS
and CC
relationships NNS
output NN
figure NN
2 CD
: :
plum NN
system NN
architecture NN
: :
rectangles NNS
represent VBP
domain-independent JJ
, ,
language-independent JJ
algorithms NN
; :
ovals NNS
represent VBP
knowledge NN
bases NNS
. .

for IN
example NN
, ,
statistical JJ
techniques NNS
may MD
have VB
suggested VBN
the DT
importance NN
of IN
hire NN
, ,
a DT
verb NN
which WDT
many JJ
groups NNS
did VBD
not RB
happen VB
to TO
define VB
. .

second NN
, ,
since IN
there EX
has VBZ
been VBN
a DT
marked JJ
improvement NN
in IN
the DT
quality NN
of IN
full JJ
parsers NNS
, ,
now RB
achieving VBG
an DT
f NN
in IN
the DT
high JJ
80s CD
< JJ
tref NN
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
, ,
we PRP
believe VBP
it PRP
is VBZ
now RB
feasible JJ
to TO
consider VB
using VBG
full JJ
parsers NNS
again RB
. .

the DT
rationale NN
is VBZ
straightforward JJ
: :
for IN
full JJ
templates NNS
eg VBP
, ,
st JJ
scores NNS
have VBP
been VBN
mired VBN
with IN
an DT
f NN
in IN
the DT
50s CD
ever RB
since IN
muc-3 NN
in IN
1991 CD
. .

pattern NN
matching NN
has VBZ
given VBN
us PRP
very RB
robust JJ
, ,
very RB
portable JJ
technology NN
, ,
but CC
has VBZ
not RB
broken VBN
the DT
performance NN
barrier NN
all DT
systems NNS
have VBP
run VBN
up RP
against IN
. .

however RB
, ,
unlike IN
the DT
models NNS
of IN
< NNP
ref NN
> NNP
black JJ
1993 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
tref VBZ
> NNP
magerman NN
1995 CD
< NNP
/tref NNP
> NNP
, ,
and CC
< NNP
ref VBP
> NN
collins NNS
1996 CD
< NNP
/ref NNP
> NNP
, ,
we PRP
put VBD
an DT
assumption NN
that IN
syntactic JJ
and CC
lexical/semantie JJ
features NNS
are VBP
independent JJ
. .

then RB
, ,
we PRP
focus VBP
on IN
extracting VBG
lexical/semantic JJ
collocational JJ
knowledge NN
of IN
verbs NN
which WDT
is VBZ
useful JJ
in IN
syntactic JJ
analysis NN
. .

in IN
those DT
research NN
, ,
extracted VBD
lexical/semantic JJ
collocation NN
is VBZ
especially RB
useful JJ
in IN
terms NNS
of IN
ranking VBG
parses NNS
in IN
syntactic JJ
analysis NN
as RB
well RB
as IN
automatic JJ
construction NN
of IN
lexicon NN
for IN
nlp NN
. .

for IN
example NN
, ,
in IN
the DT
context NN
of IN
syntactic JJ
disambiguation NN
, ,
< NNP
ref VBZ
> NNP
black JJ
1993 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NNP
magerman NN
1995 CD
< NNP
/tref NNP
> NNP
proposed VBD
statistical JJ
parsing NN
models NNS
based-on JJ
decision-tree JJ
learning NN
techniques NNS
, ,
which WDT
incorporated VBD
not RB
only RB
syntactic JJ
but CC
also RB
lexical/semantic JJ
information NN
in IN
the DT
decision-trees NNS
. .

the DT
key NN
to TO
extraction NN
of IN
the DT
relations NNS
is VBZ
that IN
any DT
phrase NN
can MD
be VB
substituted VBN
by IN
the DT
corresponding JJ
tree JJ
head-word JJ
links NNS
marked VBD
bold JJ
in IN
figure NN
1 CD
. .

because IN
we PRP
assumed VBD
that IN
the DT
relations NNS
within IN
the DT
same JJ
phrase NN
are VBP
independent JJ
, ,
all PDT
the DT
relations NNS
are VBP
between IN
the DT
modifier NN
constituents NNS
and CC
the DT
head NN
of IN
a DT
phrase NN
only RB
. .

when WRB
inspecting VBG
manually RB
, ,
the DT
binary JJ
word NN
tree NN
representation NN
appears VBZ
to TO
be VB
the DT
most RBS
easy JJ
to TO
understand VB
. .

in IN
this DT
case NN
it PRP
is VBZ
necessary JJ
to TO
use VB
a DT
hard-clustering JJ
method NN
, ,
such JJ
that IN
a DT
binary JJ
word NN
tree NN
can MD
be VB
constructed VBN
by IN
the DT
clustering NN
process NN
, ,
as IN
we PRP
did VBD
in IN
the DT
example NN
in IN
the DT
previous JJ
sections NNS
. .

we PRP
present VBP
a DT
hard JJ
clustering NN
algorithm NN
, ,
in IN
the DT
sense NN
that WDT
every DT
word NN
belongs VBZ
to TO
exactly RB
one CD
cluster NN
or CC
is VBZ
one CD
leaf NN
in IN
the DT
binary JJ
word-tree NN
of IN
a DT
particular JJ
part NN
of IN
speech NN
. .

these DT
results NNS
have VBP
important JJ
implications NNS
for IN
crosslinguistic JJ
parsing NN
research NN
, ,
as IN
they PRP
allow VBP
us PRP
to TO
tease VB
apart RB
language-specific JJ
and CC
annotationspecific JJ
effects NNS
. .

previous JJ
work NN
for IN
english JJ
eg NN
, ,
< NNP
tref VBZ
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
collins NNS
, ,
1997 CD
< NN
/ref NNP
> NNP
has VBZ
shown VBN
that IN
lexicalization NN
leads VBZ
to TO
a DT
sizable JJ
improvement NN
in IN
parsing VBG
performance NN
. .

research NN
on IN
german JJ
< NNP
ref NN
> NNP
dubey NN
and CC
keller NN
, ,
2003 CD
< NN
/ref NNP
> NN
showed VBD
that IN
lexicalization NN
leads VBZ
to TO
no DT
sizable JJ
improvement NN
in IN
parsing VBG
performance NN
for IN
this DT
language NN
. .

algorithms NN
for IN
decision NN
tree NN
induction NN
< NNP
ref NN
> NNP
quinlan NN
1986 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
bahl NN
et NN
al NN
1989 CD
< NNP
/ref NNP
> NNP
have VBP
been VBN
successfully RB
applied VBN
to TO
nlp VB
problems NNS
such JJ
as IN
parsing VBG
< NNP
ref NN
> NNP
resnik NN
1993 CD
< NNP
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
magerman NN
1995 CD
< NNP
/tref NNP
> NNP
and CC
discourse JJ
analysis NN
< NNP
ref NN
> NNP
siegel NN
and CC
mckeown JJ
1994 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
soderland NN
and CC
lehnert JJ
1994 CD
< NNP
/ref NNP
> NNP
. .

we PRP
tested VBD
the DT
satz NN
system NN
using VBG
the DT
c45 NN
< NNP
ref NN
> NNP
quinlan NN
1993 CD
< NNP
/ref NNP
> NNP
decision NN
tree JJ
induction NN
program NN
as IN
the DT
learning NN
algorithm NN
and CC
compared VBN
the DT
results NNS
to TO
those DT
obtained VBN
previously RB
with IN
the DT
neural JJ
network NN
. .

in IN
order NN
to TO
construct VB
the DT
etrees NNS
, ,
which WDT
make VBP
such JJ
distinction NN
, ,
lextract JJ
requires VBZ
its PRP$
user NN
to TO
provide VB
additional JJ
information NN
in IN
the DT
form NN
of IN
three CD
tables NNS
: :
a DT
head NN
percolation NN
table NN
, ,
an DT
argument NN
table NN
, ,
and CC
a DT
tagset NN
table NN
. .

they PRP
consider VBP
systematically RB
a DT
number NN
of IN
alternative JJ
probao NN
bilistic JJ
formulations NNS
, ,
including VBG
those DT
of IN
< JJ
ref NN
> NNP
resnik NN
1992 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
ref VBP
> NNP
schabes NN
1992 CD
< NNP
/ref NNP
> NNP
and CC
implemented VBN
systems NNS
based VBN
on IN
other JJ
underlying JJ
grammatical JJ
frameworks NNS
, ,
evaluating VBG
their PRP$
adequacy NN
from IN
both CC
a DT
theoretical JJ
and CC
empirical JJ
perspective NN
in IN
terms NNS
of IN
their PRP$
ability NN
to TO
model VB
particular JJ
distributions NNS
of IN
data NNS
that WDT
occur VBP
in IN
existing VBG
treebanks NNS
. .

< JJ
tref NN
> NNP
magerman NN
1995 CD
< NNP
/tref NNP
> NNP
, ,
< NNP
ref VBZ
> CD
collins NNS
1996 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> CD
ratnaparkhi NN
1997 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> CD
charniak NN
1997 CD
< NNP
/ref NNP
> NNP
and CC
others NNS
describe VBP
implemented VBN
systems NNS
with IN
impressive JJ
accuracy NN
on IN
parsing VBG
unseen JJ
data NNS
from IN
the DT
penn NN
treebank NN
< NNP
ref NN
> NNP
marcus NN
, ,
santorini NN
marcinkiewicz NN
, ,
1993 CD
< NN
/ref NNP
> NNP
. .

the DT
accuracies NNS
reported VBD
for IN
these DT
systems NNS
are VBP
substantially RB
better JJR
than IN
their PRP$
non-lexicalised JJ
probabilistic JJ
context-free JJ
grammar NN
analogues NNS
, ,
demonstrating VBG
clearly RB
the DT
value NN
of IN
lexico-statistical JJ
information NN
. .

in IN
our PRP$
experiments NNS
, ,
the DT
window NN
starts VBZ
al IN
the DT
sentence NN
prior RB
to TO
that DT
containing VBG
the DT
token NN
and CC
extends VBZ
back RB
w WP
the DT
window NN
size NN
sentences NNS
. .

the DT
choice NN
to TO
use VB
sentences NNS
as IN
the DT
unit NN
of IN
distance NN
is VBZ
motivated VBN
by IN
our PRP$
intention NN
to TO
incorporale JJ
triggers NNS
of IN
this DT
form NN
into IN
a DT
probabilistie NN
treebank NN
based VBN
parser NN
and CC
tagger NN
, ,
sneh NN
as IN
< JJ
ref NN
> NNP
black JJ
et NN
al NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
black JJ
et NN
al NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
brill NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
collins NNS
, ,
1996 CD
< NN
/ref CC
> NN
: :
aelinek NN
et NN
al NN
, ,
1994 CD
; :
< CC
tref VB
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
blatnaparkhi NN
, ,
1997 CD
. .

all DT
su JJ
< NNP
h NN
parsers NNS
and CC
taggers NNS
of IN
which WDT
we PRP
are VBP
aware JJ
use IN
only RB
intrasentential JJ
information NN
in IN
predicting VBG
parses NNS
or CC
tags NNS
, ,
and CC
we PRP
wish VBP
to TO
remove VB
this DT
information NN
, ,
as RB
far RB
as IN
possible JJ
, ,
from IN
our PRP$
results NNS
; :
the DT
window NN
was VBD
not RB
allowed VBN
to TO
cross VB
a DT
document NN
bmndary NN
. .

second JJ
, ,
one CD
might MD
propagate VB
lexical JJ
information NN
upward RB
through IN
the DT
productions NNS
. .

a DT
more RBR
linguistically RB
motivated JJ
approach NN
is VBZ
to TO
expand VB
the DT
domain NN
of IN
productions NNS
downward VBP
to TO
incorporate VB
more JJR
tree JJ
structures NNS
. .

for IN
each DT
word NN
a45 NN
, ,
the DT
upper-most JJ
node NN
with IN
lexical JJ
head NN
a45 NN
which WDT
has VBZ
a DT
right JJ
sibling NN
node NN
determines VBZ
the DT
features NNS
on IN
the DT
basis NN
of IN
which WDT
we PRP
decide VBP
whether IN
to TO
insert VB
a DT
discourse JJ
boundary NN
. .

coming VBG
to TO
this DT
problem NN
from IN
the DT
standpoint NN
of IN
tree JJ
transformation NN
, ,
we PRP
naturally RB
view VBP
our PRP$
work NN
as IN
a DT
descendent NN
of IN
< NNP
ref NN
> NNP
johnson NN
1998 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
ref VBP
> NNP
klein NN
and CC
manning NN
2003 CD
< NNP
/ref NNP
> NNP
. .

in IN
retrospect NN
, ,
however RB
, ,
there EX
are VBP
perhaps RB
even RB
greater JJR
similarities NNS
to TO
that DT
of IN
< NNP
tref NN
> NNP
magerman NN
, ,
1995 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
henderson NN
, ,
2003 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
matsuzaki NN
et NN
al NN
, ,
2005 CD
< NN
/ref NNP
> NNP
. .

we PRP
would MD
like VB
to TO
infer VB
the DT
number NN
of IN
annotations NNS
for IN
each DT
nonterminal JJ
automatically RB
. .

however RB
, ,
again RB
in IN
retrospect NN
, ,
it PRP
is VBZ
in IN
the DT
work NN
of IN
< JJ
tref NN
> NNP
magerman NN
1995 CD
< NNP
/tref NNP
> VBZ
that IN
we PRP
see VBP
the DT
greatest JJS
similarity NN
. .

perhaps RB
a DT
more RBR
substantial JJ
difference NN
is VBZ
that IN
by IN
not RB
casting VBG
his PRP$
problem NN
as IN
one CD
of IN
learning VBG
phrasal JJ
categories NNS
magerman VBP
loses VBZ
all DT
of IN
the DT
free JJ
pcfg NN
technology NN
that IN
we PRP
can MD
leverage VB
. .

our PRP$
experiment NN
quantitatively RB
analyzes VBZ
several JJ
feature NN
types NNS
power NN
for IN
syntactic JJ
structure NN
prediction NN
and CC
draws VB
a DT
series NN
of IN
interesting JJ
conclusions NNS
. .

the DT
paper NN
proposes VBZ
an DT
information-theory-based JJ
feature NN
types NNS
analysis NN
model NN
, ,
which WDT
uses VBZ
the DT
measures NNS
of IN
predictive JJ
information NN
quantity NN
, ,
predictive JJ
information NN
gain NN
, ,
predictive JJ
information NN
redundancy NN
and CC
predictive JJ
information NN
summation NN
to TO
quantitatively RB
analyse VB
the DT
different JJ
contextual JJ
feature NN
types NNS
or CC
feature NN
types NNS
combinations NNS
predictive VBP
power NN
for IN
syntactic JJ
structure NN
. .

pf NN
model NN
describes VBZ
the DT
probability NN
of IN
each DT
feature NN
in IN
feature NN
set VBN
fs NN
taking VBG
on IN
specific JJ
values NNS
when WRB
a DT
cfg NN
rule NN
a DT
- :
> NN
is VBZ
given VBN
. .

to TO
make VB
the DT
model NN
more RBR
practical JJ
in IN
parameter NN
estimation NN
, ,
we PRP
assume VBP
the DT
features NNS
in IN
feature NN
set VBN
fs NNS
are VBP
independent JJ
from IN
each DT
other JJ
, ,
thus RB
: :
fsfi NN
afipafsp NN
, ,
, ,
5 CD
under IN
this DT
pcfgpf NN
model NN
, ,
the DT
goal NN
of IN
a DT
parser NN
is VBZ
to TO
choose VB
a DT
parse NN
that WDT
maximizes VBZ
the DT
following JJ
score NN
: :
, ,
maxarg VBZ
1 CD
afs NN
i NN
i VBP
i VBP
n VBP
i JJ
t VBP
pstscore RB
6 CD
our PRP$
model NN
is VBZ
thus RB
a DT
simplification NN
of IN
more RBR
sophisticated JJ
models NNS
which WDT
integrate VBP
pcfgs NN
with IN
features NNS
, ,
such JJ
as IN
those DT
in IN
< JJ
tref NN
> NNP
magerman1995 NN
< NNP
/tref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
collins1997 NN
< NNP
/ref NNP
> NNP
and CC
< NNP
ref VBP
> NNP
goodman1997 NN
< NNP
/ref NNP
> NNP
. .

compared VBN
with IN
these DT
models NNS
, ,
our PRP$
model NN
is VBZ
more RBR
practical JJ
when WRB
only RB
small JJ
training NN
data NNS
is VBZ
available JJ
, ,
since IN
we PRP
assume VBP
the DT
independence NN
between IN
features NNS
. .

other JJ
studies NNS
have VBP
shown VBN
that IN
when WRB
both DT
speech NN
and CC
text NN
are VBP
available JJ
to TO
labelers NNS
, ,
segmentation NN
is VBZ
clearer JJR
< JJ
ref NN
> NN
swerts NNS
1995 CD
< NNP
/ref NNP
> NNP
and CC
reliability NN
improves VBZ
< NNP
tref NN
> NNP
hirschberg NN
and CC
nakatani JJ
1996 CD
< NNP
/tref NNP
> NNP
. .

recall NN
precision NN
fallout IN
error NN
summed VBN
deviation NN
pause NN
92 CD
18 CD
54 CD
49 CD
193 CD
cue NN
72 CD
15 CD
53 CD
50 CD
216 CD
np JJ
50 CD
31 CD
15 CD
19 CD
153 CD
humans NNS
74 CD
55 CD
09 CD
11 CD
91 CD
if IN
cue1 VBN
true JJ
then RB
boundary JJ
else RB
nonboundary JJ
figure NN
11 CD
cue NN
word NN
algorithm NN
. .

< JJ
ref NN
> NN
in IN
grosz NN
and CC
hirschberg NN
1992 CD
< NNP
/ref NNP
> NNP
, ,
percent NN
agreement NN
see VBP
section NN
32 CD
among IN
7 CD
coders NNS
on IN
3 CD
texts NNS
under IN
two CD
conditions NNS
-- :
text JJ
plus CC
speech NN
or CC
text NN
alone RB
-- :
is VBZ
reported VBN
at IN
levels NNS
ranging VBG
from IN
743 CD
to TO
951 CD
. .

< JJ
ref NN
> NN
in IN
hirschberg NN
and CC
nakatani JJ
1996 CD
< NNP
/ref NNP
> NNP
, ,
average JJ
reliability NN
measured VBN
using VBG
the DT
kappa NN
coefficient NN
discussed VBN
in IN
carletta NN
1996 CD
of IN
segmentinitial JJ
labels NNS
among IN
3 CD
coders NNS
on IN
9 CD
monologues NNS
produced VBN
by IN
the DT
same JJ
speaker NN
, ,
labeled VBD
using VBG
text NN
and CC
speech NN
, ,
is8 NN
or CC
above NN
for IN
both DT
read JJ
and CC
spontaneous JJ
speech NN
; :
values NNS
of IN
at IN
least JJS
8 CD
are VBP
typically RB
viewed VBN
as IN
representing VBG
high JJ
reliability NN
see VBP
section NN
32 CD
. .

< JJ
ref NN
> NNP
wilson NN
and CC
wiebe NN
2005 CD
< NNP
/ref NNP
> NNP
extend VBP
this DT
basic JJ
annotation NN
scheme NN
to TO
include VB
different JJ
types NNS
of IN
subjectivity NN
, ,
including VBG
positive JJ
sentiment NN
, ,
negative JJ
sentiment NN
, ,
positive JJ
arguing NN
, ,
and CC
negative JJ
arguing NN
. .

speech NN
was VBD
found VBN
to TO
improve VB
inter-annotator NN
agreement NN
in IN
discourse JJ
segmentation NN
of IN
monologs NNS
< NNP
tref NN
> NNP
hirschberg NN
and CC
nakatani JJ
1996 CD
< NNP
/tref NNP
> NNP
. .

acoustic JJ
clues NNS
have VBP
been VBN
successfully RB
employed VBN
for IN
the DT
reliable JJ
detection NN
of IN
the DT
speakers NNS
emotions NNS
, ,
including VBG
frustration NN
, ,
annoyance NN
, ,
anger NN
, ,
happiness NN
, ,
sadness NN
, ,
and CC
boredom NN
< NNP
ref NN
> NNP
liscombe VBZ
et FW
al NN
2003 CD
< NNP
/ref NNP
> NNP
. .

61 CD
reader NN
judgments NNS
there EX
is VBZ
a DT
growing VBG
concern NN
surrounding VBG
issues NNS
of IN
intercoder NN
reliability NN
when WRB
using VBG
human JJ
judgments NNS
to TO
evaluate VB
discourse-processing JJ
algorithms NNS
< VBP
ref JJ
> NNP
carletta NN
1996 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
condon NN
and CC
cech NN
1995 CD
< NNP
/ref NNP
> NNP
. .

proposals NNS
have VBP
recently RB
been VBN
made VBN
for IN
protocols NNS
for IN
the DT
collection NN
of IN
human JJ
discourse NN
segmentation NN
data NNS
< NNP
ref NN
> NNP
nakatani CC
et RB
al JJ
1995 CD
< NNP
/ref NNP
> NNP
and CC
for IN
how WRB
to TO
evaluate VB
the DT
validity NN
of IN
judgments NNS
so RB
obtained JJ
< NNP
ref NN
> NNP
carletta NN
1996 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
isard NN
and CC
carletta NN
1995 CD
< NNP
/ref NNP
> NNP
; :
ros6 JJ
1995 CD
; :
< CC
ref VB
> NNP
passonneau NN
and CC
litman JJ
1993 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
litman NN
and CC
passonneau NN
1995 CD
< NNP
/ref NNP
> NNP
. .

recently RB
, ,
hirschberg VBD
52 CD
< NNP
ref NN
> NNP
hearst NN
texttiling NN
and CC
nakatani JJ
1996 CD
< NNP
/ref NNP
> NNP
have VBP
reported VBN
promising JJ
results NNS
for IN
obtaining VBG
higher JJR
interjudge NN
agreement NN
using VBG
their PRP$
collection NN
protocols NNS
. .

proposals NNS
have VBP
recently RB
been VBN
made VBN
for IN
protocols NNS
for IN
the DT
collection NN
of IN
human JJ
discourse NN
segmentation NN
data NNS
< NNP
ref NN
> NNP
nakatani CC
et RB
al JJ
1995 CD
< NNP
/ref NNP
> NNP
and CC
for IN
how WRB
to TO
evaluate VB
the DT
validity NN
of IN
judgments NNS
so RB
obtained JJ
< NNP
ref NN
> NNP
carletta NN
1996 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
isard NN
and CC
carletta NN
1995 CD
< NNP
/ref NNP
> NNP
; :
ros6 JJ
1995 CD
; :
< CC
ref VB
> NNP
passonneau NN
and CC
litman JJ
1993 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
litman NN
and CC
passonneau NN
1995 CD
< NNP
/ref NNP
> NNP
. .

recently RB
, ,
hirschberg VBD
52 CD
< NNP
ref NN
> NNP
hearst NN
texttiling NN
and CC
nakatani JJ
1996 CD
< NNP
/ref NNP
> NNP
have VBP
reported VBN
promising JJ
results NNS
for IN
obtaining VBG
higher JJR
interjudge NN
agreement NN
using VBG
their PRP$
collection NN
protocols NNS
. .

the DT
judges NNS
were VBD
asked VBN
simply RB
to TO
mark VB
the DT
paragraph NN
boundaries NNS
at IN
which WDT
the DT
topic NN
changed VBD
; :
they PRP
were VBD
not RB
given VBN
more JJR
explicit JJ
instructions NNS
about IN
the DT
granularity NN
of IN
the DT
segmentation NN
. .

metric JJ
f NN
nm NN
s NN
nonm JJ
p NN
user NN
turns VBZ
218 CD
53 CD
228 CD
65 CD
065 CD
correct NN
turns VBZ
72 CD
18 CD
67 CD
22 CD
059 CD
asrmis NN
37 CD
27 CD
46 CD
28 CD
046 CD
semmis NN
5 CD
6 CD
12 CD
14 CD
009 CD
table JJ
2 CD
. .

average JJ
standard JJ
deviation NN
for IN
objective JJ
metrics NNS
in IN
the DT
first JJ
problem NN
6 CD
related JJ
work NN
discourse NN
structure NN
has VBZ
been VBN
successfully RB
used VBN
in IN
non-interactive JJ
settings NNS
eg IN
understanding VBG
specific JJ
lexical JJ
and CC
prosodic JJ
phenomena NNS
< VBP
tref JJ
> NNP
hirschberg NN
and CC
nakatani NN
, ,
1996 CD
< NN
/tref NNP
> NNP
, ,
natural JJ
language NN
generation NN
< NNP
ref NN
> NNP
hovy NN
, ,
1993 CD
< NN
/ref NNP
> NNP
, ,
essay VBP
scoring VBG
< NNP
ref NN
> NN
higgins VBZ
et JJ
al NN
, ,
2004 CD
< NN
/ref NNP
> NNP
as RB
well RB
as IN
in IN
interactive JJ
settings NNS
eg VBP
predictive/generative JJ
models NNS
of IN
postural JJ
shifts NNS
< VBP
ref JJ
> NNP
cassell NN
et RB
al RB
, ,
2001 CD
< NN
/ref NNP
> NNP
, ,
generation/interpretation NN
of IN
anaphoric JJ
expressions NNS
< VBP
ref JJ
> NNP
allen NN
et NN
al NN
, ,
2001 CD
< NN
/ref NNP
> NNP
, ,
performance NN
modeling VBG
< NNP
ref NN
> NNP
rotaru NN
and CC
litman NN
, ,
2006 CD
< NN
/ref NNP
> NNP
. .

one CD
related VBN
study NN
is VBZ
that IN
of IN
< NNP
ref NN
> NNP
rich JJ
and CC
sidner NN
, ,
1998 CD
< NN
/ref NNP
> NNP
. .

prosody NN
labeling VBG
on IN
spontaneous JJ
speech NN
corpora NNS
like IN
boston NN
directions NNS
corpus VBP
bdc NN
, ,
switchboard NN
swbd NN
has VBZ
garnered VBN
attention NN
in IN
< NNP
tref NN
> NNP
hirschberg NN
and CC
nakatani NN
, ,
1996 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gregory NN
and CC
altun NN
, ,
2004 CD
< NN
/ref NNP
> NNP
. .

automatic JJ
prosody NN
labeling NN
has VBZ
been VBN
achieved VBN
through IN
various JJ
machine NN
learning VBG
techniques NNS
, ,
such JJ
as IN
decision NN
trees NNS
< VBP
ref JJ
> NNP
hirschberg NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
wightman NN
and CC
ostendorf NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
ma NN
et NN
al NN
, ,
2003 CD
< NN
/ref NNP
> NNP
, ,
rule-based JJ
systems NNS
< MD
ref VB
> NNP
shimei NN
and CC
mckeown NN
, ,
1999 CD
< NN
/ref NNP
> NNP
, ,
bagging NN
and CC
boosting VBG
on IN
cart NN
< NNP
ref NN
> NNP
sun NN
, ,
2002 CD
< NN
/ref NNP
> NNP
, ,
hidden JJ
markov NN
models NNS
< VBP
ref JJ
> NNP
conkie NN
et NN
al NN
, ,
1999 CD
< NN
/ref NNP
> NNP
, ,
neural JJ
networks NNS
hasegawa- JJ
< NNP
ref NN
> NNP
johnson NN
et NN
al NN
, ,
2005 CD
< NN
/ref NNP
> NNP
, ,
maximum-entropy JJ
models NNS
< VBP
ref JJ
> NNP
brenier NN
et NN
al NN
, ,
2005 CD
< NN
/ref NNP
> NNP
and CC
conditional JJ
random NN
fields NNS
< VBP
ref JJ
> NNP
gregory NN
and CC
altun NN
, ,
2004 CD
< NN
/ref NNP
> NNP
. .

for IN
example NN
, ,
in IN
figure NN
1 CD
, ,
if IN
the DT
student NN
would MD
have VB
answered VBN
tutor NN
2 CD
correctly RB
, ,
the DT
next JJ
tutor NN
turn NN
would MD
have VB
had VBD
the DT
same JJ
content NN
as IN
tutor NN
5 CD
but CC
the DT
advance NN
label NN
. .

also RB
, ,
while IN
a DT
human JJ
annotation NN
of IN
the DT
discourse NN
structure NN
will MD
be VB
more RBR
complex JJ
but CC
more JJR
time NN
consuming VBG
< JJ
tref NN
> NNP
hirschberg NN
and CC
nakatani NN
, ,
1996 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
levow NN
, ,
2004 CD
< NN
/ref NNP
> NNP
, ,
its PRP$
advantages NNS
are VBP
outweighed VBN
by IN
the DT
automatic JJ
nature NN
of IN
our PRP$
discourse NN
structure NN
annotation NN
. .

we PRP
would MD
like VB
to TO
highlight VB
that IN
our PRP$
transition NN
annotation NN
is VBZ
domain JJ
independent JJ
and CC
automatic JJ
. .

our PRP$
transition NN
labels NNS
capture VBP
behavior NN
like IN
starting VBG
a DT
new JJ
dialogue NN
newtoplevel NN
, ,
crossing VBG
discourse NN
segment NN
boundaries NNS
push NN
, ,
popup NN
, ,
popupadv NN
and CC
local JJ
phenomena NNS
inside IN
a DT
discourse JJ
segment NN
advance NN
, ,
samegoal NN
. .

information NN
status NN
has VBZ
generated VBN
large JJ
interest NN
among IN
researchers NNS
because IN
of IN
its PRP$
complex JJ
interaction NN
with IN
other JJ
linguistic JJ
phenomena NNS
, ,
thus RB
affecting VBG
several JJ
natural JJ
language NN
processing NN
tasks NNS
. .

since IN
it PRP
correlates VBZ
with IN
word NN
order NN
and CC
pitch NN
accent NN
< NNP
ref NN
> NNP
lambrecht NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
hirschberg NN
and CC
nakatani NN
, ,
1996 CD
< NN
/tref NNP
> NNP
, ,
for IN
instance NN
, ,
incorporating VBG
knowledge NN
on IN
information NN
status NN
would MD
be VB
helpful JJ
for IN
natural JJ
language NN
generation NN
, ,
and CC
in IN
particular JJ
text-tospeech JJ
systems NNS
. .

another DT
area NN
where WRB
information NN
status NN
can MD
play VB
an DT
important JJ
role NN
is VBZ
anaphora JJ
resolution NN
. .

following VBG
the DT
methodology NN
in IN
ttirschberg NN
and CC
< NNP
ref VBP
> NNP
nakatani RB
, ,
1996 CD
< NN
/ref NNP
> NNP
, ,
we PRP
measured VBD
the DT
reliability NN
of IN
coding VBG
for IN
a DT
linearized JJ
version NN
of IN
the DT
iu NN
tree NN
, ,
by IN
calculating VBG
the DT
reliability NN
of IN
coding NN
of IN
iu JJ
beginnings NNS
using VBG
the DT
kappa NN
metric JJ
. .

we PRP
calculated VBD
the DT
observed JJ
pairwise NN
agreement NN
of IN
cgus NN
marked VBN
as IN
the DT
beginnings NNS
of IN
ius NN
, ,
and CC
factored VBD
out RP
the DT
expected JJ
agreement NN
estimated VBN
from IN
the DT
actual JJ
data NNS
, ,
giving VBG
the DT
pairwise NN
kappa NN
score NN
. .

other JJ
attempts NNS
have VBP
had VBN
more JJR
success NN
using VBG
improved JJ
annotation NN
tools NNS
and CC
more JJR
precise JJ
instructions NNS
< VBP
ref NN
> NNP
grosz NN
and CC
hirschberg NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
hirschberg NN
and CC
nakatani NN
, ,
1996 CD
< NN
/tref NNP
> NNP
. .

while IN
agreement NN
among IN
annotators NNS
regarding VBG
linear JJ
segmentation NN
has VBZ
been VBN
found VBN
to TO
be VB
higher JJR
than IN
80 CD
< JJ
ref NN
> NNP
hearst NN
, ,
1997 CD
< NN
/ref NNP
> NNP
, ,
with IN
respect NN
to TO
hierarchical JJ
segmentation NN
it PRP
has VBZ
been VBN
observed VBN
to TO
be VB
as RB
low JJ
as IN
60 CD
< JJ
ref NN
> NNP
flammia NN
and CC
zue NN
, ,
1995 CD
< NN
/ref NNP
> NNP
. .

let VB
a28a30a40a30a11a14a28a21a40a30a28a16a31a36a3a41a34 PRP
be VB
the DT
set NN
of IN
senses NNS
of IN
a3 NN
for IN
each DT
sense NN
of IN
a3 JJ
a3a42a28a44a43a46a45a47a28a30a40a30a11a14a28a21a40a30a28a16a31a36a3a41a34 IN
we PRP
obtain VB
a DT
ranking JJ
score NN
by IN
summing VBG
over IN
the DT
a27a48a28a21a28a16a31a32a3a6a15a33a11a50a49a30a34 NN
of IN
each DT
neighbour JJ
a11a50a49a51a45a52a4a6a5 NN
multiplied VBN
by IN
a DT
weight NN
. .

this DT
weight NN
is VBZ
the DT
wordnet NN
similarity NN
score NN
a3a42a11a14a28a30a28 NN
between IN
the DT
target NN
sense NN
a3a53a28a35a43 NN
and CC
the DT
sense NN
of IN
a11a54a49 NN
a11a14a28a35a55a56a45a57a28a30a40a30a11a14a28a21a40a30a28a16a31a36a11a54a49a16a34 NN
that WDT
maximises VBZ
this DT
score NN
, ,
divided VBN
by IN
the DT
sum NN
of IN
all DT
such JJ
wordnet JJ
similarity NN
scores NNS
for IN
a28a30a40a21a11a19a28a21a40a30a28a26a31a32a3a41a34 NN
and CC
a11a50a49 JJ
thus RB
we PRP
rank VBP
each DT
sense NN
a3a42a28 VBZ
a43 RB
a45a10a28a30a40a21a11a19a28a21a40a30a28a26a31a32a3a41a34 JJ
using VBG
: :
a58a41a59 NN
a11a14a2a54a60a61a11a50a62a64a63a66a65a35a67a16a68a12a40a26a31a32a3a53a28 NN
a43 NN
a34a69a7 NN
a70 NN
a71a44a72a33a73a16a74a76a75 NN
a27a48a28a21a28a16a31a32a3a6a15a33a11a50a49a30a34a30a77 NN
a3a42a11a14a28a21a28a16a31a32a3a53a28a35a43a36a15a33a11a50a49a30a34 NN
a78 NN
a5a19a79a81a80a39a82 NN
a73 NN
a79a61a83 NN
a71 NN
a79a81a83a61a79a36a84a85a5a19a86 NN
a3a53a11a14a28a30a28a26a31a32a3a42a28 NN
a43 NN
a82 NN
a15a17a11 NN
a49 NN
a34 NN
1 CD
where WRB
: :
a3a42a11a14a28a21a28a16a31a32a3a53a28a35a43a87a15a17a11a54a49a21a34a66a7 NN
a88a46a89a21a90 NN
a71 NN
a79a92a91 NN
a73 NN
a79a81a83 NN
a71 NN
a79a81a83a61a79a93a84 NN
a71a44a72 NN
a86 NN
a31a36a3a42a11a14a28a30a28a26a31a32a3a53a28a35a43a36a15a33a11a14a28a35a55a29a34a87a34 VBZ
22 CD
acquiring VBG
the DT
automatic JJ
thesaurus NN
there EX
are VBP
many JJ
alternative JJ
distributional JJ
similarity NN
measures NNS
proposed VBN
in IN
the DT
literature NN
, ,
for IN
this DT
work NN
we PRP
used VBD
the DT
measure NN
and CC
thesaurus NN
construction NN
method NN
described VBN
by IN
< NNP
tref NN
> NNP
lin NN
1998 CD
< NNP
/tref NNP
> NNP
. .

importantly RB
, ,
inter-dependence NN
between IN
links NNS
can MD
still RB
be VB
accommodated VBN
by IN
exploiting VBG
dynamic JJ
features NNS
in IN
training NN
features NNS
that WDT
take VBP
into IN
account NN
the DT
labels NNS
of IN
some DT
of IN
the DT
surrounding VBG
components NNS
when WRB
predicting VBG
the DT
label NN
of IN
a DT
target NN
component NN
. .

4 CD
extensions NNS
to TO
large JJ
margin NN
parsing VBG
the DT
approach NN
presented VBN
above IN
has VBZ
a DT
limitation NN
: :
it PRP
uses VBZ
a DT
local JJ
scoring NN
function NN
instead RB
of IN
a DT
global JJ
scoring NN
function NN
to TO
compute VB
the DT
score NN
for IN
a DT
candidate NN
tree NN
. .

realword NN
spelling VBG
correction NN
is VBZ
also RB
referred VBN
to TO
as IN
context JJ
sensitive JJ
spelling VBG
correction NN
, ,
which WDT
tries VBZ
to TO
detect VB
incorrect JJ
usage NN
of IN
valid JJ
words NNS
in IN
certain JJ
contexts NN
< NNP
ref NN
> NNP
golding NN
and CC
roth NN
, ,
1996 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
mangu NN
and CC
brill NN
, ,
1997 CD
< NN
/ref NNP
> NNP
. .

distributional JJ
similarity NN
between IN
words NNS
has VBZ
been VBN
investigated VBN
and CC
successfully RB
applied VBN
in IN
many JJ
natural JJ
language NN
tasks NNS
such JJ
as IN
automatic JJ
semantic JJ
knowledge NN
acquisition NN
< NNP
tref NN
> NNP
dekang NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
and CC
language NN
model NN
smoothing VBG
< JJ
ref NN
> NNP
essen NN
and CC
steinbiss NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan JJ
et FW
al NN
, ,
1997 CD
< NN
/ref NNP
> NNP
. .

3 CD
distributional JJ
similarity-based JJ
models NNS
for IN
query NN
spelling VBG
correction NN
31 CD
motivation NN
most RBS
of IN
the DT
previous JJ
work NN
on IN
spelling VBG
correction NN
concentrates NNS
on IN
the DT
problem NN
of IN
designing VBG
better JJR
error NN
models NNS
based VBN
on IN
properties NNS
of IN
character NN
strings NNS
. .

in IN
this DT
light NN
, ,
the DT
contributions NNS
of IN
this DT
paper NN
are VBP
fourfold VBN
. .

first RB
, ,
instead RB
of IN
separately RB
addressing VBG
the DT
tasks NNS
of IN
collecting VBG
unlabeled JJ
sets NNS
of IN
instances NNS
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
, ,
assigning VBG
appropriate JJ
class NN
labels NNS
to TO
a DT
given VBN
set NN
of IN
instances NNS
< NNP
ref NN
> NNP
pantel NN
and CC
ravichandran NN
, ,
2004 CD
< NN
/ref NNP
> NNP
, ,
and CC
identifying VBG
relevant JJ
attributes NNS
for IN
a DT
given VBN
set NN
of IN
classes NNS
< NNP
ref NN
> NNP
pasca NN
, ,
2007 CD
< NN
/ref NNP
> NNP
, ,
our PRP$
integrated JJ
method NN
from IN
section NN
2 CD
enables VBZ
the DT
simultaneous JJ
extraction NN
of IN
class NN
instances NNS
, ,
associated VBN
labels NNS
and CC
attributes NNS
. .

second JJ
, ,
by IN
exploiting VBG
the DT
contents NNS
of IN
query JJ
logs NNS
during IN
the DT
extraction NN
of IN
labeled JJ
classes NNS
of IN
instances NNS
from IN
web JJ
documents NNS
, ,
we PRP
acquire VB
thousands NNS
4,583 CD
, ,
to TO
be VB
exact JJ
of IN
open-domain JJ
classes NNS
covering VBG
a DT
wide JJ
range NN
of IN
topics NNS
and CC
domains NNS
. .

the DT
accuracy NN
reported VBD
in IN
section NN
32 CD
exceeds NNS
80 CD
for IN
both DT
instance NN
sets NNS
and CC
class NN
labels NNS
, ,
although IN
the DT
extraction NN
of IN
classes NNS
requires VBZ
a DT
remarkably RB
small JJ
amount NN
of IN
supervision NN
, ,
in IN
the DT
form NN
of IN
only RB
a DT
few JJ
commonly-used JJ
is-a JJ
extraction NN
patterns NNS
. .

another DT
approach NN
used VBD
the DT
words NNS
distribution NN
to TO
cluster VB
the DT
words NNS
< NNP
ref NN
> NNP
pereira NN
, ,
1993 CD
< NN
/ref NNP
> NNP
, ,
and CC
inoue JJ
< NNP
ref NN
> NNP
inoue NN
, ,
1991 CD
< NN
/ref NNP
> NNP
also RB
used VBD
the DT
word NN
distributional JJ
information NN
in IN
the DT
japanese-english JJ
word NN
pairs NNS
to TO
resolve VB
the DT
polysemous JJ
word NN
problem NN
. .

the DT
wmts NN
is VBZ
well RB
suited VBN
to TO
lra VB
, ,
because IN
the DT
wmts NN
scales VBZ
well RB
to TO
large JJ
corpora VB
one CD
terabyte NN
, ,
in IN
our PRP$
case NN
, ,
it PRP
gives VBZ
exact JJ
frequency NN
counts NNS
unlike IN
most JJS
web JJ
search NN
engines NNS
, ,
it PRP
is VBZ
designed VBN
for IN
passage NN
retrieval NN
rather RB
than IN
document NN
retrieval NN
, ,
and CC
it PRP
has VBZ
a DT
powerful JJ
query JJ
syntax NN
. .

find VB
alternates NNS
: :
for IN
each DT
word NN
pair VBZ
a DT
: :
b NN
in IN
the DT
input NN
set VBN
, ,
look VB
in IN
< NNP
tref NN
> NN
lins VBZ
1998a CD
< NN
/tref NNP
> NNP
thesaurus NN
for IN
the DT
top JJ
num NN
sim NN
words NNS
in IN
the DT
following JJ
experiments NNS
, ,
num JJ
sim NN
is VBZ
10 CD
that WDT
are VBP
most RBS
similar JJ
to TO
a DT
for IN
each DT
a DT
prime JJ
that WDT
is VBZ
similar JJ
to TO
a DT
, ,
make VB
a DT
new JJ
word NN
pair NN
a DT
prime JJ
: :
b NN
likewise NN
, ,
look NN
for IN
the DT
top JJ
num NN
sim NN
words NNS
that WDT
are VBP
most RBS
similar JJ
to TO
b VB
, ,
and CC
for IN
each DT
b NN
prime NN
, ,
make VB
a DT
new JJ
word NN
pair NN
a DT
: :
b NN
prime VBZ
a DT
: :
b NN
is VBZ
called VBN
the DT
original JJ
pair NN
and CC
each DT
a DT
prime JJ
: :
b NN
or CC
a DT
: :
b NN
prime NN
is VBZ
an DT
alternate JJ
pair NN
. .

the DT
intent NN
is VBZ
that IN
alternates NNS
should MD
have VB
almost RB
the DT
same JJ
semantic JJ
relations NNS
as IN
the DT
original JJ
. .

for IN
each DT
input NN
pair NN
, ,
there EX
will MD
now RB
be VB
2 CD
num JJ
sim NN
alternate NN
pairs NNS
. .

for IN
each DT
input NN
pair NN
, ,
there EX
will MD
now RB
be VB
2 CD
num JJ
sim NN
alternate NN
pairs NNS
. .

the DT
first JJ
column NN
in IN
table JJ
7 CD
shows VBZ
the DT
alternate NN
pairs NNS
that WDT
are VBP
generated VBN
for IN
the DT
original JJ
pair NN
quart NN
: :
volume NN
. .

as IN
a DT
courtesy NN
to TO
other JJ
users NNS
of IN
lins NNS
on-line JJ
system NN
, ,
we PRP
insert VBP
a DT
20-second JJ
delay NN
between IN
each DT
two CD
queries NNS
. .

the DT
classes NNS
of IN
words NNS
are VBP
computed VBN
on IN
the DT
fly NN
over IN
all DT
sequences NNS
of IN
terms NNS
in IN
the DT
extracted JJ
patterns NNS
, ,
on IN
top NN
of IN
a DT
large JJ
set NN
of IN
pairwise NN
similarities NNS
among IN
words NNS
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
extracted VBD
in IN
advance NN
from IN
around IN
50 CD
million CD
news NN
articles NNS
indexed VBN
by IN
the DT
google NN
search NN
engine NN
over IN
three CD
years NNS
. .

all DT
digits NNS
in IN
both DT
patterns NNS
and CC
sentences NNS
are VBP
replaced VBN
with IN
a DT
common JJ
marker NN
, ,
such JJ
810 CD
that IN
any DT
two CD
numerical JJ
values NNS
with IN
the DT
same JJ
number NN
of IN
digits NNS
will MD
overlap VB
during IN
matching NN
. .

538 CD
ture NN
for IN
npi NN
whose WP$
value NN
is VBZ
the DT
most RBS
likely JJ
ne JJ
type NN
. .

motivated VBN
by IN
this DT
observation NN
, ,
we PRP
create VBP
for IN
each DT
of IN
npis JJ
ten NNS
most RBS
semantically RB
similar JJ
nps NN
a DT
neighbor JJ
feature NN
whose WP$
value NN
is VBZ
the DT
surface NN
string NN
of IN
the DT
np NN
. .

to TO
determine VB
the DT
ten JJ
nearest JJS
neighbors NNS
, ,
we PRP
use VBP
the DT
semantic JJ
similarity NN
values NNS
provided VBN
by IN
lins NNS
dependency-based JJ
thesaurus NN
, ,
which WDT
is VBZ
constructed VBN
using VBG
a DT
distributional JJ
approach NN
combined VBN
with IN
an DT
information-theoretic JJ
de FW
nition NN
of IN
similarity NN
. .

an DT
example NN
extraction NN
would MD
be VB
< JJ
eastern JJ
airlines NNS
, ,
the DT
carrier NN
> NN
, ,
where WRB
the DT
rst JJ
entry NN
is VBZ
a DT
proper JJ
noun NN
labeled VBN
with IN
either DT
one CD
of IN
the DT
seven CD
muc-style JJ
ne JJ
types4 NN
or CC
others5 NN
and CC
the DT
second JJ
entry NN
is VBZ
a DT
common JJ
noun NN
. .

we PRP
then RB
infer VBP
the DT
sc NN
of IN
a DT
common JJ
noun NN
as IN
follows VBZ
: :
1 CD
we PRP
compute VBP
the DT
probability NN
that IN
the DT
common JJ
noun JJ
co-occurs NNS
with IN
each DT
of IN
the DT
eight CD
ne NNS
types6 RB
based VBN
on IN
the DT
extracted JJ
appositive JJ
relations NNS
, ,
and CC
2 CD
if IN
the DT
most RBS
likely JJ
ne NN
type NN
has VBZ
a DT
co-occurrence JJ
probability NN
above IN
a DT
certain JJ
threshold NN
we PRP
set VBD
it PRP
to TO
07 CD
, ,
we PRP
create VBP
a DT
induced JJ
class NN
fea1this NN
is VBZ
motivated VBN
by IN
< NNP
tref NN
> NN
lins VBZ
1998c CD
< NN
/tref NNP
> NNP
observation NN
that IN
a DT
coreference NN
resolver NN
that WDT
employs VBZ
only RB
the DT
rst JJ
wordnet NN
sense NN
performs VBZ
slightly RB
better JJR
than IN
one CD
that WDT
employs VBZ
more JJR
than IN
one CD
sense NN
. .

2 CD
subj JJ
verb NN
: :
if IN
npi DT
is VBZ
involved VBN
in IN
a DT
subjectverb JJ
relation NN
, ,
we PRP
create VBP
a DT
subj JJ
verb NN
feature NN
whose WP$
value NN
is VBZ
the DT
verb NN
participating VBG
in IN
the DT
relation NN
. .

our PRP$
motivation NN
here RB
is VBZ
to TO
coarsely RB
model VB
subcategorization NN
. .

the DT
distributed JJ
frequency NN
of IN
an DT
object NN
, ,
which WDT
takes VBZ
an DT
average NN
of IN
the DT
frequency NN
of IN
occurrence NN
with IN
an DT
object NN
over IN
all DT
verbs NNS
occurring VBG
with IN
the DT
object NN
above IN
a DT
threshold NN
. .

the DT
classes NNS
over IN
which WDT
the DT
probability NN
distribution NN
is VBZ
calculated VBN
are VBP
selected VBN
according VBG
to TO
the DT
minimum JJ
description NN
length NN
principle NN
mdl NN
which WDT
uses VBZ
the DT
argument NN
head NN
tokens NNS
for IN
nding VBG
the DT
best JJS
classes NNS
for IN
representation NN
. .

similarity NN
and CC
association NN
measures NNS
can MD
help VB
for IN
the DT
cases NNS
of IN
near-synonymy JJ
. .

however RB
, ,
while IN
similarity NN
measures NNS
such JJ
as IN
wordnet JJ
distance NN
or CC
lins VBZ
similarity NN
metric JJ
only RB
detect JJ
cases NNS
of IN
semantic JJ
similarity NN
, ,
association NN
measures NNS
such JJ
as IN
the DT
ones NNS
used VBN
by IN
poesio JJ
et NN
al NN
, ,
or CC
by IN
garera NN
and CC
yarowsky NN
also RB
find VBP
cases NNS
of IN
associative JJ
bridg497 NN
lin98 NN
rff NN
they PRP
they PRP
: :
g2 NN
pl03 NN
land NN
country/state/land NN
staat NN
staat NN
kemalismus NN
regierung NN
kontinent NN
state NN
state NN
kemalism NN
government NN
continent NN
stadt NN
stadt NN
bauernfamilie NN
prasident JJ
region NN
city NN
city NN
agricultural JJ
family NN
president NN
region NN
region NN
landesregierung NN
bankgesellschaft NN
dollar NN
stadt JJ
region NN
country NN
government NN
banking VBG
corporation NN
dollar NN
city NN
bundesrepublik NN
bundesregierung NN
baht NN
albanien NN
staat VBZ
federal JJ
republic JJ
federal JJ
government NN
baht NN
albania NN
state NN
republik NN
gewerkschaft NN
gasag NN
hauptstadt NN
bundesland VBP
republic JJ
trade NN
union NN
a DT
gas NN
company NN
capital NN
state NN
medikament JJ
medical JJ
drug NN
arzneimittel NN
pille NN
ru NN
patient JJ
arzneimittel NN
pharmaceutical JJ
pill NN
a DT
drug NN
patient JJ
pharmaceutical JJ
praparat NN
droge NN
abtreibungspille NN
arzt JJ
lebensmittel NN
preparation NN
drug NN
non-medical JJ
abortion NN
pill NN
doctor NN
foodstuff NN
pille NN
praparat NN
viagra NN
pille NN
praparat NN
pill NN
preparation NN
viagra NN
pill NN
preparation NN
hormon NN
pestizid NN
pharmakonzern JJ
behandlung NN
behandlung NN
hormone NN
pesticide NN
pharmaceutical JJ
company NN
treatment NN
treatment NN
lebensmittel NN
lebensmittel NN
praparat NN
abtreibungspille VBZ
arznei JJ
foodstuff NN
foodstuff NN
preparation NN
abortion NN
pill NN
drug NN
highest JJS
ranked JJ
words NNS
, ,
with IN
very RB
rare JJ
words NNS
removed VBN
: :
ru NN
486 CD
, ,
an DT
abortifacient JJ
drug NN
lin98 NN
: :
lins VBZ
distributional JJ
similarity NN
measure NN
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
rff NN
: :
geffet NN
and CC
dagans NNS
relative JJ
feature NN
focus NN
measure NN
< NNP
ref NN
> NNP
geffet NN
and CC
dagan NN
, ,
2004 CD
< NN
/ref CC
> NN
they PRP
: :
association NN
measure NN
introduced VBN
by IN
< JJ
ref NN
> NNP
garera NN
and CC
yarowsky JJ
2006 CD
< NNP
/ref NNP
> VBZ
they PRP
: :
g2 NN
: :
similar JJ
method NN
using VBG
a DT
log-likelihood-based JJ
statistic JJ
see NN
< JJ
ref NN
> NN
dunning VBG
1993 CD
< JJ
/ref NNP
> NN
this DT
statistic NN
has VBZ
a DT
preference NN
for IN
higher-frequency NN
terms NNS
pl03 NN
: :
semantic JJ
space NN
association NN
measure NN
proposed VBN
by IN
< NNP
ref NN
> NNP
pado NN
and CC
lapata NN
2003 CD
< NNP
/ref NNP
> NNP
table JJ
1 CD
: :
similarity NN
and CC
association NN
measures NNS
: :
most JJS
similar JJ
items NNS
ing VBG
like IN
1a CD
, ,
b NN
; :
the DT
result NN
of IN
this DT
can MD
be VB
seen VBN
in IN
table JJ
2 CD
: :
while IN
the DT
similarity NN
measures VBZ
lin98 JJR
, ,
rff JJ
list NN
substitutable NN
terms NNS
which WDT
behave VBP
like IN
synonyms NN
in IN
many JJ
contexts NN
, ,
the DT
association NN
measures VBZ
garera NN
and CC
yarowskys NN
they PRP
measure VBP
, ,
pado NN
and CC
lapatas JJ
association NN
measure NN
also RB
find VBP
non-compatible JJ
associations NNS
such JJ
as IN
countrycapital NN
or CC
drugtreatment NN
, ,
which WDT
is VBZ
why WRB
they PRP
are VBP
commonly RB
called VBN
relationfree NN
. .

for IN
the DT
purpose NN
of IN
coreference NN
resolution NN
, ,
however RB
we PRP
do VBP
not RB
want VB
to TO
resolve VB
the DT
door NN
to TO
the DT
antecedent NN
the DT
house NN
as IN
the DT
two CD
descriptions NNS
do VBP
not RB
corefer VB
, ,
and CC
it PRP
may MD
be VB
useful JJ
to TO
filter VB
out RP
non-similar JJ
associations NNS
. .

12 CD
information NN
sources NNS
different JJ
resources NNS
may MD
be VB
differently RB
suited VBN
for IN
the DT
recognition NN
of IN
the DT
various JJ
relations NNS
. .

while IN
none NN
of IN
the DT
information NN
sources NNS
can MD
match VB
the DT
precision NN
of IN
the DT
hypernymy NN
information NN
encoded VBD
in IN
germanet NN
, ,
or CC
that IN
of IN
using VBG
a DT
combination NN
of IN
high-precision NN
patterns NNS
with IN
the DT
world NN
wide JJ
web NN
as IN
a DT
very RB
large JJ
corpus NN
, ,
it PRP
is VBZ
possible JJ
to TO
achieve VB
a DT
considerable JJ
improvement NN
in IN
terms NNS
of IN
recall NN
without IN
sacrificing VBG
too RB
much JJ
precision NN
by IN
combining VBG
these DT
methods NNS
. .

for IN
the DT
association NN
measures NNS
, ,
the DT
fact NN
that IN
they PRP
are VBP
relation-free JJ
also RB
means VBZ
that IN
they PRP
can MD
profit VB
from IN
added JJ
semantic JJ
filtering NN
. .

the DT
novel JJ
distance-bounded JJ
semantic JJ
similarity NN
method NN
where WRB
we PRP
use VBP
the DT
most RBS
similar JJ
words NNS
in IN
the DT
previous JJ
discourse NN
together RB
with IN
a DT
semantic JJ
classbased JJ
filter NN
and CC
a DT
distance NN
limit NN
comes VBZ
near IN
the DT
precision NN
of IN
using VBG
surface NN
patterns NNS
, ,
and CC
offers VBZ
better RBR
accuracy NN
than IN
gasperin NN
and CC
vieiras JJ
method NN
of IN
using VBG
the DT
globally RB
most JJS
similar JJ
words NNS
. .

note NN
, ,
however RB
, ,
that IN
< NNP
ref VBD
> NNP
mccarthy JJ
et NN
al NN
, ,
2004 CD
< NN
/ref NNP
> NNP
used VBD
the DT
information NN
about IN
distributionally RB
similar JJ
words NNS
to TO
approximate VB
corpus NN
frequencies NNS
for IN
word NN
senses NNS
, ,
whereas IN
we PRP
target VBP
the DT
estimation NN
of IN
a DT
property NN
of IN
a DT
given VBN
word NN
sense NN
the DT
subjectivity NN
. .

next JJ
, ,
for IN
each DT
sense NN
wsi NN
of IN
the DT
word NN
w NN
, ,
we PRP
determine VBP
the DT
similarity NN
with IN
each DT
of IN
the DT
words NNS
in IN
the DT
list NN
dsw NN
, ,
using VBG
a DT
wordnet-based JJ
measure NN
of IN
semantic JJ
similarity NN
wnss NN
. .

41 CD
weight NN
tuning NN
there EX
are VBP
several JJ
motivations NNS
for IN
learning VBG
the DT
graph NN
weights NNS
in IN
this DT
domain NN
. .

first RB
, ,
some DT
dependency NN
relations NNS
foremost VBP
, ,
subject JJ
and CC
object NN
are VBP
in IN
general JJ
more RBR
salient JJ
than IN
others NNS
< VBP
tref JJ
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
pado NN
and CC
lapata NN
, ,
2007 CD
< NN
/ref NNP
> NNP
. .

in IN
addition NN
, ,
dependency NN
relations NNS
may MD
have VB
varying VBG
importance NN
per IN
different JJ
notions NNS
of IN
word NN
similarity NN
eg NN
, ,
noun JJ
vs NN
verb NN
similarity NN
< NNP
ref NN
> NNP
resnik NN
and CC
diab NN
, ,
2000 CD
< NN
/ref NNP
> NNP
. .

the DT
learning NN
methods NNS
described VBN
in IN
this DT
paper NN
can MD
be VB
readily RB
applied VBN
to TO
911 CD
other JJ
directed VBN
and CC
labelled VBN
entity-relation NN
graphs7 NN
the DT
graph NN
representation NN
described VBN
in IN
this DT
paper NN
is VBZ
perhaps RB
most RBS
related JJ
to TO
syntax-based JJ
vector NN
space NN
models NNS
, ,
which WDT
derive VBP
a DT
notion NN
of IN
semantic JJ
similarity NN
from IN
statistics NNS
associated VBN
with IN
a DT
parsed JJ
corpus NN
< NNP
ref NN
> NNP
grefenstette NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
pado NN
and CC
lapata NN
, ,
2007 CD
< NN
/ref NNP
> NNP
. .

in IN
most JJS
cases NNS
, ,
these DT
models NNS
construct VBP
vectors NNS
to TO
represent VB
each DT
word NN
wi NN
, ,
where WRB
each DT
element NN
in IN
the DT
vector NN
for IN
wi JJ
corresponds NNS
to TO
particular JJ
context NN
c NN
, ,
and CC
represents VBZ
a DT
count NN
or CC
an DT
indication NN
of IN
whether IN
wi NN
occurred VBD
in IN
context NN
c NN
a DT
context NN
can MD
refer VB
to TO
simple VB
co-occurrence NN
with IN
another DT
word NN
wj NN
, ,
to TO
a DT
particular JJ
syntactic JJ
relation NN
to TO
another DT
word NN
eg NN
, ,
a DT
relation NN
of IN
direct JJ
object NN
to TO
wj VB
, ,
etc FW
given VBN
these DT
word NN
vectors NNS
, ,
inter-word JJ
similarity NN
is VBZ
evaluated VBN
using VBG
some DT
appropriate JJ
similarity NN
measure NN
for IN
the DT
vector NN
space NN
, ,
such JJ
as IN
cosine NN
vector NN
similarity NN
, ,
or CC
lins VBZ
similarity JJ
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
. .

recently RB
, ,
pado NN
and CC
lapata NN
< NNP
ref NN
> NNP
pado NN
and CC
lapata NN
, ,
2007 CD
< NN
/ref NNP
> NNP
have VBP
suggested VBN
an DT
extended JJ
syntactic JJ
vector NN
space NN
model NN
called VBN
dependency NN
vectors NNS
, ,
in IN
which WDT
rather RB
than IN
simple JJ
counts NNS
, ,
the DT
components NNS
of IN
a DT
word NN
vector NN
of IN
contexts JJ
consist NN
of IN
weighted JJ
scores NNS
, ,
which WDT
combine VBP
both DT
co-occurrence JJ
frequency NN
and CC
the DT
importance NN
of IN
a DT
context NN
, ,
based VBN
on IN
properties NNS
of IN
the DT
connecting NN
dependency NN
paths NNS
. .

instead RB
, ,
we PRP
include VBP
learning VBG
techniques NNS
to TO
optimize VB
the DT
graphwalk NN
based VBN
similarity NN
measure NN
. .

the DT
learning NN
methods NNS
described VBN
in IN
this DT
paper NN
can MD
be VB
readily RB
applied VBN
to TO
911 CD
other JJ
directed VBN
and CC
labelled VBN
entity-relation NN
graphs7 NN
the DT
graph NN
representation NN
described VBN
in IN
this DT
paper NN
is VBZ
perhaps RB
most RBS
related JJ
to TO
syntax-based JJ
vector NN
space NN
models NNS
, ,
which WDT
derive VBP
a DT
notion NN
of IN
semantic JJ
similarity NN
from IN
statistics NNS
associated VBN
with IN
a DT
parsed JJ
corpus NN
< NNP
ref NN
> NNP
grefenstette NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
pado NN
and CC
lapata NN
, ,
2007 CD
< NN
/ref NNP
> NNP
. .

in IN
most JJS
cases NNS
, ,
these DT
models NNS
construct VBP
vectors NNS
to TO
represent VB
each DT
word NN
wi NN
, ,
where WRB
each DT
element NN
in IN
the DT
vector NN
for IN
wi JJ
corresponds NNS
to TO
particular JJ
context NN
c NN
, ,
and CC
represents VBZ
a DT
count NN
or CC
an DT
indication NN
of IN
whether IN
wi NN
occurred VBD
in IN
context NN
c NN
a DT
context NN
can MD
refer VB
to TO
simple VB
co-occurrence NN
with IN
another DT
word NN
wj NN
, ,
to TO
a DT
particular JJ
syntactic JJ
relation NN
to TO
another DT
word NN
eg NN
, ,
a DT
relation NN
of IN
direct JJ
object NN
to TO
wj VB
, ,
etc FW
given VBN
these DT
word NN
vectors NNS
, ,
inter-word JJ
similarity NN
is VBZ
evaluated VBN
using VBG
some DT
appropriate JJ
similarity NN
measure NN
for IN
the DT
vector NN
space NN
, ,
such JJ
as IN
cosine NN
vector NN
similarity NN
, ,
or CC
lins VBZ
similarity JJ
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
. .

recently RB
, ,
pado NN
and CC
lapata NN
< NNP
ref NN
> NNP
pado NN
and CC
lapata NN
, ,
2007 CD
< NN
/ref NNP
> NNP
have VBP
suggested VBN
an DT
extended JJ
syntactic JJ
vector NN
space NN
model NN
called VBN
dependency NN
vectors NNS
, ,
in IN
which WDT
rather RB
than IN
simple JJ
counts NNS
, ,
the DT
components NNS
of IN
a DT
word NN
vector NN
of IN
contexts JJ
consist NN
of IN
weighted JJ
scores NNS
, ,
which WDT
combine VBP
both DT
co-occurrence JJ
frequency NN
and CC
the DT
importance NN
of IN
a DT
context NN
, ,
based VBN
on IN
properties NNS
of IN
the DT
connecting NN
dependency NN
paths NNS
. .

to TO
further JJ
enhance VB
the DT
quality NN
of IN
co-occurrence NN
data NNS
, ,
we PRP
search VBP
on IN
the DT
specific JJ
phrase NN
a16 NN
is VBZ
measured VBN
in IN
in IN
which WDT
a16 NN
is VBZ
one CD
of IN
the DT
related JJ
concepts NNS
of IN
a14 NN
this DT
allows VBZ
for IN
the DT
simultaneous JJ
discovery NN
of IN
unknown JJ
units NNS
and CC
the DT
retrieval NN
of IN
their PRP$
co-occurrence NN
counts NNS
. .

this DT
allows VBZ
us PRP
to TO
handle VB
sentential JJ
constructions NNS
that WDT
may MD
intervene VB
between IN
measured VBN
and CC
a DT
meaningful JJ
unit NN
. .

for IN
each DT
unit NN
a17 NN
that WDT
is VBZ
related VBN
to TO
measured VBN
via IN
in IN
, ,
we PRP
increment VBP
the DT
co-occurrence NN
count NN
a18a20a19a21a17a23a22a24a16a26a25 NN
, ,
thereby RB
collecting VBG
frequency NN
counts NNS
for IN
each DT
a17 NN
with IN
a16 PDT
the DT
patterns NNS
precision NN
prevents NNS
incidental JJ
cooccurrence NN
between IN
a DT
related JJ
concept NN
and CC
some DT
unit NN
that WDT
may MD
occur VB
simply RB
because IN
of IN
the DT
general JJ
topic NN
of IN
the DT
document NN
. .

thus RB
, ,
there EX
is VBZ
strong JJ
motivation NN
to TO
expand VB
the DT
list NN
of IN
units NNS
obtained VBN
from IN
google NN
by IN
automatically RB
considering VBG
similar JJ
units NNS
. .

the DT
similar JJ
word NN
expansion NN
can MD
add VB
a DT
term NN
like JJ
gigs NNS
as IN
a DT
unit NN
for IN
size NN
by IN
virtue NN
of IN
its PRP$
association NN
with IN
gigabytes NNS
, ,
which WDT
is VBZ
on IN
the DT
original JJ
list NN
. .

cluster NN
clustered VBD
similar JJ
words NNS
of IN
duty NN
with IN
similarity NN
score NN
responsibility NN
016 CD
, ,
obligation NN
0109 CD
, ,
task NN
0101 CD
, ,
function NN
0098 CD
, ,
role NN
0091 CD
, ,
post NN
0087 CD
, ,
position NN
0086 CD
, ,
job NN
0084 CD
, ,
chore VBD
008 CD
, ,
mission NN
008 CD
, ,
assignment NN
0079 CD
, ,
liability NN
0077 CD
tariff0091 NN
, ,
restriction NN
0089 CD
, ,
tax NN
0086 CD
, ,
regulation NN
0085 CD
, ,
requirement NN
0081 CD
, ,
procedure NN
0079 CD
, ,
penalty NN
0079 CD
, ,
quota NN
0074 CD
, ,
rule NN
007 CD
, ,
levy NN
0061 CD
fee NN
0085 CD
, ,
salary JJ
0081 CD
, ,
pay NN
0064 CD
, ,
fine JJ
0058 CD
personnel NN
0073 CD
, ,
staff0073 VBD
training NN
0072 CD
, ,
work NN
0064 CD
, ,
exercise NN
0061 CD
privilege NN
0069 CD
, ,
right JJ
0057 CD
, ,
license NN
0056 CD
22 CD
. .

cluster NN
clustered VBD
similar JJ
words NNS
of IN
duty NN
with IN
similarity NN
score NN
responsibility NN
016 CD
, ,
obligation NN
0109 CD
, ,
task NN
0101 CD
, ,
function NN
0098 CD
, ,
role NN
0091 CD
, ,
post NN
0087 CD
, ,
position NN
0086 CD
, ,
job NN
0084 CD
, ,
chore VBD
008 CD
, ,
mission NN
008 CD
, ,
assignment NN
0079 CD
, ,
liability NN
0077 CD
tariff0091 NN
, ,
restriction NN
0089 CD
, ,
tax NN
0086 CD
, ,
regulation NN
0085 CD
, ,
requirement NN
0081 CD
, ,
procedure NN
0079 CD
, ,
penalty NN
0079 CD
, ,
quota NN
0074 CD
, ,
rule NN
007 CD
, ,
levy NN
0061 CD
fee NN
0085 CD
, ,
salary JJ
0081 CD
, ,
pay NN
0064 CD
, ,
fine JJ
0058 CD
personnel NN
0073 CD
, ,
staff0073 VBD
training NN
0072 CD
, ,
work NN
0064 CD
, ,
exercise NN
0061 CD
privilege NN
0069 CD
, ,
right JJ
0057 CD
, ,
license NN
0056 CD
22 CD
. .

43 CD
alignment JJ
model NN
< NNP
ref NN
> NNP
glickman NN
et NN
al NN
, ,
2006 CD
< NN
/ref NNP
> NNP
was VBD
among IN
the DT
top JJ
scoring NN
systems NNS
on IN
the DT
rte-1 JJ
challenge NN
and CC
supplies NNS
a DT
probabilistically RB
motivated JJ
lexical JJ
measure NN
based VBN
on IN
word NN
co-occurrence NN
statistics NNS
. .

we PRP
are VBP
going VBG
to TO
extend VB
the DT
set NN
of IN
content JJ
bearing NN
words NNS
and CC
to TO
include VB
verbs NNS
. .

we PRP
will MD
take VB
advantage NN
of IN
the DT
flexibility NN
provided VBN
by IN
our PRP$
framework NN
and CC
use NN
syntax NN
based VBN
measure NN
of IN
similarity NN
in IN
the DT
computation NN
of IN
the DT
verb NN
vectors NNS
, ,
following VBG
< JJ
tref JJ
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
. .

we PRP
are VBP
planning VBG
to TO
integrate VB
more RBR
sophisticated JJ
techniques NNS
in IN
our PRP$
framework NN
. .

in IN
this DT
paper NN
the DT
sophisticated JJ
parser NN
rasp NN
toolkit VBD
2 CD
< NNP
ref NN
> NNP
briscoe NN
et NN
al NN
, ,
2006 CD
< NN
/ref NNP
> NNP
was VBD
utilized VBN
to TO
extract VB
this DT
kind NN
of IN
word NN
relations NNS
. .

we PRP
use VBP
the DT
following JJ
example NN
for IN
illustration NN
purposes NNS
: :
the DT
library NN
has VBZ
a DT
large JJ
collection NN
of IN
classic JJ
books NNS
by IN
such JJ
authors NNS
as IN
herrick NN
and CC
shakespeare NN
. .

as IN
manning NN
and CC
schu NN
tze NN
1999 CD
argued VBD
, ,
this DT
does VBZ
not RB
seem VB
to TO
be VB
a DT
good JJ
measure NN
of IN
the DT
strength NN
of IN
association NN
between IN
a DT
word NN
and CC
a DT
local JJ
position NN
. .

it PRP
is VBZ
a DT
statistically RB
based VBN
dependency NN
parser NN
which WDT
is VBZ
reported VBN
to TO
reach VB
89 CD
precision NN
and CC
82 CD
recall NN
on IN
press NN
reportage NN
texts NN
. .

this DT
is VBZ
a DT
syntactic JJ
detector NN
, ,
a DT
point NN
missed VBN
by IN
< NNP
ref NN
> NN
evans VBZ
2001 CD
< NN
/ref NNP
> NN
in IN
his PRP$
criticism NN
: :
the DT
patterns NNS
are VBP
robust JJ
to TO
intervening VBG
words NNS
and CC
modi NN
ers NNS
eg VBP
it PRP
was VBD
never RB
thought VBN
by IN
the DT
committee NN
that WDT
provided VBD
the DT
sentence NN
is VBZ
parsed VBN
correctly7 NN
we PRP
automatically RB
parse JJ
sentences NNS
with IN
minipar NN
, ,
a DT
broad-coverage JJ
dependency NN
parser NN
< NNP
tref NN
> NNP
lin NN
, ,
1998b CD
< NN
/tref NNP
> NNP
. .

our PRP$
work NN
is VBZ
part NN
of IN
a DT
trend NN
of IN
extracting VBG
other JJ
important JJ
information NN
from IN
statistical JJ
distributions NNS
. .

unfortunately RB
, ,
none NN
of IN
the DT
corpus-based JJ
features NNS
improved VBN
performance NN
on IN
the DT
development NN
set NN
and CC
are VBP
thus RB
excluded VBN
from IN
further JJ
consideration NN
. .

1 CD
thesaurus JJ
creation NN
over IN
the DT
last JJ
ten JJ
years NNS
, ,
interest NN
has VBZ
been VBN
growing VBG
in IN
distributional JJ
thesauruses NNS
hereafter VBP
simply RB
thesauruses NNS
. .

we PRP
then RB
calculate VB
normalized JJ
tuple JJ
similarity NN
scores VBZ
over IN
the DT
tuple JJ
pairs NNS
using VBG
a DT
metric JJ
that WDT
accounts VBZ
for IN
similarities NNS
in IN
both DT
syntactic JJ
structure NN
and CC
content NN
of IN
each DT
tuple NN
. .

a DT
thesaurus NN
constructed VBN
from IN
corpus NN
statistics NNS
< VBP
tref JJ
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
is VBZ
utilized VBN
for IN
the DT
content JJ
similarity NN
. .

we PRP
term NN
these DT
vectors NNS
lexical VBP
because IN
they PRP
are VBP
collected VBN
by IN
looking VBG
only RB
at IN
the DT
lexicals NNS
in IN
the DT
text NN
ie NN
no DT
sense NN
information NN
is VBZ
used VBN
. .

we PRP
use VBP
the DT
term NN
ontological JJ
feature NN
vector NN
to TO
refer VB
to TO
a DT
feature NN
vector NN
whose WP$
features NNS
are VBP
for IN
a DT
particular JJ
sense NN
of IN
the DT
word NN
. .

summationtext JJ
lh NN
scorel NN
openclasswordsh VBD
2 CD
2we CD
set VBD
the DT
threshold NN
to TO
001 CD
3the CD
active JJ
verbal JJ
form NN
with IN
direct JJ
modifiers NNS
where WRB
scorel NN
is VBZ
1 CD
if IN
it PRP
appears VBZ
in IN
p NN
, ,
or CC
if IN
it PRP
is VBZ
a DT
derivation NN
of IN
a DT
word NN
in IN
p NN
according VBG
to TO
wordnet NN
. .

3 CD
proof NN
system NN
like IN
logic-based JJ
systems NNS
, ,
our PRP$
proof NN
system NN
consists VBZ
of IN
propositions NNS
t NNS
, ,
h NN
, ,
and CC
intermediate JJ
premises NNS
, ,
and CC
inference NN
entailment NN
rules NNS
, ,
which WDT
derive VBP
new JJ
propositions NNS
from IN
previously RB
established VBN
ones NNS
. .

as IN
a DT
striking JJ
example NN
, ,
the DT
14 CD
most JJS
syntactically RB
similar JJ
verbs NNS
to TO
believe VB
in IN
order NN
are VBP
think NN
, ,
guess NN
, ,
hope NN
, ,
feel NN
, ,
wonder NN
, ,
theorize NN
, ,
fear NN
, ,
reckon NN
, ,
contend NN
, ,
suppose VB
, ,
understand VB
, ,
know VB
, ,
doubt NN
, ,
and CC
suggest JJS
all DT
mental JJ
action NN
verbs NN
. .

verb NN
pairs NNS
instances NNS
cosine VBP
bind IN
83 CD
bound NN
95 CD
0950 CD
plunge NN
94 CD
tumble NN
87 CD
0888 CD
dive NN
36 CD
plunge NN
94 CD
0867 CD
dive JJ
36 CD
tumble JJ
87 CD
0866 CD
jump NN
79 CD
tumble NN
87 CD
0865 CD
fall NN
84 CD
fell VBD
102 CD
0859 CD
intersperse NN
99 CD
perch NN
81 CD
0859 CD
assail NN
100 CD
chide NN
98 CD
0859 CD
dip NN
81 CD
fell VBD
102 CD
0858 CD
buffet NN
72 CD
embroil NN
100 CD
0856 CD
embroil NN
100 CD
lock NN
73 CD
0856 CD
embroil NN
100 CD
superimpose RB
100 CD
0856 CD
fell VBD
102 CD
jump NN
79 CD
0855 CD
fell VBD
102 CD
tumble JJ
87 CD
0855 CD
embroil NN
100 CD
whipsaw VBD
63 CD
0850 CD
pluck NN
100 CD
whisk NN
99 CD
0849 CD
acquit NN
100 CD
hospitalize NN
99 CD
0849 CD
disincline NN
70 CD
obligate NN
94 CD
0848 CD
jump NN
79 CD
plunge NN
94 CD
0848 CD
dive JJ
36 CD
jump NN
79 CD
0847 CD
assail NN
100 CD
lambaste NN
100 CD
0847 CD
festoon NN
98 CD
strew VBD
100 CD
0846 CD
mar NN
78 CD
whipsaw VBD
63 CD
0846 CD
pluck NN
100 CD
whipsaw VBD
63 CD
0846 CD
ensconce NN
101 CD
whipsaw VBD
63 CD
0845 CD
table JJ
2 CD
. .

top JJ
25 CD
most JJS
syntactically RB
similar JJ
pairs NNS
of IN
the DT
3257 CD
verbs NN
in IN
propbank NN
. .

our PRP$
approach NN
is VBZ
strictly RB
empirical JJ
; :
the DT
similarity NN
of IN
verbs NN
is VBZ
determined VBN
by IN
examining VBG
the DT
syntactic JJ
contexts NN
in IN
which WDT
they PRP
appear VBP
in IN
a DT
large JJ
text NN
corpus NN
. .

our PRP$
approach NN
is VBZ
analogous JJ
to TO
previous JJ
work NN
in IN
extracting VBG
collocations NNS
from IN
large JJ
text NN
corpora NN
using VBG
syntactic JJ
information NN
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
. .

this DT
work NN
proposes VBZ
using VBG
graded VBN
word NN
sense NN
relationships VBZ
rather RB
than IN
fixed VBN
groupings NNS
clusters NNS
. .

this DT
is VBZ
transformed VBN
from IN
a DT
distance NN
measure NN
in IN
the DT
wn-similarity JJ
package NN
by IN
taking VBG
the DT
reciprocal JJ
: :
jcns1 NN
, ,
s2 JJ
1/djcns1 CD
, ,
s2 NN
we PRP
use VBP
raw JJ
bnc NN
data NNS
for IN
calculating VBG
ic JJ
values NNS
. .

dist NN
we PRP
use VBP
a DT
distributional JJ
similarity NN
measure NN
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
to TO
obtain VB
a DT
fixed JJ
number NN
50 CD
of IN
the DT
top JJ
ranked VBD
nearest JJS
neighbours NNS
for IN
the DT
target NN
nouns NNS
. .

the DT
number NN
of IN
unique JJ
collocations NNS
in IN
the DT
resulting JJ
database NN
2 CD
is VBZ
about IN
11 CD
million CD
. .

to TO
measure VB
the DT
compositionality NN
, ,
semantically RB
similar JJ
words NNS
are VBP
more RBR
suitable JJ
than IN
synomys NN
. .

902 CD
614 CD
distributed JJ
frequency NN
of IN
object JJ
a0 IN
the DT
distributed JJ
frequency NN
of IN
object NN
is VBZ
based VBN
on IN
the DT
idea NN
that IN
if IN
an DT
object NN
appears VBZ
only RB
with IN
one CD
verb NN
or CC
few JJ
verbs NNS
in IN
a DT
large JJ
corpus NN
, ,
the DT
collocation NN
is VBZ
expected VBN
to TO
have VB
idiomatic JJ
nature NN
< NNP
ref NN
> NNP
tapanainen NN
et NN
al NN
, ,
1998 CD
< NN
/ref NNP
> NNP
. .

for IN
example NN
, ,
sure JJ
in IN
make NN
sure JJ
occurs VBZ
with IN
very RB
few JJ
verbs NNS
. .

the DT
higher JJR
the DT
value NN
of IN
a38 NN
, ,
the DT
more RBR
is VBZ
the DT
likelihood NN
of IN
the DT
collocation NN
to TO
be VB
a DT
mwe NN
. .

we PRP
obtained VBD
the DT
best JJS
results NNS
section NN
8 CD
when WRB
we PRP
substituted VBD
top-5 JJ
similar JJ
words NNS
for IN
both DT
the DT
verb NN
and CC
the DT
object NN
. .

to TO
measure VB
the DT
compositionality NN
, ,
semantically RB
similar JJ
words NNS
are VBP
more RBR
suitable JJ
than IN
synomys NN
. .

lins NNS
database NN
was VBD
created VBN
using VBG
the DT
particular JJ
distributionalsimilaritymeasurein NN
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
, ,
applied VBD
to TO
a DT
large JJ
corpus NN
of IN
news NN
data NNS
64 CD
million CD
words NNS
4 CD
. .

the DT
setting NN
allowed VBD
us PRP
to TO
analyze VB
different JJ
types NNS
of IN
state NN
of IN
the DT
art NN
models NNS
and CC
their PRP$
behavior NN
with IN
respect NN
to TO
characteristic JJ
sub-cases NNS
of IN
the DT
problem NN
. .

the DT
major JJ
conclusion NN
that WDT
seems VBZ
to TO
arise VB
from IN
our PRP$
experiments NNS
is VBZ
the DT
effectiveness NN
of IN
combining VBG
a DT
knowledge NN
based VBN
thesaurus NN
such JJ
as IN
wordnet NN
with IN
distributional JJ
statistical JJ
information NN
such JJ
as IN
< JJ
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
, ,
overcoming VBG
the DT
known JJ
deficiencies NNS
of IN
each DT
method NN
alone RB
. .

on IN
the DT
other JJ
hand NN
, ,
successfully RB
incorporating VBG
local JJ
and CC
global JJ
contextual JJ
information NN
, ,
as IN
similar JJ
to TO
wsd VB
methods NNS
, ,
remains VBZ
a DT
challenging JJ
task NN
for IN
future JJ
research NN
. .

the DT
method NN
we PRP
use VBP
to TO
predict VB
the DT
rst NN
sense NN
is VBZ
that IN
of IN
mccarthy JJ
et FW
al NN
. .

in IN
the DT
case NN
of IN
sfs NN
, ,
we PRP
perform VBP
full JJ
synset NN
wsd NNS
based VBN
on IN
one CD
of IN
the DT
above NN
options NNS
, ,
and CC
then RB
map VB
the DT
prediction NN
onto IN
the DT
corresponding JJ
unique JJ
sf NN
. .

if IN
a98a56a30a31a4 JJ
a33 NN
is VBZ
the DT
set NN
of IN
co-occurrence NN
types NNS
a30 VBP
a55 JJ
a14a16a95 JJ
a33 NN
such JJ
that IN
a99a100a30a42a4a43a14 VBP
a55 JJ
a14a32a95 NN
a33 NN
is VBZ
positive JJ
then RB
the DT
similarity NN
between IN
two CD
nouns NNS
, ,
a4 NN
and CC
a10 NN
, ,
can MD
be VB
computed VBN
as IN
: :
a26a41a28a15a28a27a30a42a4a43a14a16a10 NN
a33 NN
a8 NN
a75 NN
a83a102a101a42a103a50 NN
a85 NN
a70a11a104 NN
a83a102a6a13a85a106a105 NN
a104 NN
a83 NN
a67 NN
a85 NN
a30a78a99a100a30a31a4a7a14 NN
a55 NN
a14a16a95 NN
a33a41a107 NN
a99a108a30a31a10a109a14 NN
a55 NN
a14a16a95 NN
a33a86a33 NN
a75 NN
a83a102a101a42a103a50 NN
a85 NN
a70a11a104 NN
a83a102a6a13a85 NN
a99a108a30a31a4a7a14 NN
a55 NN
a14a32a95 NN
a33a45a107 NN
a75 NN
a83a84a101a42a103a50 NN
a85 NN
a70a11a104 NN
a83 NN
a67 NN
a85 NN
a99a108a30a31a10a109a14 NN
a55 NN
a14a16a95 NN
a33 NN
where WRB
: :
a99a108a30a31a4a7a14 NN
a55 NN
a14a32a95 NN
a33 NN
a8a111a110a21a112a114a113 NN
a54 NN
a30a31a95a73a115a116a4a118a117 NN
a55 NN
a33 NN
a54 NN
a30a42a95a73a115 NN
a55 NN
a33 VBZ
a DT
thesaurus JJ
entry NN
of IN
size NN
a3 NN
for IN
a DT
target NN
noun JJ
a4 NN
is VBZ
then RB
defined VBN
as IN
the DT
a3 NN
most RBS
similar JJ
nouns NNS
to TO
a4 VB
22 CD
the DT
wordnet NN
similarity NN
package NN
we PRP
use VBP
the DT
wordnet NN
similarity NN
package NN
005 CD
and CC
wordnet JJ
version NN
16 CD
. .

in IN
order NN
to TO
find VB
the DT
predominant JJ
sense NN
of IN
a DT
target NN
word NN
we PRP
use VBP
a DT
thesaurus NN
acquired VBN
from IN
automatically RB
parsed VBN
text NN
based VBN
on IN
the DT
method NN
of IN
< NNP
tref NN
> NNP
lin NN
1998 CD
< NNP
/tref NNP
> NNP
. .

we PRP
then RB
use VBP
the DT
wordnet NN
similarity NN
package NN
< NNP
ref NN
> NNP
patwardhan NN
and CC
pedersen NN
, ,
2003 CD
< NN
/ref NNP
> NNP
to TO
give VB
us PRP
a DT
semantic JJ
similarity NN
measure NN
hereafter NN
referred VBD
to TO
as IN
the DT
wordnet NN
similarity NN
measure NN
to TO
weight VB
the DT
contribution NN
that IN
each DT
neighbour NN
makes VBZ
to TO
the DT
various JJ
senses NNS
of IN
the DT
target NN
word NN
. .

let VB
a28a15a34a20a10a18a28a20a34a15a28a25a30a31a4 PRP
a33 RB
be VB
the DT
set NN
of IN
senses NNS
of IN
a4 NN
for IN
each DT
sense NN
of IN
a4 NN
a4a35a28a37a36a39a38a40a28a20a34a15a10a13a28a15a34a20a28a27a30a31a4 NN
a33 IN
we PRP
obtain VB
a DT
ranking JJ
score NN
by IN
summing VBG
over IN
the DT
a26a41a28a15a28a27a30a42a4a43a14a16a10a45a44 JJ
a33 NN
of IN
each DT
neighbour JJ
a10a46a44a47a38a48a5 NN
a6 NN
multiplied VBN
by IN
a DT
weight NN
. .

this DT
weight NN
is VBZ
the DT
wordnet NN
similarity NN
score NN
a4a49a10a13a28a15a28 NN
between IN
the DT
target NN
sense NN
a4a35a28a37a36 NN
and CC
the DT
sense NN
of IN
a10a45a44 NN
a10a13a28a37a50a51a38a52a28a15a34a15a10a13a28a20a34a15a28a27a30a42a10a45a44 NN
a33 NN
that WDT
maximises VBZ
this DT
score NN
, ,
divided VBN
by IN
the DT
sum NN
of IN
all DT
such JJ
wordnet JJ
similarity NN
scores NNS
for IN
a28a20a34a15a10a13a28a15a34a20a28a27a30a31a4 NN
a33 NN
and CC
a10a46a44 JJ
thus RB
we PRP
rank VBP
each DT
sense NN
a4a49a28 VBZ
a36 JJ
a38a53a28a15a34a20a10a18a28a20a34a15a28a25a30a31a4 NN
a33 NN
using VBG
: :
a54a56a55 NN
a34a15a57a41a58a41a59a60a34a15a10a13a61a37a34a63a62a64a61a37a65 NN
a55 NN
a34a27a30a31a4a35a28a37a36 NN
a33 NN
a8 NN
a66 NN
a67a69a68a32a70a27a71a73a72 NN
a26a29a28a20a28a27a30a31a4a7a14a32a10 NN
a44 NN
a33a15a74 NN
a4a49a10a13a28a20a28a27a30a31a4a35a28a37a36a42a14a32a10a46a44 NN
a33 NN
a75 NN
a6a18a76a78a77a80a79 NN
a70 NN
a76a82a81 NN
a67 NN
a76a78a81a82a76a42a83a84a6a18a85 NN
a4a35a10a13a28a15a28a25a30a31a4a49a28 NN
a36 NN
a79 NN
a14a16a10a45a44 NN
a33 NN
1 CD
where WRB
: :
a4a49a10a13a28a20a28a27a30a31a4a35a28a37a36a86a14a16a10a45a44 NN
a33 NN
a8 NN
a87a89a88a20a90 NN
a67 NN
a76a92a91 NN
a70 NN
a76a78a81 NN
a67 NN
a76a78a81a82a76a93a83 NN
a67a69a68 NN
a85 NN
a30a42a4a49a10a13a28a15a28a25a30a31a4a35a28a37a36a42a14a32a10a13a28a37a50 NN
a33a86a33 VBZ
21 CD
acquiring VBG
the DT
automatic JJ
thesaurus NN
the DT
thesaurus NN
was VBD
acquired VBN
using VBG
the DT
method NN
described VBN
by IN
< NNP
tref NN
> NNP
lin NN
1998 CD
< NNP
/tref NNP
> NNP
. .

< JJ
ref NN
> NNS
like IN
lin NN
1999 CD
< NNP
/ref NNP
> NNP
, ,
we PRP
generate VBP
lexical JJ
variants NNS
of IN
the DT
target NN
automatically RB
by IN
replacing VBG
either CC
the DT
verb NN
or CC
the DT
noun JJ
constituent NN
by IN
a DT
semantically RB
similar JJ
word NN
from IN
the DT
automatically-built JJ
thesaurus NN
of IN
< NNP
tref NN
> NNP
lin NN
1998 CD
< NNP
/tref NNP
> NNP
. .

we PRP
use VBP
wordnet JJ
wn NN
as IN
our PRP$
sense NN
inventory NN
. .

the DT
senses NNS
of IN
a DT
worda2 NN
are VBP
each DT
assigned VBD
a DT
ranking NN
score NN
which WDT
sums VBZ
over IN
the DT
distributional JJ
similarity NN
scores NNS
of IN
the DT
neighbours NNS
and CC
weights NNS
each DT
neighbours NNS
score RB
by IN
a DT
wn JJ
similarity NN
score NN
< NNP
ref NN
> NNP
patwardhan NN
and CC
pedersen NN
, ,
2003 CD
< NN
/ref NNP
> NNP
between IN
the DT
sense NN
of IN
a2 NN
and CC
the DT
sense NN
of IN
the DT
neighbour NN
that WDT
maximises VBZ
the DT
wn NN
similarity NN
score NN
. .

early JJ
experiments NNS
in IN
thesaurus JJ
extraction NN
< NNP
ref NN
> NNP
grefenstette NN
, ,
1994 CD
< NN
/ref NNP
> NNP
suffered VBD
from IN
the DT
limited JJ
size NN
of IN
available JJ
corpora NNS
, ,
but CC
more RBR
recent JJ
experiments NNS
have VBP
used VBN
much RB
larger JJR
corpora NN
with IN
greater JJR
success NN
< NNP
tref NN
> NNP
lin NN
, ,
1998a CD
< NN
/tref NNP
> NNP
. .

the DT
list NN
of IN
measure NN
and CC
weight JJ
functions NNS
we PRP
compared VBN
against IN
is VBZ
not RB
complete JJ
, ,
and CC
we PRP
hope VBP
to TO
add VB
other JJ
functions NNS
to TO
provide VB
a DT
general JJ
framework NN
for IN
thesaurus JJ
extraction NN
experimentation NN
. .

we PRP
would MD
also RB
like VB
to TO
expand VB
our PRP$
evaluation NN
to TO
include VB
direct JJ
methods NNS
used VBN
by IN
others NNS
< NNP
tref NN
> NNP
lin NN
, ,
1998a CD
< NN
/tref NNP
> NNP
and CC
using VBG
the DT
extracted JJ
thesaurus NN
in IN
nlp JJ
tasks NNS
. .

our PRP$
proposed VBN
weight NN
functions NNS
are VBP
motivated VBN
by IN
our PRP$
intuition NN
that IN
highly RB
predictive JJ
attributes NNS
are VBP
strong JJ
collocations NNS
with IN
their PRP$
terms NNS
. .

we PRP
describe VBP
the DT
functions NNS
evaluated VBN
in IN
these DT
experiments NNS
using VBG
an DT
extension NN
of IN
the DT
asterisk JJ
notation NN
used VBN
by IN
< JJ
tref NN
> NNP
lin VBZ
1998a CD
< NN
/tref NNP
> NNP
, ,
where WRB
an DT
asterisk NN
indicates VBZ
a DT
set NN
ranging NN
over IN
all DT
existing VBG
values NNS
of IN
that DT
variable NN
. .

432 CD
the DT
brandeis NN
semantic JJ
ontology NN
as IN
a DT
second JJ
source NN
of IN
lexical JJ
coherence NN
, ,
we PRP
used VBD
the DT
brandeis JJ
semantic JJ
ontology NN
or CC
bso NN
< JJ
ref NN
> NNP
pustejovsky NN
et NN
al NN
, ,
2006 CD
< NN
/ref NNP
> NNP
. .

the DT
bso NN
is VBZ
a DT
lexicallybased JJ
ontology NN
in IN
the DT
generative JJ
lexicon NN
tradition NN
< NNP
ref NN
> NNP
pustejovsky NN
, ,
2001 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
pustejovsky NN
, ,
1995 CD
< NN
/ref NNP
> NNP
. .

3 CD
learning VBG
to TO
merge VB
word NN
senses VBZ
31 CD
wordnet-based JJ
features NNS
here RB
we PRP
describe VBP
the DT
feature NN
space NN
we PRP
construct VBP
for IN
classifying VBG
whether IN
or CC
not RB
a DT
pair NN
of IN
synsets NNS
should MD
be VB
merged VBN
; :
first RB
, ,
we PRP
employ VBP
a DT
wide JJ
variety NN
of IN
linguistic JJ
features NNS
based VBN
on IN
information NN
derived VBN
from IN
wordnet NN
. .

we PRP
use VBP
eight CD
similarity NN
measures NNS
implemented VBN
within IN
the DT
wordnet NN
: :
:similarity NN
package5 NN
, ,
described VBN
in IN
< NNP
ref NN
> NNP
pedersen NN
et NN
al NN
, ,
2004 CD
< NN
/ref NNP
> NNP
; :
these DT
include VBP
three CD
measures NNS
derived VBN
from IN
the DT
paths NNS
between IN
the DT
synsets NNS
in IN
wordnet NN
: :
hso NN
hirst NN
and CC
st- JJ
< NNP
ref NN
> NNP
onge NN
, ,
1998 CD
< NN
/ref NNP
> NNP
, ,
lch NN
< NNP
ref NN
> NNP
leacock NN
and CC
chodorow NN
, ,
1998 CD
< NN
/ref NNP
> NNP
, ,
and CC
wup JJ
< NNP
ref NN
> NNP
wu NN
and CC
palmer NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
three CD
measures NNS
based VBN
on IN
information NN
content NN
: :
res NNS
< VBP
ref JJ
> NNP
resnik NN
, ,
1995 CD
< NN
/ref NNP
> NNP
, ,
lin NN
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
, ,
and CC
jcn NN
< NNP
ref NN
> NNP
jiang NN
and CC
conrath NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
the DT
gloss-based JJ
extended JJ
lesk NN
measure NN
lesk NN
, ,
< NNP
ref VBZ
> NNP
banerjee NN
and CC
pedersen NN
, ,
2003 CD
< NN
/ref NNP
> NNP
, ,
and CC
finally RB
the DT
gloss NN
vector NN
similarity NN
measure NN
vector NN
< NNP
ref NN
> NNP
patwardan NN
, ,
2003 CD
< NN
/ref NNP
> NNP
. .

in IN
this DT
paper NN
we PRP
focus VBP
on IN
the DT
task NN
of IN
automatically RB
selecting VBG
the DT
best JJS
near-synonym JJ
that DT
should MD
be VB
used VBN
in IN
a DT
particular JJ
context NN
. .

the DT
natural JJ
way NN
to TO
validate VB
an DT
algorithm NN
for IN
this DT
task NN
would MD
be VB
to TO
ask VB
human JJ
readers NNS
to TO
evaluate VB
the DT
quality NN
of IN
the DT
algorithms NN
output NN
, ,
but CC
this DT
kind NN
of IN
evaluation NN
would MD
be VB
very RB
laborious JJ
. .

word-similarity NN
classes NNS
< VBP
tref JJ
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
derived VBD
from IN
clustering VBG
are VBP
also RB
used VBN
to TO
expand VB
the DT
pool NN
of IN
potential JJ
collocations NNS
; :
this DT
type NN
of IN
semantic JJ
relatedness NN
among IN
words NNS
is VBZ
expressed VBN
in IN
the DT
similarcoll NN
feature NN
. .

when WRB
formulating VBG
the DT
features NNS
similarcoll VBP
and CC
dictcoll NN
, ,
the DT
words NNS
related VBN
to TO
each DT
context NN
word NN
are VBP
considered VBN
as IN
potential JJ
collocations NNS
< VBP
ref JJ
> NNP
wiebe NN
et NN
al NN
, ,
1998 CD
< NN
/ref NNP
> NNP
. .

co-occurrence NN
fresense NN
distinctions NNS
precision VBP
recall VB
fine-grained JJ
566 CD
565 CD
course-grained JJ
660 CD
658 CD
table JJ
1 CD
: :
results NNS
for IN
senseval-3 JJ
test NN
data NNS
. .

if IN
the DT
precision NN
of IN
s NN
i NN
c VBP
i NN
, ,
n NN
is VBZ
greater JJR
than IN
a DT
threshold JJ
t NN
, ,
then RB
the DT
words NNS
in IN
this DT
set NN
are VBP
retained VBN
as IN
pses NNS
. .

this DT
is VBZ
important JJ
for IN
subjectivity NN
recognition NN
, ,
because IN
pses NNS
are VBP
not RB
limited VBN
to TO
verb-noun JJ
relationships NNS
. .

the DT
method NN
is VBZ
then RB
used VBN
to TO
identify VB
an DT
unusual JJ
form NN
of IN
collocation NN
: :
one CD
or CC
more JJR
positions NNS
in IN
the DT
collocation NN
may MD
be VB
filled VBN
by IN
any DT
word NN
of IN
an DT
appropriate JJ
part NN
of IN
speech NN
that WDT
is VBZ
unique JJ
in IN
the DT
test NN
data NNS
. .

we PRP
hypothesized VBD
that IN
two CD
words NNS
may MD
be VB
distributionally RB
similar JJ
because IN
they PRP
are VBP
both DT
potentially RB
subjective JJ
eg NN
, ,
tragic JJ
, ,
sad JJ
, ,
and CC
poignant NN
are VBP
identified VBN
from IN
bizarre NN
. .

in IN
addition NN
, ,
we PRP
use VBP
distributional JJ
similarity NN
to TO
improve VB
estimates NNS
of IN
unseen JJ
events NNS
: :
a DT
word NN
is VBZ
selected VBN
or CC
discarded VBN
based VBN
on IN
the DT
precision NN
of IN
it PRP
together RB
with IN
its PRP$
n NN
most RBS
similar JJ
neighbors NNS
. .

we PRP
also RB
presented VBD
a DT
procedure NN
for IN
automatically RB
identifying VBG
potentially RB
subjective JJ
collocations NNS
, ,
including VBG
fixed VBN
collocations NNS
and CC
collocations NNS
with IN
placeholders NNS
for IN
unique JJ
words NNS
. .

table JJ
9 CD
summarizes VBZ
the DT
results NNS
of IN
testing VBG
all DT
of IN
the DT
above JJ
types NNS
of IN
pses NNS
. .

all DT
show NN
increased VBD
precision NN
in IN
the DT
evaluations NNS
. .

we PRP
picked VBD
the DT
widely RB
cited VBN
and CC
competitive JJ
eg NN
. .

< JJ
ref NN
> NNP
weeds NNS
and CC
weir NN
, ,
2003 CD
< NN
/ref NNP
> NNP
measure NN
of IN
< NNP
tref NN
> NNP
lin NN
1998 CD
< NNP
/tref NNP
> NNP
as IN
a DT
representative JJ
case NN
, ,
and CC
utilized VBD
it PRP
for IN
our PRP$
analysis NN
and CC
as IN
a DT
starting NN
point NN
for IN
improvement NN
. .

21 CD
lins VBZ
98 CD
similarity NN
measure NN
lins VBZ
similarity JJ
measure NN
between IN
two CD
words NNS
, ,
w NN
and CC
v NN
, ,
is VBZ
defined VBN
as IN
follows VBZ
: :
, ,
, ,
, ,
, ,
, ,
, ,
fvweightfwweight VBD
fvweightfwweight JJ
vwsim NN
vffwff NN
vfwff NN
where WRB
fw NN
and CC
fv NN
are VBP
the DT
active JJ
features NNS
of IN
the DT
two CD
words NNS
and CC
the DT
weight NN
function NN
is VBZ
defined VBN
as IN
mi NN
. .

the DT
target NN
text NN
is VBZ
used VBN
for IN
this DT
purpose NN
, ,
provided VBD
it PRP
is VBZ
large JJ
enough RB
to TO
learn VB
a DT
thesaurus NN
from IN
. .

otherwise RB
a DT
large JJ
corpus NN
with IN
sense NN
distribution NN
similar JJ
to TO
the DT
target NN
text JJ
text NN
pertaining NN
to TO
the DT
specified VBN
domain NN
must MD
be VB
used VBN
. .

below NN
are VBP
contrived VBN
, ,
but CC
plausible JJ
, ,
examples NNS
of IN
each DT
for IN
the DT
word NN
pulse NN
; :
the DT
numbers NNS
are VBP
conditional JJ
probabilities NNS
. .

relation-free JJ
dp NN
pulse NN
: :
beat NN
28 CD
, ,
racing VBG
2 CD
, ,
grow NN
13 CD
, ,
beans NNS
09 CD
, ,
heart NN
04 CD
, ,
. .

jsd NN
cp NN
is VBZ
another DT
relative NN
entropybased VBN
measure NN
like IN
asd NN
cp NN
but CC
it PRP
is VBZ
symmetric JJ
. .

simjami NN
is VBZ
a DT
variant JJ
< NN
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
in IN
which WDT
the DT
features NNS
of IN
a DT
word NN
are VBP
those DT
contexts NNS
for IN
which WDT
the DT
pointwise NN
mutual JJ
information NN
mi NN
between IN
the DT
word NN
and CC
the DT
context NN
is VBZ
positive JJ
, ,
where WRB
mi NN
can MD
be VB
calculated VBN
using VBG
ic NN
; :
w CC
log NN
pcjwpc NN
. .

let VB
seenrp NN
be VB
the DT
set NN
of IN
seen VBN
headwords NNS
for IN
an DT
argument NN
rp NN
of IN
a DT
predicate NN
p NN
then RB
we PRP
model VBP
the DT
selectional JJ
preference NN
s NN
of IN
rp NN
for IN
a DT
possible JJ
headword NN
w0 NN
as IN
a DT
weighted JJ
sum NN
of IN
the DT
similarities NNS
between IN
w0 NN
and CC
the DT
seen VBN
headwords NNS
: :
srpw0 NN
summationdisplay NN
wseenrp NN
simw0 NN
, ,
wwtrpw NN
simw0 NN
, ,
w NN
is VBZ
the DT
similarity NN
between IN
the DT
seen VBN
and CC
the DT
potential JJ
headword NN
, ,
and CC
wtrpw NN
is VBZ
the DT
weight NN
of IN
seen VBN
headword NN
w NN
similarity NN
simw0 NN
, ,
w WP
will MD
be VB
computed VBN
on IN
the DT
generalization NN
corpus NN
, ,
again RB
on IN
the DT
basis NN
of IN
extracted JJ
tuples NNS
p RB
, ,
rp NN
, ,
w NN
. .

we PRP
will MD
be VB
using VBG
the DT
similarity NN
metrics NNS
shown VBN
in IN
table JJ
1 CD
: :
cosine NN
, ,
the DT
dice NNS
and CC
jaccard NN
coefficients NNS
, ,
and CC
< NNP
ref VBP
> NNP
hindles NNS
1990 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NN
lins NNS
1998 CD
< NNP
/tref NNP
> NNP
mutual JJ
information-based JJ
metrics NNS
. .

in IN
this DT
paper NN
we PRP
propose VBP
a DT
new JJ
, ,
simple JJ
model NN
for IN
selectional JJ
preference NN
induction NN
that WDT
uses VBZ
corpus-based JJ
semantic JJ
similarity NN
metrics NNS
, ,
such JJ
as IN
cosine NN
or CC
< VB
tref JJ
> NN
lins VBZ
1998 CD
< NN
/tref NNP
> NNP
mutual JJ
informationbased VBD
metric JJ
, ,
for IN
the DT
generalization NN
step NN
. .

the DT
use NN
of IN
synonyms NN
is VBZ
another DT
way NN
of IN
increasing VBG
the DT
coverage NN
of IN
question NN
terminology NN
; :
; :
while IN
semantic JJ
features NNS
try VBP
to TO
achieve VB
it PRP
by IN
generalization NN
, ,
synonyms NN
do VBP
it PRP
by IN
lexical JJ
expansion NN
. .

our PRP$
plan NN
is VBZ
to TO
use VB
the DT
synonyms NN
obtained VBN
from IN
very RB
large JJ
corpora NN
reported VBD
in IN
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
. .

our PRP$
approach NN
can MD
be VB
distinguished VBN
from IN
classical JJ
distributional JJ
approach NN
by IN
different JJ
points NNS
. .

first RB
, ,
we PRP
use VBP
triple JJ
occurrences NNS
to TO
build VB
a DT
distributional JJ
space NN
one CD
triple NN
implies VBZ
two CD
contexts NN
and CC
two CD
lexical JJ
units NNS
, ,
but CC
we PRP
use VBP
the DT
transpose NN
of IN
the DT
classical JJ
space NN
: :
each DT
point NN
x VBP
i NN
of IN
this DT
space NN
is VBZ
a DT
syntactical JJ
context NN
with IN
the DT
form NN
rw NN
, ,
each DT
dimension NN
j NN
is VBZ
a DT
lexical JJ
units NNS
, ,
and CC
each DT
value NN
x VBP
i JJ
j NN
is VBZ
the DT
frequency NN
of IN
corresponding VBG
triple JJ
occurrences NNS
. .

it PRP
extends VBZ
prior JJ
work NN
on IN
syntax-based JJ
models NNS
< VBP
ref JJ
> NNP
grefenstette NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
, ,
by IN
providing VBG
a DT
general JJ
framework NN
for IN
defining VBG
context NN
so RB
that IN
a DT
large JJ
number NN
of IN
syntactic JJ
relations NNS
can MD
be VB
used VBN
in IN
the DT
construction NN
of IN
the DT
semantic JJ
space NN
. .

our PRP$
approach NN
differs NNS
from IN
< JJ
tref NN
> NNP
lin NN
1998 CD
< NNP
/tref NNP
> NNP
in IN
three CD
important JJ
ways NNS
: :
a DT
by IN
introducing VBG
dependency NN
paths IN
we PRP
can MD
capture VB
non-immediate JJ
relationships NNS
between IN
words NNS
ie VBP
, ,
between IN
subjects NNS
and CC
objects NNS
, ,
whereas NNS
lin VBP
considers NNS
only RB
local JJ
context NN
dependency NN
edges VBZ
in IN
our PRP$
terminology NN
; :
the DT
semantic JJ
space NN
is VBZ
therefore RB
constructed VBN
solely RB
from IN
isolated VBN
head/modifier NN
pairs NNS
and CC
their PRP$
inter-dependencies NNS
are VBP
not RB
taken VBN
into IN
account NN
; :
b CC
lin NN
creates VBZ
the DT
semantic JJ
space NN
from IN
the DT
set NN
of IN
dependency NN
edges NNS
that WDT
are VBP
relevant JJ
for IN
a DT
given VBN
word NN
; :
by IN
introducing VBG
dependency NN
labels NNS
and CC
the DT
path NN
value NN
function NN
we PRP
can MD
selectively RB
weight VB
the DT
importance NN
of IN
different JJ
labels NNS
eg VBP
, ,
subject JJ
, ,
object JJ
, ,
modifier JJR
and CC
parametrize VB
the DT
space NN
accordingly RB
for IN
different JJ
tasks NNS
; :
c VBZ
considerable JJ
flexibility NN
is VBZ
allowed VBN
in IN
our PRP$
formulation NN
for IN
selecting VBG
the DT
dimensions NNS
of IN
the DT
semantic JJ
space NN
; :
the DT
latter NN
can MD
be VB
words NNS
see VB
the DT
leaves NNS
in IN
figure NN
1 CD
, ,
parts NNS
of IN
speech NN
or CC
dependency NN
edges NNS
; :
in IN
lins NNS
approach VBP
, ,
it PRP
is VBZ
only RB
dependency NN
edges VBZ
features NNS
in IN
his PRP$
terminology NN
that WDT
form VBZ
the DT
dimensions NNS
of IN
the DT
semantic JJ
space NN
. .

write VB
a DT
for IN
the DT
lexical JJ
association NN
function NN
which WDT
computes VBZ
the DT
value NN
of IN
a DT
cell NN
of IN
the DT
matrix NN
from IN
a DT
co-occurrence JJ
frequency NN
: :
ki NN
j VBZ
a DT
f JJ
bi NN
; :
t CC
j $
3 CD
evaluation NN
31 CD
parameter NN
settings NNS
all DT
our PRP$
experiments NNS
were VBD
conducted VBN
on IN
the DT
british JJ
national JJ
corpus NN
bnc NN
, ,
a DT
100 CD
million CD
word NN
collection NN
of IN
samples NNS
of IN
written VBN
and CC
spoken VBN
language NN
< NN
ref NN
> NNP
burnard NN
, ,
1995 CD
< NN
/ref NNP
> NNP
. .

we PRP
used VBD
< NNP
tref JJ
> NN
lins VBZ
1998 CD
< NN
/tref NNP
> NNP
broad JJ
coverage NN
dependency NN
parser NN
minipar NN
to TO
obtain VB
a DT
parsed JJ
version NN
of IN
the DT
corpus NN
. .

minipar NN
employs VBZ
a DT
manually RB
constructed VBN
grammar NN
and CC
a DT
lexicon NN
derived VBN
from IN
wordnet NN
with IN
the DT
addition NN
of IN
proper JJ
names NNS
130,000 CD
entries NNS
in IN
total JJ
. .

it PRP
extends VBZ
prior JJ
work NN
on IN
syntax-based JJ
models NNS
< VBP
ref JJ
> NNP
grefenstette NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
, ,
by IN
providing VBG
a DT
general JJ
framework NN
for IN
defining VBG
context NN
so RB
that IN
a DT
large JJ
number NN
of IN
syntactic JJ
relations NNS
can MD
be VB
used VBN
in IN
the DT
construction NN
of IN
the DT
semantic JJ
space NN
. .

our PRP$
approach NN
differs NNS
from IN
< JJ
tref NN
> NNP
lin NN
1998 CD
< NNP
/tref NNP
> NNP
in IN
three CD
important JJ
ways NNS
: :
a DT
by IN
introducing VBG
dependency NN
paths IN
we PRP
can MD
capture VB
non-immediate JJ
relationships NNS
between IN
words NNS
ie VBP
, ,
between IN
subjects NNS
and CC
objects NNS
, ,
whereas NNS
lin VBP
considers NNS
only RB
local JJ
context NN
dependency NN
edges VBZ
in IN
our PRP$
terminology NN
; :
the DT
semantic JJ
space NN
is VBZ
therefore RB
constructed VBN
solely RB
from IN
isolated VBN
head/modifier NN
pairs NNS
and CC
their PRP$
inter-dependencies NNS
are VBP
not RB
taken VBN
into IN
account NN
; :
b CC
lin NN
creates VBZ
the DT
semantic JJ
space NN
from IN
the DT
set NN
of IN
dependency NN
edges NNS
that WDT
are VBP
relevant JJ
for IN
a DT
given VBN
word NN
; :
by IN
introducing VBG
dependency NN
labels NNS
and CC
the DT
path NN
value NN
function NN
we PRP
can MD
selectively RB
weight VB
the DT
importance NN
of IN
different JJ
labels NNS
eg VBP
, ,
subject JJ
, ,
object JJ
, ,
modifier JJR
and CC
parametrize VB
the DT
space NN
accordingly RB
for IN
different JJ
tasks NNS
; :
c VBZ
considerable JJ
flexibility NN
is VBZ
allowed VBN
in IN
our PRP$
formulation NN
for IN
selecting VBG
the DT
dimensions NNS
of IN
the DT
semantic JJ
space NN
; :
the DT
latter NN
can MD
be VB
words NNS
see VB
the DT
leaves NNS
in IN
figure NN
1 CD
, ,
parts NNS
of IN
speech NN
or CC
dependency NN
edges NNS
; :
in IN
lins NNS
approach VBP
, ,
it PRP
is VBZ
only RB
dependency NN
edges VBZ
features NNS
in IN
his PRP$
terminology NN
that WDT
form VBZ
the DT
dimensions NNS
of IN
the DT
semantic JJ
space NN
. .

experiment NN
2 CD
showed VBD
that IN
a DT
model NN
that WDT
relies VBZ
on IN
rich JJ
context JJ
specifications NNS
can MD
reliably VB
distinguish JJ
between IN
different JJ
types NNS
of IN
lexical JJ
relations NNS
. .

however RB
, ,
at IN
structural JJ
level NN
, ,
the DT
concept-based JJ
seeds NNS
share NN
the DT
same JJ
or CC
similar JJ
linguistic JJ
patterns NNS
eg POS
subject-verb-object JJ
patterns NNS
with IN
the DT
corresponding JJ
types NNS
of IN
proper JJ
names NNS
. .

in IN
fact NN
, ,
the DT
anaphoric JJ
function NN
of IN
pronouns NNS
and CC
common JJ
nouns NNS
to TO
represent VB
antecedent JJ
nes NNS
indicates VBZ
the DT
substitutability NN
of IN
proper JJ
names NNS
by IN
the DT
corresponding JJ
common JJ
nouns NNS
or CC
pronouns NNS
. .

for IN
the DT
distributional JJ
similarity NN
component NN
we PRP
employ VBP
the DT
similarity NN
scheme NN
of IN
< NNP
ref NN
> NNP
geffet NN
and CC
dagan NN
, ,
2004 CD
< NN
/ref NNP
> NNP
, ,
which WDT
was VBD
shown VBN
to TO
yield VB
improved JJ
predictions NNS
of IN
non-directional JJ
lexical JJ
entailment NN
pairs NNS
. .

this DT
scheme NN
utilizes VBZ
the DT
symmetric JJ
similarity NN
measure NN
of IN
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
to TO
induce VB
improved JJ
feature NN
weights NNS
via IN
bootstrapping NN
. .

these DT
weights NNS
identify VBP
the DT
most RBS
characteristic JJ
features NNS
of IN
each DT
word NN
, ,
yielding VBG
cleaner JJR
feature NN
vector NN
representations NNS
and CC
better JJR
similarity NN
assessments NNS
. .

distributional JJ
similarity NN
measures NNS
are VBP
typically RB
computed VBN
through IN
exhaustive JJ
processing NN
of IN
a DT
corpus NN
, ,
and CC
are VBP
therefore RB
applicable JJ
to TO
corpora VB
of IN
bounded JJ
size NN
. .

the DT
method NN
uses VBZ
a DT
thesaurus NN
obtained VBN
from IN
the DT
text NN
by IN
parsing VBG
, ,
extracting VBG
grammatical JJ
relations NNS
and CC
then RB
listing VBG
each DT
word NN
w VBZ
with IN
its PRP$
top JJ
k NN
nearest JJS
neighbours NN
, ,
where WRB
k NN
is VBZ
a DT
constant JJ
. .

like IN
< NNP
ref VBP
> NNP
mccarthy JJ
et NN
al NN
, ,
2004 CD
< NN
/ref NNP
> NNP
we PRP
use VBP
k JJ
50 CD
and CC
obtain VB
our PRP$
thesaurus NN
using VBG
the DT
distributional JJ
similarity NN
metric JJ
described VBN
by IN
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
and CC
we PRP
use VBP
wordnet JJ
wn NN
as IN
our PRP$
sense NN
inventory NN
. .

the DT
senses NNS
of IN
a DT
word NN
w NN
are VBP
each DT
assigned VBD
a DT
ranking NN
score NN
which WDT
sums VBZ
over IN
the DT
distributional JJ
similarity NN
scores NNS
of IN
the DT
neighbours NNS
and CC
weights NNS
each DT
neighbours NNS
score RB
by IN
a DT
wn JJ
similarity NN
score NN
< NNP
ref NN
> NNP
patwardhan NN
and CC
pedersen NN
, ,
2003 CD
< NN
/ref NNP
> NNP
between IN
the DT
sense NN
of IN
w NN
and CC
the DT
sense NN
of IN
the DT
neighbour NN
that WDT
maximises VBZ
the DT
wn NN
similarity NN
score NN
. .

those DT
words NNS
that WDT
obtain VB
the DT
best JJS
values NNS
are VBP
considered VBN
to TO
be VB
most RBS
similar JJ
. .

practical JJ
implementations NNS
of IN
algorithms NNS
based VBN
on IN
this DT
principle NN
have VBP
led VBN
to TO
excellent JJ
results NNS
as IN
documented VBN
in IN
papers NNS
by IN
< NNP
ref NN
> NNP
ruge NN
1992 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
grefenstette NN
1994 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> CD
agarwal NN
1995 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> NNP
landauer NN
dumais NN
1997 CD
< NNP
/ref NNP
> NNP
, ,
< NNP
ref VBZ
> CD
schtze NN
1997 CD
< NNP
/ref NNP
> NNP
, ,
and CC
< NNP
tref VBP
> NNP
lin NN
1998 CD
< NNP
/tref NNP
> NNP
. .

fortunately RB
, ,
we PRP
did VBD
not RB
need VB
to TO
conduct VB
our PRP$
own JJ
experiment NN
to TO
obtain VB
the DT
humans NNS
similarity NN
estimates NNS
. .

there EX
are VBP
two CD
parameters NNS
of IN
this DT
process NN
, ,
neither DT
of IN
whichwas NN
varied VBN
in IN
< NNP
ref NN
> NNP
wiebe NN
, ,
2000 CD
< NN
/ref CC
> NN
: :
c NN
, ,
the DT
cluster NN
size NN
considered VBN
, ,
andft RB
, ,
a DT
lteringthreshold NN
, ,
such JJ
that IN
, ,
if IN
the DT
seed NN
word NN
and CC
the DT
words NNS
in IN
its PRP$
cluster NN
have VBP
, ,
as IN
a DT
set NN
, ,
lower JJR
precision NN
than IN
the DT
ltering VBG
threshold NN
on IN
the DT
training NN
data NNS
, ,
the DT
entire JJ
cluster NN
, ,
including VBG
the DT
seed NN
word NN
, ,
is VBZ
ltered VBN
out RP
. .

the DT
use NN
of IN
wordnet NN
measures NNS
is VBZ
intended VBN
to TO
simulate VB
the DT
mental JJ
connections NNS
that IN
visitors NNS
make VBP
between IN
exhibit NN
content NN
, ,
given VBN
that IN
each DT
visit NN
can MD
interpret VB
content NN
in IN
a DT
number NN
of IN
different JJ
ways NNS
. .

22 CD
vocabulary JJ
support NN
synonyms NN
for IN
lower JJR
frequency NN
more RBR
difficult JJ
words NNS
are VBP
output NN
using VBG
a DT
statistically-generated JJ
word NN
similarity NN
matrix NN
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
. .

this DT
shows VBZ
that IN
we PRP
have VBP
extracted VBN
a DT
reasonable JJ
number NN
of IN
features NNS
for IN
each DT
phrase NN
, ,
since IN
distributional JJ
similarity NN
techniques NNS
have VBP
been VBN
shown VBN
to TO
work VB
well RB
for IN
words NNS
which WDT
occur VBP
more JJR
than IN
100 CD
times NNS
in IN
a DT
given VBN
corpus NN
< NNP
tref NN
> NNP
lin NN
, ,
1998 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
weeds NNS
and CC
weir NN
, ,
2003 CD
< NN
/ref NNP
> NNP
. .

w NN
ord NN
s VBZ
imilar JJ
w NN
ords NNS
with IN
similarity NN
score NN
eat NN
cook NN
0127 CD
, ,
drink NN
0108 CD
, ,
consume NN
0101 CD
, ,
feed NN
0094 CD
, ,
taste NN
0093 CD
, ,
like IN
0092 CD
, ,
serve VB
0089 CD
, ,
bake NN
0087 CD
, ,
sleep JJ
0086 CD
, ,
pick NN
0085 CD
, ,
fry NN
0084 CD
, ,
freeze NN
0081 CD
, ,
enjoy NN
0079 CD
, ,
smoke NN
0078 CD
, ,
harvest NN
0076 CD
, ,
love NN
0076 CD
, ,
chop NN
0074 CD
, ,
sprinkle NN
0072 CD
, ,
toss NN
0072 CD
, ,
chew VBP
0072 CD
salad NN
soup NN
0172 CD
, ,
sandwich JJ
0169 CD
, ,
sauce NN
0152 CD
, ,
pasta NN
0149 CD
, ,
dish JJ
0135 CD
, ,
vegetable JJ
0135 CD
, ,
cheese JJ
0132 CD
, ,
dessert VBZ
013 CD
, ,
entree JJ
0121 CD
, ,
bread NN
0116 CD
, ,
meat NN
0116 CD
, ,
chicken NN
0115 CD
, ,
pizza NN
0114 CD
, ,
rice NN
0112 CD
, ,
seafood VBD
011 CD
, ,
dressing VBG
0109 CD
, ,
cake NN
0107 CD
, ,
steak NN
0105 CD
, ,
noodle JJ
0105 CD
, ,
bean JJ
0102 CD
the DT
collocation NN
database NN
for IN
the DT
words NNS
eat NN
and CC
salad VB
the DT
database NN
contains VBZ
a DT
total NN
of IN
11 CD
million CD
unique JJ
dependency NN
relationships NNS
. .

21 CD
collocation NN
database NN
given VBN
a DT
word NN
w NN
in IN
a DT
dependency NN
relationship NN
such JJ
as IN
subject NN
or CC
object NN
, ,
the DT
collocation NN
database NN
is VBZ
used VBN
to TO
retrieve VB
the DT
words NNS
that WDT
occurred VBD
in IN
that DT
relationship NN
with IN
w NN
, ,
in IN
a DT
large JJ
corpus NN
, ,
along IN
with IN
their PRP$
frequencies NNS
< VBP
tref JJ
> NNP
lin NN
, ,
1998a CD
< NN
/tref NNP
> NNP
. .

eat NN
: :
object NN
: :
almond NN
1 CD
, ,
a DT
pple NN
25 CD
, ,
bean JJ
5 CD
, ,
beam NN
1 CD
, ,
binge NN
1 CD
, ,
bread VBD
13 CD
, ,
cake NN
17 CD
, ,
cheese JJ
8 CD
, ,
dish JJ
14 CD
, ,
disorder NN
20 CD
, ,
egg NN
31 CD
, ,
grape NN
12 CD
, ,
grub NN
2 CD
, ,
hay NN
3 CD
, ,
junk NN
1 CD
, ,
meat NN
70 CD
, ,
poultry NN
3 CD
, ,
rabbit NN
4 CD
, ,
soup NN
5 CD
, ,
sandwich VBD
18 CD
, ,
pasta NN
7 CD
, ,
vegetable JJ
35 CD
, ,
subject JJ
: :
adult NN
3 CD
, ,
animal NN
8 CD
, ,
beetle RB
1 CD
, ,
cat NN
3 CD
, ,
child NN
41 CD
, ,
decrease NN
1 CD
, ,
dog NN
24 CD
, ,
family NN
29 CD
, ,
guest JJS
7 CD
, ,
kid VBD
22 CD
, ,
patient NN
7 CD
, ,
refugee NN
2 CD
, ,
rider JJR
1 CD
, ,
russian JJ
1 CD
, ,
shark NN
2 CD
, ,
something NN
19 CD
, ,
we PRP
239 CD
, ,
wolf NN
5 CD
, ,
salad NN
: :
adj-modifier JJ
: :
assorted JJ
1 CD
, ,
crisp NN
4 CD
, ,
fresh JJ
13 CD
, ,
good JJ
3 CD
, ,
grilled VBD
5 CD
, ,
leftover RB
3 CD
, ,
mixed JJ
4 CD
, ,
olive JJ
3 CD
, ,
prepared VBD
3 CD
, ,
side NN
4 CD
, ,
small JJ
6 CD
, ,
special JJ
5 CD
, ,
vegetable JJ
3 CD
, ,
object-of JJ
: :
add VB
3 CD
, ,
consume NN
1 CD
, ,
dress NN
1 CD
, ,
grow NN
1 CD
, ,
harvest RB
2 CD
, ,
have VBP
20 CD
, ,
like IN
5 CD
, ,
love VBD
1 CD
, ,
mix NN
1 CD
, ,
pick NN
1 CD
, ,
place NN
3 CD
, ,
prepare NN
4 CD
, ,
return NN
3 CD
, ,
rinse NN
1 CD
, ,
season NN
1 CD
, ,
serve VBP
8 CD
, ,
sprinkle NN
1 CD
, ,
taste NN
1 CD
, ,
test NN
1 CD
, ,
toss NN
8 CD
, ,
try NN
3 CD
, ,
figure NN
1 CD
. .

eat NN
: :
object NN
: :
almond NN
1 CD
, ,
a DT
pple NN
25 CD
, ,
bean JJ
5 CD
, ,
beam NN
1 CD
, ,
binge NN
1 CD
, ,
bread VBD
13 CD
, ,
cake NN
17 CD
, ,
cheese JJ
8 CD
, ,
dish JJ
14 CD
, ,
disorder NN
20 CD
, ,
egg NN
31 CD
, ,
grape NN
12 CD
, ,
grub NN
2 CD
, ,
hay NN
3 CD
, ,
junk NN
1 CD
, ,
meat NN
70 CD
, ,
poultry NN
3 CD
, ,
rabbit NN
4 CD
, ,
soup NN
5 CD
, ,
sandwich VBD
18 CD
, ,
pasta NN
7 CD
, ,
vegetable JJ
35 CD
, ,
subject JJ
: :
adult NN
3 CD
, ,
animal NN
8 CD
, ,
beetle RB
1 CD
, ,
cat NN
3 CD
, ,
child NN
41 CD
, ,
decrease NN
1 CD
, ,
dog NN
24 CD
, ,
family NN
29 CD
, ,
guest JJS
7 CD
, ,
kid VBD
22 CD
, ,
patient NN
7 CD
, ,
refugee NN
2 CD
, ,
rider JJR
1 CD
, ,
russian JJ
1 CD
, ,
shark NN
2 CD
, ,
something NN
19 CD
, ,
we PRP
239 CD
, ,
wolf NN
5 CD
, ,
salad NN
: :
adj-modifier JJ
: :
assorted JJ
1 CD
, ,
crisp NN
4 CD
, ,
fresh JJ
13 CD
, ,
good JJ
3 CD
, ,
grilled VBD
5 CD
, ,
leftover RB
3 CD
, ,
mixed JJ
4 CD
, ,
olive JJ
3 CD
, ,
prepared VBD
3 CD
, ,
side NN
4 CD
, ,
small JJ
6 CD
, ,
special JJ
5 CD
, ,
vegetable JJ
3 CD
, ,
object-of JJ
: :
add VB
3 CD
, ,
consume NN
1 CD
, ,
dress NN
1 CD
, ,
grow NN
1 CD
, ,
harvest RB
2 CD
, ,
have VBP
20 CD
, ,
like IN
5 CD
, ,
love VBD
1 CD
, ,
mix NN
1 CD
, ,
pick NN
1 CD
, ,
place NN
3 CD
, ,
prepare NN
4 CD
, ,
return NN
3 CD
, ,
rinse NN
1 CD
, ,
season NN
1 CD
, ,
serve VBP
8 CD
, ,
sprinkle NN
1 CD
, ,
taste NN
1 CD
, ,
test NN
1 CD
, ,
toss NN
8 CD
, ,
try NN
3 CD
, ,
figure NN
1 CD
. .

excepts NNS
of IN
entries NNS
in IN
the DT
collocation NN
database NN
for IN
eat NN
and CC
salad NN
table NN
1 CD
the DT
top JJ
20 CD
most JJS
similar JJ
words NNS
of IN
eat NN
and CC
salad NN
as IN
given VBN
by IN
< NNP
tref NN
> NNP
lin NN
, ,
1998b CD
< NN
/tref NNP
> NNP
. .

w NN
ord NN
s VBZ
imilar JJ
w NN
ords NNS
with IN
similarity NN
score NN
eat NN
cook NN
0127 CD
, ,
drink NN
0108 CD
, ,
consume NN
0101 CD
, ,
feed NN
0094 CD
, ,
taste NN
0093 CD
, ,
like IN
0092 CD
, ,
serve VB
0089 CD
, ,
bake NN
0087 CD
, ,
sleep JJ
0086 CD
, ,
pick NN
0085 CD
, ,
fry NN
0084 CD
, ,
freeze NN
0081 CD
, ,
enjoy NN
0079 CD
, ,
smoke NN
0078 CD
, ,
harvest NN
0076 CD
, ,
love NN
0076 CD
, ,
chop NN
0074 CD
, ,
sprinkle NN
0072 CD
, ,
toss NN
0072 CD
, ,
chew VBP
0072 CD
salad NN
soup NN
0172 CD
, ,
sandwich JJ
0169 CD
, ,
sauce NN
0152 CD
, ,
pasta NN
0149 CD
, ,
dish JJ
0135 CD
, ,
vegetable JJ
0135 CD
, ,
cheese JJ
0132 CD
, ,
dessert VBZ
013 CD
, ,
entree JJ
0121 CD
, ,
bread NN
0116 CD
, ,
meat NN
0116 CD
, ,
chicken NN
0115 CD
, ,
pizza NN
0114 CD
, ,
rice NN
0112 CD
, ,
seafood VBD
011 CD
, ,
dressing VBG
0109 CD
, ,
cake NN
0107 CD
, ,
steak NN
0105 CD
, ,
noodle JJ
0105 CD
, ,
bean JJ
0102 CD
the DT
collocation NN
database NN
for IN
the DT
words NNS
eat NN
and CC
salad VB
the DT
database NN
contains VBZ
a DT
total NN
of IN
11 CD
million CD
unique JJ
dependency NN
relationships NNS
. .

each DT
cluster NN
corresponds VBZ
to TO
a DT
sense NN
of IN
the DT
headword NN
. .

thus RB
, ,
correct JJ
match NN
of IN
an DT
argument NN
corresponds VBZ
to TO
correct VB
role NN
identification NN
. .

the DT
contextual JJ
preferences NNS
for IN
h NN
were VBD
constructed VBN
manually RB
: :
the DT
named-entity JJ
types NNS
for IN
cpv NN
: :
nh NN
were VBD
set VBN
by IN
adapting VBG
the DT
entity NN
types NNS
given VBN
in IN
the DT
guidelines NNS
to TO
the DT
types NNS
supported VBN
by IN
the DT
lingpipe JJ
ner NN
described VBN
in IN
section NN
32 CD
. .

as IN
a DT
more RBR
natural JJ
ranking NN
method NN
, ,
we PRP
also RB
utilize VBP
scbc NNS
directly RB
, ,
denoted VBD
rankedcbc NN
, ,
having VBG
mv NN
: :
er NN
, ,
t NN
scbcr NN
, ,
t NN
. .

first RB
of IN
all DT
, ,
it PRP
allows VBZ
us PRP
to TO
provide VB
both DT
positive JJ
and CC
negative JJ
examples NNS
, ,
avoiding VBG
the DT
use NN
of IN
one-class JJ
classification NN
algorithms NN
that IN
in IN
practice NN
perform NN
poorly RB
< NNP
ref NN
> NNP
dagan VBZ
et FW
al NN
, ,
2006 CD
< NN
/ref NNP
> NNP
. .

second JJ
, ,
the DT
large JJ
availability NN
of IN
manually RB
constructed VBN
substitution NN
lexica NN
, ,
such JJ
as IN
wordnet NN
< NN
ref NN
> NNP
fellbaum NN
, ,
1998 CD
< NN
/ref NNP
> NNP
, ,
or CC
the DT
use NN
of IN
repositories NNS
based VBN
on IN
statistical JJ
word NN
similarities NNS
, ,
such JJ
as IN
the DT
database NN
constructed VBN
by IN
< NNP
tref NN
> NNP
lin NN
1998 CD
< NNP
/tref NNP
> NNP
, ,
allows VBZ
us PRP
to TO
find VB
an DT
adequate JJ
substitution NN
lexicon NN
for IN
each DT
target NN
word NN
in IN
most JJS
of IN
the DT
cases NNS
. .

2006 CD
adapted VBD
the DT
classical JJ
supervised VBD
wsd JJ
setting NN
to TO
approach VB
the DT
sense NN
matching VBG
problem NN
ie NN
, ,
the DT
binary JJ
lexical JJ
entailment NN
problem NN
of IN
deciding VBG
whether IN
a DT
word NN
, ,
such JJ
as IN
position NN
, ,
entails VBZ
a DT
different JJ
word NN
, ,
such JJ
as IN
job NN
, ,
in IN
a DT
given VBN
context NN
by IN
defining VBG
a DT
one-class JJ
learning NN
algorithm NNS
based VBN
on IN
support NN
vector NN
machines NNS
svm NN
. .

however RB
, ,
in IN
other JJ
research NN
< NNP
ref VBZ
> NNP
budanitsky NN
and CC
hirst JJ
2001 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
patwardhan NN
, ,
banerjee NN
, ,
and CC
pedersen VB
2003 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
mccarthy NN
, ,
koeling NN
, ,
and CC
weeds NNS
2004 CD
< NNP
/ref NNP
> NNP
, ,
it PRP
has VBZ
been VBN
shown VBN
that IN
the DT
distance NN
measure NN
of IN
< NNP
ref NN
> NNP
jiang NN
and CC
conrath NN
1997 CD
< NNP
/ref NNP
> NNP
referred VBD
to TO
herein VB
as IN
the DT
jc NN
measure NN
is VBZ
a DT
superior JJ
wordnet-based JJ
semantic JJ
similarity NN
measure NN
: :
wn JJ
dist NN
jc NN
w VBD
1 CD
, ,
w VBD
2 CD
max NNS
c VBP
1 CD
sw JJ
1 CD
c JJ
2 CD
sw JJ
2 CD
parenleftbigg NN
max NN
csupc NN
1 CD
supc NN
2 CD
2logc CD
log JJ
pc NN
1 CD
log JJ
pc NN
2 CD
parenrightbigg NN
50 CD
in IN
our PRP$
work NN
, ,
we PRP
make VBP
an DT
empirical JJ
comparison NN
of IN
neighbors NNS
derived VBN
using VBG
a DT
wordnet-based JJ
measure NN
and CC
each DT
of IN
the DT
distributional JJ
similarity NN
measures NNS
using VBG
the DT
technique NN
discussed VBN
in IN
section NN
3 CD
. .

45 CD
hindles NNS
< VBP
ref NN
> JJ
measure NN
hindle NN
1990 CD
< NNP
/ref NNP
> NNP
proposed VBD
an DT
mi-based JJ
measure NN
, ,
which WDT
he PRP
used VBD
to TO
show VB
that DT
nouns NNS
could MD
be VB
reliably RB
clustered VBN
based VBN
on IN
their PRP$
verb JJ
co-occurrences NNS
. .

this DT
expression NN
is VBZ
the DT
same JJ
as IN
the DT
numerator NN
in IN
the DT
expressions NNS
for IN
precision NN
and CC
recall NN
in IN
the DT
difference-weighted JJ
mi-based JJ
crm NN
: :
p NN
dw NN
mi NN
w VBD
1 CD
, ,
w VBD
2 CD
summationtext JJ
tp NN
iw NN
1 CD
, ,
c VBD
miniw JJ
1 CD
, ,
c NN
, ,
iw JJ
2 CD
, ,
c VBD
iw JJ
1 CD
, ,
c VBP
summationtext JJ
fw NN
1 CD
iw NN
1 CD
, ,
c VBP
summationtext JJ
tp NN
miniw NN
1 CD
, ,
c NN
, ,
iw JJ
2 CD
, ,
c VBP
summationtext JJ
fw NN
1 CD
iw NN
1 CD
, ,
c VBD
39 CD
r NN
dw NN
mi NN
w VBD
1 CD
, ,
w VBD
2 CD
summationtext JJ
tp NN
iw NN
2 CD
, ,
c VBD
miniw JJ
2 CD
, ,
c NN
, ,
iw JJ
1 CD
, ,
c VBD
iw JJ
2 CD
, ,
c VBP
summationtext JJ
fw NN
2 CD
iw NN
2 CD
, ,
c VBP
summationtext JJ
tp NN
miniw NN
2 CD
, ,
c NN
, ,
iw JJ
1 CD
, ,
c VBP
summationtext JJ
fw NN
2 CD
iw NN
2 CD
, ,
c VBD
40 CD
since IN
tp NN
tw NN
1 CD
tw NN
2 CD
. .

further RB
, ,
the DT
noun JJ
hyponymy NN
hierarchy NN
in IN
wordnet NN
, ,
which WDT
will MD
be VB
used VBN
as IN
a DT
pseudo-gold JJ
standard NN
for IN
comparison NN
, ,
is VBZ
widely RB
recognized VBN
in IN
this DT
area NN
of IN
research NN
. .

we PRP
consider VBP
only RB
a DT
single JJ
grammatical JJ
relation NN
because IN
we PRP
believe VBP
that IN
it PRP
is VBZ
important JJ
to TO
evaluate VB
the DT
usefulness NN
of IN
each DT
grammatical JJ
relation NN
in IN
calculating VBG
similarity NN
before IN
deciding VBG
how WRB
to TO
combine VB
information NN
from IN
5 CD
this DT
results NNS
in IN
a DT
single JJ
80:20 CD
split NN
of IN
the DT
complete JJ
data NN
set NN
, ,
in IN
which WDT
we PRP
are VBP
guaranteed VBN
that IN
the DT
original JJ
relative JJ
frequencies NNS
of IN
the DT
target NN
nouns NNS
are VBP
maintained VBN
. .

33 CD
evaluation NN
of IN
class NN
attributes NNS
extraction VBP
parameters NNS
: :
given VBN
a DT
target NN
class NN
specified VBN
as IN
a DT
set NN
of IN
instances NNS
and CC
a DT
set NN
of IN
five CD
seed NN
attributes NNS
for IN
a DT
class NN
eg NN
, ,
quality NN
, ,
speed NN
, ,
number NN
of IN
users NNS
, ,
market NN
share NN
, ,
reliability NN
for IN
searchengine NN
, ,
the DT
method NN
described VBN
in IN
section NN
22 CD
extracts NNS
ranked JJ
lists NNS
of IN
class NN
attributes NNS
from IN
the DT
input NN
query RB
logs RB
. .

each DT
attribute NN
of IN
the DT
merged JJ
list NN
is VBZ
0 CD
02 CD
04 CD
06 CD
08 CD
1 CD
0 CD
10 CD
20 CD
30 CD
40 CD
50 CD
precision NN
rank NN
class NN
: :
holiday NN
manually RB
assembled VBD
instances NNS
automatically RB
extracted VBD
instances NNS
0 CD
02 CD
04 CD
06 CD
08 CD
1 CD
0 CD
10 CD
20 CD
30 CD
40 CD
50 CD
precision NN
rank NN
class NN
: :
average-class NN
manually RB
assembled VBD
instances NNS
automatically RB
extracted VBD
instances NNS
0 CD
02 CD
04 CD
06 CD
08 CD
1 CD
0 CD
10 CD
20 CD
30 CD
40 CD
50 CD
precision NN
rank NN
class NN
: :
mountain NN
manually RB
assembled VBD
instances NNS
automatically RB
extracted VBD
instances NNS
0 CD
02 CD
04 CD
06 CD
08 CD
1 CD
0 CD
10 CD
20 CD
30 CD
40 CD
50 CD
precision NN
rank NN
class NN
: :
average-class NN
manually RB
assembled VBD
instances NNS
automatically RB
extracted VBD
instances NNS
figure NN
3 CD
: :
accuracy NN
of IN
attributes NNS
extracted VBN
based VBN
on IN
manually RB
assembled VBN
, ,
gold JJ
standard NN
m NN
vs NN
automatically RB
extracted VBD
e JJ
instance NN
sets NNS
, ,
for IN
a DT
few JJ
target NN
classes NNS
leftmost VBP
graphs NN
and CC
as IN
an DT
average NN
over IN
all DT
37 CD
target NN
classes NNS
rightmost VBP
graphs NN
. .

distance-weighted JJ
averaging VBG
differs NNS
from IN
distributional JJ
clustering NN
in IN
that DT
it PRP
does VBZ
not RB
explicitly RB
cluster JJ
words NNS
. .

the DT
choice NN
of IN
these DT
two CD
measures NNS
was VBD
motivated VBN
by IN
work NN
described VBN
in IN
< NNP
ref NN
> NNP
dagan NN
, ,
lee NN
, ,
and CC
pereira NN
1999 CD
< NNP
/ref NNP
> NNP
, ,
in IN
which WDT
the DT
jensenshannon NN
divergence NN
outperforms NNS
related JJ
similarity NN
measures NNS
such JJ
as IN
the DT
confusion NN
probability NN
or CC
the DT
l JJ
1 CD
norm NN
on IN
a DT
pseudodisambiguation NN
task NN
that WDT
uses VBZ
verb-object JJ
pairs NNS
. .

the DT
confusion NN
probability NN
has VBZ
been VBN
used VBN
by IN
several JJ
authors NNS
to TO
smooth VB
word NN
co367 NN
lapata VBD
the DT
disambiguation NN
of IN
nominalizations NNS
occurrence NN
probabilities NNS
< VBP
ref JJ
> NNP
essen NN
and CC
steinbiss JJ
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
grishman NN
and CC
sterling NN
1994 CD
< NNP
/ref NNP
> NNP
and CC
shown VBN
to TO
give VB
promising JJ
performance NN
. .

< JJ
ref NN
> NNP
briefly NN
, ,
clark NN
and CC
weir NN
2002 CD
< NNP
/ref NNP
> NNP
populate VBP
the DT
wordnet NN
hierarchy NN
based VBN
on IN
corpus NN
frequencies NNS
of IN
all DT
nouns NNS
for IN
a DT
verb/slot NN
pair NN
, ,
and CC
then RB
determine VB
the DT
appropriate JJ
probability NN
estimate NN
at IN
each DT
node NN
in IN
the DT
hierarchy NN
by IN
using VBG
a24 JJ
a102 NN
to TO
determine VB
whether IN
to TO
generalize VB
an DT
estimate NN
to TO
a DT
parent NN
node NN
in IN
the DT
hierarchy NN
. .

we PRP
compare VBP
spd JJ
to TO
other JJ
measures NNS
applied VBN
directly RB
to TO
the DT
unpropagated JJ
probability NN
profiles NNS
given VBN
by IN
the DT
clark-weir JJ
method NN
: :
the DT
probability NN
distribution NN
distance NN
given VBN
by IN
skew JJ
divergence NN
skew NN
< NNP
tref NN
> NNP
lee NN
, ,
1999 CD
< NN
/tref NNP
> NNP
, ,
as RB
well RB
as IN
the DT
general JJ
vector NN
distance NN
given VBN
by IN
cosine NN
cos NN
. .

these DT
are VBP
the DT
measures NNS
aside RB
from IN
spd NN
that WDT
performed VBD
best RBS
in IN
our PRP$
pilot NN
experiments NNS
. .

it PRP
is VBZ
worth JJ
noting VBG
that IN
the DT
method NN
of IN
< NNP
ref NN
> NNP
clark NN
and CC
weir NN
2002 CD
< NNP
/ref FW
> NN
does VBZ
not RB
yield VB
a DT
tree JJ
cut NN
, ,
but CC
instead RB
generally RB
populates VBZ
the DT
wordnet NN
hierarchy NN
with IN
non-zero JJ
probabilities NNS
. .

due JJ
to TO
the DT
original JJ
kl NN
distance NN
is VBZ
asymmetric JJ
and CC
is VBZ
not RB
defined VBN
when WRB
zero NN
frequency NN
occurs VBZ
. .

some DT
enhanced VBD
kl JJ
models NNS
were VBD
developed VBN
to TO
prevent VB
these DT
problems NNS
such JJ
as IN
jensen-shannon JJ
< NNP
ref NN
> NNP
jianhua NN
, ,
1991 CD
< NN
/ref NNP
> NNP
, ,
which WDT
introducing VBG
a DT
probabilistic JJ
variable JJ
m NN
, ,
or CC
-skew JJ
divergence NN
< NNP
tref NN
> NNP
lee NN
, ,
1999 CD
< NN
/tref NNP
> NNP
, ,
by IN
adopting VBG
adjustable JJ
variable NN
. .

research NN
shows VBZ
that IN
skew JJ
divergence NN
achieves NNS
better RBR
performance NN
than IN
other JJ
measures NNS
. .

< JJ
ref NN
> NNP
lee NN
, ,
2001 CD
< NN
/ref NNP
> VBZ
1yxs CD
rgencedskewdive JJ
yxxkl NN
aaa NN
2/,2/yx CD
, ,
js NN
shannon-djensen JJ
yxm NN
myklmxkl NN
to TO
convert VB
distance NN
to TO
similarity NN
value NN
, ,
we PRP
adopt VBP
the DT
formula NN
inspired VBN
by IN
< NNP
ref NN
> NNP
mochihashi NN
, ,
and CC
matsumoto NN
2002 CD
< NNP
/ref NNP
> NNP
. .

the DT
constant NN
is VBZ
a DT
value NN
between IN
0 CD
and CC
1 CD
we PRP
also RB
experimented VBD
with IN
euclidian JJ
distance NN
, ,
the DT
l1 NN
norm NN
, ,
and CC
cosine NN
measures NNS
. .

this DT
choice NN
of IN
similarity NN
measures NNS
was VBD
motivated VBN
by IN
results NNS
of IN
studies NNS
by IN
< NNP
ref NN
> NNP
levy NN
et NN
al NN
1998 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
tref VBP
> NNP
lee NN
1999 CD
< NNP
/tref NNP
> NNP
which WDT
compared VBN
several JJ
well RB
known VBN
measures NNS
on IN
similar JJ
tasks NNS
and CC
found VBN
these DT
three CD
to TO
be VB
superior JJ
to TO
many JJ
others NNS
. .

another DT
reason NN
for IN
this DT
choice NN
is VBZ
that IN
there EX
are VBP
different JJ
ideas NNS
underlying VBG
these DT
measures NNS
: :
while IN
the DT
jaccards NNS
coefficient NN
is VBZ
a DT
binary JJ
measure NN
, ,
l1 NN
and CC
the DT
skew NN
divergence NN
are VBP
probabilistic JJ
, ,
the DT
former JJ
being VBG
geometrically RB
motivated VBN
and CC
the DT
latter JJ
being VBG
a DT
version NN
of IN
the DT
information NN
theoretic JJ
kullback NN
leibler NN
divergence NN
cf NN
. .

the DT
optimal JJ
configuration NN
varies NNS
by IN
the DT
divergence NN
measure NN
with IN
d NN
50 CD
and CC
c $
14 CD
for IN
kl NN
divergence NN
, ,
d VBZ
200 CD
and CC
c $
4 CD
for IN
symmetrised VBN
kl NN
, ,
and CC
d VBZ
150 CD
and CC
c $
2 CD
for IN
js NN
divergence NN
. .

for IN
a48 JJ
a49 NN
a1a51a50a23a52a54a53a19a5 NN
and CC
word-conditional JJ
context NN
distributions NNS
a55 VBP
and CC
a56 RB
, ,
we PRP
have VBP
the DT
so-called JJ
a48 NN
-divergences NNS
< VBP
ref JJ
> NNP
zhu NN
and CC
rohwer NN
, ,
1998 CD
< NN
/ref CC
> NN
: :
a57 NN
a58 NN
a1a59a55a60a52a61a56a4a5a63a62a59a64 NN
a53a65a14 NN
a7 NN
a55 NN
a58 NN
a56 NN
a11a38a66 NN
a58 NN
a48a67a1a45a53a18a14a16a48a42a5 VBD
1 CD
divergences NNS
a57 JJ
a68 NN
and CC
a57 NN
a11 NNS
are VBP
defined VBN
as IN
limits NNS
as IN
a48a6a69 JJ
a50 NN
and CC
a48a6a69a70a53 NN
: :
a57 NN
a11 NN
a1a59a55a60a52a61a56a4a5a71a64 NN
a57 NN
a68 NN
a1a51a56a67a52a51a55a72a5a71a64a74a73 NN
a55a76a75a78a77a47a79 NN
a55 NN
a56 NN
in IN
other JJ
words NNS
, ,
a57 JJ
a11a19a1a59a55a60a52a61a56a4a5 NN
is VBZ
the DT
kl-divergence NN
of IN
a55 NN
from IN
a56 JJ
members NNS
of IN
this DT
divergence NN
family NN
are VBP
in IN
some DT
sense NN
preferred VBN
by IN
theory NN
to TO
alternative JJ
measures NNS
. .

it PRP
can MD
be VB
shown VBN
that IN
the DT
a48 JJ
-divergences NNS
or CC
divergences NNS
defined VBN
by IN
combinations NNS
of IN
them PRP
, ,
such JJ
as IN
the DT
jensen-shannon NN
or CC
skew NN
divergences NNS
< VBP
tref JJ
> NNP
lee NN
, ,
1999 CD
< NN
/tref NNP
> NNP
are VBP
the DT
only JJ
ones NNS
that WDT
are VBP
robust JJ
to TO
redundant VB
contexts NN
ie NN
, ,
only RB
divergences VBZ
in IN
this DT
family NN
are VBP
invariant JJ
< NNP
ref NN
> NNP
csiszar NN
, ,
1975 CD
< NN
/ref NNP
> NNP
. .

note NN
that IN
if IN
any DT
a56 JJ
a8 NN
a64a80a50 NN
, ,
then RB
a57 JJ
a11a81a1a59a55a60a52a61a56a4a5 NN
is VBZ
infinite JJ
; :
in IN
general JJ
, ,
the DT
kldivergence NN
is VBZ
very RB
sensitive JJ
to TO
small JJ
probabilities NNS
, ,
and CC
careful JJ
attention NN
must MD
be VB
paid VBN
to TO
smoothing VBG
if IN
it PRP
is VBZ
to TO
be VB
used VBN
with IN
text JJ
co-occurrence NN
data NNS
. .

we PRP
do VBP
not RB
know VB
whether IN
or CC
to TO
what WP
extent NN
this DT
particular JJ
parameter NN
setting NN
is VBZ
universally RB
best RBS
, ,
best JJS
only RB
for IN
english JJ
, ,
best JJS
for IN
newswire NN
english NN
, ,
or CC
best JJS
only RB
for IN
the DT
specific JJ
test NN
we PRP
have VBP
devised VBN
. .

we PRP
have VBP
restricted VBN
our PRP$
attention NN
to TO
a DT
relatively RB
small JJ
space NN
of IN
similarity NN
measures NNS
, ,
excluding VBG
many JJ
previously RB
proposed VBN
measures NNS
of IN
lexical JJ
affinity NN
but CC
see VBP
weeds NNS
, ,
et FW
al NN
2004 CD
, ,
and CC
< NNP
tref VBP
> NNP
lee NN
1999 CD
< NNP
/tref NNP
> NNP
for IN
some DT
empirical JJ
comparisons NNS
. .

lee NN
observed VBD
that IN
measures NNS
from IN
the DT
space NN
of IN
invariant JJ
divergences NNS
particularly RB
the DT
js NN
and CC
skew JJ
divergences NNS
perform VBP
at IN
least JJS
as RB
well RB
as IN
any DT
of IN
a DT
wide JJ
variety NN
of IN
alternatives NNS
. .

jensen-shannon NN
is VBZ
well RB
defined VBN
for IN
all DT
distributions NNS
becausetheaverageofpi VBP
andqi JJ
isnon-zerowhenevereither JJ
number NN
is VBZ
these DT
measures NNS
and CC
others NNS
are VBP
surveyed VBN
in IN
< NNP
ref NN
> NNP
lee NN
, ,
2001 CD
< NN
/ref NNP
> NNP
, ,
who WP
finds VBZ
that IN
jensen-shannon NN
is VBZ
outperformed VBN
by IN
the DT
skew NN
divergence NN
measure NN
introduced VBN
by IN
lee NN
in IN
1999 CD
. .

the DT
skew NN
divergence2 NN
accounts NNS
for IN
zeros NN
in IN
q NN
by IN
mixing VBG
in IN
a DT
small JJ
amount NN
of IN
p NN
sp NN
, ,
q JJ
dp NN
bardbl NN
q VBD
1p CD
summationtexti NN
pi NN
log NN
piqi1pi NN
lee NN
found VBD
that IN
as IN
1 CD
, ,
the DT
performance NN
of IN
skew JJ
divergence NN
on IN
natural JJ
language NN
tasks NNS
improves VBZ
. .

in IN
particular JJ
, ,
it PRP
outperforms VBZ
most RBS
other JJ
models NNS
and CC
even RB
beats NNS
pure VBP
kl JJ
divergence NN
modified VBD
to TO
avoid VB
zeros NN
with IN
sophisticated JJ
smoothing NN
models NNS
. .

one-noun JJ
of-prep JJ
his-det JJ
worst-adj JJ
of-prep JJ
all-det JJ
quality-noun JJ
of-prep JJ
the-det JJ
to-prep JJ
do-verb JJ
so-adverb JJ
in-prep JJ
the-det JJ
company-noun JJ
you-pronoun JJ
and-conj JJ
your-pronoun JJ
have-verb JJ
taken-verb JJ
the-det JJ
rest-noun JJ
of-prep JJ
us-pronoun JJ
are-verb JJ
at-prep JJ
least-adj JJ
but-conj JJ
if-prep JJ
you-pronoun JJ
as-prep JJ
a-det JJ
weapon-noun JJ
continue-verb JJ
to-to JJ
do-verb JJ
purpose-noun JJ
of-prep JJ
the-det JJ
could-modal JJ
have-verb JJ
be-verb JJ
it-pronoun JJ
seem-verb JJ
to-prep JJ
to-pronoun JJ
continue-verb JJ
to-prep JJ
have-verb JJ
be-verb JJ
the-det JJ
do-verb JJ
something-noun JJ
about-prep JJ
cause-verb JJ
you-pronoun JJ
to-to JJ
evidence-noun JJ
to-to JJ
back-adverb JJ
that-prep JJ
you-pronoun JJ
are-verb JJ
i-pronoun JJ
be-verb JJ
not-adverb JJ
of-prep JJ
the-det JJ
century-noun JJ
of-prep JJ
money-noun JJ
be-prep JJ
291 CD
wiebe NN
, ,
wilson NN
, ,
bruce NN
, ,
bell NN
, ,
and CC
martin NN
learning VBG
subjective JJ
language NN
table JJ
6 CD
random JJ
sample NN
of IN
unique JJ
generalized JJ
collocations NNS
in IN
op1 NN
. .

however RB
, ,
due JJ
to TO
the DT
lack NN
of IN
a DT
tight JJ
de FW
nition NN
for IN
the DT
concept NN
of IN
distributional JJ
similarity NN
and CC
the DT
broad JJ
range NN
of IN
potential JJ
applications NNS
, ,
a DT
large JJ
number NN
of IN
measures NNS
of IN
distributional JJ
similarity NN
have VBP
been VBN
proposed VBN
or CC
adopted VBN
see JJ
section NN
2 CD
. .

the DT
rst JJ
approach NN
is VBZ
not RB
ideal JJ
since IN
it PRP
assumes VBZ
that IN
the DT
goal NN
of IN
distributional JJ
similarity NN
methods NNS
is VBZ
to TO
predict VB
semantic JJ
similarity NN
and CC
that IN
the DT
semantic JJ
resource NN
used VBN
is VBZ
a DT
valid JJ
gold NN
standard NN
. .

further RB
, ,
the DT
second JJ
approach NN
is VBZ
clearly RB
advantageous JJ
when WRB
one NN
wishes VBZ
to TO
apply VB
distributional JJ
similarity NN
methods NNS
in IN
a DT
particular JJ
application NN
area NN
. .

23 CD
distributional JJ
kernels NNS
given VBN
the DT
effectiveness NN
of IN
distributional JJ
similarity NN
measures NNS
for IN
numerous JJ
tasks NNS
in IN
nlp NN
and CC
the DT
interpretation NN
of IN
kernels NNS
as IN
similarity NN
functions NNS
, ,
it PRP
seems VBZ
natural JJ
to TO
consider VB
the DT
use NN
of IN
kernels NNS
tailored VBN
for IN
co-occurrence NN
distributions NNS
when WRB
performing VBG
semantic JJ
classification NN
. .

650 CD
distance NN
definition NN
derived VBD
linear JJ
kernel NNS
l2 VBP
distance2 JJ
summationtextcpcw1pcw22 NN
summationtextc NN
pcw1pcw2 NN
l1 NN
distance NN
summationtextcpcw1pcw2 NN
summationtextc NN
minpcw1 NN
, ,
pcw2 JJ
jensen-shannon NN
summationtextc NN
pcw1log2 NN
2pcw1pcw1pcw2 CD
summationtextc NN
pcw1log2 NN
pcw1pcw1pcw2 NN
divergence NN
pcw2log2 VBD
2pcw2pcw1pcw2 CD
pcw2log2 NN
pcw2pcw1pcw2 NN
hellinger NN
distance NN
summationtextcradicalbigpcw1radicalbigpcw22 NN
summationtextcradicalbigpcw1pcw2 NN
table JJ
1 CD
: :
squared VBN
metric JJ
distances NNS
on IN
co-occurrence NN
distributions NNS
and CC
corresponding VBG
linear JJ
kernels NNS
were VBD
shown VBN
by IN
lee NN
to TO
give VB
better JJR
similarity NN
estimates NNS
than IN
the DT
l2 JJ
distance NN
. .

those DT
two CD
measures NNS
have VBP
been VBN
previously RB
shown VBN
to TO
give VB
promising JJ
performance NN
for IN
the DT
task NN
of IN
estimating VBG
the DT
frequencies NNS
of IN
unseen JJ
verb-argument JJ
pairs NNS
< MD
ref VB
> NNP
dagan JJ
et FW
al NN
, ,
1999 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
grishman NN
and CC
sterling NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
lapata NN
, ,
2000 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
lee NN
, ,
1999 CD
< NN
/tref NNP
> NNP
. .

those DT
two CD
measures NNS
have VBP
been VBN
previously RB
shown VBN
to TO
give VB
promising JJ
performance NN
for IN
the DT
task NN
of IN
estimating VBG
the DT
frequencies NNS
of IN
unseen JJ
verb-argument JJ
pairs NNS
< MD
ref VB
> NNP
dagan JJ
et FW
al NN
, ,
1999 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
grishman NN
and CC
sterling NN
, ,
1994 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
lapata NN
, ,
2000 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
lee NN
, ,
1999 CD
< NN
/tref NNP
> NNP
. .

the DT
skew NN
divergence NN
represents VBZ
a DT
generalisation NN
of IN
the DT
kullback-leibler JJ
divergence NN
and CC
was VBD
proposed VBN
by IN
< NNP
tref NN
> NNP
lee NN
1999 CD
< NNP
/tref NNP
> NNP
as IN
a DT
linguistically RB
motivated VBN
distance NN
measure NN
. .

we PRP
use VBP
a DT
value NN
of IN
:99 NNP
. .

we PRP
explored VBD
in IN
detail NN
the DT
influence NN
of IN
different JJ
types NNS
and CC
sizes NNS
of IN
context NN
by IN
varying VBG
the DT
context NN
specification NN
and CC
path NN
value NN
functions NNS
. .

there EX
are VBP
a DT
number NN
of IN
studies NNS
that IN
, ,
starting VBG
from IN
this DT
hypothesis NN
, ,
have VBP
built VBN
automatic JJ
or CC
semi-automatic JJ
procedures NNS
for IN
clustering VBG
words NNS
< NNP
ref NN
> NNP
brill NN
and CC
marcus NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
pereira NN
et NN
al NN
, ,
1993 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
martin NNP
et FW
al NN
, ,
1998 CD
< NN
/ref NNP
> NNP
, ,
especially RB
in IN
the DT
field NN
of IN
cognitive JJ
sciences NNS
< VBP
ref JJ
> NNP
redington NN
et NN
al NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
gobet NN
and CC
pine NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
clark NN
, ,
2000 CD
< NN
/ref NNP
> NNP
. .

in IN
< NNP
ref NN
> NNP
brill NN
and CC
marcus NN
, ,
1992 CD
< NN
/ref NNP
> NN
it PRP
is VBZ
given VBN
a DT
semiautomatic JJ
procedure NN
that IN
, ,
starting VBG
from IN
lexical JJ
statistical JJ
data NNS
collected VBN
from IN
a DT
large JJ
corpus NN
, ,
aims VBZ
to TO
arrange VB
target NN
words NNS
in IN
a DT
tree NN
more RBR
precisely RB
a DT
dendrogram NN
, ,
instead RB
of IN
clustering VBG
them PRP
automatically RB
. .

this DT
procedure NN
requires VBZ
a DT
linguistic JJ
examination NN
of IN
the DT
resulting VBG
tree NN
, ,
in IN
order NN
to TO
identify VB
the DT
word NN
classes VBZ
that WDT
are VBP
most RBS
appropriate JJ
to TO
describe VB
the DT
phenomenon NN
under IN
investigation NN
. .

the DT
formula NN
is VBZ
symmetric JJ
but CC
does VBZ
not RB
satisfy VB
the DT
triangle NN
inequality NN
. .

this DT
shows VBZ
that IN
we PRP
have VBP
extracted VBN
a DT
reasonable JJ
number NN
of IN
features NNS
for IN
each DT
phrase NN
, ,
since IN
distributional JJ
similarity NN
techniques NNS
have VBP
been VBN
shown VBN
to TO
work VB
well RB
for IN
words NNS
which WDT
occur VBP
more JJR
than IN
100 CD
times NNS
in IN
a DT
given VBN
corpus NN
< NNP
ref NN
> NNP
lin NN
, ,
1998 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
weeds NNS
and CC
weir NN
, ,
2003 CD
< NN
/ref NNP
> NNP
. .

word NN
similarity-based JJ
smoothing NN
approach NN
is VBZ
used VBN
in IN
our PRP$
system NN
to TO
make VB
advantage NN
of IN
the DT
huge JJ
unlabeled JJ
corpus NN
. .

this DT
is VBZ
advantageous JJ
in IN
the DT
computation NN
of IN
similarity NN
, ,
since IN
computing VBG
the DT
sums NNS
over IN
all DT
co-occurrence JJ
types NNS
rather RB
than IN
just RB
those DT
co-occurring JJ
with IN
at IN
least JJS
one CD
of IN
the DT
words NNS
is VBZ
1 CD
very RB
computationally RB
expensive JJ
and CC
2 CD
due JJ
to TO
their PRP$
vast JJ
number NN
, ,
the DT
effect NN
of IN
these DT
zero CD
frequency NN
co-occurrence NN
types NNS
tends VBZ
to TO
outweigh VB
the DT
effect NN
of IN
those DT
co-occurrence JJ
types NNS
that WDT
have VBP
actually RB
occurred VBN
. .

24 CD
difference-weighted JJ
models NNS
in IN
additive JJ
models NNS
, ,
no DT
distinction NN
is VBZ
made VBN
between IN
features NNS
that WDT
have VBP
occurred VBN
to TO
the DT
same JJ
extent NN
with IN
each DT
word NN
and CC
features NNS
that WDT
have VBP
occurred VBN
to TO
different JJ
extents NNS
with IN
each DT
word NN
. .

further RB
, ,
the DT
noun JJ
hyponymy NN
hierarchy NN
in IN
wordnet NN
, ,
which WDT
will MD
be VB
used VBN
as IN
a DT
pseudo-gold JJ
standard NN
for IN
comparison NN
, ,
is VBZ
widely RB
recognized VBN
in IN
this DT
area NN
of IN
research NN
. .

we PRP
consider VBP
only RB
a DT
single JJ
grammatical JJ
relation NN
because IN
we PRP
believe VBP
that IN
it PRP
is VBZ
important JJ
to TO
evaluate VB
the DT
usefulness NN
of IN
each DT
grammatical JJ
relation NN
in IN
calculating VBG
similarity NN
before IN
deciding VBG
how WRB
to TO
combine VB
information NN
from IN
5 CD
this DT
results NNS
in IN
a DT
single JJ
80:20 CD
split NN
of IN
the DT
complete JJ
data NN
set NN
, ,
in IN
which WDT
we PRP
are VBP
guaranteed VBN
that IN
the DT
original JJ
relative JJ
frequencies NNS
of IN
the DT
target NN
nouns NNS
are VBP
maintained VBN
. .

a DT
statistical JJ
technique NN
using VBG
a DT
language NN
model NN
that WDT
assigns VBZ
a DT
zero NN
probability NN
to TO
these DT
previously RB
unseen JJ
events NNS
will MD
rule VB
the DT
correct JJ
parse NN
or CC
interpretation NN
of IN
the DT
utterance NN
impossible JJ
. .

similarity-based JJ
smoothing VBG
< JJ
ref NN
> NNP
hindle NN
1990 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
brown JJ
et RB
al JJ
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan NN
, ,
marcus NN
, ,
and CC
markovitch NN
1993 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
pereira NN
, ,
tishby NN
, ,
and CC
lee JJ
1993 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
dagan NN
, ,
lee NN
, ,
and CC
pereira NN
1999 CD
< NNP
/ref NNP
> NNP
provides VBZ
an DT
intuitively RB
appealing VBG
approach NN
to TO
language NN
modeling NN
. .

for IN
example NN
, ,
in IN
a DT
speech NN
recognition NN
task NN
, ,
we PRP
might MD
predict VB
that DT
cat NN
is VBZ
a DT
more RBR
likely JJ
subject NN
of IN
growl NN
than IN
the DT
word NN
cap NN
, ,
even RB
though IN
neither DT
co-occurrence NN
has VBZ
been VBN
seen VBN
before IN
, ,
based VBN
on IN
the DT
fact NN
that IN
cat NN
is VBZ
similar JJ
to TO
words NNS
that WDT
do VBP
occur RB
as IN
the DT
subject NN
of IN
growl NN
eg NN
, ,
dog NN
and CC
tiger NN
, ,
whereas JJ
cap NN
is VBZ
not RB
. .

by IN
using VBG
japanese JJ
html NN
documents NNS
, ,
we PRP
empirically RB
show VBP
that IN
our PRP$
proposed VBN
method NN
can MD
obtain VB
a DT
significant JJ
number NN
of IN
hyponymy NN
relations NNS
which WDT
would MD
otherwise RB
be VB
missed VBN
by IN
alternative JJ
methods NNS
. .

most JJS
of IN
these DT
techniques NNS
have VBP
relied VBN
on IN
particular JJ
linguistic JJ
patterns NNS
, ,
such JJ
as IN
np NNS
such JJ
as IN
np IN
the DT
frequencies NNS
of IN
use NN
for IN
such JJ
linguistic JJ
patterns NNS
are VBP
relatively RB
low JJ
, ,
though RB
, ,
and CC
there EX
can MD
be VB
many JJ
expressions NNS
that WDT
do VBP
not RB
appear VB
in IN
such JJ
patterns NNS
even RB
if IN
we PRP
look VBP
at IN
large JJ
corpora NNS
. .

the DT
effort NN
of IN
searching VBG
for IN
other JJ
clues NNS
indicating VBG
hyponymy NN
relations NNS
is VBZ
thus RB
significant JJ
. .

another DT
line NN
of IN
research NN
, ,
which WDT
is VBZ
more RBR
closely RB
related VBN
to TO
the DT
current JJ
study NN
, ,
is VBZ
to TO
extend VB
existing VBG
thesauri NN
by IN
classifying VBG
new JJ
words NNS
with IN
respect NN
to TO
their PRP$
given VBN
structures NNS
eg VBP
< JJ
ref NN
> NNP
tokunaga NN
et NN
al NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
pekar NN
, ,
2004 CD
< NN
/ref NNP
> NNP
. .

an DT
early JJ
effort NN
along IN
this DT
line NN
is VBZ
< JJ
ref NN
> NNP
hearst NN
1992 CD
< NNP
/ref NNP
> NNP
, ,
who WP
attempted VBD
to TO
identify VB
hyponyms NN
from IN
large JJ
text NN
corpora NN
, ,
based VBN
on IN
a DT
set NN
of IN
lexico-syntactic JJ
patterns NNS
, ,
to TO
augment VB
and CC
critique VB
the DT
content NN
of IN
wordnet NN
. .

in IN
contrast NN
, ,
in IN
this DT
paper NN
we PRP
focus VBP
on IN
the DT
problem NN
of IN
determining VBG
the DT
categories NNS
of IN
interest NN
. .

another DT
thread NN
of IN
work NN
is VBZ
on IN
finding VBG
synonymous JJ
terms NNS
and CC
word NN
associations NNS
, ,
as RB
well RB
as IN
automatic JJ
acquisition NN
of IN
is-a JJ
or CC
genus-head JJ
relations NNS
from IN
dictionary JJ
definitions NNS
and CC
free JJ
text NN
< NNP
ref NN
> NNP
hearst NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
caraballo NN
, ,
1999 CD
< NN
/tref NNP
> NNP
. .

that DT
work NN
focuses VBZ
on IN
finding VBG
the DT
right JJ
position NN
for IN
a DT
word NN
within IN
a DT
lexicon NN
, ,
rather RB
than IN
building VBG
up RP
comprehensible JJ
and CC
coherent NN
faceted VBN
hierarchies NNS
. .

one CD
way NN
to TO
overcome VB
this DT
problem NN
might MD
be VB
to TO
give VB
judges NNS
information NN
about IN
a DT
sequence NN
of IN
higher JJR
ancestors NNS
, ,
in IN
order NN
to TO
make VB
the DT
judgement NN
easier NN
. .

< JJ
ref NN
> NNP
charniak NN
roark NN
1998 CD
< NNP
/ref NNP
> NNP
, ,
evaluating VBG
the DT
semantic JJ
lexicon NN
against IN
gold JJ
standard JJ
resources NNS
the DT
muc-4 NN
and CC
the DT
wsj NN
corpus NN
, ,
reports VBZ
that IN
the DT
ratio NN
of IN
valid JJ
to TO
total JJ
entries NNS
for IN
their PRP$
system NN
lies VBZ
between IN
20 CD
and CC
40 CD
. .

such JJ
hierarchical JJ
examples NNS
are VBP
quite RB
sparse JJ
, ,
and CC
greater JJR
coverage NN
was VBD
later RB
attained VBN
by IN
< NNP
ref NN
> NNP
riloff NN
and CC
shepherd NN
1997 CD
< NNP
/ref NNP
> NNP
and CC
< NNP
ref VBP
> NNP
roark NN
and CC
charniak NN
1998 CD
< NNP
/ref NNP
> NNP
in IN
extracting VBG
relations NNS
not RB
of IN
hierarchy NN
but CC
of IN
similarity NN
, ,
by IN
finding VBG
conjunctions NNS
or CC
co-ordinations NNS
such JJ
as IN
cloves NNS
, ,
cinammon NN
, ,
and CC
nutmeg RB
and CC
cars NNS
and CC
trucks NNS
this DT
work NN
was VBD
extended VBN
by IN
< NNP
tref NN
> NNP
caraballo NN
1999 CD
< NNP
/tref NNP
> NNP
, ,
who WP
built VBD
classes NNS
of IN
related JJ
words NNS
in IN
this DT
fashion NN
and CC
then RB
reasoned VBD
that IN
if IN
a DT
hierarchical JJ
relationship NN
could MD
be VB
extracted VBN
for IN
any DT
member NN
of IN
this DT
class NN
, ,
it PRP
could MD
be VB
applied VBN
to TO
all DT
members NNS
of IN
the DT
class NN
. .

this DT
technique NN
can MD
often RB
mistakenly RB
reason NN
across IN
an DT
ambiguous JJ
middle-term NN
, ,
a DT
situation NN
that WDT
was VBD
improved VBN
upon IN
by IN
< NNP
ref NN
> NNP
cederberg NN
and CC
widdows VBZ
2003 CD
< NN
/ref NNP
> NNP
, ,
by IN
combining VBG
pattern-based JJ
extraction NN
with IN
contextual JJ
filtering VBG
using VBG
latent JJ
semantic JJ
analysis NN
. .

semantic JJ
word NN
learning NN
is VBZ
different JJ
from IN
subjective JJ
word NN
learning NN
, ,
but CC
we PRP
have VBP
shown VBN
that IN
metabootstrapping VBG
and CC
basilisk NN
could MD
be VB
successfully RB
applied VBN
to TO
subjectivity NN
learning NN
. .

this DT
includes VBZ
the DT
extraction NN
of IN
hyponymy NN
and CC
synonymy JJ
relations NNS
< VBP
ref JJ
> NNP
hearst NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
tref VBZ
> CD
caraballo NN
1999 CD
< NNP
/tref NNP
> NNP
, ,
among IN
others NNS
as RB
well RB
as IN
meronymy NN
< NNP
ref NN
> NNP
berland NN
and CC
charniak NN
1999 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
meyer NN
2001 CD
< NNP
/ref NNP
> NNP
. .

10 CD
one CD
approach NN
to TO
the DT
extraction NN
of IN
instances NNS
of IN
a DT
particular JJ
lexical JJ
relation NN
is VBZ
the DT
use NN
of IN
patterns NNS
that WDT
express VBP
lexical JJ
relations NNS
structurally RB
explicitly RB
in IN
a DT
corpus NN
< NNP
ref NN
> NNP
hearst NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
berland NN
and CC
charniak NN
1999 CD
< NNP
/ref NNP
> NNP
; :
< NNP
tref VBZ
> CD
caraballo NN
1999 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
meyer NN
2001 CD
< NNP
/ref NNP
> NNP
, ,
and CC
this DT
is VBZ
the DT
approach NN
we PRP
focus VBP
on IN
here RB
. .

this DT
includes VBZ
the DT
extraction NN
of IN
hyponymy NN
and CC
synonymy JJ
relations NNS
< VBP
ref JJ
> NNP
hearst NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
tref VBZ
> CD
caraballo NN
1999 CD
< NNP
/tref NNP
> NNP
, ,
among IN
others NNS
as RB
well RB
as IN
meronymy NN
< NNP
ref NN
> NNP
berland NN
and CC
charniak NN
1999 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
meyer NN
2001 CD
< NNP
/ref NNP
> NNP
. .

10 CD
one CD
approach NN
to TO
the DT
extraction NN
of IN
instances NNS
of IN
a DT
particular JJ
lexical JJ
relation NN
is VBZ
the DT
use NN
of IN
patterns NNS
that WDT
express VBP
lexical JJ
relations NNS
structurally RB
explicitly RB
in IN
a DT
corpus NN
< NNP
ref NN
> NNP
hearst NN
1992 CD
< NNP
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
berland NN
and CC
charniak NN
1999 CD
< NNP
/ref NNP
> NNP
; :
< NNP
tref VBZ
> CD
caraballo NN
1999 CD
< NNP
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
meyer NN
2001 CD
< NNP
/ref NNP
> NNP
, ,
and CC
this DT
is VBZ
the DT
approach NN
we PRP
focus VBP
on IN
here RB
. .

the DT
literature NN
on IN
automated JJ
text NN
categorization NN
is VBZ
enormous JJ
, ,
but CC
assumes VBZ
that IN
a DT
set NN
of IN
categories NNS
has VBZ
already RB
been VBN
created VBN
, ,
whereas IN
the DT
problem NN
here RB
is VBZ
to TO
determine VB
the DT
categories NNS
of IN
interest NN
. .

there RB
has VBZ
also RB
been VBN
extensive JJ
work NN
on IN
finding VBG
synonymous JJ
terms NNS
and CC
word NN
associations NNS
, ,
as RB
well RB
as IN
automatic JJ
acquisition NN
of IN
is-a JJ
or CC
genus-head JJ
relations NNS
from IN
dictionary JJ
definitions NNS
and CC
glosses NNS
< VBP
ref JJ
> NN
klavans NNS
and CC
whitman NN
, ,
2001 CD
< NN
/ref NNP
> NNP
and CC
from IN
free JJ
text NN
< NNP
ref NN
> NNP
hearst NN
, ,
1992 CD
< NN
/ref NNP
> NNP
; :
< NNP
tref VBZ
> NNP
caraballo NN
, ,
1999 CD
< NN
/tref NNP
> NNP
. .

in IN
this DT
paper NN
, ,
we PRP
evaluate VBP
some DT
existing VBG
similarity NN
metrics NNS
and CC
propose NN
and CC
motivate VB
a DT
new JJ
metric JJ
which WDT
outperforms VBZ
the DT
existing VBG
metrics NNS
. .

the DT
advantage NN
of IN
clustering VBG
approaches NNS
is VBZ
that IN
they PRP
permit VBP
algorithms JJ
to TO
identify VB
is-a JJ
relations NNS
that WDT
do VBP
not RB
explicitly RB
appear VBP
in IN
text NN
, ,
however RB
they PRP
generally RB
fail VBP
to TO
produce VB
coherent JJ
clusters NNS
from IN
fewer JJR
than IN
100 CD
million CD
words NNS
; :
hence NN
they PRP
are VBP
unreliable JJ
for IN
small JJ
corpora NNS
. .

in IN
section NN
3 CD
, ,
we PRP
show VBP
how WRB
latent JJ
semantic JJ
analysis NN
can MD
be VB
used VBN
to TO
filter VB
potential JJ
relationships NNS
according VBG
to TO
their PRP$
semantic JJ
plausibility NN
. .

in IN
section NN
4 CD
, ,
we PRP
show VBP
how WRB
correctly RB
extracted VBN
relationships NNS
can MD
be VB
used VBN
as IN
seed-cases NNS
to TO
extract VB
several JJ
more JJR
relationships NNS
, ,
thus RB
improving VBG
recall NN
; :
this DT
work NN
shares NNS
some DT
similarities NNS
with IN
that DT
of IN
< NNP
tref NN
> NNP
caraballo NN
1999 CD
< NNP
/tref NNP
> NNP
. .

in IN
section NN
5 CD
we PRP
show VBP
that IN
combining VBG
the DT
techniques NNS
of IN
section NN
3 CD
and CC
section NN
4 CD
improves VBZ
both DT
precision NN
and CC
recall NN
. .

4 CD
improving VBG
recall NN
using VBG
coordination NN
information NN
one CD
of IN
the DT
main JJ
challenges NNS
facing VBG
hyponymy JJ
extraction NN
is VBZ
that IN
comparatively RB
few JJ
of IN
the DT
correct JJ
relations NNS
that WDT
might MD
be VB
found VBN
in IN
text NN
are VBP
expressed VBN
overtly RB
by IN
the DT
simple JJ
lexicosyntactic JJ
patterns NNS
used VBN
in IN
section NN
2 CD
, ,
as IN
was VBD
apparent JJ
in IN
the DT
results NNS
presented VBD
in IN
that DT
section NN
. .

first RB
of IN
all DT
, ,
it PRP
would MD
be VB
interesting VBG
to TO
apply VB
lsa NN
to TO
a DT
system NN
for IN
building VBG
an DT
entire JJ
hypernym-labelled JJ
ontology NN
in IN
roughly RB
the DT
way NN
described VBN
in IN
< NNP
tref NN
> NNP
caraballo NN
, ,
1999 CD
< NN
/tref NNP
> NNP
, ,
perhaps RB
by IN
using VBG
an DT
lsa-weighted JJ
voting NN
method NN
to TO
determine VB
which WDT
hypernym NN
would MD
be VB
used VBN
to TO
label VB
each DT
node NN
. .

also RB
, ,
systematic JJ
comparison NN
of IN
the DT
lexicosyntactic JJ
patterns NNS
used VBN
for IN
extraction NN
to TO
determine VB
the DT
relative JJ
productiveness NN
and CC
accuracy NN
of IN
each DT
pattern NN
might MD
prove VB
illuminating NN
, ,
as IN
would MD
comparison VB
across IN
different JJ
corpora NN
to TO
determine VB
the DT
impact NN
of IN
the DT
topic NN
area NN
and CC
medium/format NN
of IN
documents NNS
on IN
the DT
effectiveness NN
of IN
hyponymy JJ
extraction NN
. .

this DT
project NN
is VBZ
meant VBN
to TO
provide VB
a DT
tool NN
to TO
support VB
other JJ
methods NNS
. .

2 CD
previous JJ
work NN
to TO
the DT
best JJS
of IN
our PRP$
knowledge NN
, ,
this DT
is VBZ
the DT
first JJ
attempt NN
to TO
automatically RB
rank VB
nouns NNS
based VBN
on IN
specificity NN
. .

our PRP$
disposal NN
, ,
wordnet NN
< NN
ref NN
> NNP
fellbaum NN
, ,
1998 CD
< NN
/ref NNP
> NNP
contains VBZ
very RB
little JJ
information NN
that WDT
would MD
be VB
considered VBN
as IN
being VBG
about IN
attributesonly RB
information NN
about IN
parts NNS
, ,
not RB
about IN
qualities NNS
such JJ
as IN
height NN
, ,
or CC
even RB
to TO
the DT
values NNS
of IN
such JJ
attributes NNS
in IN
the DT
adjective JJ
networkand NN
this DT
information NN
is VBZ
still RB
very RB
sparse JJ
. .

2 CD
the DT
work NN
discussed VBN
here RB
could MD
be VB
perhaps RB
best RBS
described VBN
as IN
an DT
example NN
of IN
empirical JJ
ontology NN
: :
using VBG
linguistics NNS
and CC
philosophical JJ
ideas NNS
to TO
improve VB
the DT
results NNS
of IN
empirical JJ
work NN
on IN
lexical JJ
/ NNP
ontology NN
acquisition NN
, ,
and CC
vice NN
versa NN
, ,
using VBG
findings NNS
from IN
empirical JJ
analysis NN
to TO
question VB
some DT
of IN
the DT
assumptions NNS
of IN
theoretical JJ
work NN
on IN
ontology NN
and CC
the DT
lexicon NN
. .

my PRP$
analysis NN
of IN
the DT
sinica NN
corpus NN
shows VBZ
that IN
contrary JJ
to TO
expectation VB
, ,
most JJS
of IN
unknown JJ
words NNS
in IN
chinese JJ
are VBP
common JJ
nouns NNS
, ,
adjectives NNS
, ,
and CC
verbs VBZ
rather RB
than IN
proper JJ
nouns NNS
. .

while IN
context NN
is VBZ
clearly RB
an DT
important JJ
feature NN
, ,
this DT
paper NN
focuses VBZ
on IN
non-contextual JJ
features NNS
, ,
which WDT
may MD
play VB
a DT
key JJ
role NN
for IN
unknown JJ
words NNS
that WDT
occur VBP
only RB
once RB
and CC
hence RB
have VBP
limited VBN
context NN
. .

another DT
related JJ
line NN
of IN
work NN
is VBZ
automated VBN
ontology JJ
construction NN
, ,
which WDT
aims VBZ
to TO
create VB
lexical JJ
hierarchies NNS
based VBN
on IN
semantic JJ
classes NNS
eg VBP
, ,
< JJ
tref NN
> NNP
caraballo NN
, ,
1999 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
cimiano NN
and CC
volker NN
, ,
2005 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
mann NN
, ,
2002 CD
< NN
/ref NNP
> NNP
, ,
and CC
learning VBG
semantic JJ
relations NNS
such JJ
as IN
meronymy NN
< NNP
ref NN
> NNP
berland NN
and CC
charniak NN
, ,
1999 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
girju NN
et NN
al NN
, ,
2003 CD
< NN
/ref NNP
> NNP
. .

weakly RB
supervised VBD
learning VBG
methods NNS
for IN
semantic JJ
lexicon NN
generation NN
have VBP
utilized VBN
co-occurrence NN
statistics NNS
< VBP
ref JJ
> NNP
riloff NN
and CC
shepherd NN
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
roark NN
and CC
charniak NN
, ,
1998 CD
< NN
/ref NNP
> NNP
, ,
syntactic JJ
information NN
< NNP
ref NN
> NNP
tanev NN
and CC
magnini NN
, ,
2006 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
pantel NN
and CC
ravichandran NN
, ,
2004 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
phillips NNS
and CC
riloff NN
, ,
2002 CD
< NN
/ref NNP
> NNP
, ,
lexico-syntactic JJ
contextual JJ
patterns NNS
eg RB
, ,
resides NNS
in IN
< JJ
location NN
> NN
or CC
moved VBN
to TO
< VB
location NN
> NNP
< NNP
ref NN
> NNP
riloff NN
and CC
jones NNS
, ,
1999 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
thelen NN
and CC
riloff NN
, ,
2002 CD
< NN
/ref NNP
> NNP
, ,
and CC
local JJ
and CC
global JJ
contexts NN
< NNP
ref NN
> NNP
fleischman NN
and CC
hovy NN
, ,
2002 CD
< NN
/ref NNP
> NNP
. .

the DT
features NNS
are VBP
shown VBN
with IN
hidden JJ
variables NNS
corresponding VBG
to TO
wordspecific VB
hidden JJ
values NNS
, ,
such JJ
as IN
shares1 NN
or CC
bought3 NN
. .

however RB
, ,
we PRP
did VBD
not RB
find VB
a DT
significant JJ
difference NN
between IN
the DT
performance NN
of IN
either DT
method NN
. .

mainstream NN
approaches NNS
in IN
statistical JJ
parsing NN
are VBP
based VBN
on IN
nondeterministic JJ
parsing NN
techniques NNS
, ,
usually RB
employing VBG
some DT
kind NN
of IN
dynamic JJ
programming NN
, ,
in IN
combination NN
with IN
generative JJ
probabilistic JJ
models NNS
that IN
provide VBP
an DT
n-best JJ
ranking NN
of IN
the DT
set NN
of IN
candidate NN
analyses NNS
derived VBN
by IN
the DT
parser NN
< NNP
ref NN
> NN
collins NNS
, ,
1997 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
collins NNS
, ,
1999 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
charniak NN
, ,
2000 CD
< NN
/ref NNP
> NNP
. .

these DT
parsers NNS
can MD
be VB
enhanced VBN
by IN
using VBG
a DT
discriminative JJ
model NN
, ,
which WDT
reranks VBZ
the DT
analyses NNS
output NN
by IN
the DT
parser NN
< NNP
tref NN
> NNP
johnson NN
et NN
al NN
, ,
1999 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> JJ
collins NNS
and CC
duffy NN
, ,
2005 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
charniak NN
and CC
johnson NN
, ,
2005 CD
< NN
/ref NNP
> NNP
. .

a DT
radically RB
different JJ
approach NN
is VBZ
to TO
perform VB
disambiguation NN
deterministically RB
, ,
using VBG
a DT
greedy NN
parsing VBG
algorithm NN
that WDT
approximates VBZ
a DT
globally RB
optimal JJ
solution NN
by IN
making VBG
a DT
sequence NN
of IN
locally RB
optimal JJ
choices NNS
, ,
guided VBN
by IN
a DT
classifier NN
trained VBN
on IN
gold JJ
standard JJ
derivations NNS
from IN
a DT
treebank NN
. .

maximum-entropy JJ
markov NN
models NNS
< VBP
ref JJ
> NNP
mccallum NN
et NN
al NN
, ,
2000 CD
< NN
/ref NNP
> NNP
and CC
stochastic JJ
unification-based JJ
grammars NNS
< VBP
tref JJ
> NNP
johnson NN
et NN
al NN
, ,
1999 CD
< NN
/tref NNP
> NNP
are VBP
standardly RB
estimated VBN
with IN
conditional JJ
estimators NNS
, ,
and CC
it PRP
would MD
be VB
interesting VBG
to TO
know VB
whether IN
conditional JJ
estimation NN
affects VBZ
the DT
quality NN
of IN
the DT
estimated VBN
model NN
. .

it PRP
should MD
be VB
noted VBN
that IN
in IN
practice NN
, ,
the DT
mcle NN
of IN
a DT
model NN
with IN
a DT
large JJ
number NN
of IN
features NNS
with IN
complex JJ
dependencies NNS
may MD
yield VB
far RB
better JJR
performance NN
than IN
the DT
mle NN
of IN
the DT
much JJ
smaller JJR
model NN
that WDT
could MD
be VB
estimated VBN
with IN
the DT
same JJ
computational JJ
effort NN
. .

nevertheless RB
, ,
as IN
this DT
paper NN
shows VBZ
, ,
conditional JJ
estimators NNS
can MD
be VB
used VBN
with IN
other JJ
kinds NNS
of IN
models NNS
besides IN
maxent JJ
models NNS
, ,
and CC
in IN
any DT
event NN
it PRP
is VBZ
interesting VBG
to TO
ask VB
whether IN
the DT
mle NN
differs NNS
from IN
the DT
mcle NN
in IN
actual JJ
applications NNS
, ,
and CC
if IN
so RB
, ,
how WRB
. .

therefore RB
there EX
are VBP
a DT
large JJ
number NN
of IN
features NNS
available JJ
that WDT
could MD
be VB
used VBN
by IN
stochastic JJ
models NNS
for IN
disambiguation NN
. .

other JJ
researchers NNS
have VBP
worked VBN
on IN
extracting VBG
features NNS
useful JJ
for IN
disambiguation NN
from IN
unification JJ
grammar NN
analyses NNS
and CC
have VBP
built VBN
log JJ
linear JJ
models NNS
aka VBP
stochastic JJ
unification NN
based VBN
grammars NNS
< JJ
tref JJ
> NNP
johnson NN
et NN
al NN
, ,
1999 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
riezler NN
et NN
al NN
, ,
2000 CD
< NN
/ref NNP
> NNP
. .

one CD
is VBZ
for IN
a DT
simple JJ
model NN
with IN
a DT
relatively RB
small JJ
number NN
of IN
features NNS
, ,
and CC
the DT
other JJ
is VBZ
for IN
a DT
model NN
with IN
a DT
large JJ
number NN
of IN
features NNS
. .

the DT
usefulness NN
of IN
priors NNS
in IN
maximum JJ
entropy NN
models NNS
is VBZ
not RB
new JJ
to TO
this DT
work NN
: :
gaussian JJ
prior JJ
smoothing NN
is VBZ
advocated VBN
in IN
< NNP
ref NN
> NNP
chen NN
and CC
rosenfeld NN
2000 CD
< NNP
/ref NNP
> NNP
, ,
and CC
used VBN
in IN
all PDT
the DT
stochastic JJ
lfg NN
work NN
< NNP
tref NN
> NNP
johnson NN
et NN
al NN
, ,
1999 CD
< NN
/tref NNP
> NNP
. .

however RB
, ,
until IN
recently RB
, ,
its PRP$
role NN
and CC
importance NN
have VBP
not RB
been VBN
widely RB
understood JJ
. .

for IN
example NN
, ,
< NNP
ref VBZ
> NNP
zhang NNP
and CC
oles NNS
2001 CD
< NNP
/ref NNP
> NNP
attribute VBZ
the DT
perceived JJ
limited JJ
success NN
of IN
logistic JJ
regression NN
for IN
text JJ
categorization NN
to TO
a DT
lack NN
of IN
use NN
of IN
regularization NN
. .

the DT
data NN
for IN
estimation NN
consists NNS
of IN
pairs NNS
of IN
original JJ
sentences NNS
y RB
and CC
goldstandard VB
summarized VBN
f-structures NNS
s NNS
which WDT
were VBD
manually RB
selected VBN
from IN
the DT
transfer NN
output NN
for IN
each DT
sentence NN
. .

for IN
training VBG
data NNS
sj NN
, ,
yjmj1 NN
and CC
a DT
set NN
of IN
possible JJ
summarized JJ
structures NNS
sy VBP
for IN
each DT
sentence NN
y NN
, ,
the DT
objective NN
was VBD
to TO
maximize VB
a DT
discriminative JJ
criterion NN
, ,
namely RB
the DT
conditional JJ
likelihood NN
l NN
of IN
a DT
summarized JJ
f-structure NN
given VBN
the DT
sentence NN
. .

in IN
global JJ
linear JJ
models NNS
glms NNS
for IN
structured JJ
prediction NN
, ,
eg NN
, ,
< NNP
tref VBZ
> NNP
johnson NN
et NN
al NN
, ,
1999 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
lafferty NN
et NN
al NN
, ,
2001 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
collins NNS
, ,
2002 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
altun NN
et NN
al NN
, ,
2003 CD
< NN
/ref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
taskar NN
et NN
al NN
, ,
2004 CD
< NN
/ref NNP
> NNP
, ,
the DT
optimal JJ
label NN
y NN
for IN
an DT
input NN
x NN
is VBZ
y JJ
arg JJ
max NN
yyx NN
w NN
fx NN
, ,
y RB
1 CD
where WRB
yx NN
is VBZ
the DT
set NN
of IN
possible JJ
labels NNS
for IN
the DT
input NN
x NNP
; :
fx NN
, ,
y NN
rd NN
is VBZ
a DT
feature NN
vector NN
that WDT
represents VBZ
the DT
pair NN
x NNP
, ,
y NN
; :
and CC
w NN
is VBZ
a DT
parameter NN
vector NN
. .

this DT
paper NN
describes VBZ
a DT
glm NN
for IN
natural JJ
language NN
parsing NN
, ,
trained VBD
using VBG
the DT
averaged JJ
perceptron NN
. .

a DT
crucial JJ
advantage NN
of IN
our PRP$
approach NN
is VBZ
that IN
it PRP
considers VBZ
a DT
very RB
large JJ
set NN
of IN
alternatives NNS
in IN
yx NN
, ,
and CC
can MD
thereby VB
avoid JJ
search NN
errors NNS
that WDT
may MD
be VB
made VBN
in IN
the DT
first-pass NN
parser1 NN
another DT
approach NN
that WDT
allows VBZ
efficient JJ
training NN
of IN
glms NN
is VBZ
to TO
use VB
simpler JJ
syntactic JJ
representations NNS
, ,
in IN
particular JJ
dependency NN
structures VBZ
mcdon1some JJ
features NNS
used VBN
within IN
reranking VBG
approaches NNS
may MD
be VB
difficult JJ
to TO
incorporate VB
within IN
dynamic JJ
programming NN
, ,
but CC
it PRP
is VBZ
nevertheless RB
useful JJ
to TO
make VB
use NN
of IN
glms NNS
in IN
the DT
dynamicprogramming NN
stage NN
of IN
parsing NN
. .

moreover RB
, ,
property NN
design NN
can MD
be VB
carried VBN
out RP
in IN
a DT
targeted JJ
way NN
, ,
ie JJ
properties NNS
can MD
be VB
designed VBN
in IN
order NN
to TO
improve VB
the DT
disambiguation NN
of IN
grammatical JJ
relations NNS
that IN
, ,
so RB
far RB
, ,
are VBP
disambiguated VBN
particularly RB
poorly RB
or CC
that DT
are VBP
of IN
special JJ
interest NN
for IN
the DT
task NN
that IN
the DT
systems NNS
output NN
is VBZ
used VBN
for IN
. .

by IN
demonstrating VBG
that IN
property NN
design NN
is VBZ
the DT
key NN
to TO
good JJ
log-linear JJ
models NNS
for IN
deepsyntactic JJ
disambiguation NN
, ,
our PRP$
work NN
confirms VBZ
that IN
specifying VBG
the DT
features NNS
of IN
a DT
subg JJ
stochastic JJ
unification-based JJ
grammar NN
is VBZ
as RB
much JJ
an DT
empirical JJ
matter NN
as IN
specifying VBG
the DT
grammar NN
itself PRP
< JJ
tref NN
> NNP
johnson NN
et NN
al NN
, ,
1999 CD
< NN
/tref NNP
> NNP
. .

furthermore RB
, ,
i JJ
thank VBD
the DT
audiences NNS
at IN
several JJ
pargram JJ
meetings NNS
, ,
at IN
the DT
research NN
workshop NN
of IN
the DT
israel NN
science NN
foundation NN
on IN
large-scale JJ
grammar NN
development NN
and CC
grammar NN
engineering NN
at IN
the DT
university NN
of IN
haifa NN
and CC
at IN
the DT
sfb NN
732 CD
opening VBG
colloquium NN
in IN
stuttgart NN
for IN
their PRP$
important JJ
feedback NN
on IN
earlier JJR
versions NNS
of IN
this DT
work NN
. .

firstly RB
, ,
the DT
rudimentary JJ
character NN
of IN
functional JJ
annotations NNS
in IN
standard JJ
treebanks NNS
has VBZ
hindered VBN
the DT
direct JJ
use NN
of IN
such JJ
data NNS
for IN
statistical JJ
estimation NN
of IN
linguistically RB
fine-grained JJ
statistical JJ
parsing VBG
systems NNS
. .

furthermore RB
, ,
the DT
effort NN
involved VBN
in IN
coding VBG
broadcoverage NN
grammars NNS
by IN
hand NN
has VBZ
often RB
led VBN
to TO
the DT
specialization NN
of IN
grammars NNS
to TO
relatively RB
small JJ
domains NNS
, ,
thus RB
sacrificing VBG
grammar NN
coverage NN
ie VBD
the DT
percentage NN
of IN
sentences NNS
for IN
which WDT
at IN
least JJS
one CD
analysis NN
is VBZ
found VBN
on IN
free JJ
text NN
. .

one CD
appeal NN
of IN
these DT
methods NNS
is VBZ
their PRP$
flexibility NN
in IN
incorporating VBG
features NNS
into IN
a DT
model NN
: :
essentially RB
any DT
features NNS
which WDT
might MD
be VB
useful JJ
in IN
discriminating VBG
good JJ
from IN
bad JJ
structures NNS
can MD
be VB
included VBN
. .

a DT
second JJ
appeal NN
of IN
these DT
methods NNS
is VBZ
that IN
their PRP$
training NN
criterion NN
is VBZ
often RB
discriminative JJ
, ,
attempting VBG
to TO
explicitly RB
push VB
the DT
score NN
or CC
probability NN
of IN
the DT
correct JJ
structure NN
for IN
each DT
training NN
sentence NN
above IN
the DT
score NN
of IN
competing VBG
structures NNS
. .

as IN
expected VBN
, ,
we PRP
observed VBD
that IN
the DT
regularization NN
term NN
increases VBZ
the DT
accuracy NN
, ,
especially RB
when WRB
the DT
training NN
data NNS
is VBZ
small JJ
; :
but CC
we PRP
did VBD
not RB
observe VB
much JJ
difference NN
when WRB
we PRP
used VBD
different JJ
regularization NN
terms NNS
. .

our PRP$
goal NN
in IN
this DT
paper NN
is VBZ
not RB
to TO
build VB
the DT
best JJS
tagger NN
or CC
recognizer NN
, ,
but CC
to TO
compare VB
different JJ
loss NN
functions NNS
and CC
optimization NN
methods NNS
. .

since IN
we PRP
did VBD
not RB
spend VB
much JJ
effort NN
on IN
designing VBG
the DT
most RBS
useful JJ
features NNS
, ,
our PRP$
results NNS
are VBP
slightly RB
worse JJR
than IN
, ,
but CC
comparable JJ
to TO
the DT
best JJS
performing NN
models NNS
. .

this DT
method NN
generates VBZ
50-best JJ
lists NNS
that WDT
are VBP
of IN
substantially RB
higher JJR
quality NN
than IN
previously RB
obtainable JJ
. .

we PRP
used VBD
these DT
parses NNS
as IN
the DT
input NN
to TO
a DT
maxent NN
reranker NN
< NNP
tref NN
> NNP
johnson NN
et NN
al NN
, ,
1999 CD
< NN
/tref NNP
> NNP
; :
< NNP
ref VBZ
> NNP
riezler NN
et NN
al NN
, ,
2002 CD
< NN
/ref NNP
> VBZ
that WDT
selects VBZ
the DT
best JJS
parse NN
from IN
the DT
set NN
of IN
parses NNS
for IN
each DT
sentence NN
, ,
obtaining VBG
an DT
f-score NN
of IN
910 CD
on IN
sentences NNS
of IN
length NN
100 CD
or CC
less JJR
. .

we PRP
describe VBP
a DT
reranking NN
parser NN
which WDT
uses VBZ
a DT
regularized JJ
maxent NN
reranker NN
to TO
select VB
the DT
best JJS
parse NN
from IN
the DT
50-best JJ
parses NNS
returned VBN
by IN
a DT
generative JJ
parsing NN
model NN
. .

